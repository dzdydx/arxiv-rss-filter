{
  "https://rss.arxiv.org/rss/cs.CL+cs.CV+cs.MM+cs.LG+cs.SI": {
    "feed": {
      "title": "cs.CL, cs.CV, cs.MM, cs.LG, cs.SI updates on arXiv.org",
      "link": "http://rss.arxiv.org/rss/cs.CL+cs.CV+cs.MM+cs.LG+cs.SI",
      "updated": "Fri, 02 May 2025 04:09:52 +0000",
      "published": "Fri, 02 May 2025 00:00:00 -0400"
    },
    "entries": [
      {
        "id": "oai:arXiv.org:2505.00001v1",
        "title": "Rosetta-PL: Propositional Logic as a Benchmark for Large Language Model Reasoning",
        "link": "https://arxiv.org/abs/2505.00001",
        "author": "Shaun Baek, Shaun Esua-Mensah, Cyrus Tsui, Sejan Vigneswaralingam, Abdullah Alali, Michael Lu, Vasu Sharma, Kevin Zhu",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00001v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are primarily trained on high-resource natural languages, limiting their effectiveness in low-resource settings and in tasks requiring deep logical reasoning. This research introduces Rosetta-PL, a benchmark designed to evaluate LLMs' logical reasoning and generalization capabilities in a controlled environment. We construct Rosetta-PL by translating a dataset of logical propositions from Lean into a custom logical language, which is then used to fine-tune an LLM (e.g., GPT-4o). Our experiments analyze the impact of the size of the dataset and the translation methodology on the performance of the model. Our results indicate that preserving logical relationships in the translation process significantly boosts precision, with accuracy plateauing beyond roughly 20,000 training samples. These insights provide valuable guidelines for optimizing LLM training in formal reasoning tasks and improving performance in various low-resource language applications."
      },
      {
        "id": "oai:arXiv.org:2505.00002v1",
        "title": "Symbol grounding in computational systems: A paradox of intentions",
        "link": "https://arxiv.org/abs/2505.00002",
        "author": "Vincent C. M\\\"uller",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00002v1 Announce Type: new \nAbstract: The paper presents a paradoxical feature of computational systems that suggests that computationalism cannot explain symbol grounding. If the mind is a digital computer, as computationalism claims, then it can be computing either over meaningful symbols or over meaningless symbols. If it is computing over meaningful symbols its functioning presupposes the existence of meaningful symbols in the system, i.e. it implies semantic nativism. If the mind is computing over meaningless symbols, no intentional cognitive processes are available prior to symbol grounding. In this case, no symbol grounding could take place since any grounding presupposes intentional cognitive processes. So, whether computing in the mind is over meaningless or over meaningful symbols, computationalism implies semantic nativism."
      },
      {
        "id": "oai:arXiv.org:2505.00003v1",
        "title": "The Mind in the Machine: A Survey of Incorporating Psychological Theories in LLMs",
        "link": "https://arxiv.org/abs/2505.00003",
        "author": "Zizhou Liu, Ziwei Gong, Lin Ai, Zheng Hui, Run Chen, Colin Wayne Leach, Michelle R. Greene, Julia Hirschberg",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00003v1 Announce Type: new \nAbstract: Psychological insights have long shaped pivotal NLP breakthroughs, including the cognitive underpinnings of attention mechanisms, formative reinforcement learning, and Theory of Mind-inspired social modeling. As Large Language Models (LLMs) continue to grow in scale and complexity, there is a rising consensus that psychology is essential for capturing human-like cognition, behavior, and interaction. This paper reviews how psychological theories can inform and enhance stages of LLM development, including data, pre-training, post-training, and evaluation\\&amp;application. Our survey integrates insights from cognitive, developmental, behavioral, social, personality psychology, and psycholinguistics. Our analysis highlights current trends and gaps in how psychological theories are applied. By examining both cross-domain connections and points of tension, we aim to bridge disciplinary divides and promote more thoughtful integration of psychology into future NLP research."
      },
      {
        "id": "oai:arXiv.org:2505.00004v1",
        "title": "LangVAE and LangSpace: Building and Probing for Language Model VAEs",
        "link": "https://arxiv.org/abs/2505.00004",
        "author": "Danilo S. Carvalho, Yingji Zhang, Harriet Unsworth, Andr\\'e Freitas",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00004v1 Announce Type: new \nAbstract: We present LangVAE, a novel framework for modular construction of variational autoencoders (VAEs) on top of pre-trained large language models (LLMs). Such language model VAEs can encode the knowledge of their pre-trained components into more compact and semantically disentangled representations. The representations obtained in this way can be analysed with the LangVAE companion framework: LangSpace, which implements a collection of probing methods, such as vector traversal and interpolation, disentanglement measures, and cluster visualisations. LangVAE and LangSpace offer a flexible, efficient and scalable way of building and analysing textual representations, with simple integration for models available on the HuggingFace Hub. Additionally, we conducted a set of experiments with different encoder and decoder combinations, as well as annotated inputs, revealing a wide range of interactions across architectural families and sizes w.r.t. generalisation and disentanglement. Our findings demonstrate a promising framework for systematising the experimentation and understanding of textual representations."
      },
      {
        "id": "oai:arXiv.org:2505.00005v1",
        "title": "Belief System Dynamics as Network of Single Layered Neural Network",
        "link": "https://arxiv.org/abs/2505.00005",
        "author": "Yujian Fu",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00005v1 Announce Type: new \nAbstract: As problems in political polarization and the spread of misinformation become serious, belief propagation on a social network becomes an important question to explore. Previous breakthroughs have been made in algorithmic approaches to understanding how group consensus or polarization can occur in a population. This paper proposed a modified model of the Friedkin-Johnsen model that tries to explain the underlying stubbornness of individual as well as possible back fire effect by treating each individual as a single layer neural network on a set of evidence for a particular statement with input being confidence level on each evidence, and belief of the statement is the output of this neural network.\n  In this papar, we reafirmed the importance of Madison's cure for the mischief of faction, and found that when structure of understanding is polarized, a network with a giant component can decrease the variance in the belief distribution more than a network with two communities, but creates more social pressure by doing so. We also found that when community structure is formed, variance in the belief distribution become less sensitive to confidence level of individuals. The model can have various applications to political and historical problems caused by misinfomation and conflicting economic interest as well as applications to personality theory and behavior psychology."
      },
      {
        "id": "oai:arXiv.org:2505.00006v1",
        "title": "Toward a digital twin of U.S. Congress",
        "link": "https://arxiv.org/abs/2505.00006",
        "author": "Hayden Helm, Tianyi Chen, Harvey McGuinness, Paige Lee, Brandon Duderstadt, Carey E. Priebe",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00006v1 Announce Type: new \nAbstract: In this paper we provide evidence that a virtual model of U.S. congresspersons based on a collection of language models satisfies the definition of a digital twin. In particular, we introduce and provide high-level descriptions of a daily-updated dataset that contains every Tweet from every U.S. congressperson during their respective terms. We demonstrate that a modern language model equipped with congressperson-specific subsets of this data are capable of producing Tweets that are largely indistinguishable from actual Tweets posted by their physical counterparts. We illustrate how generated Tweets can be used to predict roll-call vote behaviors and to quantify the likelihood of congresspersons crossing party lines, thereby assisting stakeholders in allocating resources and potentially impacting real-world legislative dynamics. We conclude with a discussion of the limitations and important extensions of our analysis."
      },
      {
        "id": "oai:arXiv.org:2505.00008v1",
        "title": "A Scoping Review of Natural Language Processing in Addressing Medically Inaccurate Information: Errors, Misinformation, and Hallucination",
        "link": "https://arxiv.org/abs/2505.00008",
        "author": "Zhaoyi Sun, Wen-Wai Yim, Ozlem Uzuner, Fei Xia, Meliha Yetisgen",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00008v1 Announce Type: new \nAbstract: Objective: This review aims to explore the potential and challenges of using Natural Language Processing (NLP) to detect, correct, and mitigate medically inaccurate information, including errors, misinformation, and hallucination. By unifying these concepts, the review emphasizes their shared methodological foundations and their distinct implications for healthcare. Our goal is to advance patient safety, improve public health communication, and support the development of more reliable and transparent NLP applications in healthcare.\n  Methods: A scoping review was conducted following PRISMA guidelines, analyzing studies from 2020 to 2024 across five databases. Studies were selected based on their use of NLP to address medically inaccurate information and were categorized by topic, tasks, document types, datasets, models, and evaluation metrics.\n  Results: NLP has shown potential in addressing medically inaccurate information on the following tasks: (1) error detection (2) error correction (3) misinformation detection (4) misinformation correction (5) hallucination detection (6) hallucination mitigation. However, challenges remain with data privacy, context dependency, and evaluation standards.\n  Conclusion: This review highlights the advancements in applying NLP to tackle medically inaccurate information while underscoring the need to address persistent challenges. Future efforts should focus on developing real-world datasets, refining contextual methods, and improving hallucination management to ensure reliable and transparent healthcare applications."
      },
      {
        "id": "oai:arXiv.org:2505.00009v1",
        "title": "Efficient Knowledge Transfer in Multi-Task Learning through Task-Adaptive Low-Rank Representation",
        "link": "https://arxiv.org/abs/2505.00009",
        "author": "Xiao Zhang, Kangsheng Wang, Tianyu Hu, Huimin Ma",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00009v1 Announce Type: new \nAbstract: Pre-trained language models (PLMs) demonstrate remarkable intelligence but struggle with emerging tasks unseen during training in real-world applications. Training separate models for each new task is usually impractical. Multi-task learning (MTL) addresses this challenge by transferring shared knowledge from source tasks to target tasks. As an dominant parameter-efficient fine-tuning method, prompt tuning (PT) enhances MTL by introducing an adaptable vector that captures task-specific knowledge, which acts as a prefix to the original prompt that preserves shared knowledge, while keeping PLM parameters frozen. However, PT struggles to effectively capture the heterogeneity of task-specific knowledge due to its limited representational capacity. To address this challenge, we propose Task-Adaptive Low-Rank Representation (TA-LoRA), an MTL method built on PT, employing the low-rank representation to model task heterogeneity and a fast-slow weights mechanism where the slow weight encodes shared knowledge, while the fast weight captures task-specific nuances, avoiding the mixing of shared and task-specific knowledge, caused by training low-rank representations from scratch. Moreover, a zero-initialized attention mechanism is introduced to minimize the disruption of immature low-rank components on original prompts during warm-up epochs. Experiments on 16 tasks demonstrate that TA-LoRA achieves state-of-the-art performance in full-data and few-shot settings while maintaining superior parameter efficiency."
      },
      {
        "id": "oai:arXiv.org:2505.00010v1",
        "title": "Jailbreak Detection in Clinical Training LLMs Using Feature-Based Predictive Models",
        "link": "https://arxiv.org/abs/2505.00010",
        "author": "Tri Nguyen, Lohith Srikanth Pentapalli, Magnus Sieverding, Laurah Turner, Seth Overla, Weibing Zheng, Chris Zhou, David Furniss, Danielle Weber, Michael Gharib, Matt Kelleher, Michael Shukis, Cameron Pawlik, Kelly Cohen",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00010v1 Announce Type: new \nAbstract: Jailbreaking in Large Language Models (LLMs) threatens their safe use in sensitive domains like education by allowing users to bypass ethical safeguards. This study focuses on detecting jailbreaks in 2-Sigma, a clinical education platform that simulates patient interactions using LLMs. We annotated over 2,300 prompts across 158 conversations using four linguistic variables shown to correlate strongly with jailbreak behavior. The extracted features were used to train several predictive models, including Decision Trees, Fuzzy Logic-based classifiers, Boosting methods, and Logistic Regression. Results show that feature-based predictive models consistently outperformed Prompt Engineering, with the Fuzzy Decision Tree achieving the best overall performance. Our findings demonstrate that linguistic-feature-based models are effective and explainable alternatives for jailbreak detection. We suggest future work explore hybrid frameworks that integrate prompt-based flexibility with rule-based robustness for real-time, spectrum-based jailbreak monitoring in educational LLMs."
      },
      {
        "id": "oai:arXiv.org:2505.00012v1",
        "title": "The AI Co-Ethnographer: How Far Can Automation Take Qualitative Research?",
        "link": "https://arxiv.org/abs/2505.00012",
        "author": "Fabian Retkowski, Andreas Sudmann, Alexander Waibel",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00012v1 Announce Type: new \nAbstract: Qualitative research often involves labor-intensive processes that are difficult to scale while preserving analytical depth. This paper introduces The AI Co-Ethnographer (AICoE), a novel end-to-end pipeline developed for qualitative research and designed to move beyond the limitations of simply automating code assignments, offering a more integrated approach. AICoE organizes the entire process, encompassing open coding, code consolidation, code application, and even pattern discovery, leading to a comprehensive analysis of qualitative data."
      },
      {
        "id": "oai:arXiv.org:2505.00013v1",
        "title": "Performance Evaluation of Emotion Classification in Japanese Using RoBERTa and DeBERTa",
        "link": "https://arxiv.org/abs/2505.00013",
        "author": "Yoichi Takenaka",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00013v1 Announce Type: new \nAbstract: Background Practical applications such as social media monitoring and customer-feedback analysis require accurate emotion detection for Japanese text, yet resource scarcity and class imbalance hinder model performance.\n  Objective This study aims to build a high-accuracy model for predicting the presence or absence of eight Plutchik emotions in Japanese sentences.\n  Methods Using the WRIME corpus, we transform reader-averaged intensity scores into binary labels and fine-tune four pre-trained language models (BERT, RoBERTa, DeBERTa-v3-base, DeBERTa-v3-large). For context, we also assess two large language models (TinySwallow-1.5B-Instruct and ChatGPT-4o). Accuracy and F1-score serve as evaluation metrics.\n  Results DeBERTa-v3-large attains the best mean accuracy (0.860) and F1-score (0.662), outperforming all other models. It maintains robust F1 across both high-frequency emotions (e.g., Joy, Anticipation) and low-frequency emotions (e.g., Anger, Trust). The LLMs lag, with ChatGPT-4o and TinySwallow-1.5B-Instruct scoring 0.527 and 0.292 in mean F1, respectively.\n  Conclusion The fine-tuned DeBERTa-v3-large model currently offers the most reliable solution for binary emotion classification in Japanese. We release this model as a pip-installable package (pip install deberta-emotion-predictor). Future work should augment data for rare emotions, reduce model size, and explore prompt engineering to improve LLM performance.\n  This manuscript is under review for possible publication in New Generation Computing."
      },
      {
        "id": "oai:arXiv.org:2505.00014v1",
        "title": "Manifold-Constrained Sentence Embeddings via Triplet Loss: Projecting Semantics onto Spheres, Tori, and M\\\"obius Strips",
        "link": "https://arxiv.org/abs/2505.00014",
        "author": "Vinit K. Chavan",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00014v1 Announce Type: new \nAbstract: Recent advances in representation learning have emphasized the role of embedding geometry in capturing semantic structure. Traditional sentence embeddings typically reside in unconstrained Euclidean spaces, which may limit their ability to reflect complex relationships in language. In this work, we introduce a novel framework that constrains sentence embeddings to lie on continuous manifolds -- specifically the unit sphere, torus, and M\\\"obius strip -- using triplet loss as the core training objective. By enforcing differential geometric constraints on the output space, our approach encourages the learning of embeddings that are both discriminative and topologically structured.\n  We evaluate our method on benchmark datasets (AG News and MBTI) and compare it to classical baselines including TF-IDF, Word2Vec, and unconstrained Keras-derived embeddings. Our results demonstrate that manifold-constrained embeddings, particularly those projected onto spheres and M\\\"obius strips, significantly outperform traditional approaches in both clustering quality (Silhouette Score) and classification performance (Accuracy). These findings highlight the value of embedding in manifold space -- where topological structure complements semantic separation -- offering a new and mathematically grounded direction for geometric representation learning in NLP."
      },
      {
        "id": "oai:arXiv.org:2505.00015v1",
        "title": "Design and Application of Multimodal Large Language Model Based System for End to End Automation of Accident Dataset Generation",
        "link": "https://arxiv.org/abs/2505.00015",
        "author": "MD Thamed Bin Zaman Chowdhury, Moazzem Hossain",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00015v1 Announce Type: new \nAbstract: Road traffic accidents remain a major public safety and socio-economic issue in developing countries like Bangladesh. Existing accident data collection is largely manual, fragmented, and unreliable, resulting in underreporting and inconsistent records. This research proposes a fully automated system using Large Language Models (LLMs) and web scraping techniques to address these challenges. The pipeline consists of four components: automated web scraping code generation, news collection from online sources, accident news classification with structured data extraction, and duplicate removal. The system uses the multimodal generative LLM Gemini-2.0-Flash for seamless automation. The code generation module classifies webpages into pagination, dynamic, or infinite scrolling categories and generates suitable Python scripts for scraping. LLMs also classify and extract key accident information such as date, time, location, fatalities, injuries, road type, vehicle types, and pedestrian involvement. A deduplication algorithm ensures data integrity by removing duplicate reports. The system scraped 14 major Bangladeshi news sites over 111 days (Oct 1, 2024 - Jan 20, 2025), processing over 15,000 news articles and identifying 705 unique accidents. The code generation module achieved 91.3% calibration and 80% validation accuracy. Chittagong reported the highest number of accidents (80), fatalities (70), and injuries (115), followed by Dhaka, Faridpur, Gazipur, and Cox's Bazar. Peak accident times were morning (8-9 AM), noon (12-1 PM), and evening (6-7 PM). A public repository was also developed with usage instructions. This study demonstrates the viability of an LLM-powered, scalable system for accurate, low-effort accident data collection, providing a foundation for data-driven road safety policymaking in Bangladesh."
      },
      {
        "id": "oai:arXiv.org:2505.00016v1",
        "title": "Sparks of Tabular Reasoning via Text2SQL Reinforcement Learning",
        "link": "https://arxiv.org/abs/2505.00016",
        "author": "Josefa Lia Stoisser, Marc Boubnovski Martell, Julien Fauqueur",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00016v1 Announce Type: new \nAbstract: This work reframes the Text-to-SQL task as a pathway for teaching large language models (LLMs) to reason over and manipulate tabular data--moving beyond the traditional focus on query generation. We propose a two-stage framework that leverages SQL supervision to develop transferable table reasoning capabilities. First, we synthesize detailed chain-of-thought (CoT) traces from real-world SQL queries, providing step-by-step, clause-level supervision that teaches the model how to traverse, filter, and aggregate table fields. Second, we introduce a Group Relative Policy Optimization (GRPO) reinforcement learning objective that connects SQL execution accuracy to generalizable reasoning by encouraging steps that extend beyond task-specific syntax and transfer across datasets. Empirically, our approach improves performance on standard Text-to-SQL benchmarks and achieves substantial gains on reasoning-intensive datasets such as BIRD and CRT-QA, demonstrating enhanced generalization and interpretability. Specifically, the distilled-quantized LLaMA model achieved a 20\\% increase in accuracy when trained on Text-to-SQL tasks, while Qwen achieved a 5\\% increase. These results suggest that SQL can serve not only as a target formalism but also as an effective scaffold for learning robust, transferable reasoning over structured data."
      },
      {
        "id": "oai:arXiv.org:2505.00017v1",
        "title": "ReCellTy: Domain-specific knowledge graph retrieval-augmented LLMs workflow for single-cell annotation",
        "link": "https://arxiv.org/abs/2505.00017",
        "author": "Dezheng Han, Yibin Jia, Ruxiao Chen, Wenjie Han, Shuaishuai Guo, Jianbo Wang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00017v1 Announce Type: new \nAbstract: To enable precise and fully automated cell type annotation with large language models (LLMs), we developed a graph structured feature marker database to retrieve entities linked to differential genes for cell reconstruction. We further designed a multi task workflow to optimize the annotation process. Compared to general purpose LLMs, our method improves human evaluation scores by up to 0.21 and semantic similarity by 6.1% across 11 tissue types, while more closely aligning with the cognitive logic of manual annotation."
      },
      {
        "id": "oai:arXiv.org:2505.00019v1",
        "title": "An Empirical Study on Prompt Compression for Large Language Models",
        "link": "https://arxiv.org/abs/2505.00019",
        "author": "Zheng Zhang, Jinyi Li, Yihuai Lan, Xiang Wang, Hao Wang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00019v1 Announce Type: new \nAbstract: Prompt engineering enables Large Language Models (LLMs) to perform a variety of tasks. However, lengthy prompts significantly increase computational complexity and economic costs. To address this issue, we study six prompt compression methods for LLMs, aiming to reduce prompt length while maintaining LLM response quality. In this paper, we present a comprehensive analysis covering aspects such as generation performance, model hallucinations, efficacy in multimodal tasks, word omission analysis, and more. We evaluate these methods across 13 datasets, including news, scientific articles, commonsense QA, math QA, long-context QA, and VQA datasets. Our experiments reveal that prompt compression has a greater impact on LLM performance in long contexts compared to short ones. In the Longbench evaluation, moderate compression even enhances LLM performance. Our code and data is available at https://github.com/3DAgentWorld/Toolkit-for-Prompt-Compression."
      },
      {
        "id": "oai:arXiv.org:2505.00020v1",
        "title": "Beyond Public Access in LLM Pre-Training Data",
        "link": "https://arxiv.org/abs/2505.00020",
        "author": "Sruly Rosenblat, Tim O'Reilly, Ilan Strauss",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00020v1 Announce Type: new \nAbstract: Using a legally obtained dataset of 34 copyrighted O'Reilly Media books, we apply the DE-COP membership inference attack method to investigate whether OpenAI's large language models were trained on copyrighted content without consent. Our AUROC scores show that GPT-4o, OpenAI's more recent and capable model, demonstrates strong recognition of paywalled O'Reilly book content (AUROC = 82\\%), compared to OpenAI's earlier model GPT-3.5 Turbo. In contrast, GPT-3.5 Turbo shows greater relative recognition of publicly accessible O'Reilly book samples. GPT-4o Mini, as a much smaller model, shows no knowledge of public or non-public O'Reilly Media content when tested (AUROC $\\approx$ 50\\%). Testing multiple models, with the same cutoff date, helps us account for potential language shifts over time that might bias our findings. These results highlight the urgent need for increased corporate transparency regarding pre-training data sources as a means to develop formal licensing frameworks for AI content training"
      },
      {
        "id": "oai:arXiv.org:2505.00021v1",
        "title": "Ustnlp16 at SemEval-2025 Task 9: Improving Model Performance through Imbalance Handling and Focal Loss",
        "link": "https://arxiv.org/abs/2505.00021",
        "author": "Zhuoang Cai, Zhenghao Li, Yang Liu, Liyuan Guo, Yangqiu Song",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00021v1 Announce Type: new \nAbstract: Classification tasks often suffer from imbal- anced data distribution, which presents chal- lenges in food hazard detection due to severe class imbalances, short and unstructured text, and overlapping semantic categories. In this paper, we present our system for SemEval- 2025 Task 9: Food Hazard Detection, which ad- dresses these issues by applying data augmenta- tion techniques to improve classification perfor- mance. We utilize transformer-based models, BERT and RoBERTa, as backbone classifiers and explore various data balancing strategies, including random oversampling, Easy Data Augmentation (EDA), and focal loss. Our ex- periments show that EDA effectively mitigates class imbalance, leading to significant improve- ments in accuracy and F1 scores. Furthermore, combining focal loss with oversampling and EDA further enhances model robustness, par- ticularly for hard-to-classify examples. These findings contribute to the development of more effective NLP-based classification models for food hazard detection."
      },
      {
        "id": "oai:arXiv.org:2505.00022v1",
        "title": "Aleph-Alpha-GermanWeb: Improving German-language LLM pre-training with model-based data curation and synthetic data generation",
        "link": "https://arxiv.org/abs/2505.00022",
        "author": "Thomas F Burns, Letitia Parcalabescu, Stephan W\\\"aldchen, Michael Barlow, Gregor Ziegltrum, Volker Stampa, Bastian Harren, Bj\\\"orn Deiseroth",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00022v1 Announce Type: new \nAbstract: Scaling data quantity is essential for large language models (LLMs), yet recent findings show that data quality can significantly boost performance and training efficiency. We introduce a German-language dataset curation pipeline that combines heuristic and model-based filtering techniques with synthetic data generation. We use our pipeline to create Aleph-Alpha-GermanWeb, a large-scale German pre-training dataset which draws from: (1) Common Crawl web data, (2) FineWeb2, and (3) synthetically-generated data conditioned on actual, organic web data. We evaluate our dataset by pre-training both a 1B Llama-style model and an 8B tokenizer-free hierarchical autoregressive transformer (HAT). A comparison on German-language benchmarks, including MMMLU, shows significant performance gains of Aleph-Alpha-GermanWeb over FineWeb2 alone. This advantage holds at the 8B scale even when FineWeb2 is enriched by human-curated high-quality data sources such as Wikipedia. Our findings support the growing body of evidence that model-based data curation and synthetic data generation can significantly enhance LLM pre-training datasets."
      },
      {
        "id": "oai:arXiv.org:2505.00023v1",
        "title": "CORG: Generating Answers from Complex, Interrelated Contexts",
        "link": "https://arxiv.org/abs/2505.00023",
        "author": "Hyunji Lee, Franck Dernoncourt, Trung Bui, Seunghyun Yoon",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00023v1 Announce Type: new \nAbstract: In a real-world corpus, knowledge frequently recurs across documents but often contains inconsistencies due to ambiguous naming, outdated information, or errors, leading to complex interrelationships between contexts. Previous research has shown that language models struggle with these complexities, typically focusing on single factors in isolation. We classify these relationships into four types: distracting, ambiguous, counterfactual, and duplicated. Our analysis reveals that no single approach effectively addresses all these interrelationships simultaneously. Therefore, we introduce Context Organizer (CORG), a framework that organizes multiple contexts into independently processed groups. This design allows the model to efficiently find all relevant answers while ensuring disambiguation. CORG consists of three key components: a graph constructor, a reranker, and an aggregator. Our results demonstrate that CORG balances performance and efficiency effectively, outperforming existing grouping methods and achieving comparable results to more computationally intensive, single-context approaches."
      },
      {
        "id": "oai:arXiv.org:2505.00024v1",
        "title": "Nemotron-Research-Tool-N1: Tool-Using Language Models with Reinforced Reasoning",
        "link": "https://arxiv.org/abs/2505.00024",
        "author": "Shaokun Zhang, Yi Dong, Jieyu Zhang, Jan Kautz, Bryan Catanzaro, Andrew Tao, Qingyun Wu, Zhiding Yu, Guilin Liu",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00024v1 Announce Type: new \nAbstract: Enabling large language models with external tools has become a pivotal strategy for extending their functionality beyond text generation tasks. Prior work typically enhances tool-use abilities by either applying supervised fine-tuning (SFT) to enforce tool-call correctness or distilling reasoning traces from stronger models for SFT. However, both approaches fall short, either omitting reasoning entirely or producing imitative reasoning that limits generalization. Inspired by the success of DeepSeek-R1 in eliciting reasoning through rule-based reinforcement learning, we develop the Nemotron-Research-Tool-N1 series of tool-using language models using a similar training paradigm. Instead of restrictively supervising intermediate reasoning traces distilled from stronger models, Nemotron-Research-Tool-N1 is optimized with a binary reward that evaluates only the structural validity and functional correctness of tool invocations. This lightweight supervision allows the model to autonomously internalize reasoning strategies, without the need for annotated reasoning trajectories. Experiments on the BFCL and API-Bank benchmarks show that Nemotron-Research-Tool-N1-7B and Nemotron-Research-Tool-N1-14B, built on Qwen-2.5-7B/14B-Instruct, achieve state-of-the-art results, outperforming GPT-4o on both evaluations."
      },
      {
        "id": "oai:arXiv.org:2505.00025v1",
        "title": "A Method for the Architecture of a Medical Vertical Large Language Model Based on Deepseek R1",
        "link": "https://arxiv.org/abs/2505.00025",
        "author": "Mingda Zhang, Jianglong Qin",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00025v1 Announce Type: new \nAbstract: In recent years, despite foundation models like DeepSeek-R1 and ChatGPT demonstrating significant capabilities in general tasks, professional knowledge barriers, computational resource requirements, and deployment environment limitations have severely hindered their application in actual medical scenarios. Addressing these challenges, this paper proposes an efficient lightweight medical vertical large language model architecture method, systematically solving the lightweight problem of medical large models from three dimensions: knowledge acquisition, model compression, and computational optimization. At the knowledge acquisition level, a knowledge transfer pipeline is designed from the fine-tuned DeepSeek-R1-Distill-70B teacher model to the DeepSeek-R1-Distill-7B student model, and Low-Rank Adaptation (LoRA) technology is adopted to precisely adjust key attention layers. At the model compression level, compression techniques including 4-bit weight quantization are implemented while preserving the core representation ability for medical reasoning. At the computational optimization level, inference optimization techniques such as Flash Attention acceleration and continuous batching are integrated, and a professional prompt template system is constructed to adapt to different types of medical problems. Experimental results on medical question-answering datasets show that the method proposed in this paper maintains professional accuracy while reducing memory consumption by 64.7\\% and inference latency by 12.4\\%, providing an effective solution for the application of medical large models in resource-constrained environments such as edge computing devices."
      },
      {
        "id": "oai:arXiv.org:2505.00026v1",
        "title": "Theory of Mind in Large Language Models: Assessment and Enhancement",
        "link": "https://arxiv.org/abs/2505.00026",
        "author": "Ruirui Chen, Weifeng Jiang, Chengwei Qin, Cheston Tan",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00026v1 Announce Type: new \nAbstract: Theory of Mind (ToM)-the ability to infer and reason about others' mental states-is fundamental to human social intelligence. As Large Language Models (LLMs) become increasingly integrated into daily life, it is crucial to assess and enhance their capacity to interpret and respond to human mental states. In this paper, we review LLMs' ToM capabilities by examining both evaluation benchmarks and the strategies designed to improve them. We focus on widely adopted story-based benchmarks and provide an in-depth analysis of methods aimed at enhancing ToM in LLMs. Furthermore, we outline promising future research directions informed by recent benchmarks and state-of-the-art approaches. Our survey serves as a valuable resource for researchers interested in advancing LLMs' ToM capabilities."
      },
      {
        "id": "oai:arXiv.org:2505.00027v1",
        "title": "Extracting Abstraction Dimensions by Identifying Syntax Pattern from Texts",
        "link": "https://arxiv.org/abs/2505.00027",
        "author": "Jian Zhou, Jiazheng Li, Sirui Zhuge, Hai Zhuge",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00027v1 Announce Type: new \nAbstract: This paper proposed an approach to automatically discovering subject dimension, action dimension, object dimension and adverbial dimension from texts to efficiently operate texts and support query in natural language. The high quality of trees guarantees that all subjects, actions, objects and adverbials and their subclass relations within texts can be represented. The independency of trees ensures that there is no redundant representation between trees. The expressiveness of trees ensures that the majority of sentences can be accessed from each tree and the rest of sentences can be accessed from at least one tree so that the tree-based search mechanism can support querying in natural language. Experiments show that the average precision, recall and F1-score of the abstraction trees constructed by the subclass relations of subject, action, object and adverbial are all greater than 80%. The application of the proposed approach to supporting query in natural language demonstrates that different types of question patterns for querying subject or object have high coverage of texts, and searching multiple trees on subject, action, object and adverbial according to the question pattern can quickly reduce search space to locate target sentences, which can support precise operation on texts."
      },
      {
        "id": "oai:arXiv.org:2505.00028v1",
        "title": "Enhancing Speech-to-Speech Dialogue Modeling with End-to-End Retrieval-Augmented Generation",
        "link": "https://arxiv.org/abs/2505.00028",
        "author": "Pengchao Feng, Ziyang Ma, Wenxi Chen, Yao Li, Sheng Wang, Kai Yu, Xie Chen",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00028v1 Announce Type: new \nAbstract: In recent years, end-to-end speech-to-speech (S2S) dialogue systems have garnered increasing research attention due to their advantages over traditional cascaded systems, including achieving lower latency and more natural integration of nonverbal cues such as emotion and speaker identity. However, these end-to-end systems face key challenges, particularly in incorporating external knowledge, a capability commonly addressed by Retrieval-Augmented Generation (RAG) in text-based large language models (LLMs). The core difficulty lies in the modality gap between input speech and retrieved textual knowledge, which hinders effective integration. To address this issue, we propose a novel end-to-end RAG framework that directly retrieves relevant textual knowledge from speech queries, eliminating the need for intermediate speech-to-text conversion via techniques like ASR. Experimental results demonstrate that our method significantly improves the performance of end-to-end S2S dialogue systems while achieving higher retrieval efficiency. Although the overall performance still lags behind cascaded models, our framework offers a promising direction for enhancing knowledge integration in end-to-end S2S systems. We will release the code and dataset to support reproducibility and promote further research in this area."
      },
      {
        "id": "oai:arXiv.org:2505.00029v1",
        "title": "Keep the General, Inject the Specific: Structured Dialogue Fine-Tuning for Knowledge Injection without Catastrophic Forgetting",
        "link": "https://arxiv.org/abs/2505.00029",
        "author": "Yijie Hong, Xiaofei Yin, Xinzhong Wang, Yi Tu, Ya Guo, Sufeng Duan, Weiqiang Wang, Lingyong Fang, Depeng Wang, Huijia Zhu",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00029v1 Announce Type: new \nAbstract: Large Vision Language Models have demonstrated impressive versatile capabilities through extensive multimodal pre-training, but face significant limitations when incorporating specialized knowledge domains beyond their training distribution. These models struggle with a fundamental dilemma: direct adaptation approaches that inject domain-specific knowledge often trigger catastrophic forgetting of foundational visual-linguistic abilities. We introduce Structured Dialogue Fine-Tuning (SDFT), an effective approach that effectively injects domain-specific knowledge while minimizing catastrophic forgetting. Drawing inspiration from supervised fine-tuning in LLMs and subject-driven personalization in text-to-image diffusion models, our method employs a three-phase dialogue structure: Foundation Preservation reinforces pre-trained visual-linguistic alignment through caption tasks; Contrastive Disambiguation introduces carefully designed counterfactual examples to maintain semantic boundaries; and Knowledge Specialization embeds specialized information through chain-of-thought reasoning. Experimental results across multiple domains confirm SDFT's effectiveness in balancing specialized knowledge acquisition with general capability retention. Our key contributions include a data-centric dialogue template that balances foundational alignment with targeted knowledge integration, a weighted multi-turn supervision framework, and comprehensive evaluation across diverse knowledge types."
      },
      {
        "id": "oai:arXiv.org:2505.00030v1",
        "title": "Can Language Models Represent the Past without Anachronism?",
        "link": "https://arxiv.org/abs/2505.00030",
        "author": "Ted Underwood, Laura K. Nelson, Matthew Wilkens",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00030v1 Announce Type: new \nAbstract: Before researchers can use language models to simulate the past, they need to understand the risk of anachronism. We find that prompting a contemporary model with examples of period prose does not produce output consistent with period style. Fine-tuning produces results that are stylistically convincing enough to fool an automated judge, but human evaluators can still distinguish fine-tuned model outputs from authentic historical text. We tentatively conclude that pretraining on period prose may be required in order to reliably simulate historical perspectives for social research."
      },
      {
        "id": "oai:arXiv.org:2505.00031v1",
        "title": "Learning to Plan Before Answering: Self-Teaching LLMs to Learn Abstract Plans for Problem Solving",
        "link": "https://arxiv.org/abs/2505.00031",
        "author": "Jin Zhang, Flood Sung, Zhilin Yang, Yang Gao, Chongjie Zhang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00031v1 Announce Type: new \nAbstract: In the field of large language model (LLM) post-training, the effectiveness of utilizing synthetic data generated by the LLM itself has been well-presented. However, a key question remains unaddressed: what essential information should such self-generated data encapsulate? Existing approaches only produce step-by-step problem solutions, and fail to capture the abstract meta-knowledge necessary for generalization across similar problems. Drawing insights from cognitive science, where humans employ high-level abstraction to simplify complex problems before delving into specifics, we introduce a novel self-training algorithm: LEarning to Plan before Answering (LEPA). LEPA trains the LLM to formulate anticipatory plans, which serve as abstract meta-knowledge for problem-solving, before engaging with the intricacies of problems. This approach not only outlines the solution generation path but also shields the LLM from the distraction of irrelevant details. During data generation, LEPA first crafts an anticipatory plan based on the problem, and then generates a solution that aligns with both the plan and the problem. LEPA refines the plan through self-reflection, aiming to acquire plans that are instrumental in yielding correct solutions. During model optimization, the LLM is trained to predict both the refined plans and the corresponding solutions. By efficiently extracting and utilizing the anticipatory plans, LEPA demonstrates remarkable superiority over conventional algorithms on various challenging natural language reasoning benchmarks."
      },
      {
        "id": "oai:arXiv.org:2505.00032v1",
        "title": "MDD-LLM: Towards Accuracy Large Language Models for Major Depressive Disorder Diagnosis",
        "link": "https://arxiv.org/abs/2505.00032",
        "author": "Yuyang Sha, Hongxin Pan, Wei Xu, Weiyu Meng, Gang Luo, Xinyu Du, Xiaobing Zhai, Henry H. Y. Tong, Caijuan Shi, Kefeng Li",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00032v1 Announce Type: new \nAbstract: Major depressive disorder (MDD) impacts more than 300 million people worldwide, highlighting a significant public health issue. However, the uneven distribution of medical resources and the complexity of diagnostic methods have resulted in inadequate attention to this disorder in numerous countries and regions. This paper introduces a high-performance MDD diagnosis tool named MDD-LLM, an AI-driven framework that utilizes fine-tuned large language models (LLMs) and extensive real-world samples to tackle challenges in MDD diagnosis. Therefore, we select 274,348 individual information from the UK Biobank cohort to train and evaluate the proposed method. Specifically, we select 274,348 individual records from the UK Biobank cohort and design a tabular data transformation method to create a large corpus for training and evaluating the proposed approach. To illustrate the advantages of MDD-LLM, we perform comprehensive experiments and provide several comparative analyses against existing model-based solutions across multiple evaluation metrics. Experimental results show that MDD-LLM (70B) achieves an accuracy of 0.8378 and an AUC of 0.8919 (95% CI: 0.8799 - 0.9040), significantly outperforming existing machine learning and deep learning frameworks for MDD diagnosis. Given the limited exploration of LLMs in MDD diagnosis, we examine numerous factors that may influence the performance of our proposed method, such as tabular data transformation techniques and different fine-tuning strategies."
      },
      {
        "id": "oai:arXiv.org:2505.00033v1",
        "title": "From Attention to Atoms: Spectral Dictionary Learning for Fast, Interpretable Language Models",
        "link": "https://arxiv.org/abs/2505.00033",
        "author": "Andrew Kiruluta",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00033v1 Announce Type: new \nAbstract: We propose a novel spectral generative modeling framework for natural language processing that jointly learns a global time varying Fourier dictionary and per token mixing coefficients, replacing the ubiquitous self attention mechanism in transformer architectures. By enforcing reconstruction losses in both the time domain (embedding reconstruction) and the frequency domain (via Short Time Fourier Transform magnitude matching) alongside a standard language modeling objective, and fitting a Gaussian Mixture Model (GMM) prior over the learned mixing vectors, our approach achieves competitive perplexity and generation quality on standard benchmarks such as WikiText2 and Penn Treebank. In contrast to the quadratic computation complexity of self attention, our method operates with linear complexity, delivering substantial efficiency gains. We demonstrate that spectral dictionary models can achieve competitive performance compared to transformer baselines while significantly reducing inference latency and memory footprint, offering a compelling alternative for scalable language modeling."
      },
      {
        "id": "oai:arXiv.org:2505.00034v1",
        "title": "Improving Phishing Email Detection Performance of Small Large Language Models",
        "link": "https://arxiv.org/abs/2505.00034",
        "author": "Zijie Lin, Zikang Liu, Hanbo Fan",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00034v1 Announce Type: new \nAbstract: Large language models(LLMs) have demonstrated remarkable performance on many natural language processing(NLP) tasks and have been employed in phishing email detection research. However, in current studies, well-performing LLMs typically contain billions or even tens of billions of parameters, requiring enormous computational resources. To reduce computational costs, we investigated the effectiveness of small-parameter LLMs for phishing email detection. These LLMs have around 3 billion parameters and can run on consumer-grade GPUs. However, small LLMs often perform poorly in phishing email detection task. To address these issues, we designed a set of methods including Prompt Engineering, Explanation Augmented Fine-tuning, and Model Ensemble to improve phishing email detection capabilities of small LLMs. We validated the effectiveness of our approach through experiments, significantly improving accuracy on the SpamAssassin dataset from around 0.5 for baseline models like Qwen2.5-1.5B-Instruct to 0.976."
      },
      {
        "id": "oai:arXiv.org:2505.00035v1",
        "title": "Linguistic Complexity and Socio-cultural Patterns in Hip-Hop Lyrics",
        "link": "https://arxiv.org/abs/2505.00035",
        "author": "Aayam Bansal, Raghav Agarwal, Kaashvi Jain",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00035v1 Announce Type: new \nAbstract: This paper presents a comprehensive computational framework for analyzing linguistic complexity and socio-cultural trends in hip-hop lyrics. Using a dataset of 3,814 songs from 146 influential artists spanning four decades (1980-2020), we employ natural language processing techniques to quantify multiple dimensions of lyrical complexity. Our analysis reveals a 23.7% increase in vocabulary diversity over the study period, with East Coast artists demonstrating 17.3% higher lexical variation than other regions. Rhyme density increased by 34.2% across all regions, with Midwest artists exhibiting the highest technical complexity (3.04 rhymes per line). Topic modeling identified significant shifts in thematic content, with social justice themes decreasing from 28.5% to 13.8% of content while introspective themes increased from 7.6% to 26.3%. Sentiment analysis demon- strated that lyrics became significantly more negative during sociopolitical crises, with polarity decreasing by 0.31 following major social unrest. Multi-dimensional analysis revealed four dis- tinct stylistic approaches that correlate strongly with geographic origin (r=0.68, p!0.001) and time period (r=0.59, p<0.001). These findings establish quantitative evidence for the evolution of hip- hop as both an art form and a reflection of societal dynamics, providing insights into the interplay between linguistic innovation and cultural context in popular music."
      },
      {
        "id": "oai:arXiv.org:2505.00036v1",
        "title": "A Framework to Assess the Persuasion Risks Large Language Model Chatbots Pose to Democratic Societies",
        "link": "https://arxiv.org/abs/2505.00036",
        "author": "Zhongren Chen, Joshua Kalla, Quan Le, Shinpei Nakamura-Sakai, Jasjeet Sekhon, Ruixiao Wang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00036v1 Announce Type: new \nAbstract: In recent years, significant concern has emerged regarding the potential threat that Large Language Models (LLMs) pose to democratic societies through their persuasive capabilities. We expand upon existing research by conducting two survey experiments and a real-world simulation exercise to determine whether it is more cost effective to persuade a large number of voters using LLM chatbots compared to standard political campaign practice, taking into account both the \"receive\" and \"accept\" steps in the persuasion process (Zaller 1992). These experiments improve upon previous work by assessing extended interactions between humans and LLMs (instead of using single-shot interactions) and by assessing both short- and long-run persuasive effects (rather than simply asking users to rate the persuasiveness of LLM-produced content). In two survey experiments (N = 10,417) across three distinct political domains, we find that while LLMs are about as persuasive as actual campaign ads once voters are exposed to them, political persuasion in the real-world depends on both exposure to a persuasive message and its impact conditional on exposure. Through simulations based on real-world parameters, we estimate that LLM-based persuasion costs between \\$48-\\$74 per persuaded voter compared to \\$100 for traditional campaign methods, when accounting for the costs of exposure. However, it is currently much easier to scale traditional campaign persuasion methods than LLM-based persuasion. While LLMs do not currently appear to have substantially greater potential for large-scale political persuasion than existing non-LLM methods, this may change as LLM capabilities continue to improve and it becomes easier to scalably encourage exposure to persuasive LLMs."
      },
      {
        "id": "oai:arXiv.org:2505.00038v1",
        "title": "HyPerAlign: Hypotheses-driven Personalized Alignment",
        "link": "https://arxiv.org/abs/2505.00038",
        "author": "Cristina Garbacea, Chenhao Tan",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00038v1 Announce Type: new \nAbstract: Alignment algorithms are widely used to align large language models (LLMs) to human users based on preference annotations that reflect their intended real-world use cases. Typically these (often divergent) preferences are aggregated over a diverse set of users, resulting in fine-tuned models that are aligned to the ``average-user'' preference. Nevertheless, current models are used by individual users in very specific contexts and situations, emphasizing the need for user-dependent preference control. In this work we address the problem of personalizing LLM outputs to their users, aiming to generate customized responses tailored to individual users, instead of generic outputs that emulate the collective voices of diverse populations. We propose a novel interpretable and sample-efficient hypotheses-driven personalization approach (HyPerAlign) where given few-shot examples written by a particular user, we first infer hypotheses about their communication strategies, personality and writing style, then prompt LLM models with these hypotheses and user specific attributes to generate customized outputs. We conduct experiments on two different personalization tasks, authorship attribution and deliberative alignment, with datasets from diverse domains (news articles, blog posts, emails, jailbreaking benchmarks), and demonstrate the superiority of hypotheses-driven personalization approach when compared to preference-based fine-tuning methods. For deliberative alignment, the helpfulness of LLM models is improved by up to $70\\%$ on average. For authorship attribution, results indicate consistently high win-rates (commonly $>90\\%$) against state-of-the-art preference fine-tuning approaches for LLM personalization across diverse user profiles and LLM models. Overall, our approach represents an interpretable and sample-efficient strategy for the personalization of LLM models to individual users."
      },
      {
        "id": "oai:arXiv.org:2505.00039v1",
        "title": "Graph RAG for Legal Norms: A Hierarchical and Temporal Approach",
        "link": "https://arxiv.org/abs/2505.00039",
        "author": "Hudson de Martim",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00039v1 Announce Type: new \nAbstract: This article proposes an adaptation of Graph Retrieval Augmented Generation (Graph RAG) specifically designed for the analysis and comprehension of legal norms, which are characterized by their predefined hierarchical structure, extensive network of internal and external references and multiple temporal versions. By combining structured knowledge graphs with contextually enriched text segments, Graph RAG offers a promising solution to address the inherent complexity and vast volume of legal data. The integration of hierarchical structure and temporal evolution into knowledge graphs - along with the concept of comprehensive Text Units - facilitates the construction of richer, interconnected representations of legal knowledge. Through a detailed analysis of Graph RAG and its application to legal norm datasets, this article aims to significantly advance the field of Artificial Intelligence applied to Law, creating opportunities for more effective systems in legal research, legislative analysis, and decision support."
      },
      {
        "id": "oai:arXiv.org:2505.00044v1",
        "title": "Learning to Borrow Features for Improved Detection of Small Objects in Single-Shot Detectors",
        "link": "https://arxiv.org/abs/2505.00044",
        "author": "Richard Schmit",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00044v1 Announce Type: new \nAbstract: Detecting small objects remains a significant challenge in single-shot object detectors due to the inherent trade-off between spatial resolution and semantic richness in convolutional feature maps. To address this issue, we propose a novel framework that enables small object representations to \"borrow\" discriminative features from larger, semantically richer instances within the same class. Our architecture introduces three key components: the Feature Matching Block (FMB) to identify semantically similar descriptors across layers, the Feature Representing Block (FRB) to generate enhanced shallow features through weighted aggregation, and the Feature Fusion Block (FFB) to refine feature maps by integrating original, borrowed, and context information. Built upon the SSD framework, our method improves the descriptive capacity of shallow layers while maintaining real-time detection performance. Experimental results demonstrate that our approach significantly boosts small object detection accuracy over baseline methods, offering a promising direction for robust object detection in complex visual environments."
      },
      {
        "id": "oai:arXiv.org:2505.00047v1",
        "title": "Base Models Beat Aligned Models at Randomness and Creativity",
        "link": "https://arxiv.org/abs/2505.00047",
        "author": "Peter West, Christopher Potts",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00047v1 Announce Type: new \nAbstract: Alignment has quickly become a default ingredient in LLM development, with techniques such as reinforcement learning from human feedback making models act safely, follow instructions, and perform ever-better on complex tasks. While these techniques are certainly useful, we propose that they should not be universally applied and demonstrate a range of tasks on which base language models consistently outperform their popular aligned forms. Particularly, we study tasks that require unpredictable outputs, such as random number generation, mixed strategy games (rock-paper-scissors and hide-and-seek), and creative writing. In each case, aligned models tend towards narrow behaviors that result in distinct disadvantages, for instance, preferring to generate \"7\" over other uniformly random numbers, becoming almost fully predictable in some game states, or prioritizing pleasant writing over creative originality. Across models tested, better performance on common benchmarks tends to correlate with worse performance on our tasks, suggesting an effective trade-off in the required capabilities."
      },
      {
        "id": "oai:arXiv.org:2505.00050v1",
        "title": "Emotional Analysis of Fashion Trends Using Social Media and AI: Sentiment Analysis on Twitter for Fashion Trend Forecasting",
        "link": "https://arxiv.org/abs/2505.00050",
        "author": "Aayam Bansal, Agneya Tharun",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00050v1 Announce Type: new \nAbstract: This study explores the intersection of fashion trends and social media sentiment through computational analysis of Twitter data using the T4SA (Twitter for Sentiment Analysis) dataset. By applying natural language processing and machine learning techniques, we examine how sentiment patterns in fashion-related social media conversations can serve as predictors for emerging fashion trends. Our analysis involves the identification and categorization of fashion-related content, sentiment classification with improved normalization techniques, time series decomposition, statistically validated causal relationship modeling, cross-platform sentiment comparison, and brand-specific sentiment analysis. Results indicate correlations between sentiment patterns and fashion theme popularity, with accessories and streetwear themes showing statistically significant rising trends. The Granger causality analysis establishes sustainability and streetwear as primary trend drivers, showing bidirectional relationships with several other themes. The findings demonstrate that social media sentiment analysis can serve as an effective early indicator of fashion trend trajectories when proper statistical validation is applied. Our improved predictive model achieved 78.35% balanced accuracy in sentiment classification, establishing a reliable foundation for trend prediction across positive, neutral, and negative sentiment categories."
      },
      {
        "id": "oai:arXiv.org:2505.00056v1",
        "title": "Clustering Internet Memes Through Template Matching and Multi-Dimensional Similarity",
        "link": "https://arxiv.org/abs/2505.00056",
        "author": "Tygo Bloem, Filip Ilievski",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00056v1 Announce Type: new \nAbstract: Meme clustering is critical for toxicity detection, virality modeling, and typing, but it has received little attention in previous research. Clustering similar Internet memes is challenging due to their multimodality, cultural context, and adaptability. Existing approaches rely on databases, overlook semantics, and struggle to handle diverse dimensions of similarity. This paper introduces a novel method that uses template-based matching with multi-dimensional similarity features, thus eliminating the need for predefined databases and supporting adaptive matching. Memes are clustered using local and global features across similarity categories such as form, visual content, text, and identity. Our combined approach outperforms existing clustering methods, producing more consistent and coherent clusters, while similarity-based feature sets enable adaptability and align with human intuition. We make all supporting code publicly available to support subsequent research. Code: https://github.com/tygobl/meme-clustering"
      },
      {
        "id": "oai:arXiv.org:2505.00057v1",
        "title": "A Report on the llms evaluating the high school questions",
        "link": "https://arxiv.org/abs/2505.00057",
        "author": "Zhu Jiawei, Chen Wei",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00057v1 Announce Type: new \nAbstract: This report aims to evaluate the performance of large language models (LLMs) in solving high school science questions and to explore their potential applications in the educational field. With the rapid development of LLMs in the field of natural language processing, their application in education has attracted widespread attention. This study selected mathematics exam questions from the college entrance examinations (2019-2023) as evaluation data and utilized at least eight LLM APIs to provide answers. A comprehensive assessment was conducted based on metrics such as accuracy, response time, logical reasoning, and creativity. Through an in-depth analysis of the evaluation results, this report reveals the strengths and weaknesses of LLMs in handling high school science questions and discusses their implications for educational practice. The findings indicate that although LLMs perform excellently in certain aspects, there is still room for improvement in logical reasoning and creative problem-solving. This report provides an empirical foundation for further research and application of LLMs in the educational field and offers suggestions for improvement."
      },
      {
        "id": "oai:arXiv.org:2505.00059v1",
        "title": "BERSting at the Screams: A Benchmark for Distanced, Emotional and Shouted Speech Recognition",
        "link": "https://arxiv.org/abs/2505.00059",
        "author": "Paige Tutt\\\"os\\'i, Mantaj Dhillon, Luna Sang, Shane Eastwood, Poorvi Bhatia, Quang Minh Dinh, Avni Kapoor, Yewon Jin, Angelica Lim",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00059v1 Announce Type: new \nAbstract: Some speech recognition tasks, such as automatic speech recognition (ASR), are approaching or have reached human performance in many reported metrics. Yet, they continue to struggle in complex, real-world, situations, such as with distanced speech. Previous challenges have released datasets to address the issue of distanced ASR, however, the focus remains primarily on distance, specifically relying on multi-microphone array systems. Here we present the B(asic) E(motion) R(andom phrase) S(hou)t(s) (BERSt) dataset. The dataset contains almost 4 hours of English speech from 98 actors with varying regional and non-native accents. The data was collected on smartphones in the actors homes and therefore includes at least 98 different acoustic environments. The data also includes 7 different emotion prompts and both shouted and spoken utterances. The smartphones were places in 19 different positions, including obstructions and being in a different room than the actor. This data is publicly available for use and can be used to evaluate a variety of speech recognition tasks, including: ASR, shout detection, and speech emotion recognition (SER). We provide initial benchmarks for ASR and SER tasks, and find that ASR degrades both with an increase in distance and shout level and shows varied performance depending on the intended emotion. Our results show that the BERSt dataset is challenging for both ASR and SER tasks and continued work is needed to improve the robustness of such systems for more accurate real-world use."
      },
      {
        "id": "oai:arXiv.org:2505.00060v1",
        "title": "Fact-Consistency Evaluation of Text-to-SQL Generation for Business Intelligence Using Exaone 3.5",
        "link": "https://arxiv.org/abs/2505.00060",
        "author": "Jeho Choi",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00060v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have shown promise in enabling natural language interfaces for structured data querying through text-to-SQL generation. However, their application in real-world Business Intelligence (BI) contexts remains limited due to semantic hallucinations, structural errors, and a lack of domain-specific evaluation frameworks. In this study, we propose a Fact-Consistency Evaluation Framework for assessing the semantic accuracy of LLM-generated SQL outputs using Exaone 3.5--an instruction-tuned, bilingual LLM optimized for enterprise tasks. We construct a domain-specific benchmark comprising 219 natural language business questions across five SQL complexity levels, derived from actual sales data in LG Electronics' internal BigQuery environment. Each question is paired with a gold-standard SQL query and a validated ground-truth answer. We evaluate model performance using answer accuracy, execution success rate, semantic error rate, and non-response rate. Experimental results show that while Exaone 3.5 performs well on simple aggregation tasks (93% accuracy in L1), it exhibits substantial degradation in arithmetic reasoning (4% accuracy in H1) and grouped ranking tasks (31% in H4), with semantic errors and non-responses concentrated in complex cases. Qualitative error analysis further identifies common failure types such as misapplied arithmetic logic, incomplete filtering, and incorrect grouping operations. Our findings highlight the current limitations of LLMs in business-critical environments and underscore the need for fact-consistency validation layers and hybrid reasoning approaches. This work contributes a reproducible benchmark and evaluation methodology for advancing reliable natural language interfaces to structured enterprise data systems."
      },
      {
        "id": "oai:arXiv.org:2505.00061v1",
        "title": "Enhancing Security and Strengthening Defenses in Automated Short-Answer Grading Systems",
        "link": "https://arxiv.org/abs/2505.00061",
        "author": "Sahar Yarmohammadtoosky, Yiyun Zhou, Victoria Yaneva, Peter Baldwin, Saed Rezayi, Brian Clauser, Polina Harikeo",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00061v1 Announce Type: new \nAbstract: This study examines vulnerabilities in transformer-based automated short-answer grading systems used in medical education, with a focus on how these systems can be manipulated through adversarial gaming strategies. Our research identifies three main types of gaming strategies that exploit the system's weaknesses, potentially leading to false positives. To counteract these vulnerabilities, we implement several adversarial training methods designed to enhance the systems' robustness. Our results indicate that these methods significantly reduce the susceptibility of grading systems to such manipulations, especially when combined with ensemble techniques like majority voting and ridge regression, which further improve the system's defense against sophisticated adversarial inputs. Additionally, employing large language models such as GPT-4 with varied prompting techniques has shown promise in recognizing and scoring gaming strategies effectively. The findings underscore the importance of continuous improvements in AI-driven educational tools to ensure their reliability and fairness in high-stakes settings."
      },
      {
        "id": "oai:arXiv.org:2505.00063v1",
        "title": "GDI-Bench: A Benchmark for General Document Intelligence with Vision and Reasoning Decoupling",
        "link": "https://arxiv.org/abs/2505.00063",
        "author": "Siqi Li, Yufan Shen, Xiangnan Chen, Jiayi Chen, Hengwei Ju, Haodong Duan, Song Mao, Hongbin Zhou, Bo Zhang, Pinlong Cai, Licheng Wen, Botian Shi, Yong Liu, Xinyu Cai, Yu Qiao",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00063v1 Announce Type: new \nAbstract: The rapid advancement of multimodal large language models (MLLMs) has profoundly impacted the document domain, creating a wide array of application scenarios. This progress highlights the need for a comprehensive benchmark to evaluate these models' capabilities across various document-specific tasks. However, existing benchmarks often fail to locate specific model weaknesses or guide systematic improvements. To bridge this gap, we introduce a General Document Intelligence Benchmark (GDI-Bench), featuring 1.9k images across 9 key scenarios and 19 document-specific tasks. By decoupling visual complexity and reasoning complexity, the GDI-Bench structures graded tasks that allow performance assessment by difficulty, aiding in model weakness identification and optimization guidance. We evaluate the GDI-Bench on various open-source and closed-source models, conducting decoupled analyses in the visual and reasoning domains. For instance, the GPT-4o model excels in reasoning tasks but exhibits limitations in visual capabilities. To address the diverse tasks and domains in the GDI-Bench, we propose a GDI Model that mitigates the issue of catastrophic forgetting during the supervised fine-tuning (SFT) process through a intelligence-preserving training strategy. Our model achieves state-of-the-art performance on previous benchmarks and the GDI-Bench. Both our benchmark and model will be open source."
      },
      {
        "id": "oai:arXiv.org:2505.00065v1",
        "title": "ConSens: Assessing context grounding in open-book question answering",
        "link": "https://arxiv.org/abs/2505.00065",
        "author": "Ivan Vankov, Matyo Ivanov, Adriana Correia, Victor Botev",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00065v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have demonstrated considerable success in open-book question answering (QA), where the task requires generating answers grounded in a provided external context. A critical challenge in open-book QA is to ensure that model responses are based on the provided context rather than its parametric knowledge, which can be outdated, incomplete, or incorrect. Existing evaluation methods, primarily based on the LLM-as-a-judge approach, face significant limitations, including biases, scalability issues, and dependence on costly external systems. To address these challenges, we propose a novel metric that contrasts the perplexity of the model response under two conditions: when the context is provided and when it is not. The resulting score quantifies the extent to which the model's answer relies on the provided context. The validity of this metric is demonstrated through a series of experiments that show its effectiveness in identifying whether a given answer is grounded in the provided context. Unlike existing approaches, this metric is computationally efficient, interpretable, and adaptable to various use cases, offering a scalable and practical solution to assess context utilization in open-book QA systems."
      },
      {
        "id": "oai:arXiv.org:2505.00101v1",
        "title": "From Lab to Wrist: Bridging Metabolic Monitoring and Consumer Wearables for Heart Rate and Oxygen Consumption Modeling",
        "link": "https://arxiv.org/abs/2505.00101",
        "author": "Barak Gahtan, Sanketh Vedula, Gil Samuelly Leichtag, Einat Kodesh, Alex M. Bronstein",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00101v1 Announce Type: new \nAbstract: Understanding physiological responses during running is critical for performance optimization, tailored training prescriptions, and athlete health management. We introduce a comprehensive framework -- what we believe to be the first capable of predicting instantaneous oxygen consumption (VO$_{2}$) trajectories exclusively from consumer-grade wearable data. Our approach employs two complementary physiological models: (1) accurate modeling of heart rate (HR) dynamics via a physiologically constrained ordinary differential equation (ODE) and neural Kalman filter, trained on over 3 million HR observations, achieving 1-second interval predictions with mean absolute errors as low as 2.81\\,bpm (correlation 0.87); and (2) leveraging the principles of precise HR modeling, a novel VO$_{2}$ prediction architecture requiring only the initial second of VO$_{2}$ data for calibration, enabling robust, sequence-to-sequence metabolic demand estimation. Despite relying solely on smartwatch and chest-strap data, our method achieves mean absolute percentage errors of approximately 13\\%, effectively capturing rapid physiological transitions and steady-state conditions across diverse running intensities. Our synchronized dataset, complemented by blood lactate measurements, further lays the foundation for future noninvasive metabolic zone identification. By embedding physiological constraints within modern machine learning, this framework democratizes advanced metabolic monitoring, bridging laboratory-grade accuracy and everyday accessibility, thus empowering both elite athletes and recreational fitness enthusiasts."
      },
      {
        "id": "oai:arXiv.org:2505.00114v1",
        "title": "Fine-Tuning LLMs for Low-Resource Dialect Translation: The Case of Lebanese",
        "link": "https://arxiv.org/abs/2505.00114",
        "author": "Silvana Yakhni, Ali Chehab",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00114v1 Announce Type: new \nAbstract: This paper examines the effectiveness of Large Language Models (LLMs) in translating the low-resource Lebanese dialect, focusing on the impact of culturally authentic data versus larger translated datasets. We compare three fine-tuning approaches: Basic, contrastive, and grammar-hint tuning, using open-source Aya23 models. Experiments reveal that models fine-tuned on a smaller but culturally aware Lebanese dataset (LW) consistently outperform those trained on larger, non-native data. The best results were achieved through contrastive fine-tuning paired with contrastive prompting, which indicates the benefits of exposing translation models to bad examples. In addition, to ensure authentic evaluation, we introduce LebEval, a new benchmark derived from native Lebanese content, and compare it to the existing FLoRes benchmark. Our findings challenge the \"More Data is Better\" paradigm and emphasize the crucial role of cultural authenticity in dialectal translation. We made our datasets and code available on Github."
      },
      {
        "id": "oai:arXiv.org:2505.00127v1",
        "title": "Between Underthinking and Overthinking: An Empirical Study of Reasoning Length and correctness in LLMs",
        "link": "https://arxiv.org/abs/2505.00127",
        "author": "Jinyan Su, Jennifer Healey, Preslav Nakov, Claire Cardie",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00127v1 Announce Type: new \nAbstract: Large language models (LLMs) are increasingly optimized for long reasoning, under the assumption that more reasoning leads to better performance. However, emerging evidence suggests that longer responses can sometimes degrade accuracy rather than improve it. In this paper, we conduct a systematic empirical study of the relationship between reasoning length and answer correctness. We find that LLMs tend to overthink simple problems, generating unnecessarily long outputs, and underthink harder ones, failing to extend their reasoning when it is most needed. This indicates that models might misjudge problem difficulty and fail to calibrate their response length appropriately. Furthermore, we investigate the effects of length reduction with a preference optimization algorithm when simply preferring the shorter responses regardless of answer correctness. Experiments show that the generation length can be significantly reduced while maintaining acceptable accuracy. Our findings highlight generation length as a meaningful signal for reasoning behavior and motivate further exploration into LLMs' self-awareness in reasoning length adaptation."
      },
      {
        "id": "oai:arXiv.org:2505.00131v1",
        "title": "Kernel-Based Ensemble Gaussian Mixture Probability Hypothesis Density Filter",
        "link": "https://arxiv.org/abs/2505.00131",
        "author": "Dalton Durant, Renato Zanetti",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00131v1 Announce Type: new \nAbstract: In this work, a kernel-based Ensemble Gaussian Mixture Probability Hypothesis Density (EnGM-PHD) filter is presented for multi-target filtering applications. The EnGM-PHD filter combines the Gaussian-mixture-based techniques of the Gaussian Mixture Probability Hypothesis Density (GM-PHD) filter with the particle-based techniques of the Sequential Monte Carlo Probability Hypothesis Density (SMC-PHD) filter. It achieves this by obtaining particles from the posterior intensity function, propagating them through the system dynamics, and then using Kernel Density Estimation (KDE) techniques to approximate the Gaussian mixture of the prior intensity function. This approach guarantees convergence to the true intensity function in the limit of the number of components. Moreover, in the special case of a single target with no births, deaths, clutter, and perfect detection probability, the EnGM-PHD filter reduces to the standard Ensemble Gaussian Mixture Filter (EnGMF). In the presented experiment, the results indicate that the EnGM-PHD filter achieves better multi-target filtering performance than both the GM-PHD and SMC-PHD filters while using the same number of components or particles."
      },
      {
        "id": "oai:arXiv.org:2505.00134v1",
        "title": "Investigating Zero-Shot Diagnostic Pathology in Vision-Language Models with Efficient Prompt Design",
        "link": "https://arxiv.org/abs/2505.00134",
        "author": "Vasudev Sharma, Ahmed Alagha, Abdelhakim Khellaf, Vincent Quoc-Huy Trinh, Mahdi S. Hosseini",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00134v1 Announce Type: new \nAbstract: Vision-language models (VLMs) have gained significant attention in computational pathology due to their multimodal learning capabilities that enhance big-data analytics of giga-pixel whole slide image (WSI). However, their sensitivity to large-scale clinical data, task formulations, and prompt design remains an open question, particularly in terms of diagnostic accuracy. In this paper, we present a systematic investigation and analysis of three state of the art VLMs for histopathology, namely Quilt-Net, Quilt-LLAVA, and CONCH, on an in-house digestive pathology dataset comprising 3,507 WSIs, each in giga-pixel form, across distinct tissue types. Through a structured ablative study on cancer invasiveness and dysplasia status, we develop a comprehensive prompt engineering framework that systematically varies domain specificity, anatomical precision, instructional framing, and output constraints. Our findings demonstrate that prompt engineering significantly impacts model performance, with the CONCH model achieving the highest accuracy when provided with precise anatomical references. Additionally, we identify the critical importance of anatomical context in histopathological image analysis, as performance consistently degraded when reducing anatomical precision. We also show that model complexity alone does not guarantee superior performance, as effective domain alignment and domain-specific training are critical. These results establish foundational guidelines for prompt engineering in computational pathology and highlight the potential of VLMs to enhance diagnostic accuracy when properly instructed with domain-appropriate prompts."
      },
      {
        "id": "oai:arXiv.org:2505.00135v1",
        "title": "Eye2Eye: A Simple Approach for Monocular-to-Stereo Video Synthesis",
        "link": "https://arxiv.org/abs/2505.00135",
        "author": "Michal Geyer, Omer Tov, Linyi Jin, Richard Tucker, Inbar Mosseri, Tali Dekel, Noah Snavely",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00135v1 Announce Type: new \nAbstract: The rising popularity of immersive visual experiences has increased interest in stereoscopic 3D video generation. Despite significant advances in video synthesis, creating 3D videos remains challenging due to the relative scarcity of 3D video data. We propose a simple approach for transforming a text-to-video generator into a video-to-stereo generator. Given an input video, our framework automatically produces the video frames from a shifted viewpoint, enabling a compelling 3D effect. Prior and concurrent approaches for this task typically operate in multiple phases, first estimating video disparity or depth, then warping the video accordingly to produce a second view, and finally inpainting the disoccluded regions. This approach inherently fails when the scene involves specular surfaces or transparent objects. In such cases, single-layer disparity estimation is insufficient, resulting in artifacts and incorrect pixel shifts during warping. Our work bypasses these restrictions by directly synthesizing the new viewpoint, avoiding any intermediate steps. This is achieved by leveraging a pre-trained video model's priors on geometry, object materials, optics, and semantics, without relying on external geometry models or manually disentangling geometry from the synthesis process. We demonstrate the advantages of our approach in complex, real-world scenarios featuring diverse object materials and compositions. See videos on https://video-eye2eye.github.io"
      },
      {
        "id": "oai:arXiv.org:2505.00136v1",
        "title": "GPRat: Gaussian Process Regression with Asynchronous Tasks",
        "link": "https://arxiv.org/abs/2505.00136",
        "author": "Maksim Helmann, Alexander Strack, Dirk Pfl\\\"uger",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00136v1 Announce Type: new \nAbstract: Python is the de-facto language for software development in artificial intelligence (AI). Commonly used libraries, such as PyTorch and TensorFlow, rely on parallelization built into their BLAS backends to achieve speedup on CPUs. However, only applying parallelization in a low-level backend can lead to performance and scaling degradation. In this work, we present a novel way of binding task-based C++ code built on the asynchronous runtime model HPX to a high-level Python API using pybind11. We develop a parallel Gaussian process (GP) li- brary as an application. The resulting Python library GPRat combines the ease of use of commonly available GP libraries with the performance and scalability of asynchronous runtime systems. We evaluate the per- formance on a mass-spring-damper system, a standard benchmark from control theory, for varying numbers of regressors (features). The results show almost no binding overhead when binding the asynchronous HPX code using pybind11. Compared to GPyTorch and GPflow, GPRat shows superior scaling on up to 64 cores on an AMD EPYC 7742 CPU for train- ing. Furthermore, our library achieves a prediction speedup of 7.63 over GPyTorch and 25.25 over GPflow. If we increase the number of features from eight to 128, we observe speedups of 29.62 and 21.19, respectively. These results showcase the potential of using asynchronous tasks within Python-based AI applications."
      },
      {
        "id": "oai:arXiv.org:2505.00147v1",
        "title": "AdaptMI: Adaptive Skill-based In-context Math Instruction for Small Language Models",
        "link": "https://arxiv.org/abs/2505.00147",
        "author": "Yinghui He, Abhishek Panigrahi, Yong Lin, Sanjeev Arora",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00147v1 Announce Type: new \nAbstract: In-context learning (ICL) allows a language model to improve its problem-solving capability when provided with suitable information in context. Since the choice of in-context information can be determined based on the problem itself, in-context learning is analogous to human learning from teachers in a classroom. Recent works (Didolkar et al., 2024a; 2024b) show that ICL performance can be improved by leveraging a frontier large language model's (LLM) ability to predict required skills to solve a problem, popularly referred to as an LLM's metacognition, and using the recommended skills to construct necessary in-context examples. While this skill-based strategy boosts ICL performance in larger models, its gains on small language models (SLMs) have been minimal, highlighting a performance gap in ICL capabilities. We investigate this gap and show that skill-based prompting can hurt SLM performance on easy questions by introducing unnecessary information, akin to cognitive overload. To address this, we introduce AdaptMI, an adaptive approach to selecting skill-based in-context Math Instructions for SLMs. Inspired by cognitive load theory from human pedagogy, our method only introduces skill-based examples when the model performs poorly. We further propose AdaptMI+, which adds examples targeted to the specific skills missing from the model's responses. On 5-shot evaluations across popular math benchmarks and five SLMs (1B--7B; Qwen, Llama), AdaptMI+ improves accuracy by up to 6% over naive skill-based strategies."
      },
      {
        "id": "oai:arXiv.org:2505.00150v1",
        "title": "Detecting and Mitigating Hateful Content in Multimodal Memes with Vision-Language Models",
        "link": "https://arxiv.org/abs/2505.00150",
        "author": "Minh-Hao Van, Xintao Wu",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00150v1 Announce Type: new \nAbstract: The rapid evolution of social media has provided enhanced communication channels for individuals to create online content, enabling them to express their thoughts and opinions. Multimodal memes, often utilized for playful or humorous expressions with visual and textual elements, are sometimes misused to disseminate hate speech against individuals or groups. While the detection of hateful memes is well-researched, developing effective methods to transform hateful content in memes remains a significant challenge. Leveraging the powerful generation and reasoning capabilities of Vision-Language Models (VLMs), we address the tasks of detecting and mitigating hateful content. This paper presents two key contributions: first, a definition-guided prompting technique for detecting hateful memes, and second, a unified framework for mitigating hateful content in memes, named UnHateMeme, which works by replacing hateful textual and/or visual components. With our definition-guided prompts, VLMs achieve impressive performance on hateful memes detection task. Furthermore, our UnHateMeme framework, integrated with VLMs, demonstrates a strong capability to convert hateful memes into non-hateful forms that meet human-level criteria for hate speech and maintain multimodal coherence between image and text. Through empirical experiments, we show the effectiveness of state-of-the-art pretrained VLMs such as LLaVA, Gemini and GPT-4o on the proposed tasks, providing a comprehensive analysis of their respective strengths and limitations for these tasks. This paper aims to shed light on important applications of VLMs for ensuring safe and respectful online environments."
      },
      {
        "id": "oai:arXiv.org:2505.00156v1",
        "title": "V3LMA: Visual 3D-enhanced Language Model for Autonomous Driving",
        "link": "https://arxiv.org/abs/2505.00156",
        "author": "Jannik L\\\"ubberstedt, Esteban Rivera, Nico Uhlemann, Markus Lienkamp",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00156v1 Announce Type: new \nAbstract: Large Vision Language Models (LVLMs) have shown strong capabilities in understanding and analyzing visual scenes across various domains. However, in the context of autonomous driving, their limited comprehension of 3D environments restricts their effectiveness in achieving a complete and safe understanding of dynamic surroundings. To address this, we introduce V3LMA, a novel approach that enhances 3D scene understanding by integrating Large Language Models (LLMs) with LVLMs. V3LMA leverages textual descriptions generated from object detections and video inputs, significantly boosting performance without requiring fine-tuning. Through a dedicated preprocessing pipeline that extracts 3D object data, our method improves situational awareness and decision-making in complex traffic scenarios, achieving a score of 0.56 on the LingoQA benchmark. We further explore different fusion strategies and token combinations with the goal of advancing the interpretation of traffic scenes, ultimately enabling safer autonomous driving systems."
      },
      {
        "id": "oai:arXiv.org:2505.00162v1",
        "title": "Stochastic Subspace Descent Accelerated via Bi-fidelity Line Search",
        "link": "https://arxiv.org/abs/2505.00162",
        "author": "Nuojin Cheng, Alireza Doostan, Stephen Becker",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00162v1 Announce Type: new \nAbstract: Efficient optimization remains a fundamental challenge across numerous scientific and engineering domains, especially when objective function and gradient evaluations are computationally expensive. While zeroth-order optimization methods offer effective approaches when gradients are inaccessible, their practical performance can be limited by the high cost associated with function queries. This work introduces the bi-fidelity stochastic subspace descent (BF-SSD) algorithm, a novel zeroth-order optimization method designed to reduce this computational burden. BF-SSD leverages a bi-fidelity framework, constructing a surrogate model from a combination of computationally inexpensive low-fidelity (LF) and accurate high-fidelity (HF) function evaluations. This surrogate model facilitates an efficient backtracking line search for step size selection, for which we provide theoretical convergence guarantees under standard assumptions. We perform a comprehensive empirical evaluation of BF-SSD across four distinct problems: a synthetic optimization benchmark, dual-form kernel ridge regression, black-box adversarial attacks on machine learning models, and transformer-based black-box language model fine-tuning. Numerical results demonstrate that BF-SSD consistently achieves superior optimization performance while requiring significantly fewer HF function evaluations compared to relevant baseline methods. This study highlights the efficacy of integrating bi-fidelity strategies within zeroth-order optimization, positioning BF-SSD as a promising and computationally efficient approach for tackling large-scale, high-dimensional problems encountered in various real-world applications."
      },
      {
        "id": "oai:arXiv.org:2505.00169v1",
        "title": "GEOM-Drugs Revisited: Toward More Chemically Accurate Benchmarks for 3D Molecule Generation",
        "link": "https://arxiv.org/abs/2505.00169",
        "author": "Filipp Nikitin, Ian Dunn, David Ryan Koes, Olexandr Isayev",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00169v1 Announce Type: new \nAbstract: Deep generative models have shown significant promise in generating valid 3D molecular structures, with the GEOM-Drugs dataset serving as a key benchmark. However, current evaluation protocols suffer from critical flaws, including incorrect valency definitions, bugs in bond order calculations, and reliance on force fields inconsistent with the reference data. In this work, we revisit GEOM-Drugs and propose a corrected evaluation framework: we identify and fix issues in data preprocessing, construct chemically accurate valency tables, and introduce a GFN2-xTB-based geometry and energy benchmark. We retrain and re-evaluate several leading models under this framework, providing updated performance metrics and practical recommendations for future benchmarking. Our results underscore the need for chemically rigorous evaluation practices in 3D molecular generation. Our recommended evaluation methods and GEOM-Drugs processing scripts are available at https://github.com/isayevlab/geom-drugs-3dgen-evaluation."
      },
      {
        "id": "oai:arXiv.org:2505.00171v1",
        "title": "Attention-enabled Explainable AI for Bladder Cancer Recurrence Prediction",
        "link": "https://arxiv.org/abs/2505.00171",
        "author": "Saram Abbas, Naeem Soomro, Rishad Shafik, Rakesh Heer, Kabita Adhikari",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00171v1 Announce Type: new \nAbstract: Non-muscle-invasive bladder cancer (NMIBC) is a relentless challenge in oncology, with recurrence rates soaring as high as 70-80%. Each recurrence triggers a cascade of invasive procedures, lifelong surveillance, and escalating healthcare costs - affecting 460,000 individuals worldwide. However, existing clinical prediction tools remain fundamentally flawed, often overestimating recurrence risk and failing to provide personalized insights for patient management. In this work, we propose an interpretable deep learning framework that integrates vector embeddings and attention mechanisms to improve NMIBC recurrence prediction performance. We incorporate vector embeddings for categorical variables such as smoking status and intravesical treatments, allowing the model to capture complex relationships between patient attributes and recurrence risk. These embeddings provide a richer representation of the data, enabling improved feature interactions and enhancing prediction performance. Our approach not only enhances performance but also provides clinicians with patient-specific insights by highlighting the most influential features contributing to recurrence risk for each patient. Our model achieves accuracy of 70% with tabular data, outperforming conventional statistical methods while providing clinician-friendly patient-level explanations through feature attention. Unlike previous studies, our approach identifies new important factors influencing recurrence, such as surgical duration and hospital stay, which had not been considered in existing NMIBC prediction models."
      },
      {
        "id": "oai:arXiv.org:2505.00189v1",
        "title": "Chronic Diseases Prediction using Machine Learning and Deep Learning Methods",
        "link": "https://arxiv.org/abs/2505.00189",
        "author": "Houda Belhad, Asmae Bourbia, Salma Boughanja",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00189v1 Announce Type: new \nAbstract: Chronic diseases, such as cardiovascular disease, diabetes, chronic kidney disease, and thyroid disorders, are the leading causes of premature mortality worldwide. Early detection and intervention are crucial for improving patient outcomes, yet traditional diagnostic methods often fail due to the complex nature of these conditions. This study explores the application of machine learning (ML) and deep learning (DL) techniques to predict chronic disease and thyroid disorders. We used a variety of models, including Logistic Regression (LR), Random Forest (RF), Gradient Boosted Trees (GBT), Neural Networks (NN), Decision Trees (DT) and Native Bayes (NB), to analyze and predict disease outcomes. Our methodology involved comprehensive data pre-processing, including handling missing values, categorical encoding, and feature aggregation, followed by model training and evaluation. Performance metrics such ad precision, recall, accuracy, F1-score, and Area Under the Curve (AUC) were used to assess the effectiveness of each model. The results demonstrated that ensemble methods like Random Forest and Gradient Boosted Trees consistently outperformed. Neutral Networks also showed superior performance, particularly in capturing complex data patterns. The findings highlight the potential of ML and DL in revolutionizing chronic disease prediction, enabling early diagnosis and personalized treatment strategies. However, challenges such as data quality, model interpretability, and the need for advanced computational techniques in healthcare to improve patient outcomes and reduce the burden of chronic diseases. This study was conducted as part of Big Data class project under the supervision of our professors Mr. Abderrahmane EZ-ZAHOUT and Mr. Abdessamad ESSAIDI."
      },
      {
        "id": "oai:arXiv.org:2505.00190v1",
        "title": "Empirical Evaluation of Progressive Coding for Sparse Autoencoders",
        "link": "https://arxiv.org/abs/2505.00190",
        "author": "Hans Peter, Anders S{\\o}gaard",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00190v1 Announce Type: new \nAbstract: Sparse autoencoders (SAEs) \\citep{bricken2023monosemanticity,gao2024scalingevaluatingsparseautoencoders} rely on dictionary learning to extract interpretable features from neural networks at scale in an unsupervised manner, with applications to representation engineering and information retrieval. SAEs are, however, computationally expensive \\citep{lieberum2024gemmascopeopensparse}, especially when multiple SAEs of different sizes are needed. We show that dictionary importance in vanilla SAEs follows a power law. We compare progressive coding based on subset pruning of SAEs -- to jointly training nested SAEs, or so-called {\\em Matryoshka} SAEs \\citep{bussmann2024learning,nabeshima2024Matryoshka} -- on a language modeling task. We show Matryoshka SAEs exhibit lower reconstruction loss and recaptured language modeling loss, as well as higher representational similarity. Pruned vanilla SAEs are more interpretable, however. We discuss the origins and implications of this trade-off."
      },
      {
        "id": "oai:arXiv.org:2505.00191v1",
        "title": "IP-CRR: Information Pursuit for Interpretable Classification of Chest Radiology Reports",
        "link": "https://arxiv.org/abs/2505.00191",
        "author": "Yuyan Ge, Kwan Ho Ryan Chan, Pablo Messina, Ren\\'e Vidal",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00191v1 Announce Type: new \nAbstract: The development of AI-based methods for analyzing radiology reports could lead to significant advances in medical diagnosis--from improving diagnostic accuracy to enhancing efficiency and reducing workload. However, the lack of interpretability in these methods has hindered their adoption in clinical settings. In this paper, we propose an interpretable-by-design framework for classifying radiology reports. The key idea is to extract a set of most informative queries from a large set of reports and use these queries and their corresponding answers to predict a diagnosis. Thus, the explanation for a prediction is, by construction, the set of selected queries and answers. We use the Information Pursuit framework to select informative queries, the Flan-T5 model to determine if facts are present in the report, and a classifier to predict the disease. Experiments on the MIMIC-CXR dataset demonstrate the effectiveness of the proposed method, highlighting its potential to enhance trust and usability in medical AI."
      },
      {
        "id": "oai:arXiv.org:2505.00196v1",
        "title": "Mapping minds not averages: a scalable subject-specific manifold learning framework for neuroimaging data",
        "link": "https://arxiv.org/abs/2505.00196",
        "author": "Eloy Geenjaar, Vince Calhoun",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00196v1 Announce Type: new \nAbstract: Mental and cognitive representations are believed to reside on low-dimensional, non-linear manifolds embedded within high-dimensional brain activity. Uncovering these manifolds is key to understanding individual differences in brain function, yet most existing machine learning methods either rely on population-level spatial alignment or assume data that is temporally structured, either because data is aligned among subjects or because event timings are known. We introduce a manifold learning framework that can capture subject-specific spatial variations across both structured and temporally unstructured neuroimaging data. On simulated data and two naturalistic fMRI datasets (Sherlock and Forrest Gump), our framework outperforms group-based baselines by recovering more accurate and individualized representations. We further show that the framework scales efficiently to large datasets and generalizes well to new subjects. To test this, we apply the framework to temporally unstructured resting-state fMRI data from individuals with schizophrenia and healthy controls. We further apply our method to a large resting-state fMRI dataset comprising individuals with schizophrenia and controls. In this setting, we demonstrate that the framework scales efficiently to large populations and generalizes robustly to unseen subjects. The learned subject-specific spatial maps our model finds reveal clinically relevant patterns, including increased activation in the basal ganglia, visual, auditory, and somatosensory regions, and decreased activation in the insula, inferior frontal gyrus, and angular gyrus. These findings suggest that our framework can uncover clinically relevant subject-specific brain activity patterns. Our approach thus provides a scalable and individualized framework for modeling brain activity, with applications in computational neuroscience and clinical research."
      },
      {
        "id": "oai:arXiv.org:2505.00209v1",
        "title": "Direct Motion Models for Assessing Generated Videos",
        "link": "https://arxiv.org/abs/2505.00209",
        "author": "Kelsey Allen, Carl Doersch, Guangyao Zhou, Mohammed Suhail, Danny Driess, Ignacio Rocco, Yulia Rubanova, Thomas Kipf, Mehdi S. M. Sajjadi, Kevin Murphy, Joao Carreira, Sjoerd van Steenkiste",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00209v1 Announce Type: new \nAbstract: A current limitation of video generative video models is that they generate plausible looking frames, but poor motion -- an issue that is not well captured by FVD and other popular methods for evaluating generated videos. Here we go beyond FVD by developing a metric which better measures plausible object interactions and motion. Our novel approach is based on auto-encoding point tracks and yields motion features that can be used to not only compare distributions of videos (as few as one generated and one ground truth, or as many as two datasets), but also for evaluating motion of single videos. We show that using point tracks instead of pixel reconstruction or action recognition features results in a metric which is markedly more sensitive to temporal distortions in synthetic data, and can predict human evaluations of temporal consistency and realism in generated videos obtained from open-source models better than a wide range of alternatives. We also show that by using a point track representation, we can spatiotemporally localize generative video inconsistencies, providing extra interpretability of generated video errors relative to prior work. An overview of the results and link to the code can be found on the project page: http://trajan-paper.github.io."
      },
      {
        "id": "oai:arXiv.org:2505.00210v1",
        "title": "Generative Machine Learning in Adaptive Control of Dynamic Manufacturing Processes: A Review",
        "link": "https://arxiv.org/abs/2505.00210",
        "author": "Suk Ki Lee, Hyunwoong Ko",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00210v1 Announce Type: new \nAbstract: Dynamic manufacturing processes exhibit complex characteristics defined by time-varying parameters, nonlinear behaviors, and uncertainties. These characteristics require sophisticated in-situ monitoring techniques utilizing multimodal sensor data and adaptive control systems that can respond to real-time feedback while maintaining product quality. Recently, generative machine learning (ML) has emerged as a powerful tool for modeling complex distributions and generating synthetic data while handling these manufacturing uncertainties. However, adopting these generative technologies in dynamic manufacturing systems lacks a functional control-oriented perspective to translate their probabilistic understanding into actionable process controls while respecting constraints. This review presents a functional classification of Prediction-Based, Direct Policy, Quality Inference, and Knowledge-Integrated approaches, offering a perspective for understanding existing ML-enhanced control systems and incorporating generative ML. The analysis of generative ML architectures within this framework demonstrates control-relevant properties and potential to extend current ML-enhanced approaches where conventional methods prove insufficient. We show generative ML's potential for manufacturing control through decision-making applications, process guidance, simulation, and digital twins, while identifying critical research gaps: separation between generation and control functions, insufficient physical understanding of manufacturing phenomena, and challenges adapting models from other domains. To address these challenges, we propose future research directions aimed at developing integrated frameworks that combine generative ML and control technologies to address the dynamic complexities of modern manufacturing systems."
      },
      {
        "id": "oai:arXiv.org:2505.00216v1",
        "title": "Online Federation For Mixtures of Proprietary Agents with Black-Box Encoders",
        "link": "https://arxiv.org/abs/2505.00216",
        "author": "Xuwei Yang, Fatemeh Tavakoli, David B. Emerson, Anastasis Kratsios",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00216v1 Announce Type: new \nAbstract: Most industry-standard generative AIs and feature encoders are proprietary, offering only black-box access: their outputs are observable, but their internal parameters and architectures remain hidden from the end-user. This black-box access is especially limiting when constructing mixture-of-expert type ensemble models since the user cannot optimize each proprietary AI's internal parameters. Our problem naturally lends itself to a non-competitive game-theoretic lens where each proprietary AI (agent) is inherently competing against the other AI agents, with this competition arising naturally due to their obliviousness of the AI's to their internal structure. In contrast, the user acts as a central planner trying to synchronize the ensemble of competing AIs.\n  We show the existence of the unique Nash equilibrium in the online setting, which we even compute in closed-form by eliciting a feedback mechanism between any given time series and the sequence generated by each (proprietary) AI agent. Our solution is implemented as a decentralized, federated-learning algorithm in which each agent optimizes their structure locally on their machine without ever releasing any internal structure to the others. We obtain refined expressions for pre-trained models such as transformers, random feature models, and echo-state networks. Our ``proprietary federated learning'' algorithm is implemented on a range of real-world and synthetic time-series benchmarks. It achieves orders-of-magnitude improvements in predictive accuracy over natural benchmarks, of which there are surprisingly few due to this natural problem still being largely unexplored."
      },
      {
        "id": "oai:arXiv.org:2505.00220v1",
        "title": "Towards Robust and Generalizable Gerchberg Saxton based Physics Inspired Neural Networks for Computer Generated Holography: A Sensitivity Analysis Framework",
        "link": "https://arxiv.org/abs/2505.00220",
        "author": "Ankit Amrutkar, Bj\\\"orn Kampa, Volkmar Schulz, Johannes Stegmaier, Markus Rothermel, Dorit Merhof",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00220v1 Announce Type: new \nAbstract: Computer-generated holography (CGH) enables applications in holographic augmented reality (AR), 3D displays, systems neuroscience, and optical trapping. The fundamental challenge in CGH is solving the inverse problem of phase retrieval from intensity measurements. Physics-inspired neural networks (PINNs), especially Gerchberg-Saxton-based PINNs (GS-PINNs), have advanced phase retrieval capabilities. However, their performance strongly depends on forward models (FMs) and their hyperparameters (FMHs), limiting generalization, complicating benchmarking, and hindering hardware optimization. We present a systematic sensitivity analysis framework based on Saltelli's extension of Sobol's method to quantify FMH impacts on GS-PINN performance. Our analysis demonstrates that SLM pixel-resolution is the primary factor affecting neural network sensitivity, followed by pixel-pitch, propagation distance, and wavelength. Free space propagation forward models demonstrate superior neural network performance compared to Fourier holography, providing enhanced parameterization and generalization. We introduce a composite evaluation metric combining performance consistency, generalization capability, and hyperparameter perturbation resilience, establishing a unified benchmarking standard across CGH configurations. Our research connects physics-inspired deep learning theory with practical CGH implementations through concrete guidelines for forward model selection, neural network architecture, and performance evaluation. Our contributions advance the development of robust, interpretable, and generalizable neural networks for diverse holographic applications, supporting evidence-based decisions in CGH research and implementation."
      },
      {
        "id": "oai:arXiv.org:2505.00225v1",
        "title": "Predicting Estimated Times of Restoration for Electrical Outages Using Longitudinal Tabular Transformers",
        "link": "https://arxiv.org/abs/2505.00225",
        "author": "Bogireddy Sai Prasanna Teja, Valliappan Muthukaruppan, Carls Benjamin",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00225v1 Announce Type: new \nAbstract: As climate variability increases, the ability of utility providers to deliver precise Estimated Times of Restoration (ETR) during natural disasters has become increasingly critical. Accurate and timely ETRs are essential for enabling customer preparedness during extended power outages, where informed decision-making can be crucial, particularly in severe weather conditions. Nonetheless, prevailing utility practices predominantly depend on manual assessments or traditional statistical methods, which often fail to achieve the level of precision required for reliable and actionable predictions. To address these limitations, we propose a Longitudinal Tabular Transformer (LTT) model that leverages historical outage event data along with sequential updates of these events to improve the accuracy of ETR predictions. The model's performance was evaluated over 34,000 storm-related outage events from three major utility companies, collectively serving over 3 million customers over a 2-year period. Results demonstrate that the LTT model improves the Customer Satisfaction Impact (CSI) metric by an average of 19.08% (p > 0.001) compared to existing methods. Additionally, we introduce customer-informed regression metrics that align model evaluation with real-world satisfaction, ensuring the outcomes resonate with customer expectations. Furthermore, we employ interpretability techniques to analyze the temporal significance of incorporating sequential updates in modeling outage events and to identify the contributions of predictive features to a given ETR. This comprehensive approach not only improves predictive accuracy but also enhances transparency, fostering greater trust in the model's capabilities."
      },
      {
        "id": "oai:arXiv.org:2505.00228v1",
        "title": "ReXGradient-160K: A Large-Scale Publicly Available Dataset of Chest Radiographs with Free-text Reports",
        "link": "https://arxiv.org/abs/2505.00228",
        "author": "Xiaoman Zhang, Juli\\'an N. Acosta, Josh Miller, Ouwen Huang, Pranav Rajpurkar",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00228v1 Announce Type: new \nAbstract: We present ReXGradient-160K, representing the largest publicly available chest X-ray dataset to date in terms of the number of patients. This dataset contains 160,000 chest X-ray studies with paired radiological reports from 109,487 unique patients across 3 U.S. health systems (79 medical sites). This comprehensive dataset includes multiple images per study and detailed radiology reports, making it particularly valuable for the development and evaluation of AI systems for medical imaging and automated report generation models. The dataset is divided into training (140,000 studies), validation (10,000 studies), and public test (10,000 studies) sets, with an additional private test set (10,000 studies) reserved for model evaluation on the ReXrank benchmark. By providing this extensive dataset, we aim to accelerate research in medical imaging AI and advance the state-of-the-art in automated radiological analysis. Our dataset will be open-sourced at https://huggingface.co/datasets/rajpurkarlab/ReXGradient-160K."
      },
      {
        "id": "oai:arXiv.org:2505.00232v1",
        "title": "Scaling On-Device GPU Inference for Large Generative Models",
        "link": "https://arxiv.org/abs/2505.00232",
        "author": "Jiuqiang Tang, Raman Sarokin, Ekaterina Ignasheva, Grant Jensen, Lin Chen, Juhyun Lee, Andrei Kulik, Matthias Grundmann",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00232v1 Announce Type: new \nAbstract: Driven by the advancements in generative AI, large machine learning models have revolutionized domains such as image processing, audio synthesis, and speech recognition. While server-based deployments remain the locus of peak performance, the imperative for on-device inference, necessitated by privacy and efficiency considerations, persists. Recognizing GPUs as the on-device ML accelerator with the widest reach, we present ML Drift--an optimized framework that extends the capabilities of state-of-the-art GPU-accelerated inference engines. ML Drift enables on-device execution of generative AI workloads which contain 10 to 100x more parameters than existing on-device generative AI models. ML Drift addresses intricate engineering challenges associated with cross-GPU API development, and ensures broad compatibility across mobile and desktop/laptop platforms, thereby facilitating the deployment of significantly more complex models on resource-constrained devices. Our GPU-accelerated ML/AI inference engine achieves an order-of-magnitude performance improvement relative to existing open-source GPU inference engines."
      },
      {
        "id": "oai:arXiv.org:2505.00234v1",
        "title": "Self-Generated In-Context Examples Improve LLM Agents for Sequential Decision-Making Tasks",
        "link": "https://arxiv.org/abs/2505.00234",
        "author": "Vishnu Sarukkai, Zhiqiang Xie, Kayvon Fatahalian",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00234v1 Announce Type: new \nAbstract: Many methods for improving Large Language Model (LLM) agents for sequential decision-making tasks depend on task-specific knowledge engineering--such as prompt tuning, curated in-context examples, or customized observation and action spaces. Using these approaches, agent performance improves with the quality or amount of knowledge engineering invested. Instead, we investigate how LLM agents can automatically improve their performance by learning in-context from their own successful experiences on similar tasks. Rather than relying on task-specific knowledge engineering, we focus on constructing and refining a database of self-generated examples. We demonstrate that even a naive accumulation of successful trajectories across training tasks boosts test performance on three benchmarks: ALFWorld (73% to 89%), Wordcraft (55% to 64%), and InterCode-SQL (75% to 79%)--matching the performance the initial agent achieves if allowed two to three attempts per task. We then introduce two extensions: (1) database-level selection through population-based training to identify high-performing example collections, and (2) exemplar-level selection that retains individual trajectories based on their empirical utility as in-context examples. These extensions further enhance performance, achieving 91% on ALFWorld--matching more complex approaches that employ task-specific components and prompts. Our results demonstrate that automatic trajectory database construction offers a compelling alternative to labor-intensive knowledge engineering."
      },
      {
        "id": "oai:arXiv.org:2505.00236v1",
        "title": "Node2Vec-DGI-EL: A Hierarchical Graph Representation Learning Model for Ingredient-Disease Association Prediction",
        "link": "https://arxiv.org/abs/2505.00236",
        "author": "Leifeng Zhang, Xin Dong, Shuaibing Jia, Jianhua Zhang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00236v1 Announce Type: new \nAbstract: Traditional Chinese medicine, as an essential component of traditional medicine, contains active ingredients that serve as a crucial source for modern drug development, holding immense therapeutic potential and development value. A multi-layered and complex network is formed from Chinese medicine to diseases and used to predict the potential associations between Chinese medicine ingredients and diseases. This study proposes an ingredient-disease association prediction model (Node2Vec-DGI-EL) based on hierarchical graph representation learning. First, the model uses the Node2Vec algorithm to extract node embedding vectors from the network as the initial features of the nodes. Next, the network nodes are deeply represented and learned using the DGI algorithm to enhance the model's expressive power. To improve prediction accuracy and robustness, an ensemble learning method is incorporated to achieve more accurate ingredient-disease association predictions. The effectiveness of the model is then evaluated through a series of theoretical verifications. The results demonstrated that the proposed model significantly outperformed existing methods, achieving an AUC of 0.9987 and an AUPR of 0.9545, thereby indicating superior predictive capability. Ablation experiments further revealed the contribution and importance of each module. Additionally, case studies explored potential associations, such as triptonide with hypertensive retinopathy and methyl ursolate with colorectal cancer. Molecular docking experiments validated these findings, showing the triptonide-PGR interaction and the methyl ursolate-NFE2L2 interaction can bind stable. In conclusion, the Node2Vec-DGI-EL model focuses on TCM datasets and effectively predicts ingredient-disease associations, overcoming the reliance on node semantic information."
      },
      {
        "id": "oai:arXiv.org:2505.00242v1",
        "title": "D-Tracker: Modeling Interest Diffusion in Social Activity Tensor Data Streams",
        "link": "https://arxiv.org/abs/2505.00242",
        "author": "Shingo Higashiguchi, Yasuko Matsubara, Koki Kawabata, Taichi Murayama, Yasushi Sakurai",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00242v1 Announce Type: new \nAbstract: Large quantities of social activity data, such as weekly web search volumes and the number of new infections with infectious diseases, reflect peoples' interests and activities. It is important to discover temporal patterns from such data and to forecast future activities accurately. However, modeling and forecasting social activity data streams is difficult because they are high-dimensional and composed of multiple time-varying dynamics such as trends, seasonality, and interest diffusion. In this paper, we propose D-Tracker, a method for continuously capturing time-varying temporal patterns within social activity tensor data streams and forecasting future activities. Our proposed method has the following properties: (a) Interpretable: it incorporates the partial differential equation into a tensor decomposition framework and captures time-varying temporal patterns such as trends, seasonality, and interest diffusion between locations in an interpretable manner; (b) Automatic: it has no hyperparameters and continuously models tensor data streams fully automatically; (c) Scalable: the computation time of D-Tracker is independent of the time series length. Experiments using web search volume data obtained from GoogleTrends, and COVID-19 infection data obtained from COVID-19 Open Data Repository show that our method can achieve higher forecasting accuracy in less computation time than existing methods while extracting the interest diffusion between locations. Our source code and datasets are available at {https://github.com/Higashiguchi-Shingo/D-Tracker."
      },
      {
        "id": "oai:arXiv.org:2505.00254v1",
        "title": "Empowering Agentic Video Analytics Systems with Video Language Models",
        "link": "https://arxiv.org/abs/2505.00254",
        "author": "Yuxuan Yan, Shiqi Jiang, Ting Cao, Yifan Yang, Qianqian Yang, Yuanchao Shu, Yuqing Yang, Lili Qiu",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00254v1 Announce Type: new \nAbstract: AI-driven video analytics has become increasingly pivotal across diverse domains. However, existing systems are often constrained to specific, predefined tasks, limiting their adaptability in open-ended analytical scenarios. The recent emergence of Video-Language Models (VLMs) as transformative technologies offers significant potential for enabling open-ended video understanding, reasoning, and analytics. Nevertheless, their limited context windows present challenges when processing ultra-long video content, which is prevalent in real-world applications. To address this, we introduce AVA, a VLM-powered system designed for open-ended, advanced video analytics. AVA incorporates two key innovations: (1) the near real-time construction of Event Knowledge Graphs (EKGs) for efficient indexing of long or continuous video streams, and (2) an agentic retrieval-generation mechanism that leverages EKGs to handle complex and diverse queries. Comprehensive evaluations on public benchmarks, LVBench and VideoMME-Long, demonstrate that AVA achieves state-of-the-art performance, attaining 62.3% and 64.1% accuracy, respectively, significantly surpassing existing VLM and video Retrieval-Augmented Generation (RAG) systems. Furthermore, to evaluate video analytics in ultra-long and open-world video scenarios, we introduce a new benchmark, AVA-100. This benchmark comprises 8 videos, each exceeding 10 hours in duration, along with 120 manually annotated, diverse, and complex question-answer pairs. On AVA-100, AVA achieves top-tier performance with an accuracy of 75.8%."
      },
      {
        "id": "oai:arXiv.org:2505.00257v1",
        "title": "Graph Privacy: A Heterogeneous Federated GNN for Trans-Border Financial Data Circulation",
        "link": "https://arxiv.org/abs/2505.00257",
        "author": "Zhizhong Tan, Jiexin Zheng, Kevin Qi Zhang, Wenyong Wang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00257v1 Announce Type: new \nAbstract: The sharing of external data has become a strong demand of financial institutions, but the privacy issue has led to the difficulty of interconnecting different platforms and the low degree of data openness. To effectively solve the privacy problem of financial data in trans-border flow and sharing, to ensure that the data is available but not visible, to realize the joint portrait of all kinds of heterogeneous data of business organizations in different industries, we propose a Heterogeneous Federated Graph Neural Network (HFGNN) approach. In this method, the distribution of heterogeneous business data of trans-border organizations is taken as subgraphs, and the sharing and circulation process among subgraphs is constructed as a statistically heterogeneous global graph through a central server. Each subgraph learns the corresponding personalized service model through local training to select and update the relevant subset of subgraphs with aggregated parameters, and effectively separates and combines topological and feature information among subgraphs. Finally, our simulation experimental results show that the proposed method has higher accuracy performance and faster convergence speed than existing methods."
      },
      {
        "id": "oai:arXiv.org:2505.00259v1",
        "title": "Pack-PTQ: Advancing Post-training Quantization of Neural Networks by Pack-wise Reconstruction",
        "link": "https://arxiv.org/abs/2505.00259",
        "author": "Changjun Li, Runqing Jiang, Zhuo Song, Pengpeng Yu, Ye Zhang, Yulan Guo",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00259v1 Announce Type: new \nAbstract: Post-training quantization (PTQ) has evolved as a prominent solution for compressing complex models, which advocates a small calibration dataset and avoids end-to-end retraining. However, most existing PTQ methods employ block-wise reconstruction, which neglects cross-block dependency and exhibits a notable accuracy drop in low-bit cases. To address these limitations, this paper presents a novel PTQ method, dubbed Pack-PTQ. First, we design a Hessian-guided adaptive packing mechanism to partition blocks into non-overlapping packs, which serve as the base unit for reconstruction, thereby preserving the cross-block dependency and enabling accurate quantization parameters estimation. Second, based on the pack configuration, we propose a mixed-precision quantization approach to assign varied bit-widths to packs according to their distinct sensitivities, thereby further enhancing performance. Extensive experiments on 2D image and 3D point cloud classification tasks, using various network architectures, demonstrate the superiority of our method over the state-of-the-art PTQ methods."
      },
      {
        "id": "oai:arXiv.org:2505.00261v1",
        "title": "Enriching the Korean Learner Corpus with Multi-reference Annotations and Rubric-Based Scoring",
        "link": "https://arxiv.org/abs/2505.00261",
        "author": "Jayoung Song, KyungTae Lim, Jungyeul Park",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00261v1 Announce Type: new \nAbstract: Despite growing global interest in Korean language education, there remains a significant lack of learner corpora tailored to Korean L2 writing. To address this gap, we enhance the KoLLA Korean learner corpus by adding multiple grammatical error correction (GEC) references, thereby enabling more nuanced and flexible evaluation of GEC systems, and reflects the variability of human language. Additionally, we enrich the corpus with rubric-based scores aligned with guidelines from the Korean National Language Institute, capturing grammatical accuracy, coherence, and lexical diversity. These enhancements make KoLLA a robust and standardized resource for research in Korean L2 education, supporting advancements in language learning, assessment, and automated error correction."
      },
      {
        "id": "oai:arXiv.org:2505.00265v1",
        "title": "Field-scale soil moisture estimated from Sentinel-1 SAR data using a knowledge-guided deep learning approach",
        "link": "https://arxiv.org/abs/2505.00265",
        "author": "Yi Yu, Patrick Filippi, Thomas F. A. Bishop",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00265v1 Announce Type: new \nAbstract: Soil moisture (SM) estimation from active microwave data remains challenging due to the complex interactions between radar backscatter and surface characteristics. While the water cloud model (WCM) provides a semi-physical approach for understanding these interactions, its empirical component often limits performance across diverse agricultural landscapes. This research presents preliminary efforts for developing a knowledge-guided deep learning approach, which integrates WCM principles into a long short-term memory (LSTM) model, to estimate field SM using Sentinel-1 Synthetic Aperture Radar (SAR) data. Our proposed approach leverages LSTM's capacity to capture spatiotemporal dependencies while maintaining physical consistency through a modified dual-component loss function, including a WCM-based semi-physical component and a boundary condition regularisation. The proposed approach is built upon the soil backscatter coefficients isolated from the total backscatter, together with Landsat-resolution vegetation information and surface characteristics. A four-fold spatial cross-validation was performed against in-situ SM data to assess the model performance. Results showed the proposed approach reduced SM retrieval uncertainties by 0.02 m$^3$/m$^3$ and achieved correlation coefficients (R) of up to 0.64 in areas with varying vegetation cover and surface conditions, demonstrating the potential to address the over-simplification in WCM."
      },
      {
        "id": "oai:arXiv.org:2505.00268v1",
        "title": "Consistency in Language Models: Current Landscape, Challenges, and Future Directions",
        "link": "https://arxiv.org/abs/2505.00268",
        "author": "Jekaterina Novikova, Carol Anderson, Borhane Blili-Hamelin, Subhabrata Majumdar",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00268v1 Announce Type: new \nAbstract: The hallmark of effective language use lies in consistency -- expressing similar meanings in similar contexts and avoiding contradictions. While human communication naturally demonstrates this principle, state-of-the-art language models struggle to maintain reliable consistency across different scenarios. This paper examines the landscape of consistency research in AI language systems, exploring both formal consistency (including logical rule adherence) and informal consistency (such as moral and factual coherence). We analyze current approaches to measure aspects of consistency, identify critical research gaps in standardization of definitions, multilingual assessment, and methods to improve consistency. Our findings point to an urgent need for robust benchmarks to measure and interdisciplinary approaches to ensure consistency in the application of language models on domain-specific tasks while preserving the utility and adaptability."
      },
      {
        "id": "oai:arXiv.org:2505.00275v1",
        "title": "AdCare-VLM: Leveraging Large Vision Language Model (LVLM) to Monitor Long-Term Medication Adherence and Care",
        "link": "https://arxiv.org/abs/2505.00275",
        "author": "Md Asaduzzaman Jabin, Hanqi Jiang, Yiwei Li, Patrick Kaggwa, Eugene Douglass, Juliet N. Sekandi, Tianming Liu",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00275v1 Announce Type: new \nAbstract: Chronic diseases, including diabetes, hypertension, asthma, HIV-AIDS, epilepsy, and tuberculosis, necessitate rigorous adherence to medication to avert disease progression, manage symptoms, and decrease mortality rates. Adherence is frequently undermined by factors including patient behavior, caregiver support, elevated medical costs, and insufficient healthcare infrastructure. We propose AdCare-VLM, a specialized Video-LLaVA-based multimodal large vision language model (LVLM) aimed at visual question answering (VQA) concerning medication adherence through patient videos. We employ a private dataset comprising 806 custom-annotated tuberculosis (TB) medication monitoring videos, which have been labeled by clinical experts, to fine-tune the model for adherence pattern detection. We present LLM-TB-VQA, a detailed medical adherence VQA dataset that encompasses positive, negative, and ambiguous adherence cases. Our method identifies correlations between visual features, such as the clear visibility of the patient's face, medication, water intake, and the act of ingestion, and their associated medical concepts in captions. This facilitates the integration of aligned visual-linguistic representations and improves multimodal interactions. Experimental results indicate that our method surpasses parameter-efficient fine-tuning (PEFT) enabled VLM models, such as LLaVA-V1.5 and Chat-UniVi, with absolute improvements ranging from 3.1% to 3.54% across pre-trained, regular, and low-rank adaptation (LoRA) configurations. Comprehensive ablation studies and attention map visualizations substantiate our approach, enhancing interpretability."
      },
      {
        "id": "oai:arXiv.org:2505.00279v1",
        "title": "Policies of Multiple Skill Levels for Better Strength Estimation in Games",
        "link": "https://arxiv.org/abs/2505.00279",
        "author": "Kyota Kuboki, Tatsuyoshi Ogawa, Chu-Hsuan Hsueh, Shi-Jim Yen, Kokolo Ikeda",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00279v1 Announce Type: new \nAbstract: Accurately estimating human skill levels is crucial for designing effective human-AI interactions so that AI can provide appropriate challenges or guidance. In games where AI players have beaten top human professionals, strength estimation plays a key role in adapting AI behavior to match human skill levels. In a previous state-of-the-art study, researchers have proposed a strength estimator trained using human players' match data. Given some matches, the strength estimator computes strength scores and uses them to estimate player ranks (skill levels). In this paper, we focus on the observation that human players' behavior tendency varies according to their strength and aim to improve the accuracy of strength estimation by taking this into account. Specifically, in addition to strength scores, we obtain policies for different skill levels from neural networks trained using human players' match data. We then combine features based on these policies with the strength scores to estimate strength. We conducted experiments on Go and chess. For Go, our method achieved an accuracy of 80% in strength estimation when given 10 matches, which increased to 92% when given 20 matches. In comparison, the previous state-of-the-art method had an accuracy of 71% with 10 matches and 84% with 20 matches, demonstrating improvements of 8-9%. We observed similar improvements in chess. These results contribute to developing a more accurate strength estimation method and to improving human-AI interaction."
      },
      {
        "id": "oai:arXiv.org:2505.00287v1",
        "title": "Avatar Communication Provides More Efficient Online Social Support Than Text Communication",
        "link": "https://arxiv.org/abs/2505.00287",
        "author": "Masanori Takano, Kenji Yokotani, Takahiro Kato, Nobuhito Abe, Fumiaki Taka",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00287v1 Announce Type: new \nAbstract: Online communication via avatars provides a richer online social experience than text communication. This reinforces the importance of online social support. Online social support is effective for people who lack social resources because of the anonymity of online communities. We aimed to understand online social support via avatars and their social relationships to provide better social support to avatar users. Therefore, we administered a questionnaire to three avatar communication service users (Second Life, ZEPETO, and Pigg Party) and three text communication service users (Facebook, X, and Instagram) (N=8,947). There was no duplication of users for each service. By comparing avatar and text communication users, we examined the amount of online social support, stability of online relationships, and the relationships between online social support and offline social resources (e.g., offline social support). We observed that avatar communication service users received more online social support, had more stable relationships, and had fewer offline social resources than text communication service users. However, the positive association between online and offline social support for avatar communication users was more substantial than for text communication users. These findings highlight the significance of realistic online communication experiences through avatars, including nonverbal and real-time interactions with co-presence. The findings also highlighted avatar communication service users' problems in the physical world, such as the lack of offline social resources. This study suggests that enhancing online social support through avatars can address these issues. This could help resolve social resource problems, both online and offline in future metaverse societies."
      },
      {
        "id": "oai:arXiv.org:2505.00290v1",
        "title": "Multi-Hierarchical Fine-Grained Feature Mapping Driven by Feature Contribution for Molecular Odor Prediction",
        "link": "https://arxiv.org/abs/2505.00290",
        "author": "Hong Xin Xie, Jian De Sun, Fan Fu Xue, Zi Fei Han, Shan Shan Feng, Qi Chen",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00290v1 Announce Type: new \nAbstract: Molecular odor prediction is the process of using a molecule's structure to predict its smell. While accurate prediction remains challenging, AI models can suggest potential odors. Existing methods, however, often rely on basic descriptors or handcrafted fingerprints, which lack expressive power and hinder effective learning. Furthermore, these methods suffer from severe class imbalance, limiting the training effectiveness of AI models. To address these challenges, we propose a Feature Contribution-driven Hierarchical Multi-Feature Mapping Network (HMFNet). Specifically, we introduce a fine-grained, Local Multi-Hierarchy Feature Extraction module (LMFE) that performs deep feature extraction at the atomic level, capturing detailed features crucial for odor prediction. To enhance the extraction of discriminative atomic features, we integrate a Harmonic Modulated Feature Mapping (HMFM). This module dynamically learns feature importance and frequency modulation, improving the model's capability to capture relevant patterns. Additionally, a Global Multi-Hierarchy Feature Extraction module (GMFE) is designed to learn global features from the molecular graph topology, enabling the model to fully leverage global information and enhance its discriminative power for odor prediction. To further mitigate the issue of class imbalance, we propose a Chemically-Informed Loss (CIL). Experimental results demonstrate that our approach significantly improves performance across various deep learning models, highlighting its potential to advance molecular structure representation and accelerate the development of AI-driven technologies."
      },
      {
        "id": "oai:arXiv.org:2505.00291v1",
        "title": "Repetition Makes Perfect: Recurrent Sum-GNNs Match Message Passing Limit",
        "link": "https://arxiv.org/abs/2505.00291",
        "author": "Eran Rosenbluth, Martin Grohe",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00291v1 Announce Type: new \nAbstract: We provide first tight bounds for the expressivity of Recurrent Graph Neural Networks (recurrent GNNs) with finite-precision parameters. We prove that recurrent GNNs, with sum aggregation and ReLU activation, can emulate any graph algorithm that respects the natural message-passing invariance induced by the color refinement (or Weisfeiler-Leman) algorithm. While it is well known that the expressive power of GNNs is limited by this invariance [Morris et al., AAAI 2019; Xu et al., ICLR 2019], we establish that recurrent GNNs can actually reach this limit. This is in contrast to non-recurrent GNNs, which have the power of Weisfeiler-Leman only in a very weak, \"non-uniform\", sense where every graph size requires a different GNN model to compute with. The emulation we construct introduces only a polynomial overhead in both time and space.\n  Furthermore, we show that by incorporating random initialization, recurrent GNNs can emulate all graph algorithms, implying in particular that any graph algorithm with polynomial-time complexity can be emulated by a recurrent GNN with random initialization, running in polynomial time."
      },
      {
        "id": "oai:arXiv.org:2505.00293v1",
        "title": "Reducing Sexual Predation and Victimization Through Warnings and Awareness among High-Risk Users",
        "link": "https://arxiv.org/abs/2505.00293",
        "author": "Masanori Takano, Mao Nishiguchi, Fujio Toriumi",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00293v1 Announce Type: new \nAbstract: Online sexual predators target children by building trust, creating dependency, and arranging meetings for sexual purposes. This poses a significant challenge for online communication platforms that strive to monitor and remove such content and terminate predators' accounts. However, these platforms can only take such actions if sexual predators explicitly violate the terms of service, not during the initial stages of relationship-building. This study designed and evaluated a strategy to prevent sexual predation and victimization by delivering warnings and raising awareness among high-risk individuals based on the routine activity theory in criminal psychology. We identified high-risk users as those with a high probability of committing or being subjected to violations, using a machine learning model that analyzed social networks and monitoring data from the platform. We conducted a randomized controlled trial on a Japanese avatar-based communication application, Pigg Party. High-risk players in the intervention group received warnings and awareness-building messages, while those in the control group did not receive the messages, regardless of their risk level. The trial involved 12,842 high-risk players in the intervention group and 12,844 in the control group for 138 days. The intervention successfully reduced violations and being violated among women for 12 weeks, although the impact on men was limited. These findings contribute to efforts to combat online sexual abuse and advance understanding of criminal psychology."
      },
      {
        "id": "oai:arXiv.org:2505.00295v1",
        "title": "Fine-grained spatial-temporal perception for gas leak segmentation",
        "link": "https://arxiv.org/abs/2505.00295",
        "author": "Xinlong Zhao, Shan Du",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00295v1 Announce Type: new \nAbstract: Gas leaks pose significant risks to human health and the environment. Despite long-standing concerns, there are limited methods that can efficiently and accurately detect and segment leaks due to their concealed appearance and random shapes. In this paper, we propose a Fine-grained Spatial-Temporal Perception (FGSTP) algorithm for gas leak segmentation. FGSTP captures critical motion clues across frames and integrates them with refined object features in an end-to-end network. Specifically, we first construct a correlation volume to capture motion information between consecutive frames. Then, the fine-grained perception progressively refines the object-level features using previous outputs. Finally, a decoder is employed to optimize boundary segmentation. Because there is no highly precise labeled dataset for gas leak segmentation, we manually label a gas leak video dataset, GasVid. Experimental results on GasVid demonstrate that our model excels in segmenting non-rigid objects such as gas leaks, generating the most accurate mask compared to other state-of-the-art (SOTA) models."
      },
      {
        "id": "oai:arXiv.org:2505.00302v1",
        "title": "Temporal Attention Evolutional Graph Convolutional Network for Multivariate Time Series Forecasting",
        "link": "https://arxiv.org/abs/2505.00302",
        "author": "Xinlong Zhao, Liying Zhang, Tianbo Zou, Yan Zhang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00302v1 Announce Type: new \nAbstract: Multivariate time series forecasting enables the prediction of future states by leveraging historical data, thereby facilitating decision-making processes. Each data node in a multivariate time series encompasses a sequence of multiple dimensions. These nodes exhibit interdependent relationships, forming a graph structure. While existing prediction methods often assume a fixed graph structure, many real-world scenarios involve dynamic graph structures. Moreover, interactions among time series observed at different time scales vary significantly. To enhance prediction accuracy by capturing precise temporal and spatial features, this paper introduces the Temporal Attention Evolutional Graph Convolutional Network (TAEGCN). This novel method not only integrates causal temporal convolution and a multi-head self-attention mechanism to learn temporal features of nodes, but also construct the dynamic graph structure based on these temporal features to keep the consistency of the changing in spatial feature with temporal series. TAEGCN adeptly captures temporal causal relationships and hidden spatial dependencies within the data. Furthermore, TAEGCN incorporates a unified neural network that seamlessly integrates these components to generate final predictions. Experimental results conducted on two public transportation network datasets, METR-LA and PEMS-BAY, demonstrate the superior performance of the proposed model."
      },
      {
        "id": "oai:arXiv.org:2505.00307v1",
        "title": "Gateformer: Advancing Multivariate Time Series Forecasting through Temporal and Variate-Wise Attention with Gated Representations",
        "link": "https://arxiv.org/abs/2505.00307",
        "author": "Yu-Hsiang Lan, Anton Alyakin, Eric K. Oermann",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00307v1 Announce Type: new \nAbstract: There has been a recent surge of interest in time series modeling using the Transformer architecture. However, forecasting multivariate time series with Transformer presents a unique challenge as it requires modeling both temporal (cross-time) and variate (cross-variate) dependencies. While Transformer-based models have gained popularity for their flexibility in capturing both sequential and cross-variate relationships, it is unclear how to best integrate these two sources of information in the context of the Transformer architecture while optimizing for both performance and efficiency. We re-purpose the Transformer architecture to effectively model both cross-time and cross-variate dependencies. Our approach begins by embedding each variate independently into a variate-wise representation that captures its cross-time dynamics, and then models cross-variate dependencies through attention mechanisms on these learned embeddings. Gating operations in both cross-time and cross-variate modeling phases regulate information flow, allowing the model to focus on the most relevant features for accurate predictions. Our method achieves state-of-the-art performance across 13 real-world datasets and can be seamlessly integrated into other Transformer-based and LLM-based forecasters, delivering performance improvements up to 20.7\\% over original models. Code is available at this repository: https://github.com/nyuolab/Gateformer."
      },
      {
        "id": "oai:arXiv.org:2505.00308v1",
        "title": "AI-Assisted Decision-Making for Clinical Assessment of Auto-Segmented Contour Quality",
        "link": "https://arxiv.org/abs/2505.00308",
        "author": "Biling Wang, Austen Maniscalco, Ti Bai, Siqiu Wang, Michael Dohopolski, Mu-Han Lin, Chenyang Shen, Dan Nguyen, Junzhou Huang, Steve Jiang, Xinlei Wang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00308v1 Announce Type: new \nAbstract: Purpose: This study presents a Deep Learning (DL)-based quality assessment (QA) approach for evaluating auto-generated contours (auto-contours) in radiotherapy, with emphasis on Online Adaptive Radiotherapy (OART). Leveraging Bayesian Ordinal Classification (BOC) and calibrated uncertainty thresholds, the method enables confident QA predictions without relying on ground truth contours or extensive manual labeling. Methods: We developed a BOC model to classify auto-contour quality and quantify prediction uncertainty. A calibration step was used to optimize uncertainty thresholds that meet clinical accuracy needs. The method was validated under three data scenarios: no manual labels, limited labels, and extensive labels. For rectum contours in prostate cancer, we applied geometric surrogate labels when manual labels were absent, transfer learning when limited, and direct supervision when ample labels were available. Results: The BOC model delivered robust performance across all scenarios. Fine-tuning with just 30 manual labels and calibrating with 34 subjects yielded over 90% accuracy on test data. Using the calibrated threshold, over 93% of the auto-contours' qualities were accurately predicted in over 98% of cases, reducing unnecessary manual reviews and highlighting cases needing correction. Conclusion: The proposed QA model enhances contouring efficiency in OART by reducing manual workload and enabling fast, informed clinical decisions. Through uncertainty quantification, it ensures safer, more reliable radiotherapy workflows."
      },
      {
        "id": "oai:arXiv.org:2505.00312v1",
        "title": "AWARE-NET: Adaptive Weighted Averaging for Robust Ensemble Network in Deepfake Detection",
        "link": "https://arxiv.org/abs/2505.00312",
        "author": "Muhammad Salman, Iqra Tariq, Mishal Zulfiqar, Muqadas Jalal, Sami Aujla, Sumbal Fatima",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00312v1 Announce Type: new \nAbstract: Deepfake detection has become increasingly important due to the rise of synthetic media, which poses significant risks to digital identity and cyber presence for security and trust. While multiple approaches have improved detection accuracy, challenges remain in achieving consistent performance across diverse datasets and manipulation types. In response, we propose a novel two-tier ensemble framework for deepfake detection based on deep learning that hierarchically combines multiple instances of three state-of-the-art architectures: Xception, Res2Net101, and EfficientNet-B7. Our framework employs a unique approach where each architecture is instantiated three times with different initializations to enhance model diversity, followed by a learnable weighting mechanism that dynamically combines their predictions. Unlike traditional fixed-weight ensembles, our first-tier averages predictions within each architecture family to reduce model variance, while the second tier learns optimal contribution weights through backpropagation, automatically adjusting each architecture's influence based on their detection reliability. Our experiments achieved state-of-the-art intra-dataset performance with AUC scores of 99.22% (FF++) and 100.00% (CelebDF-v2), and F1 scores of 98.06% (FF++) and 99.94% (CelebDF-v2) without augmentation. With augmentation, we achieve AUC scores of 99.47% (FF++) and 100.00% (CelebDF-v2), and F1 scores of 98.43% (FF++) and 99.95% (CelebDF-v2). The framework demonstrates robust cross-dataset generalization, achieving AUC scores of 88.20% and 72.52%, and F1 scores of 93.16% and 80.62% in cross-dataset evaluations."
      },
      {
        "id": "oai:arXiv.org:2505.00315v1",
        "title": "Mixture of Sparse Attention: Content-Based Learnable Sparse Attention via Expert-Choice Routing",
        "link": "https://arxiv.org/abs/2505.00315",
        "author": "Piotr Pi\\k{e}kos, R\\'obert Csord\\'as, J\\\"urgen Schmidhuber",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00315v1 Announce Type: new \nAbstract: Recent advances in large language models highlighted the excessive quadratic cost of self-attention. Despite the significant research efforts, subquadratic attention methods still suffer from inferior performance in practice. We hypothesize that dynamic, learned content-based sparsity can lead to more efficient attention mechanisms. We present Mixture of Sparse Attention (MoSA), a novel approach inspired by Mixture of Experts (MoE) with expert choice routing. MoSA dynamically selects tokens for each attention head, allowing arbitrary sparse attention patterns. By selecting $k$ tokens from a sequence of length $T$, MoSA reduces the computational complexity of each attention head from $O(T^2)$ to $O(k^2 + T)$. This enables using more heads within the same computational budget, allowing higher specialization. We show that among the tested sparse attention variants, MoSA is the only one that can outperform the dense baseline, sometimes with up to 27% better perplexity for an identical compute budget. MoSA can also reduce the resource usage compared to dense self-attention. Despite using torch implementation without an optimized kernel, perplexity-matched MoSA models are simultaneously faster in wall-clock time, require less memory for training, and drastically reduce the size of the KV-cache compared to the dense transformer baselines."
      },
      {
        "id": "oai:arXiv.org:2505.00316v1",
        "title": "Surrogate modeling of Cellular-Potts Agent-Based Models as a segmentation task using the U-Net neural network architecture",
        "link": "https://arxiv.org/abs/2505.00316",
        "author": "Tien Comlekoglu, J. Quetzalc\\'oatl Toledo-Mar\\'in, Tina Comlekoglu, Douglas W. DeSimone, Shayn M. Peirce, Geoffrey Fox, James A. Glazier",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00316v1 Announce Type: new \nAbstract: The Cellular-Potts model is a powerful and ubiquitous framework for developing computational models for simulating complex multicellular biological systems. Cellular-Potts models (CPMs) are often computationally expensive due to the explicit modeling of interactions among large numbers of individual model agents and diffusive fields described by partial differential equations (PDEs). In this work, we develop a convolutional neural network (CNN) surrogate model using a U-Net architecture that accounts for periodic boundary conditions. We use this model to accelerate the evaluation of a mechanistic CPM previously used to investigate \\textit{in vitro} vasculogenesis. The surrogate model was trained to predict 100 computational steps ahead (Monte-Carlo steps, MCS), accelerating simulation evaluations by a factor of 590 times compared to CPM code execution. Over multiple recursive evaluations, our model effectively captures the emergent behaviors demonstrated by the original Cellular-Potts model of such as vessel sprouting, extension and anastomosis, and contraction of vascular lacunae. This approach demonstrates the potential for deep learning to serve as efficient surrogate models for CPM simulations, enabling faster evaluation of computationally expensive CPM of biological processes at greater spatial and temporal scales."
      },
      {
        "id": "oai:arXiv.org:2505.00326v1",
        "title": "Optimal Vector Compressed Sensing Using James Stein Shrinkage",
        "link": "https://arxiv.org/abs/2505.00326",
        "author": "Apratim Dey, David Donoho",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00326v1 Announce Type: new \nAbstract: The trend in modern science and technology is to take vector measurements rather than scalars, ruthlessly scaling to ever higher dimensional vectors. For about two decades now, traditional scalar Compressed Sensing has been synonymous with a Convex Optimization based procedure called Basis Pursuit. In the vector recovery case, the natural tendency is to return to a straightforward vector extension of Basis Pursuit, also based on Convex Optimization. However, Convex Optimization is provably suboptimal, particularly when $B$ is large. In this paper, we propose SteinSense, a lightweight iterative algorithm, which is provably optimal when $B$ is large. It does not have any tuning parameter, does not need any training data, requires zero knowledge of sparsity, is embarrassingly simple to implement, and all of this makes it easily scalable to high vector dimensions. We conduct a massive volume of both real and synthetic experiments that confirm the efficacy of SteinSense, and also provide theoretical justification based on ideas from Approximate Message Passing. Fascinatingly, we discover that SteinSense is quite robust, delivering the same quality of performance on real data, and even under substantial departures from conditions under which existing theory holds."
      },
      {
        "id": "oai:arXiv.org:2505.00333v1",
        "title": "Communication-Efficient Wireless Federated Fine-Tuning for Large-Scale AI Models",
        "link": "https://arxiv.org/abs/2505.00333",
        "author": "Bumjun Kim, Wan Choi",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00333v1 Announce Type: new \nAbstract: Transformer-based large language models (LLMs) have achieved remarkable success across various tasks. Yet, fine-tuning such massive models in federated learning (FL) settings poses significant challenges due to resource constraints and communication overhead. Low-Rank Adaptation (LoRA) addresses these issues by training compact, low-rank matrices instead of fully fine-tuning large models. This paper introduces a wireless federated LoRA fine-tuning framework that optimizes both learning performance and communication efficiency. We provide a novel convergence analysis, revealing how LoRA rank and covariance effects influence FL training dynamics. Leveraging these insights, we propose Sparsified Orthogonal Fine-Tuning (\\textbf{SOFT}), an adaptive sparsification method that streamlines parameter updates without expensive matrix multiplications and singular value decomposition (SVD) operations. Additionally, we present a Two Stage Federated Algorithm (\\textbf{TSFA}) algorithm that pre-determines key parameters offline and dynamically adjusts bandwidth and sparsification online, ensuring efficient training under latency constraints. Experiments on benchmark datasets show that our approach achieves accuracy comparable to ideal scenario models while significantly reducing communication overhead. Our framework thus enables scalable, resource-efficient deployment of large models in real-world wireless FL scenarios."
      },
      {
        "id": "oai:arXiv.org:2505.00334v1",
        "title": "Quaternion Wavelet-Conditioned Diffusion Models for Image Super-Resolution",
        "link": "https://arxiv.org/abs/2505.00334",
        "author": "Luigi Sigillo, Christian Bianchi, Danilo Comminiello",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00334v1 Announce Type: new \nAbstract: Image Super-Resolution is a fundamental problem in computer vision with broad applications spacing from medical imaging to satellite analysis. The ability to reconstruct high-resolution images from low-resolution inputs is crucial for enhancing downstream tasks such as object detection and segmentation. While deep learning has significantly advanced SR, achieving high-quality reconstructions with fine-grained details and realistic textures remains challenging, particularly at high upscaling factors. Recent approaches leveraging diffusion models have demonstrated promising results, yet they often struggle to balance perceptual quality with structural fidelity. In this work, we introduce ResQu a novel SR framework that integrates a quaternion wavelet preprocessing framework with latent diffusion models, incorporating a new quaternion wavelet- and time-aware encoder. Unlike prior methods that simply apply wavelet transforms within diffusion models, our approach enhances the conditioning process by exploiting quaternion wavelet embeddings, which are dynamically integrated at different stages of denoising. Furthermore, we also leverage the generative priors of foundation models such as Stable Diffusion. Extensive experiments on domain-specific datasets demonstrate that our method achieves outstanding SR results, outperforming in many cases existing approaches in perceptual quality and standard evaluation metrics. The code will be available after the revision process."
      },
      {
        "id": "oai:arXiv.org:2505.00335v1",
        "title": "Efficient Neural Video Representation with Temporally Coherent Modulation",
        "link": "https://arxiv.org/abs/2505.00335",
        "author": "Seungjun Shin, Suji Kim, Dokwan Oh",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00335v1 Announce Type: new \nAbstract: Implicit neural representations (INR) has found successful applications across diverse domains. To employ INR in real-life, it is important to speed up training. In the field of INR for video applications, the state-of-the-art approach employs grid-type parametric encoding and successfully achieves a faster encoding speed in comparison to its predecessors. However, the grid usage, which does not consider the video's dynamic nature, leads to redundant use of trainable parameters. As a result, it has significantly lower parameter efficiency and higher bitrate compared to NeRV-style methods that do not use a parametric encoding. To address the problem, we propose Neural Video representation with Temporally coherent Modulation (NVTM), a novel framework that can capture dynamic characteristics of video. By decomposing the spatio-temporal 3D video data into a set of 2D grids with flow information, NVTM enables learning video representation rapidly and uses parameter efficiently. Our framework enables to process temporally corresponding pixels at once, resulting in the fastest encoding speed for a reasonable video quality, especially when compared to the NeRV-style method, with a speed increase of over 3 times. Also, it remarks an average of 1.54dB/0.019 improvements in PSNR/LPIPS on UVG (Dynamic) (even with 10% fewer parameters) and an average of 1.84dB/0.013 improvements in PSNR/LPIPS on MCL-JCV (Dynamic), compared to previous grid-type works. By expanding this to compression tasks, we demonstrate comparable performance to video compression standards (H.264, HEVC) and recent INR approaches for video compression. Additionally, we perform extensive experiments demonstrating the superior performance of our algorithm across diverse tasks, encompassing super resolution, frame interpolation and video inpainting. Project page is https://sujiikim.github.io/NVTM/."
      },
      {
        "id": "oai:arXiv.org:2505.00337v1",
        "title": "T2VPhysBench: A First-Principles Benchmark for Physical Consistency in Text-to-Video Generation",
        "link": "https://arxiv.org/abs/2505.00337",
        "author": "Xuyang Guo, Jiayan Huo, Zhenmei Shi, Zhao Song, Jiahao Zhang, Jiale Zhao",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00337v1 Announce Type: new \nAbstract: Text-to-video generative models have made significant strides in recent years, producing high-quality videos that excel in both aesthetic appeal and accurate instruction following, and have become central to digital art creation and user engagement online. Yet, despite these advancements, their ability to respect fundamental physical laws remains largely untested: many outputs still violate basic constraints such as rigid-body collisions, energy conservation, and gravitational dynamics, resulting in unrealistic or even misleading content. Existing physical-evaluation benchmarks typically rely on automatic, pixel-level metrics applied to simplistic, life-scenario prompts, and thus overlook both human judgment and first-principles physics. To fill this gap, we introduce \\textbf{T2VPhysBench}, a first-principled benchmark that systematically evaluates whether state-of-the-art text-to-video systems, both open-source and commercial, obey twelve core physical laws including Newtonian mechanics, conservation principles, and phenomenological effects. Our benchmark employs a rigorous human evaluation protocol and includes three targeted studies: (1) an overall compliance assessment showing that all models score below 0.60 on average in each law category; (2) a prompt-hint ablation revealing that even detailed, law-specific hints fail to remedy physics violations; and (3) a counterfactual robustness test demonstrating that models often generate videos that explicitly break physical rules when so instructed. The results expose persistent limitations in current architectures and offer concrete insights for guiding future research toward truly physics-aware video generation."
      },
      {
        "id": "oai:arXiv.org:2505.00339v1",
        "title": "Enhancing AI-Driven Education: Integrating Cognitive Frameworks, Linguistic Feedback Analysis, and Ethical Considerations for Improved Content Generation",
        "link": "https://arxiv.org/abs/2505.00339",
        "author": "Antoun Yaacoub, Sansiri Tarnpradab, Phattara Khumprom, Zainab Assaghir, Lionel Prevost, J\\'er\\^ome Da-Rugna",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00339v1 Announce Type: new \nAbstract: Artificial intelligence (AI) is rapidly transforming education, presenting unprecedented opportunities for personalized learning and streamlined content creation. However, realizing the full potential of AI in educational settings necessitates careful consideration of the quality, cognitive depth, and ethical implications of AI-generated materials. This paper synthesizes insights from four related studies to propose a comprehensive framework for enhancing AI-driven educational tools. We integrate cognitive assessment frameworks (Bloom's Taxonomy and SOLO Taxonomy), linguistic analysis of AI-generated feedback, and ethical design principles to guide the development of effective and responsible AI tools. We outline a structured three-phase approach encompassing cognitive alignment, linguistic feedback integration, and ethical safeguards. The practical application of this framework is demonstrated through its integration into OneClickQuiz, an AI-powered Moodle plugin for quiz generation. This work contributes a comprehensive and actionable guide for educators, researchers, and developers aiming to harness AI's potential while upholding pedagogical and ethical standards in educational content generation."
      },
      {
        "id": "oai:arXiv.org:2505.00347v1",
        "title": "Pushing the Limits of Low-Bit Optimizers: A Focus on EMA Dynamics",
        "link": "https://arxiv.org/abs/2505.00347",
        "author": "Cong Xu, Wenbin Liang, Mo Yu, Anan Liu, Ke-Yue Zhang, Lizhuang Ma, Jianyong Wang, Jun Wang, Wei Zhang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00347v1 Announce Type: new \nAbstract: The explosion in model sizes leads to continued growth in prohibitive training/fine-tuning costs, particularly for stateful optimizers which maintain auxiliary information of even 2x the model size to achieve optimal convergence. We therefore present in this work a novel type of optimizer that carries with extremely lightweight state overloads, achieved through ultra-low-precision quantization. While previous efforts have achieved certain success with 8-bit or 4-bit quantization, our approach enables optimizers to operate at precision as low as 3 bits, or even 2 bits per state element. This is accomplished by identifying and addressing two critical challenges: the signal swamping problem in unsigned quantization that results in unchanged state dynamics, and the rapidly increased gradient variance in signed quantization that leads to incorrect descent directions. The theoretical analysis suggests a tailored logarithmic quantization for the former and a precision-specific momentum value for the latter. Consequently, the proposed SOLO achieves substantial memory savings (approximately 45 GB when training a 7B model) with minimal accuracy loss. We hope that SOLO can contribute to overcoming the bottleneck in computational resources, thereby promoting greater accessibility in fundamental research."
      },
      {
        "id": "oai:arXiv.org:2505.00348v1",
        "title": "Validation of a 24-hour-ahead Prediction model for a Residential Electrical Load under diverse climate",
        "link": "https://arxiv.org/abs/2505.00348",
        "author": "Ehtisham Asghar, Martin Hill, Ibrahim Sengor, Conor Lynch, Phan Quang An",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00348v1 Announce Type: new \nAbstract: Accurate household electrical energy demand prediction is essential for effectively managing sustainable Energy Communities. Integrated with the Energy Management System, these communities aim to optimise operational costs. However, most existing forecasting models are region-specific and depend on large datasets, limiting their applicability across different climates and geographical areas. These models often lack flexibility and may not perform well in regions with limited historical data, leading to inaccurate predictions. This paper proposes a global model for 24-hour-ahead hourly electrical energy demand prediction that is designed to perform effectively across diverse climate conditions and datasets. The model's efficiency is demonstrated using data from two distinct regions: Ireland, with a maritime climate and Vietnam, with a tropical climate. Remarkably, the model achieves high accuracy even with a limited dataset spanning only nine months. Its robustness is further validated across different seasons in Ireland (summer and winter) and Vietnam (dry and wet). The proposed model is evaluated against state-of-the-art machine learning and deep learning methods. Simulation results indicate that the model consistently outperforms benchmark models, showcasing its capability to provide reliable forecasts globally, regardless of varying climatic conditions and data availability. This research underscores the model's potential to enhance the efficiency and sustainability of Energy Communities worldwide. The proposed model achieves a Mean Absolute Percentage Error of 8.0% and 4.0% on the full Irish and Vietnamese datasets."
      },
      {
        "id": "oai:arXiv.org:2505.00350v1",
        "title": "Optimizing Deep Neural Networks using Safety-Guided Self Compression",
        "link": "https://arxiv.org/abs/2505.00350",
        "author": "Mohammad Zbeeb, Mariam Salman, Mohammad Bazzi, Ammar Mohanna",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00350v1 Announce Type: new \nAbstract: The deployment of deep neural networks on resource-constrained devices necessitates effective model com- pression strategies that judiciously balance the reduction of model size with the preservation of performance. This study introduces a novel safety-driven quantization framework that leverages preservation sets to systematically prune and quantize neural network weights, thereby optimizing model complexity without compromising accuracy. The proposed methodology is rigorously evaluated on both a convolutional neural network (CNN) and an attention-based language model, demonstrating its applicability across diverse architectural paradigms. Experimental results reveal that our framework achieves up to a 2.5% enhancement in test accuracy relative to the original unquantized models while maintaining 60% of the initial model size. In comparison to conventional quantization techniques, our approach not only augments generalization by eliminating parameter noise and retaining essential weights but also reduces variance, thereby ensuring the retention of critical model features. These findings underscore the efficacy of safety-driven quantization as a robust and reliable strategy for the efficient optimization of deep learn- ing models. The implementation and comprehensive experimental evaluations of our framework are publicly accessible at GitHub."
      },
      {
        "id": "oai:arXiv.org:2505.00358v1",
        "title": "R&B: Domain Regrouping and Data Mixture Balancing for Efficient Foundation Model Training",
        "link": "https://arxiv.org/abs/2505.00358",
        "author": "Albert Ge, Tzu-Heng Huang, John Cooper, Avi Trost, Ziyi Chu, Satya Sai Srinath Namburi GNVV, Ziyang Cai, Kendall Park, Nicholas Roberts, Frederic Sala",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00358v1 Announce Type: new \nAbstract: Data mixing strategies have successfully reduced the costs involved in training language models. While promising, such methods suffer from two flaws. First, they rely on predetermined data domains (e.g., data sources, task types), which may fail to capture critical semantic nuances, leaving performance on the table. Second, these methods scale with the number of domains in a computationally prohibitive way. We address these challenges via R&amp;B, a framework that re-partitions training data based on semantic similarity (Regroup) to create finer-grained domains, and efficiently optimizes the data composition (Balance) by leveraging a Gram matrix induced by domain gradients obtained throughout training. Unlike prior works, it removes the need for additional compute to obtain evaluation information such as losses or gradients. We analyze this technique under standard regularity conditions and provide theoretical insights that justify R&amp;B's effectiveness compared to non-adaptive mixing approaches. Empirically, we demonstrate the effectiveness of R&amp;B on five diverse datasets ranging from natural language to reasoning and multimodal tasks. With as little as 0.01% additional compute overhead, R&amp;B matches or exceeds the performance of state-of-the-art data mixing strategies."
      },
      {
        "id": "oai:arXiv.org:2505.00359v1",
        "title": "TNStream: Applying Tightest Neighbors to Micro-Clusters to Define Multi-Density Clusters in Streaming Data",
        "link": "https://arxiv.org/abs/2505.00359",
        "author": "Qifen Zeng, Haomin Bao, Yuanzhuo Hu, Zirui Zhang, Yuheng Zheng, Luosheng Wen",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00359v1 Announce Type: new \nAbstract: In data stream clustering, systematic theory of stream clustering algorithms remains relatively scarce. Recently, density-based methods have gained attention. However, existing algorithms struggle to simultaneously handle arbitrarily shaped, multi-density, high-dimensional data while maintaining strong outlier resistance. Clustering quality significantly deteriorates when data density varies complexly. This paper proposes a clustering algorithm based on the novel concept of Tightest Neighbors and introduces a data stream clustering theory based on the Skeleton Set. Based on these theories, this paper develops a new method, TNStream, a fully online algorithm. The algorithm adaptively determines the clustering radius based on local similarity, summarizing the evolution of multi-density data streams in micro-clusters. It then applies a Tightest Neighbors-based clustering algorithm to form final clusters. To improve efficiency in high-dimensional cases, Locality-Sensitive Hashing (LSH) is employed to structure micro-clusters, addressing the challenge of storing k-nearest neighbors. TNStream is evaluated on various synthetic and real-world datasets using different clustering metrics. Experimental results demonstrate its effectiveness in improving clustering quality for multi-density data and validate the proposed data stream clustering theory."
      },
      {
        "id": "oai:arXiv.org:2505.00364v1",
        "title": "From GNNs to Trees: Multi-Granular Interpretability for Graph Neural Networks",
        "link": "https://arxiv.org/abs/2505.00364",
        "author": "Jie Yang, Yuwen Wang, Kaixuan Chen, Tongya Zheng, Yihe Zhou, Zhenbang Xiao, Ji Cao, Mingli Song, Shunyu Liu",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00364v1 Announce Type: new \nAbstract: Interpretable Graph Neural Networks (GNNs) aim to reveal the underlying reasoning behind model predictions, attributing their decisions to specific subgraphs that are informative. However, existing subgraph-based interpretable methods suffer from an overemphasis on local structure, potentially overlooking long-range dependencies within the entire graphs. Although recent efforts that rely on graph coarsening have proven beneficial for global interpretability, they inevitably reduce the graphs to a fixed granularity. Such an inflexible way can only capture graph connectivity at a specific level, whereas real-world graph tasks often exhibit relationships at varying granularities (e.g., relevant interactions in proteins span from functional groups, to amino acids, and up to protein domains). In this paper, we introduce a novel Tree-like Interpretable Framework (TIF) for graph classification, where plain GNNs are transformed into hierarchical trees, with each level featuring coarsened graphs of different granularity as tree nodes. Specifically, TIF iteratively adopts a graph coarsening module to compress original graphs (i.e., root nodes of trees) into increasingly coarser ones (i.e., child nodes of trees), while preserving diversity among tree nodes within different branches through a dedicated graph perturbation module. Finally, we propose an adaptive routing module to identify the most informative root-to-leaf paths, providing not only the final prediction but also the multi-granular interpretability for the decision-making process. Extensive experiments on the graph classification benchmarks with both synthetic and real-world datasets demonstrate the superiority of TIF in interpretability, while also delivering a competitive prediction performance akin to the state-of-the-art counterparts."
      },
      {
        "id": "oai:arXiv.org:2505.00365v1",
        "title": "SacFL: Self-Adaptive Federated Continual Learning for Resource-Constrained End Devices",
        "link": "https://arxiv.org/abs/2505.00365",
        "author": "Zhengyi Zhong, Weidong Bao, Ji Wang, Jianguo Chen, Lingjuan Lyu, Wei Yang Bryan Lim",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00365v1 Announce Type: new \nAbstract: The proliferation of end devices has led to a distributed computing paradigm, wherein on-device machine learning models continuously process diverse data generated by these devices. The dynamic nature of this data, characterized by continuous changes or data drift, poses significant challenges for on-device models. To address this issue, continual learning (CL) is proposed, enabling machine learning models to incrementally update their knowledge and mitigate catastrophic forgetting. However, the traditional centralized approach to CL is unsuitable for end devices due to privacy and data volume concerns. In this context, federated continual learning (FCL) emerges as a promising solution, preserving user data locally while enhancing models through collaborative updates. Aiming at the challenges of limited storage resources for CL, poor autonomy in task shift detection, and difficulty in coping with new adversarial tasks in FCL scenario, we propose a novel FCL framework named SacFL. SacFL employs an Encoder-Decoder architecture to separate task-robust and task-sensitive components, significantly reducing storage demands by retaining lightweight task-sensitive components for resource-constrained end devices. Moreover, $\\rm{SacFL}$ leverages contrastive learning to introduce an autonomous data shift detection mechanism, enabling it to discern whether a new task has emerged and whether it is a benign task. This capability ultimately allows the device to autonomously trigger CL or attack defense strategy without additional information, which is more practical for end devices. Comprehensive experiments conducted on multiple text and image datasets, such as Cifar100 and THUCNews, have validated the effectiveness of $\\rm{SacFL}$ in both class-incremental and domain-incremental scenarios. Furthermore, a demo system has been developed to verify its practicality."
      },
      {
        "id": "oai:arXiv.org:2505.00367v1",
        "title": "KoACD: The First Korean Adolescent Dataset for Cognitive Distortion Analysis",
        "link": "https://arxiv.org/abs/2505.00367",
        "author": "JunSeo Kim, HyeHyeon Kim",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00367v1 Announce Type: new \nAbstract: Cognitive distortion refers to negative thinking patterns that can lead to mental health issues like depression and anxiety in adolescents. Previous studies using natural language processing (NLP) have focused mainly on small-scale adult datasets, with limited research on adolescents. This study introduces KoACD, the first large-scale dataset of cognitive distortions in Korean adolescents, containing 108,717 instances. We applied a multi-Large Language Model (LLM) negotiation method to refine distortion classification and generate synthetic data using two approaches: cognitive clarification for textual clarity and cognitive balancing for diverse distortion representation. Validation through LLMs and expert evaluations showed that while LLMs classified distortions with explicit markers, they struggled with context-dependent reasoning, where human evaluators demonstrated higher accuracy. KoACD aims to enhance future research on cognitive distortion detection."
      },
      {
        "id": "oai:arXiv.org:2505.00369v1",
        "title": "Automated segmenta-on of pediatric neuroblastoma on multi-modal MRI: Results of the SPPIN challenge at MICCAI 2023",
        "link": "https://arxiv.org/abs/2505.00369",
        "author": "M. A. D. Buser, D. C. Simons, M. Fitski, M. H. W. A. Wijnen, A. S. Littooij, A. H. ter Brugge, I. N. Vos, M. H. A. Janse, M. de Boer, R. ter Maat, J. Sato, S. Kido, S. Kondo, S. Kasai, M. Wodzinski, H. Muller, J. Ye, J. He, Y. Kirchhoff, M. R. Rokkus, G. Haokai, S. Zitong, M. Fern\\'andez-Pat\\'on, D. Veiga-Canuto, D. G. Ellis, M. R. Aizenberg, B. H. M. van der Velden, H. Kuijf, A. De Luca, A. F. W. van der Steeg",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00369v1 Announce Type: new \nAbstract: Surgery plays an important role within the treatment for neuroblastoma, a common pediatric cancer. This requires careful planning, often via magnetic resonance imaging (MRI)-based anatomical 3D models. However, creating these models is often time-consuming and user dependent. We organized the Surgical Planning in Pediatric Neuroblastoma (SPPIN) challenge, to stimulate developments on this topic, and set a benchmark for fully automatic segmentation of neuroblastoma on multi-model MRI. The challenge started with a training phase, where teams received 78 sets of MRI scans from 34 patients, consisting of both diagnostic and post-chemotherapy MRI scans. The final test phase, consisting of 18 MRI sets from 9 patients, determined the ranking of the teams. Ranking was based on the Dice similarity coefficient (Dice score), the 95th percentile of the Hausdorff distance (HD95) and the volumetric similarity (VS). The SPPIN challenge was hosted at MICCAI 2023. The final leaderboard consisted of 9 teams. The highest-ranking team achieved a median Dice score 0.82, a median HD95 of 7.69 mm and a VS of 0.91, utilizing a large, pretrained network called STU-Net. A significant difference for the segmentation results between diagnostic and post-chemotherapy MRI scans was observed (Dice = 0.89 vs Dice = 0.59, P = 0.01) for the highest-ranking team. SPPIN is the first medical segmentation challenge in extracranial pediatric oncology. The highest-ranking team used a large pre-trained network, suggesting that pretraining can be of use in small, heterogenous datasets. Although the results of the highest-ranking team were high for most patients, segmentation especially in small, pre-treated tumors were insufficient. Therefore, more reliable segmentation methods are needed to create clinically applicable models to aid surgical planning in pediatric neuroblastoma."
      },
      {
        "id": "oai:arXiv.org:2505.00375v1",
        "title": "Learning to Estimate Package Delivery Time in Mixed Imbalanced Delivery and Pickup Logistics Services",
        "link": "https://arxiv.org/abs/2505.00375",
        "author": "Jinhui Yi, Huan Yan, Haotian Wang, Jian Yuan, Yong Li",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00375v1 Announce Type: new \nAbstract: Accurately estimating package delivery time is essential to the logistics industry, which enables reasonable work allocation and on-time service guarantee. This becomes even more necessary in mixed logistics scenarios where couriers handle a high volume of delivery and a smaller number of pickup simultaneously. However, most of the related works treat the pickup and delivery patterns on couriers' decision behavior equally, neglecting that the pickup has a greater impact on couriers' decision-making compared to the delivery due to its tighter time constraints. In such context, we have three main challenges: 1) multiple spatiotemporal factors are intricately interconnected, significantly affecting couriers' delivery behavior; 2) pickups have stricter time requirements but are limited in number, making it challenging to model their effects on couriers' delivery process; 3) couriers' spatial mobility patterns are critical determinants of their delivery behavior, but have been insufficiently explored. To deal with these, we propose TransPDT, a Transformer-based multi-task package delivery time prediction model. We first employ the Transformer encoder architecture to capture the spatio-temporal dependencies of couriers' historical travel routes and pending package sets. Then we design the pattern memory to learn the patterns of pickup in the imbalanced dataset via attention mechanism. We also set the route prediction as an auxiliary task of delivery time prediction, and incorporate the prior courier spatial movement regularities in prediction. Extensive experiments on real industry-scale datasets demonstrate the superiority of our method. A system based on TransPDT is deployed internally in JD Logistics to track more than 2000 couriers handling hundreds of thousands of packages per day in Beijing."
      },
      {
        "id": "oai:arXiv.org:2505.00378v1",
        "title": "Cues3D: Unleashing the Power of Sole NeRF for Consistent and Unique Instances in Open-Vocabulary 3D Panoptic Segmentation",
        "link": "https://arxiv.org/abs/2505.00378",
        "author": "Feng Xue, Wenzhuang Xu, Guofeng Zhong, Anlong Minga, Nicu Sebe",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00378v1 Announce Type: new \nAbstract: Open-vocabulary 3D panoptic segmentation has recently emerged as a significant trend. Top-performing methods currently integrate 2D segmentation with geometry-aware 3D primitives. However, the advantage would be lost without high-fidelity 3D point clouds, such as methods based on Neural Radiance Field (NeRF). These methods are limited by the insufficient capacity to maintain consistency across partial observations. To address this, recent works have utilized contrastive loss or cross-view association pre-processing for view consensus. In contrast to them, we present Cues3D, a compact approach that relies solely on NeRF instead of pre-associations. The core idea is that NeRF's implicit 3D field inherently establishes a globally consistent geometry, enabling effective object distinction without explicit cross-view supervision. We propose a three-phase training framework for NeRF, initialization-disambiguation-refinement, whereby the instance IDs are corrected using the initially-learned knowledge. Additionally, an instance disambiguation method is proposed to match NeRF-rendered 3D masks and ensure globally unique 3D instance identities. With the aid of Cues3D, we obtain highly consistent and unique 3D instance ID for each object across views with a balanced version of NeRF. Our experiments are conducted on ScanNet v2, ScanNet200, ScanNet++, and Replica datasets for 3D instance, panoptic, and semantic segmentation tasks. Cues3D outperforms other 2D image-based methods and competes with the latest 2D-3D merging based methods, while even surpassing them when using additional 3D point clouds. The code link could be found in the appendix and will be released on \\href{https://github.com/mRobotit/Cues3D}{github}"
      },
      {
        "id": "oai:arXiv.org:2505.00380v1",
        "title": "The Invisible Threat: Evaluating the Vulnerability of Cross-Spectral Face Recognition to Presentation Attacks",
        "link": "https://arxiv.org/abs/2505.00380",
        "author": "Anjith George, Sebastien Marcel",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00380v1 Announce Type: new \nAbstract: Cross-spectral face recognition systems are designed to enhance the performance of facial recognition systems by enabling cross-modal matching under challenging operational conditions. A particularly relevant application is the matching of near-infrared (NIR) images to visible-spectrum (VIS) images, enabling the verification of individuals by comparing NIR facial captures acquired with VIS reference images. The use of NIR imaging offers several advantages, including greater robustness to illumination variations, better visibility through glasses and glare, and greater resistance to presentation attacks. Despite these claimed benefits, the robustness of NIR-based systems against presentation attacks has not been systematically studied in the literature. In this work, we conduct a comprehensive evaluation into the vulnerability of NIR-VIS cross-spectral face recognition systems to presentation attacks. Our empirical findings indicate that, although these systems exhibit a certain degree of reliability, they remain vulnerable to specific attacks, emphasizing the need for further research in this area."
      },
      {
        "id": "oai:arXiv.org:2505.00382v1",
        "title": "Approximation to Deep Q-Network by Stochastic Delay Differential Equations",
        "link": "https://arxiv.org/abs/2505.00382",
        "author": "Jianya Lu, Yingjun Mo",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00382v1 Announce Type: new \nAbstract: Despite the significant breakthroughs that the Deep Q-Network (DQN) has brought to reinforcement learning, its theoretical analysis remains limited. In this paper, we construct a stochastic differential delay equation (SDDE) based on the DQN algorithm and estimate the Wasserstein-1 distance between them. We provide an upper bound for the distance and prove that the distance between the two converges to zero as the step size approaches zero. This result allows us to understand DQN's two key techniques, the experience replay and the target network, from the perspective of continuous systems. Specifically, the delay term in the equation, corresponding to the target network, contributes to the stability of the system. Our approach leverages a refined Lindeberg principle and an operator comparison to establish these results."
      },
      {
        "id": "oai:arXiv.org:2505.00389v1",
        "title": "CSE-SFP: Enabling Unsupervised Sentence Representation Learning via a Single Forward Pass",
        "link": "https://arxiv.org/abs/2505.00389",
        "author": "Bowen Zhang, Zixin Song, Chunping Li",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00389v1 Announce Type: new \nAbstract: As a fundamental task in Information Retrieval and Computational Linguistics, sentence representation has profound implications for a wide range of practical applications such as text clustering, content analysis, question-answering systems, and web search. Recent advances in pre-trained language models (PLMs) have driven remarkable progress in this field, particularly through unsupervised embedding derivation methods centered on discriminative PLMs like BERT. However, due to time and computational constraints, few efforts have attempted to integrate unsupervised sentence representation with generative PLMs, which typically possess much larger parameter sizes. Given that state-of-the-art models in both academia and industry are predominantly based on generative architectures, there is a pressing need for an efficient unsupervised text representation framework tailored to decoder-only PLMs. To address this concern, we propose CSE-SFP, an innovative method that exploits the structural characteristics of generative models. Compared to existing strategies, CSE-SFP requires only a single forward pass to perform effective unsupervised contrastive learning. Rigorous experimentation demonstrates that CSE-SFP not only produces higher-quality embeddings but also significantly reduces both training time and memory consumption. Furthermore, we introduce two ratio metrics that jointly assess alignment and uniformity, thereby providing a more robust means for evaluating the semantic spatial properties of encoding models."
      },
      {
        "id": "oai:arXiv.org:2505.00394v1",
        "title": "SOTA: Spike-Navigated Optimal TrAnsport Saliency Region Detection in Composite-bias Videos",
        "link": "https://arxiv.org/abs/2505.00394",
        "author": "Wenxuan Liu, Yao Deng, Kang Chen, Xian Zhong, Zhaofei Yu, Tiejun Huang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00394v1 Announce Type: new \nAbstract: Existing saliency detection methods struggle in real-world scenarios due to motion blur and occlusions. In contrast, spike cameras, with their high temporal resolution, significantly enhance visual saliency maps. However, the composite noise inherent to spike camera imaging introduces discontinuities in saliency detection. Low-quality samples further distort model predictions, leading to saliency bias. To address these challenges, we propose Spike-navigated Optimal TrAnsport Saliency Region Detection (SOTA), a framework that leverages the strengths of spike cameras while mitigating biases in both spatial and temporal dimensions. Our method introduces Spike-based Micro-debias (SM) to capture subtle frame-to-frame variations and preserve critical details, even under minimal scene or lighting changes. Additionally, Spike-based Global-debias (SG) refines predictions by reducing inconsistencies across diverse conditions. Extensive experiments on real and synthetic datasets demonstrate that SOTA outperforms existing methods by eliminating composite noise bias. Our code and dataset will be released at https://github.com/lwxfight/sota."
      },
      {
        "id": "oai:arXiv.org:2505.00398v1",
        "title": "Safety in the Face of Adversity: Achieving Zero Constraint Violation in Online Learning with Slowly Changing Constraints",
        "link": "https://arxiv.org/abs/2505.00398",
        "author": "Bassel Hamoud, Ilnura Usmanova, Kfir Y. Levy",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00398v1 Announce Type: new \nAbstract: We present the first theoretical guarantees for zero constraint violation in Online Convex Optimization (OCO) across all rounds, addressing dynamic constraint changes. Unlike existing approaches in constrained OCO, which allow for occasional safety breaches, we provide the first approach for maintaining strict safety under the assumption of gradually evolving constraints, namely the constraints change at most by a small amount between consecutive rounds. This is achieved through a primal-dual approach and Online Gradient Ascent in the dual space. We show that employing a dichotomous learning rate enables ensuring both safety, via zero constraint violation, and sublinear regret. Our framework marks a departure from previous work by providing the first provable guarantees for maintaining absolute safety in the face of changing constraints in OCO."
      },
      {
        "id": "oai:arXiv.org:2505.00402v1",
        "title": "DeepSTA: A Spatial-Temporal Attention Network for Logistics Delivery Timely Rate Prediction in Anomaly Conditions",
        "link": "https://arxiv.org/abs/2505.00402",
        "author": "Jinhui Yi, Huan Yan, Haotian Wang, Jian Yuan, Yong Li",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00402v1 Announce Type: new \nAbstract: Prediction of couriers' delivery timely rates in advance is essential to the logistics industry, enabling companies to take preemptive measures to ensure the normal operation of delivery services. This becomes even more critical during anomaly conditions like the epidemic outbreak, during which couriers' delivery timely rate will decline markedly and fluctuates significantly. Existing studies pay less attention to the logistics scenario. Moreover, many works focusing on prediction tasks in anomaly scenarios fail to explicitly model abnormal events, e.g., treating external factors equally with other features, resulting in great information loss. Further, since some anomalous events occur infrequently, traditional data-driven methods perform poorly in these scenarios. To deal with them, we propose a deep spatial-temporal attention model, named DeepSTA. To be specific, to avoid information loss, we design an anomaly spatio-temporal learning module that employs a recurrent neural network to model incident information. Additionally, we utilize Node2vec to model correlations between road districts, and adopt graph neural networks and long short-term memory to capture the spatial-temporal dependencies of couriers. To tackle the issue of insufficient training data in abnormal circumstances, we propose an anomaly pattern attention module that adopts a memory network for couriers' anomaly feature patterns storage via attention mechanisms. The experiments on real-world logistics datasets during the COVID-19 outbreak in 2022 show the model outperforms the best baselines by 12.11% in MAE and 13.71% in MSE, demonstrating its superior performance over multiple competitive baselines."
      },
      {
        "id": "oai:arXiv.org:2505.00410v1",
        "title": "Machine Learning Meets Transparency in Osteoporosis Risk Assessment: A Comparative Study of ML and Explainability Analysis",
        "link": "https://arxiv.org/abs/2505.00410",
        "author": "Farhana Elias, Md Shihab Reza, Muhammad Zawad Mahmud, Samiha Islam",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00410v1 Announce Type: new \nAbstract: The present research tackles the difficulty of predicting osteoporosis risk via machine learning (ML) approaches, emphasizing the use of explainable artificial intelligence (XAI) to improve model transparency. Osteoporosis is a significant public health concern, sometimes remaining untreated owing to its asymptomatic characteristics, and early identification is essential to avert fractures. The research assesses six machine learning classifiers: Random Forest, Logistic Regression, XGBoost, AdaBoost, LightGBM, and Gradient Boosting and utilizes a dataset based on clinical, demographic, and lifestyle variables. The models are refined using GridSearchCV to calibrate hyperparameters, with the objective of enhancing predictive efficacy. XGBoost had the greatest accuracy (91%) among the evaluated models, surpassing others in precision (0.92), recall (0.91), and F1-score (0.90). The research further integrates XAI approaches, such as SHAP, LIME, and Permutation Feature Importance, to elucidate the decision-making process of the optimal model. The study indicates that age is the primary determinant in forecasting osteoporosis risk, followed by hormonal alterations and familial history. These results corroborate clinical knowledge and affirm the models' therapeutic significance. The research underscores the significance of explainability in machine learning models for healthcare applications, guaranteeing that physicians can rely on the system's predictions. The report ultimately proposes directions for further research, such as validation across varied populations and the integration of supplementary biomarkers for enhanced predictive accuracy."
      },
      {
        "id": "oai:arXiv.org:2505.00415v1",
        "title": "CICADA: Cross-Domain Interpretable Coding for Anomaly Detection and Adaptation in Multivariate Time Series",
        "link": "https://arxiv.org/abs/2505.00415",
        "author": "Tian Lan, Yifei Gao, Yimeng Lu, Chen Zhang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00415v1 Announce Type: new \nAbstract: Unsupervised Time series anomaly detection plays a crucial role in applications across industries. However, existing methods face significant challenges due to data distributional shifts across different domains, which are exacerbated by the non-stationarity of time series over time. Existing models fail to generalize under multiple heterogeneous source domains and emerging unseen new target domains. To fill the research gap, we introduce CICADA (Cross-domain Interpretable Coding for Anomaly Detection and Adaptation), with four key innovations: (1) a mixture of experts (MOE) framework that captures domain-agnostic anomaly features with high flexibility and interpretability; (2) a novel selective meta-learning mechanism to prevent negative transfer between dissimilar domains, (3) an adaptive expansion algorithm for emerging heterogeneous domain expansion, and (4) a hierarchical attention structure that quantifies expert contributions during fusion to enhance interpretability further.Extensive experiments on synthetic and real-world industrial datasets demonstrate that CICADA outperforms state-of-the-art methods in both cross-domain detection performance and interpretability."
      },
      {
        "id": "oai:arXiv.org:2505.00421v1",
        "title": "Real-Time Animatable 2DGS-Avatars with Detail Enhancement from Monocular Videos",
        "link": "https://arxiv.org/abs/2505.00421",
        "author": "Xia Yuan, Hai Yuan, Wenyi Ge, Ying Fu, Xi Wu, Guanyu Xing",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00421v1 Announce Type: new \nAbstract: High-quality, animatable 3D human avatar reconstruction from monocular videos offers significant potential for reducing reliance on complex hardware, making it highly practical for applications in game development, augmented reality, and social media. However, existing methods still face substantial challenges in capturing fine geometric details and maintaining animation stability, particularly under dynamic or complex poses. To address these issues, we propose a novel real-time framework for animatable human avatar reconstruction based on 2D Gaussian Splatting (2DGS). By leveraging 2DGS and global SMPL pose parameters, our framework not only aligns positional and rotational discrepancies but also enables robust and natural pose-driven animation of the reconstructed avatars. Furthermore, we introduce a Rotation Compensation Network (RCN) that learns rotation residuals by integrating local geometric features with global pose parameters. This network significantly improves the handling of non-rigid deformations and ensures smooth, artifact-free pose transitions during animation. Experimental results demonstrate that our method successfully reconstructs realistic and highly animatable human avatars from monocular videos, effectively preserving fine-grained details while ensuring stable and natural pose variation. Our approach surpasses current state-of-the-art methods in both reconstruction quality and animation robustness on public benchmarks."
      },
      {
        "id": "oai:arXiv.org:2505.00422v1",
        "title": "Toward Automated Regulatory Decision-Making: Trustworthy Medical Device Risk Classification with Multimodal Transformers and Self-Training",
        "link": "https://arxiv.org/abs/2505.00422",
        "author": "Yu Han, Aaron Ceross, Jeroen H. M. Bergmann",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00422v1 Announce Type: new \nAbstract: Accurate classification of medical device risk levels is essential for regulatory oversight and clinical safety. We present a Transformer-based multimodal framework that integrates textual descriptions and visual information to predict device regulatory classification. The model incorporates a cross-attention mechanism to capture intermodal dependencies and employs a self-training strategy for improved generalization under limited supervision. Experiments on a real-world regulatory dataset demonstrate that our approach achieves up to 90.4% accuracy and 97.9% AUROC, significantly outperforming text-only (77.2%) and image-only (54.8%) baselines. Compared to standard multimodal fusion, the self-training mechanism improved SVM performance by 3.3 percentage points in accuracy (from 87.1% to 90.4%) and 1.4 points in macro-F1, suggesting that pseudo-labeling can effectively enhance generalization under limited supervision. Ablation studies further confirm the complementary benefits of both cross-modal attention and self-training."
      },
      {
        "id": "oai:arXiv.org:2505.00426v1",
        "title": "Leveraging Pretrained Diffusion Models for Zero-Shot Part Assembly",
        "link": "https://arxiv.org/abs/2505.00426",
        "author": "Ruiyuan Zhang, Qi Wang, Jiaxiang Liu, Yu Zhang, Yuchi Huo, Chao Wu",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00426v1 Announce Type: new \nAbstract: 3D part assembly aims to understand part relationships and predict their 6-DoF poses to construct realistic 3D shapes, addressing the growing demand for autonomous assembly, which is crucial for robots. Existing methods mainly estimate the transformation of each part by training neural networks under supervision, which requires a substantial quantity of manually labeled data. However, the high cost of data collection and the immense variability of real-world shapes and parts make traditional methods impractical for large-scale applications. In this paper, we propose first a zero-shot part assembly method that utilizes pre-trained point cloud diffusion models as discriminators in the assembly process, guiding the manipulation of parts to form realistic shapes. Specifically, we theoretically demonstrate that utilizing a diffusion model for zero-shot part assembly can be transformed into an Iterative Closest Point (ICP) process. Then, we propose a novel pushing-away strategy to address the overlap parts, thereby further enhancing the robustness of the method. To verify our work, we conduct extensive experiments and quantitative comparisons to several strong baseline methods, demonstrating the effectiveness of the proposed approach, which even surpasses the supervised learning method. The code has been released on https://github.com/Ruiyuan-Zhang/Zero-Shot-Assembly."
      },
      {
        "id": "oai:arXiv.org:2505.00439v1",
        "title": "Per-Domain Generalizing Policies: On Validation Instances and Scaling Behavior",
        "link": "https://arxiv.org/abs/2505.00439",
        "author": "Timo P. Gros, Nicola J. M\\\"uller, Daniel Fiser, Isabel Valera, Verena Wolf, J\\\"org Hoffmann",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00439v1 Announce Type: new \nAbstract: Recent work has shown that successful per-domain generalizing action policies can be learned. Scaling behavior, from small training instances to large test instances, is the key objective; and the use of validation instances larger than training instances is one key to achieve it. Prior work has used fixed validation sets. Here, we introduce a method generating the validation set dynamically, on the fly, increasing instance size so long as informative and feasible.We also introduce refined methodology for evaluating scaling behavior, generating test instances systematically to guarantee a given confidence in coverage performance for each instance size. In experiments, dynamic validation improves scaling behavior of GNN policies in all 9 domains used."
      },
      {
        "id": "oai:arXiv.org:2505.00452v1",
        "title": "ClearLines - Camera Calibration from Straight Lines",
        "link": "https://arxiv.org/abs/2505.00452",
        "author": "Gregory Schroeder, Mohamed Sabry, Cristina Olaverri-Monreal",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00452v1 Announce Type: new \nAbstract: The problem of calibration from straight lines is fundamental in geometric computer vision, with well-established theoretical foundations. However, its practical applicability remains limited, particularly in real-world outdoor scenarios. These environments pose significant challenges due to diverse and cluttered scenes, interrupted reprojections of straight 3D lines, and varying lighting conditions, making the task notoriously difficult. Furthermore, the field lacks a dedicated dataset encouraging the development of respective detection algorithms. In this study, we present a small dataset named \"ClearLines\", and by detailing its creation process, provide practical insights that can serve as a guide for developing and refining straight 3D line detection algorithms."
      },
      {
        "id": "oai:arXiv.org:2505.00466v1",
        "title": "A Generalised Framework for Property-Driven Machine Learning",
        "link": "https://arxiv.org/abs/2505.00466",
        "author": "Thomas Flinkow, Marco Casadio, Colin Kessler, Rosemary Monahan, Ekaterina Komendantskaya",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00466v1 Announce Type: new \nAbstract: Neural networks have been shown to frequently fail to satisfy critical safety and correctness properties after training, highlighting the pressing need for training methods that incorporate such properties directly. While adversarial training can be used to improve robustness to small perturbations within $\\epsilon$-cubes, domains other than computer vision -- such as control systems and natural language processing -- may require more flexible input region specifications via generalised hyper-rectangles. Meanwhile, differentiable logics offer a way to encode arbitrary logical constraints as additional loss terms that guide the learning process towards satisfying these constraints. In this paper, we investigate how these two complementary approaches can be unified within a single framework for property-driven machine learning. We show that well-known properties from the literature are subcases of this general approach, and we demonstrate its practical effectiveness on a case study involving a neural network controller for a drone system. Our framework is publicly available at https://github.com/tflinkow/property-driven-ml."
      },
      {
        "id": "oai:arXiv.org:2505.00467v1",
        "title": "Red Teaming Large Language Models for Healthcare",
        "link": "https://arxiv.org/abs/2505.00467",
        "author": "Vahid Balazadeh, Michael Cooper, David Pellow, Atousa Assadi, Jennifer Bell, Jim Fackler, Gabriel Funingana, Spencer Gable-Cook, Anirudh Gangadhar, Abhishek Jaiswal, Sumanth Kaja, Christopher Khoury, Randy Lin, Kaden McKeen, Sara Naimimohasses, Khashayar Namdar, Aviraj Newatia, Allan Pang, Anshul Pattoo, Sameer Peesapati, Diana Prepelita, Bogdana Rakova, Saba Sadatamin, Rafael Schulman, Ajay Shah, Syed Azhar Shah, Syed Ahmar Shah, Babak Taati, Balagopal Unnikrishnan, Stephanie Williams, Rahul G Krishnan",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00467v1 Announce Type: new \nAbstract: We present the design process and findings of the pre-conference workshop at the Machine Learning for Healthcare Conference (2024) entitled Red Teaming Large Language Models for Healthcare, which took place on August 15, 2024. Conference participants, comprising a mix of computational and clinical expertise, attempted to discover vulnerabilities -- realistic clinical prompts for which a large language model (LLM) outputs a response that could cause clinical harm. Red-teaming with clinicians enables the identification of LLM vulnerabilities that may not be recognised by LLM developers lacking clinical expertise. We report the vulnerabilities found, categorise them, and present the results of a replication study assessing the vulnerabilities across all LLMs provided."
      },
      {
        "id": "oai:arXiv.org:2505.00473v1",
        "title": "Interpretable Spatial-Temporal Fusion Transformers: Multi-Output Prediction for Parametric Dynamical Systems with Time-Varying Inputs",
        "link": "https://arxiv.org/abs/2505.00473",
        "author": "Shuwen Sun, Lihong Feng, Peter Benner",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00473v1 Announce Type: new \nAbstract: We explore the promising performance of a transformer model in predicting outputs of parametric dynamical systems with external time-varying input signals. The outputs of such systems vary not only with physical parameters but also with external time-varying input signals. Accurately catching the dynamics of such systems is challenging. We have adapted and extended an existing transformer model for single output prediction to a multiple-output transformer that is able to predict multiple output responses of these systems. The multiple-output transformer generalizes the interpretability of the original transformer. The generalized interpretable attention weight matrix explores not only the temporal correlations in the sequence, but also the interactions between the multiple outputs, providing explanation for the spatial correlation in the output domain. This multiple-output transformer accurately predicts the sequence of multiple outputs, regardless of the nonlinearity of the system and the dimensionality of the parameter space."
      },
      {
        "id": "oai:arXiv.org:2505.00479v1",
        "title": "Computational Identification of Regulatory Statements in EU Legislation",
        "link": "https://arxiv.org/abs/2505.00479",
        "author": "Gijs Jan Brandsma, Jens Blom-Hansen, Christiaan Meijer, Kody Moodley",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00479v1 Announce Type: new \nAbstract: Identifying regulatory statements in legislation is useful for developing metrics to measure the regulatory density and strictness of legislation. A computational method is valuable for scaling the identification of such statements from a growing body of EU legislation, constituting approximately 180,000 published legal acts between 1952 and 2023. Past work on extraction of these statements varies in the permissiveness of their definitions for what constitutes a regulatory statement. In this work, we provide a specific definition for our purposes based on the institutional grammar tool. We develop and compare two contrasting approaches for automatically identifying such statements in EU legislation, one based on dependency parsing, and the other on a transformer-based machine learning model. We found both approaches performed similarly well with accuracies of 80% and 84% respectively and a K alpha of 0.58. The high accuracies and not exceedingly high agreement suggests potential for combining strengths of both approaches."
      },
      {
        "id": "oai:arXiv.org:2505.00482v1",
        "title": "JointDiT: Enhancing RGB-Depth Joint Modeling with Diffusion Transformers",
        "link": "https://arxiv.org/abs/2505.00482",
        "author": "Kwon Byung-Ki, Qi Dai, Lee Hyoseok, Chong Luo, Tae-Hyun Oh",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00482v1 Announce Type: new \nAbstract: We present JointDiT, a diffusion transformer that models the joint distribution of RGB and depth. By leveraging the architectural benefit and outstanding image prior of the state-of-the-art diffusion transformer, JointDiT not only generates high-fidelity images but also produces geometrically plausible and accurate depth maps. This solid joint distribution modeling is achieved through two simple yet effective techniques that we propose, i.e., adaptive scheduling weights, which depend on the noise levels of each modality, and the unbalanced timestep sampling strategy. With these techniques, we train our model across all noise levels for each modality, enabling JointDiT to naturally handle various combinatorial generation tasks, including joint generation, depth estimation, and depth-conditioned image generation by simply controlling the timestep of each branch. JointDiT demonstrates outstanding joint generation performance. Furthermore, it achieves comparable results in depth estimation and depth-conditioned image generation, suggesting that joint distribution modeling can serve as a replaceable alternative to conditional generation. The project page is available at https://byungki-k.github.io/JointDiT/."
      },
      {
        "id": "oai:arXiv.org:2505.00495v1",
        "title": "Enhancing Tropical Cyclone Path Forecasting with an Improved Transformer Network",
        "link": "https://arxiv.org/abs/2505.00495",
        "author": "Nguyen Van Thanh, Nguyen Dang Huynh, Nguyen Ngoc Tan, Nguyen Thai Minh, Nguyen Nam Hoang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00495v1 Announce Type: new \nAbstract: A storm is a type of extreme weather. Therefore, forecasting the path of a storm is extremely important for protecting human life and property. However, storm forecasting is very challenging because storm trajectories frequently change. In this study, we propose an improved deep learning method using a Transformer network to predict the movement trajectory of a storm over the next 6 hours. The storm data used to train the model was obtained from the National Oceanic and Atmospheric Administration (NOAA) [1]. Simulation results show that the proposed method is more accurate than traditional methods. Moreover, the proposed method is faster and more cost-effective"
      },
      {
        "id": "oai:arXiv.org:2505.00497v1",
        "title": "KeySync: A Robust Approach for Leakage-free Lip Synchronization in High Resolution",
        "link": "https://arxiv.org/abs/2505.00497",
        "author": "Antoni Bigata, Rodrigo Mira, Stella Bounareli, Micha{\\l} Stypu{\\l}kowski, Konstantinos Vougioukas, Stavros Petridis, Maja Pantic",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00497v1 Announce Type: new \nAbstract: Lip synchronization, known as the task of aligning lip movements in an existing video with new input audio, is typically framed as a simpler variant of audio-driven facial animation. However, as well as suffering from the usual issues in talking head generation (e.g., temporal consistency), lip synchronization presents significant new challenges such as expression leakage from the input video and facial occlusions, which can severely impact real-world applications like automated dubbing, but are often neglected in existing works. To address these shortcomings, we present KeySync, a two-stage framework that succeeds in solving the issue of temporal consistency, while also incorporating solutions for leakage and occlusions using a carefully designed masking strategy. We show that KeySync achieves state-of-the-art results in lip reconstruction and cross-synchronization, improving visual quality and reducing expression leakage according to LipLeak, our novel leakage metric. Furthermore, we demonstrate the effectiveness of our new masking approach in handling occlusions and validate our architectural choices through several ablation studies. Code and model weights can be found at https://antonibigata.github.io/KeySync."
      },
      {
        "id": "oai:arXiv.org:2505.00502v1",
        "title": "Towards Scalable Human-aligned Benchmark for Text-guided Image Editing",
        "link": "https://arxiv.org/abs/2505.00502",
        "author": "Suho Ryu, Kihyun Kim, Eugene Baek, Dongsoo Shin, Joonseok Lee",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00502v1 Announce Type: new \nAbstract: A variety of text-guided image editing models have been proposed recently. However, there is no widely-accepted standard evaluation method mainly due to the subjective nature of the task, letting researchers rely on manual user study. To address this, we introduce a novel Human-Aligned benchmark for Text-guided Image Editing (HATIE). Providing a large-scale benchmark set covering a wide range of editing tasks, it allows reliable evaluation, not limited to specific easy-to-evaluate cases. Also, HATIE provides a fully-automated and omnidirectional evaluation pipeline. Particularly, we combine multiple scores measuring various aspects of editing so as to align with human perception. We empirically verify that the evaluation of HATIE is indeed human-aligned in various aspects, and provide benchmark results on several state-of-the-art models to provide deeper insights on their performance."
      },
      {
        "id": "oai:arXiv.org:2505.00503v1",
        "title": "Variational OOD State Correction for Offline Reinforcement Learning",
        "link": "https://arxiv.org/abs/2505.00503",
        "author": "Ke Jiang, Wen Jiang, Xiaoyang Tan",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00503v1 Announce Type: new \nAbstract: The performance of Offline reinforcement learning is significantly impacted by the issue of state distributional shift, and out-of-distribution (OOD) state correction is a popular approach to address this problem. In this paper, we propose a novel method named Density-Aware Safety Perception (DASP) for OOD state correction. Specifically, our method encourages the agent to prioritize actions that lead to outcomes with higher data density, thereby promoting its operation within or the return to in-distribution (safe) regions. To achieve this, we optimize the objective within a variational framework that concurrently considers both the potential outcomes of decision-making and their density, thus providing crucial contextual information for safe decision-making. Finally, we validate the effectiveness and feasibility of our proposed method through extensive experimental evaluations on the offline MuJoCo and AntMaze suites."
      },
      {
        "id": "oai:arXiv.org:2505.00506v1",
        "title": "HalluMix: A Task-Agnostic, Multi-Domain Benchmark for Real-World Hallucination Detection",
        "link": "https://arxiv.org/abs/2505.00506",
        "author": "Deanna Emery, Michael Goitia, Freddie Vargus, Iulia Neagu",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00506v1 Announce Type: new \nAbstract: As large language models (LLMs) are increasingly deployed in high-stakes domains, detecting hallucinated content$\\unicode{x2013}$text that is not grounded in supporting evidence$\\unicode{x2013}$has become a critical challenge. Existing benchmarks for hallucination detection are often synthetically generated, narrowly focused on extractive question answering, and fail to capture the complexity of real-world scenarios involving multi-document contexts and full-sentence outputs. We introduce the HalluMix Benchmark, a diverse, task-agnostic dataset that includes examples from a range of domains and formats. Using this benchmark, we evaluate seven hallucination detection systems$\\unicode{x2013}$both open and closed source$\\unicode{x2013}$highlighting differences in performance across tasks, document lengths, and input representations. Our analysis highlights substantial performance disparities between short and long contexts, with critical implications for real-world Retrieval Augmented Generation (RAG) implementations. Quotient Detections achieves the best overall performance, with an accuracy of 0.82 and an F1 score of 0.84."
      },
      {
        "id": "oai:arXiv.org:2505.00507v1",
        "title": "HeAL3D: Heuristical-enhanced Active Learning for 3D Object Detection",
        "link": "https://arxiv.org/abs/2505.00507",
        "author": "Esteban Rivera, Surya Prabhakaran, Markus Lienkamp",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00507v1 Announce Type: new \nAbstract: Active Learning has proved to be a relevant approach to perform sample selection for training models for Autonomous Driving. Particularly, previous works on active learning for 3D object detection have shown that selection of samples in uncontrolled scenarios is challenging. Furthermore, current approaches focus exclusively on the theoretical aspects of the sample selection problem but neglect the practical insights that can be obtained from the extensive literature and application of 3D detection models. In this paper, we introduce HeAL (Heuristical-enhanced Active Learning for 3D Object Detection) which integrates those heuristical features together with Localization and Classification to deliver the most contributing samples to the model's training. In contrast to previous works, our approach integrates heuristical features such as object distance and point-quantity to estimate the uncertainty, which enhance the usefulness of selected samples to train detection models. Our quantitative evaluation on KITTI shows that HeAL presents competitive mAP with respect to the State-of-the-Art, and achieves the same mAP as the full-supervised baseline with only 24% of the samples."
      },
      {
        "id": "oai:arXiv.org:2505.00509v1",
        "title": "Self-Ablating Transformers: More Interpretability, Less Sparsity",
        "link": "https://arxiv.org/abs/2505.00509",
        "author": "Jeremias Ferrao, Luhan Mikaelson, Keenan Pepper, Natalia Perez-Campanero Antolin",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00509v1 Announce Type: new \nAbstract: A growing intuition in machine learning suggests a link between sparsity and interpretability. We introduce a novel self-ablation mechanism to investigate this connection ante-hoc in the context of language transformers. Our approach dynamically enforces a k-winner-takes-all constraint, forcing the model to demonstrate selective activation across neuron and attention units. Unlike post-hoc methods that analyze already-trained models, our approach integrates interpretability directly into model training, promoting feature localization from inception. Training small models on the TinyStories dataset and employing interpretability tests, we find that self-ablation leads to more localized circuits, concentrated feature representations, and increased neuron specialization without compromising language modelling performance. Surprisingly, our method also decreased overall sparsity, indicating that self-ablation promotes specialization rather than widespread inactivity. This reveals a complex interplay between sparsity and interpretability, where decreased global sparsity can coexist with increased local specialization, leading to enhanced interpretability. To facilitate reproducibility, we make our code available at https://github.com/keenanpepper/self-ablating-transformers."
      },
      {
        "id": "oai:arXiv.org:2505.00511v1",
        "title": "Inconsistency-based Active Learning for LiDAR Object Detection",
        "link": "https://arxiv.org/abs/2505.00511",
        "author": "Esteban Rivera, Loic Stratil, Markus Lienkamp",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00511v1 Announce Type: new \nAbstract: Deep learning models for object detection in autonomous driving have recently achieved impressive performance gains and are already being deployed in vehicles worldwide. However, current models require increasingly large datasets for training. Acquiring and labeling such data is costly, necessitating the development of new strategies to optimize this process. Active learning is a promising approach that has been extensively researched in the image domain. In our work, we extend this concept to the LiDAR domain by developing several inconsistency-based sample selection strategies and evaluate their effectiveness in various settings. Our results show that using a naive inconsistency approach based on the number of detected boxes, we achieve the same mAP as the random sampling strategy with 50% of the labeled data."
      },
      {
        "id": "oai:arXiv.org:2505.00512v1",
        "title": "InterLoc: LiDAR-based Intersection Localization using Road Segmentation with Automated Evaluation Method",
        "link": "https://arxiv.org/abs/2505.00512",
        "author": "Nguyen Hoang Khoi Tran, Julie Stephany Berrio, Mao Shan, Zhenxing Ming, Stewart Worrall",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00512v1 Announce Type: new \nAbstract: Intersections are geometric and functional key points in every road network. They offer strong landmarks to correct GNSS dropouts and anchor new sensor data in up-to-date maps. Despite that importance, intersection detectors either ignore the rich semantic information already computed onboard or depend on scarce, hand-labeled intersection datasets. To close that gap, this paper presents a LiDAR-based method for intersection detection that (i) fuses semantic road segmentation with vehicle localization to detect intersection candidates in a bird's eye view (BEV) representation and (ii) refines those candidates by analyzing branch topology with a least squares formulation. To evaluate our method, we introduce an automated benchmarking pipeline that pairs detections with OpenStreetMap (OSM) intersection nodes using precise GNSS/INS ground-truth poses. Tested on eight SemanticKITTI sequences, the approach achieves a mean localization error of 1.9 m, 89% precision, and 77% recall at a 5 m tolerance, outperforming the latest learning-based baseline. Moreover, the method is robust to segmentation errors higher than those of the benchmark model, demonstrating its applicability in the real world."
      },
      {
        "id": "oai:arXiv.org:2505.00530v1",
        "title": "Leveraging Partial SMILES Validation Scheme for Enhanced Drug Design in Reinforcement Learning Frameworks",
        "link": "https://arxiv.org/abs/2505.00530",
        "author": "Xinyu Wang, Jinbo Bi, Minghu Song",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00530v1 Announce Type: new \nAbstract: SMILES-based molecule generation has emerged as a powerful approach in drug discovery. Deep reinforcement learning (RL) using large language model (LLM) has been incorporated into the molecule generation process to achieve high matching score in term of likelihood of desired molecule candidates. However, a critical challenge in this approach is catastrophic forgetting during the RL phase, where knowledge such as molecule validity, which often exceeds 99\\% during pretraining, significantly deteriorates. Current RL algorithms applied in drug discovery, such as REINVENT, use prior models as anchors to retian pretraining knowledge, but these methods lack robust exploration mechanisms. To address these issues, we propose Partial SMILES Validation-PPO (PSV-PPO), a novel RL algorithm that incorporates real-time partial SMILES validation to prevent catastrophic forgetting while encouraging exploration. Unlike traditional RL approaches that validate molecule structures only after generating entire sequences, PSV-PPO performs stepwise validation at each auto-regressive step, evaluating not only the selected token candidate but also all potential branches stemming from the prior partial sequence. This enables early detection of invalid partial SMILES across all potential paths. As a result, PSV-PPO maintains high validity rates even during aggressive exploration of the vast chemical space. Our experiments on the PMO and GuacaMol benchmark datasets demonstrate that PSV-PPO significantly reduces the number of invalid generated structures while maintaining competitive exploration and optimization performance. While our work primarily focuses on maintaining validity, the framework of PSV-PPO can be extended in future research to incorporate additional forms of valuable domain knowledge, further enhancing reinforcement learning applications in drug discovery."
      },
      {
        "id": "oai:arXiv.org:2505.00533v1",
        "title": "Test-time Correlation Alignment",
        "link": "https://arxiv.org/abs/2505.00533",
        "author": "Linjing You, Jiabao Lu, Xiayuan Huang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00533v1 Announce Type: new \nAbstract: Deep neural networks often experience performance drops due to distribution shifts between training and test data. Although domain adaptation offers a solution, privacy concerns restrict access to training data in many real-world scenarios. This restriction has spurred interest in Test-Time Adaptation (TTA), which adapts models using only unlabeled test data. However, current TTA methods still face practical challenges: (1) a primary focus on instance-wise alignment, overlooking CORrelation ALignment (CORAL) due to missing source correlations; (2) complex backpropagation operations for model updating, resulting in overhead computation and (3) domain forgetting.\n  To address these challenges, we provide a theoretical analysis to investigate the feasibility of Test-time Correlation Alignment (TCA), demonstrating that correlation alignment between high-certainty instances and test instances can enhance test performances with a theoretical guarantee. Based on this, we propose two simple yet effective algorithms: LinearTCA and LinearTCA+. LinearTCA applies a simple linear transformation to achieve both instance and correlation alignment without additional model updates, while LinearTCA+ serves as a plug-and-play module that can easily boost existing TTA methods. Extensive experiments validate our theoretical insights and show that TCA methods significantly outperforms baselines across various tasks, benchmarks and backbones. Notably, LinearTCA improves adaptation accuracy by 5.88% on OfficeHome dataset, while using only 4% maximum GPU memory usage and 0.6% computation time compared to the best baseline TTA method."
      },
      {
        "id": "oai:arXiv.org:2505.00534v1",
        "title": "A Robust Deep Networks based Multi-Object MultiCamera Tracking System for City Scale Traffic",
        "link": "https://arxiv.org/abs/2505.00534",
        "author": "Muhammad Imran Zaman, Usama Ijaz Bajwa, Gulshan Saleem, Rana Hammad Raza",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00534v1 Announce Type: new \nAbstract: Vision sensors are becoming more important in Intelligent Transportation Systems (ITS) for traffic monitoring, management, and optimization as the number of network cameras continues to rise. However, manual object tracking and matching across multiple non-overlapping cameras pose significant challenges in city-scale urban traffic scenarios. These challenges include handling diverse vehicle attributes, occlusions, illumination variations, shadows, and varying video resolutions. To address these issues, we propose an efficient and cost-effective deep learning-based framework for Multi-Object Multi-Camera Tracking (MO-MCT). The proposed framework utilizes Mask R-CNN for object detection and employs Non-Maximum Suppression (NMS) to select target objects from overlapping detections. Transfer learning is employed for re-identification, enabling the association and generation of vehicle tracklets across multiple cameras. Moreover, we leverage appropriate loss functions and distance measures to handle occlusion, illumination, and shadow challenges. The final solution identification module performs feature extraction using ResNet-152 coupled with Deep SORT based vehicle tracking. The proposed framework is evaluated on the 5th AI City Challenge dataset (Track 3), comprising 46 camera feeds. Among these 46 camera streams, 40 are used for model training and validation, while the remaining six are utilized for model testing. The proposed framework achieves competitive performance with an IDF1 score of 0.8289, and precision and recall scores of 0.9026 and 0.8527 respectively, demonstrating its effectiveness in robust and accurate vehicle tracking."
      },
      {
        "id": "oai:arXiv.org:2505.00541v1",
        "title": "KnowEEG: Explainable Knowledge Driven EEG Classification",
        "link": "https://arxiv.org/abs/2505.00541",
        "author": "Amarpal Sahota, Navid Mohammadi Foumani, Raul Santos-Rodriguez, Zahraa S. Abdallah",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00541v1 Announce Type: new \nAbstract: Electroencephalography (EEG) is a method of recording brain activity that shows significant promise in applications ranging from disease classification to emotion detection and brain-computer interfaces. Recent advances in deep learning have improved EEG classification performance yet model explainability remains an issue. To address this key limitation of explainability we introduce KnowEEG; a novel explainable machine learning approach for EEG classification. KnowEEG extracts a comprehensive set of per-electrode features, filters them using statistical tests, and integrates between-electrode connectivity statistics. These features are then input to our modified Random Forest model (Fusion Forest) that balances per electrode statistics with between electrode connectivity features in growing the trees of the forest. By incorporating knowledge from both the generalized time-series and EEG-specific domains, KnowEEG achieves performance comparable to or exceeding state-of-the-art deep learning models across five different classification tasks: emotion detection, mental workload classification, eyes open/closed detection, abnormal EEG classification, and event detection. In addition to high performance, KnowEEG provides inherent explainability through feature importance scores for understandable features. We demonstrate by example on the eyes closed/open classification task that this explainability can be used to discover knowledge about the classes. This discovered knowledge for eyes open/closed classification was proven to be correct by current neuroscience literature. Therefore, the impact of KnowEEG will be significant for domains where EEG explainability is critical such as healthcare."
      },
      {
        "id": "oai:arXiv.org:2505.00546v1",
        "title": "Directly Forecasting Belief for Reinforcement Learning with Delays",
        "link": "https://arxiv.org/abs/2505.00546",
        "author": "Qingyuan Wu, Yuhui Wang, Simon Sinong Zhan, Yixuan Wang, Chung-Wei Lin, Chen Lv, Qi Zhu, J\\\"urgen Schmidhuber, Chao Huang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00546v1 Announce Type: new \nAbstract: Reinforcement learning (RL) with delays is challenging as sensory perceptions lag behind the actual events: the RL agent needs to estimate the real state of its environment based on past observations. State-of-the-art (SOTA) methods typically employ recursive, step-by-step forecasting of states. This can cause the accumulation of compounding errors. To tackle this problem, our novel belief estimation method, named Directly Forecasting Belief Transformer (DFBT), directly forecasts states from observations without incrementally estimating intermediate states step-by-step. We theoretically demonstrate that DFBT greatly reduces compounding errors of existing recursively forecasting methods, yielding stronger performance guarantees. In experiments with D4RL offline datasets, DFBT reduces compounding errors with remarkable prediction accuracy. DFBT's capability to forecast state sequences also facilitates multi-step bootstrapping, thus greatly improving learning efficiency. On the MuJoCo benchmark, our DFBT-based method substantially outperforms SOTA baselines."
      },
      {
        "id": "oai:arXiv.org:2505.00551v1",
        "title": "100 Days After DeepSeek-R1: A Survey on Replication Studies and More Directions for Reasoning Language Models",
        "link": "https://arxiv.org/abs/2505.00551",
        "author": "Chong Zhang, Yue Deng, Xiang Lin, Bin Wang, Dianwen Ng, Hai Ye, Xingxuan Li, Yao Xiao, Zhanfeng Mo, Qi Zhang, Lidong Bing",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00551v1 Announce Type: new \nAbstract: The recent development of reasoning language models (RLMs) represents a novel evolution in large language models. In particular, the recent release of DeepSeek-R1 has generated widespread social impact and sparked enthusiasm in the research community for exploring the explicit reasoning paradigm of language models. However, the implementation details of the released models have not been fully open-sourced by DeepSeek, including DeepSeek-R1-Zero, DeepSeek-R1, and the distilled small models. As a result, many replication studies have emerged aiming to reproduce the strong performance achieved by DeepSeek-R1, reaching comparable performance through similar training procedures and fully open-source data resources. These works have investigated feasible strategies for supervised fine-tuning (SFT) and reinforcement learning from verifiable rewards (RLVR), focusing on data preparation and method design, yielding various valuable insights. In this report, we provide a summary of recent replication studies to inspire future research. We primarily focus on SFT and RLVR as two main directions, introducing the details for data construction, method design and training procedure of current replication studies. Moreover, we conclude key findings from the implementation details and experimental results reported by these studies, anticipating to inspire future research. We also discuss additional techniques of enhancing RLMs, highlighting the potential of expanding the application scope of these models, and discussing the challenges in development. By this survey, we aim to help researchers and developers of RLMs stay updated with the latest advancements, and seek to inspire new ideas to further enhance RLMs."
      },
      {
        "id": "oai:arXiv.org:2505.00557v1",
        "title": "Triggering Hallucinations in LLMs: A Quantitative Study of Prompt-Induced Hallucination in Large Language Models",
        "link": "https://arxiv.org/abs/2505.00557",
        "author": "Makoto Sato",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00557v1 Announce Type: new \nAbstract: Hallucinations in large language models (LLMs) present a growing challenge across real-world applications, from healthcare to law, where factual reliability is essential. Despite advances in alignment and instruction tuning, LLMs can still generate outputs that are fluent yet fundamentally untrue. Understanding the cognitive dynamics that underlie these hallucinations remains an open problem. In this study, we propose a prompt-based framework to systematically trigger and quantify hallucination: a Hallucination-Inducing Prompt (HIP), which synthetically fuses semantically distant concepts (e.g., periodic table of elements and tarot divination) in a misleading way, and a Hallucination Quantifying Prompt (HQP), which scores the plausibility, confidence, and coherence of the output. Controlled experiments across multiple LLMs revealed that HIPs consistently produced less coherent and more hallucinated responses than their null-fusion controls. These effects varied across models, with reasoning-oriented LLMs showing distinct profiles from general-purpose ones. Our framework provides a reproducible testbed for studying hallucination vulnerability, and opens the door to developing safer, more introspective LLMs that can detect and self-regulate the onset of conceptual instability."
      },
      {
        "id": "oai:arXiv.org:2505.00564v1",
        "title": "X-ray illicit object detection using hybrid CNN-transformer neural network architectures",
        "link": "https://arxiv.org/abs/2505.00564",
        "author": "Jorgen Cani, Christos Diou, Spyridon Evangelatos, Panagiotis Radoglou-Grammatikis, Vasileios Argyriou, Panagiotis Sarigiannidis, Iraklis Varlamis, Georgios Th. Papadopoulos",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00564v1 Announce Type: new \nAbstract: In the field of X-ray security applications, even the smallest details can significantly impact outcomes. Objects that are heavily occluded or intentionally concealed pose a great challenge for detection, whether by human observation or through advanced technological applications. While certain Deep Learning (DL) architectures demonstrate strong performance in processing local information, such as Convolutional Neural Networks (CNNs), others excel in handling distant information, e.g., transformers. In X-ray security imaging the literature has been dominated by the use of CNN-based methods, while the integration of the two aforementioned leading architectures has not been sufficiently explored. In this paper, various hybrid CNN-transformer architectures are evaluated against a common CNN object detection baseline, namely YOLOv8. In particular, a CNN (HGNetV2) and a hybrid CNN-transformer (Next-ViT-S) backbone are combined with different CNN/transformer detection heads (YOLOv8 and RT-DETR). The resulting architectures are comparatively evaluated on three challenging public X-ray inspection datasets, namely EDS, HiXray, and PIDray. Interestingly, while the YOLOv8 detector with its default backbone (CSP-DarkNet53) is generally shown to be advantageous on the HiXray and PIDray datasets, when a domain distribution shift is incorporated in the X-ray images (as happens in the EDS datasets), hybrid CNN-transformer architectures exhibit increased robustness. Detailed comparative evaluation results, including object-level detection performance and object-size error analysis, demonstrate the strengths and weaknesses of each architectural combination and suggest guidelines for future research. The source code and network weights of the models employed in this study are available at https://github.com/jgenc/xray-comparative-evaluation."
      },
      {
        "id": "oai:arXiv.org:2505.00568v1",
        "title": "Multimodal Masked Autoencoder Pre-training for 3D MRI-Based Brain Tumor Analysis with Missing Modalities",
        "link": "https://arxiv.org/abs/2505.00568",
        "author": "Lucas Robinet, Ahmad Berjaoui, Elizabeth Cohen-Jonathan Moyal",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00568v1 Announce Type: new \nAbstract: Multimodal magnetic resonance imaging (MRI) constitutes the first line of investigation for clinicians in the care of brain tumors, providing crucial insights for surgery planning, treatment monitoring, and biomarker identification. Pre-training on large datasets have been shown to help models learn transferable representations and adapt with minimal labeled data. This behavior is especially valuable in medical imaging, where annotations are often scarce. However, applying this paradigm to multimodal medical data introduces a challenge: most existing approaches assume that all imaging modalities are available during both pre-training and fine-tuning. In practice, missing modalities often occur due to acquisition issues, specialist unavailability, or specific experimental designs on small in-house datasets. Consequently, a common approach involves training a separate model for each desired modality combination, making the process both resource-intensive and impractical for clinical use. Therefore, we introduce BM-MAE, a masked image modeling pre-training strategy tailored for multimodal MRI data. The same pre-trained model seamlessly adapts to any combination of available modalities, extracting rich representations that capture both intra- and inter-modal information. This allows fine-tuning on any subset of modalities without requiring architectural changes, while still benefiting from a model pre-trained on the full set of modalities. Extensive experiments show that the proposed pre-training strategy outperforms or remains competitive with baselines that require separate pre-training for each modality subset, while substantially surpassing training from scratch on several downstream tasks. Additionally, it can quickly and efficiently reconstruct missing modalities, highlighting its practical value. Code and trained models are available at: https://github.com/Lucas-rbnt/bmmae"
      },
      {
        "id": "oai:arXiv.org:2505.00569v1",
        "title": "AnimalMotionCLIP: Embedding motion in CLIP for Animal Behavior Analysis",
        "link": "https://arxiv.org/abs/2505.00569",
        "author": "Enmin Zhong, Carlos R. del-Blanco, Daniel Berj\\'on, Fernando Jaureguizar, Narciso Garc\\'ia",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00569v1 Announce Type: new \nAbstract: Recently, there has been a surge of interest in applying deep learning techniques to animal behavior recognition, particularly leveraging pre-trained visual language models, such as CLIP, due to their remarkable generalization capacity across various downstream tasks. However, adapting these models to the specific domain of animal behavior recognition presents two significant challenges: integrating motion information and devising an effective temporal modeling scheme. In this paper, we propose AnimalMotionCLIP to address these challenges by interleaving video frames and optical flow information in the CLIP framework. Additionally, several temporal modeling schemes using an aggregation of classifiers are proposed and compared: dense, semi dense, and sparse. As a result, fine temporal actions can be correctly recognized, which is of vital importance in animal behavior analysis. Experiments on the Animal Kingdom dataset demonstrate that AnimalMotionCLIP achieves superior performance compared to state-of-the-art approaches."
      },
      {
        "id": "oai:arXiv.org:2505.00570v1",
        "title": "FreqKV: Frequency Domain Key-Value Compression for Efficient Context Window Extension",
        "link": "https://arxiv.org/abs/2505.00570",
        "author": "Jushi Kai, Boyi Zeng, Yixuan Wang, Haoli Bai, Bo Jiang, Zhouhan Lin",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00570v1 Announce Type: new \nAbstract: Extending the context window in large language models (LLMs) is essential for applications involving long-form content generation. However, the linear increase in key-value (KV) cache memory requirements and the quadratic complexity of self-attention with respect to sequence length present significant challenges during fine-tuning and inference. Existing methods suffer from performance degradation when extending to longer contexts. In this work, we introduce a novel context extension method that optimizes both fine-tuning and inference efficiency. Our method exploits a key observation: in the frequency domain, the energy distribution of the KV cache is primarily concentrated in low-frequency components. By filtering out the high-frequency components, the KV cache can be effectively compressed with minimal information loss. Building on this insight, we propose an efficient compression technique, FreqKV, that iteratively compresses the increasing KV cache to a fixed size in the frequency domain, applicable to both fine-tuning and inference. FreqKV introduces no additional parameters or architectural modifications. With minimal fine-tuning, LLMs can learn to leverage the limited cache that is compressed in the frequency domain and extend the context window efficiently. Experiments on various long context language modeling and understanding tasks demonstrate the efficiency and efficacy of the proposed method."
      },
      {
        "id": "oai:arXiv.org:2505.00580v1",
        "title": "Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors",
        "link": "https://arxiv.org/abs/2505.00580",
        "author": "Xinyu Ding, Lexuan Chen, Siyu Liao, Zhongfeng Wang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00580v1 Announce Type: new \nAbstract: Foundation models have achieved tremendous success in different domains. However, their huge computation and storage complexity make these models difficult to fine-tune and also less applicable in practice. Recent study shows training in Fourier domain can be an effective fine-tuning method in terms of both model performance and number of training parameters. In this work, we propose to further reduce the complexity by the factorization through the product of interleaved circulant and diagonal matrices. In addition, we address the case of non-square fine-tuning weights by partitioning the circulant matrix into blocks. Our method avoids the construction of weight change matrix and utilizes 1D fast Fourier transform (FFT) instead of 2D FFT. Experimental results show that our method achieves similar or better performance across various tasks with much less floating-point operations (FLOPs) and the number of trainable parameters."
      },
      {
        "id": "oai:arXiv.org:2505.00582v1",
        "title": "Block Circulant Adapter for Large Language Models",
        "link": "https://arxiv.org/abs/2505.00582",
        "author": "Xinyu Ding, Meiqi Wang, Siyu Liao, Zhongfeng Wang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00582v1 Announce Type: new \nAbstract: Fine-tuning large language models (LLMs) is difficult due to their huge model size. Recent Fourier domain-based methods show potential for reducing fine-tuning costs. We propose a block circulant matrix-based fine-tuning method with a stable training heuristic to leverage the properties of circulant matrices and one-dimensional Fourier transforms to reduce storage and computation costs. Experiments show that our method uses $14\\times$ less number of parameters than VeRA, $16\\times$ smaller than LoRA and $32\\times$ less FLOPs than FourierFT, while maintaining close or better task performance. Our approach presents a promising way in frequency domain to fine-tune large models on downstream tasks."
      },
      {
        "id": "oai:arXiv.org:2505.00584v1",
        "title": "Synthesizing and Identifying Noise Levels in Autonomous Vehicle Camera Radar Datasets",
        "link": "https://arxiv.org/abs/2505.00584",
        "author": "Mathis Morales, Golnaz Habibi",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00584v1 Announce Type: new \nAbstract: Detecting and tracking objects is a crucial component of any autonomous navigation method. For the past decades, object detection has yielded promising results using neural networks on various datasets. While many methods focus on performance metrics, few projects focus on improving the robustness of these detection and tracking pipelines, notably to sensor failures. In this paper we attempt to address this issue by creating a realistic synthetic data augmentation pipeline for camera-radar Autonomous Vehicle (AV) datasets. Our goal is to accurately simulate sensor failures and data deterioration due to real-world interferences. We also present our results of a baseline lightweight Noise Recognition neural network trained and tested on our augmented dataset, reaching an overall recognition accuracy of 54.4\\% on 11 categories across 10086 images and 2145 radar point-clouds."
      },
      {
        "id": "oai:arXiv.org:2505.00590v1",
        "title": "Unlocking the Potential of Linear Networks for Irregular Multivariate Time Series Forecasting",
        "link": "https://arxiv.org/abs/2505.00590",
        "author": "Chengsen Wang, Qi Qi, Jingyu Wang, Haifeng Sun, Zirui Zhuang, Jianxin Liao",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00590v1 Announce Type: new \nAbstract: Time series forecasting holds significant importance across various industries, including finance, transportation, energy, healthcare, and climate. Despite the widespread use of linear networks due to their low computational cost and effectiveness in modeling temporal dependencies, most existing research has concentrated on regularly sampled and fully observed multivariate time series. However, in practice, we frequently encounter irregular multivariate time series characterized by variable sampling intervals and missing values. The inherent intra-series inconsistency and inter-series asynchrony in such data hinder effective modeling and forecasting with traditional linear networks relying on static weights. To tackle these challenges, this paper introduces a novel model named AiT. AiT utilizes an adaptive linear network capable of dynamically adjusting weights according to observation time points to address intra-series inconsistency, thereby enhancing the accuracy of temporal dependencies modeling. Furthermore, by incorporating the Transformer module on variable semantics embeddings, AiT efficiently captures variable correlations, avoiding the challenge of inter-series asynchrony. Comprehensive experiments across four benchmark datasets demonstrate the superiority of AiT, improving prediction accuracy by 11% and decreasing runtime by 52% compared to existing state-of-the-art methods."
      },
      {
        "id": "oai:arXiv.org:2505.00591v1",
        "title": "Explainable AI in Spatial Analysis",
        "link": "https://arxiv.org/abs/2505.00591",
        "author": "Ziqi Li",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00591v1 Announce Type: new \nAbstract: This chapter discusses the opportunities of eXplainable Artificial Intelligence (XAI) within the realm of spatial analysis. A key objective in spatial analysis is to model spatial relationships and infer spatial processes to generate knowledge from spatial data, which has been largely based on spatial statistical methods. More recently, machine learning offers scalable and flexible approaches that complement traditional methods and has been increasingly applied in spatial data science. Despite its advantages, machine learning is often criticized for being a black box, which limits our understanding of model behavior and output. Recognizing this limitation, XAI has emerged as a pivotal field in AI that provides methods to explain the output of machine learning models to enhance transparency and understanding. These methods are crucial for model diagnosis, bias detection, and ensuring the reliability of results obtained from machine learning models. This chapter introduces key concepts and methods in XAI with a focus on Shapley value-based approaches, which is arguably the most popular XAI method, and their integration with spatial analysis. An empirical example of county-level voting behaviors in the 2020 Presidential election is presented to demonstrate the use of Shapley values and spatial analysis with a comparison to multi-scale geographically weighted regression. The chapter concludes with a discussion on the challenges and limitations of current XAI techniques and proposes new directions."
      },
      {
        "id": "oai:arXiv.org:2505.00592v1",
        "title": "Uncertainty-Aware Multi-Expert Knowledge Distillation for Imbalanced Disease Grading",
        "link": "https://arxiv.org/abs/2505.00592",
        "author": "Shuo Tong, Shangde Gao, Ke Liu, Zihang Huang, Hongxia Xu, Haochao Ying, Jian Wu",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00592v1 Announce Type: new \nAbstract: Automatic disease image grading is a significant application of artificial intelligence for healthcare, enabling faster and more accurate patient assessments. However, domain shifts, which are exacerbated by data imbalance, introduce bias into the model, posing deployment difficulties in clinical applications. To address the problem, we propose a novel \\textbf{U}ncertainty-aware \\textbf{M}ulti-experts \\textbf{K}nowledge \\textbf{D}istillation (UMKD) framework to transfer knowledge from multiple expert models to a single student model. Specifically, to extract discriminative features, UMKD decouples task-agnostic and task-specific features with shallow and compact feature alignment in the feature space. At the output space, an uncertainty-aware decoupled distillation (UDD) mechanism dynamically adjusts knowledge transfer weights based on expert model uncertainties, ensuring robust and reliable distillation. Additionally, UMKD also tackles the problems of model architecture heterogeneity and distribution discrepancies between source and target domains, which are inadequately tackled by previous KD approaches. Extensive experiments on histology prostate grading (\\textit{SICAPv2}) and fundus image grading (\\textit{APTOS}) demonstrate that UMKD achieves a new state-of-the-art in both source-imbalanced and target-imbalanced scenarios, offering a robust and practical solution for real-world disease image grading."
      },
      {
        "id": "oai:arXiv.org:2505.00598v1",
        "title": "Fast and Low-Cost Genomic Foundation Models via Outlier Removal",
        "link": "https://arxiv.org/abs/2505.00598",
        "author": "Haozheng Luo, Chenghao Qiu, Maojiang Su, Zhihan Zhou, Zoe Mehta, Guo Ye, Jerry Yao-Chieh Hu, Han Liu",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00598v1 Announce Type: new \nAbstract: We propose the first unified adversarial attack benchmark for Genomic Foundation Models (GFMs), named GERM. Unlike existing GFM benchmarks, GERM offers the first comprehensive evaluation framework to systematically assess the vulnerability of GFMs to adversarial attacks. Methodologically, we evaluate the adversarial robustness of five state-of-the-art GFMs using four widely adopted attack algorithms and three defense strategies. Importantly, our benchmark provides an accessible and comprehensive framework to analyze GFM vulnerabilities with respect to model architecture, quantization schemes, and training datasets. Empirically, transformer-based models exhibit greater robustness to adversarial perturbations compared to HyenaDNA, highlighting the impact of architectural design on vulnerability. Moreover, adversarial attacks frequently target biologically significant genomic regions, suggesting that these models effectively capture meaningful sequence features."
      },
      {
        "id": "oai:arXiv.org:2505.00599v1",
        "title": "Visual Trajectory Prediction of Vessels for Inland Navigation",
        "link": "https://arxiv.org/abs/2505.00599",
        "author": "Alexander Puzicha, Konstantin W\\\"ustefeld, Kathrin Wilms, Frank Weichert",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00599v1 Announce Type: new \nAbstract: The future of inland navigation increasingly relies on autonomous systems and remote operations, emphasizing the need for accurate vessel trajectory prediction. This study addresses the challenges of video-based vessel tracking and prediction by integrating advanced object detection methods, Kalman filters, and spline-based interpolation. However, existing detection systems often misclassify objects in inland waterways due to complex surroundings. A comparative evaluation of tracking algorithms, including BoT-SORT, Deep OC-SORT, and ByeTrack, highlights the robustness of the Kalman filter in providing smoothed trajectories. Experimental results from diverse scenarios demonstrate improved accuracy in predicting vessel movements, which is essential for collision avoidance and situational awareness. The findings underline the necessity of customized datasets and models for inland navigation. Future work will expand the datasets and incorporate vessel classification to refine predictions, supporting both autonomous systems and human operators in complex environments."
      },
      {
        "id": "oai:arXiv.org:2505.00606v1",
        "title": "Dietary Intake Estimation via Continuous 3D Reconstruction of Food",
        "link": "https://arxiv.org/abs/2505.00606",
        "author": "Wallace Lee, YuHao Chen",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00606v1 Announce Type: new \nAbstract: Monitoring dietary habits is crucial for preventing health risks associated with overeating and undereating, including obesity, diabetes, and cardiovascular diseases. Traditional methods for tracking food intake rely on self-reported data before or after the eating, which are prone to inaccuracies. This study proposes an approach to accurately monitor ingest behaviours by leveraging 3D food models constructed from monocular 2D video. Using COLMAP and pose estimation algorithms, we generate detailed 3D representations of food, allowing us to observe changes in food volume as it is consumed. Experiments with toy models and real food items demonstrate the approach's potential. Meanwhile, we have proposed a new methodology for automated state recognition challenges to accurately detect state changes and maintain model fidelity. The 3D reconstruction approach shows promise in capturing comprehensive dietary behaviour insights, ultimately contributing to the development of automated and accurate dietary monitoring tools."
      },
      {
        "id": "oai:arXiv.org:2505.00615v1",
        "title": "Pixel3DMM: Versatile Screen-Space Priors for Single-Image 3D Face Reconstruction",
        "link": "https://arxiv.org/abs/2505.00615",
        "author": "Simon Giebenhain, Tobias Kirschstein, Martin R\\\"unz, Lourdes Agapito, Matthias Nie{\\ss}ner",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00615v1 Announce Type: new \nAbstract: We address the 3D reconstruction of human faces from a single RGB image. To this end, we propose Pixel3DMM, a set of highly-generalized vision transformers which predict per-pixel geometric cues in order to constrain the optimization of a 3D morphable face model (3DMM). We exploit the latent features of the DINO foundation model, and introduce a tailored surface normal and uv-coordinate prediction head. We train our model by registering three high-quality 3D face datasets against the FLAME mesh topology, which results in a total of over 1,000 identities and 976K images. For 3D face reconstruction, we propose a FLAME fitting opitmization that solves for the 3DMM parameters from the uv-coordinate and normal estimates. To evaluate our method, we introduce a new benchmark for single-image face reconstruction, which features high diversity facial expressions, viewing angles, and ethnicities. Crucially, our benchmark is the first to evaluate both posed and neutral facial geometry. Ultimately, our method outperforms the most competitive baselines by over 15% in terms of geometric accuracy for posed facial expressions."
      },
      {
        "id": "oai:arXiv.org:2505.00619v1",
        "title": "Diverse Semantics-Guided Feature Alignment and Decoupling for Visible-Infrared Person Re-Identification",
        "link": "https://arxiv.org/abs/2505.00619",
        "author": "Neng Dong, Shuanglin Yan, Liyan Zhang, Jinhui Tang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00619v1 Announce Type: new \nAbstract: Visible-Infrared Person Re-Identification (VI-ReID) is a challenging task due to the large modality discrepancy between visible and infrared images, which complicates the alignment of their features into a suitable common space. Moreover, style noise, such as illumination and color contrast, reduces the identity discriminability and modality invariance of features. To address these challenges, we propose a novel Diverse Semantics-guided Feature Alignment and Decoupling (DSFAD) network to align identity-relevant features from different modalities into a textual embedding space and disentangle identity-irrelevant features within each modality. Specifically, we develop a Diverse Semantics-guided Feature Alignment (DSFA) module, which generates pedestrian descriptions with diverse sentence structures to guide the cross-modality alignment of visual features. Furthermore, to filter out style information, we propose a Semantic Margin-guided Feature Decoupling (SMFD) module, which decomposes visual features into pedestrian-related and style-related components, and then constrains the similarity between the former and the textual embeddings to be at least a margin higher than that between the latter and the textual embeddings. Additionally, to prevent the loss of pedestrian semantics during feature decoupling, we design a Semantic Consistency-guided Feature Restitution (SCFR) module, which further excavates useful information for identification from the style-related features and restores it back into the pedestrian-related features, and then constrains the similarity between the features after restitution and the textual embeddings to be consistent with that between the features before decoupling and the textual embeddings. Extensive experiments on three VI-ReID datasets demonstrate the superiority of our DSFAD."
      },
      {
        "id": "oai:arXiv.org:2505.00624v1",
        "title": "FineScope : Precision Pruning for Domain-Specialized Large Language Models Using SAE-Guided Self-Data Cultivation",
        "link": "https://arxiv.org/abs/2505.00624",
        "author": "Chaitali Bhattacharyya, Yeseong Kim",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00624v1 Announce Type: new \nAbstract: Training large language models (LLMs) from scratch requires significant computational resources, driving interest in developing smaller, domain-specific LLMs that maintain both efficiency and strong task performance. Medium-sized models such as LLaMA, llama} have served as starting points for domain-specific adaptation, but they often suffer from accuracy degradation when tested on specialized datasets. We introduce FineScope, a framework for deriving compact, domain-optimized LLMs from larger pretrained models. FineScope leverages the Sparse Autoencoder (SAE) framework, inspired by its ability to produce interpretable feature representations, to extract domain-specific subsets from large datasets. We apply structured pruning with domain-specific constraints, ensuring that the resulting pruned models retain essential knowledge for the target domain. To further enhance performance, these pruned models undergo self-data distillation, leveraging SAE-curated datasets to restore key domain-specific information lost during pruning. Extensive experiments and ablation studies demonstrate that FineScope achieves highly competitive performance, outperforming several large-scale state-of-the-art LLMs in domain-specific tasks. Additionally, our results show that FineScope enables pruned models to regain a substantial portion of their original performance when fine-tuned with SAE-curated datasets. Furthermore, applying these datasets to fine-tune pretrained LLMs without pruning also improves their domain-specific accuracy, highlighting the robustness of our approach. The code will be released."
      },
      {
        "id": "oai:arXiv.org:2505.00626v1",
        "title": "The Illusion of Role Separation: Hidden Shortcuts in LLM Role Learning (and How to Fix Them)",
        "link": "https://arxiv.org/abs/2505.00626",
        "author": "Zihao Wang, Yibo Jiang, Jiahao Yu, Heqing Huang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00626v1 Announce Type: new \nAbstract: Large language models (LLMs) that integrate multiple input roles (e.g., system instructions, user queries, external tool outputs) are increasingly prevalent in practice. Ensuring that the model accurately distinguishes messages from each role -- a concept we call \\emph{role separation} -- is crucial for consistent multi-role behavior. Although recent work often targets state-of-the-art prompt injection defenses, it remains unclear whether such methods truly teach LLMs to differentiate roles or merely memorize known triggers. In this paper, we examine \\emph{role-separation learning}: the process of teaching LLMs to robustly distinguish system and user tokens. Through a \\emph{simple, controlled experimental framework}, we find that fine-tuned models often rely on two proxies for role identification: (1) task type exploitation, and (2) proximity to begin-of-text. Although data augmentation can partially mitigate these shortcuts, it generally leads to iterative patching rather than a deeper fix. To address this, we propose reinforcing \\emph{invariant signals} that mark role boundaries by adjusting token-wise cues in the model's input encoding. In particular, manipulating position IDs helps the model learn clearer distinctions and reduces reliance on superficial proxies. By focusing on this mechanism-centered perspective, our work illuminates how LLMs can more reliably maintain consistent multi-role behavior without merely memorizing known prompts or triggers."
      },
      {
        "id": "oai:arXiv.org:2505.00627v1",
        "title": "Brain Foundation Models with Hypergraph Dynamic Adapter for Brain Disease Analysis",
        "link": "https://arxiv.org/abs/2505.00627",
        "author": "Zhongying Deng, Haoyu Wang, Ziyan Huang, Lipei Zhang, Angelica I. Aviles-Rivero, Chaoyu Liu, Junjun He, Zoe Kourtzi, Carola-Bibiane Sch\\\"onlieb",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00627v1 Announce Type: new \nAbstract: Brain diseases, such as Alzheimer's disease and brain tumors, present profound challenges due to their complexity and societal impact. Recent advancements in brain foundation models have shown significant promise in addressing a range of brain-related tasks. However, current brain foundation models are limited by task and data homogeneity, restricted generalization beyond segmentation or classification, and inefficient adaptation to diverse clinical tasks. In this work, we propose SAM-Brain3D, a brain-specific foundation model trained on over 66,000 brain image-label pairs across 14 MRI sub-modalities, and Hypergraph Dynamic Adapter (HyDA), a lightweight adapter for efficient and effective downstream adaptation. SAM-Brain3D captures detailed brain-specific anatomical and modality priors for segmenting diverse brain targets and broader downstream tasks. HyDA leverages hypergraphs to fuse complementary multi-modal data and dynamically generate patient-specific convolutional kernels for multi-scale feature fusion and personalized patient-wise adaptation. Together, our framework excels across a broad spectrum of brain disease segmentation and classification tasks. Extensive experiments demonstrate that our method consistently outperforms existing state-of-the-art approaches, offering a new paradigm for brain disease analysis through multi-modal, multi-scale, and dynamic foundation modeling."
      },
      {
        "id": "oai:arXiv.org:2505.00630v1",
        "title": "Vision Mamba in Remote Sensing: A Comprehensive Survey of Techniques, Applications and Outlook",
        "link": "https://arxiv.org/abs/2505.00630",
        "author": "Muyi Bao, Shuchang Lyu, Zhaoyang Xu, Huiyu Zhou, Jinchang Ren, Shiming Xiang, Xiangtai Li, Guangliang Cheng",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00630v1 Announce Type: new \nAbstract: Deep learning has profoundly transformed remote sensing, yet prevailing architectures like Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) remain constrained by critical trade-offs: CNNs suffer from limited receptive fields, while ViTs grapple with quadratic computational complexity, hindering their scalability for high-resolution remote sensing data. State Space Models (SSMs), particularly the recently proposed Mamba architecture, have emerged as a paradigm-shifting solution, combining linear computational scaling with global context modeling. This survey presents a comprehensive review of Mamba-based methodologies in remote sensing, systematically analyzing about 120 studies to construct a holistic taxonomy of innovations and applications. Our contributions are structured across five dimensions: (i) foundational principles of vision Mamba architectures, (ii) micro-architectural advancements such as adaptive scan strategies and hybrid SSM formulations, (iii) macro-architectural integrations, including CNN-Transformer-Mamba hybrids and frequency-domain adaptations, (iv) rigorous benchmarking against state-of-the-art methods in multiple application tasks, such as object detection, semantic segmentation, change detection, etc. and (v) critical analysis of unresolved challenges with actionable future directions. By bridging the gap between SSM theory and remote sensing practice, this survey establishes Mamba as a transformative framework for remote sensing analysis. To our knowledge, this paper is the first systematic review of Mamba architectures in remote sensing. Our work provides a structured foundation for advancing research in remote sensing systems through SSM-based methods. We curate an open-source repository (https://github.com/BaoBao0926/Awesome-Mamba-in-Remote-Sensing) to foster community-driven advancements."
      },
      {
        "id": "oai:arXiv.org:2505.00650v1",
        "title": "OmicsCL: Unsupervised Contrastive Learning for Cancer Subtype Discovery and Survival Stratification",
        "link": "https://arxiv.org/abs/2505.00650",
        "author": "Atahan Karagoz",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00650v1 Announce Type: new \nAbstract: Unsupervised learning of disease subtypes from multi-omics data presents a significant opportunity for advancing personalized medicine. We introduce OmicsCL, a modular contrastive learning framework that jointly embeds heterogeneous omics modalities-such as gene expression, DNA methylation, and miRNA expression-into a unified latent space. Our method incorporates a survival-aware contrastive loss that encourages the model to learn representations aligned with survival-related patterns, without relying on labeled outcomes. Evaluated on the TCGA BRCA dataset, OmicsCL uncovers clinically meaningful clusters and achieves strong unsupervised concordance with patient survival. The framework demonstrates robustness across hyperparameter configurations and can be tuned to prioritize either subtype coherence or survival stratification. Ablation studies confirm that integrating survival-aware loss significantly enhances the predictive power of learned embeddings. These results highlight the promise of contrastive objectives for biological insight discovery in high-dimensional, heterogeneous omics data."
      },
      {
        "id": "oai:arXiv.org:2505.00654v1",
        "title": "Large Language Models Understanding: an Inherent Ambiguity Barrier",
        "link": "https://arxiv.org/abs/2505.00654",
        "author": "Daniel N. Nissani (Nissensohn)",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00654v1 Announce Type: new \nAbstract: A lively ongoing debate is taking place, since the extraordinary emergence of Large Language Models (LLMs) with regards to their capability to understand the world and capture the meaning of the dialogues in which they are involved. Arguments and counter-arguments have been proposed based upon thought experiments, anecdotal conversations between LLMs and humans, statistical linguistic analysis, philosophical considerations, and more. In this brief paper we present a counter-argument based upon a thought experiment and semi-formal considerations leading to an inherent ambiguity barrier which prevents LLMs from having any understanding of what their amazingly fluent dialogues mean."
      },
      {
        "id": "oai:arXiv.org:2505.00661v1",
        "title": "On the generalization of language models from in-context learning and finetuning: a controlled study",
        "link": "https://arxiv.org/abs/2505.00661",
        "author": "Andrew K. Lampinen, Arslan Chaudhry, Stephanie C. Y. Chan, Cody Wild, Diane Wan, Alex Ku, J\\\"org Bornschein, Razvan Pascanu, Murray Shanahan, James L. McClelland",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00661v1 Announce Type: new \nAbstract: Large language models exhibit exciting capabilities, yet can show surprisingly narrow generalization from finetuning -- from failing to generalize to simple reversals of relations they are trained on, to missing logical deductions that can be made from trained information. These failures to generalize from fine-tuning can hinder practical application of these models. However, language models' in-context learning shows different inductive biases, and can generalize better in some of these cases. Here, we explore these differences in generalization between in-context- and fine-tuning-based learning. To do so, we constructed several novel datasets to evaluate and improve models' ability to generalize from finetuning data. The datasets are constructed to isolate the knowledge in the dataset from that in pretraining, to create clean tests of generalization. We expose pretrained large models to controlled subsets of the information in these datasets -- either in context, or through fine-tuning -- and evaluate their performance on test sets that require various types of generalization. We find overall that in data-matched settings, in-context learning can generalize more flexibly than fine-tuning (though we also find some qualifications of prior findings, such as cases when fine-tuning can generalize to reversals embedded in a larger structure of knowledge). We build on these findings to propose a method to enable improved generalization from fine-tuning: adding in-context inferences to finetuning data. We show that this method improves generalization across various splits of our datasets and other benchmarks. Our results have implications for understanding the inductive biases of different modes of learning in language models, and practically improving their performance."
      },
      {
        "id": "oai:arXiv.org:2505.00662v1",
        "title": "DeepCritic: Deliberate Critique with Large Language Models",
        "link": "https://arxiv.org/abs/2505.00662",
        "author": "Wenkai Yang, Jingwen Chen, Yankai Lin, Ji-Rong Wen",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00662v1 Announce Type: new \nAbstract: As Large Language Models (LLMs) are rapidly evolving, providing accurate feedback and scalable oversight on their outputs becomes an urgent and critical problem. Leveraging LLMs as critique models to achieve automated supervision is a promising solution. In this work, we focus on studying and enhancing the math critique ability of LLMs. Current LLM critics provide critiques that are too shallow and superficial on each step, leading to low judgment accuracy and struggling to offer sufficient feedback for the LLM generator to correct mistakes. To tackle this issue, we propose a novel and effective two-stage framework to develop LLM critics that are capable of deliberately critiquing on each reasoning step of math solutions. In the first stage, we utilize Qwen2.5-72B-Instruct to generate 4.5K long-form critiques as seed data for supervised fine-tuning. Each seed critique consists of deliberate step-wise critiques that includes multi-perspective verifications as well as in-depth critiques of initial critiques for each reasoning step. Then, we perform reinforcement learning on the fine-tuned model with either existing human-labeled data from PRM800K or our automatically annotated data obtained via Monte Carlo sampling-based correctness estimation, to further incentivize its critique ability. Our developed critique model built on Qwen2.5-7B-Instruct not only significantly outperforms existing LLM critics (including the same-sized DeepSeek-R1-distill models and GPT-4o) on various error identification benchmarks, but also more effectively helps the LLM generator refine erroneous steps through more detailed feedback."
      },
      {
        "id": "oai:arXiv.org:2505.00663v1",
        "title": "Wasserstein Policy Optimization",
        "link": "https://arxiv.org/abs/2505.00663",
        "author": "David Pfau, Ian Davies, Diana Borsa, Joao G. M. Araujo, Brendan Tracey, Hado van Hasselt",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00663v1 Announce Type: new \nAbstract: We introduce Wasserstein Policy Optimization (WPO), an actor-critic algorithm for reinforcement learning in continuous action spaces. WPO can be derived as an approximation to Wasserstein gradient flow over the space of all policies projected into a finite-dimensional parameter space (e.g., the weights of a neural network), leading to a simple and completely general closed-form update. The resulting algorithm combines many properties of deterministic and classic policy gradient methods. Like deterministic policy gradients, it exploits knowledge of the gradient of the action-value function with respect to the action. Like classic policy gradients, it can be applied to stochastic policies with arbitrary distributions over actions -- without using the reparameterization trick. We show results on the DeepMind Control Suite and a magnetic confinement fusion task which compare favorably with state-of-the-art continuous control methods."
      },
      {
        "id": "oai:arXiv.org:2505.00668v1",
        "title": "Deep Reinforcement Learning for Urban Air Quality Management: Multi-Objective Optimization of Pollution Mitigation Booth Placement in Metropolitan Environments",
        "link": "https://arxiv.org/abs/2505.00668",
        "author": "Kirtan Rajesh, Suvidha Rupesh Kumar",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00668v1 Announce Type: new \nAbstract: Urban air pollution remains a pressing global concern, particularly in densely populated and traffic-intensive metropolitan areas like Delhi, where exposure to harmful pollutants severely impacts public health. Delhi, being one of the most polluted cities globally, experiences chronic air quality issues due to vehicular emissions, industrial activities, and construction dust, which exacerbate its already fragile atmospheric conditions. Traditional pollution mitigation strategies, such as static air purifying installations, often fail to maximize their impact due to suboptimal placement and limited adaptability to dynamic urban environments. This study presents a novel deep reinforcement learning (DRL) framework to optimize the placement of air purification booths to improve the air quality index (AQI) in the city of Delhi. We employ Proximal Policy Optimization (PPO), a state-of-the-art reinforcement learning algorithm, to iteratively learn and identify high-impact locations based on multiple spatial and environmental factors, including population density, traffic patterns, industrial influence, and green space constraints. Our approach is benchmarked against conventional placement strategies, including random and greedy AQI-based methods, using multi-dimensional performance evaluation metrics such as AQI improvement, spatial coverage, population and traffic impact, and spatial entropy. Experimental results demonstrate that the RL-based approach outperforms baseline methods by achieving a balanced and effective distribution of air purification infrastructure. Notably, the DRL framework achieves an optimal trade-off between AQI reduction and high-coverage deployment, ensuring equitable environmental benefits across urban regions. The findings underscore the potential of AI-driven spatial optimization in advancing smart city initiatives and data-driven urban air quality management."
      },
      {
        "id": "oai:arXiv.org:2505.00675v1",
        "title": "Rethinking Memory in AI: Taxonomy, Operations, Topics, and Future Directions",
        "link": "https://arxiv.org/abs/2505.00675",
        "author": "Yiming Du, Wenyu Huang, Danna Zheng, Zhaowei Wang, Sebastien Montella, Mirella Lapata, Kam-Fai Wong, Jeff Z. Pan",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00675v1 Announce Type: new \nAbstract: Memory is a fundamental component of AI systems, underpinning large language models (LLMs) based agents. While prior surveys have focused on memory applications with LLMs, they often overlook the atomic operations that underlie memory dynamics. In this survey, we first categorize memory representations into parametric, contextual structured, and contextual unstructured and then introduce six fundamental memory operations: Consolidation, Updating, Indexing, Forgetting, Retrieval, and Compression. We systematically map these operations to the most relevant research topics across long-term, long-context, parametric modification, and multi-source memory. By reframing memory systems through the lens of atomic operations and representation types, this survey provides a structured and dynamic perspective on research, benchmark datasets, and tools related to memory in AI, clarifying the functional interplay in LLMs based agents while outlining promising directions for future research\\footnote{The paper list, datasets, methods and tools are available at \\href{https://github.com/Elvin-Yiming-Du/Survey_Memory_in_AI}{https://github.com/Elvin-Yiming-Du/Survey\\_Memory\\_in\\_AI}.}."
      },
      {
        "id": "oai:arXiv.org:2505.00679v1",
        "title": "Steering Large Language Models with Register Analysis for Arbitrary Style Transfer",
        "link": "https://arxiv.org/abs/2505.00679",
        "author": "Xinchen Yang, Marine Carpuat",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00679v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have demonstrated strong capabilities in rewriting text across various styles. However, effectively leveraging this ability for example-based arbitrary style transfer, where an input text is rewritten to match the style of a given exemplar, remains an open challenge. A key question is how to describe the style of the exemplar to guide LLMs toward high-quality rewrites. In this work, we propose a prompting method based on register analysis to guide LLMs to perform this task. Empirical evaluations across multiple style transfer tasks show that our prompting approach enhances style transfer strength while preserving meaning more effectively than existing prompting strategies."
      },
      {
        "id": "oai:arXiv.org:2505.00681v1",
        "title": "MINERVA: Evaluating Complex Video Reasoning",
        "link": "https://arxiv.org/abs/2505.00681",
        "author": "Arsha Nagrani, Sachit Menon, Ahmet Iscen, Shyamal Buch, Ramin Mehran, Nilpa Jha, Anja Hauth, Yukun Zhu, Carl Vondrick, Mikhail Sirotenko, Cordelia Schmid, Tobias Weyand",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00681v1 Announce Type: new \nAbstract: Multimodal LLMs are turning their focus to video benchmarks, however most video benchmarks only provide outcome supervision, with no intermediate or interpretable reasoning steps. This makes it challenging to assess if models are truly able to combine perceptual and temporal information to reason about videos, or simply get the correct answer by chance or by exploiting linguistic biases. To remedy this, we provide a new video reasoning dataset called MINERVA for modern multimodal models. Each question in the dataset comes with 5 answer choices, as well as detailed, hand-crafted reasoning traces. Our dataset is multimodal, diverse in terms of video domain and length, and consists of complex multi-step questions. Extensive benchmarking shows that our dataset provides a challenge for frontier open-source and proprietary models. We perform fine-grained error analysis to identify common failure modes across various models, and create a taxonomy of reasoning errors. We use this to explore both human and LLM-as-a-judge methods for scoring video reasoning traces, and find that failure modes are primarily related to temporal localization, followed by visual perception errors, as opposed to logical or completeness errors. The dataset, along with questions, answer candidates and reasoning traces will be publicly available under https://github.com/google-deepmind/neptune?tab=readme-ov-file\\#minerva."
      },
      {
        "id": "oai:arXiv.org:2505.00684v1",
        "title": "Visual Test-time Scaling for GUI Agent Grounding",
        "link": "https://arxiv.org/abs/2505.00684",
        "author": "Tiange Luo, Lajanugen Logeswaran, Justin Johnson, Honglak Lee",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00684v1 Announce Type: new \nAbstract: We introduce RegionFocus, a visual test-time scaling approach for Vision Language Model Agents. Understanding webpages is challenging due to the visual complexity of GUI images and the large number of interface elements, making accurate action selection difficult. Our approach dynamically zooms in on relevant regions, reducing background clutter and improving grounding accuracy. To support this process, we propose an image-as-map mechanism that visualizes key landmarks at each step, providing a transparent action record and enables the agent to effectively choose among action candidates. Even with a simple region selection strategy, we observe significant performance gains of 28+\\% on Screenspot-pro and 24+\\% on WebVoyager benchmarks on top of two state-of-the-art open vision language model agents, UI-TARS and Qwen2.5-VL, highlighting the effectiveness of visual test-time scaling in interactive settings. We achieve a new state-of-the-art grounding performance of 61.6\\% on the ScreenSpot-Pro benchmark by applying RegionFocus to a Qwen2.5-VL-72B model. Our code will be released publicly at https://github.com/tiangeluo/RegionFocus."
      },
      {
        "id": "oai:arXiv.org:2505.00685v1",
        "title": "On the Importance of Gaussianizing Representations",
        "link": "https://arxiv.org/abs/2505.00685",
        "author": "Daniel Eftekhari, Vardan Papyan",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00685v1 Announce Type: new \nAbstract: The normal distribution plays a central role in information theory - it is at the same time the best-case signal and worst-case noise distribution, has the greatest representational capacity of any distribution, and offers an equivalence between uncorrelatedness and independence for joint distributions. Accounting for the mean and variance of activations throughout the layers of deep neural networks has had a significant effect on facilitating their effective training, but seldom has a prescription for precisely what distribution these activations should take, and how this might be achieved, been offered. Motivated by the information-theoretic properties of the normal distribution, we address this question and concurrently present normality normalization: a novel normalization layer which encourages normality in the feature representations of neural networks using the power transform and employs additive Gaussian noise during training. Our experiments comprehensively demonstrate the effectiveness of normality normalization, in regards to its generalization performance on an array of widely used model and dataset combinations, its strong performance across various common factors of variation such as model width, depth, and training minibatch size, its suitability for usage wherever existing normalization layers are conventionally used, and as a means to improving model robustness to random perturbations."
      },
      {
        "id": "oai:arXiv.org:2505.00690v1",
        "title": "Towards Autonomous Micromobility through Scalable Urban Simulation",
        "link": "https://arxiv.org/abs/2505.00690",
        "author": "Wayne Wu, Honglin He, Chaoyuan Zhang, Jack He, Seth Z. Zhao, Ran Gong, Quanyi Li, Bolei Zhou",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00690v1 Announce Type: new \nAbstract: Micromobility, which utilizes lightweight mobile machines moving in urban public spaces, such as delivery robots and mobility scooters, emerges as a promising alternative to vehicular mobility. Current micromobility depends mostly on human manual operation (in-person or remote control), which raises safety and efficiency concerns when navigating busy urban environments full of unpredictable obstacles and pedestrians. Assisting humans with AI agents in maneuvering micromobility devices presents a viable solution for enhancing safety and efficiency. In this work, we present a scalable urban simulation solution to advance autonomous micromobility. First, we build URBAN-SIM - a high-performance robot learning platform for large-scale training of embodied agents in interactive urban scenes. URBAN-SIM contains three critical modules: Hierarchical Urban Generation pipeline, Interactive Dynamics Generation strategy, and Asynchronous Scene Sampling scheme, to improve the diversity, realism, and efficiency of robot learning in simulation. Then, we propose URBAN-BENCH - a suite of essential tasks and benchmarks to gauge various capabilities of the AI agents in achieving autonomous micromobility. URBAN-BENCH includes eight tasks based on three core skills of the agents: Urban Locomotion, Urban Navigation, and Urban Traverse. We evaluate four robots with heterogeneous embodiments, such as the wheeled and legged robots, across these tasks. Experiments on diverse terrains and urban structures reveal each robot's strengths and limitations."
      },
      {
        "id": "oai:arXiv.org:2505.00702v1",
        "title": "RayZer: A Self-supervised Large View Synthesis Model",
        "link": "https://arxiv.org/abs/2505.00702",
        "author": "Hanwen Jiang, Hao Tan, Peng Wang, Haian Jin, Yue Zhao, Sai Bi, Kai Zhang, Fujun Luan, Kalyan Sunkavalli, Qixing Huang, Georgios Pavlakos",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00702v1 Announce Type: new \nAbstract: We present RayZer, a self-supervised multi-view 3D Vision model trained without any 3D supervision, i.e., camera poses and scene geometry, while exhibiting emerging 3D awareness. Concretely, RayZer takes unposed and uncalibrated images as input, recovers camera parameters, reconstructs a scene representation, and synthesizes novel views. During training, RayZer relies solely on its self-predicted camera poses to render target views, eliminating the need for any ground-truth camera annotations and allowing RayZer to be trained with 2D image supervision. The emerging 3D awareness of RayZer is attributed to two key factors. First, we design a self-supervised framework, which achieves 3D-aware auto-encoding of input images by disentangling camera and scene representations. Second, we design a transformer-based model in which the only 3D prior is the ray structure, connecting camera, pixel, and scene simultaneously. RayZer demonstrates comparable or even superior novel view synthesis performance than ``oracle'' methods that rely on pose annotations in both training and testing. Project: https://hwjiang1510.github.io/RayZer/"
      },
      {
        "id": "oai:arXiv.org:2505.00703v1",
        "title": "T2I-R1: Reinforcing Image Generation with Collaborative Semantic-level and Token-level CoT",
        "link": "https://arxiv.org/abs/2505.00703",
        "author": "Dongzhi Jiang, Ziyu Guo, Renrui Zhang, Zhuofan Zong, Hao Li, Le Zhuo, Shilin Yan, Pheng-Ann Heng, Hongsheng Li",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00703v1 Announce Type: new \nAbstract: Recent advancements in large language models have demonstrated how chain-of-thought (CoT) and reinforcement learning (RL) can improve performance. However, applying such reasoning strategies to the visual generation domain remains largely unexplored. In this paper, we present T2I-R1, a novel reasoning-enhanced text-to-image generation model, powered by RL with a bi-level CoT reasoning process. Specifically, we identify two levels of CoT that can be utilized to enhance different stages of generation: (1) the semantic-level CoT for high-level planning of the prompt and (2) the token-level CoT for low-level pixel processing during patch-by-patch generation. To better coordinate these two levels of CoT, we introduce BiCoT-GRPO with an ensemble of generation rewards, which seamlessly optimizes both generation CoTs within the same training step. By applying our reasoning strategies to the baseline model, Janus-Pro, we achieve superior performance with 13% improvement on T2I-CompBench and 19% improvement on the WISE benchmark, even surpassing the state-of-the-art model FLUX.1. Code is available at: https://github.com/CaraJ7/T2I-R1"
      },
      {
        "id": "oai:arXiv.org:2411.15923v1",
        "title": "Deep Learning for automated multi-scale functional field boundaries extraction using multi-date Sentinel-2 and PlanetScope imagery: Case Study of Netherlands and Pakistan",
        "link": "https://arxiv.org/abs/2411.15923",
        "author": "Saba Zahid, Sajid Ghuffar,  Obaid-ur-Rehman, Syed Roshaan Ali Shah",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2411.15923v1 Announce Type: cross \nAbstract: This study explores the effectiveness of multi-temporal satellite imagery for better functional field boundary delineation using deep learning semantic segmentation architecture on two distinct geographical and multi-scale farming systems of Netherlands and Pakistan. Multidate images of April, August and October 2022 were acquired for PlanetScope and Sentinel-2 in sub regions of Netherlands and November 2022, February and March 2023 for selected area of Dunyapur in Pakistan. For Netherlands, Basic registration crop parcels (BRP) vector layer was used as labeled training data. while self-crafted field boundary vector data were utilized for Pakistan. Four deep learning models with UNET architecture were evaluated using different combinations of multi-date images and NDVI stacks in the Netherlands subregions. A comparative analysis of IoU scores assessed the effectiveness of the proposed multi-date NDVI stack approach. These findings were then applied for transfer learning, using pre-trained models from the Netherlands on the selected area in Pakistan. Additionally, separate models were trained using self-crafted field boundary data for Pakistan, and combined models were developed using data from both the Netherlands and Pakistan. Results indicate that multi-date NDVI stacks provide additional temporal context, reflecting crop growth over different times of the season. The study underscores the critical role of multi-scale ground information from diverse geographical areas in developing robust and universally applicable models for field boundary delineation. The results also highlight the importance of fine spatial resolution for extraction of field boundaries in regions with small scale framing. The findings can be extended to multi-scale implementations for improved automatic field boundary delineation in heterogeneous agricultural environments."
      },
      {
        "id": "oai:arXiv.org:2504.21413v1",
        "title": "An Inversion Theorem for Buffered Linear Toeplitz (BLT) Matrices and Applications to Streaming Differential Privacy",
        "link": "https://arxiv.org/abs/2504.21413",
        "author": "H. Brendan McMahan, Krishna Pillutla",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.21413v1 Announce Type: cross \nAbstract: Buffered Linear Toeplitz (BLT) matrices are a family of parameterized lower-triangular matrices that play an important role in streaming differential privacy with correlated noise. Our main result is a BLT inversion theorem: the inverse of a BLT matrix is itself a BLT matrix with different parameters. We also present an efficient and differentiable $O(d^3)$ algorithm to compute the parameters of the inverse BLT matrix, where $d$ is the degree of the original BLT (typically $d < 10$). Our characterization enables direct optimization of BLT parameters for privacy mechanisms through automatic differentiation."
      },
      {
        "id": "oai:arXiv.org:2504.21707v1",
        "title": "Recursive KL Divergence Optimization: A Dynamic Framework for Representation Learning",
        "link": "https://arxiv.org/abs/2504.21707",
        "author": "Anthony D Martin",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.21707v1 Announce Type: cross \nAbstract: We propose a generalization of modern representation learning objectives by reframing them as recursive divergence alignment processes over localized conditional distributions While recent frameworks like Information Contrastive Learning I-Con unify multiple learning paradigms through KL divergence between fixed neighborhood conditionals we argue this view underplays a crucial recursive structure inherent in the learning process. We introduce Recursive KL Divergence Optimization RKDO a dynamic formalism where representation learning is framed as the evolution of KL divergences across data neighborhoods. This formulation captures contrastive clustering and dimensionality reduction methods as static slices while offering a new path to model stability and local adaptation. Our experiments demonstrate that RKDO offers dual efficiency advantages approximately 30 percent lower loss values compared to static approaches across three different datasets and 60 to 80 percent reduction in computational resources needed to achieve comparable results. This suggests that RKDOs recursive updating mechanism provides a fundamentally more efficient optimization landscape for representation learning with significant implications for resource constrained applications."
      },
      {
        "id": "oai:arXiv.org:2505.00037v1",
        "title": "Can a Quantum Support Vector Machine algorithm be utilized to identify Key Biomarkers from Multi-Omics data of COVID19 patients?",
        "link": "https://arxiv.org/abs/2505.00037",
        "author": "Junggu Choi, Chansu Yu, Kyle L. Jung, Suan-Sin Foo, Weiqiang Chen, Suzy AA Comhair, Serpil C. Erzurum, Lara Jehi, Jae U. Jung",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00037v1 Announce Type: cross \nAbstract: Identifying key biomarkers for COVID-19 from high-dimensional multi-omics data is critical for advancing both diagnostic and pathogenesis research. In this study, we evaluated the applicability of the Quantum Support Vector Machine (QSVM) algorithm for biomarker-based classification of COVID-19. Proteomic and metabolomic biomarkers from two independent datasets were ranked by importance using ridge regression and grouped accordingly. The top- and bottom-ranked biomarker sets were then used to train and evaluate both classical SVM (CSVM) and QSVM models, serving as predictive and negative control inputs, respectively. The QSVM was implemented with multiple quantum kernels, including amplitude encoding, angle encoding, the ZZ feature map, and the projected quantum kernel. Across various experimental settings, QSVM consistently achieved classification performance that was comparable to or exceeded that of CSVM, while reflecting the importance rankings by ridge regression. Although the experiments were conducted in numerical simulation, our findings highlight the potential of QSVM as a promising approach for multi-omics data analysis in biomedical research."
      },
      {
        "id": "oai:arXiv.org:2505.00046v1",
        "title": "SR-NeRV: Improving Embedding Efficiency of Neural Video Representation via Super-Resolution",
        "link": "https://arxiv.org/abs/2505.00046",
        "author": "Taiga Hayami, Kakeru Koizumi, Hiroshi Watanabe",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00046v1 Announce Type: cross \nAbstract: Implicit Neural Representations (INRs) have garnered significant attention for their ability to model complex signals across a variety of domains. Recently, INR-based approaches have emerged as promising frameworks for neural video compression. While conventional methods primarily focus on embedding video content into compact neural networks for efficient representation, they often struggle to reconstruct high-frequency details under stringent model size constraints, which are critical in practical compression scenarios. To address this limitation, we propose an INR-based video representation method that integrates a general-purpose super-resolution (SR) network. Motivated by the observation that high-frequency components exhibit low temporal redundancy across frames, our method entrusts the reconstruction of fine details to the SR network. Experimental results demonstrate that the proposed method outperforms conventional INR-based baselines in terms of reconstruction quality, while maintaining comparable model sizes."
      },
      {
        "id": "oai:arXiv.org:2505.00049v1",
        "title": "Humanizing LLMs: A Survey of Psychological Measurements with Tools, Datasets, and Human-Agent Applications",
        "link": "https://arxiv.org/abs/2505.00049",
        "author": "Wenhan Dong, Yuemeng Zhao, Zhen Sun, Yule Liu, Zifan Peng, Jingyi Zheng, Zongmin Zhang, Ziyi Zhang, Jun Wu, Ruiming Wang, Shengmin Xu, Xinyi Huang, Xinlei He",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00049v1 Announce Type: cross \nAbstract: As large language models (LLMs) are increasingly used in human-centered tasks, assessing their psychological traits is crucial for understanding their social impact and ensuring trustworthy AI alignment. While existing reviews have covered some aspects of related research, several important areas have not been systematically discussed, including detailed discussions of diverse psychological tests, LLM-specific psychological datasets, and the applications of LLMs with psychological traits. To address this gap, we systematically review six key dimensions of applying psychological theories to LLMs: (1) assessment tools; (2) LLM-specific datasets; (3) evaluation metrics (consistency and stability); (4) empirical findings; (5) personality simulation methods; and (6) LLM-based behavior simulation. Our analysis highlights both the strengths and limitations of current methods. While some LLMs exhibit reproducible personality patterns under specific prompting schemes, significant variability remains across tasks and settings. Recognizing methodological challenges such as mismatches between psychological tools and LLMs' capabilities, as well as inconsistencies in evaluation practices, this study aims to propose future directions for developing more interpretable, robust, and generalizable psychological assessment frameworks for LLMs."
      },
      {
        "id": "oai:arXiv.org:2505.00105v1",
        "title": "Optimization of embeddings storage for RAG systems using quantization and dimensionality reduction techniques",
        "link": "https://arxiv.org/abs/2505.00105",
        "author": "Naam\\'an Huerga-P\\'erez, Rub\\'en \\'Alvarez, Rub\\'en Ferrero-Guill\\'en, Alberto Mart\\'inez-Guti\\'errez, Javier D\\'iez-Gonz\\'alez",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00105v1 Announce Type: cross \nAbstract: Retrieval-Augmented Generation enhances language models by retrieving relevant information from external knowledge bases, relying on high-dimensional vector embeddings typically stored in float32 precision. However, storing these embeddings at scale presents significant memory challenges. To address this issue, we systematically investigate on MTEB benchmark two complementary optimization strategies: quantization, evaluating standard formats (float16, int8, binary) and low-bit floating-point types (float8), and dimensionality reduction, assessing methods like PCA, Kernel PCA, UMAP, Random Projections and Autoencoders. Our results show that float8 quantization achieves a 4x storage reduction with minimal performance degradation (<0.3%), significantly outperforming int8 quantization at the same compression level, being simpler to implement. PCA emerges as the most effective dimensionality reduction technique. Crucially, combining moderate PCA (e.g., retaining 50% dimensions) with float8 quantization offers an excellent trade-off, achieving 8x total compression with less performance impact than using int8 alone (which provides only 4x compression). To facilitate practical application, we propose a methodology based on visualizing the performance-storage trade-off space to identify the optimal configuration that maximizes performance within their specific memory constraints."
      },
      {
        "id": "oai:arXiv.org:2505.00110v1",
        "title": "On the expressivity of deep Heaviside networks",
        "link": "https://arxiv.org/abs/2505.00110",
        "author": "Insung Kong, Juntong Chen, Sophie Langer, Johannes Schmidt-Hieber",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00110v1 Announce Type: cross \nAbstract: We show that deep Heaviside networks (DHNs) have limited expressiveness but that this can be overcome by including either skip connections or neurons with linear activation. We provide lower and upper bounds for the Vapnik-Chervonenkis (VC) dimensions and approximation rates of these network classes. As an application, we derive statistical convergence rates for DHN fits in the nonparametric regression model."
      },
      {
        "id": "oai:arXiv.org:2505.00115v1",
        "title": "Rootlets-based registration to the spinal cord PAM50 template",
        "link": "https://arxiv.org/abs/2505.00115",
        "author": "Sandrine B\\'edard, Jan Valo\\v{s}ek, Valeria Oliva, Kenneth A. Weber II, Julien Cohen-Adad",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00115v1 Announce Type: cross \nAbstract: Spinal cord functional MRI studies require precise localization of spinal levels for reliable voxelwise group analyses. Traditional template-based registration of the spinal cord uses intervertebral discs for alignment. However, substantial anatomical variability across individuals exists between vertebral and spinal levels. This study proposes a novel registration approach that leverages spinal nerve rootlets to improve alignment accuracy and reproducibility across individuals. We developed a registration method leveraging dorsal cervical rootlets segmentation and aligning them non-linearly with the PAM50 spinal cord template. Validation was performed on a multi-subject, multi-site dataset (n=267, 44 sites) and a multi-subject dataset with various neck positions (n=10, 3 sessions). We further validated the method on task-based functional MRI (n=23) to compare group-level activation maps using rootlet-based registration to traditional disc-based methods. Rootlet-based registration showed superior alignment across individuals compared to the traditional disc-based method. Notably, rootlet positions were more stable across neck positions. Group-level analysis of task-based functional MRI using rootlet-based increased Z scores and activation cluster size compared to disc-based registration (number of active voxels from 3292 to 7978). Rootlet-based registration enhances both inter- and intra-subject anatomical alignment and yields better spatial normalization for group-level fMRI analyses. Our findings highlight the potential of rootlet-based registration to improve the precision and reliability of spinal cord neuroimaging group analysis."
      },
      {
        "id": "oai:arXiv.org:2505.00133v1",
        "title": "Efficient and robust 3D blind harmonization for large domain gaps",
        "link": "https://arxiv.org/abs/2505.00133",
        "author": "Hwihun Jeong, Hayeon Lee, Se Young Chun, Jongho Lee",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00133v1 Announce Type: cross \nAbstract: Blind harmonization has emerged as a promising technique for MR image harmonization to achieve scale-invariant representations, requiring only target domain data (i.e., no source domain data necessary). However, existing methods face limitations such as inter-slice heterogeneity in 3D, moderate image quality, and limited performance for a large domain gap. To address these challenges, we introduce BlindHarmonyDiff, a novel blind 3D harmonization framework that leverages an edge-to-image model tailored specifically to harmonization. Our framework employs a 3D rectified flow trained on target domain images to reconstruct the original image from an edge map, then yielding a harmonized image from the edge of a source domain image. We propose multi-stride patch training for efficient 3D training and a refinement module for robust inference by suppressing hallucination. Extensive experiments demonstrate that BlindHarmonyDiff outperforms prior arts by harmonizing diverse source domain images to the target domain, achieving higher correspondence to the target domain characteristics. Downstream task-based quality assessments such as tissue segmentation and age prediction on diverse MR scanners further confirm the effectiveness of our approach and demonstrate the capability of our robust and generalizable blind harmonization."
      },
      {
        "id": "oai:arXiv.org:2505.00137v1",
        "title": "Toward Practical Quantum Machine Learning: A Novel Hybrid Quantum LSTM for Fraud Detection",
        "link": "https://arxiv.org/abs/2505.00137",
        "author": "Rushikesh Ubale, Sujan K. K., Sangram Deshpande, Gregory T. Byrd",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00137v1 Announce Type: cross \nAbstract: We present a novel hybrid quantum-classical neural network architecture for fraud detection that integrates a classical Long Short-Term Memory (LSTM) network with a variational quantum circuit. By leveraging quantum phenomena such as superposition and entanglement, our model enhances the feature representation of sequential transaction data, capturing complex non-linear patterns that are challenging for purely classical models. A comprehensive data preprocessing pipeline is employed to clean, encode, balance, and normalize a credit card fraud dataset, ensuring a fair comparison with baseline models. Notably, our hybrid approach achieves per-epoch training times in the range of 45-65 seconds, which is significantly faster than similar architectures reported in the literature, where training typically requires several minutes per epoch. Both classical and quantum gradients are jointly optimized via a unified backpropagation procedure employing the parameter-shift rule for the quantum parameters. Experimental evaluations demonstrate competitive improvements in accuracy, precision, recall, and F1 score relative to a conventional LSTM baseline. These results underscore the promise of hybrid quantum-classical techniques in advancing the efficiency and performance of fraud detection systems.\n  Keywords: Hybrid Quantum-Classical Neural Networks, Quantum Computing, Fraud Detection, Hybrid Quantum LSTM, Variational Quantum Circuit, Parameter-Shift Rule, Financial Risk Analysis"
      },
      {
        "id": "oai:arXiv.org:2505.00186v1",
        "title": "Neuroevolution of Self-Attention Over Proto-Objects",
        "link": "https://arxiv.org/abs/2505.00186",
        "author": "Rafael C. Pinto, Anderson R. Tavares",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00186v1 Announce Type: cross \nAbstract: Proto-objects - image regions that share common visual properties - offer a promising alternative to traditional attention mechanisms based on rectangular-shaped image patches in neural networks. Although previous work demonstrated that evolving a patch-based hard-attention module alongside a controller network could achieve state-of-the-art performance in visual reinforcement learning tasks, our approach leverages image segmentation to work with higher-level features. By operating on proto-objects rather than fixed patches, we significantly reduce the representational complexity: each image decomposes into fewer proto-objects than regular patches, and each proto-object can be efficiently encoded as a compact feature vector. This enables a substantially smaller self-attention module that processes richer semantic information. Our experiments demonstrate that this proto-object-based approach matches or exceeds the state-of-the-art performance of patch-based implementations with 62% less parameters and 2.6 times less training time."
      },
      {
        "id": "oai:arXiv.org:2505.00195v1",
        "title": "Algorithmic Collective Action with Two Collectives",
        "link": "https://arxiv.org/abs/2505.00195",
        "author": "Aditya Karan, Nicholas Vincent, Karrie Karahalios, Hari Sundaram",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00195v1 Announce Type: cross \nAbstract: Given that data-dependent algorithmic systems have become impactful in more domains of life, the need for individuals to promote their own interests and hold algorithms accountable has grown. To have meaningful influence, individuals must band together to engage in collective action. Groups that engage in such algorithmic collective action are likely to vary in size, membership characteristics, and crucially, objectives. In this work, we introduce a first of a kind framework for studying collective action with two or more collectives that strategically behave to manipulate data-driven systems. With more than one collective acting on a system, unexpected interactions may occur. We use this framework to conduct experiments with language model-based classifiers and recommender systems where two collectives each attempt to achieve their own individual objectives. We examine how differing objectives, strategies, sizes, and homogeneity can impact a collective's efficacy. We find that the unintentional interactions between collectives can be quite significant; a collective acting in isolation may be able to achieve their objective (e.g., improve classification outcomes for themselves or promote a particular item), but when a second collective acts simultaneously, the efficacy of the first group drops by as much as $75\\%$. We find that, in the recommender system context, neither fully heterogeneous nor fully homogeneous collectives stand out as most efficacious and that heterogeneity's impact is secondary compared to collective size. Our results signal the need for more transparency in both the underlying algorithmic models and the different behaviors individuals or collectives may take on these systems. This approach also allows collectives to hold algorithmic system developers accountable and provides a framework for people to actively use their own data to promote their own interests."
      },
      {
        "id": "oai:arXiv.org:2505.00212v1",
        "title": "Which Agent Causes Task Failures and When? On Automated Failure Attribution of LLM Multi-Agent Systems",
        "link": "https://arxiv.org/abs/2505.00212",
        "author": "Shaokun Zhang, Ming Yin, Jieyu Zhang, Jiale Liu, Zhiguang Han, Jingyang Zhang, Beibin Li, Chi Wang, Huazheng Wang, Yiran Chen, Qingyun Wu",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00212v1 Announce Type: cross \nAbstract: Failure attribution in LLM multi-agent systems-identifying the agent and step responsible for task failures-provides crucial clues for systems debugging but remains underexplored and labor-intensive. In this paper, we propose and formulate a new research area: automated failure attribution for LLM multi-agent systems. To support this initiative, we introduce the Who&amp;When dataset, comprising extensive failure logs from 127 LLM multi-agent systems with fine-grained annotations linking failures to specific agents and decisive error steps. Using the Who&amp;When, we develop and evaluate three automated failure attribution methods, summarizing their corresponding pros and cons. The best method achieves 53.5% accuracy in identifying failure-responsible agents but only 14.2% in pinpointing failure steps, with some methods performing below random. Even SOTA reasoning models, such as OpenAI o1 and DeepSeek R1, fail to achieve practical usability. These results highlight the task's complexity and the need for further research in this area. Code and dataset are available at https://github.com/mingyin1/Agents_Failure_Attribution"
      },
      {
        "id": "oai:arXiv.org:2505.00222v1",
        "title": "AI-Enhanced Automatic Design of Efficient Underwater Gliders",
        "link": "https://arxiv.org/abs/2505.00222",
        "author": "Peter Yichen Chen, Pingchuan Ma, Niklas Hagemann, John Romanishin, Wei Wang, Daniela Rus, Wojciech Matusik",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00222v1 Announce Type: cross \nAbstract: The development of novel autonomous underwater gliders has been hindered by limited shape diversity, primarily due to the reliance on traditional design tools that depend heavily on manual trial and error. Building an automated design framework is challenging due to the complexities of representing glider shapes and the high computational costs associated with modeling complex solid-fluid interactions. In this work, we introduce an AI-enhanced automated computational framework designed to overcome these limitations by enabling the creation of underwater robots with non-trivial hull shapes. Our approach involves an algorithm that co-optimizes both shape and control signals, utilizing a reduced-order geometry representation and a differentiable neural-network-based fluid surrogate model. This end-to-end design workflow facilitates rapid iteration and evaluation of hydrodynamic performance, leading to the discovery of optimal and complex hull shapes across various control settings. We validate our method through wind tunnel experiments and swimming pool gliding tests, demonstrating that our computationally designed gliders surpass manually designed counterparts in terms of energy efficiency. By addressing challenges in efficient shape representation and neural fluid surrogate models, our work paves the way for the development of highly efficient underwater gliders, with implications for long-range ocean exploration and environmental monitoring."
      },
      {
        "id": "oai:arXiv.org:2505.00229v1",
        "title": "Inference for max-linear Bayesian networks with noise",
        "link": "https://arxiv.org/abs/2505.00229",
        "author": "Mark Adams, Kamillo Ferry, Ruriko Yoshida",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00229v1 Announce Type: cross \nAbstract: Max-Linear Bayesian Networks (MLBNs) provide a powerful framework for causal inference in extreme-value settings; we consider MLBNs with noise parameters with a given topology in terms of the max-plus algebra by taking its logarithm. Then, we show that an estimator of a parameter for each edge in a directed acyclic graph (DAG) is distributed normally. We end this paper with computational experiments with the expectation and maximization (EM) algorithm and quadratic optimization."
      },
      {
        "id": "oai:arXiv.org:2505.00233v1",
        "title": "Explorative Curriculum Learning for Strongly Correlated Electron Systems",
        "link": "https://arxiv.org/abs/2505.00233",
        "author": "Kimihiro Yamazaki, Takuya Konishi, Yoshinobu Kawahara",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00233v1 Announce Type: cross \nAbstract: Recent advances in neural network quantum states (NQS) have enabled high-accuracy predictions for complex quantum many-body systems such as strongly correlated electron systems. However, the computational cost remains prohibitive, making exploration of the diverse parameters of interaction strengths and other physical parameters inefficient. While transfer learning has been proposed to mitigate this challenge, achieving generalization to large-scale systems and diverse parameter regimes remains difficult. To address this limitation, we propose a novel curriculum learning framework based on transfer learning for NQS. This facilitates efficient and stable exploration across a vast parameter space of quantum many-body systems. In addition, by interpreting NQS transfer learning through a perturbative lens, we demonstrate how prior physical knowledge can be flexibly incorporated into the curriculum learning process. We also propose Pairing-Net, an architecture to practically implement this strategy for strongly correlated electron systems, and empirically verify its effectiveness. Our results show an approximately 200-fold speedup in computation and a marked improvement in optimization stability compared to conventional methods."
      },
      {
        "id": "oai:arXiv.org:2505.00237v1",
        "title": "Future-Oriented Navigation: Dynamic Obstacle Avoidance with One-Shot Energy-Based Multimodal Motion Prediction",
        "link": "https://arxiv.org/abs/2505.00237",
        "author": "Ze Zhang, Georg Hess, Junjie Hu, Emmanuel Dean, Lennart Svensson, Knut {\\AA}kesson",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00237v1 Announce Type: cross \nAbstract: This paper proposes an integrated approach for the safe and efficient control of mobile robots in dynamic and uncertain environments. The approach consists of two key steps: one-shot multimodal motion prediction to anticipate motions of dynamic obstacles and model predictive control to incorporate these predictions into the motion planning process. Motion prediction is driven by an energy-based neural network that generates high-resolution, multi-step predictions in a single operation. The prediction outcomes are further utilized to create geometric shapes formulated as mathematical constraints. Instead of treating each dynamic obstacle individually, predicted obstacles are grouped by proximity in an unsupervised way to improve performance and efficiency. The overall collision-free navigation is handled by model predictive control with a specific design for proactive dynamic obstacle avoidance. The proposed approach allows mobile robots to navigate effectively in dynamic environments. Its performance is accessed across various scenarios that represent typical warehouse settings. The results demonstrate that the proposed approach outperforms other existing dynamic obstacle avoidance methods."
      },
      {
        "id": "oai:arXiv.org:2505.00240v1",
        "title": "LLM-Based Threat Detection and Prevention Framework for IoT Ecosystems",
        "link": "https://arxiv.org/abs/2505.00240",
        "author": "Yazan Otoum, Arghavan Asad, Amiya Nayak",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00240v1 Announce Type: cross \nAbstract: The increasing complexity and scale of the Internet of Things (IoT) have made security a critical concern. This paper presents a novel Large Language Model (LLM)-based framework for comprehensive threat detection and prevention in IoT environments. The system integrates lightweight LLMs fine-tuned on IoT-specific datasets (IoT-23, TON_IoT) for real-time anomaly detection and automated, context-aware mitigation strategies optimized for resource-constrained devices. A modular Docker-based deployment enables scalable and reproducible evaluation across diverse network conditions. Experimental results in simulated IoT environments demonstrate significant improvements in detection accuracy, response latency, and resource efficiency over traditional security methods. The proposed framework highlights the potential of LLM-driven, autonomous security solutions for future IoT ecosystems."
      },
      {
        "id": "oai:arXiv.org:2505.00263v1",
        "title": "EnronQA: Towards Personalized RAG over Private Documents",
        "link": "https://arxiv.org/abs/2505.00263",
        "author": "Michael J. Ryan, Danmei Xu, Chris Nivera, Daniel Campos",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00263v1 Announce Type: cross \nAbstract: Retrieval Augmented Generation (RAG) has become one of the most popular methods for bringing knowledge-intensive context to large language models (LLM) because of its ability to bring local context at inference time without the cost or data leakage risks associated with fine-tuning. A clear separation of private information from the LLM training has made RAG the basis for many enterprise LLM workloads as it allows the company to augment LLM's understanding using customers' private documents. Despite its popularity for private documents in enterprise deployments, current RAG benchmarks for validating and optimizing RAG pipelines draw their corpora from public data such as Wikipedia or generic web pages and offer little to no personal context. Seeking to empower more personal and private RAG we release the EnronQA benchmark, a dataset of 103,638 emails with 528,304 question-answer pairs across 150 different user inboxes. EnronQA enables better benchmarking of RAG pipelines over private data and allows for experimentation on the introduction of personalized retrieval settings over realistic data. Finally, we use EnronQA to explore the tradeoff in memorization and retrieval when reasoning over private documents."
      },
      {
        "id": "oai:arXiv.org:2505.00282v1",
        "title": "A Unifying Framework for Robust and Efficient Inference with Unstructured Data",
        "link": "https://arxiv.org/abs/2505.00282",
        "author": "Jacob Carlson, Melissa Dell",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00282v1 Announce Type: cross \nAbstract: This paper presents a general framework for conducting efficient and robust inference on parameters derived from unstructured data, which include text, images, audio, and video. Economists have long incorporated data extracted from texts and images into their analyses, a practice that has accelerated with advancements in deep neural networks. However, neural networks do not generically produce unbiased predictions, potentially propagating bias to estimators that use their outputs. To address this challenge, we reframe inference with unstructured data as a missing structured data problem, where structured data are imputed from unstructured inputs using deep neural networks. This perspective allows us to apply classic results from semiparametric inference, yielding valid, efficient, and robust estimators based on unstructured data. We formalize this approach with MARS (Missing At Random Structured Data), a unifying framework that integrates and extends existing methods for debiased inference using machine learning predictions, linking them to a variety of older, familiar problems such as causal inference. We develop robust and efficient estimators for both descriptive and causal estimands and address challenges such as inference using aggregated and transformed predictions from unstructured data. Importantly, MARS applies to common empirical settings that have received limited attention in the existing literature. Finally, we reanalyze prominent studies that use unstructured data, demonstrating the practical value of MARS."
      },
      {
        "id": "oai:arXiv.org:2505.00299v1",
        "title": "Intelligent Task Scheduling for Microservices via A3C-Based Reinforcement Learning",
        "link": "https://arxiv.org/abs/2505.00299",
        "author": "Yang Wang, Tengda Tang, Zhou Fang, Yingnan Deng, Yifei Duan",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00299v1 Announce Type: cross \nAbstract: To address the challenges of high resource dynamism and intensive task concurrency in microservice systems, this paper proposes an adaptive resource scheduling method based on the A3C reinforcement learning algorithm. The scheduling problem is modeled as a Markov Decision Process, where policy and value networks are jointly optimized to enable fine-grained resource allocation under varying load conditions. The method incorporates an asynchronous multi-threaded learning mechanism, allowing multiple agents to perform parallel sampling and synchronize updates to the global network parameters. This design improves both policy convergence efficiency and model stability. In the experimental section, a real-world dataset is used to construct a scheduling scenario. The proposed method is compared with several typical approaches across multiple evaluation metrics, including task delay, scheduling success rate, resource utilization, and convergence speed. The results show that the proposed method delivers high scheduling performance and system stability in multi-task concurrent environments. It effectively alleviates the resource allocation bottlenecks faced by traditional methods under heavy load, demonstrating its practical value for intelligent scheduling in microservice systems."
      },
      {
        "id": "oai:arXiv.org:2505.00304v1",
        "title": "Reinforcement Learning with Continuous Actions Under Unmeasured Confounding",
        "link": "https://arxiv.org/abs/2505.00304",
        "author": "Yuhan Li, Eugene Han, Yifan Hu, Wenzhuo Zhou, Zhengling Qi, Yifan Cui, Ruoqing Zhu",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00304v1 Announce Type: cross \nAbstract: This paper addresses the challenge of offline policy learning in reinforcement learning with continuous action spaces when unmeasured confounders are present. While most existing research focuses on policy evaluation within partially observable Markov decision processes (POMDPs) and assumes discrete action spaces, we advance this field by establishing a novel identification result to enable the nonparametric estimation of policy value for a given target policy under an infinite-horizon framework. Leveraging this identification, we develop a minimax estimator and introduce a policy-gradient-based algorithm to identify the in-class optimal policy that maximizes the estimated policy value. Furthermore, we provide theoretical results regarding the consistency, finite-sample error bound, and regret bound of the resulting optimal policy. Extensive simulations and a real-world application using the German Family Panel data demonstrate the effectiveness of our proposed methodology."
      },
      {
        "id": "oai:arXiv.org:2505.00310v1",
        "title": "Statistical Learning for Heterogeneous Treatment Effects: Pretraining, Prognosis, and Prediction",
        "link": "https://arxiv.org/abs/2505.00310",
        "author": "Maximilian Schuessler, Erik Sverdrup, Robert Tibshirani",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00310v1 Announce Type: cross \nAbstract: Robust estimation of heterogeneous treatment effects is a fundamental challenge for optimal decision-making in domains ranging from personalized medicine to educational policy. In recent years, predictive machine learning has emerged as a valuable toolbox for causal estimation, enabling more flexible effect estimation. However, accurately estimating conditional average treatment effects (CATE) remains a major challenge, particularly in the presence of many covariates. In this article, we propose pretraining strategies that leverages a phenomenon in real-world applications: factors that are prognostic of the outcome are frequently also predictive of treatment effect heterogeneity. In medicine, for example, components of the same biological signaling pathways frequently influence both baseline risk and treatment response. Specifically, we demonstrate our approach within the R-learner framework, which estimates the CATE by solving individual prediction problems based on a residualized loss. We use this structure to incorporate \"side information\" and develop models that can exploit synergies between risk prediction and causal effect estimation. In settings where these synergies are present, this cross-task learning enables more accurate signal detection: yields lower estimation error, reduced false discovery rates, and higher power for detecting heterogeneity."
      },
      {
        "id": "oai:arXiv.org:2505.00318v1",
        "title": "FedEMA: Federated Exponential Moving Averaging with Negative Entropy Regularizer in Autonomous Driving",
        "link": "https://arxiv.org/abs/2505.00318",
        "author": "Wei-Bin Kou, Guangxu Zhu, Bingyang Cheng, Shuai Wang, Ming Tang, Yik-Chung Wu",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00318v1 Announce Type: cross \nAbstract: Street Scene Semantic Understanding (denoted as S3U) is a crucial but complex task for autonomous driving (AD) vehicles. Their inference models typically face poor generalization due to domain-shift. Federated Learning (FL) has emerged as a promising paradigm for enhancing the generalization of AD models through privacy-preserving distributed learning. However, these FL AD models face significant temporal catastrophic forgetting when deployed in dynamically evolving environments, where continuous adaptation causes abrupt erosion of historical knowledge. This paper proposes Federated Exponential Moving Average (FedEMA), a novel framework that addresses this challenge through two integral innovations: (I) Server-side model's historical fitting capability preservation via fusing current FL round's aggregation model and a proposed previous FL round's exponential moving average (EMA) model; (II) Vehicle-side negative entropy regularization to prevent FL models' possible overfitting to EMA-introduced temporal patterns. Above two strategies empower FedEMA a dual-objective optimization that balances model generalization and adaptability. In addition, we conduct theoretical convergence analysis for the proposed FedEMA. Extensive experiments both on Cityscapes dataset and Camvid dataset demonstrate FedEMA's superiority over existing approaches, showing 7.12% higher mean Intersection-over-Union (mIoU)."
      },
      {
        "id": "oai:arXiv.org:2505.00321v1",
        "title": "Edge Large AI Models: Revolutionizing 6G Networks",
        "link": "https://arxiv.org/abs/2505.00321",
        "author": "Zixin Wang, Yuanming Shi, Yong Zhou, Jingyang Zhu, Khaled. B. Letaief",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00321v1 Announce Type: cross \nAbstract: Large artificial intelligence models (LAMs) possess human-like abilities to solve a wide range of real-world problems, exemplifying the potential of experts in various domains and modalities. By leveraging the communication and computation capabilities of geographically dispersed edge devices, edge LAM emerges as an enabling technology to empower the delivery of various real-time intelligent services in 6G. Unlike traditional edge artificial intelligence (AI) that primarily supports a single task using small models, edge LAM is featured by the need of the decomposition and distributed deployment of large models, and the ability to support highly generalized and diverse tasks. However, due to limited communication, computation, and storage resources over wireless networks, the vast number of trainable neurons and the substantial communication overhead pose a formidable hurdle to the practical deployment of edge LAMs. In this paper, we investigate the opportunities and challenges of edge LAMs from the perspectives of model decomposition and resource management. Specifically, we propose collaborative fine-tuning and full-parameter training frameworks, alongside a microservice-assisted inference architecture, to enhance the deployment of edge LAM over wireless networks. Additionally, we investigate the application of edge LAM in air-interface designs, focusing on channel prediction and beamforming. These innovative frameworks and applications offer valuable insights and solutions for advancing 6G technology."
      },
      {
        "id": "oai:arXiv.org:2505.00325v1",
        "title": "CognitionNet: A Collaborative Neural Network for Play Style Discovery in Online Skill Gaming Platform",
        "link": "https://arxiv.org/abs/2505.00325",
        "author": "Rukma Talwadker, Surajit Chakrabarty, Aditya Pareek, Tridib Mukherjee, Deepak Saini",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00325v1 Announce Type: cross \nAbstract: Games are one of the safest source of realizing self-esteem and relaxation at the same time. An online gaming platform typically has massive data coming in, e.g., in-game actions, player moves, clickstreams, transactions etc. It is rather interesting, as something as simple as data on gaming moves can help create a psychological imprint of the user at that moment, based on her impulsive reactions and response to a situation in the game. Mining this knowledge can: (a) immediately help better explain observed and predicted player behavior; and (b) consequently propel deeper understanding towards players' experience, growth and protection. To this effect, we focus on discovery of the \"game behaviours\" as micro-patterns formed by continuous sequence of games and the persistent \"play styles\" of the players' as a sequence of such sequences on an online skill gaming platform for Rummy. We propose a two stage deep neural network, CognitionNet. The first stage focuses on mining game behaviours as cluster representations in a latent space while the second aggregates over these micro patterns to discover play styles via a supervised classification objective around player engagement. The dual objective allows CognitionNet to reveal several player psychology inspired decision making and tactics. To our knowledge, this is the first and one-of-its-kind research to fully automate the discovery of: (i) player psychology and game tactics from telemetry data; and (ii) relevant diagnostic explanations to players' engagement predictions. The collaborative training of the two networks with differential input dimensions is enabled using a novel formulation of \"bridge loss\". The network plays pivotal role in obtaining homogeneous and consistent play style definitions and significantly outperforms the SOTA baselines wherever applicable."
      },
      {
        "id": "oai:arXiv.org:2505.00374v1",
        "title": "Towards Lightweight Hyperspectral Image Super-Resolution with Depthwise Separable Dilated Convolutional Network",
        "link": "https://arxiv.org/abs/2505.00374",
        "author": "Usman Muhammad, Jorma Laaksonen, Lyudmila Mihaylova",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00374v1 Announce Type: cross \nAbstract: Deep neural networks have demonstrated highly competitive performance in super-resolution (SR) for natural images by learning mappings from low-resolution (LR) to high-resolution (HR) images. However, hyperspectral super-resolution remains an ill-posed problem due to the high spectral dimensionality of the data and the scarcity of available training samples. Moreover, existing methods often rely on large models with a high number of parameters or require the fusion with panchromatic or RGB images, both of which are often impractical in real-world scenarios. Inspired by the MobileNet architecture, we introduce a lightweight depthwise separable dilated convolutional network (DSDCN) to address the aforementioned challenges. Specifically, our model leverages multiple depthwise separable convolutions, similar to the MobileNet architecture, and further incorporates a dilated convolution fusion block to make the model more flexible for the extraction of both spatial and spectral features. In addition, we propose a custom loss function that combines mean squared error (MSE), an L2 norm regularization-based constraint, and a spectral angle-based loss, ensuring the preservation of both spectral and spatial details. The proposed model achieves very competitive performance on two publicly available hyperspectral datasets, making it well-suited for hyperspectral image super-resolution tasks. The source codes are publicly available at: \\href{https://github.com/Usman1021/lightweight}{https://github.com/Usman1021/lightweight}."
      },
      {
        "id": "oai:arXiv.org:2505.00393v1",
        "title": "S3AND: Efficient Subgraph Similarity Search Under Aggregated Neighbor Difference Semantics (Technical Report)",
        "link": "https://arxiv.org/abs/2505.00393",
        "author": "Qi Wen, Yutong Ye, Xiang Lian, Mingsong Chen",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00393v1 Announce Type: cross \nAbstract: For the past decades, the \\textit{subgraph similarity search} over a large-scale data graph has become increasingly important and crucial in many real-world applications, such as social network analysis, bioinformatics network analytics, knowledge graph discovery, and many others. While previous works on subgraph similarity search used various graph similarity metrics such as the graph isomorphism, graph edit distance, and so on, in this paper, we propose a novel problem, namely \\textit{subgraph similarity search under aggregated neighbor difference semantics} (S$^3$AND), which identifies subgraphs $g$ in a data graph $G$ that are similar to a given query graph $q$ by considering both keywords and graph structures (under new keyword/structural matching semantics). To efficiently tackle the S$^3$AND problem, we design two effective pruning methods, \\textit{keyword set} and \\textit{aggregated neighbor difference lower bound pruning}, which rule out false alarms of candidate vertices/subgraphs to reduce the S$^3$AND search space. Furthermore, we construct an effective indexing mechanism to facilitate our proposed efficient S$^3$AND query answering algorithm. Through extensive experiments, we demonstrate the effectiveness and efficiency of our S$^3$AND approach over both real and synthetic graphs under various parameter settings."
      },
      {
        "id": "oai:arXiv.org:2505.00409v1",
        "title": "Perceptual Implications of Automatic Anonymization in Pathological Speech",
        "link": "https://arxiv.org/abs/2505.00409",
        "author": "Soroosh Tayebi Arasteh, Saba Afza, Tri-Thien Nguyen, Lukas Buess, Maryam Parvin, Tomas Arias-Vergara, Paula Andrea Perez-Toro, Hiu Ching Hung, Mahshad Lotfinia, Thomas Gorges, Elmar Noeth, Maria Schuster, Seung Hee Yang, Andreas Maier",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00409v1 Announce Type: cross \nAbstract: Automatic anonymization techniques are essential for ethical sharing of pathological speech data, yet their perceptual consequences remain understudied. This study presents the first comprehensive human-centered analysis of anonymized pathological speech, using a structured perceptual protocol involving ten native and non-native German listeners with diverse linguistic, clinical, and technical backgrounds. Listeners evaluated anonymized-original utterance pairs from 180 speakers spanning Cleft Lip and Palate, Dysarthria, Dysglossia, Dysphonia, and age-matched healthy controls. Speech was anonymized using state-of-the-art automatic methods (equal error rates in the range of 30-40%). Listeners completed Turing-style discrimination and quality rating tasks under zero-shot (single-exposure) and few-shot (repeated-exposure) conditions. Discrimination accuracy was high overall (91% zero-shot; 93% few-shot), but varied by disorder (repeated-measures ANOVA: p=0.007), ranging from 96% (Dysarthria) to 86% (Dysphonia). Anonymization consistently reduced perceived quality (from 83% to 59%, p<0.001), with pathology-specific degradation patterns (one-way ANOVA: p=0.005). Native listeners rated original speech slightly higher than non-native listeners (Delta=4%, p=0.199), but this difference nearly disappeared after anonymization (Delta=1%, p=0.724). No significant gender-based bias was observed. Critically, human perceptual outcomes did not correlate with automatic privacy or clinical utility metrics. These results underscore the need for listener-informed, disorder- and context-specific anonymization strategies that preserve privacy while maintaining interpretability, communicative functions, and diagnostic utility, especially for vulnerable populations such as children."
      },
      {
        "id": "oai:arXiv.org:2505.00430v1",
        "title": "Over-the-Air Inference over Multi-hop MIMO Networks",
        "link": "https://arxiv.org/abs/2505.00430",
        "author": "Chenghong Bian, Meng Hua, Deniz Gunduz",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00430v1 Announce Type: cross \nAbstract: A novel over-the-air machine learning framework over multi-hop multiple-input and multiple-output (MIMO) networks is proposed. The core idea is to imitate fully connected (FC) neural network layers using multiple MIMO channels by carefully designing the precoding matrices at the transmitting nodes. A neural network dubbed PrototypeNet is employed consisting of multiple FC layers, with the number of neurons of each layer equal to the number of antennas of the corresponding terminal. To achieve satisfactory performance, we train PrototypeNet based on a customized loss function consisting of classification error and the power of latent vectors to satisfy transmit power constraints, with noise injection during training. Precoding matrices for each hop are then obtained by solving an optimization problem. We also propose a multiple-block extension when the number of antennas is limited. Numerical results verify that the proposed over-the-air transmission scheme can achieve satisfactory classification accuracy under a power constraint. The results also show that higher classification accuracy can be achieved with an increasing number of hops at a modest signal-to-noise ratio (SNR)."
      },
      {
        "id": "oai:arXiv.org:2505.00460v1",
        "title": "Subspace-Distance-Enabled Active Learning for Efficient Data-Driven Model Reduction of Parametric Dynamical Systems",
        "link": "https://arxiv.org/abs/2505.00460",
        "author": "Harshit Kapadia, Peter Benner, Lihong Feng",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00460v1 Announce Type: cross \nAbstract: In situations where the solution of a high-fidelity dynamical system needs to be evaluated repeatedly, over a vast pool of parametric configurations and in absence of access to the underlying governing equations, data-driven model reduction techniques are preferable. We propose a novel active learning approach to build a parametric data-driven reduced-order model (ROM) by greedily picking the most important parameter samples from the parameter domain. As a result, during the ROM construction phase, the number of high-fidelity solutions dynamically grow in a principled fashion. The high-fidelity solution snapshots are expressed in several parameter-specific linear subspaces, with the help of proper orthogonal decomposition (POD), and the relative distance between these subspaces is used as a guiding mechanism to perform active learning. For successfully achieving this, we provide a distance measure to evaluate the similarity between pairs of linear subspaces with different dimensions, and also show that this distance measure is a metric. The usability of the proposed subspace-distance-enabled active learning (SDE-AL) framework is demonstrated by augmenting two existing non-intrusive reduced-order modeling approaches, and providing their active-learning-driven (ActLearn) extensions, namely, SDE-ActLearn-POD-KSNN, and SDE-ActLearn-POD-NN. Furthermore, we report positive results for two parametric physical models, highlighting the efficiency of the proposed SDE-AL approach."
      },
      {
        "id": "oai:arXiv.org:2505.00462v1",
        "title": "CORSTITCH - A free, open source software for stitching and georeferencing underwater coral reef videos",
        "link": "https://arxiv.org/abs/2505.00462",
        "author": "Julian Christopher L. Maya, Johnenn R. Manalang, Maricor N. Soriano",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00462v1 Announce Type: cross \nAbstract: CorStitch is an open-source software developed to automate the creation of accurate georeferenced reef mosaics from video transects obtained through Automated Rapid Reef Assessment System surveys. We utilized a Fourier-based image correlation algorithm to stitch sequential video frames, aligning them with synchronized GNSS timestamps. The resulting compressed Keyhole Markup Language files, compatible with geographic information systems such as Google Earth, enable detailed spatial analysis. Validation through comparative analysis of mosaics from two temporally distinct surveys of the same reef demonstrated the software's consistent and reliable performance."
      },
      {
        "id": "oai:arXiv.org:2505.00500v1",
        "title": "Implicit Neural-Representation Learning for Elastic Deformable-Object Manipulations",
        "link": "https://arxiv.org/abs/2505.00500",
        "author": "Minseok Song, JeongHo Ha, Bonggyeong Park, Daehyung Park",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00500v1 Announce Type: cross \nAbstract: We aim to solve the problem of manipulating deformable objects, particularly elastic bands, in real-world scenarios. However, deformable object manipulation (DOM) requires a policy that works on a large state space due to the unlimited degree of freedom (DoF) of deformable objects. Further, their dense but partial observations (e.g., images or point clouds) may increase the sampling complexity and uncertainty in policy learning. To figure it out, we propose a novel implicit neural-representation (INR) learning for elastic DOMs, called INR-DOM. Our method learns consistent state representations associated with partially observable elastic objects reconstructing a complete and implicit surface represented as a signed distance function. Furthermore, we perform exploratory representation fine-tuning through reinforcement learning (RL) that enables RL algorithms to effectively learn exploitable representations while efficiently obtaining a DOM policy. We perform quantitative and qualitative analyses building three simulated environments and real-world manipulation studies with a Franka Emika Panda arm. Videos are available at http://inr-dom.github.io."
      },
      {
        "id": "oai:arXiv.org:2505.00525v1",
        "title": "A Methodological and Structural Review of Parkinsons Disease Detection Across Diverse Data Modalities",
        "link": "https://arxiv.org/abs/2505.00525",
        "author": "Abu Saleh Musa Miah, taro Suzuki, Jungpil Shin",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00525v1 Announce Type: cross \nAbstract: Parkinsons Disease (PD) is a progressive neurological disorder that primarily affects motor functions and can lead to mild cognitive impairment (MCI) and dementia in its advanced stages. With approximately 10 million people diagnosed globally 1 to 1.8 per 1,000 individuals, according to reports by the Japan Times and the Parkinson Foundation early and accurate diagnosis of PD is crucial for improving patient outcomes. While numerous studies have utilized machine learning (ML) and deep learning (DL) techniques for PD recognition, existing surveys are limited in scope, often focusing on single data modalities and failing to capture the potential of multimodal approaches. To address these gaps, this study presents a comprehensive review of PD recognition systems across diverse data modalities, including Magnetic Resonance Imaging (MRI), gait-based pose analysis, gait sensory data, handwriting analysis, speech test data, Electroencephalography (EEG), and multimodal fusion techniques. Based on over 347 articles from leading scientific databases, this review examines key aspects such as data collection methods, settings, feature representations, and system performance, with a focus on recognition accuracy and robustness. This survey aims to serve as a comprehensive resource for researchers, providing actionable guidance for the development of next generation PD recognition systems. By leveraging diverse data modalities and cutting-edge machine learning paradigms, this work contributes to advancing the state of PD diagnostics and improving patient care through innovative, multimodal approaches."
      },
      {
        "id": "oai:arXiv.org:2505.00526v1",
        "title": "Pre-Training Estimators for Structural Models: Application to Consumer Search",
        "link": "https://arxiv.org/abs/2505.00526",
        "author": "Yanhao 'Max' Wei, Zhenling Jiang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00526v1 Announce Type: cross \nAbstract: We explore pretraining estimators for structural econometric models. The estimator is \"pretrained\" in the sense that the bulk of the computational cost and researcher effort occur during the construction of the estimator. Subsequent applications of the estimator to different datasets require little computational cost or researcher effort. The estimation leverages a neural net to recognize the structural model's parameter from data patterns. As an initial trial, this paper builds a pretrained estimator for a sequential search model that is known to be difficult to estimate. We evaluate the pretrained estimator on 14 real datasets. The estimation takes seconds to run and shows high accuracy. We provide the estimator at pnnehome.github.io. More generally, pretrained, off-the-shelf estimators can make structural models more accessible to researchers and practitioners."
      },
      {
        "id": "oai:arXiv.org:2505.00540v1",
        "title": "Emergence of Roles in Robotic Teams with Model Sharing and Limited Communication",
        "link": "https://arxiv.org/abs/2505.00540",
        "author": "Ian O'Flynn, Harun \\v{S}iljak",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00540v1 Announce Type: cross \nAbstract: We present a reinforcement learning strategy for use in multi-agent foraging systems in which the learning is centralised to a single agent and its model is periodically disseminated among the population of non-learning agents. In a domain where multi-agent reinforcement learning (MARL) is the common approach, this approach aims to significantly reduce the computational and energy demands compared to approaches such as MARL and centralised learning models. By developing high performing foraging agents, these approaches can be translated into real-world applications such as logistics, environmental monitoring, and autonomous exploration. A reward function was incorporated into this approach that promotes role development among agents, without explicit directives. This led to the differentiation of behaviours among the agents. The implicit encouragement of role differentiation allows for dynamic actions in which agents can alter roles dependent on their interactions with the environment without the need for explicit communication between agents."
      },
      {
        "id": "oai:arXiv.org:2505.00550v1",
        "title": "Bridging Cultural and Digital Divides: A Low-Latency JackTrip Framework for Equitable Music Education in the Global South",
        "link": "https://arxiv.org/abs/2505.00550",
        "author": "Tiange Zhou, Marco Bidin",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00550v1 Announce Type: cross \nAbstract: The rapid expansion of digital technologies has transformed educational landscapes worldwide, yet significant infrastructural and cultural challenges persist in the Global South. This paper introduces a low-latency JackTrip framework designed to bridge both the cultural and digital divides in music education. By leveraging an open-source, UDP-based audio streaming protocol originally developed at Stanford's CCRMA, the framework is tailored to address technical constraints such as intermittent connectivity, limited bandwidth, and high latency that characterize many rural and underserved regions. The study systematically compares the performance of JackTrip with conventional platforms like Zoom, demonstrating that JackTrip achieves sub-30~ms latency under simulated low-resource conditions while preserving the intricate audio details essential for non-Western musical traditions. Spectral analysis confirms that JackTrip's superior handling of microtonal scales, complex rhythms, and harmonic textures provides a culturally authentic medium for real-time ensemble performance and music education. These findings underscore the transformative potential of decentralized, edge-computing solutions in empowering educators and musicians across the Global South, promoting both technological equity and cultural preservation."
      },
      {
        "id": "oai:arXiv.org:2505.00552v1",
        "title": "Graph Spectral Filtering with Chebyshev Interpolation for Recommendation",
        "link": "https://arxiv.org/abs/2505.00552",
        "author": "Chanwoo Kim, Jinkyu Sung, Yebonn Han, Joonseok Lee",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00552v1 Announce Type: cross \nAbstract: Graph convolutional networks have recently gained prominence in collaborative filtering (CF) for recommendations. However, we identify potential bottlenecks in two foundational components. First, the embedding layer leads to a latent space with limited capacity, overlooking locally observed but potentially valuable preference patterns. Also, the widely-used neighborhood aggregation is limited in its ability to leverage diverse preference patterns in a fine-grained manner. Building on spectral graph theory, we reveal that these limitations stem from graph filtering with a cut-off in the frequency spectrum and a restricted linear form. To address these issues, we introduce ChebyCF, a CF framework based on graph spectral filtering. Instead of a learned embedding, it takes a user's raw interaction history to utilize the full spectrum of signals contained in it. Also, it adopts Chebyshev interpolation to effectively approximate a flexible non-linear graph filter, and further enhances it by using an additional ideal pass filter and degree-based normalization. Through extensive experiments, we verify that ChebyCF overcomes the aforementioned bottlenecks and achieves state-of-the-art performance across multiple benchmarks and reasonably fast inference. Our code is available at https://github.com/chanwoo0806/ChebyCF."
      },
      {
        "id": "oai:arXiv.org:2505.00562v1",
        "title": "TeLoGraF: Temporal Logic Planning via Graph-encoded Flow Matching",
        "link": "https://arxiv.org/abs/2505.00562",
        "author": "Yue Meng, Chuchu Fan",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00562v1 Announce Type: cross \nAbstract: Learning to solve complex tasks with signal temporal logic (STL) specifications is crucial to many real-world applications. However, most previous works only consider fixed or parametrized STL specifications due to the lack of a diverse STL dataset and encoders to effectively extract temporal logic information for downstream tasks. In this paper, we propose TeLoGraF, Temporal Logic Graph-encoded Flow, which utilizes Graph Neural Networks (GNN) encoder and flow-matching to learn solutions for general STL specifications. We identify four commonly used STL templates and collect a total of 200K specifications with paired demonstrations. We conduct extensive experiments in five simulation environments ranging from simple dynamical models in the 2D space to high-dimensional 7DoF Franka Panda robot arm and Ant quadruped navigation. Results show that our method outperforms other baselines in the STL satisfaction rate. Compared to classical STL planning algorithms, our approach is 10-100X faster in inference and can work on any system dynamics. Besides, we show our graph-encoding method's capability to solve complex STLs and robustness to out-distribution STL specifications. Code is available at https://github.com/mengyuest/TeLoGraF"
      },
      {
        "id": "oai:arXiv.org:2505.00571v1",
        "title": "Hypothesis-free discovery from epidemiological data by automatic detection and local inference for tree-based nonlinearities and interactions",
        "link": "https://arxiv.org/abs/2505.00571",
        "author": "Giorgio Spadaccini, Marjolein Fokkema, Mark A. van de Wiel",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00571v1 Announce Type: cross \nAbstract: In epidemiological settings, Machine Learning (ML) is gaining popularity for hypothesis-free discovery of risk (or protective) factors. Although ML is strong at discovering non-linearities and interactions, this power is currently compromised by a lack of reliable inference. Although local measures of feature effect can be combined with tree ensembles, uncertainty quantifications for these measures remain only partially available and oftentimes unsatisfactory. We propose RuleSHAP, a framework for using rule-based, hypothesis-free discovery that combines sparse Bayesian regression, tree ensembles and Shapley values in a one-step procedure that both detects and tests complex patterns at the individual level. To ease computation, we derive a formula that computes marginal Shapley values more efficiently for our setting. We demonstrate the validity of our framework on simulated data. To illustrate, we apply our machinery to data from an epidemiological cohort to detect and infer several effects for high cholesterol and blood pressure, such as nonlinear interaction effects between features like age, sex, ethnicity, BMI and glucose level."
      },
      {
        "id": "oai:arXiv.org:2505.00574v1",
        "title": "Transition States Energies from Machine Learning: An Application to Reverse Water-Gas Shift on Single-Atom Alloys",
        "link": "https://arxiv.org/abs/2505.00574",
        "author": "Raffaele Cheula, Mie Andersen",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00574v1 Announce Type: cross \nAbstract: Obtaining accurate transition state (TS) energies is a bottleneck in computational screening of complex materials and reaction networks due to the high cost of TS search methods and first-principles methods such as density functional theory (DFT). Here we propose a machine learning (ML) model for predicting TS energies based on Gaussian process regression with the Wasserstein Weisfeiler-Lehman graph kernel (WWL-GPR). Applying the model to predict adsorption and TS energies for the reverse water-gas shift (RWGS) reaction on single-atom alloy (SAA) catalysts, we show that it can significantly improve the accuracy compared to traditional approaches based on scaling relations or ML models without a graph representation. Further benefitting from the low cost of model training, we train an ensemble of WWL-GPR models to obtain uncertainties through subsampling of the training data and show how these uncertainties propagate to turnover frequency (TOF) predictions through the construction of an ensemble of microkinetic models. Comparing the errors in model-based vs DFT-based TOF predictions, we show that the WWL-GPR model reduces errors by almost an order of magnitude compared to scaling relations. This demonstrates the critical impact of accurate energy predictions on catalytic activity estimation. Finally, we apply our model to screen new materials, identifying promising catalysts for RWGS. This work highlights the power of combining advanced ML techniques with DFT and microkinetic modeling for screening catalysts for complex reactions like RWGS, providing a robust framework for future catalyst design."
      },
      {
        "id": "oai:arXiv.org:2505.00586v1",
        "title": "ParkDiffusion: Heterogeneous Multi-Agent Multi-Modal Trajectory Prediction for Automated Parking using Diffusion Models",
        "link": "https://arxiv.org/abs/2505.00586",
        "author": "Jiarong Wei, Niclas V\\\"odisch, Anna Rehr, Christian Feist, Abhinav Valada",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00586v1 Announce Type: cross \nAbstract: Automated parking is a critical feature of Advanced Driver Assistance Systems (ADAS), where accurate trajectory prediction is essential to bridge perception and planning modules. Despite its significance, research in this domain remains relatively limited, with most existing studies concentrating on single-modal trajectory prediction of vehicles. In this work, we propose ParkDiffusion, a novel approach that predicts the trajectories of both vehicles and pedestrians in automated parking scenarios. ParkDiffusion employs diffusion models to capture the inherent uncertainty and multi-modality of future trajectories, incorporating several key innovations. First, we propose a dual map encoder that processes soft semantic cues and hard geometric constraints using a two-step cross-attention mechanism. Second, we introduce an adaptive agent type embedding module, which dynamically conditions the prediction process on the distinct characteristics of vehicles and pedestrians. Third, to ensure kinematic feasibility, our model outputs control signals that are subsequently used within a kinematic framework to generate physically feasible trajectories. We evaluate ParkDiffusion on the Dragon Lake Parking (DLP) dataset and the Intersections Drone (inD) dataset. Our work establishes a new baseline for heterogeneous trajectory prediction in parking scenarios, outperforming existing methods by a considerable margin."
      },
      {
        "id": "oai:arXiv.org:2505.00596v1",
        "title": "A Finite-State Controller Based Offline Solver for Deterministic POMDPs",
        "link": "https://arxiv.org/abs/2505.00596",
        "author": "Alex Schutz, Yang You, Matias Mattamala, Ipek Caliskanelli, Bruno Lacerda, Nick Hawes",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00596v1 Announce Type: cross \nAbstract: Deterministic partially observable Markov decision processes (DetPOMDPs) often arise in planning problems where the agent is uncertain about its environmental state but can act and observe deterministically. In this paper, we propose DetMCVI, an adaptation of the Monte Carlo Value Iteration (MCVI) algorithm for DetPOMDPs, which builds policies in the form of finite-state controllers (FSCs). DetMCVI solves large problems with a high success rate, outperforming existing baselines for DetPOMDPs. We also verify the performance of the algorithm in a real-world mobile robot forest mapping scenario."
      },
      {
        "id": "oai:arXiv.org:2505.00625v1",
        "title": "SA-GAT-SR: Self-Adaptable Graph Attention Networks with Symbolic Regression for high-fidelity material property prediction",
        "link": "https://arxiv.org/abs/2505.00625",
        "author": "Liu Junchi, Tang Ying, Tretiak Sergei, Duan Wenhui, Zhou Liujiang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00625v1 Announce Type: cross \nAbstract: Recent advances in machine learning have demonstrated an enormous utility of deep learning approaches, particularly Graph Neural Networks (GNNs) for materials science. These methods have emerged as powerful tools for high-throughput prediction of material properties, offering a compelling enhancement and alternative to traditional first-principles calculations. While the community has predominantly focused on developing increasingly complex and universal models to enhance predictive accuracy, such approaches often lack physical interpretability and insights into materials behavior. Here, we introduce a novel computational paradigm, Self-Adaptable Graph Attention Networks integrated with Symbolic Regression (SA-GAT-SR), that synergistically combines the predictive capability of GNNs with the interpretative power of symbolic regression. Our framework employs a self-adaptable encoding algorithm that automatically identifies and adjust attention weights so as to screen critical features from an expansive 180-dimensional feature space while maintaining O(n) computational scaling. The integrated SR module subsequently distills these features into compact analytical expressions that explicitly reveal quantum-mechanically meaningful relationships, achieving 23 times acceleration compared to conventional SR implementations that heavily rely on first principle calculations-derived features as input. This work suggests a new framework in computational materials science, bridging the gap between predictive accuracy and physical interpretability, offering valuable physical insights into material behavior."
      },
      {
        "id": "oai:arXiv.org:2505.00631v1",
        "title": "Bayes-Optimal Fair Classification with Multiple Sensitive Features",
        "link": "https://arxiv.org/abs/2505.00631",
        "author": "Yi Yang, Yinghui Huang, Xiangyu Chang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00631v1 Announce Type: cross \nAbstract: Existing theoretical work on Bayes-optimal fair classifiers usually considers a single (binary) sensitive feature. In practice, individuals are often defined by multiple sensitive features. In this paper, we characterize the Bayes-optimal fair classifier for multiple sensitive features under general approximate fairness measures, including mean difference and mean ratio. We show that these approximate measures for existing group fairness notions, including Demographic Parity, Equal Opportunity, Predictive Equality, and Accuracy Parity, are linear transformations of selection rates for specific groups defined by both labels and sensitive features. We then characterize that Bayes-optimal fair classifiers for multiple sensitive features become instance-dependent thresholding rules that rely on a weighted sum of these group membership probabilities. Our framework applies to both attribute-aware and attribute-blind settings and can accommodate composite fairness notions like Equalized Odds. Building on this, we propose two practical algorithms for Bayes-optimal fair classification via in-processing and post-processing. We show empirically that our methods compare favorably to existing methods."
      },
      {
        "id": "oai:arXiv.org:2505.00643v1",
        "title": "Deep Learning Assisted Outer Volume Removal for Highly-Accelerated Real-Time Dynamic MRI",
        "link": "https://arxiv.org/abs/2505.00643",
        "author": "Merve G\\\"ulle, Sebastian Weing\\\"artner, Mehmet Ak\\c{c}akaya",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00643v1 Announce Type: cross \nAbstract: Real-time (RT) dynamic MRI plays a vital role in capturing rapid physiological processes, offering unique insights into organ motion and function. Among these applications, RT cine MRI is particularly important for functional assessment of the heart with high temporal resolution. RT imaging enables free-breathing, ungated imaging of cardiac motion, making it a crucial alternative for patients who cannot tolerate conventional breath-hold, ECG-gated acquisitions. However, achieving high acceleration rates in RT cine MRI is challenging due to aliasing artifacts from extra-cardiac tissues, particularly at high undersampling factors. In this study, we propose a novel outer volume removal (OVR) method to address this challenge by eliminating aliasing contributions from non-cardiac regions in a post-processing framework. Our approach estimates the outer volume signal for each timeframe using composite temporal images from time-interleaved undersampling patterns, which inherently contain pseudo-periodic ghosting artifacts. A deep learning (DL) model is trained to identify and remove these artifacts, producing a clean outer volume estimate that is subsequently subtracted from the corresponding k-space data. The final reconstruction is performed with a physics-driven DL (PD-DL) method trained using an OVR-specific loss function to restore high spatio-temporal resolution images. Experimental results show that the proposed method at high accelerations achieves image quality that is visually comparable to clinical baseline images, while outperforming conventional reconstruction techniques, both qualitatively and quantitatively. The proposed approach provides a practical and effective solution for artifact reduction in RT cine MRI without requiring acquisition modifications, offering a pathway to higher acceleration rates while preserving diagnostic quality."
      },
      {
        "id": "oai:arXiv.org:2505.00649v1",
        "title": "Investigating Task Arithmetic for Zero-Shot Information Retrieval",
        "link": "https://arxiv.org/abs/2505.00649",
        "author": "Marco Braga, Pranav Kasela, Alessandro Raganato, Gabriella Pasi",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00649v1 Announce Type: cross \nAbstract: Large Language Models (LLMs) have shown impressive zero-shot performance across a variety of Natural Language Processing tasks, including document re-ranking. However, their effectiveness degrades on unseen tasks and domains, largely due to shifts in vocabulary and word distributions. In this paper, we investigate Task Arithmetic, a technique that combines the weights of LLMs pre-trained on different tasks or domains via simple mathematical operations, such as addition or subtraction, to adapt retrieval models without requiring additional fine-tuning. Our method is able to synthesize diverse tasks and domain knowledge into a single model, enabling effective zero-shot adaptation in different retrieval contexts. Extensive experiments on publicly available scientific, biomedical, and multilingual datasets show that our method improves state-of-the-art re-ranking performance by up to 18% in NDCG@10 and 15% in P@10. In addition to these empirical gains, our analysis provides insights into the strengths and limitations of Task Arithmetic as a practical strategy for zero-shot learning and model adaptation. We make our code publicly available at https://github.com/DetectiveMB/Task-Arithmetic-for-ZS-IR."
      },
      {
        "id": "oai:arXiv.org:2505.00651v1",
        "title": "Open-Source LLM-Driven Federated Transformer for Predictive IoV Management",
        "link": "https://arxiv.org/abs/2505.00651",
        "author": "Yazan Otoum, Arghavan Asad, Ishtiaq Ahmad",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00651v1 Announce Type: cross \nAbstract: The proliferation of connected vehicles within the Internet of Vehicles (IoV) ecosystem presents critical challenges in ensuring scalable, real-time, and privacy-preserving traffic management. Existing centralized IoV solutions often suffer from high latency, limited scalability, and reliance on proprietary Artificial Intelligence (AI) models, creating significant barriers to widespread deployment, particularly in dynamic and privacy-sensitive environments. Meanwhile, integrating Large Language Models (LLMs) in vehicular systems remains underexplored, especially concerning prompt optimization and effective utilization in federated contexts. To address these challenges, we propose the Federated Prompt-Optimized Traffic Transformer (FPoTT), a novel framework that leverages open-source LLMs for predictive IoV management. FPoTT introduces a dynamic prompt optimization mechanism that iteratively refines textual prompts to enhance trajectory prediction. The architecture employs a dual-layer federated learning paradigm, combining lightweight edge models for real-time inference with cloud-based LLMs to retain global intelligence. A Transformer-driven synthetic data generator is incorporated to augment training with diverse, high-fidelity traffic scenarios in the Next Generation Simulation (NGSIM) format. Extensive evaluations demonstrate that FPoTT, utilizing EleutherAI Pythia-1B, achieves 99.86% prediction accuracy on real-world data while maintaining high performance on synthetic datasets. These results underscore the potential of open-source LLMs in enabling secure, adaptive, and scalable IoV management, offering a promising alternative to proprietary solutions in smart mobility ecosystems."
      },
      {
        "id": "oai:arXiv.org:2505.00687v1",
        "title": "GuideSR: Rethinking Guidance for One-Step High-Fidelity Diffusion-Based Super-Resolution",
        "link": "https://arxiv.org/abs/2505.00687",
        "author": "Aditya Arora, Zhengzhong Tu, Yufei Wang, Ruizheng Bai, Jian Wang, Sizhuo Ma",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00687v1 Announce Type: cross \nAbstract: In this paper, we propose GuideSR, a novel single-step diffusion-based image super-resolution (SR) model specifically designed to enhance image fidelity. Existing diffusion-based SR approaches typically adapt pre-trained generative models to image restoration tasks by adding extra conditioning on a VAE-downsampled representation of the degraded input, which often compromises structural fidelity. GuideSR addresses this limitation by introducing a dual-branch architecture comprising: (1) a Guidance Branch that preserves high-fidelity structures from the original-resolution degraded input, and (2) a Diffusion Branch, which a pre-trained latent diffusion model to enhance perceptual quality. Unlike conventional conditioning mechanisms, our Guidance Branch features a tailored structure for image restoration tasks, combining Full Resolution Blocks (FRBs) with channel attention and an Image Guidance Network (IGN) with guided attention. By embedding detailed structural information directly into the restoration pipeline, GuideSR produces sharper and more visually consistent results. Extensive experiments on benchmark datasets demonstrate that GuideSR achieves state-of-the-art performance while maintaining the low computational cost of single-step approaches, with up to 1.39dB PSNR gain on challenging real-world datasets. Our approach consistently outperforms existing methods across various reference-based metrics including PSNR, SSIM, LPIPS, DISTS and FID, further representing a practical advancement for real-world image restoration."
      },
      {
        "id": "oai:arXiv.org:2505.00693v1",
        "title": "Robotic Visual Instruction",
        "link": "https://arxiv.org/abs/2505.00693",
        "author": "Yanbang Li, Ziyang Gong, Haoyang Li, Haoyang Li, Xiaoqi Huang, Haolan Kang, Guangping Bai, Xianzheng Ma",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00693v1 Announce Type: cross \nAbstract: Recently, natural language has been the primary medium for human-robot interaction. However, its inherent lack of spatial precision for robotic control introduces challenges such as ambiguity and verbosity. To address these limitations, we introduce the Robotic Visual Instruction (RoVI), a novel paradigm to guide robotic tasks through an object-centric, hand-drawn symbolic representation. RoVI effectively encodes spatial-temporal information into human-interpretable visual instructions through 2D sketches, utilizing arrows, circles, colors, and numbers to direct 3D robotic manipulation. To enable robots to understand RoVI better and generate precise actions based on RoVI, we present Visual Instruction Embodied Workflow (VIEW), a pipeline formulated for RoVI-conditioned policies. This approach leverages Vision-Language Models (VLMs) to interpret RoVI inputs, decode spatial and temporal constraints from 2D pixel space via keypoint extraction, and then transform them into executable 3D action sequences. We additionally curate a specialized dataset of 15K instances to fine-tune small VLMs for edge deployment, enabling them to effectively learn RoVI capabilities. Our approach is rigorously validated across 11 novel tasks in both real and simulated environments, demonstrating significant generalization capability. Notably, VIEW achieves an 87.5% success rate in real-world scenarios involving unseen tasks that feature multi-step actions, with disturbances, and trajectory-following requirements. Code and Datasets in this paper will be released soon."
      },
      {
        "id": "oai:arXiv.org:2505.00704v1",
        "title": "Controllable Weather Synthesis and Removal with Video Diffusion Models",
        "link": "https://arxiv.org/abs/2505.00704",
        "author": "Chih-Hao Lin, Zian Wang, Ruofan Liang, Yuxuan Zhang, Sanja Fidler, Shenlong Wang, Zan Gojcic",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00704v1 Announce Type: cross \nAbstract: Generating realistic and controllable weather effects in videos is valuable for many applications. Physics-based weather simulation requires precise reconstructions that are hard to scale to in-the-wild videos, while current video editing often lacks realism and control. In this work, we introduce WeatherWeaver, a video diffusion model that synthesizes diverse weather effects -- including rain, snow, fog, and clouds -- directly into any input video without the need for 3D modeling. Our model provides precise control over weather effect intensity and supports blending various weather types, ensuring both realism and adaptability. To overcome the scarcity of paired training data, we propose a novel data strategy combining synthetic videos, generative image editing, and auto-labeled real-world videos. Extensive evaluations show that our method outperforms state-of-the-art methods in weather simulation and removal, providing high-quality, physically plausible, and scene-identity-preserving results over various real-world videos."
      },
      {
        "id": "oai:arXiv.org:2211.09619v5",
        "title": "Introduction to Online Control",
        "link": "https://arxiv.org/abs/2211.09619",
        "author": "Elad Hazan, Karan Singh",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2211.09619v5 Announce Type: replace \nAbstract: This text presents an introduction to an emerging paradigm in control of dynamical systems and differentiable reinforcement learning called online nonstochastic control. The new approach applies techniques from online convex optimization and convex relaxations to obtain new methods with provable guarantees for classical settings in optimal and robust control.\n  The primary distinction between online nonstochastic control and other frameworks is the objective. In optimal control, robust control, and other control methodologies that assume stochastic noise, the goal is to perform comparably to an offline optimal strategy. In online nonstochastic control, both the cost functions as well as the perturbations from the assumed dynamical model are chosen by an adversary. Thus the optimal policy is not defined a priori. Rather, the target is to attain low regret against the best policy in hindsight from a benchmark class of policies.\n  This objective suggests the use of the decision making framework of online convex optimization as an algorithmic methodology. The resulting methods are based on iterative mathematical optimization algorithms, and are accompanied by finite-time regret and computational complexity guarantees."
      },
      {
        "id": "oai:arXiv.org:2301.13565v2",
        "title": "Learning Against Distributional Uncertainty: On the Trade-off Between Robustness and Specificity",
        "link": "https://arxiv.org/abs/2301.13565",
        "author": "Shixiong Wang, Haowei Wang, Xinke Li, Jean Honorio",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2301.13565v2 Announce Type: replace \nAbstract: Trustworthy machine learning aims at combating distributional uncertainties in training data distributions compared to population distributions. Typical treatment frameworks include the Bayesian approach, (min-max) distributionally robust optimization (DRO), and regularization. However, three issues have to be raised: 1) the prior distribution in the Bayesian method and the regularizer in the regularization method are difficult to specify; 2) the DRO method tends to be overly conservative; 3) all the three methods are biased estimators of the true optimal cost. This paper studies a new framework that unifies the three approaches and addresses the three challenges above. The asymptotic properties (e.g., consistencies and asymptotic normalities), non-asymptotic properties (e.g., generalization bounds and unbiasedness), and solution methods of the proposed model are studied. The new model reveals the trade-off between the robustness to the unseen data and the specificity to the training data. Experiments on various real-world tasks validate the superiority of the proposed learning framework."
      },
      {
        "id": "oai:arXiv.org:2303.12675v3",
        "title": "VecFontSDF: Learning to Reconstruct and Synthesize High-quality Vector Fonts via Signed Distance Functions",
        "link": "https://arxiv.org/abs/2303.12675",
        "author": "Zeqing Xia, Bojun Xiong, Zhouhui Lian",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2303.12675v3 Announce Type: replace \nAbstract: Font design is of vital importance in the digital content design and modern printing industry. Developing algorithms capable of automatically synthesizing vector fonts can significantly facilitate the font design process. However, existing methods mainly concentrate on raster image generation, and only a few approaches can directly synthesize vector fonts. This paper proposes an end-to-end trainable method, VecFontSDF, to reconstruct and synthesize high-quality vector fonts using signed distance functions (SDFs). Specifically, based on the proposed SDF-based implicit shape representation, VecFontSDF learns to model each glyph as shape primitives enclosed by several parabolic curves, which can be precisely converted to quadratic B\\'ezier curves that are widely used in vector font products. In this manner, most image generation methods can be easily extended to synthesize vector fonts. Qualitative and quantitative experiments conducted on a publicly-available dataset demonstrate that our method obtains high-quality results on several tasks, including vector font reconstruction, interpolation, and few-shot vector font synthesis, markedly outperforming the state of the art. Our code and trained models are available at https://xiazeqing.github.io/VecFontSDF."
      },
      {
        "id": "oai:arXiv.org:2303.15201v2",
        "title": "Learning An Active Inference Model of Driver Perception and Control: Application to Vehicle Car-Following",
        "link": "https://arxiv.org/abs/2303.15201",
        "author": "Ran Wei, Anthony D. McDonald, Alfredo Garcia, Gustav Markkula, Johan Engstrom, Matthew O'Kelly",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2303.15201v2 Announce Type: replace \nAbstract: In this paper we introduce a general estimation methodology for learning a model of human perception and control in a sensorimotor control task based upon a finite set of demonstrations. The model's structure consists of i the agent's internal representation of how the environment and associated observations evolve as a result of control actions and ii the agent's preferences over observable outcomes. We consider a model's structure specification consistent with active inference, a theory of human perception and behavior from cognitive science. According to active inference, the agent acts upon the world so as to minimize surprise defined as a measure of the extent to which an agent's current sensory observations differ from its preferred sensory observations. We propose a bi-level optimization approach to estimation which relies on a structural assumption on prior distributions that parameterize the statistical accuracy of the human agent's model of the environment. To illustrate the proposed methodology, we present the estimation of a model for car-following behavior based upon a naturalistic dataset. Overall, the results indicate that learning active inference models of human perception and control from data is a promising alternative to black-box models of driving."
      },
      {
        "id": "oai:arXiv.org:2309.08035v2",
        "title": "Interpretability-Aware Vision Transformer",
        "link": "https://arxiv.org/abs/2309.08035",
        "author": "Yao Qiang, Chengyin Li, Prashant Khanduri, Dongxiao Zhu",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2309.08035v2 Announce Type: replace \nAbstract: Vision Transformers (ViTs) have become prominent models for solving various vision tasks. However, the interpretability of ViTs has not kept pace with their promising performance. While there has been a surge of interest in developing {\\it post hoc} solutions to explain ViTs' outputs, these methods do not generalize to different downstream tasks and various transformer architectures. Furthermore, if ViTs are not properly trained with the given data and do not prioritize the region of interest, the {\\it post hoc} methods would be less effective. Instead of developing another {\\it post hoc} approach, we introduce a novel training procedure that inherently enhances model interpretability. Our interpretability-aware ViT (IA-ViT) draws inspiration from a fresh insight: both the class patch and image patches consistently generate predicted distributions and attention maps. IA-ViT is composed of a feature extractor, a predictor, and an interpreter, which are trained jointly with an interpretability-aware training objective. Consequently, the interpreter simulates the behavior of the predictor and provides a faithful explanation through its single-head self-attention mechanism. Our comprehensive experimental results demonstrate the effectiveness of IA-ViT in several image classification tasks, with both qualitative and quantitative evaluations of model performance and interpretability. Source code is available from: https://github.com/qiangyao1988/IA-ViT."
      },
      {
        "id": "oai:arXiv.org:2309.08532v3",
        "title": "EvoPrompt: Connecting LLMs with Evolutionary Algorithms Yields Powerful Prompt Optimizers",
        "link": "https://arxiv.org/abs/2309.08532",
        "author": "Qingyan Guo, Rui Wang, Junliang Guo, Bei Li, Kaitao Song, Xu Tan, Guoqing Liu, Jiang Bian, Yujiu Yang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2309.08532v3 Announce Type: replace \nAbstract: Large Language Models (LLMs) excel in various tasks, but they rely on carefully crafted prompts that often demand substantial human effort. To automate this process, in this paper, we propose a novel framework for discrete prompt optimization, called EvoPrompt, which borrows the idea of evolutionary algorithms (EAs) as they exhibit good performance and fast convergence. To enable EAs to work on discrete prompts, which are natural language expressions that need to be coherent and human-readable, we connect LLMs with EAs. This approach allows us to simultaneously leverage the powerful language processing capabilities of LLMs and the efficient optimization performance of EAs. Specifically, abstaining from any gradients or parameters, EvoPrompt starts from a population of prompts and iteratively generates new prompts with LLMs based on the evolutionary operators, improving the population based on the development set. We optimize prompts for both closed- and open-source LLMs including GPT-3.5 and Alpaca, on 31 datasets covering language understanding, generation tasks, as well as BIG-Bench Hard (BBH) tasks. EvoPrompt significantly outperforms human-engineered prompts and existing methods for automatic prompt generation (e.g., up to 25% on BBH). Furthermore, EvoPrompt demonstrates that connecting LLMs with EAs creates synergies, which could inspire further research on the combination of LLMs and conventional algorithms."
      },
      {
        "id": "oai:arXiv.org:2311.06840v4",
        "title": "Omitted Labels Induce Nontransitive Paradoxes in Causality",
        "link": "https://arxiv.org/abs/2311.06840",
        "author": "Bijan Mazaheri, Siddharth Jain, Matthew Cook, Jehoshua Bruck",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2311.06840v4 Announce Type: replace \nAbstract: We explore \"omitted label contexts,\" in which training data is limited to a subset of the possible labels. This setting is standard among specialized human experts or specific, focused studies. By studying Simpson's paradox, we observe that ``correct'' adjustments sometimes require non-exchangeable treatment and control groups. A generalization of Simpson's paradox leads us to study networks of conclusions drawn from different contexts, within which a paradox of nontransitivity arises. We prove that the space of possible nontransitive structures in these networks exactly corresponds to structures that form from aggregating ranked-choice votes."
      },
      {
        "id": "oai:arXiv.org:2311.08786v2",
        "title": "Disentangle Before Anonymize: A Two-stage Framework for Attribute-preserved and Occlusion-robust De-identification",
        "link": "https://arxiv.org/abs/2311.08786",
        "author": "Mingrui Zhu, Dongxin Chen, Xin Wei, Nannan Wang, Xinbo Gao",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2311.08786v2 Announce Type: replace \nAbstract: In an era where personal photos are easily leaked and collected, face de-identification is a crucial method for protecting identity privacy. However, current face de-identification techniques face challenges in preserving attribute details and often produce anonymized results with reduced authenticity. These shortcomings are particularly evident when handling occlusions,frequently resulting in noticeable editing artifacts. Our primary finding in this work is that simultaneous training of identity disentanglement and anonymization hinders their respective effectiveness.Therefore, we propose \"Disentangle Before Anonymize\",a novel two-stage Framework(DBAF)designed for attributepreserved and occlusion-robust de-identification. This framework includes a Contrastive Identity Disentanglement (CID) module and a Key-authorized Reversible Identity Anonymization (KRIA) module, achieving faithful attribute preservation and high-quality identity anonymization edits. Additionally, we introduce a Multiscale Attentional Attribute Retention (MAAR) module to address the issue of reduced anonymization quality under occlusions.Extensive experiments demonstrate that our method outperforms state-of-the-art de-identification approaches, delivering superior quality, enhanced detail fidelity, improved attribute preservation performance, and greater robustness to occlusions."
      },
      {
        "id": "oai:arXiv.org:2311.14090v2",
        "title": "Class Uncertainty: A Measure to Mitigate Class Imbalance",
        "link": "https://arxiv.org/abs/2311.14090",
        "author": "Z. S. Baltaci, K. Oksuz, S. Kuzucu, K. Tezoren, B. K. Konar, A. Ozkan, E. Akbas, S. Kalkan",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2311.14090v2 Announce Type: replace \nAbstract: Class-wise characteristics of training examples affect the performance of deep classifiers. A well-studied example is when the number of training examples of classes follows a long-tailed distribution, a situation that is likely to yield sub-optimal performance for under-represented classes. This class imbalance problem is conventionally addressed by approaches relying on the class-wise cardinality of training examples, such as data resampling. In this paper, we demonstrate that considering solely the cardinality of classes does not cover all issues causing class imbalance. To measure class imbalance, we propose \"Class Uncertainty\" as the average predictive uncertainty of the training examples, and we show that this novel measure captures the differences across classes better than cardinality. We also curate SVCI-20 as a novel dataset in which the classes have equal number of training examples but they differ in terms of their hardness; thereby causing a type of class imbalance which cannot be addressed by the approaches relying on cardinality. We incorporate our \"Class Uncertainty\" measure into a diverse set of ten class imbalance mitigation methods to demonstrate its effectiveness on long-tailed datasets as well as on our SVCI-20. Code and datasets will be made available."
      },
      {
        "id": "oai:arXiv.org:2312.12028v5",
        "title": "EyePreserve: Identity-Preserving Iris Synthesis",
        "link": "https://arxiv.org/abs/2312.12028",
        "author": "Siamul Karim Khan, Patrick Tinsley, Mahsa Mitcheff, Patrick Flynn, Kevin W. Bowyer, Adam Czajka",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2312.12028v5 Announce Type: replace \nAbstract: Synthesis of same-identity biometric iris images, both for existing and non-existing identities while preserving the identity across a wide range of pupil sizes, is complex due to the intricate iris muscle constriction mechanism, requiring a precise model of iris non-linear texture deformations to be embedded into the synthesis pipeline. This paper presents the first method of fully data-driven, identity-preserving, pupil size-varying synthesis of iris images. This approach is capable of synthesizing images of irises with different pupil sizes representing non-existing identities, as well as non-linearly deforming the texture of iris images of existing subjects given the segmentation mask of the target iris image. Iris recognition experiments suggest that the proposed deformation model both preserves the identity when changing the pupil size, and offers better similarity between same-identity iris samples with significant differences in pupil size, compared to state-of-the-art linear and non-linear (bio-mechanical-based) iris deformation models. Two immediate applications of the proposed approach are: (a) synthesis of, or enhancement of the existing biometric datasets for iris recognition, mimicking those acquired with iris sensors, and (b) helping forensic human experts examine iris image pairs with significant differences in pupil dilation. Images considered in this work conform to selected ISO/IEC 29794-6 quality metrics to make them applicable in biometric systems. The source codes and model weights are offered with this paper."
      },
      {
        "id": "oai:arXiv.org:2312.12419v2",
        "title": "Scene-Conditional 3D Object Stylization and Composition",
        "link": "https://arxiv.org/abs/2312.12419",
        "author": "Jinghao Zhou, Tomas Jakab, Philip Torr, Christian Rupprecht",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2312.12419v2 Announce Type: replace \nAbstract: Recently, 3D generative models have made impressive progress, enabling the generation of almost arbitrary 3D assets from text or image inputs. However, these approaches generate objects in isolation without any consideration for the scene where they will eventually be placed. In this paper, we propose a framework that allows for the stylization of an existing 3D asset to fit into a given 2D scene, and additionally produce a photorealistic composition as if the asset was placed within the environment. This not only opens up a new level of control for object stylization, for example, the same assets can be stylized to reflect changes in the environment, such as summer to winter or fantasy versus futuristic settings-but also makes the object-scene composition more controllable. We achieve this by combining modeling and optimizing the object's texture and environmental lighting through differentiable ray tracing with image priors from pre-trained text-to-image diffusion models. We demonstrate that our method is applicable to a wide variety of indoor and outdoor scenes and arbitrary objects. Project page: https://jensenzhoujh.github.io/scene-cond-3d/."
      },
      {
        "id": "oai:arXiv.org:2401.03048v3",
        "title": "Latte: Latent Diffusion Transformer for Video Generation",
        "link": "https://arxiv.org/abs/2401.03048",
        "author": "Xin Ma, Yaohui Wang, Xinyuan Chen, Gengyun Jia, Ziwei Liu, Yuan-Fang Li, Cunjian Chen, Yu Qiao",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2401.03048v3 Announce Type: replace \nAbstract: We propose Latte, a novel Latent Diffusion Transformer for video generation. Latte first extracts spatio-temporal tokens from input videos and then adopts a series of Transformer blocks to model video distribution in the latent space. In order to model a substantial number of tokens extracted from videos, four efficient variants are introduced from the perspective of decomposing the spatial and temporal dimensions of input videos. To improve the quality of generated videos, we determine the best practices of Latte through rigorous experimental analysis, including video clip patch embedding, model variants, timestep-class information injection, temporal positional embedding, and learning strategies. Our comprehensive evaluation demonstrates that Latte achieves state-of-the-art performance across four standard video generation datasets, i.e., FaceForensics, SkyTimelapse, UCF101, and Taichi-HD. In addition, we extend Latte to the text-to-video generation (T2V) task, where Latte achieves results that are competitive with recent T2V models. We strongly believe that Latte provides valuable insights for future research on incorporating Transformers into diffusion models for video generation."
      },
      {
        "id": "oai:arXiv.org:2401.15371v4",
        "title": "LegalDuet: Learning Fine-grained Representations for Legal Judgment Prediction via a Dual-View Contrastive Learning",
        "link": "https://arxiv.org/abs/2401.15371",
        "author": "Buqiang Xu, Xin Dai, Zhenghao Liu, Huiyuan Xie, Xiaoyuan Yi, Shuo Wang, Yukun Yan, Liner Yang, Yu Gu, Ge Yu",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2401.15371v4 Announce Type: replace \nAbstract: Legal Judgment Prediction (LJP) is a fundamental task of legal artificial intelligence, aiming to automatically predict the judgment outcomes of legal cases. Existing LJP models primarily focus on identifying legal triggers within criminal fact descriptions by contrastively training language models. However, these LJP models overlook the importance of learning to effectively distinguish subtle differences among judgments, which is crucial for producing more accurate predictions. In this paper, we propose LegalDuet, which continuously pretrains language models to learn a more tailored embedding space for representing legal cases. Specifically, LegalDuet designs a dual-view mechanism to continuously pretrain language models: 1) Law Case Clustering retrieves similar cases as hard negatives and employs contrastive training to differentiate among confusing cases; 2) Legal Decision Matching aims to identify legal clues within criminal fact descriptions to align them with the chain of reasoning that contains the correct legal decision. Our experiments on the CAIL2018 dataset demonstrate the effectiveness of LegalDuet. Further analysis reveals that LegalDuet improves the ability of pretrained language models to distinguish confusing criminal charges by reducing prediction uncertainty and enhancing the separability of criminal charges. The experiments demonstrate that LegalDuet produces a more concentrated and distinguishable embedding space, effectively aligning criminal facts with corresponding legal decisions. The code is available at https://github.com/NEUIR/LegalDuet."
      },
      {
        "id": "oai:arXiv.org:2402.07033v3",
        "title": "Fiddler: CPU-GPU Orchestration for Fast Inference of Mixture-of-Experts Models",
        "link": "https://arxiv.org/abs/2402.07033",
        "author": "Keisuke Kamahori, Tian Tang, Yile Gu, Kan Zhu, Baris Kasikci",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2402.07033v3 Announce Type: replace \nAbstract: Large Language Models (LLMs) with the Mixture-of-Experts (MoE) architectures have shown promising performance on various tasks. However, due to the huge model sizes, running them in resource-constrained environments where the GPU memory is not abundant is challenging. Some existing systems propose to use CPU resources to solve that, but they either suffer from the significant overhead of frequently moving data between CPU and GPU, or fail to consider distinct characteristics of CPUs and GPUs. This paper proposes Fiddler, a resource-efficient inference system for MoE models with limited GPU resources. Fiddler strategically utilizes CPU and GPU resources by determining the optimal execution strategy. Our evaluation shows that, unlike state-of-the-art systems that optimize for specific scenarios such as single batch inference or long prefill, Fiddler performs better in all scenarios. Compared against different baselines, Fiddler achieves 1.26 times speed up in single batch inference, 1.30 times in long prefill processing, and 11.57 times in beam search inference. The code of Fiddler is publicly available at https://github.com/efeslab/fiddler."
      },
      {
        "id": "oai:arXiv.org:2402.08498v5",
        "title": "\"Reasoning\" with Rhetoric: On the Style-Evidence Tradeoff in LLM-Generated Counter-Arguments",
        "link": "https://arxiv.org/abs/2402.08498",
        "author": "Preetika Verma, Kokil Jaidka, Svetlana Churina",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2402.08498v5 Announce Type: replace \nAbstract: Large language models (LLMs) play a key role in generating evidence-based and stylistic counter-arguments, yet their effectiveness in real-world applications has been underexplored. Previous research often neglects the balance between evidentiality and style, which are crucial for persuasive arguments. To address this, we evaluated the effectiveness of stylized evidence-based counter-argument generation in Counterfire, a new dataset of 38,000 counter-arguments generated by revising counter-arguments to Reddit's ChangeMyView community to follow different discursive styles. We evaluated generic and stylized counter-arguments from basic and fine-tuned models such as GPT-3.5, PaLM-2, and Koala-13B, as well as newer models (GPT-4o, Claude Haiku, LLaMA-3.1) focusing on rhetorical quality and persuasiveness. Our findings reveal that humans prefer stylized counter-arguments over the original outputs, with GPT-3.5 Turbo performing well, though still not reaching human standards of rhetorical quality nor persuasiveness. Additionally, our work created a novel argument triplets dataset for studying style control, with human preference labels that provide insights into the tradeoffs between evidence integration and argument quality."
      },
      {
        "id": "oai:arXiv.org:2402.13393v3",
        "title": "Fairness Risks for Group-conditionally Missing Demographics",
        "link": "https://arxiv.org/abs/2402.13393",
        "author": "Kaiqi Jiang, Wenzhe Fan, Mao Li, Xinhua Zhang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2402.13393v3 Announce Type: replace \nAbstract: Fairness-aware classification models have gained increasing attention in recent years as concerns grow on discrimination against some demographic groups. Most existing models require full knowledge of the sensitive features, which can be impractical due to privacy, legal issues, and an individual's fear of discrimination. The key challenge we will address is the group dependency of the unavailability, e.g., people of some age range may be more reluctant to reveal their age. Our solution augments general fairness risks with probabilistic imputations of the sensitive features, while jointly learning the group-conditionally missing probabilities in a variational auto-encoder. Our model is demonstrated effective on both image and tabular datasets, achieving an improved balance between accuracy and fairness."
      },
      {
        "id": "oai:arXiv.org:2402.14410v3",
        "title": "A new sociology of humans and machines",
        "link": "https://arxiv.org/abs/2402.14410",
        "author": "Milena Tsvetkova, Taha Yasseri, Niccolo Pescetelli, Tobias Werner",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2402.14410v3 Announce Type: replace \nAbstract: From fake social media accounts and generative artificial intelligence chatbots to trading algorithms and self-driving vehicles, robots, bots and algorithms are proliferating and permeating our communication channels, social interactions, economic transactions and transportation arteries. Networks of multiple interdependent and interacting humans and intelligent machines constitute complex social systems for which the collective outcomes cannot be deduced from either human or machine behaviour alone. Under this paradigm, we review recent research and identify general dynamics and patterns in situations of competition, coordination, cooperation, contagion and collective decision-making, with context-rich examples from high-frequency trading markets, a social media platform, an open collaboration community and a discussion forum. To ensure more robust and resilient human-machine communities, we require a new sociology of humans and machines. Researchers should study these communities using complex system methods; engineers should explicitly design artificial intelligence for human-machine and machine-machine interactions; and regulators should govern the ecological diversity and social co-development of humans and machines."
      },
      {
        "id": "oai:arXiv.org:2403.16677v3",
        "title": "FOOL: Addressing the Downlink Bottleneck in Satellite Computing with Neural Feature Compression",
        "link": "https://arxiv.org/abs/2403.16677",
        "author": "Alireza Furutanpey, Qiyang Zhang, Philipp Raith, Tobias Pfandzelter, Shangguang Wang, Schahram Dustdar",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2403.16677v3 Announce Type: replace \nAbstract: Nanosatellite constellations equipped with sensors capturing large geographic regions provide unprecedented opportunities for Earth observation. As constellation sizes increase, network contention poses a downlink bottleneck. Orbital Edge Computing (OEC) leverages limited onboard compute resources to reduce transfer costs by processing the raw captures at the source. However, current solutions have limited practicability due to reliance on crude filtering methods or over-prioritizing particular downstream tasks. This work presents FOOL, an OEC-native and task-agnostic feature compression method that preserves prediction performance. FOOL partitions high-resolution satellite imagery to maximize throughput. Further, it embeds context and leverages inter-tile dependencies to lower transfer costs with negligible overhead. While FOOL is a feature compressor, it can recover images with competitive scores on quality measures at lower bitrates. We extensively evaluate transfer cost reduction by including the peculiarity of intermittently available network connections in low earth orbit. Lastly, we test the feasibility of our system for standardized nanosatellite form factors. We demonstrate that FOOL permits downlinking over 100x the data volume without relying on prior information on the downstream tasks."
      },
      {
        "id": "oai:arXiv.org:2404.17525v3",
        "title": "Large Language Model Agent as a Mechanical Designer",
        "link": "https://arxiv.org/abs/2404.17525",
        "author": "Yayati Jadhav, Amir Barati Farimani",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2404.17525v3 Announce Type: replace \nAbstract: Conventional mechanical design follows an iterative process in which initial concepts are refined through cycles of expert assessment and resource-intensive Finite Element Method (FEM) analysis to meet performance goals. While machine learning models have been developed to assist in parts of this process, they typically require large datasets, extensive training, and are often tailored to specific tasks, limiting their generalizability. To address these limitations, we propose a framework that leverages a pretrained Large Language Model (LLM) in conjunction with an FEM module to autonomously generate, evaluate, and refine structural designs based on performance specifications and numerical feedback. The LLM operates without domain-specific fine-tuning, using general reasoning to propose design candidates, interpret FEM-derived performance metrics, and apply structurally sound modifications. Using 2D truss structures as a testbed, we show that the LLM can effectively navigate highly discrete and multi-faceted design spaces, balance competing objectives, and identify convergence when further optimization yields diminishing returns. Compared to Non-dominated Sorting Genetic Algorithm II (NSGA-II), our method achieves faster convergence and fewer FEM evaluations. Experiments with varying temperature settings (0.5, 1.0, 1.2) and model sizes (GPT-4.1 and GPT-4.1-mini) indicate that smaller models yield higher constraint satisfaction with fewer steps, while lower temperatures enhance design consistency. These results establish LLMs as a promising new class of reasoning-based, natural language-driven optimizers for autonomous design and iterative structural refinement."
      },
      {
        "id": "oai:arXiv.org:2405.00507v3",
        "title": "F2M-Reg: Unsupervised RGB-D Point Cloud Registration with Frame-to-Model Optimization",
        "link": "https://arxiv.org/abs/2405.00507",
        "author": "Zhinan Yu, Zheng Qin, Yijie Tang, Yongjun Wang, Renjiao Yi, Chenyang Zhu, Kai Xu",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2405.00507v3 Announce Type: replace \nAbstract: This work studies the problem of unsupervised RGB-D point cloud registration, which aims at training a robust registration model without ground-truth pose supervision. Existing methods usually leverages unposed RGB-D sequences and adopt a frame-to-frame framework based on differentiable rendering to train the registration model, which enforces the photometric and geometric consistency between the two frames for supervision. However, this frame-to-frame framework is vulnerable to inconsistent factors between different frames, e.g., lighting changes, geometry occlusion, and reflective materials, which leads to suboptimal convergence of the registration model. In this paper, we propose a novel frame-to-model optimization framework named F2M-Reg for unsupervised RGB-D point cloud registration. We leverage the neural implicit field as a global model of the scene and optimize the estimated poses of the frames by registering them to the global model, and the registration model is subsequently trained with the optimized poses. Thanks to the global encoding capability of neural implicit field, our frame-to-model framework is significantly more robust to inconsistent factors between different frames and thus can provide better supervision for the registration model. Besides, we demonstrate that F2M-Reg can be further enhanced by a simplistic synthetic warming-up strategy. To this end, we construct a photorealistic synthetic dataset named Sim-RGBD to initialize the registration model for the frame-to-model optimization on real-world RGB-D sequences. Extensive experiments on four challenging benchmarks have shown that our method surpasses the previous state-of-the-art counterparts by a large margin, especially under scenarios with severe lighting changes and low overlap. Our code and models are available at https://github.com/MrIsland/F2M_Reg."
      },
      {
        "id": "oai:arXiv.org:2405.04489v2",
        "title": "S3Former: Self-supervised High-resolution Transformer for Solar PV Profiling",
        "link": "https://arxiv.org/abs/2405.04489",
        "author": "Minh Tran, Adrian De Luis, Haitao Liao, Ying Huang, Roy McCann, Alan Mantooth, Jack Cothren, Ngan Le",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2405.04489v2 Announce Type: replace \nAbstract: As the impact of climate change escalates, the global necessity to transition to sustainable energy sources becomes increasingly evident. Renewable energies have emerged as a viable solution for users, with Photovoltaic energy being a favored choice for small installations due to its reliability and efficiency. Accurate mapping of PV installations is crucial for understanding the extension of its adoption and informing energy policy. To meet this need, we introduce S3Former, designed to segment solar panels from aerial imagery and provide size and location information critical for analyzing the impact of such installations on the grid. Solar panel identification is challenging due to factors such as varying weather conditions, roof characteristics, Ground Sampling Distance variations and lack of appropriate initialization weights for optimized training. To tackle these complexities, S3Former features a Masked Attention Mask Transformer incorporating a self-supervised learning pretrained backbone. Specifically, our model leverages low-level and high-level features extracted from the backbone and incorporates an instance query mechanism incorporated on the Transformer architecture to enhance the localization of solar PV installations. We introduce a self-supervised learning phase (pretext task) to improve the initialization weights on the backbone of S3Former. We evaluated S3Former using diverse datasets, demonstrate improvement state-of-the-art models."
      },
      {
        "id": "oai:arXiv.org:2405.04532v3",
        "title": "QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving",
        "link": "https://arxiv.org/abs/2405.04532",
        "author": "Yujun Lin, Haotian Tang, Shang Yang, Zhekai Zhang, Guangxuan Xiao, Chuang Gan, Song Han",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2405.04532v3 Announce Type: replace \nAbstract: Quantization can accelerate large language model (LLM) inference. Going beyond INT8 quantization, the research community is actively exploring even lower precision, such as INT4. Nonetheless, state-of-the-art INT4 quantization techniques only accelerate low-batch, edge LLM inference, failing to deliver performance gains in large-batch, cloud-based LLM serving. We uncover a critical issue: existing INT4 quantization methods suffer from significant runtime overhead (20-90%) when dequantizing either weights or partial sums on GPUs. To address this challenge, we introduce QoQ, a W4A8KV4 quantization algorithm with 4-bit weight, 8-bit activation, and 4-bit KV cache. QoQ stands for quattuor-octo-quattuor, which represents 4-8-4 in Latin. QoQ is implemented by the QServe inference library that achieves measured speedup. The key insight driving QServe is that the efficiency of LLM serving on GPUs is critically influenced by operations on low-throughput CUDA cores. Building upon this insight, in QoQ algorithm, we introduce progressive quantization that can allow low dequantization overhead in W4A8 GEMM. Additionally, we develop SmoothAttention to effectively mitigate the accuracy degradation incurred by 4-bit KV quantization. In the QServe system, we perform compute-aware weight reordering and take advantage of register-level parallelism to reduce dequantization latency. We also make fused attention memory-bound, harnessing the performance gain brought by KV4 quantization. As a result, QServe improves the maximum achievable serving throughput of Llama-3-8B by 1.2x on A100, 1.4x on L40S; and Qwen1.5-72B by 2.4x on A100, 3.5x on L40S, compared to TensorRT-LLM. Remarkably, QServe on L40S GPU can achieve even higher throughput than TensorRT-LLM on A100. Thus, QServe effectively reduces the dollar cost of LLM serving by 3x. Code is available at https://github.com/mit-han-lab/omniserve."
      },
      {
        "id": "oai:arXiv.org:2405.11536v4",
        "title": "RobMOT: Robust 3D Multi-Object Tracking by Observational Noise and State Estimation Drift Mitigation on LiDAR PointCloud",
        "link": "https://arxiv.org/abs/2405.11536",
        "author": "Mohamed Nagy, Naoufel Werghi, Bilal Hassan, Jorge Dias, Majid Khonji",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2405.11536v4 Announce Type: replace \nAbstract: This paper addresses limitations in 3D tracking-by-detection methods, particularly in identifying legitimate trajectories and reducing state estimation drift in Kalman filters. Existing methods often use threshold-based filtering for detection scores, which can fail for distant and occluded objects, leading to false positives. To tackle this, we propose a novel track validity mechanism and multi-stage observational gating process, significantly reducing ghost tracks and enhancing tracking performance. Our method achieves a $29.47\\%$ improvement in Multi-Object Tracking Accuracy (MOTA) on the KITTI validation dataset with the Second detector. Additionally, a refined Kalman filter term reduces localization noise, improving higher-order tracking accuracy (HOTA) by $4.8\\%$. The online framework, RobMOT, outperforms state-of-the-art methods across multiple detectors, with HOTA improvements of up to $3.92\\%$ on the KITTI testing dataset and $8.7\\%$ on the validation dataset, while achieving low identity switch scores. RobMOT excels in challenging scenarios, tracking distant objects and prolonged occlusions, with a $1.77\\%$ MOTA improvement on the Waymo Open dataset, and operates at a remarkable 3221 FPS on a single CPU, proving its efficiency for real-time multi-object tracking."
      },
      {
        "id": "oai:arXiv.org:2405.11804v2",
        "title": "(Perhaps) Beyond Human Translation: Harnessing Multi-Agent Collaboration for Translating Ultra-Long Literary Texts",
        "link": "https://arxiv.org/abs/2405.11804",
        "author": "Minghao Wu, Jiahao Xu, Yulin Yuan, Gholamreza Haffari, Longyue Wang, Weihua Luo, Kaifu Zhang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2405.11804v2 Announce Type: replace \nAbstract: Literary translation remains one of the most challenging frontiers in machine translation due to the complexity of capturing figurative language, cultural nuances, and unique stylistic elements. In this work, we introduce TransAgents, a novel multi-agent framework that simulates the roles and collaborative practices of a human translation company, including a CEO, Senior Editor, Junior Editor, Translator, Localization Specialist, and Proofreader. The translation process is divided into two stages: a preparation stage where the team is assembled and comprehensive translation guidelines are drafted, and an execution stage that involves sequential translation, localization, proofreading, and a final quality check. Furthermore, we propose two innovative evaluation strategies: Monolingual Human Preference (MHP), which evaluates translations based solely on target language quality and cultural appropriateness, and Bilingual LLM Preference (BLP), which leverages large language models like GPT-4} for direct text comparison. Although TransAgents achieves lower d-BLEU scores, due to the limited diversity of references, its translations are significantly better than those of other baselines and are preferred by both human evaluators and LLMs over traditional human references and GPT-4} translations. Our findings highlight the potential of multi-agent collaboration in enhancing translation quality, particularly for longer texts."
      },
      {
        "id": "oai:arXiv.org:2405.18353v3",
        "title": "Infinite-dimensional Diffusion Bridge Simulation via Operator Learning",
        "link": "https://arxiv.org/abs/2405.18353",
        "author": "Gefan Yang, Elizabeth Louise Baker, Michael L. Severinsen, Christy Anna Hipsley, Stefan Sommer",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2405.18353v3 Announce Type: replace \nAbstract: The diffusion bridge, which is a diffusion process conditioned on hitting a specific state within a finite period, has found broad applications in various scientific and engineering fields. However, simulating diffusion bridges for modeling natural data can be challenging due to both the intractability of the drift term and continuous representations of the data. Although several methods are available to simulate finite-dimensional diffusion bridges, infinite-dimensional cases remain under explored. This paper presents a method that merges score matching techniques with operator learning, enabling a direct approach to learn the infinite-dimensional bridge and achieving a discretization equivariant bridge simulation. We conduct a series of experiments, ranging from synthetic examples with closed-form solutions to the stochastic nonlinear evolution of real-world biological shape data. Our method demonstrates high efficacy, particularly due to its ability to adapt to any resolution without extra training."
      },
      {
        "id": "oai:arXiv.org:2405.18416v4",
        "title": "3D StreetUnveiler with Semantic-aware 2DGS -- a simple baseline",
        "link": "https://arxiv.org/abs/2405.18416",
        "author": "Jingwei Xu, Yikai Wang, Yiqun Zhao, Yanwei Fu, Shenghua Gao",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2405.18416v4 Announce Type: replace \nAbstract: Unveiling an empty street from crowded observations captured by in-car cameras is crucial for autonomous driving. However, removing all temporarily static objects, such as stopped vehicles and standing pedestrians, presents a significant challenge. Unlike object-centric 3D inpainting, which relies on thorough observation in a small scene, street scene cases involve long trajectories that differ from previous 3D inpainting tasks. The camera-centric moving environment of captured videos further complicates the task due to the limited degree and time duration of object observation. To address these obstacles, we introduce StreetUnveiler to reconstruct an empty street. StreetUnveiler learns a 3D representation of the empty street from crowded observations. Our representation is based on the hard-label semantic 2D Gaussian Splatting (2DGS) for its scalability and ability to identify Gaussians to be removed. We inpaint rendered image after removing unwanted Gaussians to provide pseudo-labels and subsequently re-optimize the 2DGS. Given its temporal continuous movement, we divide the empty street scene into observed, partial-observed, and unobserved regions, which we propose to locate through a rendered alpha map. This decomposition helps us to minimize the regions that need to be inpainted. To enhance the temporal consistency of the inpainting, we introduce a novel time-reversal framework to inpaint frames in reverse order and use later frames as references for earlier frames to fully utilize the long-trajectory observations. Our experiments conducted on the street scene dataset successfully reconstructed a 3D representation of the empty street. The mesh representation of the empty street can be extracted for further applications. The project page and more visualizations can be found at: https://streetunveiler.github.io"
      },
      {
        "id": "oai:arXiv.org:2406.03184v2",
        "title": "Ouroboros3D: Image-to-3D Generation via 3D-aware Recursive Diffusion",
        "link": "https://arxiv.org/abs/2406.03184",
        "author": "Hao Wen, Zehuan Huang, Yaohui Wang, Xinyuan Chen, Lu Sheng",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2406.03184v2 Announce Type: replace \nAbstract: Existing single image-to-3D creation methods typically involve a two-stage process, first generating multi-view images, and then using these images for 3D reconstruction. However, training these two stages separately leads to significant data bias in the inference phase, thus affecting the quality of reconstructed results. We introduce a unified 3D generation framework, named Ouroboros3D, which integrates diffusion-based multi-view image generation and 3D reconstruction into a recursive diffusion process. In our framework, these two modules are jointly trained through a self-conditioning mechanism, allowing them to adapt to each other's characteristics for robust inference. During the multi-view denoising process, the multi-view diffusion model uses the 3D-aware maps rendered by the reconstruction module at the previous timestep as additional conditions. The recursive diffusion framework with 3D-aware feedback unites the entire process and improves geometric consistency.Experiments show that our framework outperforms separation of these two stages and existing methods that combine them at the inference phase. Project page: https://costwen.github.io/Ouroboros3D/"
      },
      {
        "id": "oai:arXiv.org:2406.06002v2",
        "title": "Computational and Statistical Guarantees for Tensor-on-Tensor Regression with Tensor Train Decomposition",
        "link": "https://arxiv.org/abs/2406.06002",
        "author": "Zhen Qin, Zhihui Zhu",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2406.06002v2 Announce Type: replace \nAbstract: Recently, a tensor-on-tensor (ToT) regression model has been proposed to generalize tensor recovery, encompassing scenarios like scalar-on-tensor regression and tensor-on-vector regression. However, the exponential growth in tensor complexity poses challenges for storage and computation in ToT regression. To overcome this hurdle, tensor decompositions have been introduced, with the tensor train (TT)-based ToT model proving efficient in practice due to reduced memory requirements, enhanced computational efficiency, and decreased sampling complexity. Despite these practical benefits, a disparity exists between theoretical analysis and real-world performance. In this paper, we delve into the theoretical and algorithmic aspects of the TT-based ToT regression model. Assuming the regression operator satisfies the restricted isometry property (RIP), we conduct an error analysis for the solution to a constrained least-squares optimization problem. This analysis includes upper error bound and minimax lower bound, revealing that such error bounds polynomially depend on the order $N+M$. To efficiently find solutions meeting such error bounds, we propose two optimization algorithms: the iterative hard thresholding (IHT) algorithm (employing gradient descent with TT-singular value decomposition (TT-SVD)) and the factorization approach using the Riemannian gradient descent (RGD) algorithm. When RIP is satisfied, spectral initialization facilitates proper initialization, and we establish the linear convergence rate of both IHT and RGD."
      },
      {
        "id": "oai:arXiv.org:2406.13216v2",
        "title": "CombAlign: Enhancing Model Expressiveness in Unsupervised Graph Alignment",
        "link": "https://arxiv.org/abs/2406.13216",
        "author": "Songyang Chen, Yu Liu, Lei Zou, Zexuan Wang, Youfang Lin",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2406.13216v2 Announce Type: replace \nAbstract: Unsupervised graph alignment finds the node correspondence between a pair of attributed graphs by only exploiting graph structure and node features. One category of recent studies first computes the node representation and then matches nodes with the largest embedding-based similarity, while the other category reduces the problem to optimal transport (OT) via Gromov-Wasserstein learning. However, it remains largely unexplored in the model expressiveness, as well as how theoretical expressivity impacts prediction accuracy. We investigate the model expressiveness from two aspects. First, we characterize the model's discriminative power in distinguishing matched and unmatched node pairs across two graphs.Second, we study the model's capability of guaranteeing node matching properties such as one-to-one matching and mutual alignment. Motivated by our theoretical analysis, we put forward a hybrid approach named CombAlign with stronger expressive power. Specifically, we enable cross-dimensional feature interaction for OT-based learning and propose an embedding-based method inspired by the Weisfeiler-Lehman test. We also apply non-uniform marginals obtained from the embedding-based modules to OT as priors for more expressiveness. Based on that, we propose a traditional algorithm-based refinement, which combines our OT and embedding-based predictions using the ensemble learning strategy and reduces the problem to maximum weight matching. With carefully designed edge weights, we ensure those matching properties and further enhance prediction accuracy. By extensive experiments, we demonstrate a significant improvement of 14.5% in alignment accuracy compared to state-of-the-art approaches and confirm the soundness of our theoretical analysis."
      },
      {
        "id": "oai:arXiv.org:2406.17281v5",
        "title": "DRTR: Distance-Aware Graph Representation Learning",
        "link": "https://arxiv.org/abs/2406.17281",
        "author": "Dong Liu, Yanxuan Yu",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2406.17281v5 Announce Type: replace \nAbstract: We propose \\textbf{DRTR}, a novel graph learning framework that integrates distance-aware multi-hop message passing with dynamic topology refinement. Unlike standard GNNs that rely on shallow, fixed-hop aggregation, DRTR leverages both static preprocessing and dynamic resampling to capture deeper structural dependencies. A \\emph{Distance Recomputator} prunes semantically weak edges using adaptive attention, while a \\emph{Topology Reconstructor} establishes latent connections among distant but relevant nodes. This joint mechanism enables more expressive and robust representation learning across evolving graph structures. Extensive experiments demonstrate that DRTR outperforms baseline GNNs in both accuracy and scalability, especially in complex and noisy graph environments."
      },
      {
        "id": "oai:arXiv.org:2407.00966v2",
        "title": "Smoothed Analysis for Learning Concepts with Low Intrinsic Dimension",
        "link": "https://arxiv.org/abs/2407.00966",
        "author": "Gautam Chandrasekaran, Adam Klivans, Vasilis Kontonis, Raghu Meka, Konstantinos Stavropoulos",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2407.00966v2 Announce Type: replace \nAbstract: In traditional models of supervised learning, the goal of a learner -- given examples from an arbitrary joint distribution on $\\mathbb{R}^d \\times \\{\\pm 1\\}$ -- is to output a hypothesis that is competitive (to within $\\epsilon$) of the best fitting concept from some class. In order to escape strong hardness results for learning even simple concept classes, we introduce a smoothed-analysis framework that requires a learner to compete only with the best classifier that is robust to small random Gaussian perturbation.\n  This subtle change allows us to give a wide array of learning results for any concept that (1) depends on a low-dimensional subspace (aka multi-index model) and (2) has a bounded Gaussian surface area. This class includes functions of halfspaces and (low-dimensional) convex sets, cases that are only known to be learnable in non-smoothed settings with respect to highly structured distributions such as Gaussians.\n  Surprisingly, our analysis also yields new results for traditional non-smoothed frameworks such as learning with margin. In particular, we obtain the first algorithm for agnostically learning intersections of $k$-halfspaces in time $k^{poly(\\frac{\\log k}{\\epsilon \\gamma}) }$ where $\\gamma$ is the margin parameter. Before our work, the best-known runtime was exponential in $k$ (Arriaga and Vempala, 1999)."
      },
      {
        "id": "oai:arXiv.org:2407.01635v5",
        "title": "Commute Graph Neural Networks",
        "link": "https://arxiv.org/abs/2407.01635",
        "author": "Wei Zhuo, Han Yu, Guang Tan, Xiaoxiao Li",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2407.01635v5 Announce Type: replace \nAbstract: Graph Neural Networks (GNNs) have shown remarkable success in learning from graph-structured data. However, their application to directed graphs (digraphs) presents unique challenges, primarily due to the inherent asymmetry in node relationships. Traditional GNNs are adept at capturing unidirectional relations but fall short in encoding the mutual path dependencies between nodes, such as asymmetrical shortest paths typically found in digraphs. Recognizing this gap, we introduce Commute Graph Neural Networks (CGNN), an approach that seamlessly integrates node-wise commute time into the message passing scheme. The cornerstone of CGNN is an efficient method for computing commute time using a newly formulated digraph Laplacian. Commute time is then integrated into the neighborhood aggregation process, with neighbor contributions weighted according to their respective commute time to the central node in each layer. It enables CGNN to directly capture the mutual, asymmetric relationships in digraphs. Extensive experiments on 8 benchmarking datasets confirm the superiority of CGNN against 13 state-of-the-art methods."
      },
      {
        "id": "oai:arXiv.org:2407.17856v4",
        "title": "Enhancing clinical decision support with physiological waveforms -- a multimodal benchmark in emergency care",
        "link": "https://arxiv.org/abs/2407.17856",
        "author": "Juan Miguel Lopez Alcaraz, Hjalmar Bouma, Nils Strodthoff",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2407.17856v4 Announce Type: replace \nAbstract: Background: AI-driven prediction algorithms have the potential to enhance emergency medicine by enabling rapid and accurate decision-making regarding patient status and potential deterioration. However, the integration of multimodal data, including raw waveform signals, remains underexplored in clinical decision support. Methods: We present a dataset and benchmarking protocol designed to advance multimodal decision support in emergency care. Our models utilize demographics, biometrics, vital signs, laboratory values, and electrocardiogram (ECG) waveforms as inputs to predict both discharge diagnoses and patient deterioration. Results: The diagnostic model achieves area under the receiver operating curve (AUROC) scores above 0.8 for 609 out of 1,428 conditions, covering both cardiac (e.g., myocardial infarction) and non-cardiac (e.g., renal disease, diabetes) diagnoses. The deterioration model attains AUROC scores above 0.8 for 14 out of 15 targets, accurately predicting critical events such as cardiac arrest, mechanical ventilation, ICU admission, and mortality. Conclusions: Our study highlights the positive impact of incorporating raw waveform data into decision support models, improving predictive performance. By introducing a unique, publicly available dataset and baseline models, we provide a foundation for measurable progress in AI-driven decision support for emergency care."
      },
      {
        "id": "oai:arXiv.org:2407.20906v5",
        "title": "Automated Review Generation Method Based on Large Language Models",
        "link": "https://arxiv.org/abs/2407.20906",
        "author": "Shican Wu, Xiao Ma, Dehui Luo, Lulu Li, Xiangcheng Shi, Xin Chang, Xiaoyun Lin, Ran Luo, Chunlei Pei, Changying Du, Zhi-Jian Zhao, Jinlong Gong",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2407.20906v5 Announce Type: replace \nAbstract: Literature research, vital for scientific work, faces the challenge of surging information volumes exceeding researchers' processing capabilities. We present an automated review generation method based on large language models (LLMs) to overcome efficiency bottlenecks and reduce cognitive load. Our statistically validated evaluation framework demonstrates that the generated reviews match or exceed manual quality, offering broad applicability across research fields without requiring users' domain knowledge. Applied to propane dehydrogenation (PDH) catalysts, our method swiftly analyzed 343 articles, averaging seconds per article per LLM account, producing comprehensive reviews spanning 35 topics, with extended analysis of 1041 articles providing insights into catalysts' properties. Through multi-layered quality control, we effectively mitigated LLMs' hallucinations, with expert verification confirming accuracy and citation integrity while demonstrating hallucination risks reduced to below 0.5\\% with 95\\% confidence. Released Windows application enables one-click review generation, enhancing research productivity and literature recommendation efficiency while setting the stage for broader scientific explorations."
      },
      {
        "id": "oai:arXiv.org:2409.08091v4",
        "title": "EZIGen: Enhancing zero-shot personalized image generation with precise subject encoding and decoupled guidance",
        "link": "https://arxiv.org/abs/2409.08091",
        "author": "Zicheng Duan, Yuxuan Ding, Chenhui Gou, Ziqin Zhou, Ethan Smith, Lingqiao Liu",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2409.08091v4 Announce Type: replace \nAbstract: Zero-shot personalized image generation models aim to produce images that align with both a given text prompt and subject image, requiring the model to incorporate both sources of guidance. Existing methods often struggle to capture fine-grained subject details and frequently prioritize one form of guidance over the other, resulting in suboptimal subject encoding and imbalanced generation. In this study, we uncover key insights into overcoming such drawbacks, notably that 1) the choice of the subject image encoder critically influences subject identity preservation and training efficiency, and 2) the text and subject guidance should take effect at different denoising stages. Building on these insights, we introduce a new approach, EZIGen, that employs two main components: leveraging a fixed pre-trained Diffusion UNet itself as subject encoder, following a process that balances the two guidances by separating their dominance stage and revisiting certain time steps to bootstrap subject transfer quality. Through these two components, EZIGen, initially built upon SD2.1-base, achieved state-of-the-art performances on multiple personalized generation benchmarks with a unified model, while using 100 times less training data. Moreover, by further migrating our design to SDXL, EZIGen is proven to be a versatile model-agnostic solution for personalized generation. Demo Page: zichengduan.github.io/pages/EZIGen/index.html"
      },
      {
        "id": "oai:arXiv.org:2409.08215v2",
        "title": "LT3SD: Latent Trees for 3D Scene Diffusion",
        "link": "https://arxiv.org/abs/2409.08215",
        "author": "Quan Meng, Lei Li, Matthias Nie{\\ss}ner, Angela Dai",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2409.08215v2 Announce Type: replace \nAbstract: We present LT3SD, a novel latent diffusion model for large-scale 3D scene generation. Recent advances in diffusion models have shown impressive results in 3D object generation, but are limited in spatial extent and quality when extended to 3D scenes. To generate complex and diverse 3D scene structures, we introduce a latent tree representation to effectively encode both lower-frequency geometry and higher-frequency detail in a coarse-to-fine hierarchy. We can then learn a generative diffusion process in this latent 3D scene space, modeling the latent components of a scene at each resolution level. To synthesize large-scale scenes with varying sizes, we train our diffusion model on scene patches and synthesize arbitrary-sized output 3D scenes through shared diffusion generation across multiple scene patches. Through extensive experiments, we demonstrate the efficacy and benefits of LT3SD for large-scale, high-quality unconditional 3D scene generation and for probabilistic completion for partial scene observations."
      },
      {
        "id": "oai:arXiv.org:2410.01957v2",
        "title": "Challenges and Future Directions of Data-Centric AI Alignment",
        "link": "https://arxiv.org/abs/2410.01957",
        "author": "Min-Hsuan Yeh, Jeffrey Wang, Xuefeng Du, Seongheon Park, Leitian Tao, Shawn Im, Yixuan Li",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2410.01957v2 Announce Type: replace \nAbstract: As AI systems become increasingly capable and influential, ensuring their alignment with human values, preferences, and goals has become a critical research focus. Current alignment methods primarily focus on designing algorithms and loss functions but often underestimate the crucial role of data. This paper advocates for a shift towards data-centric AI alignment, emphasizing the need to enhance the quality and representativeness of data used in aligning AI systems. In this position paper, we highlight key challenges associated with both human-based and AI-based feedback within the data-centric alignment framework. Through qualitative analysis, we identify multiple sources of unreliability in human feedback, as well as problems related to temporal drift, context dependence, and AI-based feedback failing to capture human values due to inherent model limitations. We propose future research directions, including improved feedback collection practices, robust data-cleaning methodologies, and rigorous feedback verification processes. We call for future research into these critical directions to ensure, addressing gaps that persist in understanding and improving data-centric alignment practices."
      },
      {
        "id": "oai:arXiv.org:2410.08067v4",
        "title": "Reward-Augmented Data Enhances Direct Preference Alignment of LLMs",
        "link": "https://arxiv.org/abs/2410.08067",
        "author": "Shenao Zhang, Zhihan Liu, Boyi Liu, Yufeng Zhang, Yingxiang Yang, Yongfei Liu, Liyu Chen, Tao Sun, Zhaoran Wang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2410.08067v4 Announce Type: replace \nAbstract: Preference alignment in Large Language Models (LLMs) has significantly improved their ability to adhere to human instructions and intentions. However, existing direct alignment algorithms primarily focus on relative preferences and often overlook the qualitative aspects of responses, despite having access to preference data that includes reward scores from judge models during AI feedback. Striving to maximize the implicit reward gap between the chosen and the slightly inferior rejected responses can cause overfitting and unnecessary unlearning of the high-quality rejected responses. The unawareness of the reward scores also drives the LLM to indiscriminately favor the low-quality chosen responses and fail to generalize to optimal responses that are sparse in data. To overcome these shortcomings, our study introduces reward-conditioned LLM policies that discern and learn from the entire spectrum of response quality within the dataset, helping extrapolate to more optimal regions. We propose an effective yet simple data relabeling method that conditions the preference pairs on quality scores to construct a reward-augmented dataset. The experiments across various benchmarks and diverse models demonstrate that our approach consistently boosts DPO by a considerable margin. Through comprehensive ablation studies, we demonstrate that our method not only maximizes the utility of preference data but also mitigates the issue of unlearning, demonstrating its broad effectiveness beyond mere data expansion. Our code is available at https://github.com/shenao-zhang/reward-augmented-preference."
      },
      {
        "id": "oai:arXiv.org:2410.20774v2",
        "title": "Are LLM-Judges Robust to Expressions of Uncertainty? Investigating the effect of Epistemic Markers on LLM-based Evaluation",
        "link": "https://arxiv.org/abs/2410.20774",
        "author": "Dongryeol Lee, Yerin Hwang, Yongil Kim, Joonsuk Park, Kyomin Jung",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2410.20774v2 Announce Type: replace \nAbstract: In line with the principle of honesty, there has been a growing effort to train large language models (LLMs) to generate outputs containing epistemic markers. However, evaluation in the presence of epistemic markers has been largely overlooked, raising a critical question: Could the use of epistemic markers in LLM-generated outputs lead to unintended negative consequences? To address this, we present EMBER, a benchmark designed to assess the robustness of LLM-judges to epistemic markers in both single and pairwise evaluation settings. Our findings, based on evaluations using EMBER, reveal that all tested LLM-judges, including GPT-4o, show a notable lack of robustness in the presence of epistemic markers. Specifically, we observe a negative bias toward epistemic markers, with a stronger bias against markers expressing uncertainty. This suggests that LLM-judges are influenced by the presence of these markers and do not focus solely on the correctness of the content."
      },
      {
        "id": "oai:arXiv.org:2411.05793v3",
        "title": "A Comprehensive Survey of Deep Learning for Time Series Forecasting: Architectural Diversity and Open Challenges",
        "link": "https://arxiv.org/abs/2411.05793",
        "author": "Jongseon Kim, Hyungjoon Kim, HyunGi Kim, Dongjun Lee, Sungroh Yoon",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2411.05793v3 Announce Type: replace \nAbstract: Time series forecasting is a critical task that provides key information for decision-making. After traditional statistical and machine learning approaches, various fundamental deep learning architectures such as MLPs, CNNs, RNNs, and GNNs have been developed. However, the structural limitations caused by the inductive biases of each deep learning architecture constrained their performance. Transformer models, which excel at handling long-term dependencies, have become significant architectural components for time series forecasting. However, recent research has shown that alternatives such as simple linear layers can outperform Transformers. These findings have opened up new possibilities for using diverse architectures, ranging from fundamental deep learning models to emerging architectures and hybrid approaches. In this context, architectural modeling of time series forecasting has now entered a renaissance. This survey not only provides a historical context for time series forecasting but also offers comprehensive and timely analysis of the movement toward architectural diversification. By comparing and re-examining deep learning models, we uncover new perspectives and present recent trends, including hybrid, diffusion, Mamba, and foundation models. By focusing on the inherent characteristics of time series data, we also address open challenges that have gained attention in time series forecasting, such as channel dependency, distribution shift, causality, and feature extraction. These contributions help lower entry barriers for newcomers by providing a systematic understanding of the diverse research areas in time series forecasting (TSF), while offering seasoned researchers broader perspectives and new opportunities through in-depth exploration of TSF challenges. (Shortened due to arXiv's 1,920-character limit. Full version in the paper.)"
      },
      {
        "id": "oai:arXiv.org:2411.16508v4",
        "title": "All Languages Matter: Evaluating LMMs on Culturally Diverse 100 Languages",
        "link": "https://arxiv.org/abs/2411.16508",
        "author": "Ashmal Vayani, Dinura Dissanayake, Hasindri Watawana, Noor Ahsan, Nevasini Sasikumar, Omkar Thawakar, Henok Biadglign Ademtew, Yahya Hmaiti, Amandeep Kumar, Kartik Kuckreja, Mykola Maslych, Wafa Al Ghallabi, Mihail Mihaylov, Chao Qin, Abdelrahman M Shaker, Mike Zhang, Mahardika Krisna Ihsani, Amiel Esplana, Monil Gokani, Shachar Mirkin, Harsh Singh, Ashay Srivastava, Endre Hamerlik, Fathinah Asma Izzati, Fadillah Adamsyah Maani, Sebastian Cavada, Jenny Chim, Rohit Gupta, Sanjay Manjunath, Kamila Zhumakhanova, Feno Heriniaina Rabevohitra, Azril Amirudin, Muhammad Ridzuan, Daniya Kareem, Ketan More, Kunyang Li, Pramesh Shakya, Muhammad Saad, Amirpouya Ghasemaghaei, Amirbek Djanibekov, Dilshod Azizov, Branislava Jankovic, Naman Bhatia, Alvaro Cabrera, Johan Obando-Ceron, Olympiah Otieno, Fabian Farestam, Muztoba Rabbani, Sanoojan Baliah, Santosh Sanjeev, Abduragim Shtanchaev, Maheen Fatima, Thao Nguyen, Amrin Kareem, Toluwani Aremu, Nathan Xavier, Amit Bhatkal, Hawau Toyin, Aman Chadha, Hisham Cholakkal, Rao Muhammad Anwer, Michael Felsberg, Jorma Laaksonen, Thamar Solorio, Monojit Choudhury, Ivan Laptev, Mubarak Shah, Salman Khan, Fahad Khan",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2411.16508v4 Announce Type: replace \nAbstract: Existing Large Multimodal Models (LMMs) generally focus on only a few regions and languages. As LMMs continue to improve, it is increasingly important to ensure they understand cultural contexts, respect local sensitivities, and support low-resource languages, all while effectively integrating corresponding visual cues. In pursuit of culturally diverse global multimodal models, our proposed All Languages Matter Benchmark (ALM-bench) represents the largest and most comprehensive effort to date for evaluating LMMs across 100 languages. ALM-bench challenges existing models by testing their ability to understand and reason about culturally diverse images paired with text in various languages, including many low-resource languages traditionally underrepresented in LMM research. The benchmark offers a robust and nuanced evaluation framework featuring various question formats, including true/false, multiple choice, and open-ended questions, which are further divided into short and long-answer categories. ALM-bench design ensures a comprehensive assessment of a model's ability to handle varied levels of difficulty in visual and linguistic reasoning. To capture the rich tapestry of global cultures, ALM-bench carefully curates content from 13 distinct cultural aspects, ranging from traditions and rituals to famous personalities and celebrations. Through this, ALM-bench not only provides a rigorous testing ground for state-of-the-art open and closed-source LMMs but also highlights the importance of cultural and linguistic inclusivity, encouraging the development of models that can serve diverse global populations effectively. Our benchmark is publicly available."
      },
      {
        "id": "oai:arXiv.org:2412.05862v3",
        "title": "Domain-Specific Translation with Open-Source Large Language Models: Resource-Oriented Analysis",
        "link": "https://arxiv.org/abs/2412.05862",
        "author": "Aman Kassahun Wassie, Mahdi Molaei, Yasmin Moslem",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2412.05862v3 Announce Type: replace \nAbstract: In this work, we compare the domain-specific translation performance of open-source autoregressive decoder-only large language models (LLMs) with task-oriented machine translation (MT) models. Our experiments focus on the medical domain and cover four language directions with varied resource availability: English-to-French, English-to-Portuguese, English-to-Swahili, and Swahili-to-English. Despite recent advancements, LLMs demonstrate a significant quality gap in specialized translation compared to multilingual encoder-decoder MT models such as NLLB-200. Our results indicate that NLLB-200 3.3B outperforms all evaluated LLMs in the 7-8B parameter range across three out of the four language directions. While fine-tuning improves the performance of LLMs such as Mistral and Llama, these models still underperform compared to fine-tuned NLLB-200 3.3B models. Our findings highlight the ongoing need for specialized MT models to achieve high-quality domain-specific translation, especially in medium-resource and low-resource settings. Moreover, the superior performance of larger LLMs over their 8B variants suggests potential value in pre-training domain-specific medium-sized language models, employing targeted data selection and knowledge distillation approaches to enhance both quality and efficiency in specialized translation tasks."
      },
      {
        "id": "oai:arXiv.org:2412.06491v2",
        "title": "PPT: Pretraining with Pseudo-Labeled Trajectories for Motion Forecasting",
        "link": "https://arxiv.org/abs/2412.06491",
        "author": "Yihong Xu, Yuan Yin, \\'Eloi Zablocki, Tuan-Hung Vu, Alexandre Boulch, Matthieu Cord",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2412.06491v2 Announce Type: replace \nAbstract: Accurately predicting how agents move in dynamic scenes is essential for safe autonomous driving. State-of-the-art motion forecasting models rely on large curated datasets with manually annotated or heavily post-processed trajectories. However, building these datasets is costly, generally manual, hard to scale, and lacks reproducibility. They also introduce domain gaps that limit generalization across environments. We introduce PPT (Pretraining with Pseudo-labeled Trajectories), a simple and scalable alternative that uses unprocessed and diverse trajectories automatically generated from off-the-shelf 3D detectors and tracking. Unlike traditional pipelines aiming for clean, single-label annotations, PPT embraces noise and diversity as useful signals for learning robust representations. With optional finetuning on a small amount of labeled data, models pretrained with PPT achieve strong performance across standard benchmarks particularly in low-data regimes, and in cross-domain, end-to-end and multi-class settings. PPT is easy to implement and improves generalization in motion forecasting. Code and data will be released upon acceptance."
      },
      {
        "id": "oai:arXiv.org:2412.08085v2",
        "title": "Non-Myopic Multi-Objective Bayesian Optimization",
        "link": "https://arxiv.org/abs/2412.08085",
        "author": "Syrine Belakaria, Alaleh Ahmadianshalchi, Barbara Engelhardt, Stefano Ermon, Janardhan Rao Doppa",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2412.08085v2 Announce Type: replace \nAbstract: We consider the problem of finite-horizon sequential experimental design to solve multi-objective optimization (MOO) of expensive black-box objective functions. This problem arises in many real-world applications, including materials design, where we have a small resource budget to make and evaluate candidate materials in the lab. We solve this problem using the framework of Bayesian optimization (BO) and propose the first set of non-myopic methods for MOO problems. Prior work on non-myopic BO for single-objective problems relies on the Bellman optimality principle to handle the lookahead reasoning process. However, this principle does not hold for most MOO problems because the reward function needs to satisfy some conditions: scalar variable, monotonicity, and additivity. We address this challenge by using hypervolume improvement (HVI) as our scalarization approach, which allows us to use a lower-bound on the Bellman equation to approximate the finite-horizon using a batch expected hypervolume improvement (EHVI) acquisition function (AF) for MOO. Our formulation naturally allows us to use other improvement-based scalarizations and compare their efficacy to HVI. We derive three non-myopic AFs for MOBO: 1) the Nested AF, which is based on the exact computation of the lower bound, 2) the Joint AF, which is a lower bound on the nested AF, and 3) the BINOM AF, which is a fast and approximate variant based on batch multi-objective acquisition functions. Our experiments on multiple diverse real-world MO problems demonstrate that our non-myopic AFs substantially improve performance over the existing myopic AFs for MOBO."
      },
      {
        "id": "oai:arXiv.org:2412.12870v3",
        "title": "Towards Physically Interpretable World Models: Meaningful Weakly Supervised Representations for Visual Trajectory Prediction",
        "link": "https://arxiv.org/abs/2412.12870",
        "author": "Zhenjiang Mao, Ivan Ruchkin",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2412.12870v3 Announce Type: replace \nAbstract: Deep learning models are increasingly employed for perception, prediction, and control in robotic systems. For for achieving realistic and consistent outputs, it is crucial to embed physical knowledge into their learned representations. However, doing so is difficult due to high-dimensional observation data, such as images, particularly under conditions of incomplete system knowledge and imprecise state sensing. To address this, we propose Physically Interpretable World Models, a novel architecture that aligns learned latent representations with real-world physical quantities. To this end, our architecture combines three key elements: (1) a vector-quantized image autoencoder, (2) a transformer-based physically interpretable autoencoder, and (3) a partially known dynamical model. The training incorporates weak interval-based supervision to eliminate the impractical reliance on ground-truth physical knowledge. Three case studies demonstrate that our approach achieves physical interpretability and accurate state predictions, thus advancing representation learning for robotics."
      },
      {
        "id": "oai:arXiv.org:2501.00571v4",
        "title": "KnowRA: Knowledge Retrieval Augmented Method for Document-level Relation Extraction with Comprehensive Reasoning Abilities",
        "link": "https://arxiv.org/abs/2501.00571",
        "author": "Chengcheng Mai, Yuxiang Wang, Ziyu Gong, Hanxiang Wang, Yihua Huang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2501.00571v4 Announce Type: replace \nAbstract: Document-level relation extraction (Doc-RE) aims to extract relations between entities across multiple sentences. Therefore, Doc-RE requires more comprehensive reasoning abilities like humans, involving complex cross-sentence interactions between entities, contexts, and external general knowledge, compared to the sentence-level RE. However, most existing Doc-RE methods focus on optimizing single reasoning ability, but lack the ability to utilize external knowledge for comprehensive reasoning on long documents. To solve these problems, a knowledge retrieval augmented method, named KnowRA, was proposed with comprehensive reasoning to autonomously determine whether to accept external knowledge to assist DocRE. Firstly, we constructed a document graph for semantic encoding and integrated the co-reference resolution model to augment the co-reference reasoning ability. Then, we expanded the document graph into a document knowledge graph by retrieving the external knowledge base for common-sense reasoning and a novel knowledge filtration method was presented to filter out irrelevant knowledge. Finally, we proposed the axis attention mechanism to build direct and indirect associations with intermediary entities for achieving cross-sentence logical reasoning. Extensive experiments conducted on two datasets verified the effectiveness of our method compared to the state-of-the-art baselines. Our code is available at https://anonymous.4open.science/r/KnowRA."
      },
      {
        "id": "oai:arXiv.org:2501.01728v2",
        "title": "Multimodal classification of forest biodiversity potential from 2D orthophotos and 3D airborne laser scanning point clouds",
        "link": "https://arxiv.org/abs/2501.01728",
        "author": "Simon B. Jensen, Stefan Oehmcke, Andreas M{\\o}gelmose, Meysam Madadi, Christian Igel, Sergio Escalera, Thomas B. Moeslund",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2501.01728v2 Announce Type: replace \nAbstract: Assessment of forest biodiversity is crucial for ecosystem management and conservation. While traditional field surveys provide high-quality assessments, they are labor-intensive and spatially limited. This study investigates whether deep learning-based fusion of close-range sensing data from 2D orthophotos and 3D airborne laser scanning (ALS) point clouds can reliable assess the biodiversity potential of forests. We introduce the BioVista dataset, comprising 44 378 paired samples of orthophotos and ALS point clouds from temperate forests in Denmark, designed to explore multimodal fusion approaches. Using deep neural networks (ResNet for orthophotos and PointVector for ALS point clouds), we investigate each data modality's ability to assess forest biodiversity potential, achieving overall accuracies of 76.7% and 75.8%, respectively. We explore various 2D and 3D fusion approaches: confidence-based ensembling, feature-level concatenation, and end-to-end training, achieving overall accuracies of 80.5%, 81.4% and 80.4% respectively. Our results demonstrate that spectral information from orthophotos and structural information from ALS point clouds effectively complement each other in forest biodiversity assessment."
      },
      {
        "id": "oai:arXiv.org:2501.06066v3",
        "title": "Distilling Calibration via Conformalized Credal Inference",
        "link": "https://arxiv.org/abs/2501.06066",
        "author": "Jiayi Huang, Sangwoo Park, Nicola Paoletti, Osvaldo Simeone",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2501.06066v3 Announce Type: replace \nAbstract: Deploying artificial intelligence (AI) models on edge devices involves a delicate balance between meeting stringent complexity constraints, such as limited memory and energy resources, and ensuring reliable performance in sensitive decision-making tasks. One way to enhance reliability is through uncertainty quantification via Bayesian inference. This approach, however, typically necessitates maintaining and running multiple models in an ensemble, which may exceed the computational limits of edge devices. This paper introduces a low-complexity methodology to address this challenge by distilling calibration information from a more complex model. In an offline phase, predictive probabilities generated by a high-complexity cloud-based model are leveraged to determine a threshold based on the typical divergence between the cloud and edge models. At run time, this threshold is used to construct credal sets -- ranges of predictive probabilities that are guaranteed, with a user-selected confidence level, to include the predictions of the cloud model. The credal sets are obtained through thresholding of a divergence measure in the simplex of predictive probabilities. Experiments on visual and language tasks demonstrate that the proposed approach, termed Conformalized Distillation for Credal Inference (CD-CI), significantly improves calibration performance compared to low-complexity Bayesian methods, such as Laplace approximation, making it a practical and efficient solution for edge AI deployments."
      },
      {
        "id": "oai:arXiv.org:2501.09503v2",
        "title": "AnyStory: Towards Unified Single and Multiple Subject Personalization in Text-to-Image Generation",
        "link": "https://arxiv.org/abs/2501.09503",
        "author": "Junjie He, Yuxiang Tuo, Binghui Chen, Chongyang Zhong, Yifeng Geng, Liefeng Bo",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2501.09503v2 Announce Type: replace \nAbstract: Recently, large-scale generative models have demonstrated outstanding text-to-image generation capabilities. However, generating high-fidelity personalized images with specific subjects still presents challenges, especially in cases involving multiple subjects. In this paper, we propose AnyStory, a unified approach for personalized subject generation. AnyStory not only achieves high-fidelity personalization for single subjects, but also for multiple subjects, without sacrificing subject fidelity. Specifically, AnyStory models the subject personalization problem in an \"encode-then-route\" manner. In the encoding step, AnyStory utilizes a universal and powerful image encoder, i.e., ReferenceNet, in conjunction with CLIP vision encoder to achieve high-fidelity encoding of subject features. In the routing step, AnyStory utilizes a decoupled instance-aware subject router to accurately perceive and predict the potential location of the corresponding subject in the latent space, and guide the injection of subject conditions. Detailed experimental results demonstrate the excellent performance of our method in retaining subject details, aligning text descriptions, and personalizing for multiple subjects. The project page is at https://aigcdesigngroup.github.io/AnyStory/ ."
      },
      {
        "id": "oai:arXiv.org:2501.13947v3",
        "title": "A Comprehensive Survey on Integrating Large Language Models with Knowledge-Based Methods",
        "link": "https://arxiv.org/abs/2501.13947",
        "author": "Wenli Yang, Lilian Some, Michael Bain, Byeong Kang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2501.13947v3 Announce Type: replace \nAbstract: The rapid development of artificial intelligence has led to marked progress in the field. One interesting direction for research is whether Large Language Models (LLMs) can be integrated with structured knowledge-based systems. This approach aims to combine the generative language understanding of LLMs and the precise knowledge representation systems by which they are integrated. This article surveys the relationship between LLMs and knowledge bases, looks at how they can be applied in practice, and discusses related technical, operational, and ethical challenges. Utilizing a comprehensive examination of the literature, the study both identifies important issues and assesses existing solutions. It demonstrates the merits of incorporating generative AI into structured knowledge-base systems concerning data contextualization, model accuracy, and utilization of knowledge resources. The findings give a full list of the current situation of research, point out the main gaps, and propose helpful paths to take. These insights contribute to advancing AI technologies and support their practical deployment across various sectors."
      },
      {
        "id": "oai:arXiv.org:2501.16370v2",
        "title": "Advanced Physics-Informed Neural Network with Residuals for Solving Complex Integral Equations",
        "link": "https://arxiv.org/abs/2501.16370",
        "author": "Mahdi Movahedian Moghaddam, Kourosh Parand, Saeed Reza Kheradpisheh",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2501.16370v2 Announce Type: replace \nAbstract: In this paper, we present the Residual Integral Solver Network (RISN), a novel neural network architecture designed to solve a wide range of integral and integro-differential equations, including one-dimensional, multi-dimensional, ordinary and partial integro-differential, systems, fractional types, and Helmholtz-type integral equations involving oscillatory kernels. RISN integrates residual connections with high-accuracy numerical methods such as Gaussian quadrature and fractional derivative operational matrices, enabling it to achieve higher accuracy and stability than traditional Physics-Informed Neural Networks (PINN). The residual connections help mitigate vanishing gradient issues, allowing RISN to handle deeper networks and more complex kernels, particularly in multi-dimensional problems. Through extensive experiments, we demonstrate that RISN consistently outperforms not only classical PINNs but also advanced variants such as Auxiliary PINN (A-PINN) and Self-Adaptive PINN (SA-PINN), achieving significantly lower Mean Absolute Errors (MAE) across various types of equations. These results highlight RISN's robustness and efficiency in solving challenging integral and integro-differential problems, making it a valuable tool for real-world applications where traditional methods often struggle."
      },
      {
        "id": "oai:arXiv.org:2501.18028v2",
        "title": "KNN and K-means in Gini Prametric Spaces",
        "link": "https://arxiv.org/abs/2501.18028",
        "author": "Cassandra Mussard, Arthur Charpentier, St\\'ephane Mussard",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2501.18028v2 Announce Type: replace \nAbstract: This paper introduces innovative enhancements to the K-means and K-nearest neighbors (KNN) algorithms based on the concept of Gini prametric spaces. Unlike traditional distance metrics, Gini-based measures incorporate both value-based and rank-based information, improving robustness to noise and outliers. The main contributions of this work include: proposing a Gini-based measure that captures both rank information and value distances; presenting a Gini K-means algorithm that is proven to converge and demonstrates resilience to noisy data; and introducing a Gini KNN method that performs competitively with state-of-the-art approaches such as Hassanat's distance in noisy environments. Experimental evaluations on 14 datasets from the UCI repository demonstrate the superior performance and efficiency of Gini-based algorithms in clustering and classification tasks. This work opens new avenues for leveraging rank-based measures in machine learning and statistical analysis."
      },
      {
        "id": "oai:arXiv.org:2501.18768v2",
        "title": "Diversity By Design: Leveraging Distribution Matching for Offline Model-Based Optimization",
        "link": "https://arxiv.org/abs/2501.18768",
        "author": "Michael S. Yao, James C. Gee, Osbert Bastani",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2501.18768v2 Announce Type: replace \nAbstract: The goal of offline model-based optimization (MBO) is to propose new designs that maximize a reward function given only an offline dataset. However, an important desiderata is to also propose a diverse set of final candidates that capture many optimal and near-optimal design configurations. We propose Diversity in Adversarial Model-based Optimization (DynAMO) as a novel method to introduce design diversity as an explicit objective into any MBO problem. Our key insight is to formulate diversity as a distribution matching problem where the distribution of generated designs captures the inherent diversity contained within the offline dataset. Extensive experiments spanning multiple scientific domains show that DynAMO can be used with common optimization methods to significantly improve the diversity of proposed designs while still discovering high-quality candidates."
      },
      {
        "id": "oai:arXiv.org:2501.19243v2",
        "title": "Accelerating Diffusion Transformer via Error-Optimized Cache",
        "link": "https://arxiv.org/abs/2501.19243",
        "author": "Junxiang Qiu, Shuo Wang, Jinda Lu, Lin Liu, Houcheng Jiang, Xingyu Zhu, Yanbin Hao",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2501.19243v2 Announce Type: replace \nAbstract: Diffusion Transformer (DiT) is a crucial method for content generation. However, it needs a lot of time to sample. Many studies have attempted to use caching to reduce the time consumption of sampling. Existing caching methods accelerate generation by reusing DiT features from the previous time step and skipping calculations in the next, but they tend to locate and cache low-error modules without focusing on reducing caching-induced errors, resulting in a sharp decline in generated content quality when increasing caching intensity. To solve this problem, we propose the Error-Optimized Cache (EOC). This method introduces three key improvements: (1) Prior knowledge extraction: Extract and process the caching differences; (2) A judgment method for cache optimization: Determine whether certain caching steps need to be optimized; (3) Cache optimization: reduce caching errors. Experiments show that this algorithm significantly reduces the error accumulation caused by caching, especially excessive caching. On the ImageNet dataset, without substantially increasing the computational load, this method improves the FID of the generated images when the rule-based model FORA has a caching level of 75%, 50%, and 25%, and the training-based model Learning-to-cache has a caching level of 22%. Specifically, the FID values change from 30.454 to 21.690 (28.8%), from 6.857 to 5.821 (15.1%), from 3.870 to 3.692 (4.6%), and from 3.539 to 3.451 (2.5%) respectively."
      },
      {
        "id": "oai:arXiv.org:2502.00040v2",
        "title": "Multi-Objective Reinforcement Learning for Power Grid Topology Control",
        "link": "https://arxiv.org/abs/2502.00040",
        "author": "Thomas Lautenbacher, Ali Rajaei, Davide Barbieri, Jan Viebahn, Jochen L. Cremer",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2502.00040v2 Announce Type: replace \nAbstract: Transmission grid congestion increases as the electrification of various sectors requires transmitting more power. Topology control, through substation reconfiguration, can reduce congestion but its potential remains under-exploited in operations. A challenge is modeling the topology control problem to align well with the objectives and constraints of operators. Addressing this challenge, this paper investigates the application of multi-objective reinforcement learning (MORL) to integrate multiple conflicting objectives for power grid topology control. We develop a MORL approach using deep optimistic linear support (DOL) and multi-objective proximal policy optimization (MOPPO) to generate a set of Pareto-optimal policies that balance objectives such as minimizing line loading, topological deviation, and switching frequency. Initial case studies show that the MORL approach can provide valuable insights into objective trade-offs and improve Pareto front approximation compared to a random search baseline. The generated multi-objective RL policies are 30% more successful in preventing grid failure under contingencies and 20% more effective when training budget is reduced - compared to the common single objective RL policy."
      },
      {
        "id": "oai:arXiv.org:2502.05945v2",
        "title": "HSI: Head-Specific Intervention Can Induce Misaligned AI Coordination in Large Language Models",
        "link": "https://arxiv.org/abs/2502.05945",
        "author": "Paul Darm, Annalisa Riccardi",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2502.05945v2 Announce Type: replace \nAbstract: Robust alignment guardrails for large language models are becoming increasingly important with their widespread application. In contrast to previous studies, we demonstrate that inference-time activation interventions can bypass safety alignments and effectively steer model generations towards harmful AI coordination for Llama 2. Our method applies fine-grained interventions at specific model subcomponents, particularly attention heads, using a simple binary choice probing strategy. These interventions then generalise to the open-ended generation setting effectively circumventing safety guardrails. We show that probing single attention heads is more effective than intervening on full layers and intervening on only four attention heads is comparable to supervised fine-tuning. We further show that only a few example completions are needed to compute effective steering directions, which is an advantage over classical fine-tuning. Our findings highlight the shortcomings of current alignment techniques. In addition, our results suggest that, at the attention head level, activations encode fine-grained linearly separable behaviors. Practically, the approach offers a straightforward methodology to steer large language model behaviour, which could be extended to diverse domains beyond safety requiring fine-grained control over the model output. The code and datasets for this study can be found on https://github.com/PaulDrm/targeted_intervention."
      },
      {
        "id": "oai:arXiv.org:2502.05974v2",
        "title": "Decision Making in Hybrid Environments: A Model Aggregation Approach",
        "link": "https://arxiv.org/abs/2502.05974",
        "author": "Haolin Liu, Chen-Yu Wei, Julian Zimmert",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2502.05974v2 Announce Type: replace \nAbstract: Recent work by Foster et al. (2021, 2022, 2023b) and Xu and Zeevi (2023) developed the framework of decision estimation coefficient (DEC) that characterizes the complexity of general online decision making problems and provides a general algorithm design principle. These works, however, either focus on the pure stochastic regime where the world remains fixed over time, or the pure adversarial regime where the world arbitrarily changes over time. For the hybrid regime where the dynamics of the world is fixed while the reward arbitrarily changes, they only give pessimistic bounds on the decision complexity. In this work, we propose a general extension of DEC that more precisely characterizes this case. Besides applications in special cases, our framework leads to a flexible algorithm design where the learner learns over subsets of the hypothesis set, trading estimation complexity with decision complexity, which could be of independent interest. Our work covers model-based learning and model-free learning in the hybrid regime, with a newly proposed extension of the bilinear classes (Du et al., 2021) to the adversarial-reward case. In addition, our method improves the best-known regret bounds for linear Q*/V* MDPs in the pure stochastic regime."
      },
      {
        "id": "oai:arXiv.org:2502.07963v2",
        "title": "Caught in the Web of Words: Do LLMs Fall for Spin in Medical Literature?",
        "link": "https://arxiv.org/abs/2502.07963",
        "author": "Hye Sun Yun, Karen Y. C. Zhang, Ramez Kouzy, Iain J. Marshall, Junyi Jessy Li, Byron C. Wallace",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2502.07963v2 Announce Type: replace \nAbstract: Medical research faces well-documented challenges in translating novel treatments into clinical practice. Publishing incentives encourage researchers to present \"positive\" findings, even when empirical results are equivocal. Consequently, it is well-documented that authors often spin study results, especially in article abstracts. Such spin can influence clinician interpretation of evidence and may affect patient care decisions. In this study, we ask whether the interpretation of trial results offered by Large Language Models (LLMs) is similarly affected by spin. This is important since LLMs are increasingly being used to trawl through and synthesize published medical evidence. We evaluated 22 LLMs and found that they are across the board more susceptible to spin than humans. They might also propagate spin into their outputs: We find evidence, e.g., that LLMs implicitly incorporate spin into plain language summaries that they generate. We also find, however, that LLMs are generally capable of recognizing spin, and can be prompted in a way to mitigate spin's impact on LLM outputs."
      },
      {
        "id": "oai:arXiv.org:2502.10689v2",
        "title": "Self-Explaining Hypergraph Neural Networks for Diagnosis Prediction",
        "link": "https://arxiv.org/abs/2502.10689",
        "author": "Leisheng Yu, Yanxiao Cai, Minxing Zhang, Xia Hu",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2502.10689v2 Announce Type: replace \nAbstract: The burgeoning volume of electronic health records (EHRs) has enabled deep learning models to excel in predictive healthcare. However, for high-stakes applications such as diagnosis prediction, model interpretability remains paramount. Existing deep learning diagnosis prediction models with intrinsic interpretability often assign attention weights to every past diagnosis or hospital visit, providing explanations lacking flexibility and succinctness. In this paper, we introduce SHy, a self-explaining hypergraph neural network model, designed to offer personalized, concise and faithful explanations that allow for interventions from clinical experts. By modeling each patient as a unique hypergraph and employing a message-passing mechanism, SHy captures higher-order disease interactions and extracts distinct temporal phenotypes as personalized explanations. It also addresses the incompleteness of the EHR data by accounting for essential false negatives in the original diagnosis record. A qualitative case study and extensive quantitative evaluations on two real-world EHR datasets demonstrate the superior predictive performance and interpretability of SHy over existing state-of-the-art models."
      },
      {
        "id": "oai:arXiv.org:2502.14764v2",
        "title": "The illusion of households as entities in social networks",
        "link": "https://arxiv.org/abs/2502.14764",
        "author": "Izabel Aguiar, Philip S. Chodrow, Johan Ugander",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2502.14764v2 Announce Type: replace \nAbstract: Data recording connections between people in communities and villages are collected and analyzed in various ways, most often as either networks of individuals or as networks of households. These two networks can differ in substantial ways. The methodological choice of which network to study, therefore, is an important aspect in both study design and data analysis. In this work, we consider various key differences between household and individual social network structure, and ways in which the networks cannot be used interchangeably. In addition to formalizing the choices for representing each network, we explore the consequences of how the results of social network analysis change depending on the choice between studying the individual and household network -- from determining whether networks are assortative or disassortative to the ranking of influence-maximizing nodes. As our main contribution, we draw upon related work to propose a set of systematic recommendations for determining the relevant network representation to study. Our recommendations include assessing a series of entitativity criteria and relating these criteria to theories and observations about patterns and norms in social dynamics at the household level: notably, how information spreads within households and how power structures and gender roles affect this spread. We draw upon the definition of an illusion of entitativity to identify cases wherein grouping people into households does not satisfy these criteria or adequately represent given cultural or experimental contexts. Given the widespread use of social network data for studying communities, there is broad impact in understanding which network to study and the consequences of that decision. We hope that this work gives guidance to practitioners and researchers collecting and studying social network data."
      },
      {
        "id": "oai:arXiv.org:2502.18137v2",
        "title": "SpargeAttn: Accurate Sparse Attention Accelerating Any Model Inference",
        "link": "https://arxiv.org/abs/2502.18137",
        "author": "Jintao Zhang, Chendong Xiang, Haofeng Huang, Jia Wei, Haocheng Xi, Jun Zhu, Jianfei Chen",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2502.18137v2 Announce Type: replace \nAbstract: An efficient attention implementation is essential for large models due to its quadratic time complexity. Fortunately, attention commonly exhibits sparsity, i.e., many values in the attention map are near zero, allowing for the omission of corresponding computations. Many studies have utilized the sparse pattern to accelerate attention. However, most existing works focus on optimizing attention within specific models by exploiting certain sparse patterns of the attention map. A universal sparse attention that guarantees both the speedup and end-to-end performance of diverse models remains elusive. In this paper, we propose SpargeAttn, a universal sparse and quantized attention for any model. Our method uses a two-stage online filter: in the first stage, we rapidly and accurately predict the attention map, enabling the skip of some matrix multiplications in attention. In the second stage, we design an online softmax-aware filter that incurs no extra overhead and further skips some matrix multiplications. Experiments show that our method significantly accelerates diverse models, including language, image, and video generation, without sacrificing end-to-end metrics. The codes are available at https://github.com/thu-ml/SpargeAttn."
      },
      {
        "id": "oai:arXiv.org:2502.20824v2",
        "title": "MFSR-GAN: Multi-Frame Super-Resolution with Handheld Motion Modeling",
        "link": "https://arxiv.org/abs/2502.20824",
        "author": "Fadeel Sher Khan, Joshua Ebenezer, Hamid Sheikh, Seok-Jun Lee",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2502.20824v2 Announce Type: replace \nAbstract: Smartphone cameras have become ubiquitous imaging tools, yet their small sensors and compact optics often limit spatial resolution and introduce distortions. Combining information from multiple low-resolution (LR) frames to produce a high-resolution (HR) image has been explored to overcome the inherent limitations of smartphone cameras. Despite the promise of multi-frame super-resolution (MFSR), current approaches are hindered by datasets that fail to capture the characteristic noise and motion patterns found in real-world handheld burst images. In this work, we address this gap by introducing a novel synthetic data engine that uses multi-exposure static images to synthesize LR-HR training pairs while preserving sensor-specific noise characteristics and image motion found during handheld burst photography. We also propose MFSR-GAN: a multi-scale RAW-to-RGB network for MFSR. Compared to prior approaches, MFSR-GAN emphasizes a \"base frame\" throughout its architecture to mitigate artifacts. Experimental results on both synthetic and real data demonstrates that MFSR-GAN trained with our synthetic engine yields sharper, more realistic reconstructions than existing methods for real-world MFSR."
      },
      {
        "id": "oai:arXiv.org:2502.20984v3",
        "title": "UoR-NCL at SemEval-2025 Task 1: Using Generative LLMs and CLIP Models for Multilingual Multimodal Idiomaticity Representation",
        "link": "https://arxiv.org/abs/2502.20984",
        "author": "Thanet Markchom, Tong Wu, Liting Huang, Huizhi Liang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2502.20984v3 Announce Type: replace \nAbstract: SemEval-2025 Task 1 focuses on ranking images based on their alignment with a given nominal compound that may carry idiomatic meaning in both English and Brazilian Portuguese. To address this challenge, this work uses generative large language models (LLMs) and multilingual CLIP models to enhance idiomatic compound representations. LLMs generate idiomatic meanings for potentially idiomatic compounds, enriching their semantic interpretation. These meanings are then encoded using multilingual CLIP models, serving as representations for image ranking. Contrastive learning and data augmentation techniques are applied to fine-tune these embeddings for improved performance. Experimental results show that multimodal representations extracted through this method outperformed those based solely on the original nominal compounds. The fine-tuning approach shows promising outcomes but is less effective than using embeddings without fine-tuning. The source code used in this paper is available at https://github.com/tongwu17/SemEval-2025-Task1-UoR-NCL."
      },
      {
        "id": "oai:arXiv.org:2503.00917v2",
        "title": "AMUN: Adversarial Machine UNlearning",
        "link": "https://arxiv.org/abs/2503.00917",
        "author": "Ali Ebrahimpour-Boroojeny, Hari Sundaram, Varun Chandrasekaran",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2503.00917v2 Announce Type: replace \nAbstract: Machine unlearning, where users can request the deletion of a forget dataset, is becoming increasingly important because of numerous privacy regulations. Initial works on ``exact'' unlearning (e.g., retraining) incur large computational overheads. However, while computationally inexpensive, ``approximate'' methods have fallen short of reaching the effectiveness of exact unlearning: models produced fail to obtain comparable accuracy and prediction confidence on both the forget and test (i.e., unseen) dataset. Exploiting this observation, we propose a new unlearning method, Adversarial Machine UNlearning (AMUN), that outperforms prior state-of-the-art (SOTA) methods for image classification. AMUN lowers the confidence of the model on the forget samples by fine-tuning the model on their corresponding adversarial examples. Adversarial examples naturally belong to the distribution imposed by the model on the input space; fine-tuning the model on the adversarial examples closest to the corresponding forget samples (a) localizes the changes to the decision boundary of the model around each forget sample and (b) avoids drastic changes to the global behavior of the model, thereby preserving the model's accuracy on test samples. Using AMUN for unlearning a random $10\\%$ of CIFAR-10 samples, we observe that even SOTA membership inference attacks cannot do better than random guessing."
      },
      {
        "id": "oai:arXiv.org:2503.21510v2",
        "title": "Uncertainty-aware Bayesian machine learning modelling of land cover classification",
        "link": "https://arxiv.org/abs/2503.21510",
        "author": "Samuel Bilson, Anna Pustogvar",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2503.21510v2 Announce Type: replace \nAbstract: Land cover classification involves the production of land cover maps, which determine the type of land through remote sensing imagery. Over recent years, such classification is being performed by machine learning classification models, which can give highly accurate predictions on land cover per pixel using large quantities of input training data. However, such models do not currently take account of input measurement uncertainty, which is vital for traceability in metrology. In this work we propose a Bayesian classification framework using generative modelling to take account of input measurement uncertainty. We take the specific case of Bayesian quadratic discriminant analysis, and apply it to land cover datasets from Copernicus Sentinel-2 in 2020 and 2021. We benchmark the performance of the model against more popular classification models used in land cover maps such as random forests and neural networks. We find that such Bayesian models are more trustworthy, in the sense that they are more interpretable, explicitly model the input measurement uncertainty, and maintain predictive performance of class probability outputs across datasets of different years and sizes, whilst also being computationally efficient."
      },
      {
        "id": "oai:arXiv.org:2503.23895v2",
        "title": "Dynamic Parametric Retrieval Augmented Generation for Test-time Knowledge Enhancement",
        "link": "https://arxiv.org/abs/2503.23895",
        "author": "Yuqiao Tan, Shizhu He, Huanxuan Liao, Jun Zhao, Kang Liu",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2503.23895v2 Announce Type: replace \nAbstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs) by retrieving relevant documents from external sources and incorporating them into the context. While it improves reliability by providing factual texts, it significantly increases inference costs as context length grows and introduces challenging issue of RAG hallucination, primarily caused by the lack of corresponding parametric knowledge in LLMs. An efficient solution is to enhance the knowledge of LLMs at test-time. Parametric RAG (PRAG) addresses this by embedding document into LLMs parameters to perform test-time knowledge enhancement, effectively reducing inference costs through offline training. However, its high training and storage costs, along with limited generalization ability, significantly restrict its practical adoption. To address these challenges, we propose Dynamic Parametric RAG (DyPRAG), a novel framework that leverages a lightweight parameter translator model to efficiently convert documents into parametric knowledge. DyPRAG not only reduces inference, training, and storage costs but also dynamically generates parametric knowledge, seamlessly enhancing the knowledge of LLMs and resolving knowledge conflicts in a plug-and-play manner at test-time. Extensive experiments on multiple datasets demonstrate the effectiveness and generalization capabilities of DyPRAG, offering a powerful and practical RAG paradigm which enables superior knowledge fusion and mitigates RAG hallucination in real-world applications. Our code is available at https://github.com/Trae1ounG/DyPRAG."
      },
      {
        "id": "oai:arXiv.org:2504.00027v3",
        "title": "Opioid Named Entity Recognition (ONER-2025) from Reddit",
        "link": "https://arxiv.org/abs/2504.00027",
        "author": "Grigori Sidorov, Muhammad Ahmad, Iqra Ameer, Muhammad Usman, Ildar Batyrshin",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.00027v3 Announce Type: replace \nAbstract: The opioid overdose epidemic remains a critical public health crisis, particularly in the United States, leading to significant mortality and societal costs. Social media platforms like Reddit provide vast amounts of unstructured data that offer insights into public perceptions, discussions, and experiences related to opioid use. This study leverages Natural Language Processing (NLP), specifically Opioid Named Entity Recognition (ONER-2025), to extract actionable information from these platforms. Our research makes four key contributions. First, we created a unique, manually annotated dataset sourced from Reddit, where users share self-reported experiences of opioid use via different administration routes. This dataset contains 331,285 tokens and includes eight major opioid entity categories. Second, we detail our annotation process and guidelines while discussing the challenges of labeling the ONER-2025 dataset. Third, we analyze key linguistic challenges, including slang, ambiguity, fragmented sentences, and emotionally charged language, in opioid discussions. Fourth, we propose a real-time monitoring system to process streaming data from social media, healthcare records, and emergency services to identify overdose events. Using 5-fold cross-validation in 11 experiments, our system integrates machine learning, deep learning, and transformer-based language models with advanced contextual embeddings to enhance understanding. Our transformer-based models (bert-base-NER and roberta-base) achieved 97% accuracy and F1-score, outperforming baselines by 10.23% (RF=0.88)."
      },
      {
        "id": "oai:arXiv.org:2504.02546v3",
        "title": "GPG: A Simple and Strong Reinforcement Learning Baseline for Model Reasoning",
        "link": "https://arxiv.org/abs/2504.02546",
        "author": "Xiangxiang Chu, Hailang Huang, Xiao Zhang, Fei Wei, Yong Wang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.02546v3 Announce Type: replace \nAbstract: Reinforcement Learning (RL) can directly enhance the reasoning capabilities of large language models without extensive reliance on Supervised Fine-Tuning (SFT). In this work, we revisit the traditional Policy Gradient (PG) mechanism and propose a minimalist RL approach termed Group Policy Gradient (GPG). Unlike conventional methods, GPG directly optimize the original RL objective, thus obviating the need for surrogate loss functions. By eliminating the critic and reference models, avoiding KL divergence constraints, and addressing the advantage and gradient estimation bias, our approach significantly simplifies the training process compared to Group Relative Policy Optimization (GRPO). Our approach achieves superior performance without relying on auxiliary techniques or adjustments. As illustrated in Figure 1, extensive experiments demonstrate that our method not only reduces computational costs but also consistently outperforms GRPO across various unimodal and multimodal tasks. Our code is available at https://github.com/AMAP-ML/GPG."
      },
      {
        "id": "oai:arXiv.org:2504.02782v2",
        "title": "GPT-ImgEval: A Comprehensive Benchmark for Diagnosing GPT4o in Image Generation",
        "link": "https://arxiv.org/abs/2504.02782",
        "author": "Zhiyuan Yan, Junyan Ye, Weijia Li, Zilong Huang, Shenghai Yuan, Xiangyang He, Kaiqing Lin, Jun He, Conghui He, Li Yuan",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.02782v2 Announce Type: replace \nAbstract: The recent breakthroughs in OpenAI's GPT4o model have demonstrated surprisingly good capabilities in image generation and editing, resulting in significant excitement in the community. This technical report presents the first-look evaluation benchmark (named GPT-ImgEval), quantitatively and qualitatively diagnosing GPT-4o's performance across three critical dimensions: (1) generation quality, (2) editing proficiency, and (3) world knowledge-informed semantic synthesis. Across all three tasks, GPT-4o demonstrates strong performance, significantly surpassing existing methods in both image generation control and output quality, while also showcasing exceptional knowledge reasoning capabilities. Furthermore, based on the GPT-4o's generated data, we propose a classification-model-based approach to investigate the underlying architecture of GPT-4o, where our empirical results suggest the model consists of an auto-regressive (AR) combined with a diffusion-based head for image decoding, rather than the VAR-like architectures. We also provide a complete speculation on GPT-4o's overall architecture. In addition, we conduct a series of analyses to identify and visualize GPT-4o's specific limitations and the synthetic artifacts commonly observed in its image generation. We also present a comparative study of multi-round image editing between GPT-4o and Gemini 2.0 Flash, and discuss the safety implications of GPT-4o's outputs, particularly their detectability by existing image forensic models. We hope that our work can offer valuable insight and provide a reliable benchmark to guide future research, foster reproducibility, and accelerate innovation in the field of image generation and beyond. The codes and datasets used for evaluating GPT-4o can be found at https://github.com/PicoTrex/GPT-ImgEval."
      },
      {
        "id": "oai:arXiv.org:2504.03359v2",
        "title": "A metrological framework for uncertainty evaluation in machine learning classification models",
        "link": "https://arxiv.org/abs/2504.03359",
        "author": "Samuel Bilson, Maurice Cox, Anna Pustogvar, Andrew Thompson",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.03359v2 Announce Type: replace \nAbstract: Machine learning (ML) classification models are increasingly being used in a wide range of applications where it is important that predictions are accompanied by uncertainties, including in climate and earth observation, medical diagnosis and bioaerosol monitoring. The output of an ML classification model is a type of categorical variable known as a nominal property in the International Vocabulary of Metrology (VIM). However, concepts related to uncertainty evaluation for nominal properties are not defined in the VIM, nor is such evaluation addressed by the Guide to the Expression of Uncertainty in Measurement (GUM). In this paper we propose a metrological conceptual uncertainty evaluation framework for ML classification, and illustrate its use in the context of two applications that exemplify the issues and have significant societal impact, namely, climate and earth observation and medical diagnosis. Our framework would enable an extension of the VIM and GUM to uncertainty for nominal properties, which would make both applicable to ML classification models."
      },
      {
        "id": "oai:arXiv.org:2504.04318v3",
        "title": "Variational Self-Supervised Learning",
        "link": "https://arxiv.org/abs/2504.04318",
        "author": "Mehmet Can Yavuz, Berrin Yanikoglu",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.04318v3 Announce Type: replace \nAbstract: We present Variational Self-Supervised Learning (VSSL), a novel framework that combines variational inference with self-supervised learning to enable efficient, decoder-free representation learning. Unlike traditional VAEs that rely on input reconstruction via a decoder, VSSL symmetrically couples two encoders with Gaussian outputs. A momentum-updated teacher network defines a dynamic, data-dependent prior, while the student encoder produces an approximate posterior from augmented views. The reconstruction term in the ELBO is replaced with a cross-view denoising objective, preserving the analytical tractability of Gaussian KL divergence. We further introduce cosine-based formulations of KL and log-likelihood terms to enhance semantic alignment in high-dimensional latent spaces. Experiments on CIFAR-10, CIFAR-100, and ImageNet-100 show that VSSL achieves competitive or superior performance to leading self-supervised methods, including BYOL and MoCo V3. VSSL offers a scalable, probabilistically grounded approach to learning transferable representations without generative reconstruction, bridging the gap between variational modeling and modern self-supervised techniques."
      },
      {
        "id": "oai:arXiv.org:2504.04798v4",
        "title": "TabRep: Training Tabular Diffusion Models with a Simple and Effective Continuous Representation",
        "link": "https://arxiv.org/abs/2504.04798",
        "author": "Jacob Si, Zijing Ou, Mike Qu, Zhengrui Xiang, Yingzhen Li",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.04798v4 Announce Type: replace \nAbstract: Diffusion models have been the predominant generative model for tabular data generation. However, they face the conundrum of modeling under a separate versus a unified data representation. The former encounters the challenge of jointly modeling all multi-modal distributions of tabular data in one model. While the latter alleviates this by learning a single representation for all features, it currently leverages sparse suboptimal encoding heuristics and necessitates additional computation costs. In this work, we address the latter by presenting TabRep, a tabular diffusion architecture trained with a unified continuous representation. To motivate the design of our representation, we provide geometric insights into how the data manifold affects diffusion models. The key attributes of our representation are composed of its density, flexibility to provide ample separability for nominal features, and ability to preserve intrinsic relationships. Ultimately, TabRep provides a simple yet effective approach for training tabular diffusion models under a continuous data manifold. Our results showcase that TabRep achieves superior performance across a broad suite of evaluations. It is the first to synthesize tabular data that exceeds the downstream quality of the original datasets while preserving privacy and remaining computationally efficient."
      },
      {
        "id": "oai:arXiv.org:2504.05304v2",
        "title": "Gaussian Mixture Flow Matching Models",
        "link": "https://arxiv.org/abs/2504.05304",
        "author": "Hansheng Chen, Kai Zhang, Hao Tan, Zexiang Xu, Fujun Luan, Leonidas Guibas, Gordon Wetzstein, Sai Bi",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.05304v2 Announce Type: replace \nAbstract: Diffusion models approximate the denoising distribution as a Gaussian and predict its mean, whereas flow matching models reparameterize the Gaussian mean as flow velocity. However, they underperform in few-step sampling due to discretization error and tend to produce over-saturated colors under classifier-free guidance (CFG). To address these limitations, we propose a novel Gaussian mixture flow matching (GMFlow) model: instead of predicting the mean, GMFlow predicts dynamic Gaussian mixture (GM) parameters to capture a multi-modal flow velocity distribution, which can be learned with a KL divergence loss. We demonstrate that GMFlow generalizes previous diffusion and flow matching models where a single Gaussian is learned with an $L_2$ denoising loss. For inference, we derive GM-SDE/ODE solvers that leverage analytic denoising distributions and velocity fields for precise few-step sampling. Furthermore, we introduce a novel probabilistic guidance scheme that mitigates the over-saturation issues of CFG and improves image generation quality. Extensive experiments demonstrate that GMFlow consistently outperforms flow matching baselines in generation quality, achieving a Precision of 0.942 with only 6 sampling steps on ImageNet 256$\\times$256."
      },
      {
        "id": "oai:arXiv.org:2504.05520v2",
        "title": "Efficient Reinforcement Finetuning via Adaptive Curriculum Learning",
        "link": "https://arxiv.org/abs/2504.05520",
        "author": "Taiwei Shi, Yiyang Wu, Linxin Song, Tianyi Zhou, Jieyu Zhao",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.05520v2 Announce Type: replace \nAbstract: Reinforcement finetuning (RFT) has shown great potential for enhancing the mathematical reasoning capabilities of large language models (LLMs), but it is often sample- and compute-inefficient, requiring extensive training. In this work, we introduce AdaRFT (Adaptive Curriculum Reinforcement Finetuning), a method that significantly improves both the efficiency and final accuracy of RFT through adaptive curriculum learning. AdaRFT dynamically adjusts the difficulty of training problems based on the model's recent reward signals, ensuring that the model consistently trains on tasks that are challenging but solvable. This adaptive sampling strategy accelerates learning by maintaining an optimal difficulty range, avoiding wasted computation on problems that are too easy or too hard. AdaRFT requires only a lightweight extension to standard RFT algorithms like Proximal Policy Optimization (PPO), without modifying the reward function or model architecture. Experiments on competition-level math datasets-including AMC, AIME, and IMO-style problems-demonstrate that AdaRFT significantly improves both training efficiency and reasoning performance. We evaluate AdaRFT across multiple data distributions and model sizes, showing that it reduces training time by up to 2x and improves accuracy by a considerable margin, offering a more scalable and effective RFT framework."
      },
      {
        "id": "oai:arXiv.org:2504.07835v4",
        "title": "Pychop: Emulating Low-Precision Arithmetic in Numerical Methods and Neural Networks",
        "link": "https://arxiv.org/abs/2504.07835",
        "author": "Erin Carson, Xinye Chen",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.07835v4 Announce Type: replace \nAbstract: Motivated by the growing demand for low-precision arithmetic in computational science, we exploit lower-precision emulation in Python -- widely regarded as the dominant programming language for numerical analysis and machine learning. Low-precision training has revolutionized deep learning by enabling more efficient computation and reduced memory and energy consumption while maintaining model fidelity. To better enable numerical experimentation with and exploration of low precision computation, we developed the Pychop library, which supports customizable floating-point formats and a comprehensive set of rounding modes in Python, allowing users to benefit from fast, low-precision emulation in numerous applications. Pychop also introduces interfaces for both PyTorch and JAX, enabling efficient low-precision emulation on GPUs for neural network training and inference with unparalleled flexibility.\n  In this paper, we offer a comprehensive exposition of the design, implementation, validation, and practical application of Pychop, establishing it as a foundational tool for advancing efficient mixed-precision algorithms. Furthermore, we present empirical results on low-precision emulation for image classification and object detection using published datasets, illustrating the sensitivity of the use of low precision and offering valuable insights into its impact. Pychop enables in-depth investigations into the effects of numerical precision, facilitates the development of novel hardware accelerators, and integrates seamlessly into existing deep learning workflows. Software and experimental code are publicly available at https://github.com/inEXASCALE/pychop."
      },
      {
        "id": "oai:arXiv.org:2504.09948v3",
        "title": "Omni-Dish: Photorealistic and Faithful Image Generation and Editing for Arbitrary Chinese Dishes",
        "link": "https://arxiv.org/abs/2504.09948",
        "author": "Huijie Liu, Bingcan Wang, Jie Hu, Xiaoming Wei, Guoliang Kang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.09948v3 Announce Type: replace \nAbstract: Dish images play a crucial role in the digital era, with the demand for culturally distinctive dish images continuously increasing due to the digitization of the food industry and e-commerce. In general cases, existing text-to-image generation models excel in producing high-quality images; however, they struggle to capture diverse characteristics and faithful details of specific domains, particularly Chinese dishes. To address this limitation, we propose Omni-Dish, the first text-to-image generation model specifically tailored for Chinese dishes. We develop a comprehensive dish curation pipeline, building the largest dish dataset to date. Additionally, we introduce a recaption strategy and employ a coarse-to-fine training scheme to help the model better learn fine-grained culinary nuances. During inference, we enhance the user's textual input using a pre-constructed high-quality caption library and a large language model, enabling more photorealistic and faithful image generation. Furthermore, to extend our model's capability for dish editing tasks, we propose Concept-Enhanced P2P. Based on this approach, we build a dish editing dataset and train a specialized editing model. Extensive experiments demonstrate the superiority of our methods."
      },
      {
        "id": "oai:arXiv.org:2504.12561v2",
        "title": "Kernel Ridge Regression for Efficient Learning of High-Capacity Hopfield Networks",
        "link": "https://arxiv.org/abs/2504.12561",
        "author": "Akira Tamamori",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.12561v2 Announce Type: replace \nAbstract: Hopfield networks using Hebbian learning suffer from limited storage capacity. While supervised methods like Linear Logistic Regression (LLR) offer some improvement, kernel methods like Kernel Logistic Regression (KLR) significantly enhance capacity and noise robustness. However, KLR requires computationally expensive iterative learning. We propose Kernel Ridge Regression (KRR) as an efficient kernel-based alternative for learning high-capacity Hopfield networks. KRR utilizes the kernel trick and predicts bipolar states via regression, crucially offering a non-iterative, closed-form solution for learning dual variables. We evaluate KRR and compare its performance against Hebbian, LLR, and KLR. Our results demonstrate that KRR achieves state-of-the-art storage capacity (reaching $\\beta$=1.5) and noise robustness, comparable to KLR. Crucially, KRR drastically reduces training time, being orders of magnitude faster than LLR and significantly faster than KLR, especially at higher storage loads. This establishes KRR as a potent and highly efficient method for building high-performance associative memories, providing comparable performance to KLR with substantial training speed advantages. This work provides the first empirical comparison between KRR and KLR in the context of Hopfield network learning."
      },
      {
        "id": "oai:arXiv.org:2504.14194v2",
        "title": "Meta-rater: A Multi-dimensional Data Selection Method for Pre-training Language Models",
        "link": "https://arxiv.org/abs/2504.14194",
        "author": "Xinlin Zhuang, Jiahui Peng, Ren Ma, Yinfan Wang, Tianyi Bai, Xingjian Wei, Jiantao Qiu, Chi Zhang, Ying Qian, Conghui He",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.14194v2 Announce Type: replace \nAbstract: The composition of pre-training datasets for large language models (LLMs) remains largely undisclosed, hindering transparency and efforts to optimize data quality, a critical driver of model performance. Current data selection methods, such as natural language quality assessments, diversity-based filters, and classifier-based approaches, are limited by single-dimensional evaluation or redundancy-focused strategies. To address these gaps, we propose PRRC to evaluate data quality across Professionalism, Readability, Reasoning, and Cleanliness. We further introduce Meta-rater, a multi-dimensional data selection method that integrates these dimensions with existing quality metrics through learned optimal weightings. Meta-rater employs proxy models to train a regression model that predicts validation loss, enabling the identification of optimal combinations of quality scores. Experiments demonstrate that Meta-rater doubles convergence speed for 1.3B parameter models and improves downstream task performance by 3.23, with scalable benefits observed in 3.3B models trained on 100B tokens. Additionally, we release the annotated SlimPajama-627B dataset, labeled across 25 quality metrics (including PRRC), to advance research in data-centric LLM development. Our work establishes that holistic, multi-dimensional quality integration significantly outperforms conventional single-dimension approaches, offering a scalable paradigm for enhancing pre-training efficiency and model capability."
      },
      {
        "id": "oai:arXiv.org:2504.14467v2",
        "title": "LGD: Leveraging Generative Descriptions for Zero-Shot Referring Image Segmentation",
        "link": "https://arxiv.org/abs/2504.14467",
        "author": "Jiachen Li, Qing Xie, Renshu Gu, Jinyu Xu, Yongjian Liu, Xiaohan Yu",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.14467v2 Announce Type: replace \nAbstract: Zero-shot referring image segmentation aims to locate and segment the target region based on a referring expression, with the primary challenge of aligning and matching semantics across visual and textual modalities without training. Previous works address this challenge by utilizing Vision-Language Models and mask proposal networks for region-text matching. However, this paradigm may lead to incorrect target localization due to the inherent ambiguity and diversity of free-form referring expressions. To alleviate this issue, we present LGD (Leveraging Generative Descriptions), a framework that utilizes the advanced language generation capabilities of Multi-Modal Large Language Models to enhance region-text matching performance in Vision-Language Models. Specifically, we first design two kinds of prompts, the attribute prompt and the surrounding prompt, to guide the Multi-Modal Large Language Models in generating descriptions related to the crucial attributes of the referent object and the details of surrounding objects, referred to as attribute description and surrounding description, respectively. Secondly, three visual-text matching scores are introduced to evaluate the similarity between instance-level visual features and textual features, which determines the mask most associated with the referring expression. The proposed method achieves new state-of-the-art performance on three public datasets RefCOCO, RefCOCO+ and RefCOCOg, with maximum improvements of 9.97% in oIoU and 11.29% in mIoU compared to previous methods."
      },
      {
        "id": "oai:arXiv.org:2504.16060v2",
        "title": "Vision-Language Models Are Not Pragmatically Competent in Referring Expression Generation",
        "link": "https://arxiv.org/abs/2504.16060",
        "author": "Ziqiao Ma, Jing Ding, Xuejun Zhang, Dezhi Luo, Jiahe Ding, Sihan Xu, Yuchen Huang, Run Peng, Joyce Chai",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.16060v2 Announce Type: replace \nAbstract: Referring Expression Generation (REG) is a core task for evaluating the pragmatic competence of vision-language systems, requiring not only accurate semantic grounding but also adherence to principles of cooperative communication (Grice, 1975). However, current evaluations of vision-language models (VLMs) often overlook the pragmatic dimension, reducing REG to a region-based captioning task and neglecting Gricean maxims. In this work, we revisit REG from a pragmatic perspective, introducing a new dataset (RefOI) of 1.5k images annotated with both written and spoken referring expressions. Through a systematic evaluation of state-of-the-art VLMs, we identify three key failures of pragmatic competence: (1) failure to uniquely identify the referent, (2) inclusion of excessive or irrelevant information, and (3) misalignment with human pragmatic preference, such as the underuse of minimal spatial cues. We also show that standard automatic evaluations fail to capture these pragmatic violations, reinforcing superficial cues rather than genuine referential success. Our findings call for a renewed focus on pragmatically informed models and evaluation frameworks that align with real human communication."
      },
      {
        "id": "oai:arXiv.org:2504.17066v2",
        "title": "Whence Is A Model Fair? Fixing Fairness Bugs via Propensity Score Matching",
        "link": "https://arxiv.org/abs/2504.17066",
        "author": "Kewen Peng, Yicheng Yang, Hao Zhuo",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.17066v2 Announce Type: replace \nAbstract: Fairness-aware learning aims to mitigate discrimination against specific protected social groups (e.g., those categorized by gender, ethnicity, age) while minimizing predictive performance loss. Despite efforts to improve fairness in machine learning, prior studies have shown that many models remain unfair when measured against various fairness metrics. In this paper, we examine whether the way training and testing data are sampled affects the reliability of reported fairness metrics. Since training and test sets are often randomly sampled from the same population, bias present in the training data may still exist in the test data, potentially skewing fairness assessments. To address this, we propose FairMatch, a post-processing method that applies propensity score matching to evaluate and mitigate bias. FairMatch identifies control and treatment pairs with similar propensity scores in the test set and adjusts decision thresholds for different subgroups accordingly. For samples that cannot be matched, we perform probabilistic calibration using fairness-aware loss functions. Experimental results demonstrate that our approach can (a) precisely locate subsets of the test data where the model is unbiased, and (b) significantly reduce bias on the remaining data. Overall, propensity score matching offers a principled way to improve both fairness evaluation and mitigation, without sacrificing predictive performance."
      },
      {
        "id": "oai:arXiv.org:2504.17074v3",
        "title": "Conditional Diffusion-Based Retrieval of Atmospheric CO2 from Earth Observing Spectroscopy",
        "link": "https://arxiv.org/abs/2504.17074",
        "author": "William R. Keely, Otto Lamminp\\\"a\\\"a, Steffen Mauceri, Sean M. R. Crowell, Christopher W. O'Dell, Gregory R. McGarragh",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.17074v3 Announce Type: replace \nAbstract: Satellite-based estimates of greenhouse gas (GHG) properties from observations of reflected solar spectra are integral for understanding and monitoring complex terrestrial systems and their impact on the carbon cycle due to their near global coverage. Known as retrieval, making GHG concentration estimations from these observations is a non-linear Bayesian inverse problem, which is operationally solved using a computationally expensive algorithm called Optimal Estimation (OE), providing a Gaussian approximation to a non-Gaussian posterior. This leads to issues in solver algorithm convergence, and to unrealistically confident uncertainty estimates for the retrieved quantities. Upcoming satellite missions will provide orders of magnitude more data than the current constellation of GHG observers. Development of fast and accurate retrieval algorithms with robust uncertainty quantification is critical. Doing so stands to provide substantial climate impact of moving towards the goal of near continuous real-time global monitoring of carbon sources and sinks which is essential for policy making. To achieve this goal, we propose a diffusion-based approach to flexibly retrieve a Gaussian or non-Gaussian posterior, for NASA's Orbiting Carbon Observatory-2 spectrometer, while providing a substantial computational speed-up over the current operational state-of-the-art."
      },
      {
        "id": "oai:arXiv.org:2504.18506v2",
        "title": "Action-Minimization Meets Generative Modeling: Efficient Transition Path Sampling with the Onsager-Machlup Functional",
        "link": "https://arxiv.org/abs/2504.18506",
        "author": "Sanjeev Raja, Martin \\v{S}\\'ipka, Michael Psenka, Tobias Kreiman, Michal Pavelka, Aditi S. Krishnapriyan",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.18506v2 Announce Type: replace \nAbstract: Transition path sampling (TPS), which involves finding probable paths connecting two points on an energy landscape, remains a challenge due to the complexity of real-world atomistic systems. Current machine learning approaches use expensive, task-specific, and data-free training procedures, limiting their ability to benefit from recent advances in atomistic machine learning, such as high-quality datasets and large-scale pre-trained models. In this work, we address TPS by interpreting candidate paths as trajectories sampled from stochastic dynamics induced by the learned score function of pre-trained generative models, specifically denoising diffusion and flow matching. Under these dynamics, finding high-likelihood transition paths becomes equivalent to minimizing the Onsager-Machlup (OM) action functional. This enables us to repurpose pre-trained generative models for TPS in a zero-shot manner, in contrast with bespoke, task-specific TPS models trained in previous work. We demonstrate our approach on varied molecular systems, obtaining diverse, physically realistic transition pathways and generalizing beyond the pre-trained model's original training dataset. Our method can be easily incorporated into new generative models, making it practically relevant as models continue to scale and improve with increased data availability."
      },
      {
        "id": "oai:arXiv.org:2504.19013v3",
        "title": "$PINN - a Domain Decomposition Method for Bayesian Physics-Informed Neural Networks",
        "link": "https://arxiv.org/abs/2504.19013",
        "author": "J\\'ulia Vicens Figueres, Juliette Vanderhaeghen, Federica Bragone, Kateryna Morozovska, Khemraj Shukla",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.19013v3 Announce Type: replace \nAbstract: Physics-Informed Neural Networks (PINNs) are a novel computational approach for solving partial differential equations (PDEs) with noisy and sparse initial and boundary data. Although, efficient quantification of epistemic and aleatoric uncertainties in big multi-scale problems remains challenging. We propose \\$PINN a novel method of computing global uncertainty in PDEs using a Bayesian framework, by combining local Bayesian Physics-Informed Neural Networks (BPINN) with domain decomposition. The solution continuity across subdomains is obtained by imposing the flux continuity across the interface of neighboring subdomains. To demonstrate the effectiveness of \\$PINN, we conduct a series of computational experiments on PDEs in 1D and 2D spatial domains. Although we have adopted conservative PINNs (cPINNs), the method can be seamlessly extended to other domain decomposition techniques. The results infer that the proposed method recovers the global uncertainty by computing the local uncertainty exactly more efficiently as the uncertainty in each subdomain can be computed concurrently. The robustness of \\$PINN is verified by adding uncorrelated random noise to the training data up to 15% and testing for different domain sizes."
      },
      {
        "id": "oai:arXiv.org:2504.19314v2",
        "title": "BrowseComp-ZH: Benchmarking Web Browsing Ability of Large Language Models in Chinese",
        "link": "https://arxiv.org/abs/2504.19314",
        "author": "Peilin Zhou, Bruce Leon, Xiang Ying, Can Zhang, Yifan Shao, Qichen Ye, Dading Chong, Zhiling Jin, Chenxuan Xie, Meng Cao, Yuxin Gu, Sixin Hong, Jing Ren, Jian Chen, Chao Liu, Yining Hua",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.19314v2 Announce Type: replace \nAbstract: As large language models (LLMs) evolve into tool-using agents, the ability to browse the web in real-time has become a critical yardstick for measuring their reasoning and retrieval competence. Existing benchmarks such as BrowseComp concentrate on English and overlook the linguistic, infrastructural, and censorship-related complexities of other major information ecosystems -- most notably Chinese. To address this gap, we introduce BrowseComp-ZH, a high-difficulty benchmark purpose-built to comprehensively evaluate LLM agents on the Chinese web. BrowseComp-ZH consists of 289 multi-hop questions spanning 11 diverse domains. Each question is reverse-engineered from a short, objective, and easily verifiable answer (e.g., a date, number, or proper noun). A two-stage quality control protocol is applied to strive for high question difficulty and answer uniqueness. We benchmark over 20 state-of-the-art language models and agentic search systems on our proposed BrowseComp-ZH. Despite their strong conversational and retrieval capabilities, most models struggle severely: a large number achieve accuracy rates below 10%, and only a handful exceed 20%. Even the best-performing system, OpenAI's DeepResearch, reaches just 42.9%. These results demonstrate the considerable difficulty of BrowseComp-ZH, where success demands not only effective retrieval strategies, but also sophisticated reasoning and information reconciliation -- capabilities that current models still struggle to master. Our dataset, construction guidelines, and benchmark results have been publicly released at https://github.com/PALIN2018/BrowseComp-ZH."
      },
      {
        "id": "oai:arXiv.org:2504.19467v2",
        "title": "BRIDGE: Benchmarking Large Language Models for Understanding Real-world Clinical Practice Text",
        "link": "https://arxiv.org/abs/2504.19467",
        "author": "Jiageng Wu, Bowen Gu, Ren Zhou, Kevin Xie, Doug Snyder, Yixing Jiang, Valentina Carducci, Richard Wyss, Rishi J Desai, Emily Alsentzer, Leo Anthony Celi, Adam Rodman, Sebastian Schneeweiss, Jonathan H. Chen, Santiago Romero-Brufau, Kueiyu Joshua Lin, Jie Yang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.19467v2 Announce Type: replace \nAbstract: Large language models (LLMs) hold great promise for medical applications and are evolving rapidly, with new models being released at an accelerated pace. However, current evaluations of LLMs in clinical contexts remain limited. Most existing benchmarks rely on medical exam-style questions or PubMed-derived text, failing to capture the complexity of real-world electronic health record (EHR) data. Others focus narrowly on specific application scenarios, limiting their generalizability across broader clinical use. To address this gap, we present BRIDGE, a comprehensive multilingual benchmark comprising 87 tasks sourced from real-world clinical data sources across nine languages. We systematically evaluated 52 state-of-the-art LLMs (including DeepSeek-R1, GPT-4o, Gemini, and Llama 4) under various inference strategies. With a total of 13,572 experiments, our results reveal substantial performance variation across model sizes, languages, natural language processing tasks, and clinical specialties. Notably, we demonstrate that open-source LLMs can achieve performance comparable to proprietary models, while medically fine-tuned LLMs based on older architectures often underperform versus updated general-purpose models. The BRIDGE and its corresponding leaderboard serve as a foundational resource and a unique reference for the development and evaluation of new LLMs in real-world clinical text understanding.\n  The BRIDGE leaderboard: https://huggingface.co/spaces/YLab-Open/BRIDGE-Medical-Leaderboard"
      },
      {
        "id": "oai:arXiv.org:2504.19602v2",
        "title": "Soft-Label Caching and Sharpening for Communication-Efficient Federated Distillation",
        "link": "https://arxiv.org/abs/2504.19602",
        "author": "Kitsuya Azuma, Takayuki Nishio, Yuichi Kitagawa, Wakako Nakano, Takahito Tanimura",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.19602v2 Announce Type: replace \nAbstract: Federated Learning (FL) enables collaborative model training across decentralized clients, enhancing privacy by keeping data local. Yet conventional FL, relying on frequent parameter-sharing, suffers from high communication overhead and limited model heterogeneity. Distillation-based FL approaches address these issues by sharing predictions (soft-labels) instead, but they often involve redundant transmissions across communication rounds, reducing efficiency. We propose SCARLET, a novel framework integrating synchronized soft-label caching and an enhanced Entropy Reduction Aggregation (Enhanced ERA) mechanism. SCARLET minimizes redundant communication by reusing cached soft-labels, achieving up to 50% reduction in communication costs compared to existing methods while maintaining accuracy. Enhanced ERA can be tuned to adapt to non-IID data variations, ensuring robust aggregation and performance in diverse client scenarios. Experimental evaluations demonstrate that SCARLET consistently outperforms state-of-the-art distillation-based FL methods in terms of accuracy and communication efficiency. The implementation of SCARLET is publicly available at https://github.com/kitsuyaazuma/SCARLET."
      },
      {
        "id": "oai:arXiv.org:2504.20379v2",
        "title": "GSFeatLoc: Visual Localization Using Feature Correspondence on 3D Gaussian Splatting",
        "link": "https://arxiv.org/abs/2504.20379",
        "author": "Jongwon Lee, Timothy Bretl",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.20379v2 Announce Type: replace \nAbstract: In this paper, we present a method for localizing a query image with respect to a precomputed 3D Gaussian Splatting (3DGS) scene representation. First, the method uses 3DGS to render a synthetic RGBD image at some initial pose estimate. Second, it establishes 2D-2D correspondences between the query image and this synthetic image. Third, it uses the depth map to lift the 2D-2D correspondences to 2D-3D correspondences and solves a perspective-n-point (PnP) problem to produce a final pose estimate. Results from evaluation across three existing datasets with 38 scenes and over 2,700 test images show that our method significantly reduces both inference time (by over two orders of magnitude, from more than 10 seconds to as fast as 0.1 seconds) and estimation error compared to baseline methods that use photometric loss minimization. Results also show that our method tolerates large errors in the initial pose estimate of up to 55{\\deg} in rotation and 1.1 units in translation (normalized by scene scale), achieving final pose errors of less than 5{\\deg} in rotation and 0.05 units in translation on 90% of images from the Synthetic NeRF and Mip-NeRF360 datasets and on 42% of images from the more challenging Tanks and Temples dataset."
      },
      {
        "id": "oai:arXiv.org:2504.20946v2",
        "title": "Trace-of-Thought Prompting: Investigating Prompt-Based Knowledge Distillation Through Question Decomposition",
        "link": "https://arxiv.org/abs/2504.20946",
        "author": "Tyler McDonald, Ali Emami",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.20946v2 Announce Type: replace \nAbstract: Knowledge distillation allows smaller neural networks to emulate the performance of larger, teacher models with reduced computational demands. Traditional methods for Large Language Models (LLMs) often necessitate extensive fine-tuning, which limits their accessibility. To address this, we introduce Trace-of-Thought Prompting, a novel framework designed to distill critical reasoning capabilities from high-resource teacher models (over 8 billion parameters) to low-resource student models (up to 8 billion parameters). This approach leverages problem decomposition to enhance interpretability and facilitate human-in-the-loop interventions. Empirical evaluations on the GSM8K and MATH datasets show that student models achieve accuracy gains of up to 113% on GSM8K and 21% on MATH, with significant improvements particularly notable in smaller models like Llama 2 and Zephyr. Our results suggest a promising pathway for open-source, low-resource models to eventually serve both as both students and teachers, potentially reducing our reliance on high-resource, proprietary models."
      },
      {
        "id": "oai:arXiv.org:2504.21012v2",
        "title": "Waking Up an AI: A Quantitative Framework for Prompt-Induced Phase Transition in Large Language Models",
        "link": "https://arxiv.org/abs/2504.21012",
        "author": "Makoto Sato",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.21012v2 Announce Type: replace \nAbstract: What underlies intuitive human thinking? One approach to this question is to compare the cognitive dynamics of humans and large language models (LLMs). However, such a comparison requires a method to quantitatively analyze AI cognitive behavior under controlled conditions. While anecdotal observations suggest that certain prompts can dramatically change LLM behavior, these observations have remained largely qualitative. Here, we propose a two-part framework to investigate this phenomenon: a Transition-Inducing Prompt (TIP) that triggers a rapid shift in LLM responsiveness, and a Transition Quantifying Prompt (TQP) that evaluates this change using a separate LLM. Through controlled experiments, we examined how LLMs react to prompts embedding two semantically distant concepts (e.g., mathematical aperiodicity and traditional crafts)-either fused together or presented separately-by changing their linguistic quality and affective tone. Whereas humans tend to experience heightened engagement when such concepts are meaningfully blended producing a novel concept-a form of conceptual fusion-current LLMs showed no significant difference in responsiveness between semantically fused and non-fused prompts. This suggests that LLMs may not yet replicate the conceptual integration processes seen in human intuition. Our method enables fine-grained, reproducible measurement of cognitive responsiveness, and may help illuminate key differences in how intuition and conceptual leaps emerge in artificial versus human minds."
      },
      {
        "id": "oai:arXiv.org:2504.21800v2",
        "title": "How Real Are Synthetic Therapy Conversations? Evaluating Fidelity in Prolonged Exposure Dialogues",
        "link": "https://arxiv.org/abs/2504.21800",
        "author": "Suhas BN, Dominik Mattioli, Saeed Abdullah, Rosa I. Arriaga, Chris W. Wiese, Andrew M. Sherrill",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.21800v2 Announce Type: replace \nAbstract: The growing adoption of synthetic data in healthcare is driven by privacy concerns, limited access to real-world data, and the high cost of annotation. This work explores the use of synthetic Prolonged Exposure (PE) therapeutic conversations for Post-Traumatic Stress Disorder (PTSD) as a scalable alternative for training and evaluating clinical models. We systematically compare real and synthetic dialogues using linguistic, structural, and protocol-specific metrics, including turn-taking patterns and treatment fidelity. We also introduce and evaluate PE-specific metrics derived from linguistic analysis and semantic modeling, offering a novel framework for assessing clinical fidelity beyond surface fluency. Our findings show that although synthetic data holds promise for mitigating data scarcity and protecting patient privacy, it can struggle to capture the subtle dynamics of therapeutic interactions. Synthetic therapy dialogues closely match structural features of real-world conversations (e.g., speaker switch ratio: 0.98 vs. 0.99); however, they may not adequately reflect key fidelity markers (e.g., distress monitoring). We highlight gaps in existing evaluation frameworks and advocate for fidelity-aware metrics that go beyond surface fluency to uncover clinically significant failures. Our findings clarify where synthetic data can effectively complement real-world datasets -- and where critical limitations remain."
      },
      {
        "id": "oai:arXiv.org:2301.06987v3",
        "title": "Sim-Anchored Learning for On-the-Fly Adaptation",
        "link": "https://arxiv.org/abs/2301.06987",
        "author": "Bassel El Mabsout, Shahin Roozkhosh, Siddharth Mysore, Kate Saenko, Renato Mancuso",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2301.06987v3 Announce Type: replace-cross \nAbstract: Fine-tuning simulation-trained RL agents with real-world data often degrades crucial behaviors due to limited or skewed data distributions. We argue that designer priorities exist not just in reward functions, but also in simulation design choices like task selection and state initialization. When adapting to real-world data, agents can experience catastrophic forgetting in important but underrepresented scenarios. We propose framing live-adaptation as a multi-objective optimization problem, where policy objectives must be satisfied both in simulation and reality. Our approach leverages critics from simulation as \"anchors for design intent\" (anchor critics). By jointly optimizing policies against both anchor critics and critics trained on real-world experience, our method enables adaptation while preserving prioritized behaviors from simulation. Evaluations demonstrate robust behavior retention in sim-to-sim benchmarks and a sim-to-real scenario with a racing quadrotor, allowing for power consumption reductions of up to 50% without control loss. We also contribute SwaNNFlight, an open-source firmware for enabling live adaptation on similar robotic platforms."
      },
      {
        "id": "oai:arXiv.org:2302.00316v3",
        "title": "Accelerated First-Order Optimization under Nonlinear Constraints",
        "link": "https://arxiv.org/abs/2302.00316",
        "author": "Michael Muehlebach, Michael I. Jordan",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2302.00316v3 Announce Type: replace-cross \nAbstract: We exploit analogies between first-order algorithms for constrained optimization and non-smooth dynamical systems to design a new class of accelerated first-order algorithms for constrained optimization. Unlike Frank-Wolfe or projected gradients, these algorithms avoid optimization over the entire feasible set at each iteration. We prove convergence to stationary points even in a nonconvex setting and we derive accelerated rates for the convex setting both in continuous time, as well as in discrete time. An important property of these algorithms is that constraints are expressed in terms of velocities instead of positions, which naturally leads to sparse, local and convex approximations of the feasible set (even if the feasible set is nonconvex). Thus, the complexity tends to grow mildly in the number of decision variables and in the number of constraints, which makes the algorithms suitable for machine learning applications. We apply our algorithms to a compressed sensing and a sparse regression problem, showing that we can treat nonconvex $\\ell^p$ constraints ($p<1$) efficiently, while recovering state-of-the-art performance for $p=1$."
      },
      {
        "id": "oai:arXiv.org:2312.02277v5",
        "title": "A Near-Optimal Single-Loop Stochastic Algorithm for Convex Finite-Sum Coupled Compositional Optimization",
        "link": "https://arxiv.org/abs/2312.02277",
        "author": "Bokun Wang, Tianbao Yang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2312.02277v5 Announce Type: replace-cross \nAbstract: This paper studies a class of convex Finite-sum Coupled Compositional Optimization (cFCCO) problems with applications including group distributionally robust optimization (GDRO) and learning with imbalanced data. To better address these problems, we introduce an efficient single-loop primal-dual block-coordinate stochastic algorithm called ALEXR. The algorithm employs block-coordinate stochastic mirror ascent with extrapolation for the dual variable and stochastic proximal gradient descent updates for the primal variable. We establish the convergence rates of ALEXR in both convex and strongly convex cases under smoothness and non-smoothness conditions of involved functions, which not only improve the best rates in previous works on smooth cFCCO problems but also expand the realm of cFCCO for solving more challenging non-smooth problems such as the dual form of GDRO. Finally, we derive lower complexity bounds, demonstrating the (near-)optimality of ALEXR within a broad class of stochastic algorithms for cFCCO. Experimental results on GDRO and partial Area Under the ROC Curve (pAUC) maximization demonstrate the promising performance of our algorithm."
      },
      {
        "id": "oai:arXiv.org:2403.00108v2",
        "title": "LoRATK: LoRA Once, Backdoor Everywhere in the Share-and-Play Ecosystem",
        "link": "https://arxiv.org/abs/2403.00108",
        "author": "Hongyi Liu, Shaochen Zhong, Xintong Sun, Minghao Tian, Mohsen Hariri, Zirui Liu, Ruixiang Tang, Zhimeng Jiang, Jiayi Yuan, Yu-Neng Chuang, Li Li, Soo-Hyun Choi, Rui Chen, Vipin Chaudhary, Xia Hu",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2403.00108v2 Announce Type: replace-cross \nAbstract: Finetuning LLMs with LoRA has gained significant popularity due to its simplicity and effectiveness. Often, users may even find pluggable, community-shared LoRAs to enhance their base models for a specific downstream task of interest; enjoying a powerful, efficient, yet customized LLM experience with negligible investment. However, this convenient share-and-play ecosystem also introduces a new attack surface, where attackers can distribute malicious LoRAs to a community eager to try out shared assets. Despite the high-risk potential, no prior art has comprehensively explored LoRA's attack surface under the downstream-enhancing share-and-play context. In this paper, we investigate how backdoors can be injected into task-enhancing LoRAs and examine the mechanisms of such infections. We find that with a simple, efficient, yet specific recipe, a backdoor LoRA can be trained once and then seamlessly merged (in a training-free fashion) with multiple task-enhancing LoRAs, retaining both its malicious backdoor and benign downstream capabilities. This allows attackers to scale the distribution of compromised LoRAs with minimal effort by leveraging the rich pool of existing shared LoRA assets. We note that such merged LoRAs are particularly infectious -- because their malicious intent is cleverly concealed behind improved downstream capabilities, creating a strong incentive for voluntary download -- and dangerous -- because under local deployment, no safety measures exist to intervene when things go wrong. Our work is among the first to study this new threat model of training-free distribution of downstream-capable-yet-backdoor-injected LoRAs, highlighting the urgent need for heightened security awareness in the LoRA ecosystem. Warning: This paper contains offensive content and involves a real-life tragedy."
      },
      {
        "id": "oai:arXiv.org:2405.04620v5",
        "title": "Folded Context Condensation in Path Integral Formalism for Infinite Context Transformers",
        "link": "https://arxiv.org/abs/2405.04620",
        "author": "Won-Gi Paeng, Daesuk Kwon, Kyungwon Jeong, Honggyo Suh",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2405.04620v5 Announce Type: replace-cross \nAbstract: In this work, we present a generalized formulation of the Transformer algorithm by reinterpreting its core mechanisms within the framework of Path Integral formalism. In this perspective, the attention mechanism is recast as a process that integrates all possible transition paths leading to future token states, with temporal evolution governed by the Feed-Forward Network. By systematically mapping each component of the Transformer to its counterpart in the Path Integral formulation, we obtain a more compact and efficient representation, in which the contextual information of a sequence is condensed into memory-like segments. These segments are recurrently processed across Transformer layers, enabling more effective long-term information retention. We validate the effectiveness of this approach through the Passkey retrieval task and a summarization task, demonstrating that the proposed method preserves historical information while exhibiting memory usage that scales linearly with sequence length. This contrasts with the non-linear memory growth typically observed in standard attention mechanisms. We expect that this quantum-inspired generalization of the Transformer architecture will open new avenues for enhancing both the efficiency and expressiveness of future Transformer models."
      },
      {
        "id": "oai:arXiv.org:2405.19683v2",
        "title": "A Machine Learning-Based Framework for Assessing Cryptographic Indistinguishability of Lightweight Block Ciphers",
        "link": "https://arxiv.org/abs/2405.19683",
        "author": "Jimmy Dani, Kalyan Nakka, Nitesh Saxena",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2405.19683v2 Announce Type: replace-cross \nAbstract: Indistinguishability is a fundamental principle of cryptographic security, crucial for securing data transmitted between Internet of Things (IoT) devices. This principle ensures that an attacker cannot distinguish between the encrypted data, also known as ciphertext, and random data or the ciphertexts of the two messages encrypted with the same key. This research investigates the ability of machine learning (ML) in assessing indistinguishability property in encryption systems, with a focus on lightweight ciphers. As our first case study, we consider the SPECK32/64 and SIMON32/64 lightweight block ciphers, designed for IoT devices operating under significant energy constraints.\n  In this research, we introduce MIND-Crypt, a novel ML-based framework designed to assess the cryptographic indistinguishability of lightweight block ciphers, specifically the SPECK32/64 and SIMON32/64 encryption algorithm in CBC mode (Cipher Block Chaining), under Known Plaintext Attacks (KPA). Our approach involves training ML models using ciphertexts from two plaintext messages encrypted with same key to determine whether ML algorithms can identify meaningful cryptographic patterns or leakage. Our experiments show that modern ML techniques consistently achieve accuracy equivalent to random guessing, indicating that no statistically exploitable patterns exists in the ciphertexts generated by considered lightweight block ciphers. Furthermore, we demonstrate that in ML algorithms with all the possible combinations of the ciphertexts for given plaintext messages reflects memorization rather than generalization to unseen ciphertexts.\n  Collectively, these findings suggest that existing block ciphers have secure cryptographic designs against ML-based indistinguishability assessments, reinforcing their security even under round-reduced conditions."
      },
      {
        "id": "oai:arXiv.org:2406.01933v2",
        "title": "Orthogonal Causal Calibration",
        "link": "https://arxiv.org/abs/2406.01933",
        "author": "Justin Whitehouse, Christopher Jung, Vasilis Syrgkanis, Bryan Wilder, Zhiwei Steven Wu",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2406.01933v2 Announce Type: replace-cross \nAbstract: Estimates of heterogeneous treatment effects such as conditional average treatment effects (CATEs) and conditional quantile treatment effects (CQTEs) play an important role in real-world decision making. Given this importance, one should ensure these estimates are calibrated. While there is a rich literature on calibrating estimators of non-causal parameters, very few methods have been derived for calibrating estimators of causal parameters, or more generally estimators of quantities involving nuisance parameters. In this work, we develop general algorithms for reducing the task of causal calibration to that of calibrating a standard (non-causal) predictive model.\n  Throughout, we study a notion of calibration defined with respect to an arbitrary, nuisance-dependent loss $\\ell$, under which we say an estimator $\\theta$ is calibrated if its predictions cannot be changed on any level set to decrease loss. For losses $\\ell$ satisfying a condition called universal orthogonality, we present a simple algorithm that transforms partially-observed data into generalized pseudo-outcomes and applies any off-the-shelf calibration procedure. For losses $\\ell$ satisfying a weaker assumption called conditional orthogonality, we provide a similar sample splitting algorithm the performs empirical risk minimization over an appropriately defined class of functions. Convergence of both algorithms follows from a generic, two term upper bound of the calibration error of any model. We demonstrate the practical applicability of our results in experiments on both observational and synthetic data. Our results are exceedingly general, showing that essentially any existing calibration algorithm can be used in causal settings, with additional loss only arising from errors in nuisance estimation."
      },
      {
        "id": "oai:arXiv.org:2409.07415v2",
        "title": "SoK: Security and Privacy Risks of Healthcare AI",
        "link": "https://arxiv.org/abs/2409.07415",
        "author": "Yuanhaur Chang, Han Liu, Chenyang Lu, Ning Zhang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2409.07415v2 Announce Type: replace-cross \nAbstract: The integration of artificial intelligence (AI) and machine learning (ML) into healthcare systems holds great promise for enhancing patient care and care delivery efficiency; however, it also exposes sensitive data and system integrity to potential cyberattacks. Current security and privacy (S&amp;P) research on healthcare AI is highly unbalanced in terms of healthcare deployment scenarios and threat models, and has a disconnected focus with the biomedical research community. This hinders a comprehensive understanding of the risks that healthcare AI entails. To address this gap, this paper takes a thorough examination of existing healthcare AI S&amp;P research, providing a unified framework that allows the identification of under-explored areas. Our survey presents a systematic overview of healthcare AI attacks and defenses, and points out challenges and research opportunities for each AI-driven healthcare application domain. Through our experimental analysis of different threat models and feasibility studies on under-explored adversarial attacks, we provide compelling insights into the pressing need for cybersecurity research in the rapidly evolving field of healthcare AI."
      },
      {
        "id": "oai:arXiv.org:2409.12002v2",
        "title": "Towards Global Localization using Multi-Modal Object-Instance Re-Identification",
        "link": "https://arxiv.org/abs/2409.12002",
        "author": "Aneesh Chavan, Vaibhav Agrawal, Vineeth Bhat, Sarthak Chittawar, Siddharth Srivastava, Chetan Arora, K Madhava Krishna",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2409.12002v2 Announce Type: replace-cross \nAbstract: Re-identification (ReID) is a critical challenge in computer vision, predominantly studied in the context of pedestrians and vehicles. However, robust object-instance ReID, which has significant implications for tasks such as autonomous exploration, long-term perception, and scene understanding, remains underexplored. In this work, we address this gap by proposing a novel dual-path object-instance re-identification transformer architecture that integrates multimodal RGB and depth information. By leveraging depth data, we demonstrate improvements in ReID across scenes that are cluttered or have varying illumination conditions. Additionally, we develop a ReID-based localization framework that enables accurate camera localization and pose identification across different viewpoints. We validate our methods using two custom-built RGB-D datasets, as well as multiple sequences from the open-source TUM RGB-D datasets. Our approach demonstrates significant improvements in both object instance ReID (mAP of 75.18) and localization accuracy (success rate of 83% on TUM-RGBD), highlighting the essential role of object ReID in advancing robotic perception. Our models, frameworks, and datasets have been made publicly available."
      },
      {
        "id": "oai:arXiv.org:2409.16663v4",
        "title": "Mitigating Covariate Shift in Imitation Learning for Autonomous Vehicles Using Latent Space Generative World Models",
        "link": "https://arxiv.org/abs/2409.16663",
        "author": "Alexander Popov, Alperen Degirmenci, David Wehr, Shashank Hegde, Ryan Oldja, Alexey Kamenev, Bertrand Douillard, David Nist\\'er, Urs Muller, Ruchi Bhargava, Stan Birchfield, Nikolai Smolyanskiy",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2409.16663v4 Announce Type: replace-cross \nAbstract: We propose the use of latent space generative world models to address the covariate shift problem in autonomous driving. A world model is a neural network capable of predicting an agent's next state given past states and actions. By leveraging a world model during training, the driving policy effectively mitigates covariate shift without requiring an excessive amount of training data. During end-to-end training, our policy learns how to recover from errors by aligning with states observed in human demonstrations, so that at runtime it can recover from perturbations outside the training distribution. Additionally, we introduce a novel transformer-based perception encoder that employs multi-view cross-attention and a learned scene query. We present qualitative and quantitative results, demonstrating significant improvements upon prior state of the art in closed-loop testing in the CARLA simulator, as well as showing the ability to handle perturbations in both CARLA and NVIDIA's DRIVE Sim."
      },
      {
        "id": "oai:arXiv.org:2410.05573v2",
        "title": "TaeBench: Improving Quality of Toxic Adversarial Examples",
        "link": "https://arxiv.org/abs/2410.05573",
        "author": "Xuan Zhu, Dmitriy Bespalov, Liwen You, Ninad Kulkarni, Yanjun Qi",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2410.05573v2 Announce Type: replace-cross \nAbstract: Toxicity text detectors can be vulnerable to adversarial examples - small perturbations to input text that fool the systems into wrong detection. Existing attack algorithms are time-consuming and often produce invalid or ambiguous adversarial examples, making them less useful for evaluating or improving real-world toxicity content moderators. This paper proposes an annotation pipeline for quality control of generated toxic adversarial examples (TAE). We design model-based automated annotation and human-based quality verification to assess the quality requirements of TAE. Successful TAE should fool a target toxicity model into making benign predictions, be grammatically reasonable, appear natural like human-generated text, and exhibit semantic toxicity. When applying these requirements to more than 20 state-of-the-art (SOTA) TAE attack recipes, we find many invalid samples from a total of 940k raw TAE attack generations. We then utilize the proposed pipeline to filter and curate a high-quality TAE dataset we call TaeBench (of size 264k). Empirically, we demonstrate that TaeBench can effectively transfer-attack SOTA toxicity content moderation models and services. Our experiments also show that TaeBench with adversarial training achieve significant improvements of the robustness of two toxicity detectors."
      },
      {
        "id": "oai:arXiv.org:2410.16122v2",
        "title": "Integer linear programming for unsupervised training set selection in molecular machine learning",
        "link": "https://arxiv.org/abs/2410.16122",
        "author": "Matthieu Haeberle, Puck van Gerwen, Ruben Laplaza, Ksenia R. Briling, Jan Weinreich, Friedrich Eisenbrand, Clemence Corminboeuf",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2410.16122v2 Announce Type: replace-cross \nAbstract: Integer linear programming (ILP) is an elegant approach to solve linear optimization problems, naturally described using integer decision variables. Within the context of physics-inspired machine learning applied to chemistry, we demonstrate the relevance of an ILP formulation to select molecular training sets for predictions of size-extensive properties. We show that our algorithm outperforms existing unsupervised training set selection approaches, especially when predicting properties of molecules larger than those present in the training set. We argue that the reason for the improved performance is due to the selection that is based on the notion of local similarity (i.e., per-atom) and a unique ILP approach that finds optimal solutions efficiently. Altogether, this work provides a practical algorithm to improve the performance of physics-inspired machine learning models and offers insights into the conceptual differences with existing training set selection approaches."
      },
      {
        "id": "oai:arXiv.org:2411.02790v2",
        "title": "Bridging Personalization and Control in Scientific Personalized Search",
        "link": "https://arxiv.org/abs/2411.02790",
        "author": "Sheshera Mysore, Garima Dhanania, Kishor Patil, Surya Kallumadi, Andrew McCallum, Hamed Zamani",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2411.02790v2 Announce Type: replace-cross \nAbstract: Personalized search is a problem where models benefit from learning user preferences from per-user historical interaction data. The inferred preferences enable personalized ranking models to improve the relevance of documents for users. However, personalization is also seen as opaque in its use of historical interactions and is not amenable to users' control. Further, personalization limits the diversity of information users are exposed to. While search results may be automatically diversified this does little to address the lack of control over personalization. In response, we introduce a model for personalized search that enables users to control personalized rankings proactively. Our model, CtrlCE, is a novel cross-encoder model augmented with an editable memory built from users' historical interactions. The editable memory allows cross-encoders to be personalized efficiently and enables users to control personalized ranking. Next, because all queries do not require personalization, we introduce a calibrated mixing model which determines when personalization is necessary. This enables users to control personalization via their editable memory only when necessary. To thoroughly evaluate CtrlCE, we demonstrate its empirical performance in four domains of science, its ability to selectively request user control in a calibration evaluation of the mixing model, and the control provided by its editable memory in a user study."
      },
      {
        "id": "oai:arXiv.org:2411.11672v2",
        "title": "Artificial Scientific Discovery",
        "link": "https://arxiv.org/abs/2411.11672",
        "author": "Antonio Norelli",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2411.11672v2 Announce Type: replace-cross \nAbstract: Rooted in the explosion of deep learning over the past decade, this thesis spans from AlphaGo to ChatGPT to empirically examine the fundamental concepts needed to realize the vision of an artificial scientist: a machine with the capacity to autonomously generate original research and contribute to the expansion of human knowledge. The investigation begins with Olivaw, an AlphaGo Zero-like agent that discovers Othello knowledge from scratch but is unable to communicate it. This realization leads to the development of the Explanatory Learning (EL) framework, a formalization of the problem faced by a scientist when trying to explain a new phenomenon to their peers. The effective EL prescriptions allow us to crack Zendo, a popular board game simulating the scientific endeavor. This success comes with a fundamental insight: an artificial scientist must develop its own interpretation of the language used to explain its findings, and not rely on a rigid existing interpreter. Questioning the very process of learning an interpreter, we turn our attention to the inner functioning of modern multimodal models. This culminates in a simple idea to build CLIP-like models where interpretation and perception are explicitly disentangled: a cost-effective approach that couples two unimodal models using little multimodal data and no further training. Finally, we discuss what ChatGPT and its siblings are still missing to become artificial scientists, and introduce the Big-Bench Symbol Interpretation Task, a benchmark about interpreting Zendo-like explanations that sees LLMs going no further than random chance while being instead fully solved by humans."
      },
      {
        "id": "oai:arXiv.org:2411.12286v2",
        "title": "GLOVER: Generalizable Open-Vocabulary Affordance Reasoning for Task-Oriented Grasping",
        "link": "https://arxiv.org/abs/2411.12286",
        "author": "Teli Ma, Zifan Wang, Jiaming Zhou, Mengmeng Wang, Junwei Liang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2411.12286v2 Announce Type: replace-cross \nAbstract: Inferring affordable (i.e., graspable) parts of arbitrary objects based on human specifications is essential for robots advancing toward open-vocabulary manipulation. Current grasp planners, however, are hindered by limited vision-language comprehension and time-consuming 3D radiance modeling, restricting real-time, open-vocabulary interactions with objects. To address these limitations, we propose GLOVER, a unified Generalizable Open-Vocabulary Affordance Reasoning framework, which fine-tunes the Large Language Models (LLMs) to predict the visual affordance of graspable object parts within RGB feature space. We compile a dataset of over 10,000 images from human-object interactions, annotated with unified visual and linguistic affordance labels, to enable multi-modal fine-tuning. GLOVER inherits world knowledge and common-sense reasoning from LLMs, facilitating more fine-grained object understanding and sophisticated tool-use reasoning. To enable effective real-world deployment, we present Affordance-Aware Grasping Estimation (AGE), a non-parametric grasp planner that aligns the gripper pose with a superquadric surface derived from affordance data. In evaluations across 30 table-top real-world scenes, GLOVER achieves success rates of 86.0% in part identification and 76.3% in grasping, with speeds approximately 29 times faster in affordance reasoning and 40 times faster in grasping pose estimation than the previous state-of-the-art. We also validate the generalization across embodiments, showing effectiveness in humanoid robots with dexterous hands."
      },
      {
        "id": "oai:arXiv.org:2411.14412v3",
        "title": "Adversarial Data Poisoning Attacks on Quantum Machine Learning in the NISQ Era",
        "link": "https://arxiv.org/abs/2411.14412",
        "author": "Satwik Kundu, Swaroop Ghosh",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2411.14412v3 Announce Type: replace-cross \nAbstract: With the growing interest in Quantum Machine Learning (QML) and the increasing availability of quantum computers through cloud providers, addressing the potential security risks associated with QML has become an urgent priority. One key concern in the QML domain is the threat of data poisoning attacks in the current quantum cloud setting. Adversarial access to training data could severely compromise the integrity and availability of QML models. Classical data poisoning techniques require significant knowledge and training to generate poisoned data, and lack noise resilience, making them ineffective for QML models in the Noisy Intermediate Scale Quantum (NISQ) era. In this work, we first propose a simple yet effective technique to measure intra-class encoder state similarity (ESS) by analyzing the outputs of encoding circuits. Leveraging this approach, we introduce a \\underline{Qu}antum \\underline{I}ndiscriminate \\underline{D}ata Poisoning attack, QUID. Through extensive experiments conducted in both noiseless and noisy environments (e.g., IBM\\_Brisbane's noise), across various architectures and datasets, QUID achieves up to $92\\%$ accuracy degradation in model performance compared to baseline models and up to $75\\%$ accuracy degradation compared to random label-flipping. We also tested QUID against state-of-the-art classical defenses, with accuracy degradation still exceeding $50\\%$, demonstrating its effectiveness. This work represents the first attempt to reevaluate data poisoning attacks in the context of QML."
      },
      {
        "id": "oai:arXiv.org:2411.19560v2",
        "title": "Updating Katz centrality by counting walks",
        "link": "https://arxiv.org/abs/2411.19560",
        "author": "Francesca Arrigo, Daniele Bertaccini, Alessandro Filippo",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2411.19560v2 Announce Type: replace-cross \nAbstract: We develop efficient and effective strategies for the update of Katz centralities after node and edge removal in simple graphs. We provide explicit formulas for the ``loss of walks\" a network suffers when nodes/edges are removed, and use these to inform our algorithms. The theory builds on the newly introduced concept of $\\cF$-avoiding first-passage walks. Further, bounds on the change of total network communicability are also derived. Extensive numerical experiments on synthetic and real-world networks complement our theoretical results."
      },
      {
        "id": "oai:arXiv.org:2412.12126v2",
        "title": "Seamless Optical Cloud Computing across Edge-Metro Network for Generative AI",
        "link": "https://arxiv.org/abs/2412.12126",
        "author": "Sizhe Xing, Aolong Sun, Chengxi Wang, Yizhi Wang, Boyu Dong, Junhui Hu, Xuyu Deng, An Yan, Yingjun Liu, Fangchen Hu, Zhongya Li, Ouhan Huang, Junhao Zhao, Yingjun Zhou, Ziwei Li, Jianyang Shi, Xi Xiao, Richard Penty, Qixiang Cheng, Nan Chi, Junwen Zhang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2412.12126v2 Announce Type: replace-cross \nAbstract: The rapid advancement of generative artificial intelligence (AI) in recent years has profoundly reshaped modern lifestyles, necessitating a revolutionary architecture to support the growing demands for computational power. Cloud computing has become the driving force behind this transformation. However, it consumes significant power and faces computation security risks due to the reliance on extensive data centers and servers in the cloud. Reducing power consumption while enhancing computational scale remains persistent challenges in cloud computing. Here, we propose and experimentally demonstrate an optical cloud computing system that can be seamlessly deployed across edge-metro network. By modulating inputs and models into light, a wide range of edge nodes can directly access the optical computing center via the edge-metro network. The experimental validations show an energy efficiency of 118.6 mW/TOPs (tera operations per second), reducing energy consumption by two orders of magnitude compared to traditional electronic-based cloud computing solutions. Furthermore, it is experimentally validated that this architecture can perform various complex generative AI models through parallel computing to achieve image generation tasks."
      },
      {
        "id": "oai:arXiv.org:2412.18086v2",
        "title": "Generating Traffic Scenarios via In-Context Learning to Learn Better Motion Planner",
        "link": "https://arxiv.org/abs/2412.18086",
        "author": "Aizierjiang Aiersilan",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2412.18086v2 Announce Type: replace-cross \nAbstract: Motion planning is a crucial component in autonomous driving. State-of-the-art motion planners are trained on meticulously curated datasets, which are not only expensive to annotate but also insufficient in capturing rarely seen critical scenarios. Failing to account for such scenarios poses a significant risk to motion planners and may lead to incidents during testing. An intuitive solution is to manually compose such scenarios by programming and executing a simulator (e.g., CARLA). However, this approach incurs substantial human costs. Motivated by this, we propose an inexpensive method for generating diverse critical traffic scenarios to train more robust motion planners. First, we represent traffic scenarios as scripts, which are then used by the simulator to generate traffic scenarios. Next, we develop a method that accepts user-specified text descriptions, which a Large Language Model translates into scripts using in-context learning. The output scripts are sent to the simulator that produces the corresponding traffic scenarios. As our method can generate abundant safety-critical traffic scenarios, we use them as synthetic training data for motion planners. To demonstrate the value of generated scenarios, we train existing motion planners on our synthetic data, real-world datasets, and a combination of both. Our experiments show that motion planners trained with our data significantly outperform those trained solely on real-world data, showing the usefulness of our synthetic data and the effectiveness of our data generation method. Our source code is available at https://ezharjan.github.io/AutoSceneGen."
      },
      {
        "id": "oai:arXiv.org:2501.14066v2",
        "title": "Segment-and-Classify: ROI-Guided Generalizable Contrast Phase Classification in CT Using XGBoost",
        "link": "https://arxiv.org/abs/2501.14066",
        "author": "Benjamin Hou, Tejas Sudharshan Mathai, Pritam Mukherjee, Xinya Wang, Ronald M. Summers, Zhiyong Lu",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2501.14066v2 Announce Type: replace-cross \nAbstract: Purpose: To automate contrast phase classification in CT using organ-specific features extracted from a widely used segmentation tool with a lightweight decision tree classifier.\n  Materials and Methods: This retrospective study utilized three public CT datasets from separate institutions. The phase prediction model was trained on the WAW-TACE (median age: 66 [60,73]; 185 males) dataset, and externally validated on the VinDr-Multiphase (146 males; 63 females; 56 unk) and C4KC-KiTS (median age: 61 [50.68; 123 males) datasets. Contrast phase classification was performed using organ-specific features extracted by TotalSegmentator, followed by prediction using a gradient-boosted decision tree classifier.\n  Results: On the VinDr-Multiphase dataset, the phase prediction model achieved the highest or comparable AUCs across all phases (>0.937), with superior F1-scores in the non-contrast (0.994), arterial (0.937), and delayed (0.718) phases. Statistical testing indicated significant performance differences only in the arterial and delayed phases (p<0.05). On the C4KC-KiTS dataset, the phase prediction model achieved the highest AUCs across all phases (>0.991), with superior F1-scores in arterial/venous (0.968) and delayed (0.935) phases. Statistical testing confirmed significant improvements over all baseline models in these two phases (p<0.05). Performance in the non-contrast class, however, was comparable across all models, with no statistically significant differences observed (p>0.05).\n  Conclusion: The lightweight model demonstrated strong performance relative to all baseline models, and exhibited robust generalizability across datasets from different institutions."
      },
      {
        "id": "oai:arXiv.org:2501.18265v2",
        "title": "Efficiency and Effectiveness of LLM-Based Summarization of Evidence in Crowdsourced Fact-Checking",
        "link": "https://arxiv.org/abs/2501.18265",
        "author": "Kevin Roitero, Dustin Wright, Michael Soprano, Isabelle Augenstein, Stefano Mizzaro",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2501.18265v2 Announce Type: replace-cross \nAbstract: Evaluating the truthfulness of online content is critical for combating misinformation. This study examines the efficiency and effectiveness of crowdsourced truthfulness assessments through a comparative analysis of two approaches: one involving full-length webpages as evidence for each claim, and another using summaries for each evidence document generated with a large language model. Using an A/B testing setting, we engage a diverse pool of participants tasked with evaluating the truthfulness of statements under these conditions. Our analysis explores both the quality of assessments and the behavioral patterns of participants. The results reveal that relying on summarized evidence offers comparable accuracy and error metrics to the Standard modality while significantly improving efficiency. Workers in the Summary setting complete a significantly higher number of assessments, reducing task duration and costs. Additionally, the Summary modality maximizes internal agreement and maintains consistent reliance on and perceived usefulness of evidence, demonstrating its potential to streamline large-scale truthfulness evaluations."
      },
      {
        "id": "oai:arXiv.org:2502.00935v3",
        "title": "Generalizing Safety Beyond Collision-Avoidance via Latent-Space Reachability Analysis",
        "link": "https://arxiv.org/abs/2502.00935",
        "author": "Kensuke Nakamura, Lasse Peters, Andrea Bajcsy",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2502.00935v3 Announce Type: replace-cross \nAbstract: Hamilton-Jacobi (HJ) reachability is a rigorous mathematical framework that enables robots to simultaneously detect unsafe states and generate actions that prevent future failures. While in theory, HJ reachability can synthesize safe controllers for nonlinear systems and nonconvex constraints, in practice, it has been limited to hand-engineered collision-avoidance constraints modeled via low-dimensional state-space representations and first-principles dynamics. In this work, our goal is to generalize safe robot controllers to prevent failures that are hard--if not impossible--to write down by hand, but can be intuitively identified from high-dimensional observations: for example, spilling the contents of a bag. We propose Latent Safety Filters, a latent-space generalization of HJ reachability that tractably operates directly on raw observation data (e.g., RGB images) to automatically compute safety-preserving actions without explicit recovery demonstrations by performing safety analysis in the latent embedding space of a generative world model. Our method leverages diverse robot observation-action data of varying quality (including successes, random exploration, and unsafe demonstrations) to learn a world model. Constraint specification is then transformed into a classification problem in the latent space of the learned world model. In simulation and hardware experiments, we compute an approximation of Latent Safety Filters to safeguard arbitrary policies (from imitation- learned policies to direct teleoperation) from complex safety hazards, like preventing a Franka Research 3 manipulator from spilling the contents of a bag or toppling cluttered objects."
      },
      {
        "id": "oai:arXiv.org:2502.05364v2",
        "title": "Hypencoder: Hypernetworks for Information Retrieval",
        "link": "https://arxiv.org/abs/2502.05364",
        "author": "Julian Killingback, Hansi Zeng, Hamed Zamani",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2502.05364v2 Announce Type: replace-cross \nAbstract: Existing information retrieval systems are largely constrained by their reliance on vector inner products to assess query-document relevance, which naturally limits the expressiveness of the relevance score they can produce. We propose a new paradigm; instead of representing a query as a vector, we use a small neural network that acts as a learned query-specific relevance function. This small neural network takes a document representation as input (in this work we use a single vector) and produces a scalar relevance score. To produce the small neural network we use a hypernetwork, a network that produces the weights of other networks, as our query encoder. We name this category of encoder models Hypencoders. Experiments on in-domain search tasks show that Hypencoders significantly outperform strong dense retrieval models and even surpass reranking models and retrieval models with an order of magnitude more parameters. To assess the extent of Hypencoders' capabilities, we evaluate on a set of hard retrieval tasks including tip-of-the-tongue and instruction-following retrieval tasks. On harder tasks, we find that the performance gap widens substantially compared to standard retrieval tasks. Furthermore, to demonstrate the practicality of our method, we implement an approximate search algorithm and show that our model is able to retrieve from a corpus of 8.8M documents in under 60 milliseconds."
      },
      {
        "id": "oai:arXiv.org:2502.07837v2",
        "title": "RoboBERT: An End-to-end Multimodal Robotic Manipulation Model",
        "link": "https://arxiv.org/abs/2502.07837",
        "author": "Sicheng Wang, Sheng Liu, Weiheng Wang, Jianhua Shan, Bin Fang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2502.07837v2 Announce Type: replace-cross \nAbstract: Embodied intelligence seamlessly integrates vision, language, and action.~However, most multimodal robotic models rely on massive fine-tuning, incurring high time and hardware costs.~To address this, we introduce RoboBERT, an end-to-end multimodal manipulation model built around a novel two-stage training paradigm.~In the first stage, we freeze most of the vision encoder and train with a single \"standard\" instruction phrasing, allowing the model to focus on stable policy learning via a CNN-based diffusion policy.~In the second stage, we unfreeze all modules and inject diverse natural language variants, rapidly aligning varied instructions to the already-learned policy without destabilizing performance.~We further employ systematic data augmentations to enhance robustness against visual perturbations.~Without relying on auxiliary datasets, RoboBERT achieves new state-of-the-art (SOTA) mean episode lengths of 4.52 on the CALVIN ABCD-D benchmark and 3.79 on the ABC-D benchmark using only language-labeled expert demonstrations and a comparatively lightweight architecture.Real-robot trials on a 6-DOF manipulator confirm higher success rates than comparable methods trained on identical data.These results demonstrate that our data-augmentation-enhanced two-stage training paradigm delivers efficient, scalable, and broadly applicable performance for multimodal robotic systems."
      },
      {
        "id": "oai:arXiv.org:2503.11347v2",
        "title": "Integrating Dynamical Systems Modeling with Spatiotemporal scRNA-seq Data Analysis",
        "link": "https://arxiv.org/abs/2503.11347",
        "author": "Zhenyi Zhang, Yuhao Sun, Qiangwei Peng, Tiejun Li, Peijie Zhou",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2503.11347v2 Announce Type: replace-cross \nAbstract: Understanding the dynamic nature of biological systems is fundamental to deciphering cellular behavior, developmental processes, and disease progression. Single-cell RNA sequencing (scRNA-seq) has provided static snapshots of gene expression, offering valuable insights into cellular states at a single time point. Recent advancements in temporally resolved scRNA-seq, spatial transcriptomics (ST), and time-series spatial transcriptomics (temporal-ST) have further revolutionized our ability to study the spatiotemporal dynamics of individual cells. These technologies, when combined with computational frameworks such as Markov chains, stochastic differential equations (SDEs), and generative models like optimal transport and Schr\\\"odinger bridges, enable the reconstruction of dynamic cellular trajectories and cell fate decisions. This review discusses how these dynamical system approaches offer new opportunities to model and infer cellular dynamics from a systematic perspective."
      },
      {
        "id": "oai:arXiv.org:2504.01663v2",
        "title": "Recovering Small Communities in the Planted Partition Model",
        "link": "https://arxiv.org/abs/2504.01663",
        "author": "Martijn G\\\"osgens, Maximilien Dreveton",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.01663v2 Announce Type: replace-cross \nAbstract: We analyze community recovery in the planted partition model (PPM) in regimes where the number of communities is arbitrarily large. We examine the three standard recovery regimes: exact recovery, almost exact recovery, and weak recovery. When communities vary in size, traditional accuracy- or alignment-based metrics become unsuitable for assessing the correctness of a predicted partition. To address this, we redefine these recovery regimes using the correlation coefficient, a more versatile metric for comparing partitions. We then demonstrate that $\\textit{Diamond Percolation}$, an algorithm based on common-neighbors, successfully recovers communities under mild assumptions on edge probabilities, with minimal restrictions on the number and sizes of communities. As a key application, we consider the case where community sizes follow a power-law distribution, a characteristic frequently found in real-world networks. To the best of our knowledge, we provide the first recovery results for such unbalanced partitions."
      },
      {
        "id": "oai:arXiv.org:2504.17811v2",
        "title": "OmniSage: Large Scale, Multi-Entity Heterogeneous Graph Representation Learning",
        "link": "https://arxiv.org/abs/2504.17811",
        "author": "Anirudhan Badrinath, Alex Yang, Kousik Rajesh, Prabhat Agarwal, Jaewon Yang, Haoyu Chen, Jiajing Xu, Charles Rosenberg",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.17811v2 Announce Type: replace-cross \nAbstract: Representation learning, a task of learning latent vectors to represent entities, is a key task in improving search and recommender systems in web applications. Various representation learning methods have been developed, including graph-based approaches for relationships among entities, sequence-based methods for capturing the temporal evolution of user activities, and content-based models for leveraging text and visual content. However, the development of a unifying framework that integrates these diverse techniques to support multiple applications remains a significant challenge. This paper presents OmniSage, a large-scale representation framework that learns universal representations for a variety of applications at Pinterest. OmniSage integrates graph neural networks with content-based models and user sequence models by employing multiple contrastive learning tasks to effectively process graph data, user sequence data, and content signals. To support the training and inference of OmniSage, we developed an efficient infrastructure capable of supporting Pinterest graphs with billions of nodes. The universal representations generated by OmniSage have significantly enhanced user experiences on Pinterest, leading to an approximate 2.5% increase in sitewide repins (saves) across five applications. This paper highlights the impact of unifying representation learning methods, and we will open source the OmniSage code by the time of publication."
      },
      {
        "id": "oai:arXiv.org:2504.18768v2",
        "title": "TransparentGS: Fast Inverse Rendering of Transparent Objects with Gaussians",
        "link": "https://arxiv.org/abs/2504.18768",
        "author": "Letian Huang, Dongwei Ye, Jialin Dan, Chengzhi Tao, Huiwen Liu, Kun Zhou, Bo Ren, Yuanqi Li, Yanwen Guo, Jie Guo",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.18768v2 Announce Type: replace-cross \nAbstract: The emergence of neural and Gaussian-based radiance field methods has led to considerable advancements in novel view synthesis and 3D object reconstruction. Nonetheless, specular reflection and refraction continue to pose significant challenges due to the instability and incorrect overfitting of radiance fields to high-frequency light variations. Currently, even 3D Gaussian Splatting (3D-GS), as a powerful and efficient tool, falls short in recovering transparent objects with nearby contents due to the existence of apparent secondary ray effects. To address this issue, we propose TransparentGS, a fast inverse rendering pipeline for transparent objects based on 3D-GS. The main contributions are three-fold. Firstly, an efficient representation of transparent objects, transparent Gaussian primitives, is designed to enable specular refraction through a deferred refraction strategy. Secondly, we leverage Gaussian light field probes (GaussProbe) to encode both ambient light and nearby contents in a unified framework. Thirdly, a depth-based iterative probes query (IterQuery) algorithm is proposed to reduce the parallax errors in our probe-based framework. Experiments demonstrate the speed and accuracy of our approach in recovering transparent objects from complex environments, as well as several applications in computer graphics and vision."
      },
      {
        "id": "oai:arXiv.org:2504.19012v2",
        "title": "Geometry-aware Active Learning of Spatiotemporal Dynamic Systems",
        "link": "https://arxiv.org/abs/2504.19012",
        "author": "Xizhuo Zhang, Bing Yao",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.19012v2 Announce Type: replace-cross \nAbstract: Rapid developments in advanced sensing and imaging have significantly enhanced information visibility, opening opportunities for predictive modeling of complex dynamic systems. However, sensing signals acquired from such complex systems are often distributed across 3D geometries and rapidly evolving over time, posing significant challenges in spatiotemporal predictive modeling. This paper proposes a geometry-aware active learning framework for modeling spatiotemporal dynamic systems. Specifically, we propose a geometry-aware spatiotemporal Gaussian Process (G-ST-GP) to effectively integrate the temporal correlations and geometric manifold features for reliable prediction of high-dimensional dynamic behaviors. In addition, we develop an adaptive active learning strategy to strategically identify informative spatial locations for data collection and further maximize the prediction accuracy. This strategy achieves the adaptive trade-off between the prediction uncertainty in the G-ST-GP model and the space-filling design guided by the geodesic distance across the 3D geometry. We implement the proposed framework to model the spatiotemporal electrodynamics in a 3D heart geometry. Numerical experiments show that our framework outperforms traditional methods lacking the mechanism of geometric information incorporation or effective data collection."
      },
      {
        "id": "oai:arXiv.org:2504.19174v2",
        "title": "CLR-Wire: Towards Continuous Latent Representations for 3D Curve Wireframe Generation",
        "link": "https://arxiv.org/abs/2504.19174",
        "author": "Xueqi Ma, Yilin Liu, Tianlong Gao, Qirui Huang, Hui Huang",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.19174v2 Announce Type: replace-cross \nAbstract: We introduce CLR-Wire, a novel framework for 3D curve-based wireframe generation that integrates geometry and topology into a unified Continuous Latent Representation. Unlike conventional methods that decouple vertices, edges, and faces, CLR-Wire encodes curves as Neural Parametric Curves along with their topological connectivity into a continuous and fixed-length latent space using an attention-driven variational autoencoder (VAE). This unified approach facilitates joint learning and generation of both geometry and topology. To generate wireframes, we employ a flow matching model to progressively map Gaussian noise to these latents, which are subsequently decoded into complete 3D wireframes. Our method provides fine-grained modeling of complex shapes and irregular topologies, and supports both unconditional generation and generation conditioned on point cloud or image inputs. Experimental results demonstrate that, compared with state-of-the-art generative approaches, our method achieves substantial improvements in accuracy, novelty, and diversity, offering an efficient and comprehensive solution for CAD design, geometric reconstruction, and 3D content creation."
      },
      {
        "id": "oai:arXiv.org:2504.19488v2",
        "title": "Two-parameter superposable S-curves",
        "link": "https://arxiv.org/abs/2504.19488",
        "author": "Vijay Prakash S",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.19488v2 Announce Type: replace-cross \nAbstract: Straight line equation $y=mx$ with slope $m$, when singularly perturbed as $ay^3+y=mx$ with a positive parameter $a$, results in S-shaped curves or S-curves on a real plane. As $a\\rightarrow 0$, we get back $y=mx$ which is a cumulative distribution function of a continuous uniform distribution that describes the occurrence of every event in an interval to be equally probable. As $a\\rightarrow\\infty$, the derivative of $y$ has finite support only at $y=0$ resembling a degenerate distribution. Based on these arguments, in this work, we propose that these S-curves can represent maximum entropy uniform distribution to a zero entropy single value. We also argue that these S-curves are superposable as they are only parametrically nonlinear but fundamentally linear. So far, the superposed forms have been used to capture the patterns of natural systems such as nonlinear dynamics of biological growth and kinetics of enzyme reactions. Here, we attempt to use the S-curve and its superposed form as statistical models. We fit the models on a classical dataset containing flower measurements of iris plants and analyze their usefulness in pattern recognition. Based on these models, we claim that any non-uniform pattern can be represented as a singular perturbation to uniform distribution. However, our parametric estimation procedure have some limitations such as sensitivity to initial conditions depending on the data at hand."
      },
      {
        "id": "oai:arXiv.org:2504.19489v4",
        "title": "How Cohesive Are Community Search Results on Online Social Networks?: An Experimental Evaluation",
        "link": "https://arxiv.org/abs/2504.19489",
        "author": "Yining Zhao, Sourav S Bhowmick, Nastassja L. Fischer, SH Annabel Chen",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.19489v4 Announce Type: replace-cross \nAbstract: Recently, numerous community search methods for large graphs have been proposed, at the core of which is defining and measuring cohesion. This paper experimentally evaluates the effectiveness of these community search algorithms w.r.t. cohesiveness in the context of online social networks. Social communities are formed and developed under the influence of group cohesion theory, which has been extensively studied in social psychology. However, current generic methods typically measure cohesiveness using structural or attribute-based approaches and overlook domain-specific concepts such as group cohesion. We introduce five novel psychology-informed cohesiveness measures, based on the concept of group cohesion from social psychology, and propose a novel framework called CHASE for evaluating eight representative community search algorithms w.r.t. these measures on online social networks. Our analysis reveals that there is no clear correlation between structural and psychological cohesiveness, and no algorithm effectively identifies psychologically cohesive communities in online social networks. This study provides new insights that could guide the development of future community search methods."
      },
      {
        "id": "oai:arXiv.org:2504.21036v2",
        "title": "Can Differentially Private Fine-tuning LLMs Protect Against Privacy Attacks?",
        "link": "https://arxiv.org/abs/2504.21036",
        "author": "Hao Du, Shang Liu, Yang Cao",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2504.21036v2 Announce Type: replace-cross \nAbstract: Fine-tuning large language models (LLMs) has become an essential strategy for adapting them to specialized tasks; however, this process introduces significant privacy challenges, as sensitive training data may be inadvertently memorized and exposed. Although differential privacy (DP) offers strong theoretical guarantees against such leakage, its empirical privacy effectiveness on LLMs remains unclear, especially under different fine-tuning methods. In this paper, we systematically investigate the impact of DP across fine-tuning methods and privacy budgets, using both data extraction and membership inference attacks to assess empirical privacy risks. Our main findings are as follows: (1) Differential privacy reduces model utility, but its impact varies significantly across different fine-tuning methods. (2) Without DP, the privacy risks of models fine-tuned with different approaches differ considerably. (3) When DP is applied, even a relatively high privacy budget can substantially lower privacy risk. (4) The privacy-utility trade-off under DP training differs greatly among fine-tuning methods, with some methods being unsuitable for DP due to severe utility degradation. Our results provide practical guidance for privacy-conscious deployment of LLMs and pave the way for future research on optimizing the privacy-utility trade-off in fine-tuning methodologies."
      }
    ]
  },
  "https://rss.arxiv.org/rss/cs.SD+eess.AS": {
    "feed": {
      "title": "cs.SD, eess.AS updates on arXiv.org",
      "link": "http://rss.arxiv.org/rss/cs.SD+eess.AS",
      "updated": "Fri, 02 May 2025 04:02:02 +0000",
      "published": "Fri, 02 May 2025 00:00:00 -0400"
    },
    "entries": [
      {
        "id": "oai:arXiv.org:2505.00007v1",
        "title": "Discovering phoneme-specific critical articulators through a data-driven approach",
        "link": "https://arxiv.org/abs/2505.00007",
        "author": "Jesuraj Bandekar, Sathvik Udupa, Prasanta Kumar Ghosh",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00007v1 Announce Type: new \nAbstract: We propose an approach for learning critical articulators for phonemes through a machine learning approach. We formulate the learning with three models trained end to end. First, we use Acoustic to Articulatory Inversion (AAI) to predict time-varying speech articulators EMA. We also predict the phoneme-specific weights across articulators for each frame. To avoid overfitting, we also add a dropout layer before the weights prediction layer. Next, we normalize the predicted weights across articulators using min-max normalization for each frame. The normalized weights are multiplied by the ground truth $EMA$ and then we try to predict the phones at each frame. We train this whole setup end to end and use two losses. One loss is for the phone prediction which is the cross entropy loss and the other is for the AAI prediction which is the mean squared error loss. To maintain gradient flow between the phone prediction block and the $EMA$ prediction block, we use straight-through estimation. The goal here is to predict the weights of the articulator at each frame while training the model end to end."
      },
      {
        "id": "oai:arXiv.org:2505.00409v1",
        "title": "Perceptual Implications of Automatic Anonymization in Pathological Speech",
        "link": "https://arxiv.org/abs/2505.00409",
        "author": "Soroosh Tayebi Arasteh, Saba Afza, Tri-Thien Nguyen, Lukas Buess, Maryam Parvin, Tomas Arias-Vergara, Paula Andrea Perez-Toro, Hiu Ching Hung, Mahshad Lotfinia, Thomas Gorges, Elmar Noeth, Maria Schuster, Seung Hee Yang, Andreas Maier",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00409v1 Announce Type: new \nAbstract: Automatic anonymization techniques are essential for ethical sharing of pathological speech data, yet their perceptual consequences remain understudied. This study presents the first comprehensive human-centered analysis of anonymized pathological speech, using a structured perceptual protocol involving ten native and non-native German listeners with diverse linguistic, clinical, and technical backgrounds. Listeners evaluated anonymized-original utterance pairs from 180 speakers spanning Cleft Lip and Palate, Dysarthria, Dysglossia, Dysphonia, and age-matched healthy controls. Speech was anonymized using state-of-the-art automatic methods (equal error rates in the range of 30-40%). Listeners completed Turing-style discrimination and quality rating tasks under zero-shot (single-exposure) and few-shot (repeated-exposure) conditions. Discrimination accuracy was high overall (91% zero-shot; 93% few-shot), but varied by disorder (repeated-measures ANOVA: p=0.007), ranging from 96% (Dysarthria) to 86% (Dysphonia). Anonymization consistently reduced perceived quality (from 83% to 59%, p<0.001), with pathology-specific degradation patterns (one-way ANOVA: p=0.005). Native listeners rated original speech slightly higher than non-native listeners (Delta=4%, p=0.199), but this difference nearly disappeared after anonymization (Delta=1%, p=0.724). No significant gender-based bias was observed. Critically, human perceptual outcomes did not correlate with automatic privacy or clinical utility metrics. These results underscore the need for listener-informed, disorder- and context-specific anonymization strategies that preserve privacy while maintaining interpretability, communicative functions, and diagnostic utility, especially for vulnerable populations such as children."
      },
      {
        "id": "oai:arXiv.org:2505.00550v1",
        "title": "Bridging Cultural and Digital Divides: A Low-Latency JackTrip Framework for Equitable Music Education in the Global South",
        "link": "https://arxiv.org/abs/2505.00550",
        "author": "Tiange Zhou, Marco Bidin",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00550v1 Announce Type: new \nAbstract: The rapid expansion of digital technologies has transformed educational landscapes worldwide, yet significant infrastructural and cultural challenges persist in the Global South. This paper introduces a low-latency JackTrip framework designed to bridge both the cultural and digital divides in music education. By leveraging an open-source, UDP-based audio streaming protocol originally developed at Stanford's CCRMA, the framework is tailored to address technical constraints such as intermittent connectivity, limited bandwidth, and high latency that characterize many rural and underserved regions. The study systematically compares the performance of JackTrip with conventional platforms like Zoom, demonstrating that JackTrip achieves sub-30~ms latency under simulated low-resource conditions while preserving the intricate audio details essential for non-Western musical traditions. Spectral analysis confirms that JackTrip's superior handling of microtonal scales, complex rhythms, and harmonic textures provides a culturally authentic medium for real-time ensemble performance and music education. These findings underscore the transformative potential of decentralized, edge-computing solutions in empowering educators and musicians across the Global South, promoting both technological equity and cultural preservation."
      },
      {
        "id": "oai:arXiv.org:2505.00579v1",
        "title": "Voice Cloning: Comprehensive Survey",
        "link": "https://arxiv.org/abs/2505.00579",
        "author": "Hussam Azzuni, Abdulmotaleb El Saddik",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00579v1 Announce Type: new \nAbstract: Voice Cloning has rapidly advanced in today's digital world, with many researchers and corporations working to improve these algorithms for various applications. This article aims to establish a standardized terminology for voice cloning and explore its different variations. It will cover speaker adaptation as the fundamental concept and then delve deeper into topics such as few-shot, zero-shot, and multilingual TTS within that context. Finally, we will explore the evaluation metrics commonly used in voice cloning research and related datasets. This survey compiles the available voice cloning algorithms to encourage research toward its generation and detection to limit its misuse."
      },
      {
        "id": "oai:arXiv.org:2505.00059v1",
        "title": "BERSting at the Screams: A Benchmark for Distanced, Emotional and Shouted Speech Recognition",
        "link": "https://arxiv.org/abs/2505.00059",
        "author": "Paige Tutt\\\"os\\'i, Mantaj Dhillon, Luna Sang, Shane Eastwood, Poorvi Bhatia, Quang Minh Dinh, Avni Kapoor, Yewon Jin, Angelica Lim",
        "published": "Fri, 02 May 2025 00:00:00 -0400",
        "summary": "arXiv:2505.00059v1 Announce Type: cross \nAbstract: Some speech recognition tasks, such as automatic speech recognition (ASR), are approaching or have reached human performance in many reported metrics. Yet, they continue to struggle in complex, real-world, situations, such as with distanced speech. Previous challenges have released datasets to address the issue of distanced ASR, however, the focus remains primarily on distance, specifically relying on multi-microphone array systems. Here we present the B(asic) E(motion) R(andom phrase) S(hou)t(s) (BERSt) dataset. The dataset contains almost 4 hours of English speech from 98 actors with varying regional and non-native accents. The data was collected on smartphones in the actors homes and therefore includes at least 98 different acoustic environments. The data also includes 7 different emotion prompts and both shouted and spoken utterances. The smartphones were places in 19 different positions, including obstructions and being in a different room than the actor. This data is publicly available for use and can be used to evaluate a variety of speech recognition tasks, including: ASR, shout detection, and speech emotion recognition (SER). We provide initial benchmarks for ASR and SER tasks, and find that ASR degrades both with an increase in distance and shout level and shows varied performance depending on the intended emotion. Our results show that the BERSt dataset is challenging for both ASR and SER tasks and continued work is needed to improve the robustness of such systems for more accurate real-world use."
      }
    ]
  }
}