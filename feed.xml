<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
<channel>
    <title>arXiv Paper Filter</title>
    <link>https://github.com/None/arxiv_filter</link>
    <description>根据研究兴趣筛选的arXiv论文</description>
    <atom:link href="https://raw.githubusercontent.com/None/arxiv_filter/main/feed.xml" rel="self" type="application/rss+xml" />
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>zh-CN</language>
    <lastBuildDate>Wed, 07 May 2025 12:12:00 +0800</lastBuildDate>
    <managingEditor>None@github.com</managingEditor>
    <pubDate>Wed, 07 May 2025 12:12:00 +0800</pubDate>
    <skipDays>
        <day>Saturday</day>
        <day>Sunday</day>
    </skipDays>

    <item>
        <title>Harnessing Structured Knowledge: A Concept Map-Based Approach for High-Quality Multiple Choice Question Generation with Effective Distractors</title>
        <link>https://arxiv.org/abs/2505.02850</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.02850v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Nicy Scaria, Silvester John Joseph Kennedy, Diksha Seth, Ananya Thakur, Deepak Subramani</dc:creator>
        <description><![CDATA[
            背景：当前自动生成高质量选择题的方法存在生成题目认知水平低、未融入特定领域错误概念的问题。方法：提出基于分层概念图的框架，先构建覆盖物理主题及关联的概念图，再自动检索相关部分为大语言模型生成题目和干扰项提供结构化上下文，最后自动验证。效果：与两种基线方法对比，专家评估显示该方法满足所有质量标准的成功率达75.20%，远高于基线的约37%；学生评估显示猜测成功率为28.05%，低于基线的37.10%。
            arXiv:2505.02850v1 Announce Type: new 
Abstract: Generating high-quality MCQs, especially those targeting diverse cognitive levels and incorporating common misconceptions into distractor design, is time-consuming and expertise-intensive, making manual creation impractical at scale. Current automated approaches typically generate questions at lower cognitive levels and fail to incorporate domain-specific misconceptions. This paper presents a hierarchical concept map-based framework that provides structured knowledge to guide LLMs in generating MCQs with distractors. We chose high-school physics as our test domain and began by developing a hierarchical concept map covering major Physics topics and their interconnections with an efficient database design. Next, through an automated pipeline, topic-relevant sections of these concept maps are retrieved to serve as a structured context for the LLM to generate questions and distractors that specifically target common misconceptions. Lastly, an automated validation is completed to ensure that the generated MCQs meet the requirements provided. We evaluate our framework against two baseline approaches: a base LLM and a RAG-based generation. We conducted expert evaluations and student assessments of the generated MCQs. Expert evaluation shows that our method significantly outperforms the baseline approaches, achieving a success rate of 75.20% in meeting all quality criteria compared to approximately 37% for both baseline methods. Student assessment data reveal that our concept map-driven approach achieved a significantly lower guess success rate of 28.05% compared to 37.10% for the baselines, indicating a more effective assessment of conceptual understanding. The results demonstrate that our concept map-based approach enables robust assessment across cognitive levels and instant identification of conceptual gaps, facilitating faster feedback loops and targeted interventions at scale.
        ]]></description>
    </item>
    <item>
        <title>RESAnything: Attribute Prompting for Arbitrary Referring Segmentation</title>
        <link>https://arxiv.org/abs/2505.02867</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.02867v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ruiqi Wang, Hao Zhang</dc:creator>
        <description><![CDATA[
            背景：现有任意指代表达分割方法处理的输入较局限。方法：提出RESAnything模型，利用思维链推理和属性提示，通过对大语言模型系统提示，为基础图像分割模型生成的潜在分割提案生成对象/部分属性详细描述，鼓励对对象或部分属性进行深度推理。效果：作为首个基于大语言模型的零样本任意指代表达分割方法，在传统基准上零样本性能优，在含隐式查询和复杂部分关系场景中显著优于现有方法，还贡献新基准数据集。
            arXiv:2505.02867v1 Announce Type: new 
Abstract: We present an open-vocabulary and zero-shot method for arbitrary referring expression segmentation (RES), targeting input expressions that are more general than what prior works were designed to handle. Specifically, our inputs encompass both object- and part-level labels as well as implicit references pointing to properties or qualities of object/part function, design, style, material, etc. Our model, coined RESAnything, leverages Chain-of-Thoughts (CoT) reasoning, where the key idea is attribute prompting. We generate detailed descriptions of object/part attributes including shape, color, and location for potential segment proposals through systematic prompting of a large language model (LLM), where the proposals are produced by a foundational image segmentation model. Our approach encourages deep reasoning about object or part attributes related to function, style, design, etc., enabling the system to handle implicit queries without any part annotations for training or fine-tuning. As the first zero-shot and LLM-based RES method, RESAnything achieves clearly superior performance among zero-shot methods on traditional RES benchmarks and significantly outperforms existing methods on challenging scenarios involving implicit queries and complex part-level relations. Finally, we contribute a new benchmark dataset to offer ~3K carefully curated RES instances to assess part-level, arbitrary RES solutions.
        ]]></description>
    </item>
    <item>
        <title>LLM4FTS: Enhancing Large Language Models for Financial Time Series Prediction</title>
        <link>https://arxiv.org/abs/2505.02880</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.02880v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zian Liu, Renjun Jia</dc:creator>
        <description><![CDATA[
            金融时间序列预测因低信噪比和复杂时间模式存在挑战，传统模型容量有限，现有基于大语言模型（LLM）的方法忽视多尺度特征。本文提出LLM4FTS框架，通过可学习的补丁分割和动态小波卷积模块增强LLM对时间序列的建模能力。先基于DTW距离用K-means++聚类识别市场数据的尺度不变模式，再进行自适应补丁分割，还设计动态小波卷积模块。实验表明，该框架能捕捉复杂市场模式，在股票收益预测中达最优，且在实际交易系统中适用。
            arXiv:2505.02880v1 Announce Type: new 
Abstract: Predicting financial time series presents significant challenges due to inherent low signal-to-noise ratios and intricate temporal patterns. Traditional machine learning models exhibit limitations in this forecasting task constrained by their restricted model capacity. Recent advances in large language models (LLMs), with their greatly expanded parameter spaces, demonstrate promising potential for modeling complex dependencies in temporal sequences. However, existing LLM-based approaches typically focus on fixed-length patch analysis due to the Transformer architecture, ignoring market data's multi-scale pattern characteristics. In this study, we propose $LLM4FTS$, a novel framework that enhances LLM capabilities for temporal sequence modeling through learnable patch segmentation and dynamic wavelet convolution modules. Specifically,we first employ K-means++ clustering based on DTW distance to identify scale-invariant patterns in market data. Building upon pattern recognition results, we introduce adaptive patch segmentation that partitions temporal sequences while preserving maximal pattern integrity. To accommodate time-varying frequency characteristics, we devise a dynamic wavelet convolution module that emulates discrete wavelet transformation with enhanced flexibility in capturing time-frequency features. These three modules work together to improve large language model's ability to handle scale-invariant patterns in financial time series. Extensive experiments on real-world financial datasets substantiate the framework's efficacy, demonstrating superior performance in capturing complex market patterns and achieving state-of-the-art results in stock return prediction. The successful deployment in practical trading systems confirms its real-world applicability, representing a significant advancement in LLM applications for financial forecasting.
        ]]></description>
    </item>
    <item>
        <title>34 Examples of LLM Applications in Materials Science and Chemistry: Towards Automation, Assistants, Agents, and Accelerated Scientific Discovery</title>
        <link>https://arxiv.org/abs/2505.03049</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.03049v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yoel Zimmermann, Adib Bazgir, Alexander Al-Feghali, Mehrad Ansari, L. Catherine Brinson, Yuan Chiang, Defne Circi, Min-Hsueh Chiu, Nathan Daelman, Matthew L. Evans, Abhijeet S. Gangan, Janine George, Hassan Harb, Ghazal Khalighinejad, Sartaaj Takrim Khan, Sascha Klawohn, Magdalena Lederbauer, Soroush Mahjoubi, Bernadette Mohr, Seyed Mohamad Moosavi, Aakash Naik, Aleyna Beste Ozhan, Dieter Plessers, Aritra Roy, Fabian Sch\"oppach, Philippe Schwaller, Carla Terboven, Katharina Ueltzen, Shang Zhu, Jan Janssen, Calvin Li, Ian Foster, Ben Blaiszik</dc:creator>
        <description><![CDATA[
            背景：大语言模型（LLMs）正重塑材料科学和化学研究，能融合结构化与非结构化数据。方法：通过回顾材料科学与化学领域第二届年度大语言模型黑客松的34个项目，探索LLMs在研究全生命周期的应用，涵盖分子和材料性质预测等七个关键领域。效果：通过添加推理、增加训练数据和采用新技术，开源和专有LLMs性能提升，尤其在低数据环境和跨学科研究中效果显著，不过其集成到科研工作流仍面临可靠性等挑战。
            arXiv:2505.03049v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are reshaping many aspects of materials science and chemistry research, enabling advances in molecular property prediction, materials design, scientific automation, knowledge extraction, and more. Recent developments demonstrate that the latest class of models are able to integrate structured and unstructured data, assist in hypothesis generation, and streamline research workflows. To explore the frontier of LLM capabilities across the research lifecycle, we review applications of LLMs through 34 total projects developed during the second annual Large Language Model Hackathon for Applications in Materials Science and Chemistry, a global hybrid event. These projects spanned seven key research areas: (1) molecular and material property prediction, (2) molecular and material design, (3) automation and novel interfaces, (4) scientific communication and education, (5) research data management and automation, (6) hypothesis generation and evaluation, and (7) knowledge extraction and reasoning from the scientific literature. Collectively, these applications illustrate how LLMs serve as versatile predictive models, platforms for rapid prototyping of domain-specific tools, and much more. In particular, improvements in both open source and proprietary LLM performance through the addition of reasoning, additional training data, and new techniques have expanded effectiveness, particularly in low-data environments and interdisciplinary research. As LLMs continue to improve, their integration into scientific workflows presents both new opportunities and new challenges, requiring ongoing exploration, continued refinement, and further research to address reliability, interpretability, and reproducibility.
        ]]></description>
    </item>
    <item>
        <title>RAVU: Retrieval Augmented Video Understanding with Compositional Reasoning over Graph</title>
        <link>https://arxiv.org/abs/2505.03173</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.03173v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sameer Malik, Moyuru Yamada, Ayush Singh, Dishank Aggarwal</dc:creator>
        <description><![CDATA[
            当前多模态大模型理解长视频存在挑战，因缺乏显式记忆和检索机制，难以处理数分钟到数小时的视频。为此提出RAVU框架，构建视频的时空图表示，捕捉实体间时空关系，作为长期记忆来跟踪对象和动作。将复杂查询分解为推理步骤，在图上执行以检索关键信息。该方法能更准确理解长视频，尤其适用于多跳推理和跨帧跟踪对象的查询。在两个视频问答数据集上，用5 - 10帧检索时性能优于其他方法。
            arXiv:2505.03173v1 Announce Type: new 
Abstract: Comprehending long videos remains a significant challenge for Large Multi-modal Models (LMMs). Current LMMs struggle to process even minutes to hours videos due to their lack of explicit memory and retrieval mechanisms. To address this limitation, we propose RAVU (Retrieval Augmented Video Understanding), a novel framework for video understanding enhanced by retrieval with compositional reasoning over a spatio-temporal graph. We construct a graph representation of the video, capturing both spatial and temporal relationships between entities. This graph serves as a long-term memory, allowing us to track objects and their actions across time. To answer complex queries, we decompose the queries into a sequence of reasoning steps and execute these steps on the graph, retrieving relevant key information. Our approach enables more accurate understanding of long videos, particularly for queries that require multi-hop reasoning and tracking objects across frames. Our approach demonstrate superior performances with limited retrieved frames (5-10) compared with other SOTA methods and baselines on two major video QA datasets, NExT-QA and EgoSchema.
        ]]></description>
    </item>
    <item>
        <title>Survey of Abstract Meaning Representation: Then, Now, Future</title>
        <link>https://arxiv.org/abs/2505.03229</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.03229v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Behrooz Mansouri</dc:creator>
        <description><![CDATA[
            背景：为使模型理解句子语义，需有效的语义表示框架。方法：本文对抽象意义表示（AMR）进行综述，它通过基于图的结构捕捉句子含义，将句子表示为有根有向无环图，节点对应概念、边表示关系。还探讨了AMR及其扩展、解析和生成任务的不同方法，回顾其在文本生成等方面的应用。效果：分析领域发展与挑战，为未来研究方向提供见解，有望提升机器对人类语言的理解。
            arXiv:2505.03229v1 Announce Type: new 
Abstract: This paper presents a survey of Abstract Meaning Representation (AMR), a semantic representation framework that captures the meaning of sentences through a graph-based structure. AMR represents sentences as rooted, directed acyclic graphs, where nodes correspond to concepts and edges denote relationships, effectively encoding the meaning of complex sentences. This survey investigates AMR and its extensions, focusing on AMR capabilities. It then explores the parsing (text-to-AMR) and generation (AMR-to-text) tasks by showing traditional, current, and possible futures approaches. It also reviews various applications of AMR including text generation, text classification, and information extraction and information seeking. By analyzing recent developments and challenges in the field, this survey provides insights into future directions for research and the potential impact of AMR on enhancing machine understanding of human language.
        ]]></description>
    </item>
    <item>
        <title>Physics-inspired Energy Transition Neural Network for Sequence Learning</title>
        <link>https://arxiv.org/abs/2505.03281</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.03281v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhou Wu, Junyi An, Baile Xu, Furao Shen, Jian Zhao</dc:creator>
        <description><![CDATA[
            背景：Transformer在序列建模上表现出色，但捕捉长期依赖的有效性主要源于成对建模，而非对序列语义的归纳偏置。方法：受物理能量转换模型启发，提出“物理启发的能量转换神经网络”（PETNN），其记忆机制可有效存储长期依赖信息。效果：实验表明，PETNN在各种序列任务上优于基于Transformer的方法，且因其循环特性，复杂度显著降低，为开发有效循环神经网络提供了潜力。 
            arXiv:2505.03281v1 Announce Type: new 
Abstract: Recently, the superior performance of Transformers has made them a more robust and scalable solution for sequence modeling than traditional recurrent neural networks (RNNs). However, the effectiveness of Transformer in capturing long-term dependencies is primarily attributed to their comprehensive pair-modeling process rather than inherent inductive biases toward sequence semantics. In this study, we explore the capabilities of pure RNNs and reassess their long-term learning mechanisms. Inspired by the physics energy transition models that track energy changes over time, we propose a effective recurrent structure called the``Physics-inspired Energy Transition Neural Network" (PETNN). We demonstrate that PETNN's memory mechanism effectively stores information over long-term dependencies. Experimental results indicate that PETNN outperforms transformer-based methods across various sequence tasks. Furthermore, owing to its recurrent nature, PETNN exhibits significantly lower complexity. Our study presents an optimal foundational recurrent architecture and highlights the potential for developing effective recurrent neural networks in fields currently dominated by Transformer.
        ]]></description>
    </item>
    <item>
        <title>Unified Multimodal Chain-of-Thought Reward Model through Reinforcement Fine-Tuning</title>
        <link>https://arxiv.org/abs/2505.03318</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.03318v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yibin Wang, Zhimin Li, Yuhang Zang, Chunyu Wang, Qinglin Lu, Cheng Jin, Jiaqi Wang</dc:creator>
        <description><![CDATA[
            背景：当前多模态奖励模型（RMs）提供奖励信号时多为直接回应或浅层推理，导致信号不准确。方法：提出首个基于多模态思维链（CoT）的统一奖励模型UnifiedReward - Think，采用探索驱动的强化微调方法。先利用少量图像生成偏好数据提炼GPT - 4o推理过程用于模型冷启动，再准备大规模统一多模态偏好数据激发推理，保留正确输出、用错误样本进行强化微调。效果：在多种视觉奖励任务实验中展现出优越性。
            arXiv:2505.03318v1 Announce Type: new 
Abstract: Recent advances in multimodal Reward Models (RMs) have shown significant promise in delivering reward signals to align vision models with human preferences. However, current RMs are generally restricted to providing direct responses or engaging in shallow reasoning processes with limited depth, often leading to inaccurate reward signals. We posit that incorporating explicit long chains of thought (CoT) into the reward reasoning process can significantly strengthen their reliability and robustness. Furthermore, we believe that once RMs internalize CoT reasoning, their direct response accuracy can also be improved through implicit reasoning capabilities. To this end, this paper proposes UnifiedReward-Think, the first unified multimodal CoT-based reward model, capable of multi-dimensional, step-by-step long-chain reasoning for both visual understanding and generation reward tasks. Specifically, we adopt an exploration-driven reinforcement fine-tuning approach to elicit and incentivize the model's latent complex reasoning ability: (1) We first use a small amount of image generation preference data to distill the reasoning process of GPT-4o, which is then used for the model's cold start to learn the format and structure of CoT reasoning. (2) Subsequently, by leveraging the model's prior knowledge and generalization capabilities, we prepare large-scale unified multimodal preference data to elicit the model's reasoning process across various vision tasks. During this phase, correct reasoning outputs are retained for rejection sampling to refine the model (3) while incorrect predicted samples are finally used for Group Relative Policy Optimization (GRPO) based reinforcement fine-tuning, enabling the model to explore diverse reasoning paths and optimize for correct and robust solutions. Extensive experiments across various vision reward tasks demonstrate the superiority of our model.
        ]]></description>
    </item>
    <item>
        <title>Recall with Reasoning: Chain-of-Thought Distillation for Mamba's Long-Context Memory and Extrapolation</title>
        <link>https://arxiv.org/abs/2505.03320</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.03320v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Junyu Ma, Tianqing Fang, Zhisong Zhang, Hongming Zhang, Haitao Mi, Dong Yu</dc:creator>
        <description><![CDATA[
            背景：Mamba理论上的无限上下文潜力在序列远超训练长度时受限。方法：提出简单有效的“带推理的回忆”（RwR）方法，从教师模型中提炼思维链（CoT）摘要，在微调时将这些摘要作为CoT提示前置，教Mamba主动回忆和推理长上下文。效果：在LONGMEMEVAL和HELMET上的实验表明，RwR在相似预训练条件下，提升了Mamba长上下文性能，优于可比的Transformer/混合基线模型，且保留了短上下文能力，无需改变架构。
            arXiv:2505.03320v1 Announce Type: new 
Abstract: Mamba's theoretical infinite-context potential is limited in practice when sequences far exceed training lengths. This work explores unlocking Mamba's long-context memory ability by a simple-yet-effective method, Recall with Reasoning (RwR), by distilling chain-of-thought (CoT) summarization from a teacher model. Specifically, RwR prepends these summarization as CoT prompts during fine-tuning, teaching Mamba to actively recall and reason over long contexts. Experiments on LONGMEMEVAL and HELMET show RwR boosts Mamba's long-context performance against comparable Transformer/hybrid baselines under similar pretraining conditions, while preserving short-context capabilities, all without architectural changes.
        ]]></description>
    </item>
    <item>
        <title>Knowledge Augmented Complex Problem Solving with Large Language Models: A Survey</title>
        <link>https://arxiv.org/abs/2505.03418</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.03418v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Da Zheng, Lun Du, Junwei Su, Yuchen Tian, Yuqi Zhu, Jintian Zhang, Lanning Wei, Ningyu Zhang, Huajun Chen</dc:creator>
        <description><![CDATA[
            背景：解决问题是人类进步的重要驱动力，大语言模型（LLMs）可用于解决复杂问题，但在现实应用中面临多步推理、领域知识整合和结果验证等挑战。方法：本文探讨LLMs在复杂问题解决中的能力与局限，研究思维链推理、知识增强及多种验证技术，还指出软件工程、数学推理等领域的特定挑战。效果：讨论了当前LLM解决方案的根本局限及未来多步推理、领域知识整合和结果验证方向。
            arXiv:2505.03418v1 Announce Type: new 
Abstract: Problem-solving has been a fundamental driver of human progress in numerous domains. With advancements in artificial intelligence, Large Language Models (LLMs) have emerged as powerful tools capable of tackling complex problems across diverse domains. Unlike traditional computational systems, LLMs combine raw computational power with an approximation of human reasoning, allowing them to generate solutions, make inferences, and even leverage external computational tools. However, applying LLMs to real-world problem-solving presents significant challenges, including multi-step reasoning, domain knowledge integration, and result verification. This survey explores the capabilities and limitations of LLMs in complex problem-solving, examining techniques including Chain-of-Thought (CoT) reasoning, knowledge augmentation, and various LLM-based and tool-based verification techniques. Additionally, we highlight domain-specific challenges in various domains, such as software engineering, mathematical reasoning and proving, data analysis and modeling, and scientific research. The paper further discusses the fundamental limitations of the current LLM solutions and the future directions of LLM-based complex problems solving from the perspective of multi-step reasoning, domain knowledge integration and result verification.
        ]]></description>
    </item>
    <item>
        <title>An Analysis of Hyper-Parameter Optimization Methods for Retrieval Augmented Generation</title>
        <link>https://arxiv.org/abs/2505.03452</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.03452v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Matan Orbach, Ohad Eytan, Benjamin Sznajder, Ariel Gera, Odellia Boni, Yoav Kantor, Gal Bloch, Omri Levy, Hadas Abraham, Nitzan Barzilay, Eyal Shnarch, Michael E. Factor, Shila Ofek-Koifman, Paula Ta-Shma, Assaf Toledo</dc:creator>
        <description><![CDATA[
            背景：寻找特定用例的最优检索增强生成（RAG）配置复杂且成本高，现有RAG超参数优化（HPO）框架效果未严格评估。方法：对来自不同领域的5个数据集，用5种HPO算法开展研究，探索迄今最大HPO搜索空间并采用两个优化评估指标。效果：RAG HPO可通过贪心或迭代随机搜索高效完成，显著提升所有数据集上RAG性能，贪心HPO方法中先优化模型比按RAG管道顺序依次优化更优。
            arXiv:2505.03452v1 Announce Type: new 
Abstract: Finding the optimal Retrieval-Augmented Generation (RAG) configuration for a given use case can be complex and expensive. Motivated by this challenge, frameworks for RAG hyper-parameter optimization (HPO) have recently emerged, yet their effectiveness has not been rigorously benchmarked. To address this gap, we present a comprehensive study involving 5 HPO algorithms over 5 datasets from diverse domains, including a new one collected for this work on real-world product documentation. Our study explores the largest HPO search space considered to date, with two optimized evaluation metrics. Analysis of the results shows that RAG HPO can be done efficiently, either greedily or with iterative random search, and that it significantly boosts RAG performance for all datasets. For greedy HPO approaches, we show that optimizing models first is preferable to the prevalent practice of optimizing sequentially according to the RAG pipeline order.
        ]]></description>
    </item>
    <item>
        <title>Long-Short Chain-of-Thought Mixture Supervised Fine-Tuning Eliciting Efficient Reasoning in Large Language Models</title>
        <link>https://arxiv.org/abs/2505.03469</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.03469v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Bin Yu, Hang Yuan, Yuliang Wei, Bailing Wang, Weizhen Qi, Kai Chen</dc:creator>
        <description><![CDATA[
            背景：用大推理模型提炼的思维链推理数据进行监督微调，虽能让非推理模型获得推理能力，但会继承“过度思考”问题，推理链冗长冗余。方法：提出长短思维链混合监督微调（LS - Mixture SFT），将长思维链推理数据集与通过保留结构重写得到的短数据集结合。效果：相比直接监督微调，该方法训练的模型在各基准测试中平均准确率提升2.3%，同时大幅减少约47.61%的模型响应长度。
            arXiv:2505.03469v1 Announce Type: new 
Abstract: Recent advances in large language models have demonstrated that Supervised Fine-Tuning (SFT) with Chain-of-Thought (CoT) reasoning data distilled from large reasoning models (e.g., DeepSeek R1) can effectively transfer reasoning capabilities to non-reasoning models. However, models fine-tuned with this approach inherit the "overthinking" problem from teacher models, producing verbose and redundant reasoning chains during inference. To address this challenge, we propose \textbf{L}ong-\textbf{S}hort Chain-of-Thought \textbf{Mixture} \textbf{S}upervised \textbf{F}ine-\textbf{T}uning (\textbf{LS-Mixture SFT}), which combines long CoT reasoning dataset with their short counterparts obtained through structure-preserved rewriting. Our experiments demonstrate that models trained using the LS-Mixture SFT method, compared to those trained with direct SFT, achieved an average accuracy improvement of 2.3\% across various benchmarks while substantially reducing model response length by approximately 47.61\%. This work offers an approach to endow non-reasoning models with reasoning capabilities through supervised fine-tuning while avoiding the inherent overthinking problems inherited from teacher models, thereby enabling efficient reasoning in the fine-tuned models.
        ]]></description>
    </item>
    <item>
        <title>DyGEnc: Encoding a Sequence of Textual Scene Graphs to Reason and Answer Questions in Dynamic Scenes</title>
        <link>https://arxiv.org/abs/2505.03581</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.03581v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sergey Linok, Vadim Semenov, Anastasia Trunova, Oleg Bulichev, Dmitry Yudin</dc:creator>
        <description><![CDATA[
            背景：动态环境事件分析是智能体和机器人研发的挑战，现有视觉模型隐式捕捉信息，缺乏可解释时空对象表示。方法：提出DyGEnc，将压缩时空结构观察表示与大语言模型认知能力结合，基于文本场景图序列实现高级问答。效果：在STAR和AGQA数据集上，处理人机交互历史查询时比现有视觉方法高出15 - 25%，还能结合基础模型处理原始图像。
            arXiv:2505.03581v1 Announce Type: new 
Abstract: The analysis of events in dynamic environments poses a fundamental challenge in the development of intelligent agents and robots capable of interacting with humans. Current approaches predominantly utilize visual models. However, these methods often capture information implicitly from images, lacking interpretable spatial-temporal object representations. To address this issue we introduce DyGEnc - a novel method for Encoding a Dynamic Graph. This method integrates compressed spatial-temporal structural observation representation with the cognitive capabilities of large language models. The purpose of this integration is to enable advanced question answering based on a sequence of textual scene graphs. Extended evaluations on the STAR and AGQA datasets indicate that DyGEnc outperforms existing visual methods by a large margin of 15-25% in addressing queries regarding the history of human-to-object interactions. Furthermore, the proposed method can be seamlessly extended to process raw input images utilizing foundational models for extracting explicit textual scene graphs, as substantiated by the results of a robotic experiment conducted with a wheeled manipulator platform. We hope that these findings will contribute to the implementation of robust and compressed graph-based robotic memory for long-horizon reasoning. Code is available at github.com/linukc/DyGEnc.
        ]]></description>
    </item>
    <item>
        <title>ReGraP-LLaVA: Reasoning enabled Graph-based Personalized Large Language and Vision Assistant</title>
        <link>https://arxiv.org/abs/2505.03654</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.03654v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yifan Xiang, Zhenxi Zhang, Bin Li, Yixuan Weng, Shoujun Zhou, Yangfan He, Keqin Li</dc:creator>
        <description><![CDATA[
            背景：现有个性化多模态大语言模型在处理对象关系推理等方面存在局限，如训练数据缺乏可学习对象关系的多对象集，模型忽视概念间关系且实验多针对单一概念。方法：提出含120组个性化知识的数据集ReGraP，包括图像、知识图谱（KGs）和思维链（CoT）问答对；提出MLLM模型ReGraP - LLaVA，用KGs和CoT问答对训练，设计软硬图提示法对齐KGs与模型语义空间；建立ReGraP基准评估模型能力。效果：该模型在关系推理上达SOTA。
            arXiv:2505.03654v1 Announce Type: new 
Abstract: Recent advances in personalized MLLMs enable effective capture of user-specific concepts, supporting both recognition of personalized concepts and contextual captioning. However, humans typically explore and reason over relations among objects and individuals, transcending surface-level information to achieve more personalized and contextual understanding. To this end, existing methods may face three main limitations: Their training data lacks multi-object sets in which relations among objects are learnable. Building on the limited training data, their models overlook the relations between different personalized concepts and fail to reason over them. Their experiments mainly focus on a single personalized concept, where evaluations are limited to recognition and captioning tasks. To address the limitations, we present a new dataset named ReGraP, consisting of 120 sets of personalized knowledge. Each set includes images, KGs, and CoT QA pairs derived from the KGs, enabling more structured and sophisticated reasoning pathways. We propose ReGraP-LLaVA, an MLLM trained with the corresponding KGs and CoT QA pairs, where soft and hard graph prompting methods are designed to align KGs within the model's semantic space. We establish the ReGraP Benchmark, which contains diverse task types: multiple-choice, fill-in-the-blank, True/False, and descriptive questions in both open- and closed-ended settings. The proposed benchmark is designed to evaluate the relational reasoning and knowledge-connection capability of personalized MLLMs. We conduct experiments on the proposed ReGraP-LLaVA and other competitive MLLMs. Results show that the proposed model not only learns personalized knowledge but also performs relational reasoning in responses, achieving the SoTA performance compared with the competitive methods. All the codes and datasets are released at: https://github.com/xyfyyds/ReGraP.
        ]]></description>
    </item>
    <item>
        <title>STG: Spatiotemporal Graph Neural Network with Fusion and Spatiotemporal Decoupling Learning for Prognostic Prediction of Colorectal Cancer Liver Metastasis</title>
        <link>https://arxiv.org/abs/2505.03123</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.03123v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yiran Zhu, Wei Yang, Yan su, Zesheng Li, Chengchang Pan, Honggang Qi</dc:creator>
        <description><![CDATA[
            背景：当前临床模型无法有效整合肿瘤空间异质性、动态演变和复杂多模态数据关系，限制预测准确性。方法：提出多模态时空图神经网络（STG）框架，将术前CT影像和临床数据整合为异质图结构，用GraphSAGE聚合时空邻域信息，结合监督和对比学习策略。还推出轻量级版本减少参数。结果：轻量级模型参数减少78.55%，在MSKCC CRLM数据集上时间邻接准确率达85%，平均绝对误差1.1005，优于现有方法。
            arXiv:2505.03123v1 Announce Type: cross 
Abstract: We propose a multimodal spatiotemporal graph neural network (STG) framework to predict colorectal cancer liver metastasis (CRLM) progression. Current clinical models do not effectively integrate the tumor's spatial heterogeneity, dynamic evolution, and complex multimodal data relationships, limiting their predictive accuracy. Our STG framework combines preoperative CT imaging and clinical data into a heterogeneous graph structure, enabling joint modeling of tumor distribution and temporal evolution through spatial topology and cross-modal edges. The framework uses GraphSAGE to aggregate spatiotemporal neighborhood information and leverages supervised and contrastive learning strategies to enhance the model's ability to capture temporal features and improve robustness. A lightweight version of the model reduces parameter count by 78.55%, maintaining near-state-of-the-art performance. The model jointly optimizes recurrence risk regression and survival analysis tasks, with contrastive loss improving feature representational discriminability and cross-modal consistency. Experimental results on the MSKCC CRLM dataset show a time-adjacent accuracy of 85% and a mean absolute error of 1.1005, significantly outperforming existing methods. The innovative heterogeneous graph construction and spatiotemporal decoupling mechanism effectively uncover the associations between dynamic tumor microenvironment changes and prognosis, providing reliable quantitative support for personalized treatment decisions.
        ]]></description>
    </item>
    <item>
        <title>Multi-modal cascade feature transfer for polymer property prediction</title>
        <link>https://arxiv.org/abs/2505.03704</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.03704v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kiichi Obuchi, Yuta Yahagi, Kiyohiko Toyama, Shukichi Tanaka, Kota Matsui</dc:creator>
        <description><![CDATA[
            背景：聚合物数据格式多样，传统方法常分别用不同类型数据构建预测模型。方法：提出一种用于聚合物性能预测的多模态级联特征转移模型，将图卷积神经网络从化学结构中提取的特征与分子描述符、添加剂信息等特征相结合。效果：用多个聚合物数据集评估，结果显示该方法相比使用单一特征的传统基线方法，具有更高的预测性能。
            arXiv:2505.03704v1 Announce Type: cross 
Abstract: In this paper, we propose a novel transfer learning approach called multi-modal cascade model with feature transfer for polymer property prediction.Polymers are characterized by a composite of data in several different formats, including molecular descriptors and additive information as well as chemical structures. However, in conventional approaches, prediction models were often constructed using each type of data separately. Our model enables more accurate prediction of physical properties for polymers by combining features extracted from the chemical structure by graph convolutional neural networks (GCN) with features such as molecular descriptors and additive information. The predictive performance of the proposed method is empirically evaluated using several polymer datasets. We report that the proposed method shows high predictive performance compared to the baseline conventional approach using a single feature.
        ]]></description>
    </item>
    <item>
        <title>FreDF: Learning to Forecast in the Frequency Domain</title>
        <link>https://arxiv.org/abs/2402.02399</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2402.02399v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hao Wang, Licheng Pan, Zhichao Chen, Degui Yang, Sen Zhang, Yifei Yang, Xinggao Liu, Haoxuan Li, Dacheng Tao</dc:creator>
        <description><![CDATA[
            背景：时间序列建模因历史数据和未来序列的自相关性面临挑战，现有研究多关注历史数据自相关，忽视未来标签相关性，直接预测范式存在偏差。方法：提出频域增强直接预测（FreDF）方法，通过在频域学习预测来减轻标签自相关性，减少估计偏差。效果：实验表明，FreDF显著优于现有最先进方法，且能与多种预测模型兼容。代码见https://github.com/Master - PLC/FreDF。
            arXiv:2402.02399v2 Announce Type: replace 
Abstract: Time series modeling presents unique challenges due to autocorrelation in both historical data and future sequences. While current research predominantly addresses autocorrelation within historical data, the correlations among future labels are often overlooked. Specifically, modern forecasting models primarily adhere to the Direct Forecast (DF) paradigm, generating multi-step forecasts independently and disregarding label autocorrelation over time. In this work, we demonstrate that the learning objective of DF is biased in the presence of label autocorrelation. To address this issue, we propose the Frequency-enhanced Direct Forecast (FreDF), which mitigates label autocorrelation by learning to forecast in the frequency domain, thereby reducing estimation bias. Our experiments show that FreDF significantly outperforms existing state-of-the-art methods and is compatible with a variety of forecast models. Code is available at https://github.com/Master-PLC/FreDF.
        ]]></description>
    </item>
    <item>
        <title>A Survey on Self-Supervised Graph Foundation Models: Knowledge-Based Perspective</title>
        <link>https://arxiv.org/abs/2403.16137</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2403.16137v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ziwen Zhao, Yixin Su, Yuhua Li, Yixiong Zou, Ruixuan Li, Rui Zhang</dc:creator>
        <description><![CDATA[
            背景：图自监督学习是预训练图基础模型（GFMs）的常用方法，图数据中知识模式多样，但现有GFMs综述存在涵盖不全、自监督方法分类不明等问题。方法：从全新的基于知识视角对自监督GFMs进行全面综述，提出基于知识的分类法，按利用的图知识对模型分类，涵盖微观、介观和宏观知识共9类及超25个预训练前置任务和下游任务泛化策略。效果：有助于更清晰审视新架构图模型，为构建GFMs提供深入见解。
            arXiv:2403.16137v3 Announce Type: replace 
Abstract: Graph self-supervised learning (SSL) is now a go-to method for pre-training graph foundation models (GFMs). There is a wide variety of knowledge patterns embedded in the graph data, such as node properties and clusters, which are crucial to learning generalized representations for GFMs. However, existing surveys of GFMs have several shortcomings: they lack comprehensiveness regarding the most recent progress, have unclear categorization of self-supervised methods, and take a limited architecture-based perspective that is restricted to only certain types of graph models. As the ultimate goal of GFMs is to learn generalized graph knowledge, we provide a comprehensive survey of self-supervised GFMs from a novel knowledge-based perspective. We propose a knowledge-based taxonomy, which categorizes self-supervised graph models by the specific graph knowledge utilized. Our taxonomy consists of microscopic (nodes, links, etc.), mesoscopic (context, clusters, etc.), and macroscopic knowledge (global structure, manifolds, etc.). It covers a total of 9 knowledge categories and more than 25 pretext tasks for pre-training GFMs, as well as various downstream task generalization strategies. Such a knowledge-based taxonomy allows us to re-examine graph models based on new architectures more clearly, such as graph language models, as well as provide more in-depth insights for constructing GFMs.
        ]]></description>
    </item>
    <item>
        <title>Beyond Bare Queries: Open-Vocabulary Object Grounding with 3D Scene Graph</title>
        <link>https://arxiv.org/abs/2406.07113</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2406.07113v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sergey Linok, Tatiana Zemskova, Svetlana Ladanova, Roman Titkov, Dmitry Yudin, Maxim Monastyrny, Aleksei Valenkov</dc:creator>
        <description><![CDATA[
            自然语言描述的物体定位对自主智能体是重大挑战，现有基于CLIP的方法难以处理需理解物体关系的模糊描述。为此提出模块化方法BBQ，构建含度量和语义空间边的3D场景图表示，通过演绎场景推理算法利用大语言模型作为人机接口。用DINO关联构建以3D物体为中心的地图，用射线追踪算法和2D视觉语言模型将物体描述为图节点。在多个数据集和基准测试中，相比其他方法，该方法在开放词汇3D语义分割和复杂查询物体定位上表现更优，且数据处理速度快。
            arXiv:2406.07113v4 Announce Type: replace 
Abstract: Locating objects described in natural language presents a significant challenge for autonomous agents. Existing CLIP-based open-vocabulary methods successfully perform 3D object grounding with simple (bare) queries, but cannot cope with ambiguous descriptions that demand an understanding of object relations. To tackle this problem, we propose a modular approach called BBQ (Beyond Bare Queries), which constructs 3D scene graph representation with metric and semantic spatial edges and utilizes a large language model as a human-to-agent interface through our deductive scene reasoning algorithm. BBQ employs robust DINO-powered associations to construct 3D object-centric map and an advanced raycasting algorithm with a 2D vision-language model to describe them as graph nodes. On the Replica and ScanNet datasets, we have demonstrated that BBQ takes a leading place in open-vocabulary 3D semantic segmentation compared to other zero-shot methods. Also, we show that leveraging spatial relations is especially effective for scenes containing multiple entities of the same semantic class. On challenging Sr3D+, Nr3D and ScanRefer benchmarks, our deductive approach demonstrates a significant improvement, enabling objects grounding by complex queries compared to other state-of-the-art methods. The combination of our design choices and software implementation has resulted in significant data processing speed in experiments on the robot on-board computer. This promising performance enables the application of our approach in intelligent robotics projects. We made the code publicly available at https://linukc.github.io/BeyondBareQueries/.
        ]]></description>
    </item>
    <item>
        <title>CombAlign: Enhancing Model Expressiveness in Unsupervised Graph Alignment</title>
        <link>https://arxiv.org/abs/2406.13216</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2406.13216v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Songyang Chen, Yu Liu, Lei Zou, Zexuan Wang, Youfang Lin</dc:creator>
        <description><![CDATA[
            背景：无监督图对齐利用图结构和节点特征寻找属性图间节点对应关系，但模型表达能力及理论表达性对预测准确性的影响研究不足。方法：从区分匹配和未匹配节点对、保证节点匹配属性两方面研究模型表达能力，提出混合方法CombAlign，实现基于OT学习的跨维特征交互，提出基于嵌入的方法，应用非均匀边缘分布作为先验，结合集成学习策略和最大权重匹配进行细化。效果：实验表明，与现有方法相比，对齐准确率显著提高14.5%。
            arXiv:2406.13216v3 Announce Type: replace 
Abstract: Unsupervised graph alignment finds the node correspondence between a pair of attributed graphs by only exploiting graph structure and node features. One category of recent studies first computes the node representation and then matches nodes with the largest embedding-based similarity, while the other category reduces the problem to optimal transport (OT) via Gromov-Wasserstein learning. However, it remains largely unexplored in the model expressiveness, as well as how theoretical expressivity impacts prediction accuracy. We investigate the model expressiveness from two aspects. First, we characterize the model's discriminative power in distinguishing matched and unmatched node pairs across two graphs. Second, we study the model's capability of guaranteeing node matching properties such as one-to-one matching and mutual alignment. Motivated by our theoretical analysis, we put forward a hybrid approach named CombAlign with stronger expressive power. Specifically, we enable cross-dimensional feature interaction for OT-based learning and propose an embedding-based method inspired by the Weisfeiler-Lehman test. We also apply non-uniform marginals obtained from the embedding-based modules to OT as priors for more expressiveness. Based on that, we propose a traditional algorithm-based refinement, which combines our OT and embedding-based predictions using the ensemble learning strategy and reduces the problem to maximum weight matching. With carefully designed edge weights, we ensure those matching properties and further enhance prediction accuracy. By extensive experiments, we demonstrate a significant improvement of 14.5% in alignment accuracy compared to state-of-the-art approaches and confirm the soundness of our theoretical analysis.
        ]]></description>
    </item>
    <item>
        <title>MATATA: Weakly Supervised End-to-End MAthematical Tool-Augmented Reasoning for Tabular Applications</title>
        <link>https://arxiv.org/abs/2411.18915</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2411.18915v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Vishnou Vinayagame, Gregory Senay, Luis Mart\'i</dc:creator>
        <description><![CDATA[
            背景：商业文档含大量表格、文本及数值信息，需数学推理助理解，小语言模型处理此任务较难，工具增强的多步代理虽好但依赖闭源或大模型等。方法：提出MATATA，一种弱监督端到端方法，以推理链最终结果为弱监督，采用自适应规划器和跨数据集共享工具训练多步推理语言代理。效果：实验表明，MATATA在FinQA、TAT - QA达开源小语言模型推理方法最优，在TabMWP上接近GPT - 4框架。
            arXiv:2411.18915v4 Announce Type: replace 
Abstract: Business documents often contain substantial tabular and textual information with numerical values, requiring mathematical reasoning for effective document understanding. While Small Language Models (SLMs) still struggle at this task, tool-augmented multi-step agents perform better, at the cost of relying on closed-source or larger models, external data, or extensive prompt-engineering. This work introduces MATATA, a novel weakly supervised end-to-end approach to train multi-step reasoning language agents for document tabular applications. MATATA presents an annotation-free paradigm for each agent to enhance 3.8B/8B SLMs. During its two-stage training, MATATA uses the final outcome of the multi-step reasoning chain as weak supervision. This approach avoids having to individually supervise each intermediate agent in the reasoning chain. By employing an adaptive planner and shared tools across different datasets, MATATA shows robust performance. Experiments demonstrate that MATATA achieves state-of-the-art on FinQA, and on TAT-QA among reasoning methods based on open-source SLMs. Although being SLM-based, MATATA closely matches GPT-4-based frameworks on TabMWP. This novel weakly supervised approach enables training an end-to-end multi-step reasoning agent without intermediate supervision, supporting future developments of cost-effective powerful agentic systems.
        ]]></description>
    </item>
    <item>
        <title>MoM: Linear Sequence Modeling with Mixture-of-Memories</title>
        <link>https://arxiv.org/abs/2502.13685</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.13685v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jusen Du, Weigao Sun, Disen Lan, Jiaxi Hu, Yu Cheng</dc:creator>
        <description><![CDATA[
            背景：线性序列建模方法虽提升了效率，但将输入序列压缩为单一固定大小记忆状态，在召回密集型下游任务中表现不佳。方法：受神经科学启发，提出Mixture-of-Memories（MoM）架构，利用多个独立记忆状态，通过路由网络将输入令牌分配到特定记忆状态，减少记忆干扰。效果：在召回密集型任务中表现出色，超越现有线性序列建模技术，在下游语言任务中显著优于当前线性序列模型，性能与Transformer模型相当。代码已开源。
            arXiv:2502.13685v2 Announce Type: replace 
Abstract: Linear sequence modeling methods, such as linear attention, state space modeling, and linear RNNs, offer significant efficiency improvements by reducing the complexity of training and inference. However, these methods typically compress the entire input sequence into a single fixed-size memory state, which leads to suboptimal performance on recall-intensive downstream tasks. Drawing inspiration from neuroscience, particularly the brain's ability to maintain robust long-term memory while mitigating "memory interference", we introduce a novel architecture called Mixture-of-Memories (MoM). MoM utilizes multiple independent memory states, with a router network directing input tokens to specific memory states. This approach greatly enhances the overall memory capacity while minimizing memory interference. As a result, MoM performs exceptionally well on recall-intensive tasks, surpassing existing linear sequence modeling techniques. Despite incorporating multiple memory states, the computation of each memory state remains linear in complexity, allowing MoM to retain the linear-complexity advantage during training, while constant-complexity during inference. Our experimental results show that MoM significantly outperforms current linear sequence models on downstream language tasks, particularly recall-intensive tasks, and even achieves performance comparable to Transformer models. The code is released at https://github.com/OpenSparseLLMs/MoM and is also released as a part of https://github.com/OpenSparseLLMs/Linear-MoE.
        ]]></description>
    </item>
    <item>
        <title>BRIDGE: Bootstrapping Text to Control Time-Series Generation via Multi-Agent Iterative Optimization and Diffusion Modelling</title>
        <link>https://arxiv.org/abs/2503.02445</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.02445v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hao Li, Yuhao Huang, Chang Xu, Viktor Schlegel, Renhe Jiang, Riza Batista-Navarro, Goran Nenadic, Jiang Bian</dc:creator>
        <description><![CDATA[
            时间序列生成（TSG）在多领域有广泛应用，但现有方法在跨领域可控生成方面不足。本文提出“文本控制的TSG”任务，认为文本可引导和改进TSG。为此提出基于大语言模型（LLM）的多智能体框架合成文本到时间序列数据集，还引入BRIDGE混合框架，结合语义原型和文本描述实现领域级指导。该方法在12个数据集中的11个达到了最优生成保真度，与无文本输入生成相比，均方误差（MSE）可控性提升12.52%，平均绝对误差（MAE）可控性提升6.34%。
            arXiv:2503.02445v3 Announce Type: replace 
Abstract: Time-series Generation (TSG) is a prominent research area with broad applications in simulations, data augmentation, and counterfactual analysis. While existing methods have shown promise in unconditional single-domain TSG, real-world applications demand for cross-domain approaches capable of controlled generation tailored to domain-specific constraints and instance-level requirements. In this paper, we argue that text can provide semantic insights, domain information and instance-specific temporal patterns, to guide and improve TSG. We introduce ``Text-Controlled TSG'', a task focused on generating realistic time series by incorporating textual descriptions. To address data scarcity in this setting, we propose a novel LLM-based Multi-Agent framework that synthesizes diverse, realistic text-to-TS datasets. Furthermore, we introduce BRIDGE, a hybrid text-controlled TSG framework that integrates semantic prototypes with text description for supporting domain-level guidance. This approach achieves state-of-the-art generation fidelity on 11 of 12 datasets, and improves controllability by 12.52% on MSE and 6.34% MAE compared to no text input generation, highlighting its potential for generating tailored time-series data.
        ]]></description>
    </item>
    <item>
        <title>Towards Hierarchical Multi-Step Reward Models for Enhanced Reasoning in Large Language Models</title>
        <link>https://arxiv.org/abs/2503.13551</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.13551v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Teng Wang, Zhangyi Jiang, Zhenqi He, Shenyang Tong, Wenhan Yang, Yanan Zheng, Zeyu Li, Zifan He, Hailei Gong</dc:creator>
        <description><![CDATA[
            背景：现有大语言模型推理能力提升方法中，过程奖励模型（PRM）存在奖励破解问题，且推理过程标注成本高。方法：提出分层奖励模型（HRM），在细粒度和粗粒度层面评估推理步骤，还引入分层节点压缩（HNC）数据增强策略。效果：在PRM800K数据集上，HRM与HNC结合比PRM评估更稳定可靠；在MATH500和GSM8K数据集的跨领域评估中，HRM在多种推理任务上展现出强泛化性和鲁棒性。
            arXiv:2503.13551v3 Announce Type: replace 
Abstract: Recent studies show that Large Language Models (LLMs) achieve strong reasoning capabilities through supervised fine-tuning or reinforcement learning. However, a key approach, the Process Reward Model (PRM), suffers from reward hacking, making it unreliable in identifying the best intermediate step. In addition, the cost of annotating reasoning processes for reward modeling is high, making large-scale collection of high-quality data challenging. To address this, we propose a novel reward model approach called the Hierarchical Reward Model (HRM), which evaluates both individual and consecutive reasoning steps at both fine-grained and coarse-grained levels. HRM excels at assessing multi-step reasoning coherence, especially when flawed steps are later corrected through self-reflection. To further reduce the cost of generating training data, we introduce a lightweight and effective data augmentation strategy called Hierarchical Node Compression (HNC), which merges two consecutive reasoning steps into one within the tree structure. By applying HNC to MCTS-generated reasoning trajectories, we enhance the diversity and robustness of HRM training data while introducing controlled noise with minimal computational overhead. Empirical results on the PRM800K dataset show that HRM, together with HNC, provides more stable and reliable evaluations than PRM. Furthermore, cross-domain evaluations on the MATH500 and GSM8K datasets demonstrate HRM's strong generalization and robustness across a variety of reasoning tasks.
        ]]></description>
    </item>
    <item>
        <title>Dynamic Parametric Retrieval Augmented Generation for Test-time Knowledge Enhancement</title>
        <link>https://arxiv.org/abs/2503.23895</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.23895v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuqiao Tan, Shizhu He, Huanxuan Liao, Jun Zhao, Kang Liu</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）能提升大语言模型，但增加推理成本且存在幻觉问题，参数化RAG（PRAG）虽可减少推理成本，但训练和存储成本高、泛化能力有限。方法：提出动态参数化RAG（DyPRAG）框架，利用轻量级参数转换模型将文档高效转化为参数知识。效果：能降低推理、训练和存储成本，动态生成参数知识，解决知识冲突。多数据集实验证明其有效性和泛化能力，可实现更好知识融合，减轻幻觉问题。
            arXiv:2503.23895v4 Announce Type: replace 
Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs) by retrieving relevant documents from external sources and incorporating them into the context. While it improves reliability by providing factual texts, it significantly increases inference costs as context length grows and introduces challenging issue of RAG hallucination, primarily caused by the lack of corresponding parametric knowledge in LLMs. An efficient solution is to enhance the knowledge of LLMs at test-time. Parametric RAG (PRAG) addresses this by embedding document into LLMs parameters to perform test-time knowledge enhancement, effectively reducing inference costs through offline training. However, its high training and storage costs, along with limited generalization ability, significantly restrict its practical adoption. To address these challenges, we propose Dynamic Parametric RAG (DyPRAG), a novel framework that leverages a lightweight parameter translator model to efficiently convert documents into parametric knowledge. DyPRAG not only reduces inference, training, and storage costs but also dynamically generates parametric knowledge, seamlessly enhancing the knowledge of LLMs and resolving knowledge conflicts in a plug-and-play manner at test-time. Extensive experiments on multiple datasets demonstrate the effectiveness and generalization capabilities of DyPRAG, offering a powerful and practical RAG paradigm which enables superior knowledge fusion and mitigates RAG hallucination in real-world applications. Our code is available at https://github.com/Trae1ounG/DyPRAG.
        ]]></description>
    </item>
    <item>
        <title>LGIN: Defining an Approximately Powerful Hyperbolic GNN</title>
        <link>https://arxiv.org/abs/2504.00142</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.00142v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Srinitish Srinivasan, Omkumar CU</dc:creator>
        <description><![CDATA[
            背景：双曲空间的图神经网络在处理层次和复杂关系数据有潜力，但判别能力可能有限。方法：提出Lorentzian Graph Isomorphic Network (LGIN)，设计新的更新规则，结合局部邻域信息和图结构的丰富表示，保留Lorentzian度量张量。效果：在九个基准数据集上评估，LGIN表现优于或媲美现有双曲和欧几里得GNN，能有效捕捉复杂图结构、区分不同图，是首个研究双曲空间强大GNN框架的工作。
            arXiv:2504.00142v3 Announce Type: replace 
Abstract: While graph neural networks (GNNs) operating in hyperbolic spaces have shown promise for modeling hierarchical and complex relational data, a critical limitation often overlooked is their potentially limited discriminative power compared to their Euclidean counterparts or fundamental graph isomorphism tests like the Weisfeiler-Lehman (WL) hierarchy. Existing hyperbolic aggregation schemes, while curvature-aware, may not sufficiently capture the intricate structural differences required to robustly distinguish non-isomorphic graphs owing to non-injective aggregation functions. To address this expressiveness gap in hyperbolic graph learning, we introduce the Lorentzian Graph Isomorphic Network (LGIN), a novel GNN designed to achieve enhanced discriminative capabilities within the Lorentzian model of hyperbolic space. LGIN proposes a new update rule that effectively combines local neighborhood information with a richer representation of graph structure designed to preserve the Lorentzian metric tensor. This represents a significant step towards building more expressive GNNs in non-Euclidean geometries, overcoming a common bottleneck in current hyperbolic methods. We conduct extensive evaluations across nine diverse benchmark datasets, including molecular and protein structures. LGIN consistently outperforms or matches state-of-the-art hyperbolic and Euclidean GNNs, showcasing its practical efficacy and validating its superior ability to capture complex graph structures and distinguish between different graphs. To the best of our knowledge, LGIN is the first work to study the framework behind a powerful GNN on the hyperbolic space. The code for our paper can be found at https://github.com/Deceptrax123/LGIN
        ]]></description>
    </item>
    <item>
        <title>SEAL: Steerable Reasoning Calibration of Large Language Models for Free</title>
        <link>https://arxiv.org/abs/2504.07986</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.07986v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Runjin Chen, Zhenyu Zhang, Junyuan Hong, Souvik Kundu, Zhangyang Wang</dc:creator>
        <description><![CDATA[
            背景：大语言模型通过扩展思维链推理机制处理复杂推理任务，但思维链推理轨迹存在大量冗余，增加推理延迟且影响性能。方法：研究大语言模型内部推理结构，分为执行、反思和过渡三种思维类型，提出无训练方法SEAL，先离线提取潜在空间推理引导向量，再用其对推理轨迹进行动态校准。效果：在多模型和基准测试中验证有效，准确率最高提升11%，推理令牌减少11.8% - 50.4%。
            arXiv:2504.07986v2 Announce Type: replace 
Abstract: Large Language Models (LLMs), such as OpenAI's o1-series have demonstrated compelling capabilities for complex reasoning tasks via the extended chain-of-thought (CoT) reasoning mechanism. However, recent studies reveal substantial redundancy in the CoT reasoning traces, which not only increases inference latency but also negatively impacts model performance by diverting attention to unnecessary reasoning paths. To address this issue, we investigate the internal reasoning structures of LLMs and categorize them into three primary thought types: execution, reflection, and transition thoughts. Moreover, our analysis reveals that excessive reflection and transition thoughts are strongly correlated with failure cases and these thought categories exhibit clear separation in the latent space. Based on these, we introduce SEAL (Steerable reasoning calibration), a training-free approach that seamlessly calibrates the CoT process, improving accuracy while demonstrating significant efficiency gains. SEAL consists of an offline stage for extracting the reasoning steering vector in the latent space, followed by an on-the-fly calibration of the reasoning trace through representation intervention using the steering vector. Notably, the steering vector exhibits strong transferability across various tasks. Extensive experiments across multiple models (DeepSeek-R1-Distill and QwQ-32B-Preview) and benchmarks (Math500, GSM8K, LiveCodeBench) validate the effectiveness of SEAL, up to a 11% improvement in accuracy while reducing reasoning tokens by 11.8% to 50.4%. Our code is publicly available at https://github.com/VITA-Group/SEAL.
        ]]></description>
    </item>
    <item>
        <title>Chain-of-Thought Textual Reasoning for Few-shot Temporal Action Localization</title>
        <link>https://arxiv.org/abs/2504.13460</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.13460v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hongwei Ji, Wulian Yun, Mengshi Qi, Huadong Ma</dc:creator>
        <description><![CDATA[
            传统时序动作定位（TAL）依赖大量标注数据，少样本TAL虽减少依赖，但现有方法多只关注视频信息，忽略文本信息。为此，提出基于思维链文本推理的少样本TAL方法。设计了利用文本语义信息的少样本学习框架，含语义感知的文本 - 视觉对齐模块；还设计类思维链推理方法，引导模型生成视频文本描述。在多个数据集实验，结果显示该方法在单实例和多实例场景均显著优于现有方法，后续将开源代码、数据和基准。
            arXiv:2504.13460v3 Announce Type: replace 
Abstract: Traditional temporal action localization (TAL) methods rely on large amounts of detailed annotated data, whereas few-shot TAL reduces this dependence by using only a few training samples to identify unseen action categories. However, existing few-shot TAL methods typically focus solely on video-level information, neglecting textual information, which can provide valuable semantic support for the localization task. Therefore, we propose a new few-shot temporal action localization method by Chain-of-Thought textual reasoning to improve localization performance. Specifically, we design a novel few-shot learning framework that leverages textual semantic information to enhance the model's ability to capture action commonalities and variations, which includes a semantic-aware text-visual alignment module designed to align the query and support videos at different levels. Meanwhile, to better express the temporal dependencies and causal relationships between actions at the textual level to assist action localization, we design a Chain of Thought (CoT)-like reasoning method that progressively guides the Vision Language Model (VLM) and Large Language Model (LLM) to generate CoT-like text descriptions for videos. The generated texts can capture more variance of action than visual features. We conduct extensive experiments on the publicly available ActivityNet1.3 and THUMOS14 datasets. We introduce the first dataset named Human-related Anomaly Localization and explore the application of the TAL task in human anomaly detection. The experimental results demonstrate that our proposed method significantly outperforms existing methods in single-instance and multi-instance scenarios. We will release our code, data and benchmark.
        ]]></description>
    </item>
    <item>
        <title>ABG-NAS: Adaptive Bayesian Genetic Neural Architecture Search for Graph Representation Learning</title>
        <link>https://arxiv.org/abs/2504.21254</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.21254v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sixuan Wang, Jiao Yin, Jinli Cao, MingJian Tang, Hua Wang, Yanchun Zhang</dc:creator>
        <description><![CDATA[
            背景：现有图神经网络架构难以适应复杂图结构，限制其生成结构感知和任务区分性表征的能力。方法：提出ABG - NAS框架，包含综合架构搜索空间、自适应遗传优化策略和贝叶斯引导调优模块，系统探索传播和转换操作，平衡搜索的探索与利用，并优化超参数。效果：在多个基准数据集上，ABG - NAS始终优于手动设计的GNN和现有神经架构搜索方法，为不同图结构提供可扩展和自适应的解决方案。
            arXiv:2504.21254v2 Announce Type: replace 
Abstract: Effective and efficient graph representation learning is essential for enabling critical downstream tasks, such as node classification, link prediction, and subgraph search. However, existing graph neural network (GNN) architectures often struggle to adapt to diverse and complex graph structures, limiting their ability to produce structure-aware and task-discriminative representations. To address this challenge, we propose ABG-NAS, a novel framework for automated graph neural network architecture search tailored for efficient graph representation learning. ABG-NAS encompasses three key components: a Comprehensive Architecture Search Space (CASS), an Adaptive Genetic Optimization Strategy (AGOS), and a Bayesian-Guided Tuning Module (BGTM). CASS systematically explores diverse propagation (P) and transformation (T) operations, enabling the discovery of GNN architectures capable of capturing intricate graph characteristics. AGOS dynamically balances exploration and exploitation, ensuring search efficiency and preserving solution diversity. BGTM further optimizes hyperparameters periodically, enhancing the scalability and robustness of the resulting architectures. Empirical evaluations on benchmark datasets (Cora, PubMed, Citeseer, and CoraFull) demonstrate that ABG-NAS consistently outperforms both manually designed GNNs and state-of-the-art neural architecture search (NAS) methods. These results highlight the potential of ABG-NAS to advance graph representation learning by providing scalable and adaptive solutions for diverse graph structures. Our code is publicly available at https://github.com/sserranw/ABG-NAS.
        ]]></description>
    </item>
    <item>
        <title>How Transformers Learn Regular Language Recognition: A Theoretical Study on Training Dynamics and Implicit Bias</title>
        <link>https://arxiv.org/abs/2505.00926</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.00926v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ruiquan Huang, Yingbin Liang, Jing Yang</dc:creator>
        <description><![CDATA[
            语言识别任务对评估大语言模型性能及解释Transformer机制至关重要。本文聚焦“偶数对”和“奇偶校验”这两个正则语言识别任务，旨在理论分析单层Transformer在梯度下降下的训练动态，探究其如何学习解决这些任务。对于“偶数对”可直接求解，“奇偶校验”需结合思维链。分析表明，注意力层和线性层联合训练分两阶段：先注意力层快速增长映射序列为可分向量，后线性层对数增长并逼近最大间隔超平面，损失以$O(1/t)$速率下降。实验验证了理论结果。
            arXiv:2505.00926v2 Announce Type: replace 
Abstract: Language recognition tasks are fundamental in natural language processing (NLP) and have been widely used to benchmark the performance of large language models (LLMs). These tasks also play a crucial role in explaining the working mechanisms of transformers. In this work, we focus on two representative tasks in the category of regular language recognition, known as `even pairs' and `parity check', the aim of which is to determine whether the occurrences of certain subsequences in a given sequence are even. Our goal is to explore how a one-layer transformer, consisting of an attention layer followed by a linear layer, learns to solve these tasks by theoretically analyzing its training dynamics under gradient descent. While even pairs can be solved directly by a one-layer transformer, parity check need to be solved by integrating Chain-of-Thought (CoT), either into the inference stage of a transformer well-trained for the even pairs task, or into the training of a one-layer transformer. For both problems, our analysis shows that the joint training of attention and linear layers exhibits two distinct phases. In the first phase, the attention layer grows rapidly, mapping data sequences into separable vectors. In the second phase, the attention layer becomes stable, while the linear layer grows logarithmically and approaches in direction to a max-margin hyperplane that correctly separates the attention layer outputs into positive and negative samples, and the loss decreases at a rate of $O(1/t)$. Our experiments validate those theoretical results.
        ]]></description>
    </item>
    <item>
        <title>Efficient Multivariate Time Series Forecasting via Calibrated Language Models with Privileged Knowledge Distillation</title>
        <link>https://arxiv.org/abs/2505.02138</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.02138v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chenxi Liu, Hao Miao, Qianxiong Xu, Shaowen Zhou, Cheng Long, Yan Zhao, Ziyue Li, Rui Zhao</dc:creator>
        <description><![CDATA[
            背景：多变量时间序列预测（MTSF）在时间序列数据管理系统中至关重要，虽有研究用文本提示调优将大语言模型（LLMs）知识融入MTSF，但LLMs推理效率低。方法：提出TimeKD框架，利用校准语言模型和特权知识蒸馏，通过跨模态教师模型生成高质量未来表征，设计减法交叉注意力机制细化表征；采用创新特权知识蒸馏机制培养有效学生模型。效果：真实数据实验表明TimeKD有效、高效且可扩展。
            arXiv:2505.02138v2 Announce Type: replace 
Abstract: Multivariate time series forecasting (MTSF) endeavors to predict future observations given historical data, playing a crucial role in time series data management systems. With advancements in large language models (LLMs), recent studies employ textual prompt tuning to infuse the knowledge of LLMs into MTSF. However, the deployment of LLMs often suffers from low efficiency during the inference phase. To address this problem, we introduce TimeKD, an efficient MTSF framework that leverages the calibrated language models and privileged knowledge distillation. TimeKD aims to generate high-quality future representations from the proposed cross-modality teacher model and cultivate an effective student model. The cross-modality teacher model adopts calibrated language models (CLMs) with ground truth prompts, motivated by the paradigm of Learning Under Privileged Information (LUPI). In addition, we design a subtractive cross attention (SCA) mechanism to refine these representations. To cultivate an effective student model, we propose an innovative privileged knowledge distillation (PKD) mechanism including correlation and feature distillation. PKD enables the student to replicate the teacher's behavior while minimizing their output discrepancy. Extensive experiments on real data offer insight into the effectiveness, efficiency, and scalability of the proposed TimeKD.
        ]]></description>
    </item>
    <item>
        <title>A Note on Statistically Accurate Tabular Data Generation Using Large Language Models</title>
        <link>https://arxiv.org/abs/2505.02659</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.02659v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Andrey Sidorenko</dc:creator>
        <description><![CDATA[
            背景：大语言模型在合成表格数据生成方面有潜力，但现有方法难以保留复杂特征依赖，尤其是分类变量间的依赖。方法：提出一种概率驱动的提示方法，利用大语言模型估计条件分布，实现更准确和可扩展的数据合成。效果：结果显示，通过提示概率分布，可提高大语言模型生成表格数据的统计保真度，有望解决现有方法在保留特征依赖方面的难题。
            arXiv:2505.02659v2 Announce Type: replace 
Abstract: Large language models (LLMs) have shown promise in synthetic tabular data generation, yet existing methods struggle to preserve complex feature dependencies, particularly among categorical variables. This work introduces a probability-driven prompting approach that leverages LLMs to estimate conditional distributions, enabling more accurate and scalable data synthesis. The results highlight the potential of prompting probability distributions to enhance the statistical fidelity of LLM-generated tabular data.
        ]]></description>
    </item>
    <item>
        <title>Knowledge Graphs for Enhancing Large Language Models in Entity Disambiguation</title>
        <link>https://arxiv.org/abs/2505.02737</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.02737v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Gerard Pons, Besim Bilalli, Anna Queralt</dc:creator>
        <description><![CDATA[
            背景：大语言模型（LLMs）在自然语言处理任务中表现突出，但存在幻觉、知识过时等问题，重新训练成本高。方法：使用知识图谱（KGs）作为结构化外部信息源增强LLMs进行零样本实体消歧（ED），利用KG中实体类的层次表示逐步缩小候选空间，用实体描述丰富输入提示。效果：在流行ED数据集上，该方法优于未增强和仅用描述增强的LLMs，比特定任务模型适应性更强。
            arXiv:2505.02737v2 Announce Type: replace 
Abstract: Recent advances in Large Language Models (LLMs) have positioned them as a prominent solution for Natural Language Processing tasks. Notably, they can approach these problems in a zero or few-shot manner, thereby eliminating the need for training or fine-tuning task-specific models. However, LLMs face some challenges, including hallucination and the presence of outdated knowledge or missing information from specific domains in the training data. These problems cannot be easily solved by retraining the models with new data as it is a time-consuming and expensive process. To mitigate these issues, Knowledge Graphs (KGs) have been proposed as a structured external source of information to enrich LLMs. With this idea, in this work we use KGs to enhance LLMs for zero-shot Entity Disambiguation (ED). For that purpose, we leverage the hierarchical representation of the entities' classes in a KG to gradually prune the candidate space as well as the entities' descriptions to enrich the input prompt with additional factual knowledge. Our evaluation on popular ED datasets shows that the proposed method outperforms non-enhanced and description-only enhanced LLMs, and has a higher degree of adaptability than task-specific models. Furthermore, we conduct an error analysis and discuss the impact of the leveraged KG's semantic expressivity on the ED performance.
        ]]></description>
    </item>
    <item>
        <title>MAMMAL -- Molecular Aligned Multi-Modal Architecture and Language</title>
        <link>https://arxiv.org/abs/2410.22367</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.22367v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yoel Shoshan, Moshiko Raboh, Michal Ozery-Flato, Vadim Ratner, Alex Golts, Jeffrey K. Weber, Ella Barkan, Simona Rabinovici-Cohen, Sagi Polaczek, Ido Amos, Ben Shapira, Liam Hazan, Matan Ninio, Sivan Ravid, Michael M. Danziger, Yosi Shamay, Sharon Kurant, Joseph A. Morrone, Parthasarathy Suryanarayanan, Michal Rosen-Zvi, Efrat Hexter</dc:creator>
        <description><![CDATA[
            背景：当前大语言模型在生物数据集应用中常孤立训练，难以捕捉复杂多模态交互，有效药物发现需整合多生物实体的计算工具。方法：提出MAMMAL，是一种通用方法，用于创建多任务基础模型，从蛋白质、小分子和组学等多模态大规模生物数据集学习，其结构化提示语法支持多种任务。效果：在十一项下游任务评估中，九项达新的最优水平，两项与最优相当；在抗体 - 抗原等复合物结合预测上，多数目标分类性能更佳。
            arXiv:2410.22367v3 Announce Type: replace-cross 
Abstract: Large language models applied to vast biological datasets have the potential to transform biology by uncovering disease mechanisms and accelerating drug development. However, current models are often siloed, trained separately on small-molecules, proteins, or transcriptomic data, limiting their ability to capture complex, multi-modal interactions. Effective drug discovery requires computational tools that integrate multiple biological entities while supporting prediction and generation, a challenge existing models struggle to address. For this purpose, we present MAMMAL - Molecular Aligned Multi-Modal Architecture and Language - a versatile method applied to create a multi-task foundation model that learns from large-scale biological datasets across diverse modalities, including proteins, small-molecules, and omics. MAMMAL's structured prompt syntax supports classification, regression, and generation tasks while handling token and scalar inputs and outputs. Evaluated on eleven diverse downstream tasks, it reaches a new state of the art (SOTA) in nine tasks and is comparable to SOTA in two tasks, all within a unified architecture, unlike prior task-specific models. Additionally, we explored Alphafold 3 binding prediction capabilities on antibody-antigen and nanobody-antigen complexes showing significantly better classification performance of MAMMAL in 3 out of 4 targets. The model code and pretrained weights are publicly available at https://github.com/BiomedSciAI/biomed-multi-alignment and https://huggingface.co/ibm/biomed.omics.bl.sm.ma-ted-458m
        ]]></description>
    </item>
    <item>
        <title>Synergizing Large Language Models and Task-specific Models for Time Series Anomaly Detection</title>
        <link>https://arxiv.org/abs/2501.05675</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2501.05675v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Feiyi Chen, Leilei Zhang, Guansong Pang, Roger Zimmermann, Shuiguang Deng</dc:creator>
        <description><![CDATA[
            背景：在异常检测中，大语言模型（LLMs）能读取专业文档融入专家知识，特定任务小模型擅长从目标应用训练数据中提取正常数据模式和检测值波动。方法：提出CoLLaTe框架，促进LLMs与特定任务模型协作，针对协作中表达域不对齐和误差累积问题，引入模型对齐模块和协作损失函数。效果：经理论分析和实验验证，该框架有效缓解问题，性能优于基于LLMs和特定任务的模型。 
            arXiv:2501.05675v4 Announce Type: replace-cross 
Abstract: In anomaly detection, methods based on large language models (LLMs) can incorporate expert knowledge by reading professional document, while task-specific small models excel at extracting normal data patterns and detecting value fluctuations from training data of target applications. Inspired by the human nervous system, where the brain stores expert knowledge and the peripheral nervous system and spinal cord handle specific tasks like withdrawal and knee-jerk reflexes, we propose CoLLaTe, a framework designed to facilitate collaboration between LLMs and task-specific models, leveraging the strengths of both models for anomaly detection.
  In particular, we first formulate the collaboration process and identify two key challenges in the collaboration:
  (1) the misalignment between the expression domains of the LLMs and task-specific small models, and (2) error accumulation arising from the predictions of both models.
  To address these challenges, we then introduce two key components in CoLLaTe: a model alignment module and a collaborative loss function. Through theoretical analysis and experimental validation, we demonstrate that these components effectively mitigate the identified challenges and achieve better performance than both LLM-based and task-specific models.
        ]]></description>
    </item>
    <item>
        <title>A Multi-Granularity Retrieval Framework for Visually-Rich Documents</title>
        <link>https://arxiv.org/abs/2505.01457</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.01457v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mingjun Xu, Zehui Wang, Hengxing Cai, Renxin Zhong</dc:creator>
        <description><![CDATA[
            背景：现有检索增强生成（RAG）系统主要关注文本检索，处理包含文本、图像等的富视觉文档能力有限。方法：提出统一的多粒度多模态检索框架，集成分层编码策略、模态感知检索机制和基于视觉语言模型（VLM）的候选过滤，利用现成VLM并采用免训练混合检索策略。效果：实验表明，结合布局感知搜索和VLM候选验证显著提高检索准确率，最高得分达65.56 。
            arXiv:2505.01457v2 Announce Type: replace-cross 
Abstract: Retrieval-augmented generation (RAG) systems have predominantly focused on text-based retrieval, limiting their effectiveness in handling visually-rich documents that encompass text, images, tables, and charts. To bridge this gap, we propose a unified multi-granularity multimodal retrieval framework tailored for two benchmark tasks: MMDocIR and M2KR. Our approach integrates hierarchical encoding strategies, modality-aware retrieval mechanisms, and vision-language model (VLM)-based candidate filtering to effectively capture and utilize the complex interdependencies between textual and visual modalities. By leveraging off-the-shelf vision-language models and implementing a training-free hybrid retrieval strategy, our framework demonstrates robust performance without the need for task-specific fine-tuning. Experimental evaluations reveal that incorporating layout-aware search and VLM-based candidate verification significantly enhances retrieval accuracy, achieving a top performance score of 65.56. This work underscores the potential of scalable and reproducible solutions in advancing multimodal document retrieval systems.
        ]]></description>
    </item>
    <item>
        <title>The Search for Squawk: Agile Modeling in Bioacoustics</title>
        <link>https://arxiv.org/abs/2505.03071</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.03071v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Vincent Dumoulin, Otilia Stretcu, Jenny Hamer, Lauren Harrell, Rob Laber, Hugo Larochelle, Bart van Merri\"enboer, Amanda Navine, Patrick Hart, Ben Williams, Timothy A. C. Lamont, Tries B. Rasak, Mars Coral Restoration Team, Sheryn Brodie, Brendan Doohan, Phil Eichinski, Paul Roe, Lin Schwarzkopf, Tom Denton</dc:creator>
        <description><![CDATA[
            背景：被动声学监测对生态学意义重大，但从大量音频中提取信息需开发专业识别器，且任务具挑战性。方法：提出通用、可扩展且数据高效的系统，包含预训练的声学嵌入减少数据需求、索引音频搜索高效创建训练集、预计算嵌入实现高效主动学习循环。效果：生态学家将其用于三个案例研究，模拟实验也表明系统具可扩展性、高效性和通用性，能让科学家快速应对新的生物声学挑战。
            arXiv:2505.03071v1 Announce Type: new 
Abstract: Passive acoustic monitoring (PAM) has shown great promise in helping ecologists understand the health of animal populations and ecosystems. However, extracting insights from millions of hours of audio recordings requires the development of specialized recognizers. This is typically a challenging task, necessitating large amounts of training data and machine learning expertise. In this work, we introduce a general, scalable and data-efficient system for developing recognizers for novel bioacoustic problems in under an hour. Our system consists of several key components that tackle problems in previous bioacoustic workflows: 1) highly generalizable acoustic embeddings pre-trained for birdsong classification minimize data hunger; 2) indexed audio search allows the efficient creation of classifier training datasets, and 3) precomputation of embeddings enables an efficient active learning loop, improving classifier quality iteratively with minimal wait time. Ecologists employed our system in three novel case studies: analyzing coral reef health through unidentified sounds; identifying juvenile Hawaiian bird calls to quantify breeding success and improve endangered species monitoring; and Christmas Island bird occupancy modeling. We augment the case studies with simulated experiments which explore the range of design decisions in a structured way and help establish best practices. Altogether these experiments showcase our system's scalability, efficiency, and generalizability, enabling scientists to quickly address new bioacoustic challenges.
        ]]></description>
    </item>
    <item>
        <title>SonicRAG : High Fidelity Sound Effects Synthesis Based on Retrival Augmented Generation</title>
        <link>https://arxiv.org/abs/2505.03244</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.03244v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yu-Ren Guo, Wen-Kai Tai</dc:creator>
        <description><![CDATA[
            背景：大语言模型（LLMs）在自然语言处理和多模态学习中表现出色，但因标注数据集稀缺和时间建模复杂，当前音效生成技术难以实现高保真音频。方法：本文提出将LLMs与现有音效数据库集成的新框架，可根据用户需求检索、重组和合成音频。效果：提升了生成音效的多样性和质量，无需额外录制成本，为声音设计和应用提供了灵活高效的解决方案。
            arXiv:2505.03244v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language processing (NLP) and multimodal learning, with successful applications in text generation and speech synthesis, enabling a deeper understanding and generation of multimodal content. In the field of sound effects (SFX) generation, LLMs have been leveraged to orchestrate multiple models for audio synthesis. However, due to the scarcity of annotated datasets, and the complexity of temproal modeling. current SFX generation techniques still fall short in achieving high-fidelity audio. To address these limitations, this paper introduces a novel framework that integrates LLMs with existing sound effect databases, allowing for the retrieval, recombination, and synthesis of audio based on user requirements. By leveraging this approach, we enhance the diversity and quality of generated sound effects while eliminating the need for additional recording costs, offering a flexible and efficient solution for sound design and application.
        ]]></description>
    </item>
    <item>
        <title>SepALM: Audio Language Models Are Error Correctors for Robust Speech Separation</title>
        <link>https://arxiv.org/abs/2505.03273</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.03273v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhaoxi Mu, Xinyu Yang, Gang Wang</dc:creator>
        <description><![CDATA[
            背景：现有语音分离技术处理真实环境复杂音频时，分离语音易出现伪影或失真。方法：提出SepALM，利用音频语言模型在初步分离后于文本域纠正和重新合成语音，包含分离器、校正器、合成器和对齐器四个核心组件，集成基于ALM的端到端纠错机制，还开发了思维链提示和知识蒸馏技术。效果：实验表明，SepALM提高了语音分离精度，显著增强了在新声学环境中的适应性。
            arXiv:2505.03273v1 Announce Type: new 
Abstract: While contemporary speech separation technologies adeptly process lengthy mixed audio waveforms, they are frequently challenged by the intricacies of real-world environments, including noisy and reverberant settings, which can result in artifacts or distortions in the separated speech. To overcome these limitations, we introduce SepALM, a pioneering approach that employs audio language models (ALMs) to rectify and re-synthesize speech within the text domain following preliminary separation. SepALM comprises four core components: a separator, a corrector, a synthesizer, and an aligner. By integrating an ALM-based end-to-end error correction mechanism, we mitigate the risk of error accumulation and circumvent the optimization hurdles typically encountered in conventional methods that amalgamate automatic speech recognition (ASR) with large language models (LLMs). Additionally, we have developed Chain-of-Thought (CoT) prompting and knowledge distillation techniques to facilitate the reasoning and training processes of the ALM. Our experiments substantiate that SepALM not only elevates the precision of speech separation but also markedly bolsters adaptability in novel acoustic environments.
        ]]></description>
    </item>
    <item>
        <title>The Inverse Drum Machine: Source Separation Through Joint Transcription and Analysis-by-Synthesis</title>
        <link>https://arxiv.org/abs/2505.03337</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.03337v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Bernardo Torres (S2A, IDS), Geoffroy Peeters (S2A, IDS), Gael Richard (S2A, IDS)</dc:creator>
        <description><![CDATA[
            背景：现有鼓源分离的监督方法依赖孤立音轨，本文提出新方法Inverse Drum Machine（IDM）。方法：结合合成分析与深度学习，仅需转录注释，在端到端框架中联合优化自动鼓转录和单样本鼓合成，通过卷积合成样本与估计起始点重构鼓音轨，并训练神经网络匹配原始混音。效果：在StemGMD数据集上，分离性能与最先进的监督方法相当，大幅超越矩阵分解基线。
            arXiv:2505.03337v1 Announce Type: new 
Abstract: We introduce the Inverse Drum Machine (IDM), a novel approach to drum source separation that combines analysis-by-synthesis with deep learning. Unlike recent supervised methods that rely on isolated stems, IDM requires only transcription annotations. It jointly optimizes automatic drum transcription and one-shot drum sample synthesis in an end-to-end framework. By convolving synthesized one-shot samples with estimated onsets-mimicking a drum machine-IDM reconstructs individual drum stems and trains a neural network to match the original mixture. Evaluations on the StemGMD dataset show that IDM achieves separation performance on par with state-of-the-art supervised methods, while substantially outperforming matrix decomposition baselines.
        ]]></description>
    </item>
    <item>
        <title>BLAB: Brutally Long Audio Bench</title>
        <link>https://arxiv.org/abs/2505.03054</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.03054v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Orevaoghene Ahia, Martijn Bartelds, Kabir Ahuja, Hila Gonen, Valentin Hofmann, Siddhant Arora, Shuyue Stella Li, Vishal Puttagunta, Mofetoluwa Adeyemi, Charishma Buchireddy, Ben Walls, Noah Bennett, Shinji Watanabe, Noah A. Smith, Yulia Tsvetkov, Sachin Kumar</dc:creator>
        <description><![CDATA[
            背景：现有音频大语言模型多在短音频上评估，对长对话语音探索有限。方法：提出Brutally Long Audio Bench（BLAB），用平均时长51分钟的音频评估模型的定位、时长估计等任务，数据集含833 + 小时音频及对应问答，数据经人工筛选。效果：评估六个开源和专有音频大语言模型，发现包括Gemini 2.0 Pro和GPT - 4o等先进模型在BLAB任务中表现不佳，性能随音频时长增加而下降。
            arXiv:2505.03054v1 Announce Type: cross 
Abstract: Developing large audio language models (LMs) capable of understanding diverse spoken interactions is essential for accommodating the multimodal nature of human communication and can increase the accessibility of language technologies across different user populations. Recent work on audio LMs has primarily evaluated their performance on short audio segments, typically under 30 seconds, with limited exploration of long-form conversational speech segments that more closely reflect natural user interactions with these models. We introduce Brutally Long Audio Bench (BLAB), a challenging long-form audio benchmark that evaluates audio LMs on localization, duration estimation, emotion, and counting tasks using audio segments averaging 51 minutes in length. BLAB consists of 833+ hours of diverse, full-length audio clips, each paired with human-annotated, text-based natural language questions and answers. Our audio data were collected from permissively licensed sources and underwent a human-assisted filtering process to ensure task compliance. We evaluate six open-source and proprietary audio LMs on BLAB and find that all of them, including advanced models such as Gemini 2.0 Pro and GPT-4o, struggle with the tasks in BLAB. Our comprehensive analysis reveals key insights into the trade-offs between task difficulty and audio duration. In general, we find that audio LMs struggle with long-form speech, with performance declining as duration increases. They perform poorly on localization, temporal reasoning, counting, and struggle to understand non-phonemic information, relying more on prompts than audio content. BLAB serves as a challenging evaluation framework to develop audio LMs with robust long-form audio understanding capabilities.
        ]]></description>
    </item>
    <item>
        <title>AudioBench: A Universal Benchmark for Audio Large Language Models</title>
        <link>https://arxiv.org/abs/2406.16020</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2406.16020v5</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Bin Wang, Xunlong Zou, Geyu Lin, Shuo Sun, Zhuohan Liu, Wenyu Zhang, Zhengyuan Liu, AiTi Aw, Nancy F. Chen</dc:creator>
        <description><![CDATA[
            背景：目前缺乏对音频大语言模型（AudioLLMs）基于音频信号指令跟随能力的综合评估基准。方法：提出通用基准AudioBench，涵盖8个不同任务和26个数据集（7个为新提出），从语音理解、音频场景理解和语音理解（副语言）三方面评估。还评估了5个流行模型。效果：发现没有一个模型能在所有任务中始终表现出色。该基准为未来模型发展提供有力测试平台。
            arXiv:2406.16020v5 Announce Type: replace 
Abstract: We introduce AudioBench, a universal benchmark designed to evaluate Audio Large Language Models (AudioLLMs). It encompasses 8 distinct tasks and 26 datasets, among which, 7 are newly proposed datasets. The evaluation targets three main aspects: speech understanding, audio scene understanding, and voice understanding (paralinguistic). Despite recent advancements, there lacks a comprehensive benchmark for AudioLLMs on instruction following capabilities conditioned on audio signals. AudioBench addresses this gap by setting up datasets as well as desired evaluation metrics. Besides, we also evaluated the capabilities of five popular models and found that no single model excels consistently across all tasks. We outline the research outlook for AudioLLMs and anticipate that our open-sourced evaluation toolkit, data, and leaderboard will offer a robust testbed for future model developments.
        ]]></description>
    </item>
    <item>
        <title>Music for All: Representational Bias and Cross-Cultural Adaptability of Music Generation Models</title>
        <link>https://arxiv.org/abs/2502.07328</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.07328v3</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Atharva Mehta, Shivam Chauhan, Amirbek Djanibekov, Atharva Kulkarni, Gus Xia, Monojit Choudhury</dc:creator>
        <description><![CDATA[
            背景：音乐语言模型提升了AI音乐生成能力，但在覆盖全球音乐类型和文化方面存在局限。方法：研究音乐生成数据集和论文，量化音乐类型的偏差和代表性不足问题，探究参数高效微调（PEFT）技术减轻偏差的效果。效果：现有音乐数据集仅5.7%时长来自非西方音乐类型，导致模型跨类型表现差异大；对MusicGen和Mustango两个模型在印度古典音乐和土耳其马卡姆音乐上实验，凸显小数据集跨类型适配的潜力与挑战。
            arXiv:2502.07328v3 Announce Type: replace 
Abstract: The advent of Music-Language Models has greatly enhanced the automatic music generation capability of AI systems, but they are also limited in their coverage of the musical genres and cultures of the world. We present a study of the datasets and research papers for music generation and quantify the bias and under-representation of genres. We find that only 5.7% of the total hours of existing music datasets come from non-Western genres, which naturally leads to disparate performance of the models across genres. We then investigate the efficacy of Parameter-Efficient Fine-Tuning (PEFT) techniques in mitigating this bias. Our experiments with two popular models -- MusicGen and Mustango, for two underrepresented non-Western music traditions -- Hindustani Classical and Turkish Makam music, highlight the promises as well as the non-triviality of cross-genre adaptation of music through small datasets, implying the need for more equitable baseline music-language models that are designed for cross-cultural transfer learning.
        ]]></description>
    </item>
</channel>
</rss>