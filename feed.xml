<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
<channel>
    <title>arXiv Paper Filter</title>
    <link>https://github.com/None/arxiv_filter</link>
    <description>根据研究兴趣筛选的arXiv论文</description>
    <atom:link href="https://raw.githubusercontent.com/None/arxiv_filter/main/feed.xml" rel="self" type="application/rss+xml" />
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>zh-CN</language>
    <lastBuildDate>Mon, 14 Jul 2025 12:45:38 +0800</lastBuildDate>
    <managingEditor>None@github.com</managingEditor>
    <pubDate>Mon, 14 Jul 2025 12:45:38 +0800</pubDate>
    <skipDays>
        <day>Saturday</day>
        <day>Sunday</day>
    </skipDays>

    <item>
        <title>PUMA: Layer-Pruned Language Model for Efficient Unified Multimodal Retrieval with Modality-Adaptive Learning</title>
        <link>https://arxiv.org/abs/2507.08064</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.08064v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yibo Lyu, Rui Shao, Gongwei Chen, Yijie Zhu, Weili Guan, Liqiang Nie</dc:creator>
        <description><![CDATA[
            随着多媒体内容增多，现实应用对统一多模态检索（UMR）需求上升。现有多模态大语言模型（MLLMs）参数多，训练成本高、推理效率低。为此提出PUMA，从结构和学习两方面改进UMR。结构上，采用层剪枝自蒸馏，保留浅层并从深层蒸馏特征，减少参数且保留表征能力；学习上，引入模态自适应对比学习损失（MAC-Loss），按目标模态区分负样本并分配不同温度策略提升效率。实验表明，该方法显著降低资源消耗且性能良好。
            arXiv:2507.08064v1 Announce Type: new 
Abstract: As multimedia content expands, the demand for unified multimodal retrieval (UMR) in real-world applications increases. Recent work leverages multimodal large language models (MLLMs) to tackle this task. However, their large parameter size results in high training costs and low inference efficiency. To address this, we propose PUMA: a Layer-Pruned Language Model for Efficient Unified Multimodal Retrieval with Modality-Adaptive Learning. Our approach improves UMR from both structural and learning perspectives. (1) Structurally, we propose Layer-Pruned Self-Distillation, which prunes MLLMs by keeping only shallow layers while distilling features from dropped deep layers as teacher signals. This reduces parameters and preserves representation capability. (2) On the learning side, we introduce Modality-Adaptive Contrastive Learning Loss (MAC-Loss), which separates in-batch negatives into harder intra-modality and easier inter-modality groups based on the target modality, assigning different temperature strategies to enhance learning efficiency. Experiments show our method significantly reduces resource usage while maintaining strong performance.
        ]]></description>
    </item>
    <item>
        <title>GRASP: Generic Reasoning And SPARQL Generation across Knowledge Graphs</title>
        <link>https://arxiv.org/abs/2507.08107</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.08107v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sebastian Walter, Hannah Bast</dc:creator>
        <description><![CDATA[
            背景：如何利用大模型从自然语言问题或关键词查询生成RDF知识图谱上的SPARQL查询是研究热点。方法：提出一种新方法，不依赖微调，利用大语言模型通过策略性执行SPARQL查询、搜索相关IRI和文字来探索知识图谱。效果：在多种基准测试和不同规模、类型的语言模型上评估，在Wikidata上零样本达到多个基准测试的最优结果，在Freebase上接近最佳少样本方法，在其他知识图谱和基准测试中整体表现良好。
            arXiv:2507.08107v1 Announce Type: new 
Abstract: We propose a new approach for generating SPARQL queries on RDF knowledge graphs from natural language questions or keyword queries, using a large language model. Our approach does not require fine-tuning. Instead, it uses the language model to explore the knowledge graph by strategically executing SPARQL queries and searching for relevant IRIs and literals. We evaluate our approach on a variety of benchmarks (for knowledge graphs of different kinds and sizes) and language models (of different scales and types, commercial as well as open-source) and compare it with existing approaches. On Wikidata we reach state-of-the-art results on multiple benchmarks, despite the zero-shot setting. On Freebase we come close to the best few-shot methods. On other, less commonly evaluated knowledge graphs and benchmarks our approach also performs well overall. We conduct several additional studies, like comparing different ways of searching the graphs, incorporating a feedback mechanism, or making use of few-shot examples.
        ]]></description>
    </item>
    <item>
        <title>ALCo-FM: Adaptive Long-Context Foundation Model for Accident Prediction</title>
        <link>https://arxiv.org/abs/2507.08153</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.08153v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Pinaki Prasad Guha Neogi, Ahmad Mohammadshirazi, Rajiv Ramnath</dc:creator>
        <description><![CDATA[
            背景：交通事故需长上下文多模态推理来准确预测风险。方法：提出统一的自适应长上下文基础模型ALCo - FM，计算波动性预分数动态选择输入数据的上下文窗口，通过浅层交叉注意力对多模态数据编码融合，结合局部GAT层和基于H3六边形网格的BigBird式稀疏全局变压器，用蒙特卡罗丢弃法计算置信度，用类别加权损失训练，小数据微调。效果：在15个美国城市数据上达到0.94准确率、0.92 F1值和0.04的ECE，超20多个基线模型。
            arXiv:2507.08153v1 Announce Type: new 
Abstract: Traffic accidents are rare, yet high-impact events that require long-context multimodal reasoning for accurate risk forecasting. In this paper, we introduce ALCo-FM, a unified adaptive long-context foundation model that computes a volatility pre-score to dynamically select context windows for input data and encodes and fuses these multimodal data via shallow cross attention. Following a local GAT layer and a BigBird-style sparse global transformer over H3 hexagonal grids, coupled with Monte Carlo dropout for confidence, the model yields superior, well-calibrated predictions. Trained on data from 15 US cities with a class-weighted loss to counter label imbalance, and fine-tuned with minimal data on held-out cities, ALCo-FM achieves 0.94 accuracy, 0.92 F1, and an ECE of 0.04, outperforming more than 20 state-of-the-art baselines in large-scale urban risk prediction. Code and dataset are available at: https://github.com/PinakiPrasad12/ALCo-FM
        ]]></description>
    </item>
    <item>
        <title>CTRLS: Chain-of-Thought Reasoning via Latent State-Transition</title>
        <link>https://arxiv.org/abs/2507.08182</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.08182v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Junda Wu, Yuxin Xiong, Xintong Li, Zhengmian Hu, Tong Yu, Rui Wang, Xiang Chen, Jingbo Shang, Julian McAuley</dc:creator>
        <description><![CDATA[
            背景：思维链（CoT）推理可让大语言模型将复杂问题拆解成中间步骤，但传统CoT方法依赖启发式采样，缺乏对推理转换的结构化建模。方法：提出CTRLS框架，将CoT推理表述为具有潜在状态转换的马尔可夫决策过程，通过分布强化学习进行有原则的状态感知探索，采用结合epsilon - 贪心探索和基于熵的正则化的策略迭代优化潜在状态转换。效果：理论分析提供证据下界，实验表明在基准推理任务中推理准确性、多样性和探索效率均有提升。
            arXiv:2507.08182v1 Announce Type: new 
Abstract: Chain-of-thought (CoT) reasoning enables large language models (LLMs) to break down complex problems into interpretable intermediate steps, significantly enhancing model transparency and performance in reasoning tasks. However, conventional CoT methods rely on heuristic sampling without structured modeling of reasoning transitions, constraining their ability to systematically explore and discover diverse and effective reasoning trajectories. In this work, we introduce CTRLS, a framework that formulates CoT reasoning as a Markov decision process (MDP) with latent state transitions, enabling principled and state-aware exploration via distributional reinforcement learning. By modelling reasoning actions as explicit probability distributions in latent space, our approach explicitly models epistemic uncertainty, facilitating robust exploration of the reasoning space. As part of our framework, we introduce an on-policy reinforcement learning strategy incorporating epsilon-greedy exploration and entropy-based regularization to iteratively refine latent state transitions without requiring additional fine-tuning of the underlying LLM. Theoretical analyses provide evidence lower bounds (ELBO), theoretically grounding our transition-aware modeling of latent reasoning dynamics. Further experiments demonstrate improvements in reasoning accuracy, diversity, and exploration efficiency across benchmark reasoning tasks.
        ]]></description>
    </item>
    <item>
        <title>Machine Learning for Evolutionary Graph Theory</title>
        <link>https://arxiv.org/abs/2507.08363</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.08363v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Guoli Yang, Matteo Cavaliere, Mingtao Zhang, Giovanni Masala, Adam Miles, Mengzhu Wang</dc:creator>
        <description><![CDATA[
            背景：社区稳定性取决于合作与欺骗的平衡，若欺骗者过多会导致社区合作崩溃，关键挑战是提前检测崩溃风险。方法：结合进化图论与机器学习，向结构化群体引入少量欺骗者，利用机器学习检测和预测欺骗者传播与合作崩溃，使用时间和结构数据。效果：预测准确率随选择强度增强和观察窗口增大而提高，CNN - Seq - LSTM和Seq - LSTM模型表现最佳，且准确率还取决于合作与欺骗者间的博弈类型和社区结构。该研究为检测进化图论突变和预防复杂社交网络合作崩溃提供策略。
            arXiv:2507.08363v1 Announce Type: new 
Abstract: The stability of communities - whether biological, social, economic, technological or ecological depends on the balance between cooperation and cheating. While cooperation strengthens communities, selfish individuals, or "cheaters," exploit collective benefits without contributing. If cheaters become too prevalent, they can trigger the collapse of cooperation and of the community, often in an abrupt manner. A key challenge is determining whether the risk of such a collapse can be detected in advance. To address this, we use a combination of evolutionary graph theory and machine learning to examine how one can predict the unravel of cooperation on complex networks. By introducing few cheaters into a structured population, we employ machine learning to detect and anticipate the spreading of cheaters and cooperation collapse. Using temporal and structural data, the presented results show that prediction accuracy improves with stronger selection strength and larger observation windows, with CNN-Seq-LSTM and Seq-LSTM best performing models. Moreover, the accuracy for the predictions depends crucially on the type of game played between cooperators and cheaters (i.e., accuracy improves when it is more advantageous to defect) and on the community structure. Overall, this work introduces a machine learning approach into detecting abrupt shifts in evolutionary graph theory and offer potential strategies for anticipating and preventing cooperation collapse in complex social networks.
        ]]></description>
    </item>
    <item>
        <title>ChainEdit: Propagating Ripple Effects in LLM Knowledge Editing through Logical Rule-Guided Chains</title>
        <link>https://arxiv.org/abs/2507.08427</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.08427v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zilu Dong, Xiangqing Shen, Zinong Yang, Rui Xia</dc:creator>
        <description><![CDATA[
            当前大语言模型知识编辑方法在传播涟漪效应到相关事实时难以保持逻辑一致性。为此提出ChainEdit框架，将知识图导出的逻辑规则与大语言模型的逻辑推理能力相结合，实现系统的链式更新。通过从结构化知识库中自动提取逻辑模式并与大模型内部逻辑对齐，动态生成和编辑逻辑相连的知识簇。实验表明，相比基线，逻辑泛化能力提升超30%，同时保证编辑可靠性和特异性，还解决了现有基准评估偏差问题。
            arXiv:2507.08427v1 Announce Type: new 
Abstract: Current knowledge editing methods for large language models (LLMs) struggle to maintain logical consistency when propagating ripple effects to associated facts. We propose ChainEdit, a framework that synergizes knowledge graph-derived logical rules with LLM logical reasoning capabilities to enable systematic chain updates. By automatically extracting logical patterns from structured knowledge bases and aligning them with LLMs' internal logics, ChainEdit dynamically generates and edits logically connected knowledge clusters. Experiments demonstrate an improvement of more than 30% in logical generalization over baselines while preserving editing reliability and specificity. We further address evaluation biases in existing benchmarks through knowledge-aware protocols that disentangle external dependencies. This work establishes new state-of-the-art performance on ripple effect while ensuring internal logical consistency after knowledge editing.
        ]]></description>
    </item>
    <item>
        <title>KGRAG-Ex: Explainable Retrieval-Augmented Generation with Knowledge Graph-based Perturbations</title>
        <link>https://arxiv.org/abs/2507.08443</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.08443v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Georgios Balanos, Evangelos Chasanis, Konstantinos Skianis, Evaggelia Pitoura</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）可借助外部信息增强语言模型，但可解释性是关键挑战，知识图谱能提供结构化语义丰富的实体及关系表征。方法：提出KGRAG - Ex系统，利用基于提示信息提取构建的特定领域知识图谱，识别图中相关实体和语义路径并转化为伪段落指导语料检索，还引入基于扰动的解释方法评估特定图谱组件对生成答案的影响。效果：通过实验分析系统对不同扰动方法的敏感性等多方面关系。
            arXiv:2507.08443v1 Announce Type: new 
Abstract: Retrieval-Augmented Generation (RAG) enhances language models by grounding responses in external information, yet explainability remains a critical challenge, particularly when retrieval relies on unstructured text. Knowledge graphs (KGs) offer a solution by introducing structured, semantically rich representations of entities and their relationships, enabling transparent retrieval paths and interpretable reasoning. In this work, we present KGRAG-Ex, a RAG system that improves both factual grounding and explainability by leveraging a domain-specific KG constructed via prompt-based information extraction. Given a user query, KGRAG-Ex identifies relevant entities and semantic paths in the graph, which are then transformed into pseudo-paragraphs: natural language representations of graph substructures that guide corpus retrieval. To improve interpretability and support reasoning transparency, we incorporate perturbation-based explanation methods that assess the influence of specific KG-derived components on the generated answers. We conduct a series of experiments to analyze the sensitivity of the system to different perturbation methods, the relationship between graph component importance and their structural positions, the influence of semantic node types, and how graph metrics correspond to the influence of components within the explanations process.
        ]]></description>
    </item>
    <item>
        <title>Space filling positionality and the Spiroformer</title>
        <link>https://arxiv.org/abs/2507.08456</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.08456v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>M. Maurin, M. \'A. Evangelista-Alvarado, P. Su\'arez-Serrato</dc:creator>
        <description><![CDATA[
            背景：Transformer处理序列数据表现出色，但将其推广到几何领域（如流形）时，会面临缺乏明确定义的全局顺序的问题。方法：提出让注意力头遵循空间填充曲线的解决方案，并以Spiroformer为例，它是在二维球面上遵循极螺旋的Transformer。效果：该方法为Transformer在几何领域的应用提供了新途径，一定程度上解决了在几何域缺乏全局顺序的问题。
            arXiv:2507.08456v1 Announce Type: new 
Abstract: Transformers excel when dealing with sequential data. Generalizing transformer models to geometric domains, such as manifolds, we encounter the problem of not having a well-defined global order. We propose a solution with attention heads following a space-filling curve. As a first experimental example, we present the Spiroformer, a transformer that follows a polar spiral on the $2$-sphere.
        ]]></description>
    </item>
    <item>
        <title>SynBridge: Bridging Reaction States via Discrete Flow for Bidirectional Reaction Prediction</title>
        <link>https://arxiv.org/abs/2507.08475</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.08475v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Haitao Lin, Junjie Wang, Zhifeng Gao, Xiaohong Ji, Rong Zhu, Linfeng Zhang, Guolin Ke, Weinan E</dc:creator>
        <description><![CDATA[
            化学反应本质是电子重分布和重组，具有离散突变性。为模拟状态转变，提出双向基于流的生成模型SynBridge实现多任务反应预测。该模型利用图到图的变压器网络架构和离散流桥，通过化学键和原子的离散状态捕捉反应物和产物图之间的双向化学转化。在三个基准数据集上实验表明，其在正向和逆合成任务中达最优性能，消融研究和噪声调度分析显示结构化扩散在离散空间用于反应预测的优势。
            arXiv:2507.08475v1 Announce Type: new 
Abstract: The essence of a chemical reaction lies in the redistribution and reorganization of electrons, which is often manifested through electron transfer or the migration of electron pairs. These changes are inherently discrete and abrupt in the physical world, such as alterations in the charge states of atoms or the formation and breaking of chemical bonds. To model the transition of states, we propose SynBridge, a bidirectional flow-based generative model to achieve multi-task reaction prediction. By leveraging a graph-to-graph transformer network architecture and discrete flow bridges between any two discrete distributions, SynBridge captures bidirectional chemical transformations between graphs of reactants and products through the bonds' and atoms' discrete states. We further demonstrate the effectiveness of our method through extensive experiments on three benchmark datasets (USPTO-50K, USPTO-MIT, Pistachio), achieving state-of-the-art performance in both forward and retrosynthesis tasks. Our ablation studies and noise scheduling analysis reveal the benefits of structured diffusion over discrete spaces for reaction prediction.
        ]]></description>
    </item>
    <item>
        <title>AbbIE: Autoregressive Block-Based Iterative Encoder for Efficient Sequence Modeling</title>
        <link>https://arxiv.org/abs/2507.08567</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.08567v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Preslav Aleksandrov, Meghdad Kurmanji, Fernando Garcia Redondo, David O'Shea, William Shen, Alex Iacob, Lorenzo Sani, Xinchi Qiu, Nicola Cancedda, Nicholas D. Lane</dc:creator>
        <description><![CDATA[
            背景：提升大语言模型性能需新方法。方法：提出基于自回归块的迭代编码器AbbIE，是仅编码器Transformer架构的递归泛化，在潜在空间迭代，无需专门数据集和训练协议，训练时用2次迭代实现测试时向上泛化。效果：与标准Transformer相比困惑度更低，能根据任务复杂度动态调整计算资源，在零样本上下文学习任务中比其他迭代和标准方法最多提升12%，语言困惑度最多提升5%，为Transformer性能扩展开辟新途径。
            arXiv:2507.08567v1 Announce Type: new 
Abstract: We introduce the Autoregressive Block-Based Iterative Encoder (AbbIE), a novel recursive generalization of the encoder-only Transformer architecture, which achieves better perplexity than a standard Transformer and allows for the dynamic scaling of compute resources at test time. This simple, recursive approach is a complement to scaling large language model (LLM) performance through parameter and token counts. AbbIE performs its iterations in latent space, but unlike latent reasoning models, does not require a specialized dataset or training protocol. We show that AbbIE upward generalizes (ability to generalize to arbitrary iteration lengths) at test time by only using 2 iterations during train time, far outperforming alternative iterative methods. AbbIE's ability to scale its computational expenditure based on the complexity of the task gives it an up to \textbf{12\%} improvement in zero-shot in-context learning tasks versus other iterative and standard methods and up to 5\% improvement in language perplexity. The results from this study open a new avenue to Transformer performance scaling. We perform all of our evaluations on model sizes up to 350M parameters.
        ]]></description>
    </item>
    <item>
        <title>KV Cache Steering for Inducing Reasoning in Small Language Models</title>
        <link>https://arxiv.org/abs/2507.08799</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.08799v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Max Belitsky, Dawid J. Kopiczko, Michael Dorkenwald, M. Jehanzeb Mirza, Cees G. M. Snoek, Yuki M. Asano</dc:creator>
        <description><![CDATA[
            背景：现有方法在引导语言模型推理方面存在不足。方法：提出缓存引导（cache steering）轻量级方法，通过对键值缓存进行一次性干预隐式引导语言模型，利用GPT - 4o生成的推理轨迹构建引导向量，无需微调或修改提示。效果：在多种推理基准测试中，该方法改善了模型推理的定性结构和定量任务表现，与需持续干预的激活引导技术相比，在超参数稳定性、推理效率和集成难度上优势明显，是更实用的可控生成解决方案。
            arXiv:2507.08799v1 Announce Type: new 
Abstract: We propose cache steering, a lightweight method for implicit steering of language models via a one-shot intervention applied directly to the key-value cache. To validate its effectiveness, we apply cache steering to induce chain-of-thought reasoning in small language models. Our approach leverages GPT-4o-generated reasoning traces to construct steering vectors that shift model behavior toward more explicit, multi-step reasoning without fine-tuning or prompt modifications. Experimental evaluations on diverse reasoning benchmarks demonstrate that cache steering improves both the qualitative structure of model reasoning and quantitative task performance. Compared to prior activation steering techniques that require continuous interventions, our one-shot cache steering offers substantial advantages in terms of hyperparameter stability, inference-time efficiency, and ease of integration, making it a more robust and practical solution for controlled generation.
        ]]></description>
    </item>
    <item>
        <title>M2-Reasoning: Empowering MLLMs with Unified General and Spatial Reasoning</title>
        <link>https://arxiv.org/abs/2507.08306</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.08306v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Inclusion AI,  :, Fudong Wang, Jiajia Liu, Jingdong Chen, Jun Zhou, Kaixiang Ji, Lixiang Ru, Qingpei Guo, Ruobing Zheng, Tianqi Li, Yi Yuan, Yifan Mao, Yuting Xiao, Ziping Ma</dc:creator>
        <description><![CDATA[
            背景：当前多模态大语言模型（MLLMs）虽借助可验证奖励强化学习（RLVR）提升了推理能力，但在动态空间交互方面存在不足。方法：提出M2-Reasoning - 7B模型，采用新数据管道生成29.42万个高质量数据样本，还运用动态多任务训练策略和逐步优化。效果：该模型在8个基准测试中达到新的最优水平，在通用和空间推理领域表现出色。
            arXiv:2507.08306v1 Announce Type: cross 
Abstract: Recent advancements in Multimodal Large Language Models (MLLMs), particularly through Reinforcement Learning with Verifiable Rewards (RLVR), have significantly enhanced their reasoning abilities. However, a critical gap persists: these models struggle with dynamic spatial interactions, a capability essential for real-world applications. To bridge this gap, we introduce M2-Reasoning-7B, a model designed to excel in both general and spatial reasoning. Our approach integrates two key innovations: (1) a novel data pipeline that generates 294.2K high-quality data samples (168K for cold-start fine-tuning and 126.2K for RLVR), which feature logically coherent reasoning trajectories and have undergone comprehensive assessment; and (2) a dynamic multi-task training strategy with step-wise optimization to mitigate conflicts between data, and task-specific rewards for delivering tailored incentive signals. This combination of curated data and advanced training allows M2-Reasoning-7B to set a new state-of-the-art (SOTA) across 8 benchmarks, showcasing superior performance in both general and spatial reasoning domains.
        ]]></description>
    </item>
    <item>
        <title>Towards Efficient Quantity Retrieval from Text:an Approach via Description Parsing and Weak Supervision</title>
        <link>https://arxiv.org/abs/2507.08322</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.08322v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yixuan Cao, Zhengrong Chen, Chengxuan Xia, Kun Wu, Ping Luo</dc:creator>
        <description><![CDATA[
            背景：企业和政府不断产生定量事实，许多长尾定量事实埋藏于非结构化文档，难以获取。方法：提出数量检索任务，即给定定量事实描述，系统返回相关值和支持证据；引入基于描述解析的框架，将文本转换为结构化（描述，数量）对用于有效检索；利用基于数量共现的弱监督构建大型释义数据集。效果：在大型财务年报语料库和新标注的数量描述数据集上评估，将top - 1检索准确率从30.98%显著提升至64.66%。
            arXiv:2507.08322v1 Announce Type: cross 
Abstract: Quantitative facts are continually generated by companies and governments, supporting data-driven decision-making. While common facts are structured, many long-tail quantitative facts remain buried in unstructured documents, making them difficult to access. We propose the task of Quantity Retrieval: given a description of a quantitative fact, the system returns the relevant value and supporting evidence. Understanding quantity semantics in context is essential for this task. We introduce a framework based on description parsing that converts text into structured (description, quantity) pairs for effective retrieval. To improve learning, we construct a large paraphrase dataset using weak supervision based on quantity co-occurrence. We evaluate our approach on a large corpus of financial annual reports and a newly annotated quantity description dataset. Our method significantly improves top-1 retrieval accuracy from 30.98 percent to 64.66 percent.
        ]]></description>
    </item>
    <item>
        <title>xpSHACL: Explainable SHACL Validation using Retrieval-Augmented Generation and Large Language Models</title>
        <link>https://arxiv.org/abs/2507.08432</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.08432v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Gustavo Correa Publio, Jos\'e Emilio Labra Gayo</dc:creator>
        <description><![CDATA[
            背景：Shapes Constraint Language（SHACL）用于验证RDF数据，但传统验证引擎给出的英文报告难被非技术用户解读。方法：提出xpSHACL可解释验证系统，结合基于规则的理由树、检索增强生成（RAG）和大语言模型（LLMs），为约束违规生成详细、多语言、易读的解释，还使用违规知识图谱（KG）缓存和复用解释。效果：提升了验证报告的可解读性，同时提高效率和一致性。
            arXiv:2507.08432v1 Announce Type: cross 
Abstract: Shapes Constraint Language (SHACL) is a powerful language for validating RDF data. Given the recent industry attention to Knowledge Graphs (KGs), more users need to validate linked data properly. However, traditional SHACL validation engines often provide terse reports in English that are difficult for non-technical users to interpret and act upon. This paper presents xpSHACL, an explainable SHACL validation system that addresses this issue by combining rule-based justification trees with retrieval-augmented generation (RAG) and large language models (LLMs) to produce detailed, multilanguage, human-readable explanations for constraint violations. A key feature of xpSHACL is its usage of a Violation KG to cache and reuse explanations, improving efficiency and consistency.
        ]]></description>
    </item>
    <item>
        <title>A Multi-granularity Concept Sparse Activation and Hierarchical Knowledge Graph Fusion Framework for Rare Disease Diagnosis</title>
        <link>https://arxiv.org/abs/2507.08529</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.08529v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mingda Zhang, Na Zhao, Jianglong Qin, Guoyu Ye, Ruixiang Tang</dc:creator>
        <description><![CDATA[
            背景：医学大语言模型在医疗领域虽有进展，但罕见病诊断仍受知识表示深度不足、概念理解有限和临床推理受限等问题困扰。方法：提出将医学概念多粒度稀疏激活与分层知识图谱相结合的框架，通过四种匹配算法、多样性控制和五级回退策略实现精确概念激活，利用三层知识图谱提供结构化最新上下文。效果：在BioASQ罕见病问答集上，BLEU提升0.09、ROUGE提升0.05、准确率提升0.12，最高达0.89接近临床阈值，专家评估显示在多方面有改进。
            arXiv:2507.08529v1 Announce Type: cross 
Abstract: Despite advances from medical large language models in healthcare, rare-disease diagnosis remains hampered by insufficient knowledge-representation depth, limited concept understanding, and constrained clinical reasoning. We propose a framework that couples multi-granularity sparse activation of medical concepts with a hierarchical knowledge graph. Four complementary matching algorithms, diversity control, and a five-level fallback strategy enable precise concept activation, while a three-layer knowledge graph (taxonomy, clinical features, instances) provides structured, up-to-date context. Experiments on the BioASQ rare-disease QA set show BLEU gains of 0.09, ROUGE gains of 0.05, and accuracy gains of 0.12, with peak accuracy of 0.89 approaching the 0.90 clinical threshold. Expert evaluation confirms improvements in information quality, reasoning, and professional expression, suggesting our approach shortens the "diagnostic odyssey" for rare-disease patients.
        ]]></description>
    </item>
    <item>
        <title>Filter Equivariant Functions: A symmetric account of length-general extrapolation on lists</title>
        <link>https://arxiv.org/abs/2507.08796</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.08796v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Owen Lewis, Neil Ghani, Andrew Dudzik, Christos Perivolaropoulos, Razvan Pascanu, Petar Veli\v{c}kovi\'c</dc:creator>
        <description><![CDATA[
            背景：在已知输入输出示例之外进行外推的函数应具备何种特征是个难题。方法：提出“好”的外推函数应遵循特定规则，研究列表函数遵循规则的标准，引入过滤等变函数这一语义类，给出其几何解释，并提出合并算法，通过研究函数在输入子列表上的行为构建输出。效果：能实现完美外推，还证明了相关基本定理，并与知名的映射等变函数类建立联系。
            arXiv:2507.08796v1 Announce Type: cross 
Abstract: What should a function that extrapolates beyond known input/output examples look like? This is a tricky question to answer in general, as any function matching the outputs on those examples can in principle be a correct extrapolant. We argue that a "good" extrapolant should follow certain kinds of rules, and here we study a particularly appealing criterion for rule-following in list functions: that the function should behave predictably even when certain elements are removed. In functional programming, a standard way to express such removal operations is by using a filter function. Accordingly, our paper introduces a new semantic class of functions -- the filter equivariant functions. We show that this class contains interesting examples, prove some basic theorems about it, and relate it to the well-known class of map equivariant functions. We also present a geometric account of filter equivariants, showing how they correspond naturally to certain simplicial structures. Our highlight result is the amalgamation algorithm, which constructs any filter-equivariant function's output by first studying how it behaves on sublists of the input, in a way that extrapolates perfectly.
        ]]></description>
    </item>
    <item>
        <title>PIAD-SRNN: Physics-Informed Adaptive Decomposition in State-Space RNN</title>
        <link>https://arxiv.org/abs/2412.00994</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2412.00994v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ahmad Mohammadshirazi, Pinaki Prasad Guha Neogi, Rajiv Ramnath</dc:creator>
        <description><![CDATA[
            时间序列预测需在准确性和效率间权衡，现有Transformer模型虽提升了预测能力但计算成本高，线性模型精度也不理想。为此，提出PIAD - SRNN，这是一种结合物理知识的自适应分解状态空间循环神经网络，可分离季节和趋势成分并在循环框架中嵌入领域方程。在室内空气质量数据集上评估其对不同预测范围的CO₂浓度预测性能，结果显示，该模型在长短期时间序列预测的MSE和MAE指标上均优于现有最优模型。此外，论文还提供了四个整理好的数据集。
            arXiv:2412.00994v2 Announce Type: replace 
Abstract: Time series forecasting often demands a trade-off between accuracy and efficiency. While recent Transformer models have improved forecasting capabilities, they come with high computational costs. Linear-based models have shown better accuracy than Transformers but still fall short of ideal performance. We propose PIAD-SRNN, a physics-informed adaptive decomposition state-space RNN, that separates seasonal and trend components and embeds domain equations in a recurrent framework. We evaluate PIAD-SRNN's performance on indoor air quality datasets, focusing on CO2 concentration prediction across various forecasting horizons, and results demonstrate that it consistently outperforms SoTA models in both long-term and short-term time series forecasting, including transformer-based architectures, in terms of both MSE and MAE. Besides proposing PIAD-SRNN which balances accuracy with efficiency, this paper also provides four curated datasets. Code and data: https://github.com/ahmad-shirazi/DSSRNN
        ]]></description>
    </item>
    <item>
        <title>GTR: Guided Thought Reinforcement Prevents Thought Collapse in RL-based VLM Agent Training</title>
        <link>https://arxiv.org/abs/2503.08525</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.08525v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tong Wei, Yijun Yang, Junliang Xing, Yuanchun Shi, Zongqing Lu, Deheng Ye</dc:creator>
        <description><![CDATA[
            背景：基于可验证结果奖励的强化学习（RLVR）能提升大语言模型思维链推理能力，但在训练视觉语言模型（VLM）代理进行目标导向行动推理方面效果不佳，还会导致“思维崩溃”现象。方法：在复杂纸牌游戏和具体任务中实验，提出GTR框架，通过自动校正器在每个强化学习步骤评估和完善代理推理，无需密集人工标注。效果：显著提升LLaVA - 7b模型在不同视觉环境中的性能和泛化能力，任务成功率比现有最优模型高3 - 5倍，且模型规模更小。
            arXiv:2503.08525v2 Announce Type: replace 
Abstract: Reinforcement learning with verifiable outcome rewards (RLVR) has effectively scaled up chain-of-thought (CoT) reasoning in large language models (LLMs). Yet, its efficacy in training vision-language model (VLM) agents for goal-directed action reasoning in visual environments is less established. This work investigates this problem through extensive experiments on complex card games, such as 24 points, and embodied tasks from ALFWorld. We find that when rewards are based solely on action outcomes, RL fails to incentivize CoT reasoning in VLMs, instead leading to a phenomenon we termed thought collapse, characterized by a rapid loss of diversity in the agent's thoughts, state-irrelevant and incomplete reasoning, and subsequent invalid actions, resulting in negative rewards. To counteract thought collapse, we highlight the necessity of process guidance and propose an automated corrector that evaluates and refines the agent's reasoning at each RL step. This simple and scalable GTR (Guided Thought Reinforcement) framework trains reasoning and action simultaneously without the need for dense, per-step human labeling. Our experiments demonstrate that GTR significantly enhances the performance and generalization of the LLaVA-7b model across various visual environments, achieving 3-5 times higher task success rates compared to SoTA models with notably smaller model sizes.
        ]]></description>
    </item>
    <item>
        <title>Navigate the Unknown: Enhancing LLM Reasoning with Intrinsic Motivation Guided Exploration</title>
        <link>https://arxiv.org/abs/2505.17621</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17621v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jingtong Gao, Ling Pan, Yejing Wang, Rui Zhong, Chi Lu, Qingpeng Cai, Peng Jiang, Xiangyu Zhao</dc:creator>
        <description><![CDATA[
            背景：强化学习是提升大语言模型推理能力的关键方法，但现有近端策略优化等方法依赖稀疏奖励、探索机制不足，导致多步推理引导效率低。方法：提出i - MENTOR方法，在强化学习训练范式中提供密集奖励、增强探索，包括轨迹感知探索奖励、动态奖励缩放、优势保留奖励实现三项创新。效果：在三个公开数据集上的实验表明该方法有效，在困难数据集Countdown - 4上提升22.39% 。
            arXiv:2505.17621v3 Announce Type: replace 
Abstract: Reinforcement learning (RL) has emerged as a pivotal method for improving the reasoning capabilities of Large Language Models (LLMs). However, prevalent RL approaches such as Proximal Policy Optimization (PPO) and Group-Regularized Policy Optimization (GRPO) face critical limitations due to their reliance on sparse outcome-based rewards and inadequate mechanisms for incentivizing exploration. These limitations result in inefficient guidance for multi-step reasoning processes. Specifically, sparse reward signals fail to deliver effective or sufficient feedback, particularly for challenging problems. Furthermore, such reward structures induce systematic biases that prioritize exploitation of familiar trajectories over novel solution discovery. These shortcomings critically hinder performance in complex reasoning tasks, which inherently demand iterative refinement across ipntermediate steps. To address these challenges, we propose an Intrinsic Motivation guidEd exploratioN meThOd foR LLM Reasoning (i-MENTOR), a novel method designed to both deliver dense rewards and amplify explorations in the RL-based training paradigm. i-MENTOR introduces three key innovations: trajectory-aware exploration rewards that mitigate bias in token-level strategies while maintaining computational efficiency; dynamic reward scaling to stabilize exploration and exploitation in large action spaces; and advantage-preserving reward implementation that maintains advantage distribution integrity while incorporating exploratory guidance. Experiments across three public datasets demonstrate i-MENTOR's effectiveness with a 22.39% improvement on the difficult dataset Countdown-4.
        ]]></description>
    </item>
    <item>
        <title>Dualformer: Controllable Fast and Slow Thinking by Learning with Randomized Reasoning Traces</title>
        <link>https://arxiv.org/abs/2410.09918</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.09918v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>DiJia Su, Sainbayar Sukhbaatar, Michael Rabbat, Yuandong Tian, Qinqing Zheng</dc:creator>
        <description><![CDATA[
            背景：受人类思维双系统理论启发，大语言模型有快速和慢速两种推理模式。方法：提出Dualformer，通过在随机推理轨迹上训练，训练时策略性丢弃轨迹部分内容，推理时可配置为快速、慢速或自动模式。效果：在三种模式下均优于基线模型，慢速模式下在未见的30×30迷宫任务中最优率达97.6%，推理步数少45.5%；快速模式最优率80%；自动模式最优率96.6%，步数少59.9%，且推理轨迹更多样，在数学推理问题微调中也表现良好。
            arXiv:2410.09918v3 Announce Type: replace-cross 
Abstract: In cognition theory, human thinking is governed by two systems: the fast and intuitive System 1 and the slower but more deliberative System 2. Analogously, Large Language Models (LLMs) can operate in two reasoning modes: outputting only the solutions (\emph{fast mode}) or both the reasoning chain and the final solution (\emph{slow mode}). We present \dualformer, a single Transformer model that seamlessly integrates both the fast and slow reasoning modes by training on randomized reasoning traces, where different parts of the traces are strategically dropped during training. At inference time, \dualformer can be easily configured to execute in either fast or slow mode, or automatically decide which mode to engage (\emph{auto mode}). It outperforms baselines in both performance and computational efficiency across all three modes: (1) in slow mode, \dualformer achieves $97.6\%$ optimal rate on unseen $30 \times 30$ maze tasks, surpassing the \searchformer baseline ($93.3\%$) trained on data with complete reasoning traces, with $45.5\%$ fewer reasoning steps; (2) in fast mode, \dualformer achieves $80\%$ optimal rate, significantly outperforming the Solution-Only model trained on solution-only data, which has an optimal rate of only $30\%$; (3) in auto mode, \dualformer achieves $96.6\%$ optimal rate with $59.9\%$ fewer steps than \searchformer. Moreover, \dualformer produces more diverse reasoning traces than \searchformer{}. For math reasoning problems, our techniques have also achieved improved performance with LLM fine-tuning, demonstrating its generalization beyond task-specific models. We open source our code at https://github.com/facebookresearch/dualformer.
        ]]></description>
    </item>
    <item>
        <title>Audio Flamingo 3: Advancing Audio Intelligence with Fully Open Large Audio Language Models</title>
        <link>https://arxiv.org/abs/2507.08128</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.08128v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Arushi Goel, Sreyan Ghosh, Jaehyeon Kim, Sonal Kumar, Zhifeng Kong, Sang-gil Lee, Chao-Han Huck Yang, Ramani Duraiswami, Dinesh Manocha, Rafael Valle, Bryan Catanzaro</dc:creator>
        <description><![CDATA[
            本文背景是提升音频智能水平。研究团队推出全开源的大型音频语言模型Audio Flamingo 3（AF3）。方法上，引入统一音频编码器AF - Whisper，采用新策略进行多模态联合表征学习；具备灵活按需思考、多轮多音频聊天等能力；提出多个用新策略整理的大规模训练数据集，并用五阶段课程式训练策略训练。效果上，AF3在超20个音频理解和推理基准测试中取得新的最优结果，超越在更大数据集上训练的开源和闭源模型。
            arXiv:2507.08128v1 Announce Type: new 
Abstract: We present Audio Flamingo 3 (AF3), a fully open state-of-the-art (SOTA) large audio-language model that advances reasoning and understanding across speech, sound, and music. AF3 introduces: (i) AF-Whisper, a unified audio encoder trained using a novel strategy for joint representation learning across all 3 modalities of speech, sound, and music; (ii) flexible, on-demand thinking, allowing the model to do chain-of-thought-type reasoning before answering; (iii) multi-turn, multi-audio chat; (iv) long audio understanding and reasoning (including speech) up to 10 minutes; and (v) voice-to-voice interaction. To enable these capabilities, we propose several large-scale training datasets curated using novel strategies, including AudioSkills-XL, LongAudio-XL, AF-Think, and AF-Chat, and train AF3 with a novel five-stage curriculum-based training strategy. Trained on only open-source audio data, AF3 achieves new SOTA results on over 20+ (long) audio understanding and reasoning benchmarks, surpassing both open-weight and closed-source models trained on much larger datasets.
        ]]></description>
    </item>
    <item>
        <title>MIDI-VALLE: Improving Expressive Piano Performance Synthesis Through Neural Codec Language Modelling</title>
        <link>https://arxiv.org/abs/2507.08530</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.08530v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jingjing Tang, Xin Wang, Zhe Zhang, Junichi Yamagishi, Geraint Wiggins, George Fazekas</dc:creator>
        <description><![CDATA[
            从乐谱生成富有表现力的音频演奏，需模型捕捉乐器声学特性和人类演绎。传统音乐演奏合成流程分两步，但合成模型在不同MIDI源、音乐风格和录制环境中泛化能力欠佳。为此提出MIDI - VALLE，它基于VALLE框架改进，编码MIDI和音频为离散标记。通过在广泛多样的钢琴演奏数据集上训练提升泛化能力。评估显示，其在ATEPP和Maestro数据集上的弗雷歇音频距离降低超75%，听力测试中获202票，远超基线的58票，合成质量和泛化能力显著提升。
            arXiv:2507.08530v1 Announce Type: new 
Abstract: Generating expressive audio performances from music scores requires models to capture both instrument acoustics and human interpretation. Traditional music performance synthesis pipelines follow a two-stage approach, first generating expressive performance MIDI from a score, then synthesising the MIDI into audio. However, the synthesis models often struggle to generalise across diverse MIDI sources, musical styles, and recording environments. To address these challenges, we propose MIDI-VALLE, a neural codec language model adapted from the VALLE framework, which was originally designed for zero-shot personalised text-to-speech (TTS) synthesis. For performance MIDI-to-audio synthesis, we improve the architecture to condition on a reference audio performance and its corresponding MIDI. Unlike previous TTS-based systems that rely on piano rolls, MIDI-VALLE encodes both MIDI and audio as discrete tokens, facilitating a more consistent and robust modelling of piano performances. Furthermore, the model's generalisation ability is enhanced by training on an extensive and diverse piano performance dataset. Evaluation results show that MIDI-VALLE significantly outperforms a state-of-the-art baseline, achieving over 75% lower Frechet Audio Distance on the ATEPP and Maestro datasets. In the listening test, MIDI-VALLE received 202 votes compared to 58 for the baseline, demonstrating improved synthesis quality and generalisation across diverse performance MIDI inputs.
        ]]></description>
    </item>
    <item>
        <title>FreeAudio: Training-Free Timing Planning for Controllable Long-Form Text-to-Audio Generation</title>
        <link>https://arxiv.org/abs/2507.08557</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.08557v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuxuan Jiang, Zehua Chen, Zeqian Ju, Chang Li, Weibei Dou, Jun Zhu</dc:creator>
        <description><![CDATA[
            文本到音频（T2A）生成虽有进展，但因时间对齐的音频 - 文本对质量和数量有限，现有方法难以处理含精确时间控制的复杂文本提示。本文提出无训练的时间控制T2A框架FreeAudio，首次实现长文本T2A生成。先利用大语言模型规划非重叠时间窗口并重新描述，再引入解耦聚合注意力控制、上下文潜在合成和参考引导。实验表明，该方法在无训练方法中达T2A合成质量最优，与有训练方法相当，长文本生成质量与Stable Audio相近。
            arXiv:2507.08557v1 Announce Type: new 
Abstract: Text-to-audio (T2A) generation has achieved promising results with the recent advances in generative models. However, because of the limited quality and quantity of temporally-aligned audio-text pairs, existing T2A methods struggle to handle the complex text prompts that contain precise timing control, e.g., "owl hooted at 2.4s-5.2s". Recent works have explored data augmentation techniques or introduced timing conditions as model inputs to enable timing-conditioned 10-second T2A generation, while their synthesis quality is still limited. In this work, we propose a novel training-free timing-controlled T2A framework, FreeAudio, making the first attempt to enable timing-controlled long-form T2A generation, e.g., "owl hooted at 2.4s-5.2s and crickets chirping at 0s-24s". Specifically, we first employ an LLM to plan non-overlapping time windows and recaption each with a refined natural language description, based on the input text and timing prompts. Then we introduce: 1) Decoupling and Aggregating Attention Control for precise timing control; 2) Contextual Latent Composition for local smoothness and Reference Guidance for global consistency. Extensive experiments show that: 1) FreeAudio achieves state-of-the-art timing-conditioned T2A synthesis quality among training-free methods and is comparable to leading training-based methods; 2) FreeAudio demonstrates comparable long-form generation quality with training-based Stable Audio and paves the way for timing-controlled long-form T2A synthesis. Demo samples are available at: https://freeaudio.github.io/FreeAudio/
        ]]></description>
    </item>
    <item>
        <title>Unlocking Speech Instruction Data Potential with Query Rewriting</title>
        <link>https://arxiv.org/abs/2507.08603</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.08603v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yonghua Hei, Yibo Yan, Shuliang Liu, Huiyu Zhou, Linfeng Zhang, Xuming Hu</dc:creator>
        <description><![CDATA[
            背景：端到端大语音语言模型在语音指令遵循能力上未充分实现，此前构建语音指令数据集的方法有不足，且人工收集标注成本高，TTS模型转换文本指令有挑战。方法：提出多LLM知识融合的查询重写框架，用多智能体对合成语音进行标注和验证。效果：通过零样本重写可将文本指令转换为更适合TTS模型的分布进行语音合成，数据可用性从72%提升到93%，在复杂知识和上下文相关重写任务中有独特优势。
            arXiv:2507.08603v1 Announce Type: cross 
Abstract: End-to-end Large Speech Language Models~(\textbf{LSLMs}) demonstrate strong potential in response latency and speech comprehension capabilities, showcasing general intelligence across speech understanding tasks. However, the ability to follow speech instructions has not been fully realized due to the lack of datasets and heavily biased training tasks. Leveraging the rich ASR datasets, previous approaches have used Large Language Models~(\textbf{LLMs}) to continue the linguistic information of speech to construct speech instruction datasets. Yet, due to the gap between LLM-generated results and real human responses, the continuation methods further amplify these shortcomings. Given the high costs of collecting and annotating speech instruction datasets by humans, using speech synthesis to construct large-scale speech instruction datasets has become a balanced and robust alternative. Although modern Text-To-Speech~(\textbf{TTS}) models have achieved near-human-level synthesis quality, it is challenging to appropriately convert out-of-distribution text instruction to speech due to the limitations of the training data distribution in TTS models. To address this issue, we propose a query rewriting framework with multi-LLM knowledge fusion, employing multiple agents to annotate and validate the synthesized speech, making it possible to construct high-quality speech instruction datasets without relying on human annotation. Experiments show that this method can transform text instructions into distributions more suitable for TTS models for speech synthesis through zero-shot rewriting, increasing data usability from 72\% to 93\%. It also demonstrates unique advantages in rewriting tasks that require complex knowledge and context-related abilities.
        ]]></description>
    </item>
    <item>
        <title>MuCodec: Ultra Low-Bitrate Music Codec</title>
        <link>https://arxiv.org/abs/2409.13216</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2409.13216v3</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yaoxun Xu, Hangting Chen, Jianwei Yu, Wei Tan, Rongzhi Gu, Shun Lei, Zhiwei Lin, Zhiyong Wu</dc:creator>
        <description><![CDATA[
            音乐编解码器是音频编解码研究的重要部分，超低比特率压缩对音乐传输和生成意义重大。由于音乐背景复杂、人声丰富，仅靠建模语义或声学信息无法有效重建含人声和背景的音乐。为此，本文提出MuCodec，针对超低比特率音乐压缩和重建任务。它用MuEncoder提取声学和语义特征，用RVQ离散化，通过流匹配获得Mel - VAE特征，再用预训练的MEL - VAE解码器和HiFi - GAN重建音乐，能在超低（0.35kbps）或高比特率（1.35kbps）下重建高保真音乐，主客观指标达当前最优。
            arXiv:2409.13216v3 Announce Type: replace 
Abstract: Music codecs are a vital aspect of audio codec research, and ultra low-bitrate compression holds significant importance for music transmission and generation. Due to the complexity of music backgrounds and the richness of vocals, solely relying on modeling semantic or acoustic information cannot effectively reconstruct music with both vocals and backgrounds. To address this issue, we propose MuCodec, specifically targeting music compression and reconstruction tasks at ultra low bitrates. MuCodec employs MuEncoder to extract both acoustic and semantic features, discretizes them with RVQ, and obtains Mel-VAE features via flow-matching. The music is then reconstructed using a pre-trained MEL-VAE decoder and HiFi-GAN. MuCodec can reconstruct high-fidelity music at ultra low (0.35kbps) or high bitrates (1.35kbps), achieving the best results to date in both subjective and objective metrics. Code and Demo: https://xuyaoxun.github.io/MuCodec_demo/.
        ]]></description>
    </item>
    <item>
        <title>UmbraTTS: Adapting Text-to-Speech to Environmental Contexts with Flow Matching</title>
        <link>https://arxiv.org/abs/2506.09874</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.09874v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Neta Glazer, Aviv Navon, Yael Segal, Aviv Shamsian, Hilit Segev, Asaf Buchnick, Menachem Pirchi, Gil Hetz, Joseph Keshet</dc:creator>
        <description><![CDATA[
            这是一篇关于音频生成的论文。背景是当前文本转语音虽能合成自然语音，但将语音与复杂背景环境融合仍有挑战。方法是提出基于流匹配的TTS模型UmbraTTS，它能联合生成语音和环境音频，还提出自监督框架从无标注录音中提取语音、背景音频和文字稿。效果是经大量评估，UmbraTTS显著优于现有基线，能生成自然、高质量且有环境感知的音频。
            arXiv:2506.09874v2 Announce Type: replace 
Abstract: Recent advances in Text-to-Speech (TTS) have enabled highly natural speech synthesis, yet integrating speech with complex background environments remains challenging. We introduce UmbraTTS, a flow-matching based TTS model that jointly generates both speech and environmental audio, conditioned on text and acoustic context. Our model allows fine-grained control over background volume and produces diverse, coherent, and context-aware audio scenes. A key challenge is the lack of data with speech and background audio aligned in natural context. To overcome the lack of paired training data, we propose a self-supervised framework that extracts speech, background audio, and transcripts from unannotated recordings. Extensive evaluations demonstrate that UmbraTTS significantly outperformed existing baselines, producing natural, high-quality, environmentally aware audios.
        ]]></description>
    </item>
</channel>
</rss>