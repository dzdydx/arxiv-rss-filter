<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
<channel>
    <title>arXiv Paper Filter</title>
    <link>https://github.com/None/arxiv_filter</link>
    <description>根据研究兴趣筛选的arXiv论文</description>
    <atom:link href="https://raw.githubusercontent.com/None/arxiv_filter/main/feed.xml" rel="self" type="application/rss+xml" />
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>zh-CN</language>
    <lastBuildDate>Tue, 06 May 2025 12:11:42 +0800</lastBuildDate>
    <managingEditor>None@github.com</managingEditor>
    <pubDate>Tue, 06 May 2025 12:11:42 +0800</pubDate>
    <skipDays>
        <day>Saturday</day>
        <day>Sunday</day>
    </skipDays>

    <item>
        <title>SymPlanner: Deliberate Planning in Language Models with Symbolic Representation</title>
        <link>https://arxiv.org/abs/2505.01479</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.01479v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Siheng Xiong, Jieyu Zhou, Zhangding Liu, Yusen Su</dc:creator>
        <description><![CDATA[
            背景：规划是语言模型的核心挑战，特别是在需基于外部约束生成连贯多步动作序列的领域。方法：提出SymPlanner框架，将语言模型与作为显式世界模型的符号环境对接，赋予其结构化规划能力。规划基于符号状态空间，用策略模型提动作，符号环境执行并验证效果；引入迭代校正（IC）和对比排序（CR）增强探索和鲁棒性。效果：在PlanBench上评估，比纯自然语言基线生成的规划更连贯、多样且可验证。
            arXiv:2505.01479v1 Announce Type: new 
Abstract: Planning remains a core challenge for language models (LMs), particularly in domains that require coherent multi-step action sequences grounded in external constraints. We introduce SymPlanner, a novel framework that equips LMs with structured planning capabilities by interfacing them with a symbolic environment that serves as an explicit world model. Rather than relying purely on natural language reasoning, SymPlanner grounds the planning process in a symbolic state space, where a policy model proposes actions and a symbolic environment deterministically executes and verifies their effects. To enhance exploration and improve robustness, we introduce Iterative Correction (IC), which refines previously proposed actions by leveraging feedback from the symbolic environment to eliminate invalid decisions and guide the model toward valid alternatives. Additionally, Contrastive Ranking (CR) enables fine-grained comparison of candidate plans by evaluating them jointly. We evaluate SymPlanner on PlanBench, demonstrating that it produces more coherent, diverse, and verifiable plans than pure natural language baselines.
        ]]></description>
    </item>
    <item>
        <title>Subset Selection for Fine-Tuning: A Utility-Diversity Balanced Approach for Mathematical Domain Adaptation</title>
        <link>https://arxiv.org/abs/2505.01523</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.01523v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Madhav Kotecha, Vijendra Kumar Vaishya, Smita Gautam, Suraj Racha</dc:creator>
        <description><![CDATA[
            背景：为在特定领域（如数学领域）高效微调大语言模型，需解决计算成本高和训练时间长的问题。方法：采用预算子集选择方法，结合效用和多样性指标挑选训练样本，效用指标考虑困惑度和思维链损失，多样性指标确保覆盖数学子领域。效果：在LLaMA - 3 8B和Phi - 3模型上评估，与多种基线方法对比，能以精心挑选的数据点达到接近全量数据集的性能，大幅降低计算成本和训练时间。
            arXiv:2505.01523v1 Announce Type: new 
Abstract: We propose a refined approach to efficiently fine-tune large language models (LLMs) on specific domains like the mathematical domain by employing a budgeted subset selection method. Our approach combines utility and diversity metrics to select the most informative and representative training examples. The final goal is to achieve near-full dataset performance with meticulously selected data points from the entire dataset while significantly reducing computational cost and training time and achieving competitive performance as the full dataset. The utility metric incorporates both perplexity and Chain-of-Thought (CoT) loss to identify challenging examples that contribute most to model learning, while the diversity metric ensures broad coverage across mathematical subdomains. We evaluate our method on LLaMA-3 8B and Phi-3 models, comparing against several baseline approaches, including random selection, diversity-based sampling, and existing state-of-the-art subset selection techniques.
        ]]></description>
    </item>
    <item>
        <title>A Survey on Inference Engines for Large Language Models: Perspectives on Optimization and Efficiency</title>
        <link>https://arxiv.org/abs/2505.01658</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.01658v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sihyeong Park, Sungryeol Jeon, Chaelyn Lee, Seokhun Jeon, Byung-Soo Kim, Jemin Lee</dc:creator>
        <description><![CDATA[
            背景：大语言模型在多领域广泛应用，思维链等任务使推理成本大增，虽有优化方法但难选择，且缺乏对推理引擎的系统研究。方法：对25个开源和商业推理引擎进行全面评估，从易用性、可部署性等多方面考察，探究其支持的优化技术、生态成熟度等。效果：为研究人员和开发者在选择和设计优化推理引擎提供实用指导，还给出未来研究方向，并提供公开仓库跟踪领域发展。
            arXiv:2505.01658v1 Announce Type: new 
Abstract: Large language models (LLMs) are widely applied in chatbots, code generators, and search engines. Workloads such as chain-of-thought, complex reasoning, and agent services significantly increase the inference cost by invoking the model repeatedly. Optimization methods such as parallelism, compression, and caching have been adopted to reduce costs, but the diverse service requirements make it hard to select the right method. Recently, specialized LLM inference engines have emerged as a key component for integrating the optimization methods into service-oriented infrastructures. However, a systematic study on inference engines is still lacking. This paper provides a comprehensive evaluation of 25 open-source and commercial inference engines. We examine each inference engine in terms of ease-of-use, ease-of-deployment, general-purpose support, scalability, and suitability for throughput- and latency-aware computation. Furthermore, we explore the design goals of each inference engine by investigating the optimization techniques it supports. In addition, we assess the ecosystem maturity of open source inference engines and handle the performance and cost policy of commercial solutions. We outline future research directions that include support for complex LLM-based services, support of various hardware, and enhanced security, offering practical guidance to researchers and developers in selecting and designing optimized LLM inference engines. We also provide a public repository to continually track developments in this fast-evolving field: https://github.com/sihyeong/Awesome-LLM-Inference-Engine
        ]]></description>
    </item>
    <item>
        <title>An LLM-Empowered Low-Resolution Vision System for On-Device Human Behavior Understanding</title>
        <link>https://arxiv.org/abs/2505.01743</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.01743v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Siyang Jiang, Bufang Yang, Lilin Xu, Mu Yuan, Yeerzhati Abudunuer, Kaiwei Liu, Liekang Zeng, Hongkai Chen, Zhenyu Yan, Xiaofan Jiang, Guoliang Xing</dc:creator>
        <description><![CDATA[
            背景：现有大视觉语言模型主要针对高分辨率数据，难以理解低分辨率数据，大量标注低分辨率数据又需耗费大量人力。方法：提出Llambda系统，利用有限标注数据和大量未标注数据引导大语言模型生成信息丰富的字幕；设计面向对比的数据标注器生成伪标签，利用物理知识引导字幕生成器减少伪标签错误；采用基于LoRA的高效微调使模型适配低分辨率数据。效果：在多个低分辨率数据集上平均Bert - Score比多个先进LVLM系统最高提升40.03%。
            arXiv:2505.01743v1 Announce Type: new 
Abstract: The rapid advancements in Large Vision Language Models (LVLMs) offer the potential to surpass conventional labeling by generating richer, more detailed descriptions of on-device human behavior understanding (HBU) in low-resolution vision systems, such as depth, thermal, and infrared. However, existing large vision language model (LVLM) approaches are unable to understand low-resolution data well as they are primarily designed for high-resolution data, such as RGB images. A quick fixing approach is to caption a large amount of low-resolution data, but it requires a significant amount of labor-intensive annotation efforts. In this paper, we propose a novel, labor-saving system, Llambda, designed to support low-resolution HBU. The core idea is to leverage limited labeled data and a large amount of unlabeled data to guide LLMs in generating informative captions, which can be combined with raw data to effectively fine-tune LVLM models for understanding low-resolution videos in HBU. First, we propose a Contrastive-Oriented Data Labeler, which can capture behavior-relevant information from long, low-resolution videos and generate high-quality pseudo labels for unlabeled data via contrastive learning. Second, we propose a Physical-Knowledge Guided Captioner, which utilizes spatial and temporal consistency checks to mitigate errors in pseudo labels. Therefore, it can improve LLMs' understanding of sequential data and then generate high-quality video captions. Finally, to ensure on-device deployability, we employ LoRA-based efficient fine-tuning to adapt LVLMs for low-resolution data. We evaluate Llambda using a region-scale real-world testbed and three distinct low-resolution datasets, and the experiments show that Llambda outperforms several state-of-the-art LVLM systems up to $40.03\%$ on average Bert-Score.
        ]]></description>
    </item>
    <item>
        <title>Multimodal Graph Representation Learning for Robust Surgical Workflow Recognition with Adversarial Feature Disentanglement</title>
        <link>https://arxiv.org/abs/2505.01766</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.01766v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Long Bai, Boyi Ma, Ruohan Wang, Guankun Wang, Beilei Cui, Zhongliang Jiang, Mobarakol Islam, Zhe Min, Jiewen Lai, Nassir Navab, Hongliang Ren</dc:creator>
        <description><![CDATA[
            外科工作流识别对自动化任务、辅助决策和培训新手医生至关重要，但数据损坏会导致性能下降。为此，论文提出多模态图表示网络GRAD，利用多模态解缠图网络捕捉细粒度视觉信息并建模视觉与运动嵌入关系；用视觉 - 运动对抗框架对齐特征空间；设计上下文校准解码器增强鲁棒性。大量实验证明该模型及模块有效，能处理数据损坏问题，展现出良好稳定性和鲁棒性，推动了外科工作流识别自动化发展。
            arXiv:2505.01766v1 Announce Type: new 
Abstract: Surgical workflow recognition is vital for automating tasks, supporting decision-making, and training novice surgeons, ultimately improving patient safety and standardizing procedures. However, data corruption can lead to performance degradation due to issues like occlusion from bleeding or smoke in surgical scenes and problems with data storage and transmission. In this case, we explore a robust graph-based multimodal approach to integrating vision and kinematic data to enhance accuracy and reliability. Vision data captures dynamic surgical scenes, while kinematic data provides precise movement information, overcoming limitations of visual recognition under adverse conditions. We propose a multimodal Graph Representation network with Adversarial feature Disentanglement (GRAD) for robust surgical workflow recognition in challenging scenarios with domain shifts or corrupted data. Specifically, we introduce a Multimodal Disentanglement Graph Network that captures fine-grained visual information while explicitly modeling the complex relationships between vision and kinematic embeddings through graph-based message modeling. To align feature spaces across modalities, we propose a Vision-Kinematic Adversarial framework that leverages adversarial training to reduce modality gaps and improve feature consistency. Furthermore, we design a Contextual Calibrated Decoder, incorporating temporal and contextual priors to enhance robustness against domain shifts and corrupted data. Extensive comparative and ablation experiments demonstrate the effectiveness of our model and proposed modules. Moreover, our robustness experiments show that our method effectively handles data corruption during storage and transmission, exhibiting excellent stability and robustness. Our approach aims to advance automated surgical workflow recognition, addressing the complexities and dynamism inherent in surgical procedures.
        ]]></description>
    </item>
    <item>
        <title>R-Bench: Graduate-level Multi-disciplinary Benchmarks for LLM & MLLM Complex Reasoning Evaluation</title>
        <link>https://arxiv.org/abs/2505.02018</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.02018v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Meng-Hao Guo, Jiajun Xu, Yi Zhang, Jiaxi Song, Haoyang Peng, Yi-Xuan Deng, Xinzhi Dong, Kiyohiro Nakayama, Zhengyang Geng, Chen Wang, Bolin Ni, Guo-Wei Yang, Yongming Rao, Houwen Peng, Han Hu, Gordon Wetzstein, Shi-min Hu</dc:creator>
        <description><![CDATA[
            背景：现有推理基准难以严格评估复杂现实问题解决所需的细微推理能力，尤其在多学科和多模态场景。方法：提出研究生水平、多学科的中英文基准R - Bench，涵盖语言和多模态模型推理能力评估，精心设计问题确保难度校准、学科平衡和跨语言对齐。效果：评估常用模型，结果显示先进模型在复杂推理，特别是多模态推理上表现不佳，表现最好的OpenAI o1在多模态评估中准确率仅53.2%。
            arXiv:2505.02018v1 Announce Type: new 
Abstract: Reasoning stands as a cornerstone of intelligence, enabling the synthesis of existing knowledge to solve complex problems. Despite remarkable progress, existing reasoning benchmarks often fail to rigorously evaluate the nuanced reasoning capabilities required for complex, real-world problemsolving, particularly in multi-disciplinary and multimodal contexts. In this paper, we introduce a graduate-level, multi-disciplinary, EnglishChinese benchmark, dubbed as Reasoning Bench (R-Bench), for assessing the reasoning capability of both language and multimodal models. RBench spans 1,094 questions across 108 subjects for language model evaluation and 665 questions across 83 subjects for multimodal model testing in both English and Chinese. These questions are meticulously curated to ensure rigorous difficulty calibration, subject balance, and crosslinguistic alignment, enabling the assessment to be an Olympiad-level multi-disciplinary benchmark. We evaluate widely used models, including OpenAI o1, GPT-4o, DeepSeek-R1, etc. Experimental results indicate that advanced models perform poorly on complex reasoning, especially multimodal reasoning. Even the top-performing model OpenAI o1 achieves only 53.2% accuracy on our multimodal evaluation. Data and code are made publicly available at here.
        ]]></description>
    </item>
    <item>
        <title>Wide & Deep Learning for Node Classification</title>
        <link>https://arxiv.org/abs/2505.02020</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.02020v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yancheng Chen, Wenguo Yang, Zhipeng Jiang</dc:creator>
        <description><![CDATA[
            背景：谷歌的Wide & Deep架构在推荐系统中影响重大，图卷积网络虽在节点分类任务占主导，但存在异质性和表达性等问题，且似乎忽视节点特征。方法：提出灵活框架GCNIII，利用Wide & Deep架构并结合交叉记忆、初始残差和恒等映射三种技术，还探索用大语言模型进行节点特征工程。效果：综合实验表明，GCNIII能在半监督和全监督任务中更有效平衡过拟合和过泛化，在跨领域节点分类任务中表现得到提升。
            arXiv:2505.02020v1 Announce Type: new 
Abstract: Wide & Deep, a simple yet effective learning architecture for recommendation systems developed by Google, has had a significant impact in both academia and industry due to its combination of the memorization ability of generalized linear models and the generalization ability of deep models. Graph convolutional networks (GCNs) remain dominant in node classification tasks; however, recent studies have highlighted issues such as heterophily and expressiveness, which focus on graph structure while seemingly neglecting the potential role of node features. In this paper, we propose a flexible framework GCNIII, which leverages the Wide & Deep architecture and incorporates three techniques: Intersect memory, Initial residual and Identity mapping. We provide comprehensive empirical evidence showing that GCNIII can more effectively balance the trade-off between over-fitting and over-generalization on various semi- and full- supervised tasks. Additionally, we explore the use of large language models (LLMs) for node feature engineering to enhance the performance of GCNIII in cross-domain node classification tasks. Our implementation is available at https://github.com/CYCUCAS/GCNIII.
        ]]></description>
    </item>
    <item>
        <title>GraphPrompter: Multi-stage Adaptive Prompt Optimization for Graph In-Context Learning</title>
        <link>https://arxiv.org/abs/2505.02027</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.02027v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Rui Lv, Zaixi Zhang, Kai Zhang, Qi Liu, Weibo Gao, Jiawei Liu, Jiaxia Yan, Linan Yue, Fangzhou Yao</dc:creator>
        <description><![CDATA[
            图上下文学习无需更新参数就能让预训练图模型适应下游图任务，备受关注。现有方法随机选子图或边作提示，导致提示有噪声、模型性能差，且测试图类别数远超训练时，学习能力会下降。为此，提出多阶段自适应提示优化方法GraphPrompter，通过提示生成器、选择器和增强器优化提示生成、选择和使用过程。实验表明，该方法有效提升图模型上下文学习能力，平均比现有最优基线高8%以上。代码见https://github.com/karin0018/GraphPrompter。
            arXiv:2505.02027v1 Announce Type: new 
Abstract: Graph In-Context Learning, with the ability to adapt pre-trained graph models to novel and diverse downstream graphs without updating any parameters, has gained much attention in the community. The key to graph in-context learning is to perform downstream graphs conditioned on chosen prompt examples. Existing methods randomly select subgraphs or edges as prompts, leading to noisy graph prompts and inferior model performance. Additionally, due to the gap between pre-training and testing graphs, when the number of classes in the testing graphs is much greater than that in the training, the in-context learning ability will also significantly deteriorate. To tackle the aforementioned challenges, we develop a multi-stage adaptive prompt optimization method GraphPrompter, which optimizes the entire process of generating, selecting, and using graph prompts for better in-context learning capabilities. Firstly, Prompt Generator introduces a reconstruction layer to highlight the most informative edges and reduce irrelevant noise for graph prompt construction. Furthermore, in the selection stage, Prompt Selector employs the $k$-nearest neighbors algorithm and pre-trained selection layers to dynamically choose appropriate samples and minimize the influence of irrelevant prompts. Finally, we leverage a Prompt Augmenter with a cache replacement strategy to enhance the generalization capability of the pre-trained model on new datasets. Extensive experiments show that GraphPrompter effectively enhances the in-context learning ability of graph models. On average across all the settings, our approach surpasses the state-of-the-art baselines by over 8%. Our code is released at https://github.com/karin0018/GraphPrompter.
        ]]></description>
    </item>
    <item>
        <title>GRAIL: Graph Edit Distance and Node Alignment Using LLM-Generated Code</title>
        <link>https://arxiv.org/abs/2505.02124</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.02124v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Samidha Verma, Arushi Goyal, Ananya Mathur, Ankit Anand, Sayan Ranu</dc:creator>
        <description><![CDATA[
            背景：图编辑距离（GED）计算最优值是NP难问题，现有神经方法虽提升近似质量，但存在需大量难计算的真实数据、缺乏可解释性和跨域泛化能力等挑战。方法：提出GRAIL，结合大语言模型和自动提示调优生成用于计算GED的程序。效果：在七个数据集上的实验表明，GRAIL在预测质量上超越了现有GED近似方法，且在不同图分布上实现了强大的跨域泛化。
            arXiv:2505.02124v1 Announce Type: new 
Abstract: Graph Edit Distance (GED) is a widely used metric for measuring similarity between two graphs. Computing the optimal GED is NP-hard, leading to the development of various neural and non-neural heuristics. While neural methods have achieved improved approximation quality compared to non-neural approaches, they face significant challenges: (1) They require large amounts of ground truth data, which is itself NP-hard to compute. (2) They operate as black boxes, offering limited interpretability. (3) They lack cross-domain generalization, necessitating expensive retraining for each new dataset. We address these limitations with GRAIL, introducing a paradigm shift in this domain. Instead of training a neural model to predict GED, GRAIL employs a novel combination of large language models (LLMs) and automated prompt tuning to generate a program that is used to compute GED. This shift from predicting GED to generating programs imparts various advantages, including end-to-end interpretability and an autonomous self-evolutionary learning mechanism without ground-truth supervision. Extensive experiments on seven datasets confirm that GRAIL not only surpasses state-of-the-art GED approximation methods in prediction quality but also achieves robust cross-domain generalization across diverse graph distributions.
        ]]></description>
    </item>
    <item>
        <title>Efficient Multivariate Time Series Forecasting via Calibrated Language Models with Privileged Knowledge Distillation</title>
        <link>https://arxiv.org/abs/2505.02138</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.02138v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chenxi Liu, Shaowen Zhou, Hao Miao, Qianxiong Xu, Cheng Long, Ziyue Li, Rui Zhao</dc:creator>
        <description><![CDATA[
            多元时间序列预测（MTSF）在时间序列数据管理系统中至关重要。现有研究用文本提示调优将大语言模型（LLMs）知识融入MTSF，但LLMs推理效率低。为此提出TimeKD框架，利用校准语言模型和特权知识蒸馏。通过跨模态教师模型生成高质量未来表征，用减法交叉注意力机制优化；采用特权知识蒸馏机制培养学生模型，使其复制教师模型行为并减少输出差异。真实数据实验证明了TimeKD的有效性、效率和可扩展性。
            arXiv:2505.02138v1 Announce Type: new 
Abstract: Multivariate time series forecasting (MTSF) endeavors to predict future observations given historical data, playing a crucial role in time series data management systems. With advancements in large language models (LLMs), recent studies employ textual prompt tuning to infuse the knowledge of LLMs into MTSF. However, the deployment of LLMs often suffers from low efficiency during the inference phase. To address this problem, we introduce TimeKD, an efficient MTSF framework that leverages the calibrated language models and privileged knowledge distillation. TimeKD aims to generate high-quality future representations from the proposed cross-modality teacher model and cultivate an effective student model. The cross-modality teacher model adopts calibrated language models (CLMs) with ground truth prompts, motivated by the paradigm of Learning Under Privileged Information (LUPI). In addition, we design a subtractive cross attention (SCA) mechanism to refine these representations. To cultivate an effective student model, we propose an innovative privileged knowledge distillation (PKD) mechanism including correlation and feature distillation. PKD enables the student to replicate the teacher's behavior while minimizing their output discrepancy. Extensive experiments on real data offer insight into the effectiveness, efficiency, and scalability of the proposed TimeKD.
        ]]></description>
    </item>
    <item>
        <title>Incorporating Legal Structure in Retrieval-Augmented Generation: A Case Study on Copyright Fair Use</title>
        <link>https://arxiv.org/abs/2505.02164</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.02164v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Justin Ho, Alexandra Colby, William Fisher</dc:creator>
        <description><![CDATA[
            背景：DMCA下架情况增多，内容创作者缺乏可用法律支持。方法：提出结合语义搜索、法律知识图谱和法院引用网络的结构化方法，在法定因素层面建模法律先例，引入引用加权图表示，采用思维链推理和交错检索步骤。效果：初步测试显示该方法提高了检索过程中的教义相关性，为基于大语言模型的法律辅助工具的评估和部署奠定基础。
            arXiv:2505.02164v1 Announce Type: new 
Abstract: This paper presents a domain-specific implementation of Retrieval-Augmented Generation (RAG) tailored to the Fair Use Doctrine in U.S. copyright law. Motivated by the increasing prevalence of DMCA takedowns and the lack of accessible legal support for content creators, we propose a structured approach that combines semantic search with legal knowledge graphs and court citation networks to improve retrieval quality and reasoning reliability. Our prototype models legal precedents at the statutory factor level (e.g., purpose, nature, amount, market effect) and incorporates citation-weighted graph representations to prioritize doctrinally authoritative sources. We use Chain-of-Thought reasoning and interleaved retrieval steps to better emulate legal reasoning. Preliminary testing suggests this method improves doctrinal relevance in the retrieval process, laying groundwork for future evaluation and deployment of LLM-based legal assistance tools.
        ]]></description>
    </item>
    <item>
        <title>A New HOPE: Domain-agnostic Automatic Evaluation of Text Chunking</title>
        <link>https://arxiv.org/abs/2505.02171</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.02171v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Henrik Br{\aa}dland, Morten Goodwin, Per-Arne Andersen, Alexander S. Nossum, Aditya Gupta</dc:creator>
        <description><![CDATA[
            背景：文档分块影响检索增强生成（RAG），但目前缺乏分析不同分块方法影响的框架。方法：本文从内在段落属性、外在段落属性和段落 - 文档连贯性三个层面定义分块过程的关键特征，提出领域无关的自动评估指标HOPE来量化并整合这些特征。效果：在七个领域的实证评估显示，HOPE指标与多种RAG性能指标显著相关，段落语义独立对系统性能至关重要，事实正确性提升达56.2%，答案正确性提升21.1%，而传统的段落概念统一假设影响极小。
            arXiv:2505.02171v1 Announce Type: new 
Abstract: Document chunking fundamentally impacts Retrieval-Augmented Generation (RAG) by determining how source materials are segmented before indexing. Despite evidence that Large Language Models (LLMs) are sensitive to the layout and structure of retrieved data, there is currently no framework to analyze the impact of different chunking methods. In this paper, we introduce a novel methodology that defines essential characteristics of the chunking process at three levels: intrinsic passage properties, extrinsic passage properties, and passages-document coherence. We propose HOPE (Holistic Passage Evaluation), a domain-agnostic, automatic evaluation metric that quantifies and aggregates these characteristics. Our empirical evaluations across seven domains demonstrate that the HOPE metric correlates significantly (p > 0.13) with various RAG performance indicators, revealing contrasts between the importance of extrinsic and intrinsic properties of passages. Semantic independence between passages proves essential for system performance with a performance gain of up to 56.2% in factual correctness and 21.1% in answer correctness. On the contrary, traditional assumptions about maintaining concept unity within passages show minimal impact. These findings provide actionable insights for optimizing chunking strategies, thus improving RAG system design to produce more factually correct responses.
        ]]></description>
    </item>
    <item>
        <title>DNAZEN: Enhanced Gene Sequence Representations via Mixed Granularities of Coding Units</title>
        <link>https://arxiv.org/abs/2505.02206</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.02206v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Lei Mao, Yuanhe Tian, Yan Song</dc:creator>
        <description><![CDATA[
            背景：传统基因组建模将基因序列视为语言，但现有方法未充分考虑其内在信息组织和不同粒度单元对表征的贡献。方法：提出DNAZEN框架，从基因序列的不同粒度学习，通过无监督方法从大规模基因组语料库提取G - gram构建词汇表，用Transformer的G - gram编码器计算表征并集成到基础单元编码器，还提出全G - gram掩码训练模型。效果：在基准数据集的下游任务实验证明了DNAZEN的有效性。
            arXiv:2505.02206v1 Announce Type: new 
Abstract: Genome modeling conventionally treats gene sequence as a language, reflecting its structured motifs and long-range dependencies analogous to linguistic units and organization principles such as words and syntax. Recent studies utilize advanced neural networks, ranging from convolutional and recurrent models to Transformer-based models, to capture contextual information of gene sequence, with the primary goal of obtaining effective gene sequence representations and thus enhance the models' understanding of various running gene samples. However, these approaches often directly apply language modeling techniques to gene sequences and do not fully consider the intrinsic information organization in them, where they do not consider how units at different granularities contribute to representation. In this paper, we propose DNAZEN, an enhanced genomic representation framework designed to learn from various granularities in gene sequences, including small polymers and G-grams that are combinations of several contiguous polymers. Specifically, we extract the G-grams from large-scale genomic corpora through an unsupervised approach to construct the G-gram vocabulary, which is used to provide G-grams in the learning process of DNA sequences through dynamically matching from running gene samples. A Transformer-based G-gram encoder is also proposed and the matched G-grams are fed into it to compute their representations and integrated into the encoder for basic unit (E4BU), which is responsible for encoding small units and maintaining the learning and inference process. To further enhance the learning process, we propose whole G-gram masking to train DNAZEN, where the model largely favors the selection of each entire G-gram to mask rather than an ordinary masking mechanism performed on basic units. Experiments on benchmark datasets demonstrate the effectiveness of DNAZEN on various downstream tasks.
        ]]></description>
    </item>
    <item>
        <title>RM-R1: Reward Modeling as Reasoning</title>
        <link>https://arxiv.org/abs/2505.02387</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.02387v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiusi Chen, Gaotang Li, Ziqi Wang, Bowen Jin, Cheng Qian, Yu Wang, Hongru Wang, Yu Zhang, Denghui Zhang, Tong Zhang, Hanghang Tong, Heng Ji</dc:creator>
        <description><![CDATA[
            背景：奖励建模对大语言模型与人类偏好对齐至关重要，但现有奖励模型缺乏可解释性。方法：受长思维链在推理密集型任务进展的启发，提出将奖励建模作为推理任务的推理奖励模型RM - R1，采用面向推理的训练管道，包括高质量推理链蒸馏和可验证奖励的强化学习两个阶段。效果：在多个奖励模型基准测试中达到或接近最优性能，比更大的开放权重模型和专有模型最高高出13.8%。
            arXiv:2505.02387v1 Announce Type: new 
Abstract: Reward modeling is essential for aligning large language models (LLMs) with human preferences, especially through reinforcement learning from human feedback (RLHF). To provide accurate reward signals, a reward model (RM) should stimulate deep thinking and conduct interpretable reasoning before assigning a score or a judgment. However, existing RMs either produce opaque scalar scores or directly generate the prediction of a preferred answer, making them struggle to integrate natural language critiques, thus lacking interpretability. Inspired by recent advances of long chain-of-thought (CoT) on reasoning-intensive tasks, we hypothesize and validate that integrating reasoning capabilities into reward modeling significantly enhances RM's interpretability and performance. In this work, we introduce a new class of generative reward models -- Reasoning Reward Models (ReasRMs) -- which formulate reward modeling as a reasoning task. We propose a reasoning-oriented training pipeline and train a family of ReasRMs, RM-R1. The training consists of two key stages: (1) distillation of high-quality reasoning chains and (2) reinforcement learning with verifiable rewards. RM-R1 improves LLM rollouts by self-generating reasoning traces or chat-specific rubrics and evaluating candidate responses against them. Empirically, our models achieve state-of-the-art or near state-of-the-art performance of generative RMs across multiple comprehensive reward model benchmarks, outperforming much larger open-weight models (e.g., Llama3.1-405B) and proprietary ones (e.g., GPT-4o) by up to 13.8%. Beyond final performance, we perform thorough empirical analysis to understand the key ingredients of successful ReasRM training. To facilitate future research, we release six ReasRM models along with code and data at https://github.com/RM-R1-UIUC/RM-R1.
        ]]></description>
    </item>
    <item>
        <title>Optimizing Chain-of-Thought Reasoners via Gradient Variance Minimization in Rejection Sampling and RL</title>
        <link>https://arxiv.org/abs/2505.02391</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.02391v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiarui Yao, Yifan Hao, Hanning Zhang, Hanze Dong, Wei Xiong, Nan Jiang, Tong Zhang</dc:creator>
        <description><![CDATA[
            背景：大语言模型的思维链推理可看作潜在变量问题，但现有方法采用统一推理预算，未考虑难度和收敛行为差异，且静态采样策略导致随机梯度估计效率低。方法：提出GVM - RAFT，一种特定提示的动态样本分配策略，通过监控提示接受率和随机梯度范数动态分配计算资源，以最小化随机梯度方差。效果：理论分析表明该策略在合适条件下可加速收敛，数学推理实验显示其比原始RAFT提速2 - 4倍，且精度显著提升，还可用于其他强化学习算法带来类似效果。
            arXiv:2505.02391v1 Announce Type: new 
Abstract: Chain-of-thought (CoT) reasoning in large language models (LLMs) can be formalized as a latent variable problem, where the model needs to generate intermediate reasoning steps. While prior approaches such as iterative reward-ranked fine-tuning (RAFT) have relied on such formulations, they typically apply uniform inference budgets across prompts, which fails to account for variability in difficulty and convergence behavior. This work identifies the main bottleneck in CoT training as inefficient stochastic gradient estimation due to static sampling strategies. We propose GVM-RAFT, a prompt-specific Dynamic Sample Allocation Strategy designed to minimize stochastic gradient variance under a computational budget constraint. The method dynamically allocates computational resources by monitoring prompt acceptance rates and stochastic gradient norms, ensuring that the resulting gradient variance is minimized. Our theoretical analysis shows that the proposed dynamic sampling strategy leads to accelerated convergence guarantees under suitable conditions. Experiments on mathematical reasoning show that GVM-RAFT achieves a 2-4x speedup and considerable accuracy improvements over vanilla RAFT. The proposed dynamic sampling strategy is general and can be incorporated into other reinforcement learning algorithms, such as GRPO, leading to similar improvements in convergence and test accuracy. Our code is available at https://github.com/RLHFlow/GVM.
        ]]></description>
    </item>
    <item>
        <title>T2S: High-resolution Time Series Generation with Text-to-Series Diffusion Models</title>
        <link>https://arxiv.org/abs/2505.02417</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.02417v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yunfeng Ge, Jiawei Li, Yiji Zhao, Haomin Wen, Zhao Li, Meikang Qiu, Hongyan Li, Ming Jin, Shirui Pan</dc:creator>
        <description><![CDATA[
            文本到时间序列生成有潜力解决数据稀疏等问题，但扩散模型在时间序列生成的应用尚处起步阶段，现有方法存在缺乏通用时间序列描述探索、无法生成任意长度序列的局限。本文将时间序列描述分为三个级别，引入新的片段级数据集。提出基于扩散的T2S框架，用长度自适应变分自编码器编码不同长度序列，通过流匹配和扩散变换器对齐文本与潜在嵌入，以交错范式训练。实验表明，T2S在12个领域的13个数据集上达最优性能。
            arXiv:2505.02417v1 Announce Type: new 
Abstract: Text-to-Time Series generation holds significant potential to address challenges such as data sparsity, imbalance, and limited availability of multimodal time series datasets across domains. While diffusion models have achieved remarkable success in Text-to-X (e.g., vision and audio data) generation, their use in time series generation remains in its nascent stages. Existing approaches face two critical limitations: (1) the lack of systematic exploration of general-proposed time series captions, which are often domain-specific and struggle with generalization; and (2) the inability to generate time series of arbitrary lengths, limiting their applicability to real-world scenarios. In this work, we first categorize time series captions into three levels: point-level, fragment-level, and instance-level. Additionally, we introduce a new fragment-level dataset containing over 600,000 high-resolution time series-text pairs. Second, we propose Text-to-Series (T2S), a diffusion-based framework that bridges the gap between natural language and time series in a domain-agnostic manner. T2S employs a length-adaptive variational autoencoder to encode time series of varying lengths into consistent latent embeddings. On top of that, T2S effectively aligns textual representations with latent embeddings by utilizing Flow Matching and employing Diffusion Transformer as the denoiser. We train T2S in an interleaved paradigm across multiple lengths, allowing it to generate sequences of any desired length. Extensive evaluations demonstrate that T2S achieves state-of-the-art performance across 13 datasets spanning 12 domains.
        ]]></description>
    </item>
    <item>
        <title>SEFE: Superficial and Essential Forgetting Eliminator for Multimodal Continual Instruction Tuning</title>
        <link>https://arxiv.org/abs/2505.02486</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.02486v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jinpeng Chen, Runmin Cong, Yuzhi Zhao, Hongzheng Yang, Guangneng Hu, Horace Ho Shing Ip, Sam Kwong</dc:creator>
        <description><![CDATA[
            背景：多模态持续指令微调（MCIT）旨在让多模态大语言模型（MLLMs）增量学习新任务且避免灾难性遗忘，遗忘可分为表面遗忘和本质遗忘。方法：先引入答案风格多样化（ASD）范式，统一不同任务训练集风格以防止表面遗忘；在此基础上提出RegLoRA，通过正则化稳定存储先验知识的关键参数，减轻本质遗忘。效果：整体方法SEFE达到了当前最优性能。
            arXiv:2505.02486v1 Announce Type: new 
Abstract: Multimodal Continual Instruction Tuning (MCIT) aims to enable Multimodal Large Language Models (MLLMs) to incrementally learn new tasks without catastrophic forgetting. In this paper, we explore forgetting in this context, categorizing it into superficial forgetting and essential forgetting. Superficial forgetting refers to cases where the model's knowledge may not be genuinely lost, but its responses to previous tasks deviate from expected formats due to the influence of subsequent tasks' answer styles, making the results unusable. By contrast, essential forgetting refers to situations where the model provides correctly formatted but factually inaccurate answers, indicating a true loss of knowledge. Assessing essential forgetting necessitates addressing superficial forgetting first, as severe superficial forgetting can obscure the model's knowledge state. Hence, we first introduce the Answer Style Diversification (ASD) paradigm, which defines a standardized process for transforming data styles across different tasks, unifying their training sets into similarly diversified styles to prevent superficial forgetting caused by style shifts. Building on this, we propose RegLoRA to mitigate essential forgetting. RegLoRA stabilizes key parameters where prior knowledge is primarily stored by applying regularization, enabling the model to retain existing competencies. Experimental results demonstrate that our overall method, SEFE, achieves state-of-the-art performance.
        ]]></description>
    </item>
    <item>
        <title>Robustness questions the interpretability of graph neural networks: what to do?</title>
        <link>https://arxiv.org/abs/2505.02566</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.02566v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kirill Lukyanov (ISP RAS Research Center for Trusted Artificial Intelligence, Ivannikov Institute for System Programming of the Russian Academy of Sciences, Moscow Institute of Physics and Technology), Georgii Sazonov (Ivannikov Institute for System Programming of the Russian Academy of Sciences, Lomonosov Moscow State University), Serafim Boyarsky (Yandex School of Data Analysis), Ilya Makarov (1 v 5)</dc:creator>
        <description><![CDATA[
            背景：图神经网络（GNN）在图数据处理中应用广泛，但模型可解释性与鲁棒性的关系，尤其是在对抗场景下，尚不明确。方法：本文构建综合基准，评估基于GCN、SAGE等的6种GNN架构，采用4种可解释性指标，研究对抗攻击防御机制对可解释性的影响。效果：不同防御方法和模型架构对可解释性影响差异显著。该研究为开发兼具鲁棒性和可解释性的GNN奠定基础，框架将开源。
            arXiv:2505.02566v1 Announce Type: new 
Abstract: Graph Neural Networks (GNNs) have become a cornerstone in graph-based data analysis, with applications in diverse domains such as bioinformatics, social networks, and recommendation systems. However, the interplay between model interpretability and robustness remains poorly understood, especially under adversarial scenarios like poisoning and evasion attacks. This paper presents a comprehensive benchmark to systematically analyze the impact of various factors on the interpretability of GNNs, including the influence of robustness-enhancing defense mechanisms.
  We evaluate six GNN architectures based on GCN, SAGE, GIN, and GAT across five datasets from two distinct domains, employing four interpretability metrics: Fidelity, Stability, Consistency, and Sparsity. Our study examines how defenses against poisoning and evasion attacks, applied before and during model training, affect interpretability and highlights critical trade-offs between robustness and interpretability. The framework will be published as open source.
  The results reveal significant variations in interpretability depending on the chosen defense methods and model architecture characteristics. By establishing a standardized benchmark, this work provides a foundation for developing GNNs that are both robust to adversarial threats and interpretable, facilitating trust in their deployment in sensitive applications.
        ]]></description>
    </item>
    <item>
        <title>Towards Cross-Modality Modeling for Time Series Analytics: A Survey in the LLM Era</title>
        <link>https://arxiv.org/abs/2505.02583</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.02583v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chenxi Liu, Shaowen Zhou, Qianxiong Xu, Hao Miao, Cheng Long, Ziyue Li, Rui Zhao</dc:creator>
        <description><![CDATA[
            背景：边缘设备产生大量时间序列数据，大语言模型（LLMs）因文本与时间序列的序列特性用于时间序列分析，但两者存在跨模态差距。方法：对基于LLMs的时间序列跨模态建模进行综述，将现有方法按文本数据类型分为四类，总结对齐和融合等跨模态策略，在多模态数据集实验探索文本数据与策略的有效组合。效果：为从业者和研究者提供参考，指出未来研究方向。
            arXiv:2505.02583v1 Announce Type: new 
Abstract: The proliferation of edge devices has generated an unprecedented volume of time series data across different domains, motivating various well-customized methods. Recently, Large Language Models (LLMs) have emerged as a new paradigm for time series analytics by leveraging the shared sequential nature of textual data and time series. However, a fundamental cross-modality gap between time series and LLMs exists, as LLMs are pre-trained on textual corpora and are not inherently optimized for time series. Many recent proposals are designed to address this issue. In this survey, we provide an up-to-date overview of LLMs-based cross-modality modeling for time series analytics. We first introduce a taxonomy that classifies existing approaches into four groups based on the type of textual data employed for time series modeling. We then summarize key cross-modality strategies, e.g., alignment and fusion, and discuss their applications across a range of downstream tasks. Furthermore, we conduct experiments on multimodal datasets from different application domains to investigate effective combinations of textual data and cross-modality strategies for enhancing time series analytics. Finally, we suggest several promising directions for future research. This survey is designed for a range of professionals, researchers, and practitioners interested in LLM-based time series modeling.
        ]]></description>
    </item>
    <item>
        <title>SCFormer: Structured Channel-wise Transformer with Cumulative Historical State for Multivariate Time Series Forecasting</title>
        <link>https://arxiv.org/abs/2505.02655</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.02655v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Shiwei Guo, Ziang Chen, Yupeng Ma, Yunfei Han, Yi Wang</dc:creator>
        <description><![CDATA[
            背景：Transformer模型在多变量时间序列预测中表现良好，但计算时间特征时缺乏时间约束，且未有效利用累积历史序列。方法：提出带累积历史状态的结构化通道Transformer（SCFormer），对Transformer内查询、键、值矩阵及全连接层的线性变换引入时间约束，用高阶多项式投影算子处理累积历史时间序列。效果：在多个真实数据集上实验表明，SCFormer显著优于主流基线模型，有效提升时间序列预测能力。代码见https://github.com/ShiweiGuo1995/SCFormer 。
            arXiv:2505.02655v1 Announce Type: new 
Abstract: The Transformer model has shown strong performance in multivariate time series forecasting by leveraging channel-wise self-attention. However, this approach lacks temporal constraints when computing temporal features and does not utilize cumulative historical series effectively.To address these limitations, we propose the Structured Channel-wise Transformer with Cumulative Historical state (SCFormer). SCFormer introduces temporal constraints to all linear transformations, including the query, key, and value matrices, as well as the fully connected layers within the Transformer. Additionally, SCFormer employs High-order Polynomial Projection Operators (HiPPO) to deal with cumulative historical time series, allowing the model to incorporate information beyond the look-back window during prediction. Extensive experiments on multiple real-world datasets demonstrate that SCFormer significantly outperforms mainstream baselines, highlighting its effectiveness in enhancing time series forecasting. The code is publicly available at https://github.com/ShiweiGuo1995/SCFormer
        ]]></description>
    </item>
    <item>
        <title>A Note on Statistically Accurate Tabular Data Generation Using Large Language Models</title>
        <link>https://arxiv.org/abs/2505.02659</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.02659v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Andrey Sidorenko</dc:creator>
        <description><![CDATA[
            背景：大语言模型在合成表格数据生成方面有前景，但现有方法难以保留复杂特征依赖，尤其是分类变量间的依赖。方法：引入概率驱动的提示方法，利用大语言模型估计条件分布，实现更准确、可扩展的数据合成。效果：结果表明，提示概率分布可提高大语言模型生成表格数据的统计保真度，能更好地保留特征依赖。
            arXiv:2505.02659v1 Announce Type: new 
Abstract: Large language models (LLMs) have shown promise in synthetic tabular data generation, yet existing methods struggle to preserve complex feature dependencies, particularly among categorical variables. This work introduces a probability-driven prompting approach that leverages LLMs to estimate conditional distributions, enabling more accurate and scalable data synthesis. The results highlight the potential of prompting probobility distributions to enhance the statistical fidelity of LLM-generated tabular data.
        ]]></description>
    </item>
    <item>
        <title>Structure Causal Models and LLMs Integration in Medical Visual Question Answering</title>
        <link>https://arxiv.org/abs/2505.02703</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.02703v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zibo Xu, Qiang Li, Weizhi Nie, Weijie Wang, Anan Liu</dc:creator>
        <description><![CDATA[
            背景：医学视觉问答（MedVQA）因医学数据复杂存在图像与问题间的偏差，难以推断有医学意义的答案。方法：提出因果推理框架，引入新的因果图结构表示视觉与文本元素交互，用互信息发现虚假关联，提出多变量重采样前门调整法消除相对混淆效应；还采用结合多种提示形式的提示策略。效果：在三个MedVQA数据集上，显著提高了问答准确性，且在复杂医学数据下实现了真正的因果关联。
            arXiv:2505.02703v1 Announce Type: new 
Abstract: Medical Visual Question Answering (MedVQA) aims to answer medical questions according to medical images. However, the complexity of medical data leads to confounders that are difficult to observe, so bias between images and questions is inevitable. Such cross-modal bias makes it challenging to infer medically meaningful answers. In this work, we propose a causal inference framework for the MedVQA task, which effectively eliminates the relative confounding effect between the image and the question to ensure the precision of the question-answering (QA) session. We are the first to introduce a novel causal graph structure that represents the interaction between visual and textual elements, explicitly capturing how different questions influence visual features. During optimization, we apply the mutual information to discover spurious correlations and propose a multi-variable resampling front-door adjustment method to eliminate the relative confounding effect, which aims to align features based on their true causal relevance to the question-answering task. In addition, we also introduce a prompt strategy that combines multiple prompt forms to improve the model's ability to understand complex medical data and answer accurately. Extensive experiments on three MedVQA datasets demonstrate that 1) our method significantly improves the accuracy of MedVQA, and 2) our method achieves true causal correlations in the face of complex medical data.
        ]]></description>
    </item>
    <item>
        <title>Knowledge Graphs for Enhancing Large Language Models in Entity Disambiguation</title>
        <link>https://arxiv.org/abs/2505.02737</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.02737v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Pons Gerard, Bilalli Besim, Queralt Anna</dc:creator>
        <description><![CDATA[
            背景：大语言模型在自然语言处理任务中表现突出，但存在幻觉、知识过时或缺失等问题，重新训练成本高。方法：提出用知识图谱（KGs）这一结构化外部信息源增强大语言模型进行零样本实体消歧（ED），利用KG中实体类的层次表示逐步缩减候选空间，用实体描述丰富输入提示。效果：在流行ED数据集上，该方法优于未增强和仅用描述增强的大模型，比特定任务模型适应性更强。
            arXiv:2505.02737v1 Announce Type: new 
Abstract: Recent advances in Large Language Models (LLMs) have positioned them as a prominent solution for Natural Language Processing tasks. Notably, they can approach these problems in a zero or few-shot manner, thereby eliminating the need for training or fine-tuning task-specific models. However, LLMs face some challenges, including hallucination and the presence of outdated knowledge or missing information from specific domains in the training data. These problems cannot be easily solved by retraining the models with new data as it is a time-consuming and expensive process. To mitigate these issues, Knowledge Graphs (KGs) have been proposed as a structured external source of information to enrich LLMs. With this idea, in this work we use KGs to enhance LLMs for zero-shot Entity Disambiguation (ED). For that purpose, we leverage the hierarchical representation of the entities' classes in a KG to gradually prune the candidate space as well as the entities' descriptions to enrich the input prompt with additional factual knowledge. Our evaluation on popular ED datasets shows that the proposed method outperforms non-enhanced and description-only enhanced LLMs, and has a higher degree of adaptability than task-specific models. Furthermore, we conduct an error analysis and discuss the impact of the leveraged KG's semantic expressivity on the ED performance.
        ]]></description>
    </item>
    <item>
        <title>Using Knowledge Graphs to harvest datasets for efficient CLIP model training</title>
        <link>https://arxiv.org/abs/2505.02746</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.02746v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Simon Ging, Sebastian Walter, Jelena Bratuli\'c, Johannes Dienert, Hannah Bast, Thomas Brox</dc:creator>
        <description><![CDATA[
            背景：训练高质量CLIP模型需大量数据集，限制特定领域模型发展并增加成本。方法：采用知识图谱增强的智能网络搜索策略，可在数据量大幅减少的情况下从头训练稳健的CLIP模型，还引入包含3300万张图像和4600万条文本描述的EntityNet数据集。效果：仅用1000万张图像就能构建生物体专家基础模型，且能大幅缩短通用CLIP模型的训练时间。
            arXiv:2505.02746v1 Announce Type: new 
Abstract: Training high-quality CLIP models typically requires enormous datasets, which limits the development of domain-specific models -- especially in areas that even the largest CLIP models do not cover well -- and drives up training costs. This poses challenges for scientific research that needs fine-grained control over the training procedure of CLIP models. In this work, we show that by employing smart web search strategies enhanced with knowledge graphs, a robust CLIP model can be trained from scratch with considerably less data. Specifically, we demonstrate that an expert foundation model for living organisms can be built using just 10M images. Moreover, we introduce EntityNet, a dataset comprising 33M images paired with 46M text descriptions, which enables the training of a generic CLIP model in significantly reduced time.
        ]]></description>
    </item>
    <item>
        <title>AOR: Anatomical Ontology-Guided Reasoning for Medical Large Multimodal Model in Chest X-Ray Interpretation</title>
        <link>https://arxiv.org/abs/2505.02830</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.02830v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qingqiu Li, Zihang Cui, Seongsu Bae, Jilan Xu, Runtian Yuan, Yuejie Zhang, Rui Feng, Quanli Shen, Xiaobo Zhang, Junjun He, Shujun Wang</dc:creator>
        <description><![CDATA[
            背景：胸部X光检查常见，大多模态模型虽可实现自动解读，但当前医学大多模态模型存在区域级理解和交互不足、单步推理导致准确性和可解释性有限的问题。方法：提出以解剖学本体引导推理（AOR）框架，聚焦跨模态区域级信息以实现多步推理，还开发用于模型训练的AOR指令大型数据集。效果：实验表明AOR在视觉问答和报告生成任务中表现出色。 
            arXiv:2505.02830v1 Announce Type: new 
Abstract: Chest X-rays (CXRs) are the most frequently performed imaging examinations in clinical settings. Recent advancements in Large Multimodal Models (LMMs) have enabled automated CXR interpretation, enhancing diagnostic accuracy and efficiency. However, despite their strong visual understanding, current Medical LMMs (MLMMs) still face two major challenges: (1) Insufficient region-level understanding and interaction, and (2) Limited accuracy and interpretability due to single-step reasoning. In this paper, we empower MLMMs with anatomy-centric reasoning capabilities to enhance their interactivity and explainability. Specifically, we first propose an Anatomical Ontology-Guided Reasoning (AOR) framework, which centers on cross-modal region-level information to facilitate multi-step reasoning. Next, under the guidance of expert physicians, we develop AOR-Instruction, a large instruction dataset for MLMMs training. Our experiments demonstrate AOR's superior performance in both VQA and report generation tasks.
        ]]></description>
    </item>
    <item>
        <title>R1-Reward: Training Multimodal Reward Model Through Stable Reinforcement Learning</title>
        <link>https://arxiv.org/abs/2505.02835</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.02835v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yi-Fan Zhang, Xingyu Lu, Xiao Hu, Chaoyou Fu, Bin Wen, Tianke Zhang, Changyi Liu, Kaiyu Jiang, Kaibing Chen, Kaiyu Tang, Haojie Ding, Jiankang Chen, Fan Yang, Zhang Zhang, Tingting Gao, Liang Wang</dc:creator>
        <description><![CDATA[
            背景：多模态奖励模型（MRMs）对提升多模态大语言模型（MLLMs）性能至关重要，但在奖励建模的长期推理能力及激活方法上探索有限。方法：将奖励建模问题转化为基于规则的强化学习（RL）任务，提出StableReinforce算法优化现有RL方法的训练损失、优势估计策略和奖励设计，还收集200K偏好数据用于训练。效果：基于该算法训练的R1 - Reward模型在多模态奖励建模基准测试中表现出色，在VL Reward - Bench和Multimodal Reward Bench上分别比之前的SOTA模型提升8.4%和14.3%，且增加推理计算量可进一步提升性能。
            arXiv:2505.02835v1 Announce Type: new 
Abstract: Multimodal Reward Models (MRMs) play a crucial role in enhancing the performance of Multimodal Large Language Models (MLLMs). While recent advancements have primarily focused on improving the model structure and training data of MRMs, there has been limited exploration into the effectiveness of long-term reasoning capabilities for reward modeling and how to activate these capabilities in MRMs. In this paper, we explore how Reinforcement Learning (RL) can be used to improve reward modeling. Specifically, we reformulate the reward modeling problem as a rule-based RL task. However, we observe that directly applying existing RL algorithms, such as Reinforce++, to reward modeling often leads to training instability or even collapse due to the inherent limitations of these algorithms. To address this issue, we propose the StableReinforce algorithm, which refines the training loss, advantage estimation strategy, and reward design of existing RL methods. These refinements result in more stable training dynamics and superior performance. To facilitate MRM training, we collect 200K preference data from diverse datasets. Our reward model, R1-Reward, trained using the StableReinforce algorithm on this dataset, significantly improves performance on multimodal reward modeling benchmarks. Compared to previous SOTA models, R1-Reward achieves a $8.4\%$ improvement on the VL Reward-Bench and a $14.3\%$ improvement on the Multimodal Reward Bench. Moreover, with more inference compute, R1-Reward's performance is further enhanced, highlighting the potential of RL algorithms in optimizing MRMs.
        ]]></description>
    </item>
    <item>
        <title>A Multi-Granularity Multimodal Retrieval Framework for Multimodal Document Tasks</title>
        <link>https://arxiv.org/abs/2505.01457</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.01457v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mingjun Xu, Zehui Wang, Hengxing Cai, Renxin Zhong</dc:creator>
        <description><![CDATA[
            背景：现有检索增强生成（RAG）系统多聚焦文本检索，处理含文本、图像等的富视觉文档效果不佳。方法：提出统一的多粒度多模态检索框架，集成分层编码、模态感知检索机制和重排序模块，利用现成视觉语言模型和无训练混合检索策略。效果：无需特定任务微调，表现稳健。实验表明，加入布局感知搜索和重排序模块显著提升检索准确率，最高得分达65.56 。
            arXiv:2505.01457v1 Announce Type: cross 
Abstract: Retrieval-augmented generation (RAG) systems have predominantly focused on text-based retrieval, limiting their effectiveness in handling visually-rich documents that encompass text, images, tables, and charts. To bridge this gap, we propose a unified multi-granularity multimodal retrieval framework tailored for two benchmark tasks: MMDocIR and M2KR. Our approach integrates hierarchical encoding strategies, modality-aware retrieval mechanisms, and reranking modules to effectively capture and utilize the complex interdependencies between textual and visual modalities. By leveraging off-the-shelf vision-language models and implementing a training-free hybridretrieval strategy, our framework demonstrates robust performance without the need for task-specific fine-tuning. Experimental evaluations reveal that incorporating layout-aware search and reranking modules significantly enhances retrieval accuracy, achieving a top performance score of 65.56. This work underscores the potential of scalable and reproducible solutions in advancing multimodal document retrieval systems.
        ]]></description>
    </item>
    <item>
        <title>Structured Prompting and Feedback-Guided Reasoning with LLMs for Data Interpretation</title>
        <link>https://arxiv.org/abs/2505.01636</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.01636v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Amit Rath</dc:creator>
        <description><![CDATA[
            背景：大语言模型在自然语言理解和任务泛化方面表现出色，但在结构化数据分析中因模式解释不一致、用户意图与模型输出不匹配等问题而应用脆弱。方法：提出STROT框架，先进行轻量级模式自省和基于样本的字段分类，构建动态上下文，将其嵌入结构化提示引导模型生成特定任务的可解释输出，还引入基于执行反馈和验证信号的细化机制。效果：形成了一个可靠、可重复的大语言模型结构化数据推理框架，适用于对可解释性、稳定性和正确性要求高的任务。
            arXiv:2505.01636v1 Announce Type: cross 
Abstract: Large language models (LLMs) have demonstrated remarkable capabilities in natural language understanding and task generalization. However, their application to structured data analysis remains fragile due to inconsistencies in schema interpretation, misalignment between user intent and model output, and limited mechanisms for self-correction when failures occur. This paper introduces the STROT Framework (Structured Task Reasoning and Output Transformation), a method for structured prompting and feedback-driven transformation logic generation aimed at improving the reliability and semantic alignment of LLM-based analytical workflows. STROT begins with lightweight schema introspection and sample-based field classification, enabling dynamic context construction that captures both the structure and statistical profile of the input data. This contextual information is embedded in structured prompts that guide the model toward generating task-specific, interpretable outputs. To address common failure modes in complex queries, STROT incorporates a refinement mechanism in which the model iteratively revises its outputs based on execution feedback and validation signals. Unlike conventional approaches that rely on static prompts or single-shot inference, STROT treats the LLM as a reasoning agent embedded within a controlled analysis loop -- capable of adjusting its output trajectory through planning and correction. The result is a robust and reproducible framework for reasoning over structured data with LLMs, applicable to diverse data exploration and analysis tasks where interpretability, stability, and correctness are essential.
        ]]></description>
    </item>
    <item>
        <title>Attention Mechanisms Perspective: Exploring LLM Processing of Graph-Structured Data</title>
        <link>https://arxiv.org/abs/2505.02130</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.02130v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhong Guan, Likang Wu, Hongke Zhao, Ming He, Jianpin Fan</dc:creator>
        <description><![CDATA[
            背景：注意力机制对大语言模型（LLMs）很关键，但在处理图结构数据时，相比图神经网络（GNNs）的消息传递机制存在不足。方法：从注意力机制角度开展实证研究，探索LLMs如何处理图结构数据。效果：发现LLMs能识别图数据和捕捉文本 - 节点交互，但因架构限制难以建模节点间关系；其注意力分布与理想结构模式不符；全连接和固定连接注意力都有局限，中间状态注意力窗口可提升训练性能，推理时能无缝过渡到全连接窗口。
            arXiv:2505.02130v1 Announce Type: cross 
Abstract: Attention mechanisms are critical to the success of large language models (LLMs), driving significant advancements in multiple fields. However, for graph-structured data, which requires emphasis on topological connections, they fall short compared to message-passing mechanisms on fixed links, such as those employed by Graph Neural Networks (GNNs). This raises a question: ``Does attention fail for graphs in natural language settings?'' Motivated by these observations, we embarked on an empirical study from the perspective of attention mechanisms to explore how LLMs process graph-structured data. The goal is to gain deeper insights into the attention behavior of LLMs over graph structures. We uncovered unique phenomena regarding how LLMs apply attention to graph-structured data and analyzed these findings to improve the modeling of such data by LLMs. The primary findings of our research are: 1) While LLMs can recognize graph data and capture text-node interactions, they struggle to model inter-node relationships within graph structures due to inherent architectural constraints. 2) The attention distribution of LLMs across graph nodes does not align with ideal structural patterns, indicating a failure to adapt to graph topology nuances. 3) Neither fully connected attention nor fixed connectivity is optimal; each has specific limitations in its application scenarios. Instead, intermediate-state attention windows improve LLM training performance and seamlessly transition to fully connected windows during inference. Source code: \href{https://github.com/millioniron/LLM_exploration}{LLM4Exploration}
        ]]></description>
    </item>
    <item>
        <title>Estimating Commonsense Scene Composition on Belief Scene Graphs</title>
        <link>https://arxiv.org/abs/2505.02405</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.02405v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mario A. V. Saucedo, Vignesh Kottayam Viswanathan, Christoforos Kanellakis, George Nikolakopoulos</dc:creator>
        <description><![CDATA[
            背景：需理解场景中相关对象的空间关系。方法：提出常识场景组合概念，通过估计未见对象的空间分布扩展信念场景图，构建两种用于学习概率分布的相关信息（CECI）模型变体，包括基于图卷积网络的基线方法和集成大语言模型空间本体的神经符号扩展方法，还详述了数据集生成过程。效果：在模拟数据和真实室内环境中多次验证，能对不同类型房间场景进行空间解释。
            arXiv:2505.02405v1 Announce Type: cross 
Abstract: This work establishes the concept of commonsense scene composition, with a focus on extending Belief Scene Graphs by estimating the spatial distribution of unseen objects. Specifically, the commonsense scene composition capability refers to the understanding of the spatial relationships among related objects in the scene, which in this article is modeled as a joint probability distribution for all possible locations of the semantic object class. The proposed framework includes two variants of a Correlation Information (CECI) model for learning probability distributions: (i) a baseline approach based on a Graph Convolutional Network, and (ii) a neuro-symbolic extension that integrates a spatial ontology based on Large Language Models (LLMs). Furthermore, this article provides a detailed description of the dataset generation process for such tasks. Finally, the framework has been validated through multiple runs on simulated data, as well as in a real-world indoor environment, demonstrating its ability to spatially interpret scenes across different room types.
        ]]></description>
    </item>
    <item>
        <title>Recursive Decomposition with Dependencies for Generic Divide-and-Conquer Reasoning</title>
        <link>https://arxiv.org/abs/2505.02576</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.02576v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sergio Hern\'andez-Guti\'errez, Minttu Alakuijala, Alexander V. Nikitin, Pekka Marttinen</dc:creator>
        <description><![CDATA[
            背景：推理任务在多领域至关重要，大语言模型虽用思维链等技术取得进展，但在解决复杂问题时性能和执行时间不佳，且需额外监督。方法：提出带依赖的递归分解法（RDD），是可扩展的分治法，所需监督更少，能直接用于新问题，支持子任务依赖和错误恢复。效果：在两个各有六个难度级别的基准测试及两种上下文设置下评估，结果显示，随任务复杂度增加，RDD在计算匹配设置中优于其他方法，且计算效率更高。
            arXiv:2505.02576v1 Announce Type: cross 
Abstract: Reasoning tasks are crucial in many domains, especially in science and engineering. Although large language models (LLMs) have made progress in reasoning tasks using techniques such as chain-of-thought and least-to-most prompting, these approaches still do not effectively scale to complex problems in either their performance or execution time. Moreover, they often require additional supervision for each new task, such as in-context examples. In this work, we introduce Recursive Decomposition with Dependencies (RDD), a scalable divide-and-conquer method for solving reasoning problems that requires less supervision than prior approaches. Our method can be directly applied to a new problem class even in the absence of any task-specific guidance. Furthermore, RDD supports sub-task dependencies, allowing for ordered execution of sub-tasks, as well as an error recovery mechanism that can correct mistakes made in previous steps. We evaluate our approach on two benchmarks with six difficulty levels each and in two in-context settings: one with task-specific examples and one without. Our results demonstrate that RDD outperforms other methods in a compute-matched setting as task complexity increases, while also being more computationally efficient.
        ]]></description>
    </item>
    <item>
        <title>One Transformer for All Time Series: Representing and Training with Time-Dependent Heterogeneous Tabular Data</title>
        <link>https://arxiv.org/abs/2302.06375</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2302.06375v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Simone Luetto, Fabrizio Garuti, Enver Sangineto, Lorenzo Forni, Rita Cucchiara</dc:creator>
        <description><![CDATA[
            背景：近年来人们希望将深度学习技术应用于表格数据，以复制人工智能在该结构化领域的成功，但表格数据中分类元素与数值项混合的异质性使应用困难。方法：提出一种Transformer架构来表示异构的时间相关表格数据，用一组频率函数表示数值特征，并用单一损失函数统一训练整个网络。效果：摘要未提及具体效果定量指标。
            arXiv:2302.06375v4 Announce Type: replace 
Abstract: There is a recent growing interest in applying Deep Learning techniques to tabular data, in order to replicate the success of other Artificial Intelligence areas in this structured domain. Specifically interesting is the case in which tabular data have a time dependence, such as, for instance financial transactions. However, the heterogeneity of the tabular values, in which categorical elements are mixed with numerical items, makes this adaptation difficult. In this paper we propose a Transformer architecture to represent heterogeneous time-dependent tabular data, in which numerical features are represented using a set of frequency functions and the whole network is uniformly trained with a unique loss function.
        ]]></description>
    </item>
    <item>
        <title>Supercharging Graph Transformers with Advective Diffusion</title>
        <link>https://arxiv.org/abs/2310.06417</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2310.06417v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qitian Wu, Chenxiao Yang, Kaipeng Zeng, Michael Bronstein</dc:creator>
        <description><![CDATA[
            背景：现代学习系统成功的关键在于泛化能力，以往研究忽视了机器学习模型在拓扑结构变化下的泛化情况。方法：提出受物理启发的图Transformer模型AdvDIFFormer，其源于对流扩散方程，描述了具有观测和潜在拓扑结构的连续消息传递过程。效果：理论证明该模型能控制拓扑变化下的泛化误差，优于图扩散模型；在信息网络、分子筛选和蛋白质相互作用等预测任务中表现出色。
            arXiv:2310.06417v2 Announce Type: replace 
Abstract: The capability of generalization is a cornerstone for the success of modern learning systems. For non-Euclidean data, e.g., graphs, that particularly involves topological structures, one important aspect neglected by prior studies is how machine learning models generalize under topological shifts. This paper proposes AdvDIFFormer, a physics-inspired graph Transformer model designed to address this challenge. The model is derived from advective diffusion equations which describe a class of continuous message passing process with observed and latent topological structures. We show that AdvDIFFormer has provable capability for controlling generalization error with topological shifts, which in contrast cannot be guaranteed by graph diffusion models. Empirically, the model demonstrates superiority in various predictive tasks across information networks, molecular screening and protein interactions.
        ]]></description>
    </item>
    <item>
        <title>SMUTF: Schema Matching Using Generative Tags and Hybrid Features</title>
        <link>https://arxiv.org/abs/2402.01685</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2402.01685v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yu Zhang, Mei Di, Haozheng Luo, Chenwei Xu, Richard Tzong-Han Tsai</dc:creator>
        <description><![CDATA[
            背景：大规模表格数据模式匹配在开放域任务中需有效跨域匹配，且缺乏公开数据集。方法：提出SMUTF方法，结合基于规则的特征工程、预训练语言模型和生成式大语言模型，受Humanitarian Exchange Language启发部署“生成标签”，还创建并开源HDXSM数据集。效果：在多个公开数据集和HDXSM数据集评估中表现出色，超越现有模型，F1分数提高11.84%，ROC的AUC提高5.08%。
            arXiv:2402.01685v3 Announce Type: replace 
Abstract: We introduce SMUTF (Schema Matching Using Generative Tags and Hybrid Features), a unique approach for large-scale tabular data schema matching (SM), which assumes that supervised learning does not affect performance in open-domain tasks, thereby enabling effective cross-domain matching. This system uniquely combines rule-based feature engineering, pre-trained language models, and generative large language models. In an innovative adaptation inspired by the Humanitarian Exchange Language, we deploy "generative tags" for each data column, enhancing the effectiveness of SM. SMUTF exhibits extensive versatility, working seamlessly with any pre-existing pre-trained embeddings, classification methods, and generative models.
  Recognizing the lack of extensive, publicly available datasets for SM, we have created and open-sourced the HDXSM dataset from the public humanitarian data. We believe this to be the most exhaustive SM dataset currently available. In evaluations across various public datasets and the novel HDXSM dataset, SMUTF demonstrated exceptional performance, surpassing existing state-of-the-art models in terms of accuracy and efficiency, and improving the F1 score by 11.84% and the AUC of ROC by 5.08%. Code is available at https://github.com/fireindark707/Python-Schema-Matching.
        ]]></description>
    </item>
    <item>
        <title>Joint-Embedding Masked Autoencoder for Self-supervised Learning of Dynamic Functional Connectivity from the Human Brain</title>
        <link>https://arxiv.org/abs/2403.06432</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2403.06432v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jungwon Choi, Hyungi Lee, Byung-Hoon Kim, Juho Lee</dc:creator>
        <description><![CDATA[
            背景：图神经网络在学习人类大脑网络动态功能连接上有潜力，但获取大量标注临床数据困难。生成式自监督学习技术在动态图上应用待探索。方法：受计算机视觉中JEPA启发，提出时空联合嵌入掩码自编码器（ST - JEMA），采用JEPA策略重建动态图，从时间视角学习高层语义表征。效果：利用大规模UK Biobank数据集自监督学习，在动态功能连接表征学习上表现出色，在八个基准fMRI数据集预测表型和精神诊断上优于以往方法，对缺失数据的时间重建有效。
            arXiv:2403.06432v2 Announce Type: replace 
Abstract: Graph Neural Networks (GNNs) have shown promise in learning dynamic functional connectivity for distinguishing phenotypes from human brain networks. However, obtaining extensive labeled clinical data for training is often resource-intensive, making practical application difficult. Leveraging unlabeled data thus becomes crucial for representation learning in a label-scarce setting. Although generative self-supervised learning techniques, especially masked autoencoders, have shown promising results in representation learning in various domains, their application to dynamic graphs for dynamic functional connectivity remains underexplored, facing challenges in capturing high-level semantic representations. Here, we introduce the Spatio-Temporal Joint Embedding Masked Autoencoder (ST-JEMA), drawing inspiration from the Joint Embedding Predictive Architecture (JEPA) in computer vision. ST-JEMA employs a JEPA-inspired strategy for reconstructing dynamic graphs, which enables the learning of higher-level semantic representations considering temporal perspectives, addressing the challenges in fMRI data representation learning. Utilizing the large-scale UK Biobank dataset for self-supervised learning, ST-JEMA shows exceptional representation learning performance on dynamic functional connectivity demonstrating superiority over previous methods in predicting phenotypes and psychiatric diagnoses across eight benchmark fMRI datasets even with limited samples and effectiveness of temporal reconstruction on missing data scenarios. These findings highlight the potential of our approach as a robust representation learning method for leveraging label-scarce fMRI data.
        ]]></description>
    </item>
    <item>
        <title>Generative-Contrastive Heterogeneous Graph Neural Network</title>
        <link>https://arxiv.org/abs/2404.02810</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2404.02810v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yu Wang, Lei Sang, Yi Zhang, Yiwen Zhang, Xindong Wu</dc:creator>
        <description><![CDATA[
            背景：异构图能有效建模现实复杂关系，基于对比学习的异构图神经网络在下游任务有潜力，但数据增强受限，对比判别器有采样偏差且缺乏局部异质信息。方法：提出生成 - 对比异构图神经网络（GC - HGNN），包括用掩码自编码器的对比视图增强策略、生成难负样本的位置和语义感知正样本采样策略、捕获局部和全局信息的分层对比学习策略。效果：在八个真实数据集上与十七个基线模型对比，在节点分类和链接预测任务上超越最新基线模型。
            arXiv:2404.02810v3 Announce Type: replace 
Abstract: Heterogeneous Graphs (HGs) effectively model complex relationships in the real world through multi-type nodes and edges. In recent years, inspired by self-supervised learning (SSL), contrastive learning (CL)-based Heterogeneous Graphs Neural Networks (HGNNs) have shown great potential in utilizing data augmentation and contrastive discriminators for downstream tasks. However, data augmentation remains limited due to the graph data's integrity. Furthermore, the contrastive discriminators suffer from sampling bias and lack local heterogeneous information. To tackle the above limitations, we propose a novel Generative-Contrastive Heterogeneous Graph Neural Network (GC-HGNN). Specifically, we propose a heterogeneous graph generative learning method that enhances CL-based paradigm. This paradigm includes: 1) A contrastive view augmentation strategy using a masked autoencoder. 2) Position-aware and semantics-aware positive sample sampling strategy for generating hard negative samples. 3) A hierarchical contrastive learning strategy aimed at capturing local and global information. Furthermore, the hierarchical contrastive learning and sampling strategies aim to constitute an enhanced contrastive discriminator under the generative-contrastive perspective. Finally, we compare our model with seventeen baselines on eight real-world datasets. Our model outperforms the latest baselines on node classification and link prediction tasks.
        ]]></description>
    </item>
    <item>
        <title>M3-Jepa: Multimodal Alignment via Multi-directional MoE based on the JEPA framework</title>
        <link>https://arxiv.org/abs/2409.05929</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2409.05929v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hongyang Lei, Xiaolong Cheng, Dan Wang, Kun Fan, Qi Qin, Huazhen Huang, Yetao Wu, Qingqing Gu, Zhonglin Jiang, Yong Chen, Luo Ji</dc:creator>
        <description><![CDATA[
            背景：当前多模态对齐策略多在原令牌空间优化对齐，易导致信息偏差，而联合编码预测架构（JEPA）虽在潜在空间学习对齐损失，但在多模态场景应用有限。方法：提出可扩展的多模态对齐框架M3 - Jepa，用多向专家混合体（MoE）实现预测器，通过交替优化不同单向任务最大化互信息。效果：在不同模态和任务上达最优性能，能泛化到未见数据集和领域，训练和推理计算效率高，或为自监督学习和开放世界建模提供新范式。
            arXiv:2409.05929v4 Announce Type: replace 
Abstract: Current multimodal alignment strategies primarily use single or unified modality encoders, while optimizing the alignment on the original token space. Such a framework is easy to implement and incorporate with the pretrained knowledge, but might result in information bias. To deal with such issues, the joint encoding predictive architecture (JEPA) learns the alignment loss on the latent space, with a predictor to convert the input encoding to the output latent space. However, the application of JEPA in multimodal scenarios is limited so far. In this paper, we introduce M3-Jepa, a scalable multimodal alignment framework, with the predictor implemented by a multi-directional mixture of experts (MoE). We demonstrate the framework can maximize the mutual information with information theory derivations, by alternating the optimization between different uni-directional tasks. By thoroughly designed experiments, we show that M3-Jepa can obtain state-of-the-art performance on different modalities and tasks, generalize to unseen datasets and domains, and is computationally efficient in training and inference. Our study indicates that M3-Jepa might provide a new paradigm to self-supervised learning and open-world modeling.
        ]]></description>
    </item>
    <item>
        <title>T-JEPA: Augmentation-Free Self-Supervised Learning for Tabular Data</title>
        <link>https://arxiv.org/abs/2410.05016</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.05016v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hugo Thimonier, Jos\'e Lucas De Melo Costa, Fabrice Popineau, Arpad Rimmel, Bich-Li\^en Doan</dc:creator>
        <description><![CDATA[
            背景：自监督学习常用于预训练以提升下游任务表现，但为表格数据构建数据增强较难，这是结构化数据自监督学习的主要挑战。方法：提出无增强自监督学习方法T - JEPA，基于联合嵌入预测架构，在潜在空间预测同一样本不同特征子集的潜在表示，还引入正则化令牌用于模型训练。效果：实验表明，该方法在分类和回归任务上有显著提升，优于直接在原始数据空间训练的模型，部分方法表现超过或媲美传统方法，且能有效识别下游任务相关特征。
            arXiv:2410.05016v3 Announce Type: replace 
Abstract: Self-supervision is often used for pre-training to foster performance on a downstream task by constructing meaningful representations of samples. Self-supervised learning (SSL) generally involves generating different views of the same sample and thus requires data augmentations that are challenging to construct for tabular data. This constitutes one of the main challenges of self-supervision for structured data. In the present work, we propose a novel augmentation-free SSL method for tabular data. Our approach, T-JEPA, relies on a Joint Embedding Predictive Architecture (JEPA) and is akin to mask reconstruction in the latent space. It involves predicting the latent representation of one subset of features from the latent representation of a different subset within the same sample, thereby learning rich representations without augmentations. We use our method as a pre-training technique and train several deep classifiers on the obtained representation. Our experimental results demonstrate a substantial improvement in both classification and regression tasks, outperforming models trained directly on samples in their original data space. Moreover, T-JEPA enables some methods to consistently outperform or match the performance of traditional methods likes Gradient Boosted Decision Trees. To understand why, we extensively characterize the obtained representations and show that T-JEPA effectively identifies relevant features for downstream tasks without access to the labels. Additionally, we introduce regularization tokens, a novel regularization method critical for training of JEPA-based models on structured data.
        ]]></description>
    </item>
    <item>
        <title>Unveiling the Mechanisms of Explicit CoT Training: How CoT Enhances Reasoning Generalization</title>
        <link>https://arxiv.org/abs/2502.04667</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.04667v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xinhao Yao, Ruifeng Ren, Yun Liao, Yong Liu</dc:creator>
        <description><![CDATA[
            背景：将显式思维链（CoT）推理融入大语言模型（LLM）训练提升了推理能力，但CoT增强泛化的机制尚不清楚。方法：通过对照实验和理论分析，研究CoT训练如何重塑模型内部表征以及为何能提升分布内（ID）和分布外（OOD）推理泛化能力。效果：发现CoT训练有结构优势，使模型在浅层解决中间结果；理论上能分解泛化界限。实验显示，CoT训练加速收敛，增强ID和OOD泛化，在复杂数据集上验证了结果，为设计CoT策略提供见解。
            arXiv:2502.04667v2 Announce Type: replace 
Abstract: The integration of explicit Chain-of-Thought (CoT) reasoning into training large language models (LLMs) has advanced their reasoning capabilities, yet the mechanisms by which CoT enhances generalization remain poorly understood. This work investigates (1) \textit{how} CoT training reshapes internal model representations and (2) \textit{why} it improves both in-distribution (ID) and out-of-distribution (OOD) reasoning generalization. Through controlled experiments and theoretical analysis, we derive the following key insights. \textbf{1)} Structural Advantage: CoT training internalizes reasoning into a two-stage generalizing circuit, where the number of stages corresponds to the explicit reasoning steps during training. Notably, CoT-trained models resolve intermediate results at shallower layers compared to non-CoT counterparts, freeing up deeper layers to specialize in subsequent reasoning steps. \textbf{2)} Theoretical Analysis: the information-theoretic generalization bounds via distributional divergence can be decomposed into ID and OOD components. While ID error diminishes with sufficient training regardless of CoT, OOD error critically depends on CoT: Non-CoT training fails to generalize to OOD samples due to unseen reasoning patterns, whereas CoT training achieves near-perfect OOD generalization by mastering subtasks and reasoning compositions during training. The identified mechanisms explain our experimental results: CoT training accelerates convergence and enhances generalization from ID to both ID and OOD scenarios while maintaining robust performance even with tolerable noise. These findings are further validated on complex real-world datasets. This paper offers valuable insights for designing CoT strategies to enhance LLM reasoning robustness.
        ]]></description>
    </item>
    <item>
        <title>Vision-based 3D Semantic Scene Completion via Capture Dynamic Representations</title>
        <link>https://arxiv.org/abs/2503.06222</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.06222v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Meng Wang, Fan Wu, Yunchuan Qin, Ruihui Li, Zhuo Tang, Kenli Li</dc:creator>
        <description><![CDATA[
            背景：基于视觉的语义场景补全任务中，场景里动态物体影响模型从2D图像推断3D结构的准确性，现有方法存在不足。方法：提出CDScene方法，利用多模态大模型提取2D显式语义并对齐到3D空间，利用单目和立体深度特征将场景信息解耦为动态和静态特征，设计动态 - 静态自适应融合模块提取聚合互补特征。效果：在多个数据集上实验表明，CDScene优于现有先进方法，具有优越性和鲁棒性。
            arXiv:2503.06222v2 Announce Type: replace 
Abstract: The vision-based semantic scene completion task aims to predict dense geometric and semantic 3D scene representations from 2D images. However, the presence of dynamic objects in the scene seriously affects the accuracy of the model inferring 3D structures from 2D images. Existing methods simply stack multiple frames of image input to increase dense scene semantic information, but ignore the fact that dynamic objects and non-texture areas violate multi-view consistency and matching reliability. To address these issues, we propose a novel method, CDScene: Vision-based Robust Semantic Scene Completion via Capturing Dynamic Representations. First, we leverage a multimodal large-scale model to extract 2D explicit semantics and align them into 3D space. Second, we exploit the characteristics of monocular and stereo depth to decouple scene information into dynamic and static features. The dynamic features contain structural relationships around dynamic objects, and the static features contain dense contextual spatial information. Finally, we design a dynamic-static adaptive fusion module to effectively extract and aggregate complementary features, achieving robust and accurate semantic scene completion in autonomous driving scenarios. Extensive experimental results on the SemanticKITTI, SSCBench-KITTI360, and SemanticKITTI-C datasets demonstrate the superiority and robustness of CDScene over existing state-of-the-art methods.
        ]]></description>
    </item>
    <item>
        <title>Dynamic Parametric Retrieval Augmented Generation for Test-time Knowledge Enhancement</title>
        <link>https://arxiv.org/abs/2503.23895</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.23895v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuqiao Tan, Shizhu He, Huanxuan Liao, Jun Zhao, Kang Liu</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）虽能提升大语言模型可靠性，但增加推理成本且存在幻觉问题，参数化RAG（PRAG）有训练和存储成本高、泛化能力有限的缺点。方法：提出动态参数化RAG（DyPRAG）框架，利用轻量级参数翻译器模型将文档高效转化为参数知识。效果：降低推理、训练和存储成本，动态生成参数知识，解决知识冲突。多数据集实验证明其有效性和泛化能力，能缓解RAG幻觉。
            arXiv:2503.23895v3 Announce Type: replace 
Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs) by retrieving relevant documents from external sources and incorporating them into the context. While it improves reliability by providing factual texts, it significantly increases inference costs as context length grows and introduces challenging issue of RAG hallucination, primarily caused by the lack of corresponding parametric knowledge in LLMs. An efficient solution is to enhance the knowledge of LLMs at test-time. Parametric RAG (PRAG) addresses this by embedding document into LLMs parameters to perform test-time knowledge enhancement, effectively reducing inference costs through offline training. However, its high training and storage costs, along with limited generalization ability, significantly restrict its practical adoption. To address these challenges, we propose Dynamic Parametric RAG (DyPRAG), a novel framework that leverages a lightweight parameter translator model to efficiently convert documents into parametric knowledge. DyPRAG not only reduces inference, training, and storage costs but also dynamically generates parametric knowledge, seamlessly enhancing the knowledge of LLMs and resolving knowledge conflicts in a plug-and-play manner at test-time. Extensive experiments on multiple datasets demonstrate the effectiveness and generalization capabilities of DyPRAG, offering a powerful and practical RAG paradigm which enables superior knowledge fusion and mitigates RAG hallucination in real-world applications. Our code is available at https://github.com/Trae1ounG/DyPRAG.
        ]]></description>
    </item>
    <item>
        <title>GraphMaster: Automated Graph Synthesis via LLM Agents in Data-Limited Environments</title>
        <link>https://arxiv.org/abs/2504.00711</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.00711v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Enjun Du, Xunkai Li, Tian Jin, Zhihan Zhang, Rong-Hua Li, Guoren Wang</dc:creator>
        <description><![CDATA[
            背景：图基础模型受大规模图语料稀缺限制，传统图数据合成技术缺乏语义信息，大语言模型直接用于图合成存在问题。方法：提出GraphMaster，这是首个用于数据受限环境下图数据合成的多智能体框架，通过四个LLM智能体协作优化合成过程。效果：创建新的受限数据集进行测试，开发新的可解释性评估框架，实验表明GraphMaster在多个数据集上显著优于传统合成方法，为数据稀缺环境下推进图基础模型奠定基础。
            arXiv:2504.00711v2 Announce Type: replace 
Abstract: The era of foundation models has revolutionized AI research, yet Graph Foundation Models (GFMs) remain constrained by the scarcity of large-scale graph corpora. Traditional graph data synthesis techniques primarily focus on simplistic structural operations, lacking the capacity to generate semantically rich nodes with meaningful textual attributes: a critical limitation for real-world applications. While large language models (LLMs) demonstrate exceptional text generation capabilities, their direct application to graph synthesis is impeded by context window limitations, hallucination phenomena, and structural consistency challenges. To address these issues, we introduce GraphMaster, the first multi-agent framework specifically designed for graph data synthesis in data-limited environments. GraphMaster orchestrates four specialized LLM agents (Manager, Perception, Enhancement, and Evaluation) that collaboratively optimize the synthesis process through iterative refinement, ensuring both semantic coherence and structural integrity. To rigorously evaluate our approach, we create new data-limited "Sub" variants of six standard graph benchmarks, specifically designed to test synthesis capabilities under realistic constraints. Additionally, we develop a novel interpretability assessment framework that combines human evaluation with a principled Grassmannian manifold-based analysis, providing both qualitative and quantitative measures of semantic coherence. Experimental results demonstrate that GraphMaster significantly outperforms traditional synthesis methods across multiple datasets, establishing a strong foundation for advancing GFMs in data-scarce environments.
        ]]></description>
    </item>
    <item>
        <title>Hierarchical Uncertainty-Aware Graph Neural Network</title>
        <link>https://arxiv.org/abs/2504.19820</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.19820v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yoonhyuk Choi, Jiho Choi, Taewook Ko, Chong-Kwon Kim</dc:creator>
        <description><![CDATA[
            背景：现有图神经网络研究分别探索了捕捉局部不确定性和利用图层次结构的机制，但二者的协同融合研究较少。方法：提出Hierarchical Uncertainty - Aware Graph Neural Network（HU - GNN），在端到端框架内统一多尺度表示学习、不确定性估计和自监督嵌入多样性，自适应形成节点簇并在多结构尺度估计不确定性，引导消息传递和注意力加权。效果：在半监督分类任务中保留预测准确性，有效减轻噪声和对抗性扰动，在标准基准测试中实现了最先进的鲁棒性和可解释性。
            arXiv:2504.19820v2 Announce Type: replace 
Abstract: Recent research on graph neural networks (GNNs) has explored mechanisms for capturing local uncertainty and exploiting graph hierarchies to mitigate data sparsity and leverage structural properties. However, the synergistic integration of these two approaches remains underexplored. This work introduces a novel architecture, the Hierarchical Uncertainty-Aware Graph Neural Network (HU-GNN), which unifies multi-scale representation learning, principled uncertainty estimation, and self-supervised embedding diversity within a single end-to-end framework. Specifically, HU-GNN adaptively forms node clusters and estimates uncertainty at multiple structural scales from individual nodes to higher levels. These uncertainty estimates guide a robust message-passing mechanism and attention weighting, effectively mitigating noise and adversarial perturbations while preserving predictive accuracy on semi-supervised classification tasks. We also offer key theoretical contributions, including a probabilistic formulation, rigorous uncertainty-calibration guarantees, and formal robustness bounds. Extensive experiments on standard benchmarks demonstrate that our model achieves state-of-the-art robustness and interpretability.
        ]]></description>
    </item>
    <item>
        <title>RiskLabs: Predicting Financial Risk Using Large Language Model based on Multimodal and Multi-Sources Data</title>
        <link>https://arxiv.org/abs/2404.07452</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2404.07452v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yupeng Cao, Zhi Chen, Prashant Kumar, Qingyun Pei, Yangyang Yu, Haohang Li, Fabrizio Dimino, Lorenzo Ausiello, K. P. Subbalakshmi, Papa Momar Ndiaye</dc:creator>
        <description><![CDATA[
            背景：人工智能技术融入金融领域受关注，但大语言模型用于金融风险预测的研究较少。方法：提出RiskLabs框架，融合财报电话会议的文本和语音信息、市场相关时间序列数据以及新闻数据等多模态金融数据，利用大语言模型分析和预测金融风险。效果：实证结果表明，该框架能有效预测市场波动和方差，对比实验凸显了不同数据源对风险评估的作用及大语言模型的关键地位。
            arXiv:2404.07452v2 Announce Type: replace-cross 
Abstract: The integration of Artificial Intelligence (AI) techniques, particularly large language models (LLMs), in finance has garnered increasing academic attention. Despite progress, existing studies predominantly focus on tasks like financial text summarization, question-answering, and stock movement prediction (binary classification), the application of LLMs to financial risk prediction remains underexplored. Addressing this gap, in this paper, we introduce RiskLabs, a novel framework that leverages LLMs to analyze and predict financial risks. RiskLabs uniquely integrates multimodal financial data, including textual and vocal information from Earnings Conference Calls (ECCs), market-related time series data, and contextual news data to improve financial risk prediction. Empirical results demonstrate RiskLabs' effectiveness in forecasting both market volatility and variance. Through comparative experiments, we examine the contributions of different data sources to financial risk assessment and highlight the crucial role of LLMs in this process. We also discuss the challenges associated with using LLMs for financial risk prediction and explore the potential of combining them with multimodal data for this purpose.
        ]]></description>
    </item>
    <item>
        <title>Recursive Inference Scaling: A Winning Path to Scalable Inference in Language and Multimodal Systems</title>
        <link>https://arxiv.org/abs/2502.07503</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.07503v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ibrahim Alabdulmohsin, Xiaohua Zhai</dc:creator>
        <description><![CDATA[
            背景：受语言分形几何研究启发，需优化语言和多模态系统推理时间。方法：提出递归推理缩放（RINS），是一种递归深度形式，在计算匹配机制下对比多种变体。效果：在固定模型大小和训练计算预算下，显著提升语言建模性能；推广到多模态系统，如SigLIP - B/16在零样本ImageNet准确率提升2%；改善渐近性能极限和缩放指数；使用轻量级适配器时，即使推理不应用递归深度，也能提升语言建模性能。 
            arXiv:2502.07503v3 Announce Type: replace-cross 
Abstract: Inspired by recent findings on the fractal geometry of language, we introduce Recursive INference Scaling (RINS) as a complementary, plug-in recipe for scaling inference time in language and multimodal systems. RINS is a particular form of recursive depth that significantly outperforms +55 other variants, including the recent "repeat-all-over" (RAO) strategy in Mobile LLM (Liu et al., 2024) and latent recurrent thinking (Geiping et al., 2025). Unlike prior works, we carry out our comparisons on a compute-matched regime, and demonstrate that for a fixed model size and training compute budget, RINS substantially improves language modeling performance. It also generalizes beyond pure language tasks, delivering gains in multimodal systems, including a +2% improvement in 0-shot ImageNet accuracy for SigLIP-B/16. Additionally, by deriving data scaling laws, we show that RINS improves both the asymptotic performance limits and the scaling exponents. More importantly, with light-weight (linear) adapters (comprising <1% of model parameters) and stochastic dropout, RINS offers a no-regret strategy, meaning that RINS-enabled pretraining improves performance in language modeling even when recursive depth is not applied at inference time. This corresponds to improving performance on a training compute-, parameter-, and inference-matched regime, suggesting its potential as a viable component of LLM pretraining!
        ]]></description>
    </item>
    <item>
        <title>The Effectiveness of Large Language Models in Transforming Unstructured Text to Standardized Formats</title>
        <link>https://arxiv.org/abs/2503.02650</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.02650v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>William Brach, Kristi\'an Ko\v{s}\v{t}\'al, Michal Ries</dc:creator>
        <description><![CDATA[
            背景：非结构化文本数据增长给数据管理和信息检索带来挑战，大语言模型将非结构化文本转换为结构化格式的潜力待挖掘。方法：系统评估大语言模型将非结构化菜谱文本转换为结构化Cooklang格式的能力，测试四个模型，引入结合传统与语义元素识别的评估方法。效果：少样本提示下GPT - 4o表现出色（ROUGE - L: 0.9722，WER: 0.0730），首次证明大语言模型无需大量训练就能可靠转换，小模型经微调也有优化潜力，为多领域自动化生成结构化数据带来可能。
            arXiv:2503.02650v2 Announce Type: replace-cross 
Abstract: The exponential growth of unstructured text data presents a fundamental challenge in modern data management and information retrieval. While Large Language Models (LLMs) have shown remarkable capabilities in natural language processing, their potential to transform unstructured text into standardized, structured formats remains largely unexplored - a capability that could revolutionize data processing workflows across industries. This study breaks new ground by systematically evaluating LLMs' ability to convert unstructured recipe text into the structured Cooklang format. Through comprehensive testing of four models (GPT-4o, GPT-4o-mini, Llama3.1:70b, and Llama3.1:8b), an innovative evaluation approach is introduced that combines traditional metrics (WER, ROUGE-L, TER) with specialized metrics for semantic element identification. Our experiments reveal that GPT-4o with few-shot prompting achieves breakthrough performance (ROUGE-L: 0.9722, WER: 0.0730), demonstrating for the first time that LLMs can reliably transform domain-specific unstructured text into structured formats without extensive training. Although model performance generally scales with size, we uncover surprising potential in smaller models like Llama3.1:8b for optimization through targeted fine-tuning. These findings open new possibilities for automated structured data generation across various domains, from medical records to technical documentation, potentially transforming the way organizations process and utilize unstructured information.
        ]]></description>
    </item>
    <item>
        <title>Balancing Interpretability and Flexibility in Modeling Diagnostic Trajectories with an Embedded Neural Hawkes Process Model</title>
        <link>https://arxiv.org/abs/2504.21795</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.21795v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuankang Zhao, Matthew Engelhard</dc:creator>
        <description><![CDATA[
            背景：传统霍克斯过程（HP）虽可解释，但灵活性不足；基于神经网络的HP灵活性高，但可解释性差。方法：提出一种新的HP公式，在事件嵌入空间用神经网络定义灵活的影响核来建模影响函数，还可添加变压器编码器层平衡灵活性与可解释性。效果：模拟中能准确恢复影响函数，在MIMIC - IV程序数据集上表现有竞争力，在儿童诊断数据集上无需变压器层也有临床意义解释，说明该方法能有效捕捉数据自增强动态，兼顾性能与可解释性。
            arXiv:2504.21795v2 Announce Type: replace-cross 
Abstract: The Hawkes process (HP) is commonly used to model event sequences with self-reinforcing dynamics, including electronic health records (EHRs). Traditional HPs capture self-reinforcement via parametric impact functions that can be inspected to understand how each event modulates the intensity of others. Neural network-based HPs offer greater flexibility, resulting in improved fit and prediction performance, but at the cost of interpretability, which is often critical in healthcare. In this work, we aim to understand and improve upon this tradeoff. We propose a novel HP formulation in which impact functions are modeled by defining a flexible impact kernel, instantiated as a neural network, in event embedding space, which allows us to model large-scale event sequences with many event types. This approach is more flexible than traditional HPs yet more interpretable than other neural network approaches, and allows us to explicitly trade flexibility for interpretability by adding transformer encoder layers to further contextualize the event embeddings. Results show that our method accurately recovers impact functions in simulations, achieves competitive performance on MIMIC-IV procedure dataset, and gains clinically meaningful interpretation on XX-EHR with children diagnosis dataset even without transformer layers. This suggests that our flexible impact kernel is often sufficient to capture self-reinforcing dynamics in EHRs and other data effectively, implying that interpretability can be maintained without loss of performance.
        ]]></description>
    </item>
    <item>
        <title>Low-Complexity Acoustic Scene Classification with Device Information in the DCASE 2025 Challenge</title>
        <link>https://arxiv.org/abs/2505.01747</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.01747v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Florian Schmid, Paul Primus, Toni Heittola, Annamaria Mesaros, Irene Mart\'in-Morat\'o, Gerhard Widmer</dc:creator>
        <description><![CDATA[
            背景：DCASE 2025挑战赛持续关注低复杂度模型、数据效率和设备不匹配问题，今年任务新增推理时提供录音设备信息。方法：利用设备信息开发特定设备模型，训练集与DCASE 2024挑战赛25%子集匹配，强调迁移学习。效果：通用设备模型在十分类问题上准确率达50.72%，使用设备信息后准确率提升至51.89%。
            arXiv:2505.01747v1 Announce Type: new 
Abstract: This paper presents the Low-Complexity Acoustic Scene Classification with Device Information Task of the DCASE 2025 Challenge and its baseline system. Continuing the focus on low-complexity models, data efficiency, and device mismatch from previous editions (2022--2024), this year's task introduces a key change: recording device information is now provided at inference time. This enables the development of device-specific models that leverage device characteristics -- reflecting real-world deployment scenarios in which a model is designed with awareness of the underlying hardware. The training set matches the 25% subset used in the corresponding DCASE 2024 challenge, with no restrictions on external data use, highlighting transfer learning as a central topic. The baseline achieves 50.72% accuracy on this ten-class problem with a device-general model, improving to 51.89% when using the available device information.
        ]]></description>
    </item>
    <item>
        <title>FLOWER: Flow-Based Estimated Gaussian Guidance for General Speech Restoration</title>
        <link>https://arxiv.org/abs/2505.01750</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.01750v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Da-Hee Yang, Jaeuk Lee, Joon-Hyuk Chang</dc:creator>
        <description><![CDATA[
            背景：语音恢复任务有提升需求。方法：提出FLOWER，一种将高斯引导融入生成框架的语音恢复调节方法，通过归一化流网络将干净语音转换为预定义先验分布（如高斯分布），提取关键信息引导生成模型，并将引导信息融入生成网络各模块以精确控制恢复。效果：实验表明，FLOWER能有效提升各类通用语音恢复任务的性能。 
            arXiv:2505.01750v1 Announce Type: new 
Abstract: We introduce FLOWER, a novel conditioning method designed for speech restoration that integrates Gaussian guidance into generative frameworks. By transforming clean speech into a predefined prior distribution (e.g., Gaussian distribution) using a normalizing flow network, FLOWER extracts critical information to guide generative models. This guidance is incorporated into each block of the generative network, enabling precise restoration control. Experimental results demonstrate the effectiveness of FLOWER in improving performance across various general speech restoration tasks.
        ]]></description>
    </item>
    <item>
        <title>LLaMA-Omni2: LLM-based Real-time Spoken Chatbot with Autoregressive Streaming Speech Synthesis</title>
        <link>https://arxiv.org/abs/2505.02625</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.02625v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qingkai Fang, Yan Zhou, Shoutao Guo, Shaolei Zhang, Yang Feng</dc:creator>
        <description><![CDATA[
            背景：实时、智能、自然的语音交互是下一代人机交互的重要部分，基于大语言模型构建智能语音聊天机器人成为研究热点。方法：提出LLaMA - Omni 2，这是一系列参数量从0.5B到14B的语音语言模型，基于Qwen2.5系列模型构建，集成了语音编码器和自回归流式语音解码器。效果：仅在200K多轮语音对话样本上训练，就在多个语音问答和语音指令跟随基准测试中表现出色，超越了在数百万小时语音数据上训练的GLM - 4 - Voice等先前的先进模型。
            arXiv:2505.02625v1 Announce Type: cross 
Abstract: Real-time, intelligent, and natural speech interaction is an essential part of the next-generation human-computer interaction. Recent advancements have showcased the potential of building intelligent spoken chatbots based on large language models (LLMs). In this paper, we introduce LLaMA-Omni 2, a series of speech language models (SpeechLMs) ranging from 0.5B to 14B parameters, capable of achieving high-quality real-time speech interaction. LLaMA-Omni 2 is built upon the Qwen2.5 series models, integrating a speech encoder and an autoregressive streaming speech decoder. Despite being trained on only 200K multi-turn speech dialogue samples, LLaMA-Omni 2 demonstrates strong performance on several spoken question answering and speech instruction following benchmarks, surpassing previous state-of-the-art SpeechLMs like GLM-4-Voice, which was trained on millions of hours of speech data.
        ]]></description>
    </item>
    <item>
        <title>Voila: Voice-Language Foundation Models for Real-Time Autonomous Interaction and Voice Role-Play</title>
        <link>https://arxiv.org/abs/2505.02707</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.02707v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yemin Shi, Yu Shu, Siwei Dong, Guangyi Liu, Jaward Sesay, Jingwen Li, Zhiting Hu</dc:creator>
        <description><![CDATA[
            背景：理想的语音AI应能与人类实时、自主且富有情感地交互。方法：提出Voila语音语言基础模型家族，采用端到端架构，其分层多尺度Transformer结合大语言模型推理能力与声学建模，支持超百万预建语音及从10秒短音频定制新语音。效果：实现195毫秒响应延迟，超人类平均响应时间，可作为统一模型用于多种语音应用，且已开源推动人机交互研究。
            arXiv:2505.02707v1 Announce Type: cross 
Abstract: A voice AI agent that blends seamlessly into daily life would interact with humans in an autonomous, real-time, and emotionally expressive manner. Rather than merely reacting to commands, it would continuously listen, reason, and respond proactively, fostering fluid, dynamic, and emotionally resonant interactions. We introduce Voila, a family of large voice-language foundation models that make a step towards this vision. Voila moves beyond traditional pipeline systems by adopting a new end-to-end architecture that enables full-duplex, low-latency conversations while preserving rich vocal nuances such as tone, rhythm, and emotion. It achieves a response latency of just 195 milliseconds, surpassing the average human response time. Its hierarchical multi-scale Transformer integrates the reasoning capabilities of large language models (LLMs) with powerful acoustic modeling, enabling natural, persona-aware voice generation -- where users can simply write text instructions to define the speaker's identity, tone, and other characteristics. Moreover, Voila supports over one million pre-built voices and efficient customization of new ones from brief audio samples as short as 10 seconds. Beyond spoken dialogue, Voila is designed as a unified model for a wide range of voice-based applications, including automatic speech recognition (ASR), Text-to-Speech (TTS), and, with minimal adaptation, multilingual speech translation. Voila is fully open-sourced to support open research and accelerate progress toward next-generation human-machine interactions.
        ]]></description>
    </item>
    <item>
        <title>Improving Audio-Text Retrieval via Hierarchical Cross-Modal Interaction and Auxiliary Captions</title>
        <link>https://arxiv.org/abs/2307.15344</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2307.15344v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yifei Xin, Yuexian Zou</dc:creator>
        <description><![CDATA[
            背景：现有音频 - 文本检索（ATR）方法多关注整体音频片段与完整字幕句子对比，忽略细粒度跨模态关系。方法：提出分层跨模态交互（HCI）方法，同时探索片段 - 句子、子片段 - 短语和帧 - 单词关系，实现全面多模态语义比较；还提出利用预训练字幕生成器生成的辅助字幕（AC）的ATR框架，进行音频与生成字幕的特征交互，形成新音频 - 文本对用于数据增强。效果：HCI显著提升ATR性能，AC框架在多数据集上有稳定性能提升。
            arXiv:2307.15344v2 Announce Type: replace 
Abstract: Most existing audio-text retrieval (ATR) methods focus on constructing contrastive pairs between whole audio clips and complete caption sentences, while ignoring fine-grained cross-modal relationships, e.g., short segments and phrases or frames and words. In this paper, we introduce a hierarchical cross-modal interaction (HCI) method for ATR by simultaneously exploring clip-sentence, segment-phrase, and frame-word relationships, achieving a comprehensive multi-modal semantic comparison. Besides, we also present a novel ATR framework that leverages auxiliary captions (AC) generated by a pretrained captioner to perform feature interaction between audio and generated captions, which yields enhanced audio representations and is complementary to the original ATR matching branch. The audio and generated captions can also form new audio-text pairs as data augmentation for training. Experiments show that our HCI significantly improves the ATR performance. Moreover, our AC framework also shows stable performance gains on multiple datasets.
        ]]></description>
    </item>
    <item>
        <title>FolAI: Synchronized Foley Sound Generation with Semantic and Temporal Alignment</title>
        <link>https://arxiv.org/abs/2412.15023</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2412.15023v3</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Riccardo Fosco Gramaccioni, Christian Marinoni, Emilian Postolache, Marco Comunit\`a, Luca Cosmo, Joshua D. Reiss, Danilo Comminiello</dc:creator>
        <description><![CDATA[
            传统音效设计手动对齐音频与视觉线索，耗时且难扩展，缺乏保留创意的自动化工具。为此，本文提出FolAI两阶段生成框架。第一阶段从视频中估计平滑控制信号，作为音频的时间框架；第二阶段基于扩散的生成模型，结合时间包络和用户提供的语义嵌入生成音效。实验结果表明，该模型生成的音频在时间上与视觉运动对齐、语义上符合用户意图且感知上真实，为专业和交互式场景的音效合成提供了可扩展、高质量的解决方案。
            arXiv:2412.15023v3 Announce Type: replace 
Abstract: Traditional sound design workflows rely on manual alignment of audio events to visual cues, as in Foley sound design, where everyday actions like footsteps or object interactions are recreated to match the on-screen motion. This process is time-consuming, difficult to scale, and lacks automation tools that preserve creative intent. Despite recent advances in vision-to-audio generation, producing temporally coherent and semantically controllable sound effects from video remains a major challenge. To address these limitations, we introduce FolAI, a two-stage generative framework that decouples the when and the what of sound synthesis, i.e., the temporal structure extraction and the semantically guided generation, respectively. In the first stage, we estimate a smooth control signal from the video that captures the motion intensity and rhythmic structure over time, serving as a temporal scaffold for the audio. In the second stage, a diffusion-based generative model produces sound effects conditioned both on this temporal envelope and on high-level semantic embeddings, provided by the user, that define the desired auditory content (e.g., material or action type). This modular design enables precise control over both timing and timbre, streamlining repetitive tasks while preserving creative flexibility in professional Foley workflows. Results on diverse visual contexts, such as footstep generation and action-specific sonorization, demonstrate that our model reliably produces audio that is temporally aligned with visual motion, semantically consistent with user intent, and perceptually realistic. These findings highlight the potential of FolAI as a controllable and modular solution for scalable, high-quality Foley sound synthesis in professional and interactive settings. Supplementary materials are accessible on our dedicated demo page at https://ispamm.github.io/FolAI.
        ]]></description>
    </item>
    <item>
        <title>VANPY: Voice Analysis Framework</title>
        <link>https://arxiv.org/abs/2502.17579</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.17579v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Gregory Koushnir, Michael Fire, Galit Fuhrmann Alpert, Dima Kagan</dc:creator>
        <description><![CDATA[
            背景：现代数字通信中语音数据应用增多，但缺乏全面的自动语音分析和表征工具。方法：开发了开源端到端的VANPY框架，用于语音数据的自动预处理、特征提取和分类，包含超15个语音分析组件，还自研4个组件增强说话人表征能力。效果：模型在多数据集表现稳健，虽未超现有最优水平。在分析电影语音案例中，该框架能提取性别、年龄等多种说话人特征。
            arXiv:2502.17579v2 Announce Type: replace 
Abstract: Voice data is increasingly being used in modern digital communications, yet there is still a lack of comprehensive tools for automated voice analysis and characterization. To this end, we developed the VANPY (Voice Analysis in Python) framework for automated pre-processing, feature extraction, and classification of voice data. The VANPY is an open-source end-to-end comprehensive framework that was developed for the purpose of speaker characterization from voice data. The framework is designed with extensibility in mind, allowing for easy integration of new components and adaptation to various voice analysis applications. It currently incorporates over fifteen voice analysis components - including music/speech separation, voice activity detection, speaker embedding, vocal feature extraction, and various classification models.
  Four of the VANPY's components were developed in-house and integrated into the framework to extend its speaker characterization capabilities: gender classification, emotion classification, age regression, and height regression. The models demonstrate robust performance across various datasets, although not surpassing state-of-the-art performance.
  As a proof of concept, we demonstrate the framework's ability to extract speaker characteristics on a use-case challenge of analyzing character voices from the movie "Pulp Fiction." The results illustrate the framework's capability to extract multiple speaker characteristics, including gender, age, height, emotion type, and emotion intensity measured across three dimensions: arousal, dominance, and valence.
        ]]></description>
    </item>
    <item>
        <title>P2Mark: Plug-and-play Parameter-level Watermarking for Neural Speech Generation</title>
        <link>https://arxiv.org/abs/2504.05197</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.05197v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yong Ren, Jiangyan Yi, Tao Wang, Jianhua Tao, Zheng Lian, Zhengqi Wen, Chenxing Li, Ruibo Fu, Ye Bai, Xiaohui Zhang</dc:creator>
        <description><![CDATA[
            背景：神经语音生成技术发展迅速，但存在被滥用风险，现有音频水印方法不适用于开源场景。方法：提出P2Mark方法，将水印嵌入模型权重，训练时引入轻量级水印适配器，还提出梯度正交投影优化策略。效果：在两种主流波形解码器上实验表明，该方法在水印提取准确率、不可感知性和鲁棒性方面，与不适用于开源白盒保护场景的先进方法性能相当。
            arXiv:2504.05197v2 Announce Type: replace 
Abstract: Neural speech generation (NSG) has rapidly advanced as a key component of artificial intelligence-generated content, enabling the generation of high-quality, highly realistic speech for diverse applications. This development increases the risk of technique misuse and threatens social security. Audio watermarking can embed imperceptible marks into generated audio, providing a promising approach for secure NSG usage. However, current audio watermarking methods are mainly applied at the audio-level or feature-level, which are not suitable for open-sourced scenarios where source codes and model weights are released. To address this limitation, we propose a Plug-and-play Parameter-level WaterMarking (P2Mark) method for NSG. Specifically, we embed watermarks into the released model weights, offering a reliable solution for proactively tracing and protecting model copyrights in open-source scenarios. During training, we introduce a lightweight watermark adapter into the pre-trained model, allowing watermark information to be merged into the model via this adapter. This design ensures both the flexibility to modify the watermark before model release and the security of embedding the watermark within model parameters after model release. Meanwhile, we propose a gradient orthogonal projection optimization strategy to ensure the quality of the generated audio and the accuracy of watermark preservation. Experimental results on two mainstream waveform decoders in NSG (i.e., vocoder and codec) demonstrate that P2Mark achieves comparable performance to state-of-the-art audio watermarking methods that are not applicable to open-source white-box protection scenarios, in terms of watermark extraction accuracy, watermark imperceptibility, and robustness.
        ]]></description>
    </item>
</channel>
</rss>