<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
<channel>
    <title>arXiv Paper Filter</title>
    <link>https://github.com/None/arxiv_filter</link>
    <description>根据研究兴趣筛选的arXiv论文</description>
    <atom:link href="https://raw.githubusercontent.com/None/arxiv_filter/main/feed.xml" rel="self" type="application/rss+xml" />
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>zh-CN</language>
    <lastBuildDate>Tue, 22 Apr 2025 12:22:47 +0800</lastBuildDate>
    <managingEditor>None@github.com</managingEditor>
    <pubDate>Tue, 22 Apr 2025 12:22:47 +0800</pubDate>
    <skipDays>
        <day>Saturday</day>
        <day>Sunday</day>
    </skipDays>

    <item>
        <title>QuatE-D: A Distance-Based Quaternion Model for Knowledge Graph Embedding</title>
        <link>https://arxiv.org/abs/2504.13983</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.13983v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hamideh-Sadat Fazael-Ardakani, Hamid Soltanian-Zadeh</dc:creator>
        <description><![CDATA[
            背景：知识图谱嵌入（KGE）方法需在连续空间表示实体和关系，保留其结构和语义属性，基于四元数的KGE在捕捉复杂关系模式上潜力大。方法：提出QuatE - D，采用基于距离的评分函数而非传统内积方法，利用欧氏距离增强可解释性和关系结构表示灵活性。效果：实验显示，QuatE - D参数高效，性能有竞争力，尤其在降低平均排名上表现出色，为知识图谱补全提供了新方向。
            arXiv:2504.13983v1 Announce Type: new 
Abstract: Knowledge graph embedding (KGE) methods aim to represent entities and relations in a continuous space while preserving their structural and semantic properties. Quaternion-based KGEs have demonstrated strong potential in capturing complex relational patterns. In this work, we propose QuatE-D, a novel quaternion-based model that employs a distance-based scoring function instead of traditional inner-product approaches. By leveraging Euclidean distance, QuatE-D enhances interpretability and provides a more flexible representation of relational structures. Experimental results demonstrate that QuatE-D achieves competitive performance while maintaining an efficient parameterization, particularly excelling in Mean Rank reduction. These findings highlight the effectiveness of distance-based scoring in quaternion embeddings, offering a promising direction for knowledge graph completion.
        ]]></description>
    </item>
    <item>
        <title>LogicTree: Structured Proof Exploration for Coherent and Rigorous Logical Reasoning with Large Language Models</title>
        <link>https://arxiv.org/abs/2504.14089</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.14089v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kang He, Kaushik Roy</dc:creator>
        <description><![CDATA[
            背景：大语言模型在多步推理上取得进展，但在复杂逻辑推理中面临挑战，如证明寻找需系统探索和保持逻辑连贯，前提空间大时找前提组合困难。方法：提出LogicTree框架，用算法引导搜索实现结构化证明探索，引入缓存机制利用历史知识，将前提搜索分解为线性过程，还引入两种无大模型启发式方法进行前提优先级排序。效果：在五个数据集上，LogicTree推理计算更优，证明准确率更高，在GPT - 4o上比思维链和ToT分别平均高23.6%和12.5%，GPT - 4o在该框架内比o3 - mini平均高7.6%。
            arXiv:2504.14089v1 Announce Type: new 
Abstract: Large language models (LLMs) have achieved remarkable multi-step reasoning capabilities across various domains. However, LLMs still face distinct challenges in complex logical reasoning, as (1) proof-finding requires systematic exploration and the maintenance of logical coherence and (2) searching the right combination of premises at each reasoning step is inherently challenging in tasks with large premise space. To address this, we propose LogicTree, an inference-time modular framework employing algorithm-guided search to automate structured proof exploration and ensure logical coherence. Advancing beyond tree-of-thought (ToT), we incorporate caching mechanism into LogicTree to enable effective utilization of historical knowledge, preventing reasoning stagnation and minimizing redundancy. Furthermore, we address the combinatorial complexity of premise search by decomposing it into a linear process. The refined premise selection restricts subsequent inference to at most one derivation per step, enhancing reasoning granularity and enforcing strict step-by-step reasoning. Additionally, we introduce two LLM-free heuristics for premise prioritization, enabling strategic proof search. Experimental results on five datasets demonstrate that LogicTree optimally scales inference-time computation to achieve higher proof accuracy, surpassing chain-of-thought (CoT) and ToT with average gains of 23.6% and 12.5%, respectively, on GPT-4o. Moreover, within LogicTree, GPT-4o outperforms o3-mini by 7.6% on average.
        ]]></description>
    </item>
    <item>
        <title>FedC4: Graph Condensation Meets Client-Client Collaboration for Efficient and Private Federated Graph Learning</title>
        <link>https://arxiv.org/abs/2504.14188</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.14188v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zekai Chen, Xunkai Li, Yinlin Zhu, Rong-Hua Li, Guoren Wang</dc:creator>
        <description><![CDATA[
            背景：联邦图学习（FGL）能在保护隐私下进行分布式图数据协作训练，现有C - C架构存在广播冗余节点嵌入、通信成本高和隐私风险问题。方法：提出FedC4框架，将图凝聚与客户端协作结合，把客户端私有图提炼为合成节点嵌入，减少通信开销，还引入三个模块使源客户端能根据目标客户端图结构发送不同节点表示。效果：在八个真实数据集实验显示，FedC4在性能和通信效率上优于现有基线模型。
            arXiv:2504.14188v1 Announce Type: new 
Abstract: Federated Graph Learning (FGL) is an emerging distributed learning paradigm that enables collaborative model training over decentralized graph-structured data while preserving local privacy. Existing FGL methods can be categorized into two optimization architectures: (1) the Server-Client (S-C) paradigm, where clients upload local models for server-side aggregation; and (2) the Client-Client (C-C) paradigm, which allows direct information exchange among clients to support personalized training. Compared to S-C, the C-C architecture better captures global graph knowledge and enables fine-grained optimization through customized peer-to-peer communication. However, current C-C methods often broadcast identical and redundant node embeddings, incurring high communication costs and privacy risks. To address this, we propose FedC4, a novel framework that combines graph Condensation with Client-Client Collaboration. Instead of transmitting raw node-level features, FedC4 distills each client's private graph into a compact set of synthetic node embeddings, reducing communication overhead and enhancing privacy. In addition, FedC4 introduces three modules that allow source clients to send distinct node representations tailored to target clients'graph structures, enabling personalized optimization with global guidance. Extensive experiments on eight real-world datasets show that FedC4 outperforms state-of-the-art baselines in both performance and communication efficiency.
        ]]></description>
    </item>
    <item>
        <title>Integrating Single-Cell Foundation Models with Graph Neural Networks for Drug Response Prediction</title>
        <link>https://arxiv.org/abs/2504.14361</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.14361v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Till Rossner, Ziteng Li, Jonas Balke, Nikoo Salehfard, Tom Seifert, Ming Tang</dc:creator>
        <description><![CDATA[
            背景：癌症药物反应预测是重要研究方向。方法：提出将scGPT基础模型集成到DeepCDR模型中预测癌症药物反应的创新方法，利用scGPT从基因表达数据生成嵌入，作为DeepCDR的基因表达输入数据。效果：实验表明，基于scGPT的方法优于之前相关工作，包括原始DeepCDR模型和基于scFoundation的模型，能提升癌症药物反应预测的准确性，为现有方法提供了有前景的替代方案。
            arXiv:2504.14361v1 Announce Type: new 
Abstract: In this study, we propose an innovative methodology for predicting Cancer Drug Response (CDR) through the integration of the scGPT foundation model within the DeepCDR model. Our approach utilizes scGPT to generate embeddings from gene expression data, which are then used as gene expression input data for DeepCDR. The experimental findings demonstrate the efficacy of this scGPT-based method in outperforming previous related works, including the original DeepCDR model and the scFoundation-based model. This study highlights the potential of scGPT embeddings to enhance the accuracy of CDR predictions and offers a promising alternative to existing approaches.
        ]]></description>
    </item>
    <item>
        <title>Hydra: An Agentic Reasoning Approach for Enhancing Adversarial Robustness and Mitigating Hallucinations in Vision-Language Models</title>
        <link>https://arxiv.org/abs/2504.14395</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.14395v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chung-En (Johnny),  Yu (Neil),  Hsuan-Chih (Neil),  Chen, Brian Jalaian, Nathaniel D. Bastian</dc:creator>
        <description><![CDATA[
            背景：开发可信的视觉语言模型（VLM）需解决对抗鲁棒性和幻觉缓解问题，现有方法缺乏统一策略。方法：提出Hydra框架，通过迭代推理、结构化批判和跨模型验证增强VLM，采用行动 - 批判循环，利用思维链和上下文学习动态优化输出。效果：在四个VLM、三个幻觉基准等上评估，结果显示Hydra超越现有插件式VLM和去幻觉方法，无需显式对抗防御，增强了鲁棒性和事实一致性，为提高VLM可靠性提供无训练解决方案。
            arXiv:2504.14395v1 Announce Type: new 
Abstract: To develop trustworthy Vision-Language Models (VLMs), it is essential to address adversarial robustness and hallucination mitigation, both of which impact factual accuracy in high-stakes applications such as defense and healthcare. Existing methods primarily focus on either adversarial defense or hallucination post-hoc correction, leaving a gap in unified robustness strategies. We introduce \textbf{Hydra}, an adaptive agentic framework that enhances plug-in VLMs through iterative reasoning, structured critiques, and cross-model verification, improving both resilience to adversarial perturbations and intrinsic model errors. Hydra employs an Action-Critique Loop, where it retrieves and critiques visual information, leveraging Chain-of-Thought (CoT) and In-Context Learning (ICL) techniques to refine outputs dynamically. Unlike static post-hoc correction methods, Hydra adapts to both adversarial manipulations and intrinsic model errors, making it robust to malicious perturbations and hallucination-related inaccuracies. We evaluate Hydra on four VLMs, three hallucination benchmarks, two adversarial attack strategies, and two adversarial defense methods, assessing performance on both clean and adversarial inputs. Results show that Hydra surpasses plug-in VLMs and state-of-the-art (SOTA) dehallucination methods, even without explicit adversarial defenses, demonstrating enhanced robustness and factual consistency. By bridging adversarial resistance and hallucination mitigation, Hydra provides a scalable, training-free solution for improving the reliability of VLMs in real-world applications.
        ]]></description>
    </item>
    <item>
        <title>a1: Steep Test-time Scaling Law via Environment Augmented Generation</title>
        <link>https://arxiv.org/abs/2504.14597</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.14597v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Lingrui Mei, Shenghua Liu, Yiwei Wang, Baolong Bi, Yuyao Ge, Jun Wan, Yurong Wu, Xueqi Cheng</dc:creator>
        <description><![CDATA[
            背景：大语言模型在推理方面虽有突破，但在复杂多步任务中仍存在幻觉、逻辑错误和无法自我修正的问题，现有思维链提示等方法推理能力有限。方法：提出环境增强生成（EAG）框架，通过实时环境反馈验证推理步骤、动态分支探索寻找替代路径、基于成功推理轨迹学习来增强推理能力。效果：a1 - 32B模型在各基准测试中达同规模模型最优，在竞赛数学任务中媲美更大模型o1，比可比模型最高高出24.4个百分点。
            arXiv:2504.14597v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have made remarkable breakthroughs in reasoning, yet continue to struggle with hallucinations, logical errors, and inability to self-correct during complex multi-step tasks. Current approaches like chain-of-thought prompting offer limited reasoning capabilities that fail when precise step validation is required. We propose Environment Augmented Generation (EAG), a framework that enhances LLM reasoning through: (1) real-time environmental feedback validating each reasoning step, (2) dynamic branch exploration for investigating alternative solution paths when faced with errors, and (3) experience-based learning from successful reasoning trajectories. Unlike existing methods, EAG enables deliberate backtracking and strategic replanning through tight integration of execution feedback with branching exploration. Our a1-32B model achieves state-of-the-art performance among similar-sized models across all benchmarks, matching larger models like o1 on competition mathematics while outperforming comparable models by up to 24.4 percentage points. Analysis reveals EAG's distinctive scaling pattern: initial token investment in environment interaction yields substantial long-term performance dividends, with advantages amplifying proportionally to task complexity. EAG's theoretical framework demonstrates how environment interactivity and systematic branch exploration together establish a new paradigm for reliable machine reasoning, particularly for problems requiring precise multi-step calculation and logical verification.
        ]]></description>
    </item>
    <item>
        <title>Harnessing Generative LLMs for Enhanced Financial Event Entity Extraction Performance</title>
        <link>https://arxiv.org/abs/2504.14633</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.14633v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Soo-joon Choi, Ji-jun Park</dc:creator>
        <description><![CDATA[
            金融事件实体提取对分析市场动态和构建金融知识图谱至关重要，但金融文本语言专业、结构复杂，传统序列标注模型处理长距离依赖和多实体提取较困难。为此，研究将该任务转化为文本到结构化输出的生成任务，用参数高效微调方法微调预训练大语言模型，直接生成含提取实体及字符跨度的结构化表示。在CCKS 2019数据集上实验，该方法F1分数达新的最优，显著优于先前方法，能更好处理金融文本并提取高质量实体。
            arXiv:2504.14633v1 Announce Type: new 
Abstract: Financial event entity extraction is a crucial task for analyzing market dynamics and building financial knowledge graphs, yet it presents significant challenges due to the specialized language and complex structures in financial texts. Traditional approaches often rely on sequence labeling models, which can struggle with long-range dependencies and the inherent complexity of extracting multiple, potentially overlapping entities. Motivated by the advanced language understanding and generative capabilities of Large Language Models (LLMs), we propose a novel method that reframes financial event entity extraction as a text-to-structured-output generation task. Our approach involves fine-tuning a pre-trained LLM using Parameter-Efficient Fine-Tuning (PEFT) to directly generate a structured representation, such as a JSON object, containing the extracted entities and their precise character spans from the input text. We evaluate our method on the challenging CCKS 2019 Financial Event Entity Extraction dataset, comparing its performance against strong sequence labeling baselines, including SEBERTNets and sebertNets. Experimental results demonstrate that our generative LLM method achieves a new state-of-the-art F1 score on this benchmark, significantly outperforming previous methods. Through detailed quantitative analysis across event types, entity types, and instance complexity, as well as human evaluation, we show that our approach is more effective at handling the nuances of financial text and extracting high-quality entities. This work validates the potential of applying generative LLMs directly to complex, domain-specific information extraction tasks requiring structured output.
        ]]></description>
    </item>
    <item>
        <title>Relation-R1: Cognitive Chain-of-Thought Guided Reinforcement Learning for Unified Relational Comprehension</title>
        <link>https://arxiv.org/abs/2504.14642</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.14642v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Lin Li, Wei Chen, Jiahui Li, Long Chen</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型在视觉关系理解上存在局限，缺乏多实体间语义依赖建模，导致输出不可靠。方法：提出Relation - R1统一关系理解框架，在强化学习范式中集成认知思维链引导的监督微调（SFT）和组相对策略优化（GRPO），先通过SFT建立基础推理能力，再用GRPO优化输出。效果：在PSG和SWiG数据集上实验表明，Relation - R1在二元和N元关系理解中达到了当前最优性能。
            arXiv:2504.14642v1 Announce Type: new 
Abstract: Recent advances in multi-modal large language models (MLLMs) have significantly improved object-level grounding and region captioning, but remain limited in visual relation understanding (\eg, scene graph generation), particularly in modeling \textit{N}-ary relationships that identify multiple semantic roles among an action event. Such a lack of \textit{semantic dependencies} modeling among multi-entities leads to unreliable outputs, intensifying MLLMs' hallucinations and over-reliance on language priors. To this end, we propose Relation-R1, the first unified relational comprehension framework that explicitly integrates cognitive chain-of-thought (CoT)-guided Supervised Fine-Tuning (SFT) and Group Relative Policy Optimization (GRPO) within a reinforcement learning (RL) paradigm. Specifically, we first establish foundational reasoning capabilities via SFT, enforcing structured outputs with thinking processes. Then, GRPO is utilized to refine these outputs via multi-reward optimization, prioritizing visual-semantic grounding over language-induced biases, thereby improving generalization capability. Extensive experiments on widely-used PSG and SWiG datasets demonstrate that Relation-R1 achieves state-of-the-art performance in both binary and \textit{N}-ary relation understanding.
        ]]></description>
    </item>
    <item>
        <title>Generative Multimodal Pretraining with Discrete Diffusion Timestep Tokens</title>
        <link>https://arxiv.org/abs/2504.14666</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.14666v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kaihang Pan, Wang Lin, Zhongqi Yue, Tenglong Ao, Liyu Jia, Wei Zhao, Juncheng Li, Siliang Tang, Hanwang Zhang</dc:creator>
        <description><![CDATA[
            背景：当前多模态大语言模型结合大语言模型和扩散模型以统一视觉理解与生成，但现有基于空间视觉标记的方法缺乏语言固有的递归结构，大语言模型难以掌握。方法：利用扩散时间步学习离散、递归的视觉标记，这些标记能补偿噪声图像中随时间步增加的属性损失，使扩散模型在任意时间步重建原始图像。效果：在统一框架下实现无缝多模态理解与生成，实验表明在多模态理解和生成上性能优于其他模型。
            arXiv:2504.14666v1 Announce Type: new 
Abstract: Recent endeavors in Multimodal Large Language Models (MLLMs) aim to unify visual comprehension and generation by combining LLM and diffusion models, the state-of-the-art in each task, respectively. Existing approaches rely on spatial visual tokens, where image patches are encoded and arranged according to a spatial order (e.g., raster scan). However, we show that spatial tokens lack the recursive structure inherent to languages, hence form an impossible language for LLM to master. In this paper, we build a proper visual language by leveraging diffusion timesteps to learn discrete, recursive visual tokens. Our proposed tokens recursively compensate for the progressive attribute loss in noisy images as timesteps increase, enabling the diffusion model to reconstruct the original image at any timestep. This approach allows us to effectively integrate the strengths of LLMs in autoregressive reasoning and diffusion models in precise image generation, achieving seamless multimodal comprehension and generation within a unified framework. Extensive experiments show that we achieve superior performance for multimodal comprehension and generation simultaneously compared with other MLLMs. Project Page: https://DDT-LLaMA.github.io/.
        ]]></description>
    </item>
    <item>
        <title>Evaluating Temporal Plasticity in Foundation Time Series Models for Incremental Fine-tuning</title>
        <link>https://arxiv.org/abs/2504.14677</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.14677v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jia Liu, Cheng Jinguo, Xia Fang, Zhenyuan Ma, Yuankai Wu</dc:creator>
        <description><![CDATA[
            背景：时间序列基础模型在预测任务表现出色，但增量学习能力待探索。方法：首次全面研究模型的时间可塑性，用新的持续学习框架在有分布偏移的真实数据集上，对传统深度学习模型和基础模型进行实验。效果：传统模型在增量微调时性能下降，而Time - MoE和Chronos等基础模型预测准确性持续提升，表明优化基础模型微调策略比开发特定领域小模型更有价值，为开发有强持续学习能力的模型提供新评估方法和见解。
            arXiv:2504.14677v1 Announce Type: new 
Abstract: Time series foundation models excel at diverse time series forecasting tasks, but their capacity for continuous improvement through incremental learning remains unexplored. We present the first comprehensive study investigating these models' temporal plasticity - their ability to progressively enhance performance through continual learning while maintaining existing capabilities. Through experiments on real-world datasets exhibiting distribution shifts, we evaluate both conventional deep learning models and foundation models using a novel continual learning framework. Our findings reveal that while traditional models struggle with performance deterioration during incremental fine-tuning, foundation models like Time-MoE and Chronos demonstrate sustained improvement in predictive accuracy. This suggests that optimizing foundation model fine-tuning strategies may be more valuable than developing domain-specific small models. Our research introduces new evaluation methodologies and insights for developing foundation time series models with robust continuous learning capabilities.
        ]]></description>
    </item>
    <item>
        <title>Reliable Multi-Modal Object Re-Identification via Modality-Aware Graph Reasoning</title>
        <link>https://arxiv.org/abs/2504.14847</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.14847v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xixi Wan, Aihua Zheng, Zi Wang, Bo Jiang, Jin Tang, Jixin Ma</dc:creator>
        <description><![CDATA[
            多模态数据在重识别任务中至关重要，但现有方法常忽略局部特征质量差异，未充分利用模态间互补信息。本文提出模态感知图推理网络（MGRNet）。先构建模态感知图，有效捕捉和建模图像块关系，增强细粒度局部细节提取；再采用选择性图节点交换操作，结合局部和全局信息减轻低质量特征影响；最后将交换后的图输入局部感知图推理模块得到可靠特征表示。该方法还能重建缺失模态信息。在四个基准测试中达最优性能。
            arXiv:2504.14847v1 Announce Type: new 
Abstract: Multi-modal data provides abundant and diverse object information, crucial for effective modal interactions in Re-Identification (ReID) tasks. However, existing approaches often overlook the quality variations in local features and fail to fully leverage the complementary information across modalities, particularly in the case of low-quality features. In this paper, we propose to address this issue by leveraging a novel graph reasoning model, termed the Modality-aware Graph Reasoning Network (MGRNet). Specifically, we first construct modality-aware graphs to enhance the extraction of fine-grained local details by effectively capturing and modeling the relationships between patches. Subsequently, the selective graph nodes swap operation is employed to alleviate the adverse effects of low-quality local features by considering both local and global information, enhancing the representation of discriminative information. Finally, the swapped modality-aware graphs are fed into the local-aware graph reasoning module, which propagates multi-modal information to yield a reliable feature representation. Another advantage of the proposed graph reasoning approach is its ability to reconstruct missing modal information by exploiting inherent structural relationships, thereby minimizing disparities between different modalities. Experimental results on four benchmarks (RGBNT201, Market1501-MM, RGBNT100, MSVR310) indicate that the proposed method achieves state-of-the-art performance in multi-modal object ReID. The code for our method will be available upon acceptance.
        ]]></description>
    </item>
    <item>
        <title>Retrieval Augmented Generation Evaluation in the Era of Large Language Models: A Comprehensive Survey</title>
        <link>https://arxiv.org/abs/2504.14891</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.14891v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Aoran Gan, Hao Yu, Kai Zhang, Qi Liu, Wenyu Yan, Zhenya Huang, Shiwei Tong, Guoping Hu</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）结合大语言模型与外部信息检索，革新自然语言处理，但评估RAG系统因混合架构和依赖动态知识源面临挑战。方法：本文全面调研RAG评估方法与框架，系统回顾传统和新兴评估方式，还整理分类特定数据集与评估框架，对高影响力研究的评估实践进行元分析。效果：该调研是目前最全面的RAG评估综述，衔接传统与大模型驱动方法，为推动RAG发展提供关键资源。
            arXiv:2504.14891v1 Announce Type: new 
Abstract: Recent advancements in Retrieval-Augmented Generation (RAG) have revolutionized natural language processing by integrating Large Language Models (LLMs) with external information retrieval, enabling accurate, up-to-date, and verifiable text generation across diverse applications. However, evaluating RAG systems presents unique challenges due to their hybrid architecture that combines retrieval and generation components, as well as their dependence on dynamic knowledge sources in the LLM era. In response, this paper provides a comprehensive survey of RAG evaluation methods and frameworks, systematically reviewing traditional and emerging evaluation approaches, for system performance, factual accuracy, safety, and computational efficiency in the LLM era. We also compile and categorize the RAG-specific datasets and evaluation frameworks, conducting a meta-analysis of evaluation practices in high-impact RAG research. To the best of our knowledge, this work represents the most comprehensive survey for RAG evaluation, bridging traditional and LLM-driven methods, and serves as a critical resource for advancing RAG development.
        ]]></description>
    </item>
    <item>
        <title>Efficient Document Retrieval with G-Retriever</title>
        <link>https://arxiv.org/abs/2504.14955</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.14955v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Manthankumar Solanki</dc:creator>
        <description><![CDATA[
            背景：文本数据问答因应用广泛受关注，现有基于RAG的方法用PCST构建子图，但仅关注节点属性，上下文理解不完整。方法：提出改进方法，用基于注意力的子图构建技术替代PCST，对节点和边属性编码以获得更丰富图表示，还加入改进投影层和多头注意力池化以更好与大语言模型对齐。效果：在WebQSP数据集实验显示，该方法有竞争力，比原方法结果略好，利于更准确问答。
            arXiv:2504.14955v1 Announce Type: new 
Abstract: Textual data question answering has gained significant attention due to its growing applicability. Recently, a novel approach leveraging the Retrieval-Augmented Generation (RAG) method was introduced, utilizing the Prize-Collecting Steiner Tree (PCST) optimization for sub-graph construction. However, this method focused solely on node attributes, leading to incomplete contextual understanding. In this paper, we propose an enhanced approach that replaces the PCST method with an attention-based sub-graph construction technique, enabling more efficient and context-aware retrieval. Additionally, we encode both node and edge attributes, leading to richer graph representations. Our method also incorporates an improved projection layer and multi-head attention pooling for better alignment with Large Language Models (LLMs). Experimental evaluations on the WebQSP dataset demonstrate that our approach is competitive and achieves marginally better results compared to the original method, underscoring its potential for more accurate question answering.
        ]]></description>
    </item>
    <item>
        <title>ScanEdit: Hierarchically-Guided Functional 3D Scan Editing</title>
        <link>https://arxiv.org/abs/2504.15049</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.15049v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mohamed el amine Boudjoghra, Ivan Laptev, Angela Dai</dc:creator>
        <description><![CDATA[
            背景：3D 捕捉技术发展迅速，3D 数据丰富，有效 3D 场景编辑对图形应用至关重要。方法：提出 ScanEdit，一种指令驱动的复杂真实 3D 扫描功能编辑方法，采用分层引导方式，构建分层场景图表示，利用大语言模型推理能力将高级语言指令转化为对场景图分层应用的可执行命令，还结合 LLM 引导与物理约束。效果：在大量实验评估中，ScanEdit 优于现有技术，对多种真实场景和输入指令都有出色表现。
            arXiv:2504.15049v1 Announce Type: new 
Abstract: With the fast pace of 3D capture technology and resulting abundance of 3D data, effective 3D scene editing becomes essential for a variety of graphics applications. In this work we present ScanEdit, an instruction-driven method for functional editing of complex, real-world 3D scans. To model large and interdependent sets of ob- jectswe propose a hierarchically-guided approach. Given a 3D scan decomposed into its object instances, we first construct a hierarchical scene graph representation to enable effective, tractable editing. We then leverage reason- ing capabilities of Large Language Models (LLMs) and translate high-level language instructions into actionable commands applied hierarchically to the scene graph. Fi- nally, ScanEdit integrates LLM-based guidance with ex- plicit physical constraints and generates realistic scenes where object arrangements obey both physics and common sense. In our extensive experimental evaluation ScanEdit outperforms state of the art and demonstrates excellent re- sults for a variety of real-world scenes and input instruc- tions.
        ]]></description>
    </item>
    <item>
        <title>Think2SQL: Reinforce LLM Reasoning Capabilities for Text2SQL</title>
        <link>https://arxiv.org/abs/2504.15077</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.15077v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Simone Papicchio, Simone Rossi, Luca Cagliero, Paolo Papotti</dc:creator>
        <description><![CDATA[
            背景：大语言模型处理文本到SQL转换有进步，但小模型在零样本学习下处理多表和复杂SQL模式问题仍有困难，推理对Text2SQL性能的影响待研究。方法：在四个基准数据集上，研究不同大语言模型训练策略（零样本学习、有/无特定任务推理痕迹的监督微调、强化学习、监督微调+强化学习）下推理能力对Text2SQL性能的影响。效果：零样本学习通用推理处理复杂Text2SQL无效；小模型经带推理的监督微调受益大；强化学习对各模型和数据集有益；7B的Qwen - Coder - 2.5在强化学习助力下，在Bird数据集上与超百亿参数模型表现相当。
            arXiv:2504.15077v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have shown impressive capabilities in transforming natural language questions about relational databases into SQL queries. Despite recent improvements, small LLMs struggle to handle questions involving multiple tables and complex SQL patterns under a Zero-Shot Learning (ZSL) setting. Supervised Fine-Tuning (SFT) partially compensate the knowledge deficits in pretrained models but falls short while dealing with queries involving multi-hop reasoning. To bridge this gap, different LLM training strategies to reinforce reasoning capabilities have been proposed, ranging from leveraging a thinking process within ZSL, including reasoning traces in SFT, or adopt Reinforcement Learning (RL) strategies. However, the influence of reasoning on Text2SQL performance is still largely unexplored. This paper investigates to what extent LLM reasoning capabilities influence their Text2SQL performance on four benchmark datasets. To this end, it considers the following LLM settings: (1) ZSL, including general-purpose reasoning or not; (2) SFT, with and without task-specific reasoning traces; (3) RL, leveraging execution accuracy as primary reward function; (4) SFT+RL, i.e, a two-stage approach that combines SFT and RL. The results show that general-purpose reasoning under ZSL proves to be ineffective in tackling complex Text2SQL cases. Small LLMs benefit from SFT with reasoning much more than larger ones, bridging the gap of their (weaker) model pretraining. RL is generally beneficial across all tested models and datasets, particularly when SQL queries involve multi-hop reasoning and multiple tables. Small LLMs with SFT+RL excel on most complex datasets thanks to a strategic balance between generality of the reasoning process and optimization of the execution accuracy. Thanks to RL, the7B Qwen-Coder-2.5 model performs on par with 100+ Billion ones on the Bird dataset.
        ]]></description>
    </item>
    <item>
        <title>Hierarchical Attention Fusion of Visual and Textual Representations for Cross-Domain Sequential Recommendation</title>
        <link>https://arxiv.org/abs/2504.15085</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.15085v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wangyu Wu, Zhenhong Chen, Siqi Song, Xianglin Qiua, Xiaowei Huang, Fei Ma, Jimin Xiao</dc:creator>
        <description><![CDATA[
            背景：跨领域序列推荐（CDSR）旨在利用多领域历史交互预测用户行为，需通过序列内和序列间物品关系建模跨领域偏好。方法：提出分层注意力融合视觉和文本表征（HAF - VT）方法，用冻结的CLIP模型生成图像和文本嵌入，以多模态数据丰富物品表征，采用分层注意力机制联合学习单领域和跨领域偏好。效果：在四个电商数据集上评估，HAF - VT在捕捉跨领域用户兴趣方面优于现有方法。
            arXiv:2504.15085v1 Announce Type: new 
Abstract: Cross-Domain Sequential Recommendation (CDSR) predicts user behavior by leveraging historical interactions across multiple domains, focusing on modeling cross-domain preferences through intra- and inter-sequence item relationships. Inspired by human cognitive processes, we propose Hierarchical Attention Fusion of Visual and Textual Representations (HAF-VT), a novel approach integrating visual and textual data to enhance cognitive modeling. Using the frozen CLIP model, we generate image and text embeddings, enriching item representations with multimodal data. A hierarchical attention mechanism jointly learns single-domain and cross-domain preferences, mimicking human information integration. Evaluated on four e-commerce datasets, HAF-VT outperforms existing methods in capturing cross-domain user interests, bridging cognitive principles with computational models and highlighting the role of multimodal data in sequential decision-making.
        ]]></description>
    </item>
    <item>
        <title>A Deep Learning Framework for Sequence Mining with Bidirectional LSTM and Multi-Scale Attention</title>
        <link>https://arxiv.org/abs/2504.15223</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.15223v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tao Yang, Yu Cheng, Yaokun Ren, Yujia Lou, Minggu Wei, Honghui Xin</dc:creator>
        <description><![CDATA[
            背景：复杂序列数据挖掘潜在模式和建模上下文依赖存在挑战。方法：提出一种将双向长短期记忆网络（BiLSTM）与多尺度注意力机制相结合的序列模式挖掘算法，BiLSTM捕获序列前后依赖，多尺度注意力模块为不同窗口大小下的关键特征区域分配自适应权重。效果：在公开多元时间序列数据集上实验，与主流序列建模方法对比，该模型在准确率、精确率和召回率上表现更优，消融和敏感性分析为模型结构优化提供支持。
            arXiv:2504.15223v1 Announce Type: new 
Abstract: This paper addresses the challenges of mining latent patterns and modeling contextual dependencies in complex sequence data. A sequence pattern mining algorithm is proposed by integrating Bidirectional Long Short-Term Memory (BiLSTM) with a multi-scale attention mechanism. The BiLSTM captures both forward and backward dependencies in sequences, enhancing the model's ability to perceive global contextual structures. At the same time, the multi-scale attention module assigns adaptive weights to key feature regions under different window sizes. This improves the model's responsiveness to both local and global important information. Extensive experiments are conducted on a publicly available multivariate time series dataset. The proposed model is compared with several mainstream sequence modeling methods. Results show that it outperforms existing models in terms of accuracy, precision, and recall. This confirms the effectiveness and robustness of the proposed architecture in complex pattern recognition tasks. Further ablation studies and sensitivity analyses are carried out to investigate the effects of attention scale and input sequence length on model performance. These results provide empirical support for structural optimization of the model.
        ]]></description>
    </item>
    <item>
        <title>VisuLogic: A Benchmark for Evaluating Visual Reasoning in Multi-modal Large Language Models</title>
        <link>https://arxiv.org/abs/2504.15279</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.15279v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Weiye Xu, Jiahao Wang, Weiyun Wang, Zhe Chen, Wengang Zhou, Aijun Yang, Lewei Lu, Houqiang Li, Xiaohua Wang, Xizhou Zhu, Wenhai Wang, Jifeng Dai, Jinguo Zhu</dc:creator>
        <description><![CDATA[
            背景：视觉推理是人类智能核心及先进多模态模型关键能力，但当前多模态大模型推理评估依赖文本描述，无法衡量真正以视觉为中心的推理。方法：提出VisuLogic基准，包含1000个经人工验证、分六类的问题，可多视角评估模型视觉推理能力，还提供补充训练数据集和强化学习基线。效果：评估主流多模态大模型，多数准确率低于30%，略高于25%的随机基线，远低于人类的51.4%，表明视觉推理能力差距大。
            arXiv:2504.15279v1 Announce Type: new 
Abstract: Visual reasoning is a core component of human intelligence and a critical capability for advanced multimodal models. Yet current reasoning evaluations of multimodal large language models (MLLMs) often rely on text descriptions and allow language-based reasoning shortcuts, failing to measure genuine vision-centric reasoning. To address this, we introduce VisuLogic: a benchmark of 1,000 human-verified problems across six categories (e.g., quantitative shifts, spatial relations, attribute comparisons). These various types of questions can be evaluated to assess the visual reasoning capabilities of MLLMs from multiple perspectives. We evaluate leading MLLMs on this benchmark and analyze their results to identify common failure modes. Most models score below 30% accuracy-only slightly above the 25% random baseline and far below the 51.4% achieved by humans-revealing significant gaps in visual reasoning. Furthermore, we provide a supplementary training dataset and a reinforcement-learning baseline to support further progress.
        ]]></description>
    </item>
    <item>
        <title>TALES: Text Adventure Learning Environment Suite</title>
        <link>https://arxiv.org/abs/2504.14128</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.14128v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Christopher Zhang Cui, Xingdi Yuan, Zhang Xiao, Prithviraj Ammanabrolu, Marc-Alexandre C\^ot\'e</dc:creator>
        <description><![CDATA[
            背景：推理能力是大语言模型与世界交互的关键，复杂任务对顺序决策的推理能力要求更高，需基于上下文历史进行结构化推理。方法：提出TALES，包含多种合成和人工编写的文本冒险游戏，用于挑战和评估不同推理能力，并对多种大语言模型进行实验和定性分析。效果：即使表现最佳的大语言模型驱动的智能体，在面向人类设计的游戏中成功率也未达15%。
            arXiv:2504.14128v1 Announce Type: cross 
Abstract: Reasoning is an essential skill to enable Large Language Models (LLMs) to interact with the world. As tasks become more complex, they demand increasingly sophisticated and diverse reasoning capabilities for sequential decision-making, requiring structured reasoning over the context history to determine the next best action. We introduce TALES, a diverse collection of synthetic and human-written text-adventure games designed to challenge and evaluate diverse reasoning capabilities. We present results over a range of LLMs, open- and closed-weights, performing a qualitative analysis on the top performing models. Despite an impressive showing on synthetic games, even the top LLM-driven agents fail to achieve 15% on games designed for human enjoyment. Code and visualization of the experiments can be found at https://microsoft.github.io/tales.
        ]]></description>
    </item>
    <item>
        <title>InfiGUI-R1: Advancing Multimodal GUI Agents from Reactive Actors to Deliberative Reasoners</title>
        <link>https://arxiv.org/abs/2504.14239</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.14239v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuhang Liu, Pengxiang Li, Congkai Xie, Xavier Hu, Xiaotian Han, Shengyu Zhang, Hongxia Yang, Fei Wu</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型助力GUI代理自动化设备任务，但当前方法依赖手动设计推理模板，部分代理推理深度不足。方法：提出基于MLLM的GUI代理InfiGUI - R1，通过Actor2Reasoner框架，分两阶段训练。第一阶段用空间推理蒸馏注入推理能力；第二阶段用强化学习，通过子目标引导和错误恢复场景构建增强推理。效果：InfiGUI - R1在GUI基础和轨迹任务中表现出色。
            arXiv:2504.14239v1 Announce Type: cross 
Abstract: Multimodal Large Language Models (MLLMs) have powered Graphical User Interface (GUI) Agents, showing promise in automating tasks on computing devices. Recent works have begun exploring reasoning in GUI tasks with encouraging results. However, many current approaches rely on manually designed reasoning templates, which may result in reasoning that is not sufficiently robust and adaptive for complex GUI environments. Meanwhile, some existing agents continue to operate as Reactive Actors, relying primarily on implicit reasoning that may lack sufficient depth for GUI tasks demanding planning and error recovery. We argue that advancing these agents requires a shift from reactive acting towards acting based on deliberate reasoning. To facilitate this transformation, we introduce InfiGUI-R1, an MLLM-based GUI agent developed through our Actor2Reasoner framework, a reasoning-centric, two-stage training approach designed to progressively evolve agents from Reactive Actors to Deliberative Reasoners. The first stage, Reasoning Injection, focuses on establishing a basic reasoner. We employ Spatial Reasoning Distillation to transfer cross-modal spatial reasoning capabilities from teacher models to MLLMs through trajectories with explicit reasoning steps, enabling models to integrate GUI visual-spatial information with logical reasoning before action generation. The second stage, Deliberation Enhancement, refines the basic reasoner into a deliberative one using Reinforcement Learning. This stage introduces two approaches: Sub-goal Guidance, which rewards models for generating accurate intermediate sub-goals, and Error Recovery Scenario Construction, which creates failure-and-recovery training scenarios from identified prone-to-error steps. Experimental results show InfiGUI-R1 achieves strong performance in GUI grounding and trajectory tasks. Resources at https://github.com/Reallm-Labs/InfiGUI-R1.
        ]]></description>
    </item>
    <item>
        <title>CHAINSFORMER: Numerical Reasoning on Knowledge Graphs from a Chain Perspective</title>
        <link>https://arxiv.org/abs/2504.14282</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.14282v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ze Zhao, Bin Lu, Xiaoying Gan, Gu Tang, Luoyi Fu, Xinbing Wang</dc:creator>
        <description><![CDATA[
            知识图谱推理在补全和问答系统中至关重要，现有图方法难以充分利用图中逻辑路径。为此提出ChainsFormer框架支持数值推理，它能显式构建逻辑链并拓展推理深度，引入关系 - 属性链建模顺序推理模式，采用顺序上下文学习捕捉多跳推理过程，用双曲亲和度评分机制选链，结合注意力数值推理器识别关键路径。实验表明，该方法显著优于现有方法，性能提升达20.0%。
            arXiv:2504.14282v1 Announce Type: cross 
Abstract: Reasoning over Knowledge Graphs (KGs) plays a pivotal role in knowledge graph completion or question answering systems, providing richer and more accurate triples and attributes. As numerical attributes become increasingly essential in characterizing entities and relations in KGs, the ability to reason over these attributes has gained significant importance. Existing graph-based methods such as Graph Neural Networks (GNNs) and Knowledge Graph Embeddings (KGEs), primarily focus on aggregating homogeneous local neighbors and implicitly embedding diverse triples. However, these approaches often fail to fully leverage the potential of logical paths within the graph, limiting their effectiveness in exploiting the reasoning process. To address these limitations, we propose ChainsFormer, a novel chain-based framework designed to support numerical reasoning. Chainsformer not only explicitly constructs logical chains but also expands the reasoning depth to multiple hops. Specially, we introduces Relation-Attribute Chains (RA-Chains), a specialized logic chain, to model sequential reasoning patterns. ChainsFormer captures the step-by-step nature of multi-hop reasoning along RA-Chains by employing sequential in-context learning. To mitigate the impact of noisy chains, we propose a hyperbolic affinity scoring mechanism that selects relevant logic chains in a variable-resolution space. Furthermore, ChainsFormer incorporates an attention-based numerical reasoner to identify critical reasoning paths, enhancing both reasoning accuracy and transparency. Experimental results demonstrate that ChainsFormer significantly outperforms state-of-the-art methods, achieving up to a 20.0% improvement in performance. The implementations are available at https://github.com/zhaodazhuang2333/ChainsFormer.
        ]]></description>
    </item>
    <item>
        <title>FinSage: A Multi-aspect RAG System for Financial Filings Question Answering</title>
        <link>https://arxiv.org/abs/2504.14493</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.14493v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xinyu Wang, Jijun Chi, Zhenghan Tai, Tung Sum Thomas Kwok, Muzhi Li, Zhuhong Li, Hailin He, Yuchen Hua, Peng Lu, Suyuchen Wang, Yihong Wu, Jerry Huang, Ling Zhou</dc:creator>
        <description><![CDATA[
            背景：金融领域利用大模型时需结合特定数据和工具，现有RAG系统难以处理金融文件中数据的异质性和监管标准的变化，导致信息提取准确性低。方法：提出FinSage框架，包含统一数据格式并生成元数据摘要的多模态预处理管道、结合查询扩展和元数据感知语义搜索的多路径检索系统，以及经直接偏好优化微调的领域重排序模块。效果：在FinanceBench数据集上准确率超最佳基线方法24.06%，召回率达92.51%，已在线上会议服务超1200人。
            arXiv:2504.14493v1 Announce Type: cross 
Abstract: Leveraging large language models in real-world settings often entails a need to utilize domain-specific data and tools in order to follow the complex regulations that need to be followed for acceptable use. Within financial sectors, modern enterprises increasingly rely on Retrieval-Augmented Generation (RAG) systems to address complex compliance requirements in financial document workflows. However, existing solutions struggle to account for the inherent heterogeneity of data (e.g., text, tables, diagrams) and evolving nature of regulatory standards used in financial filings, leading to compromised accuracy in critical information extraction. We propose the FinSage framework as a solution, utilizing a multi-aspect RAG framework tailored for regulatory compliance analysis in multi-modal financial documents. FinSage introduces three innovative components: (1) a multi-modal pre-processing pipeline that unifies diverse data formats and generates chunk-level metadata summaries, (2) a multi-path sparse-dense retrieval system augmented with query expansion (HyDE) and metadata-aware semantic search, and (3) a domain-specialized re-ranking module fine-tuned via Direct Preference Optimization (DPO) to prioritize compliance-critical content. Extensive experiments demonstrate that FinSage achieves an impressive recall of 92.51% on 75 expert-curated questions derived from surpasses the best baseline method on the FinanceBench question answering datasets by 24.06% in accuracy. Moreover, FinSage has been successfully deployed as financial question-answering agent in online meetings, where it has already served more than 1,200 people.
        ]]></description>
    </item>
    <item>
        <title>Phoenix: A Motion-based Self-Reflection Framework for Fine-grained Robotic Action Correction</title>
        <link>https://arxiv.org/abs/2504.14588</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.14588v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wenke Xia, Ruoxuan Feng, Dong Wang, Di Hu</dc:creator>
        <description><![CDATA[
            背景：构建可泛化的自我修正系统对机器人从故障中恢复至关重要，多模态大语言模型虽赋予机器人语义反思能力，但将语义反思转化为细粒度动作修正仍是挑战。方法：构建Phoenix框架，用运动指令连接高层语义反思与低层动作修正，采用双过程运动调整机制将语义反思转化为粗粒度运动指令调整，提出多任务运动条件扩散策略结合视觉观察进行高频动作修正，还开发终身学习方法。效果：实验证明该框架在多种操作任务中泛化性和鲁棒性优越。
            arXiv:2504.14588v1 Announce Type: cross 
Abstract: Building a generalizable self-correction system is crucial for robots to recover from failures. Despite advancements in Multimodal Large Language Models (MLLMs) that empower robots with semantic reflection ability for failure, translating semantic reflection into how to correct fine-grained robotic actions remains a significant challenge. To address this gap, we build the Phoenix framework, which leverages motion instruction as a bridge to connect high-level semantic reflection with low-level robotic action correction. In this motion-based self-reflection framework, we start with a dual-process motion adjustment mechanism with MLLMs to translate the semantic reflection into coarse-grained motion instruction adjustment. To leverage this motion instruction for guiding how to correct fine-grained robotic actions, a multi-task motion-conditioned diffusion policy is proposed to integrate visual observations for high-frequency robotic action correction. By combining these two models, we could shift the demand for generalization capability from the low-level manipulation policy to the MLLMs-driven motion adjustment model and facilitate precise, fine-grained robotic action correction. Utilizing this framework, we further develop a lifelong learning method to automatically improve the model's capability from interactions with dynamic environments. The experiments conducted in both the RoboMimic simulation and real-world scenarios prove the superior generalization and robustness of our framework across a variety of manipulation tasks. Our code is released at \href{https://github.com/GeWu-Lab/Motion-based-Self-Reflection-Framework}{https://github.com/GeWu-Lab/Motion-based-Self-Reflection-Framework}.
        ]]></description>
    </item>
    <item>
        <title>HealthGenie: Empowering Users with Healthy Dietary Guidance through Knowledge Graph and Large Language Models</title>
        <link>https://arxiv.org/abs/2504.14594</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.14594v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Fan Gao, Xinjie Zhao, Ding Xia, Zhongyi Zhou, Rui Yang, Jinghui Lu, Hang Jiang, Chanjun Park, Irene Li</dc:creator>
        <description><![CDATA[
            背景：寻求饮食指导需应对复杂专业知识并考虑个人健康状况，知识图谱能提供结构化营养信息，大语言模型便于对话式推荐。方法：提出HealthGenie系统，结合大语言模型和知识图谱，接收用户查询后进行优化并从预构建知识图谱中检索信息，可视化并突出相关内容，还可提供解释。用户能交互调整偏好。效果：通过实验表明，该系统能有效支持用户获个性化饮食指导，减少交互和认知负担，证明了两者集成在决策支持上的潜力。 
            arXiv:2504.14594v1 Announce Type: cross 
Abstract: Seeking dietary guidance often requires navigating complex professional knowledge while accommodating individual health conditions. Knowledge Graphs (KGs) offer structured and interpretable nutritional information, whereas Large Language Models (LLMs) naturally facilitate conversational recommendation delivery. In this paper, we present HealthGenie, an interactive system that combines the strengths of LLMs and KGs to provide personalized dietary recommendations along with hierarchical information visualization for a quick and intuitive overview. Upon receiving a user query, HealthGenie performs query refinement and retrieves relevant information from a pre-built KG. The system then visualizes and highlights pertinent information, organized by defined categories, while offering detailed, explainable recommendation rationales. Users can further tailor these recommendations by adjusting preferences interactively. Our evaluation, comprising a within-subject comparative experiment and an open-ended discussion, demonstrates that HealthGenie effectively supports users in obtaining personalized dietary guidance based on their health conditions while reducing interaction effort and cognitive load. These findings highlight the potential of LLM-KG integration in supporting decision-making through explainable and visualized information. We examine the system's usefulness and effectiveness with an N=12 within-subject study and provide design considerations for future systems that integrate conversational LLM and KG.
        ]]></description>
    </item>
    <item>
        <title>AlignRAG: An Adaptable Framework for Resolving Misalignments in Retrieval-Aware Reasoning of RAG</title>
        <link>https://arxiv.org/abs/2504.14858</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.14858v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiaqi Wei, Hao Zhou, Xiang Zhang, Di Zhang, Zijie Qiu, Wei Wei, Jinzhe Li, Wanli Ouyang, Siqi Sun</dc:creator>
        <description><![CDATA[
            检索增强生成（RAG）是知识文本生成的基础范式，但现有RAG管道常无法使推理轨迹与检索内容的证据约束对齐。为此，本文提出AlignRAG框架，将RAG视为检索感知推理问题。该框架通过迭代的批判驱动对齐（CDA）步骤缓解推理不对齐问题，包括构建训练语料库、生成对比批判、训练批判语言模型、应用CDA优化推理轨迹。实验表明，AlignRAG始终优于所有基线，可即插即用集成到现有RAG管道，推动了检索感知生成的发展。
            arXiv:2504.14858v1 Announce Type: cross 
Abstract: Retrieval-augmented generation (RAG) has emerged as a foundational paradigm for knowledge-grounded text generation. However, existing RAG pipelines often fail to ensure that the reasoning trajectories align with the evidential constraints imposed by retrieved content. In this paper, we reframe RAG as a problem of retrieval-aware reasoning and identify a core challenge: reasoning misalignment-the mismatch between a model's reasoning trajectory and the retrieved evidence. To address this challenge, we propose AlignRAG, a novel test-time framework that mitigates reasoning misalignment through iterative Critique-Driven Alignment (CDA) steps. In contrast to prior approaches that rely on static training or post-hoc selection, AlignRAG actively refines reasoning trajectories during inference by enforcing fine-grained alignment with evidence. Our framework introduces a new paradigm for retrieval-aware reasoning by: (1) constructing context-rich training corpora; (2) generating contrastive critiques from preference-aware reasoning trajectories; (3) training a dedicated \textit{Critic Language Model (CLM)} to identify reasoning misalignments; and (4) applying CDA steps to optimize reasoning trajectories iteratively. Empirical results demonstrate that AlignRAG consistently outperforms all baselines and could integrate as a plug-and-play module into existing RAG pipelines without further changes. By reconceptualizing RAG as a structured reasoning trajectory and establishing the test-time framework for correcting reasoning misalignments in RAG, AlignRAG provides practical advancements for retrieval-aware generation.
        ]]></description>
    </item>
    <item>
        <title>The Great Nugget Recall: Automating Fact Extraction and RAG Evaluation with Large Language Models</title>
        <link>https://arxiv.org/abs/2504.15068</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.15068v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ronak Pradeep, Nandan Thakur, Shivani Upadhyay, Daniel Campos, Nick Craswell, Jimmy Lin</dc:creator>
        <description><![CDATA[
            背景：大语言模型提升了信息访问系统能力，但RAG系统评估仍是进步障碍。方法：提出自动评估框架，将原用于TREC问答赛道的金块评估方法“重构”，用AutoNuggetizer框架借助大模型自动创建金块并分配给系统答案，与人工或半人工创建金块、手动分配的策略对比。效果：社区评估显示，全自动金块评估得分与人工评估在运行层面高度一致，独立自动化组件时一致性更强，为未来RAG系统开发提供权衡依据。
            arXiv:2504.15068v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) have significantly enhanced the capabilities of information access systems, especially with retrieval-augmented generation (RAG). Nevertheless, the evaluation of RAG systems remains a barrier to continued progress, a challenge we tackle in this work by proposing an automatic evaluation framework that is validated against human annotations. We believe that the nugget evaluation methodology provides a solid foundation for evaluating RAG systems. This approach, originally developed for the TREC Question Answering (QA) Track in 2003, evaluates systems based on atomic facts that should be present in good answers. Our efforts focus on "refactoring" this methodology, where we describe the AutoNuggetizer framework that specifically applies LLMs to both automatically create nuggets and automatically assign nuggets to system answers. In the context of the TREC 2024 RAG Track, we calibrate a fully automatic approach against strategies where nuggets are created manually or semi-manually by human assessors and then assigned manually to system answers. Based on results from a community-wide evaluation, we observe strong agreement at the run level between scores derived from fully automatic nugget evaluation and human-based variants. The agreement is stronger when individual framework components such as nugget assignment are automated independently. This suggests that our evaluation framework provides tradeoffs between effort and quality that can be used to guide the development of future RAG systems. However, further research is necessary to refine our approach, particularly in establishing robust per-topic agreement to diagnose system failures effectively.
        ]]></description>
    </item>
    <item>
        <title>KGMEL: Knowledge Graph-Enhanced Multimodal Entity Linking</title>
        <link>https://arxiv.org/abs/2504.15135</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.15135v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Juyeon Kim, Geon Lee, Taeuk Kim, Kijung Shin</dc:creator>
        <description><![CDATA[
            背景：实体链接能将文本提及与知识库中对应实体对齐，多模态实体链接结合文本和图像可提升准确性，但现有方法大多忽略知识图谱三元组的结构信息。方法：提出KGMEL框架，分三步，先利用视觉语言模型生成高质量三元组，再通过对比学习学习联合表示以检索候选实体，最后用大语言模型对候选实体三元组优化并确定最佳匹配实体。效果：在基准数据集上实验表明，KGMEL性能优于现有方法。
            arXiv:2504.15135v1 Announce Type: cross 
Abstract: Entity linking (EL) aligns textual mentions with their corresponding entities in a knowledge base, facilitating various applications such as semantic search and question answering. Recent advances in multimodal entity linking (MEL) have shown that combining text and images can reduce ambiguity and improve alignment accuracy. However, most existing MEL methods overlook the rich structural information available in the form of knowledge-graph (KG) triples. In this paper, we propose KGMEL, a novel framework that leverages KG triples to enhance MEL. Specifically, it operates in three stages: (1) Generation: Produces high-quality triples for each mention by employing vision-language models based on its text and images. (2) Retrieval: Learns joint mention-entity representations, via contrastive learning, that integrate text, images, and (generated or KG) triples to retrieve candidate entities for each mention. (3) Reranking: Refines the KG triples of the candidate entities and employs large language models to identify the best-matching entity for the mention. Extensive experiments on benchmark datasets demonstrate that KGMEL outperforms existing methods. Our code and datasets are available at: https://github.com/juyeonnn/KGMEL.
        ]]></description>
    </item>
    <item>
        <title>HyperFusion: A Hypernetwork Approach to Multimodal Integration of Tabular and Medical Imaging Data for Predictive Modeling</title>
        <link>https://arxiv.org/abs/2403.13319</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2403.13319v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Daniel Duenias, Brennan Nichyporuk, Tal Arbel, Tammy Riklin Raviv</dc:creator>
        <description><![CDATA[
            背景：整合医学影像和电子病历表格数据对现代医疗至关重要，但有效融合二者仍是研究热点。方法：提出基于超网络的新框架，通过根据电子病历值和测量结果调整图像处理来融合影像与表格数据。效果：在脑磁共振成像分析的脑龄预测和阿尔茨海默病分类两个任务中验证，该框架优于单模态模型和现有影像表格数据融合方法，代码见https://github.com/daniel4725/HyperFusion 。
            arXiv:2403.13319v3 Announce Type: replace 
Abstract: The integration of diverse clinical modalities such as medical imaging and the tabular data extracted from patients' Electronic Health Records (EHRs) is a crucial aspect of modern healthcare. Integrative analysis of multiple sources can provide a comprehensive understanding of the clinical condition of a patient, improving diagnosis and treatment decision. Deep Neural Networks (DNNs) consistently demonstrate outstanding performance in a wide range of multimodal tasks in the medical domain. However, the complex endeavor of effectively merging medical imaging with clinical, demographic and genetic information represented as numerical tabular data remains a highly active and ongoing research pursuit.
  We present a novel framework based on hypernetworks to fuse clinical imaging and tabular data by conditioning the image processing on the EHR's values and measurements. This approach aims to leverage the complementary information present in these modalities to enhance the accuracy of various medical applications. We demonstrate the strength and generality of our method on two different brain Magnetic Resonance Imaging (MRI) analysis tasks, namely, brain age prediction conditioned by subject's sex and multi-class Alzheimer's Disease (AD) classification conditioned by tabular data. We show that our framework outperforms both single-modality models and state-of-the-art MRI tabular data fusion methods. A link to our code can be found at https://github.com/daniel4725/HyperFusion
        ]]></description>
    </item>
    <item>
        <title>Temporal Knowledge Graph Question Answering: A Survey</title>
        <link>https://arxiv.org/abs/2406.14191</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2406.14191v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Miao Su, Zixuan Li, Zhuo Chen, Long Bai, Xiaolong Jin, Jiafeng Guo</dc:creator>
        <description><![CDATA[
            背景：知识库问答是基于知识库回答问题的领域，近年来，知识的动态变化使时态知识图谱问答（TKGQA）受关注，但该领域存在时态问题定义模糊、方法缺乏系统分类的问题。方法：从时态问题分类和方法分类两个视角进行全面调研，先建立详细的时态问题分类，再综述基于语义解析和基于TKG嵌入的两类TKGQA技术。效果：为TKGQA提供全面参考，指明潜在研究方向以推动该领域发展。
            arXiv:2406.14191v3 Announce Type: replace 
Abstract: Knowledge Base Question Answering (KBQA) has been a long-standing field to answer questions based on knowledge bases. Recently, the evolving dynamics of knowledge have attracted a growing interest in Temporal Knowledge Graph Question Answering (TKGQA), an emerging task to answer temporal questions. However, this field grapples with ambiguities in defining temporal questions and lacks a systematic categorization of existing methods for TKGQA. In response, this paper provides a thorough survey from two perspectives: the taxonomy of temporal questions and the methodological categorization for TKGQA. Specifically, we first establish a detailed taxonomy of temporal questions engaged in prior studies. Subsequently, we provide a comprehensive review of TKGQA techniques of two categories: semantic parsing-based and TKG embedding-based. Building on this review, the paper outlines potential research directions aimed at advancing the field of TKGQA. This work aims to serve as a comprehensive reference for TKGQA and to stimulate further research.
        ]]></description>
    </item>
    <item>
        <title>Multiple-Resolution Tokenization for Time Series Forecasting with an Application to Pricing</title>
        <link>https://arxiv.org/abs/2407.03185</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2407.03185v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Egon Per\v{s}ak, Miguel F. Anjos, Sebastian Lautz, Aleksandar Kolev</dc:creator>
        <description><![CDATA[
            背景：时间序列预测有需求，现有方法待提升。方法：提出用于时间序列预测的Transformer架构，聚焦时间序列标记化，含多分辨率时间序列修补、多分辨率时变已知变量模块、捕捉跨序列信息的混合器模块及新型输出头。效果：应用于大型零售商减价团队实际预测问题，实验表明该模型性能优于内部模型和选定的现有深度学习架构。
            arXiv:2407.03185v2 Announce Type: replace 
Abstract: We propose a transformer architecture for time series forecasting with a focus on time series tokenisation and apply it to a real-world prediction problem from the pricing domain. Our architecture aims to learn effective representations at many scales across all available data simultaneously. The model contains a number of novel modules: a differentiated form of time series patching which employs multiple resolutions, a multiple-resolution module for time-varying known variables, a mixer-based module for capturing cross-series information, and a novel output head with favourable scaling to account for the increased number of tokens. We present an application of this model to a real world prediction problem faced by the markdown team at a very large retailer. On the experiments conducted our model outperforms in-house models and the selected existing deep learning architectures.
        ]]></description>
    </item>
    <item>
        <title>IFShip: Interpretable Fine-grained Ship Classification with Domain Knowledge-Enhanced Vision-Language Models</title>
        <link>https://arxiv.org/abs/2408.06631</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2408.06631v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mingning Guo, Mengwei Wu, Yuxiang Shen, Haifeng Li, Chao Tao</dc:creator>
        <description><![CDATA[
            背景：端到端遥感细粒度船舶分类推理过程不可解释，被指为“黑箱”系统。方法：提出领域知识增强的思维链提示生成机制，半自动构建特定任务数据集TITANIC - FGS，训练通用视觉语言模型得到IFShip，基于其开发FGSC视觉聊天机器人，将分类问题转为逐步推理任务。效果：IFShip在可解释性和分类准确率上优于现有算法，在FGSC任务上表现优于LLaVA和MiniGPT - 4，能提供推理链和可解释说明。
            arXiv:2408.06631v4 Announce Type: replace 
Abstract: End-to-end interpretation currently dominates the remote sensing fine-grained ship classification (RS-FGSC) task. However, the inference process remains uninterpretable, leading to criticisms of these models as "black box" systems. To address this issue, we propose a domain knowledge-enhanced Chain-of-Thought (CoT) prompt generation mechanism, which is used to semi-automatically construct a task-specific instruction-following dataset, TITANIC-FGS. By training on TITANIC-FGS, we adapt general-domain vision-language models (VLMs) to the FGSC task, resulting in a model named IFShip. Building upon IFShip, we develop an FGSC visual chatbot that redefines the FGSC problem as a step-by-step reasoning task and conveys the reasoning process in natural language. Experimental results show that IFShip outperforms state-of-the-art FGSC algorithms in both interpretability and classification accuracy. Furthermore, compared to VLMs such as LLaVA and MiniGPT-4, IFShip demonstrates superior performance on the FGSC task. It provides an accurate chain of reasoning when fine-grained ship types are recognizable to the human eye and offers interpretable explanations when they are not. Our dataset is publicly available at: https://github.com/lostwolves/IFShip.
        ]]></description>
    </item>
    <item>
        <title>Seek and Solve Reasoning for Table Question Answering</title>
        <link>https://arxiv.org/abs/2409.05286</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2409.05286v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ruya Jiang, Chun Wang, Weihong Deng</dc:creator>
        <description><![CDATA[
            背景：表格结构和问题逻辑的复杂性使大语言模型处理基于表格的问答（TQA）任务困难，常需简化任务。方法：提出Seek-and-Solve管道，让大模型先寻找相关信息再回答问题，将两阶段在推理层面整合为连贯的Seek-and-Solve思维链（SS-CoT），还从该管道提炼单步TQA求解提示，用含SS-CoT路径的示例引导模型。效果：实验表明该方法提高了性能和可靠性，且效率高。
            arXiv:2409.05286v3 Announce Type: replace 
Abstract: The complexities of table structures and question logic make table-based question answering (TQA) tasks challenging for Large Language Models (LLMs), often requiring task simplification before solving. This paper reveals that the reasoning process during task simplification may be more valuable than the simplified tasks themselves and aims to improve TQA performance by leveraging LLMs' reasoning capabilities. We propose a Seek-and-Solve pipeline that instructs the LLM to first seek relevant information and then answer questions, integrating these two stages at the reasoning level into a coherent Seek-and-Solve Chain of Thought (SS-CoT). Additionally, we distill a single-step TQA-solving prompt from this pipeline, using demonstrations with SS-CoT paths to guide the LLM in solving complex TQA tasks under In-Context Learning settings. Our experiments show that our approaches result in improved performance and reliability while being efficient. Our findings emphasize the importance of eliciting LLMs' reasoning capabilities to handle complex TQA tasks effectively.
        ]]></description>
    </item>
    <item>
        <title>Reasoning-Enhanced Healthcare Predictions with Knowledge Graph Community Retrieval</title>
        <link>https://arxiv.org/abs/2410.04585</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.04585v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Pengcheng Jiang, Cao Xiao, Minhao Jiang, Parminder Bhatia, Taha Kass-Hout, Jimeng Sun, Jiawei Han</dc:creator>
        <description><![CDATA[
            大语言模型在临床决策支持中潜力巨大，但存在幻觉问题且缺乏细粒度医学知识，传统RAG方法常检索到稀疏或无关信息。为此提出KARE框架，将知识图谱社区级检索与大模型推理结合以提升医疗预测能力。该框架整合多源数据构建知识图谱，用层次图社区检测和总结组织图谱。创新点有：构建密集医学知识结构、采用动态知识检索机制、搭建推理增强预测框架。实验表明，KARE在死亡率和再入院预测上比领先模型高10.8 - 15.0%（MIMIC - III）和12.6 - 12.7%（MIMIC - IV），还增强了预测可信度。
            arXiv:2410.04585v2 Announce Type: replace 
Abstract: Large language models (LLMs) have demonstrated significant potential in clinical decision support. Yet LLMs still suffer from hallucinations and lack fine-grained contextual medical knowledge, limiting their high-stake healthcare applications such as clinical diagnosis. Traditional retrieval-augmented generation (RAG) methods attempt to address these limitations but frequently retrieve sparse or irrelevant information, undermining prediction accuracy. We introduce KARE, a novel framework that integrates knowledge graph (KG) community-level retrieval with LLM reasoning to enhance healthcare predictions. KARE constructs a comprehensive multi-source KG by integrating biomedical databases, clinical literature, and LLM-generated insights, and organizes it using hierarchical graph community detection and summarization for precise and contextually relevant information retrieval. Our key innovations include: (1) a dense medical knowledge structuring approach enabling accurate retrieval of relevant information; (2) a dynamic knowledge retrieval mechanism that enriches patient contexts with focused, multi-faceted medical insights; and (3) a reasoning-enhanced prediction framework that leverages these enriched contexts to produce both accurate and interpretable clinical predictions. Extensive experiments demonstrate that KARE outperforms leading models by up to 10.8-15.0% on MIMIC-III and 12.6-12.7% on MIMIC-IV for mortality and readmission predictions. In addition to its impressive prediction accuracy, our framework leverages the reasoning capabilities of LLMs, enhancing the trustworthiness of clinical predictions.
        ]]></description>
    </item>
    <item>
        <title>How Do Large Language Models Understand Graph Patterns? A Benchmark for Graph Pattern Comprehension</title>
        <link>https://arxiv.org/abs/2410.05298</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.05298v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xinnan Dai, Haohao Qu, Yifen Shen, Bohang Zhang, Qihao Wen, Wenqi Fan, Dongsheng Li, Jiliang Tang, Caihua Shan</dc:creator>
        <description><![CDATA[
            背景：大语言模型（LLMs）在图相关任务能力和局限的基准测试是热门研究领域，但在图模式挖掘潜力待探索。方法：引入全面基准评估LLMs在图模式任务能力，包括基于术语或拓扑描述判断其是否理解图模式、自主发现图模式能力，涵盖合成和真实数据集及多种模型共11个任务和7个模型。效果：LLMs有初步理解图模式能力，O1 - mini在多数任务表现优；输入数据格式与预训练知识对齐可提升性能；LLMs策略与传统算法有差异。
            arXiv:2410.05298v2 Announce Type: replace 
Abstract: Benchmarking the capabilities and limitations of large language models (LLMs) in graph-related tasks is becoming an increasingly popular and crucial area of research. Recent studies have shown that LLMs exhibit a preliminary ability to understand graph structures and node features. However, the potential of LLMs in graph pattern mining remains largely unexplored. This is a key component in fields such as computational chemistry, biology, and social network analysis. To bridge this gap, this work introduces a comprehensive benchmark to assess LLMs' capabilities in graph pattern tasks. We have developed a benchmark that evaluates whether LLMs can understand graph patterns based on either terminological or topological descriptions. Additionally, our benchmark tests the LLMs' capacity to autonomously discover graph patterns from data. The benchmark encompasses both synthetic and real datasets, and a variety of models, with a total of 11 tasks and 7 models. Our experimental framework is designed for easy expansion to accommodate new models and datasets. Our findings reveal that: (1) LLMs have preliminary abilities to understand graph patterns, with O1-mini outperforming in the majority of tasks; (2) Formatting input data to align with the knowledge acquired during pretraining can enhance performance; (3) The strategies employed by LLMs may differ from those used in conventional algorithms.
        ]]></description>
    </item>
    <item>
        <title>Tree of Attributes Prompt Learning for Vision-Language Models</title>
        <link>https://arxiv.org/abs/2410.11201</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.11201v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tong Ding, Wanhua Li, Zhongqi Miao, Hanspeter Pfister</dc:creator>
        <description><![CDATA[
            背景：现有视觉语言模型的提示学习方法仅用类别名追加可学习提示令牌获取文本特征，未充分利用类别名中的丰富上下文。方法：提出属性树提示学习（TAP），先让大语言模型为每个类别生成“概念 - 属性 - 描述”结构的属性树，再用视觉和文本提示令牌学习层次结构，还引入视觉条件池化模块提取特定实例文本特征。效果：在11个不同数据集的零样本泛化、跨数据集迁移和少样本分类任务上优于现有方法。
            arXiv:2410.11201v2 Announce Type: replace 
Abstract: Prompt learning has proven effective in adapting vision language models for downstream tasks. However, existing methods usually append learnable prompt tokens solely with the category names to obtain textual features, which fails to fully leverage the rich context indicated in the category name. To address this issue, we propose the Tree of Attributes Prompt learning (TAP), which first instructs LLMs to generate a tree of attributes with a "concept - attribute - description" structure for each category, and then learn the hierarchy with vision and text prompt tokens. Unlike existing methods that merely augment category names with a set of unstructured descriptions, our approach essentially distills structured knowledge graphs associated with class names from LLMs. Furthermore, our approach introduces text and vision prompts designed to explicitly learn the corresponding visual attributes, effectively serving as domain experts. Additionally, the general and diverse descriptions generated based on the class names may be wrong or absent in the specific given images. To address this misalignment, we further introduce a vision-conditional pooling module to extract instance-specific text features. Extensive experimental results demonstrate that our approach outperforms state-of-the-art methods on the zero-shot base-to-novel generalization, cross-dataset transfer, as well as few-shot classification across 11 diverse datasets. Code is available at https://github.com/HHenryD/TAP.
        ]]></description>
    </item>
    <item>
        <title>Unraveling Arithmetic in Large Language Models: The Role of Algebraic Structures</title>
        <link>https://arxiv.org/abs/2411.16260</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2411.16260v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Fu-Chieh Chang, You-Chen Lin, Pei-Yuan Wu</dc:creator>
        <description><![CDATA[
            背景：大语言模型虽借助思维链提示在数学能力上取得进展，但单步思维链中执行算术的机制不明。方法：提出大语言模型通过捕捉代数结构（如交换律和单位元性质）学习算术，利用自定义算术问题数据集实证，还给出理论证据，表明特定权重和偏置配置下，基于Transformer的大模型能生成对输入令牌排列和单位元存在保持不变的嵌入。效果：研究表明利用代数结构可增强大语言模型算术能力，为提升其算术性能提供思路。
            arXiv:2411.16260v3 Announce Type: replace 
Abstract: Large language models (LLMs) have demonstrated remarkable mathematical capabilities, largely driven by chain-of-thought (CoT) prompting, which decomposes complex reasoning into step-by-step solutions. This approach has enabled significant advancements, as evidenced by performance on benchmarks like GSM8K and MATH. However, the mechanisms underlying LLMs' ability to perform arithmetic in a single step of CoT remain poorly understood. Existing studies debate whether LLMs encode numerical values or rely on symbolic reasoning, while others explore attention and multi-layered processing in arithmetic tasks. In this work, we propose that LLMs learn arithmetic by capturing algebraic structures, such as commutativity and identity properties. Since these structures are observable through input-output relationships, they can generalize to unseen data. We empirically demonstrate that LLMs can learn algebraic structures using a custom dataset of arithmetic problems, as well as providing theoretical evidence showing that, under specific configurations of weights and biases, the transformer-based LLMs can generate embeddings that remain invariant to both permutations of input tokens and the presence of identity elements. Our findings indicate that leveraging algebraic structures can enhance the LLMs' arithmetic capabilities, offering insights into improving their arithmetic performance.
        ]]></description>
    </item>
    <item>
        <title>LongProc: Benchmarking Long-Context Language Models on Long Procedural Generation</title>
        <link>https://arxiv.org/abs/2501.05414</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2501.05414v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xi Ye, Fangcong Yin, Yinghui He, Joie Zhang, Howard Yen, Tianyu Gao, Greg Durrett, Danqi Chen</dc:creator>
        <description><![CDATA[
            现有长上下文语言模型（LCLMs）评估基准主要关注长上下文召回。本文提出新基准LongProc，包含六项程序生成任务，如从HTML提取结构化信息到TSV格式等，测试模型遵循指令、整合分散信息及生成结构化长文本（达8K个token）的能力，且可进行基于规则的可靠评估。对23个LCLMs在三个难度级别测试发现，开源模型在2K个token任务易失败，GPT - 4o在8K个token任务性能下降，推理模型因长思维链训练表现更好，LCLMs在长文本生成中难保持连贯性，显示当前模型有很大改进空间。
            arXiv:2501.05414v2 Announce Type: replace 
Abstract: Existing benchmarks for evaluating long-context language models (LCLMs) primarily focus on long-context recall, requiring models to produce short responses based on a few critical snippets while processing thousands of irrelevant tokens. We introduce LongProc (Long Procedural Generation), a new benchmark that requires both the integration of highly dispersed information and long-form generation. LongProc consists of six diverse procedural generation tasks, such as extracting structured information from HTML pages into a TSV format and executing complex search procedures to create travel plans. These tasks challenge LCLMs by testing their ability to follow detailed procedural instructions, synthesize and reason over dispersed information, and generate structured, long-form outputs (up to 8K tokens). Furthermore, as these tasks adhere to deterministic procedures and yield structured outputs, they enable reliable rule-based evaluation. We evaluated 23 LCLMs, including instruction-tuned models and recent reasoning models, on LongProc at three difficulty levels, with the maximum number of output tokens set at 500, 2K, and 8K. Notably, while all tested models claim a context window size above 32K tokens, open-weight models typically falter on 2K-token tasks, and closed-source models like GPT-4o show significant degradation on 8K-token tasks. Reasoning models achieve stronger overall performance in long-form generation, benefiting from long CoT training. Further analysis reveals that LCLMs struggle to maintain long-range coherence in long-form generations. These findings highlight critical limitations in current LCLMs and suggest substantial room for improvement. Data and code available at: https://princeton-pli.github.io/LongProc.
        ]]></description>
    </item>
    <item>
        <title>Multi-agent Auto-Bidding with Latent Graph Diffusion Models</title>
        <link>https://arxiv.org/abs/2503.05805</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.05805v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Dom Huh, Prasant Mohapatra</dc:creator>
        <description><![CDATA[
            背景：在大规模拍卖环境中，代理需在关键绩效指标约束下动态优化出价策略，且面临不确定、稀疏和随机变量等挑战。方法：提出基于扩散的自动出价框架，结合基于图的可学习嵌入和基于规划的潜在扩散模型，利用图表示捕捉印象机会的相互依赖和多代理动态模式，通过奖励对齐技术微调模型后验。效果：在真实和合成拍卖环境评估显示，在多个常见KPI指标上自动出价性能显著提升，预测拍卖结果的准确性也提高。
            arXiv:2503.05805v3 Announce Type: replace 
Abstract: This paper proposes a diffusion-based auto-bidding framework that leverages graph representations to model large-scale auction environments. In such settings, agents must dynamically optimize bidding strategies under constraints defined by key performance indicator (KPI) metrics, all while operating in competitive environments characterized by uncertain, sparse, and stochastic variables. To address these challenges, we introduce a novel approach combining learnable graph-based embeddings with a planning-based latent diffusion model (LDM). By capturing patterns and nuances underlying the interdependence of impression opportunities and the multi-agent dynamics of the auction environment, the graph representation enable expressive computations regarding auto-bidding outcomes. With reward alignment techniques, the LDM's posterior is fine-tuned to generate auto-bidding trajectories that maximize KPI metrics while satisfying constraint thresholds. Empirical evaluations on both real-world and synthetic auction environments demonstrate significant improvements in auto-bidding performance across multiple common KPI metrics, as well as accuracy in forecasting auction outcomes.
        ]]></description>
    </item>
    <item>
        <title>STI-Bench: Are MLLMs Ready for Precise Spatial-Temporal World Understanding?</title>
        <link>https://arxiv.org/abs/2503.23765</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.23765v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yun Li, Yiming Zhang, Tao Lin, XiangRui Liu, Wenxiao Cai, Zheng Liu, Bo Zhao</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型（MLLMs）用于具身AI和自动驾驶成趋势，但在现实应用中精确的时空理解能力待考察。方法：提出STI - Bench基准，通过估计和预测物体外观、姿态、位移和运动等挑战性任务评估MLLMs的时空理解能力，涵盖多种场景的机器人和车辆操作。效果：实验表明，现有先进的MLLMs在现实时空理解方面仍有困难，尤其在需要精确距离估计和运动分析的任务中表现不佳。
            arXiv:2503.23765v3 Announce Type: replace 
Abstract: The use of Multimodal Large Language Models (MLLMs) as an end-to-end solution for Embodied AI and Autonomous Driving has become a prevailing trend. While MLLMs have been extensively studied for visual semantic understanding tasks, their ability to perform precise and quantitative spatial-temporal understanding in real-world applications remains largely unexamined, leading to uncertain prospects. To evaluate models' Spatial-Temporal Intelligence, we introduce STI-Bench, a benchmark designed to evaluate MLLMs' spatial-temporal understanding through challenging tasks such as estimating and predicting the appearance, pose, displacement, and motion of objects. Our benchmark encompasses a wide range of robot and vehicle operations across desktop, indoor, and outdoor scenarios. The extensive experiments reveals that the state-of-the-art MLLMs still struggle in real-world spatial-temporal understanding, especially in tasks requiring precise distance estimation and motion analysis.
        ]]></description>
    </item>
    <item>
        <title>FROG: Effective Friend Recommendation in Online Games via Modality-aware User Preferences</title>
        <link>https://arxiv.org/abs/2504.09428</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09428v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qiwei Wang, Dandan Lin, Wenqing Lin, Ziming Wu</dc:creator>
        <description><![CDATA[
            背景：在线游戏成为用户娱乐重要部分，产生游戏好友推荐需求，但现有方法难以有效融合多模态用户特征与友谊图结构信息。方法：提出端到端模型FROG，解决现有方法忽视用户高阶结构接近性、无法学习特定模态下用户相关性、不能捕捉不同模态局部和全局用户偏好等问题，更好建模用户对潜在好友的偏好。效果：腾讯的离线评估和在线部署实验表明，FROG优于现有方法。
            arXiv:2504.09428v2 Announce Type: replace 
Abstract: Due to the convenience of mobile devices, the online games have become an important part for user entertainments in reality, creating a demand for friend recommendation in online games. However, none of existing approaches can effectively incorporate the multi-modal user features (e.g., images and texts) with the structural information in the friendship graph, due to the following limitations: (1) some of them ignore the high-order structural proximity between users, (2) some fail to learn the pairwise relevance between users at modality-specific level, and (3) some cannot capture both the local and global user preferences on different modalities. By addressing these issues, in this paper, we propose an end-to-end model FROG that better models the user preferences on potential friends. Comprehensive experiments on both offline evaluation and online deployment at Tencent have demonstrated the superiority of FROG over existing approaches.
        ]]></description>
    </item>
    <item>
        <title>Forecasting from Clinical Textual Time Series: Adaptations of the Encoder and Decoder Language Model Families</title>
        <link>https://arxiv.org/abs/2504.10340</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.10340v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Shahriar Noroozizadeh, Sayantan Kumar, Jeremy C. Weiss</dc:creator>
        <description><![CDATA[
            背景：传统机器学习依赖结构化数据，常未充分利用临床病例报告中的丰富时间信息。方法：提出从文本时间序列进行预测的问题，以大语言模型辅助标注流程提取的带时间戳临床发现为主要输入，系统评估多种模型，包括微调的基于解码器的大语言模型和基于编码器的Transformer。效果：编码器模型在长短时间事件预测中F1分数更高、时间一致性更好，微调掩码方法提升排序性能；指令微调解码器模型在生存分析，尤其早期预后方面有优势。
            arXiv:2504.10340v2 Announce Type: replace 
Abstract: Clinical case reports encode rich, temporal patient trajectories that are often underexploited by traditional machine learning methods relying on structured data. In this work, we introduce the forecasting problem from textual time series, where timestamped clinical findings -- extracted via an LLM-assisted annotation pipeline -- serve as the primary input for prediction. We systematically evaluate a diverse suite of models, including fine-tuned decoder-based large language models and encoder-based transformers, on tasks of event occurrence prediction, temporal ordering, and survival analysis. Our experiments reveal that encoder-based models consistently achieve higher F1 scores and superior temporal concordance for short- and long-horizon event forecasting, while fine-tuned masking approaches enhance ranking performance. In contrast, instruction-tuned decoder models demonstrate a relative advantage in survival analysis, especially in early prognosis settings. Our sensitivity analyses further demonstrate the importance of time ordering, which requires clinical time series construction, as compared to text ordering, the format of the text inputs that LLMs are classically trained on. This highlights the additional benefit that can be ascertained from time-ordered corpora, with implications for temporal tasks in the era of widespread LLM use.
        ]]></description>
    </item>
    <item>
        <title>The Other Side of the Coin: Exploring Fairness in Retrieval-Augmented Generation</title>
        <link>https://arxiv.org/abs/2504.12323</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.12323v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zheng Zhang, Ning Li, Qi Liu, Rui Li, Weibo Gao, Qingyang Mao, Zhenya Huang, Baosheng Yu, Dacheng Tao</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）可提升大语言模型性能，但在有重大社会影响的领域应用时，其对大模型公平性的影响引发关注。方法：通过改变大模型、检索器和检索源开展实验，发现小模型（<8B）集成检索机制会加剧不公平，为此提出FairFT（使检索器与大模型公平性对齐）和FairFilter（检索后过滤有偏内容）两种方法。效果：在真实数据集上验证，两种方法能在保持性能的同时提升公平性。
            arXiv:2504.12323v2 Announce Type: replace 
Abstract: Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by retrieving relevant document from external knowledge sources. By referencing this external knowledge, RAG effectively reduces the generation of factually incorrect content and addresses hallucination issues within LLMs. Recently, there has been growing attention to improving the performance and efficiency of RAG systems from various perspectives. While these advancements have yielded significant results, the application of RAG in domains with considerable societal implications raises a critical question about fairness: What impact does the introduction of the RAG paradigm have on the fairness of LLMs? To address this question, we conduct extensive experiments by varying the LLMs, retrievers, and retrieval sources. Our experimental analysis reveals that the scale of the LLMs plays a significant role in influencing fairness outcomes within the RAG framework. When the model scale is smaller than 8B, the integration of retrieval mechanisms often exacerbates unfairness in small-scale LLMs (e.g., LLaMA3.2-1B, Mistral-7B, and LLaMA3-8B). To mitigate the fairness issues introduced by RAG for small-scale LLMs, we propose two approaches, FairFT and FairFilter. Specifically, in FairFT, we align the retriever with the LLM in terms of fairness, enabling it to retrieve documents that facilitate fairer model outputs. In FairFilter, we propose a fairness filtering mechanism to filter out biased content after retrieval. Finally, we validate our proposed approaches on real-world datasets, demonstrating their effectiveness in improving fairness while maintaining performance.
        ]]></description>
    </item>
    <item>
        <title>Integrating Structural and Semantic Signals in Text-Attributed Graphs with BiGTex</title>
        <link>https://arxiv.org/abs/2504.12474</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.12474v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Azadeh Beiranvand, Seyed Mehdi Vahidipour</dc:creator>
        <description><![CDATA[
            背景：文本属性图（TAGs）在表示学习中需兼顾节点文本语义和图结构依赖，而图神经网络（GNNs）难处理文本，大语言模型（LLMs）又忽略图结构。方法：提出BiGTex架构，通过堆叠图 - 文本融合单元紧密集成GNNs和LLMs，实现文本与结构表示的双向注意力，用参数高效微调（LoRA）训练。效果：在五个基准数据集实验表明，BiGTex在节点分类中达最优，且有效泛化到链接预测，消融研究凸显软提示和双向注意力的重要性。
            arXiv:2504.12474v2 Announce Type: replace 
Abstract: Text-attributed graphs (TAGs) present unique challenges in representation learning by requiring models to capture both the semantic richness of node-associated texts and the structural dependencies of the graph. While graph neural networks (GNNs) excel at modeling topological information, they lack the capacity to process unstructured text. Conversely, large language models (LLMs) are proficient in text understanding but are typically unaware of graph structure. In this work, we propose BiGTex (Bidirectional Graph Text), a novel architecture that tightly integrates GNNs and LLMs through stacked Graph-Text Fusion Units. Each unit allows for mutual attention between textual and structural representations, enabling information to flow in both directions, text influencing structure and structure guiding textual interpretation. The proposed architecture is trained using parameter-efficient fine-tuning (LoRA), keeping the LLM frozen while adapting to task-specific signals. Extensive experiments on five benchmark datasets demonstrate that BiGTex achieves state-of-the-art performance in node classification and generalizes effectively to link prediction. An ablation study further highlights the importance of soft prompting and bi-directional attention in the model's success.
        ]]></description>
    </item>
    <item>
        <title>Deep Learning Models Meet Financial Data Modalities</title>
        <link>https://arxiv.org/abs/2504.13521</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.13521v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kasymkhan Khubiev, Mikhail Semenov</dc:creator>
        <description><![CDATA[
            背景：算法交易需从多样金融数据中提取信号，深度学习处理非结构化数据成果显著，但处理结构化金融数据仍是挑战。方法：研究将深度学习模型与金融数据模态结合，提出把限价订单簿分析融入算法交易的新方法，开发嵌入技术，将顺序限价订单簿快照作为基于图像表示的不同输入通道。效果：处理限价订单簿数据的方法在高频交易算法中达最优性能，凸显深度学习在金融应用中的有效性。
            arXiv:2504.13521v2 Announce Type: replace 
Abstract: Algorithmic trading relies on extracting meaningful signals from diverse financial data sources, including candlestick charts, order statistics on put and canceled orders, traded volume data, limit order books, and news flow. While deep learning has demonstrated remarkable success in processing unstructured data and has significantly advanced natural language processing, its application to structured financial data remains an ongoing challenge. This study investigates the integration of deep learning models with financial data modalities, aiming to enhance predictive performance in trading strategies and portfolio optimization. We present a novel approach to incorporating limit order book analysis into algorithmic trading by developing embedding techniques and treating sequential limit order book snapshots as distinct input channels in an image-based representation. Our methodology for processing limit order book data achieves state-of-the-art performance in high-frequency trading algorithms, underscoring the effectiveness of deep learning in financial applications.
        ]]></description>
    </item>
    <item>
        <title>Embedding Ontologies via Incorporating Extensional and Intensional Knowledge</title>
        <link>https://arxiv.org/abs/2402.01677</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2402.01677v5</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Keyu Wang, Guilin Qi, Jiaoyan Chen, Yi Huang, Tianxing Wu</dc:creator>
        <description><![CDATA[
            背景：本体包含丰富知识，分外延和内涵知识，但现有本体嵌入方法未能同时兼顾二者。方法：提出EIKE方法，将本体表示在外延和内涵两个空间，构建统一框架嵌入实例、概念及其关系，用基于几何的方法建模外延知识，用预训练语言模型建模内涵知识，可捕捉结构和文本信息。效果：在三个数据集的三元组分类和链接预测任务中显著优于现有方法，提供了更全面的领域视角。
            arXiv:2402.01677v5 Announce Type: replace-cross 
Abstract: Ontologies contain rich knowledge within domain, which can be divided into two categories, namely extensional knowledge and intensional knowledge. Extensional knowledge provides information about the concrete instances that belong to specific concepts in the ontology, while intensional knowledge details inherent properties, characteristics, and semantic associations among concepts. However, existing ontology embedding approaches fail to take both extensional knowledge and intensional knowledge into fine consideration simultaneously. In this paper, we propose a novel ontology embedding approach named EIKE (Extensional and Intensional Knowledge Embedding) by representing ontologies in two spaces, called extensional space and intensional space. EIKE presents a unified framework for embedding instances, concepts and their relations in an ontology, applying a geometry-based method to model extensional knowledge and a pretrained language model to model intensional knowledge, which can capture both structure information and textual information. Experimental results show that EIKE significantly outperforms state-of-the-art methods in three datasets for both triple classification and link prediction, indicating that EIKE provides a more comprehensive and representative perspective of the domain.
        ]]></description>
    </item>
    <item>
        <title>SLMRec: Distilling Large Language Models into Small for Sequential Recommendation</title>
        <link>https://arxiv.org/abs/2405.17890</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2405.17890v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wujiang Xu, Qitian Wu, Zujie Liang, Jiaojiao Han, Xuying Ning, Yunxiao Shi, Wenfang Lin, Yongfeng Zhang</dc:creator>
        <description><![CDATA[
            背景：序列推荐任务需根据用户历史交互预测其下一交互项，大语言模型虽效果好，但在该场景下必要性存疑，且因其规模大，应用于处理海量日志的平台不切实际。方法：在大规模行业数据集上实验，发现大语言模型多数中间层冗余，提出SLMRec，采用知识蒸馏方法赋能小语言模型，且可与量化、剪枝等技术结合。效果：仅用大语言模型推荐模型13%的参数达最优性能，训练和推理时间分别加速6.6倍和8.0倍。
            arXiv:2405.17890v4 Announce Type: replace-cross 
Abstract: Sequential Recommendation (SR) task involves predicting the next item a user is likely to interact with, given their past interactions. The SR models examine the sequence of a user's actions to discern more complex behavioral patterns and temporal dynamics. Recent research demonstrates the great impact of LLMs on sequential recommendation systems, either viewing sequential recommendation as language modeling or serving as the backbone for user representation. Although these methods deliver outstanding performance, there is scant evidence of the necessity of a large language model and how large the language model is needed, especially in the sequential recommendation scene. Meanwhile, due to the huge size of LLMs, it is inefficient and impractical to apply a LLM-based model in real-world platforms that often need to process billions of traffic logs daily. In this paper, we explore the influence of LLMs' depth by conducting extensive experiments on large-scale industry datasets. Surprisingly, our motivational experiments reveal that most intermediate layers of LLMs are redundant, indicating that pruning the remaining layers can still maintain strong performance. Motivated by this insight, we empower small language models for SR, namely SLMRec, which adopt a simple yet effective knowledge distillation method. Moreover, SLMRec is orthogonal to other post-training efficiency techniques, such as quantization and pruning, so that they can be leveraged in combination. Comprehensive experimental results illustrate that the proposed SLMRec model attains the best performance using only 13% of the parameters found in LLM-based recommendation models while simultaneously achieving up to 6.6x and 8.0x speedups in training and inference time costs, respectively. Besides, we provide a theoretical justification for why small language models can perform comparably to large language models in SR.
        ]]></description>
    </item>
    <item>
        <title>Beyond Sequence: Impact of Geometric Context for RNA Property Prediction</title>
        <link>https://arxiv.org/abs/2410.11933</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.11933v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Junjie Xu, Artem Moskalev, Tommaso Mansi, Mangal Prakash, Rui Liao</dc:creator>
        <description><![CDATA[
            背景：准确预测RNA属性对理解生物过程和开发疗法至关重要，现有工作多聚焦一维序列模型，忽略二维和三维几何背景。方法：首次系统评估将二维和三维几何信息融入RNA属性预测，引入含增强结构注释的RNA数据集用于模型评估。效果：显式几何编码模型表现优于序列模型，各RNA任务预测RMSE平均降低约12%，在低数据和部分标记场景表现出色；无几何信息的序列模型在测序噪声下更稳健，但需2 - 5倍训练数据才能达几何感知模型性能。
            arXiv:2410.11933v2 Announce Type: replace-cross 
Abstract: Accurate prediction of RNA properties, such as stability and interactions, is crucial for advancing our understanding of biological processes and developing RNA-based therapeutics. RNA structures can be represented as 1D sequences, 2D topological graphs, or 3D all-atom models, each offering different insights into its function. Existing works predominantly focus on 1D sequence-based models, which overlook the geometric context provided by 2D and 3D geometries. This study presents the first systematic evaluation of incorporating explicit 2D and 3D geometric information into RNA property prediction, considering not only performance but also real-world challenges such as limited data availability, partial labeling, sequencing noise, and computational efficiency. To this end, we introduce a newly curated set of RNA datasets with enhanced 2D and 3D structural annotations, providing a resource for model evaluation on RNA data. Our findings reveal that models with explicit geometry encoding generally outperform sequence-based models, with an average prediction RMSE reduction of around 12% across all various RNA tasks and excelling in low-data and partial labeling regimes, underscoring the value of explicitly incorporating geometric context. On the other hand, geometry-unaware sequence-based models are more robust under sequencing noise but often require around $2-5\times$ training data to match the performance of geometry-aware models. Our study offers further insights into the trade-offs between different RNA representations in practical applications and addresses a significant gap in evaluating deep learning models for RNA tasks.
        ]]></description>
    </item>
    <item>
        <title>MaCTG: Multi-Agent Collaborative Thought Graph for Automatic Programming</title>
        <link>https://arxiv.org/abs/2410.19245</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.19245v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zixiao Zhao, Jing Sun, Zhe Hou, Zhiyuan Wei, Cheng-Hao Cai, Miao Qiao, Jin Song Dong</dc:creator>
        <description><![CDATA[
            背景：大语言模型在自动编程领域存在局限，单模型限于函数级代码生成，多智能体系统任务规划低效。方法：提出MaCTG框架，采用动态图结构实现任务精准分配与协作，自主分配角色、动态调整任务、验证集成代码，还采用混合大模型部署。效果：应用于图像处理自动编程任务，准确率达83.33%，相比现有多智能体框架，运营成本降低89.09%，展现出高效性、可扩展性和实用性。
            arXiv:2410.19245v2 Announce Type: replace-cross 
Abstract: With the rapid advancement of Large Language Models (LLMs), LLM-based approaches have demonstrated strong problem-solving capabilities across various domains. However, in automatic programming, a single LLM is typically limited to function-level code generation, while multi-agent systems composed of multiple LLMs often suffer from inefficient task planning. This lack of structured coordination can lead to cascading hallucinations, where accumulated errors across agents result in suboptimal workflows and excessive computational costs. To overcome these challenges, we introduce MaCTG (Multi-Agent Collaborative Thought Graph), a novel multi-agent framework that employs a dynamic graph structure to facilitate precise task allocation and controlled collaboration among LLM agents. MaCTG autonomously assigns agent roles based on programming requirements, dynamically refines task distribution through context-aware adjustments, and systematically verifies and integrates project-level code, effectively reducing hallucination errors and improving overall accuracy. MaCTG enhances cost-effectiveness by implementing a hybrid LLM deployment, where proprietary models handle complex reasoning, while open-source models are used for routine coding and validation tasks. To evaluate MaCTG's effectiveness, we applied it to traditional image processing auto-programming tasks, achieving a state-of-the-art accuracy of 83.33%. Additionally, by leveraging its hybrid LLM configuration, MaCTG significantly reduced operational costs by 89.09% compared to existing multi-agent frameworks, demonstrating its efficiency, scalability, and real-world applicability.
        ]]></description>
    </item>
    <item>
        <title>CTINexus: Automatic Cyber Threat Intelligence Knowledge Graph Construction Using Large Language Models</title>
        <link>https://arxiv.org/abs/2410.21060</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.21060v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yutong Cheng, Osama Bajaber, Saimon Amanuel Tsegai, Dawn Song, Peng Gao</dc:creator>
        <description><![CDATA[
            背景：网络威胁情报（CTI）报告文本是网络威胁知识的重要来源，但现有CTI知识提取方法缺乏灵活性和泛化性。方法：提出CTINexus框架，利用大语言模型优化的上下文学习进行高效CTI知识提取和高质量网络安全知识图（CSKG）构建，包括自动提示构建、分层实体对齐和长距离关系预测技术。效果：对150份CTI报告的评估显示，CTINexus在构建准确完整的CSKG方面显著优于现有方法。
            arXiv:2410.21060v2 Announce Type: replace-cross 
Abstract: Textual descriptions in cyber threat intelligence (CTI) reports, such as security articles and news, are rich sources of knowledge about cyber threats, crucial for organizations to stay informed about the rapidly evolving threat landscape. However, current CTI knowledge extraction methods lack flexibility and generalizability, often resulting in inaccurate and incomplete knowledge extraction. Syntax parsing relies on fixed rules and dictionaries, while model fine-tuning requires large annotated datasets, making both paradigms challenging to adapt to new threats and ontologies. To bridge the gap, we propose CTINexus, a novel framework leveraging optimized in-context learning (ICL) of large language models (LLMs) for data-efficient CTI knowledge extraction and high-quality cybersecurity knowledge graph (CSKG) construction. Unlike existing methods, CTINexus requires neither extensive data nor parameter tuning and can adapt to various ontologies with minimal annotated examples. This is achieved through: (1) a carefully designed automatic prompt construction strategy with optimal demonstration retrieval for extracting a wide range of cybersecurity entities and relations; (2) a hierarchical entity alignment technique that canonicalizes the extracted knowledge and removes redundancy; (3) an long-distance relation prediction technique to further complete the CSKG with missing links. Our extensive evaluations using 150 real-world CTI reports collected from 10 platforms demonstrate that CTINexus significantly outperforms existing methods in constructing accurate and complete CSKG, highlighting its potential to transform CTI analysis with an efficient and adaptable solution for the dynamic threat landscape.
        ]]></description>
    </item>
    <item>
        <title>Understanding and Optimizing Multi-Stage AI Inference Pipelines</title>
        <link>https://arxiv.org/abs/2504.09775</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09775v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Abhimanyu Rajeshkumar Bambhaniya, Hanjiang Wu, Suvinay Subramanian, Sudarshan Srinivasan, Souvik Kundu, Amir Yazdanbakhsh, Midhilesh Elavazhagan, Madhu Kumar, Tushar Krishna</dc:creator>
        <description><![CDATA[
            背景：大语言模型发展促使推理流水线和硬件平台日益复杂，现有模拟器难以对异构多引擎工作流建模。方法：提出HERMES，一个异构多阶段大语言模型推理执行模拟器，可对复杂硬件层次上的多种请求阶段建模，支持异构客户端并发执行多模型，结合真实硬件跟踪和分析建模。效果：通过案例研究探索推理阶段对端到端延迟的影响等，能为系统设计者提供优化软硬件协同设计的可行见解，助力下一代AI工作负载。
            arXiv:2504.09775v3 Announce Type: replace-cross 
Abstract: The rapid evolution of Large Language Models (LLMs) has driven the need for increasingly sophisticated inference pipelines and hardware platforms. Modern LLM serving extends beyond traditional prefill-decode workflows, incorporating multi-stage processes such as Retrieval Augmented Generation (RAG), key-value (KV) cache retrieval, dynamic model routing, and multi step reasoning. These stages exhibit diverse computational demands, requiring distributed systems that integrate GPUs, ASICs, CPUs, and memory-centric architectures. However, existing simulators lack the fidelity to model these heterogeneous, multi-engine workflows, limiting their ability to inform architectural decisions.
  To address this gap, we introduce HERMES, a Heterogeneous Multi-stage LLM inference Execution Simulator. HERMES models diverse request stages; including RAG, KV retrieval, reasoning, prefill, and decode across complex hardware hierarchies. HERMES supports heterogeneous clients executing multiple models concurrently unlike prior frameworks while incorporating advanced batching strategies and multi-level memory hierarchies. By integrating real hardware traces with analytical modeling, HERMES captures critical trade-offs such as memory bandwidth contention, inter-cluster communication latency, and batching efficiency in hybrid CPU-accelerator deployments. Through case studies, we explore the impact of reasoning stages on end-to-end latency, optimal batching strategies for hybrid pipelines, and the architectural implications of remote KV cache retrieval. HERMES empowers system designers to navigate the evolving landscape of LLM inference, providing actionable insights into optimizing hardware-software co-design for next-generation AI workloads.
        ]]></description>
    </item>
    <item>
        <title>Transformation of audio embeddings into interpretable, concept-based representations</title>
        <link>https://arxiv.org/abs/2504.14076</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.14076v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Alice Zhang, Edison Thomaz, Lie Lu</dc:creator>
        <description><![CDATA[
            背景：音频神经网络虽在下游音频任务取得佳绩，但黑箱结构使内部音频表征信息难以解释。方法：借助将音频和文本映射到共享嵌入空间的对比学习模型CLAP，探索音频嵌入的语义可解释性，并采用事后方法将CLAP嵌入转换为基于概念、具有语义可解释性的稀疏表征。效果：定性和定量评估显示，基于概念的表征在下游任务中表现不逊于原音频嵌入，且具备可解释性，微调后性能还可进一步提升，同时发布三个用于音频嵌入概念解释的特定音频词汇表。
            arXiv:2504.14076v1 Announce Type: new 
Abstract: Advancements in audio neural networks have established state-of-the-art results on downstream audio tasks. However, the black-box structure of these models makes it difficult to interpret the information encoded in their internal audio representations. In this work, we explore the semantic interpretability of audio embeddings extracted from these neural networks by leveraging CLAP, a contrastive learning model that brings audio and text into a shared embedding space. We implement a post-hoc method to transform CLAP embeddings into concept-based, sparse representations with semantic interpretability. Qualitative and quantitative evaluations show that the concept-based representations outperform or match the performance of original audio embeddings on downstream tasks while providing interpretability. Additionally, we demonstrate that fine-tuning the concept-based representations can further improve their performance on downstream tasks. Lastly, we publish three audio-specific vocabularies for concept-based interpretability of audio embeddings.
        ]]></description>
    </item>
    <item>
        <title>DiffVox: A Differentiable Model for Capturing and Analysing Professional Effects Distributions</title>
        <link>https://arxiv.org/abs/2504.14735</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.14735v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chin-Yun Yu, Marco A. Mart\'inez-Ram\'irez, Junghyun Koo, Ben Hayes, Wei-Hsiang Liao, Gy\"orgy Fazekas, Yuki Mitsufuji</dc:creator>
        <description><![CDATA[
            背景：音乐制作中需匹配人声效果。方法：提出可解释模型DiffVox，将参数均衡、动态范围控制、延迟和混响与高效可微实现相结合，通过基于梯度的优化进行参数估计，从两个数据集获取人声预设，并进行参数相关性分析、主成分分析和统计测试。效果：分析显示效果与参数间有强关联，主成分与McAdams音色维度相关，证实参数分布非高斯性，为后续人声效果建模和自动混音研究奠定基础。代码和数据集见https://github.com/SonyResearch/diffvox。
            arXiv:2504.14735v1 Announce Type: new 
Abstract: This study introduces a novel and interpretable model, DiffVox, for matching vocal effects in music production. DiffVox, short for ``Differentiable Vocal Fx", integrates parametric equalisation, dynamic range control, delay, and reverb with efficient differentiable implementations to enable gradient-based optimisation for parameter estimation. Vocal presets are retrieved from two datasets, comprising 70 tracks from MedleyDB and 365 tracks from a private collection. Analysis of parameter correlations highlights strong relationships between effects and parameters, such as the high-pass and low-shelf filters often behaving together to shape the low end, and the delay time correlates with the intensity of the delayed signals. Principal component analysis reveals connections to McAdams' timbre dimensions, where the most crucial component modulates the perceived spaciousness while the secondary components influence spectral brightness. Statistical testing confirms the non-Gaussian nature of the parameter distribution, highlighting the complexity of the vocal effects space. These initial findings on the parameter distributions set the foundation for future research in vocal effects modelling and automatic mixing. Our source code and datasets are accessible at https://github.com/SonyResearch/diffvox.
        ]]></description>
    </item>
    <item>
        <title>OmniAudio: Generating Spatial Audio from 360-Degree Video</title>
        <link>https://arxiv.org/abs/2504.14906</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.14906v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Huadai Liu, Tianyi Luo, Qikai Jiang, Kaicheng Luo, Peiwen Sun, Jialei Wan, Rongjie Huang, Qian Chen, Wen Wang, Xiangtai Li, Shiliang Zhang, Zhijie Yan, Zhou Zhao, Wei Xue</dc:creator>
        <description><![CDATA[
            传统视频到音频生成技术多关注视野视频和非空间音频，缺乏3D环境声音源空间线索。为此，提出360V2SA任务，即从360度视频生成空间音频（FOA格式）。创建了适配此任务的Sphere360数据集及数据采集清理流程。提出OmniAudio框架，利用自监督预训练结合空间和非空间音频数据，采用双分支结构捕捉360度视频信息。实验表明，该框架在Sphere360数据集的主客观指标上均达最优。
            arXiv:2504.14906v1 Announce Type: new 
Abstract: Traditional video-to-audio generation techniques primarily focus on field-of-view (FoV) video and non-spatial audio, often missing the spatial cues necessary for accurately representing sound sources in 3D environments. To address this limitation, we introduce a novel task, 360V2SA, to generate spatial audio from 360-degree videos, specifically producing First-order Ambisonics (FOA) audio - a standard format for representing 3D spatial audio that captures sound directionality and enables realistic 3D audio reproduction. We first create Sphere360, a novel dataset tailored for this task that is curated from real-world data. We also design an efficient semi-automated pipeline for collecting and cleaning paired video-audio data. To generate spatial audio from 360-degree video, we propose a novel framework OmniAudio, which leverages self-supervised pre-training using both spatial audio data (in FOA format) and large-scale non-spatial data. Furthermore, OmniAudio features a dual-branch framework that utilizes both panoramic and FoV video inputs to capture comprehensive local and global information from 360-degree videos. Experimental results demonstrate that OmniAudio achieves state-of-the-art performance across both objective and subjective metrics on Sphere360. Code and datasets will be released at https://github.com/liuhuadai/OmniAudio. The demo page is available at https://OmniAudio-360V2SA.github.io.
        ]]></description>
    </item>
    <item>
        <title>Aria-MIDI: A Dataset of Piano MIDI Files for Symbolic Music Modeling</title>
        <link>https://arxiv.org/abs/2504.15071</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.15071v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Louis Bradshaw, Simon Colton</dc:creator>
        <description><![CDATA[
            背景：为符号音乐建模提供新的MIDI文件数据集。方法：将钢琴演奏音频转录为音符创建数据集，数据处理采用多阶段流程，先用语言模型基于元数据从互联网抓取并评分音频，再用音频分类器进行修剪和分割。效果：得到超100万个不同的MIDI文件，约10万小时转录音频，还对技术深入分析，提取元数据标签。数据集见https://github.com/loubbrad/aria-midi 。
            arXiv:2504.15071v1 Announce Type: new 
Abstract: We introduce an extensive new dataset of MIDI files, created by transcribing audio recordings of piano performances into their constituent notes. The data pipeline we use is multi-stage, employing a language model to autonomously crawl and score audio recordings from the internet based on their metadata, followed by a stage of pruning and segmentation using an audio classifier. The resulting dataset contains over one million distinct MIDI files, comprising roughly 100,000 hours of transcribed audio. We provide an in-depth analysis of our techniques, offering statistical insights, and investigate the content by extracting metadata tags, which we also provide. Dataset available at https://github.com/loubbrad/aria-midi.
        ]]></description>
    </item>
    <item>
        <title>DRAGON: Distributional Rewards Optimize Diffusion Generative Models</title>
        <link>https://arxiv.org/abs/2504.15217</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.15217v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yatong Bai, Jonah Casebeer, Somayeh Sojoudi, Nicholas J. Bryan</dc:creator>
        <description><![CDATA[
            背景：传统强化学习微调媒体生成模型存在局限。方法：提出DRAGON框架，可优化评估单个样本或样本分布的奖励函数，通过选择编码器和参考示例构建奖励函数，收集生成结果并划分正负集以最大化奖励。效果：对音频领域文本到音乐扩散模型用20种奖励函数微调，在所有目标奖励上平均胜率达81.45%；在无人类偏好标注训练下，用合适示例集使音乐质量人类投票胜率达60.95%，为提升人类感知质量提供新途径。
            arXiv:2504.15217v1 Announce Type: new 
Abstract: We present Distributional RewArds for Generative OptimizatioN (DRAGON), a versatile framework for fine-tuning media generation models towards a desired outcome. Compared with traditional reinforcement learning with human feedback (RLHF) or pairwise preference approaches such as direct preference optimization (DPO), DRAGON is more flexible. It can optimize reward functions that evaluate either individual examples or distributions of them, making it compatible with a broad spectrum of instance-wise, instance-to-distribution, and distribution-to-distribution rewards. Leveraging this versatility, we construct novel reward functions by selecting an encoder and a set of reference examples to create an exemplar distribution. When cross-modality encoders such as CLAP are used, the reference examples may be of a different modality (e.g., text versus audio). Then, DRAGON gathers online and on-policy generations, scores them to construct a positive demonstration set and a negative set, and leverages the contrast between the two sets to maximize the reward. For evaluation, we fine-tune an audio-domain text-to-music diffusion model with 20 different reward functions, including a custom music aesthetics model, CLAP score, Vendi diversity, and Frechet audio distance (FAD). We further compare instance-wise (per-song) and full-dataset FAD settings while ablating multiple FAD encoders and reference sets. Over all 20 target rewards, DRAGON achieves an 81.45% average win rate. Moreover, reward functions based on exemplar sets indeed enhance generations and are comparable to model-based rewards. With an appropriate exemplar set, DRAGON achieves a 60.95% human-voted music quality win rate without training on human preference annotations. As such, DRAGON exhibits a new approach to designing and optimizing reward functions for improving human-perceived quality. Sound examples at https://ml-dragon.github.io/web.
        ]]></description>
    </item>
    <item>
        <title>Evaluating Human-AI Interaction via Usability, User Experience and Acceptance Measures for MMM-C: A Creative AI System for Music Composition</title>
        <link>https://arxiv.org/abs/2504.14071</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.14071v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Renaud Bougueng Tchemeube, Jeff Ens, Cale Plut, Philippe Pasquier, Maryam Safi, Yvan Grabit, Jean-Baptiste Rolland</dc:creator>
        <description><![CDATA[
            背景：随着人工智能发展，音乐领域的人机共创备受关注。方法：将多轨音乐机器（MMM）集成到Cubase中，创建“单参数”插件接口MMM - Cubase（MMM - C）以实现人机共创音乐，并通过三部分混合方法研究，对业余和专业两组专家级作曲家进行系统的可用性、用户体验和技术接受度评估。效果：系统获得了积极的可用性和接受度评分，用户反馈使用时体验到新奇、惊喜且操作简便，但在音乐生成时界面可控性和可预测性有局限，两组用户间无显著差异。
            arXiv:2504.14071v1 Announce Type: cross 
Abstract: With the rise of artificial intelligence (AI), there has been increasing interest in human-AI co-creation in a variety of artistic domains including music as AI-driven systems are frequently able to generate human-competitive artifacts. Now, the implications of such systems for musical practice are being investigated. We report on a thorough evaluation of the user adoption of the Multi-Track Music Machine (MMM) as a co-creative AI tool for music composers. To do this, we integrate MMM into Cubase, a popular Digital Audio Workstation (DAW) by Steinberg, by producing a "1-parameter" plugin interface named MMM-Cubase (MMM-C), which enables human-AI co-composition. We contribute a methodological assemblage as a 3-part mixed method study measuring usability, user experience and technology acceptance of the system across two groups of expert-level composers: hobbyists and professionals. Results show positive usability and acceptance scores. Users report experiences of novelty, surprise and ease of use from using the system, and limitations on controllability and predictability of the interface when generating music. Findings indicate no significant difference between the two user groups.
        ]]></description>
    </item>
    <item>
        <title>SOLIDO: A Robust Watermarking Method for Speech Synthesis via Low-Rank Adaptation</title>
        <link>https://arxiv.org/abs/2504.15035</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.15035v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yue Li, Weizhi Liu, Dongdong Lin</dc:creator>
        <description><![CDATA[
            背景：语音生成模型发展带来安全问题，现有生成水印技术计算开销大、训练成本高，处理可变长度输入时鲁棒性有限。方法：提出SOLIDO，将参数高效微调与语音水印结合，通过低秩自适应用于语音扩散模型；水印编码器转换水印，设计基于深度可分离卷积的解码器恢复水印，提出语音驱动轻量级微调策略。效果：在2000 bps大容量下保证高保真水印语音，对抗常见攻击平均提取准确率最高达99.20%和98.43%，抗时间拉伸攻击超现有方法近23%。
            arXiv:2504.15035v1 Announce Type: cross 
Abstract: The accelerated advancement of speech generative models has given rise to security issues, including model infringement and unauthorized abuse of content. Although existing generative watermarking techniques have proposed corresponding solutions, most methods require substantial computational overhead and training costs. In addition, some methods have limitations in robustness when handling variable-length inputs. To tackle these challenges, we propose \textsc{SOLIDO}, a novel generative watermarking method that integrates parameter-efficient fine-tuning with speech watermarking through low-rank adaptation (LoRA) for speech diffusion models. Concretely, the watermark encoder converts the watermark to align with the input of diffusion models. To achieve precise watermark extraction from variable-length inputs, the watermark decoder based on depthwise separable convolution is designed for watermark recovery. To further enhance speech generation performance and watermark extraction capability, we propose a speech-driven lightweight fine-tuning strategy, which reduces computational overhead through LoRA. Comprehensive experiments demonstrate that the proposed method ensures high-fidelity watermarked speech even at a large capacity of 2000 bps. Furthermore, against common individual and compound speech attacks, our SOLIDO achieves a maximum average extraction accuracy of 99.20\% and 98.43\%, respectively. It surpasses other state-of-the-art methods by nearly 23\% in resisting time-stretching attacks.
        ]]></description>
    </item>
    <item>
        <title>A Holistic Evaluation of Piano Sound Quality</title>
        <link>https://arxiv.org/abs/2310.04722</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2310.04722v3</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Monan Zhou, Shangda Wu, Shaohua Ji, Zijin Li, Wei Li</dc:creator>
        <description><![CDATA[
            背景：以往研究多关注钢琴演奏技巧对音质的影响，本文旨在开发整体评估方法辅助钢琴购买决策。方法：基于钢琴音质数据集使用主观问卷，对比不同卷积神经网络预训练模型微调结果选最优分类模型，应用等效矩形带宽分析提高模型可解释性，用焦点损失减少数据不平衡影响。效果：音乐训练者更能区分钢琴音质差异，最佳微调CNN预训练骨干作为分类器准确率达98.3%，后续将扩充数据集或采用少样本学习优化。
            arXiv:2310.04722v3 Announce Type: replace 
Abstract: This paper aims to develop a holistic evaluation method for piano sound quality to assist in purchasing decisions. Unlike previous studies that focused on the effect of piano performance techniques on sound quality, this study evaluates the inherent sound quality of different pianos. To derive quality evaluation systems, the study uses subjective questionnaires based on a piano sound quality dataset. The method selects the optimal piano classification models by comparing the fine-tuning results of different pre-training models of Convolutional Neural Networks (CNN). To improve the interpretability of the models, the study applies Equivalent Rectangular Bandwidth (ERB) analysis. The results reveal that musically trained individuals are better able to distinguish between the sound quality differences of different pianos. The best fine-tuned CNN pre-trained backbone achieves a high accuracy of 98.3% as the piano classifier. However, the dataset is limited, and the audio is sliced to increase its quantity, resulting in a lack of diversity and balance, so we use focal loss to reduce the impact of data imbalance. To optimize the method, the dataset will be expanded, or few-shot learning techniques will be employed in future research.
        ]]></description>
    </item>
    <item>
        <title>Enhancing Audio-Language Models through Self-Supervised Post-Training with Text-Audio Pairs</title>
        <link>https://arxiv.org/abs/2408.09269</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2408.09269v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Anshuman Sinha, Camille Migozzi, Aubin Rey, Chao Zhang</dc:creator>
        <description><![CDATA[
            背景：音频和文本的多模态对比学习受关注，对比训练的音频 - 语言模型（ALMs）在零样本音频分类等任务有成效，但对自然语言和时间关系的理解待研究。方法：提出时间注入方法TeminAL，采用两阶段训练方案TeminAL A&B，先学习区分多声音，再注入时间感知；还提出零样本设置下评估ALMs的策略ZSTE。效果：在ESC - 50数据集上时间理解性能平均提升5.28%，在AudioCap/Clotho数据集零样本检索和分类任务有竞争力，在多数下游任务上优于现有模型。
            arXiv:2408.09269v2 Announce Type: replace 
Abstract: Research on multi-modal contrastive learning strategies for audio and text has rapidly gained interest. Contrastively trained Audio-Language Models (ALMs), such as CLAP, which establish a unified representation across audio and language modalities, have enhanced the efficacy in various subsequent tasks by providing good text aligned audio encoders and vice versa. These improvements are evident in areas like zero-shot audio classification and audio retrieval, among others. However, the ability of these models to understand natural language and temporal relations is still a largely unexplored and open field for research. In this paper, we propose to equip the multi-modal ALMs with temporal understanding without loosing their inherent prior capabilities of audio-language tasks with a temporal instillation method TeminAL. We implement a two-stage training scheme TeminAL A $\&$ B, where the model first learns to differentiate between multiple sounds in TeminAL A, followed by a phase that instills a sense of time, thereby enhancing its temporal understanding in TeminAL B. This approach results in an average performance gain of $5.28\%$ in temporal understanding on the ESC-50 dataset, while the model remains competitive in zero-shot retrieval and classification tasks on the AudioCap/Clotho datasets. We also note the lack of proper evaluation techniques for contrastive ALMs and propose a strategy for evaluating ALMs in zero-shot settings. The general-purpose zero-shot model evaluation strategy ZSTE, is used to evaluate various prior models. ZSTE demonstrates a general strategy to evaluate all ZS contrastive models. The model trained with TeminAL successfully outperforms current models on most downstream tasks.
        ]]></description>
    </item>
    <item>
        <title>MoWE-Audio: Multitask AudioLLMs with Mixture of Weak Encoders</title>
        <link>https://arxiv.org/abs/2409.06635</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2409.06635v4</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wenyu Zhang, Shuo Sun, Bin Wang, Xunlong Zou, Zhuohan Liu, Yingxu He, Geyu Lin, Nancy F. Chen, Ai Ti Aw</dc:creator>
        <description><![CDATA[
            背景：大语言模型发展推动了音频大语言模型（AudioLLMs），但现有AudioLLMs中预训练音频编码器捕捉新任务和数据集特征的能力有限。方法：提出将弱编码器混合体（MoWE）纳入AudioLLM框架，用相对轻量级的编码器池补充基础编码器，根据音频输入选择性激活以增强特征提取，且不显著增加模型大小。效果：实证结果表明，MoWE有效提升了多任务性能，拓宽了AudioLLMs在更多样化音频任务中的适用性。
            arXiv:2409.06635v4 Announce Type: replace 
Abstract: The rapid advancements in large language models (LLMs) have significantly enhanced natural language processing capabilities, facilitating the development of AudioLLMs that process and understand speech and audio inputs alongside text. Existing AudioLLMs typically combine a pre-trained audio encoder with a pre-trained LLM, which are subsequently finetuned on specific audio tasks. However, the pre-trained audio encoder has constrained capacity to capture features for new tasks and datasets. To address this, we propose to incorporate mixtures of `weak' encoders (MoWE) into the AudioLLM framework. MoWE supplements a base encoder with a pool of relatively light weight encoders, selectively activated based on the audio input to enhance feature extraction without significantly increasing model size. Our empirical results demonstrate that MoWE effectively improves multi-task performance, broadening the applicability of AudioLLMs to more diverse audio tasks.
        ]]></description>
    </item>
    <item>
        <title>A Survey on Speech Large Language Models</title>
        <link>https://arxiv.org/abs/2410.18908</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.18908v3</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jing Peng, Yucheng Wang, Yu Xi, Xu Li, Xizhuo Zhang, Kai Yu</dc:creator>
        <description><![CDATA[
            背景：大语言模型（LLMs）能力强，研究者积极将其融入语音理解领域。方法：提出语音大语言模型（Speech LLMs），采用“音频特征提取->多模态信息融合->LLM推理”架构，实现更丰富特征提取与音文模态融合。效果：论文评估了Speech LLMs进展与跨任务集成潜力，指出特定条件下LLMs休眠等挑战，还探索训练策略并给出解决方案，为后续研究提供参考。
            arXiv:2410.18908v3 Announce Type: replace 
Abstract: Large Language Models (LLMs) exhibit strong contextual understanding and remarkable multitask performance. As a result, researchers have been actively exploring the integration of LLMs into the domain of speech understanding, with a primary focus on a broad range of speech-to-text tasks. These include automatic speech recognition (ASR), speech-to-text translation (ST), speech emotion recognition (SER), and others. We refer to such models as Speech LLMs, which are typically built on a unified architecture that follows the pipeline of Audio Feature Extraction -> Multimodal Information Fusion -> LLM Inference. This approach enables richer audio feature extraction while facilitating end-to-end fusion of audio and text modalities, thereby achieving deeper understanding and reasoning from audio data. This paper elucidates the development of Speech LLMs, offering an in-depth analysis of system architectures. Through extensive research and a series of targeted experiments, the paper assesses the advancements in Speech LLMs and their potential for cross-task integration within the speech understanding field. Furthermore, it highlights key challenges identified through experimentation, such as the dormancy of LLMs under certain conditions. The paper further explores training strategies for Speech LLMs, proposes potential solutions based on these findings, and offers valuable insights and references for future research.
        ]]></description>
    </item>
    <item>
        <title>TechSinger: Technique Controllable Multilingual Singing Voice Synthesis via Flow Matching</title>
        <link>https://arxiv.org/abs/2502.12572</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.12572v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wenxiang Guo, Yu Zhang, Changhao Pan, Rongjie Huang, Li Tang, Ruiqi Li, Zhiqing Hong, Yongqi Wang, Zhou Zhao</dc:creator>
        <description><![CDATA[
            背景：现有歌声合成方法难以精确控制发声技巧，限制了合成声音表现力。方法：提出TechSinger系统，支持五种语言和七种发声技巧，利用基于流匹配的生成模型实现对多种技巧的表达控制；开发技巧检测模型标注训练数据，采用基于提示的技巧预测模型让用户通过自然语言指定发声属性。效果：实验表明，该系统显著提升合成歌声的表现力和真实感，在音质和技巧控制方面优于现有方法。
            arXiv:2502.12572v2 Announce Type: replace 
Abstract: Singing voice synthesis has made remarkable progress in generating natural and high-quality voices. However, existing methods rarely provide precise control over vocal techniques such as intensity, mixed voice, falsetto, bubble, and breathy tones, thus limiting the expressive potential of synthetic voices. We introduce TechSinger, an advanced system for controllable singing voice synthesis that supports five languages and seven vocal techniques. TechSinger leverages a flow-matching-based generative model to produce singing voices with enhanced expressive control over various techniques. To enhance the diversity of training data, we develop a technique detection model that automatically annotates datasets with phoneme-level technique labels. Additionally, our prompt-based technique prediction model enables users to specify desired vocal attributes through natural language, offering fine-grained control over the synthesized singing. Experimental results demonstrate that TechSinger significantly enhances the expressiveness and realism of synthetic singing voices, outperforming existing methods in terms of audio quality and technique-specific control. Audio samples can be found at https://gwx314.github.io/tech-singer/.
        ]]></description>
    </item>
    <item>
        <title>A Survey on Music Generation from Single-Modal, Cross-Modal, and Multi-Modal Perspectives</title>
        <link>https://arxiv.org/abs/2504.00837</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.00837v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 22 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Shuyu Li, Shulei Ji, Zihao Wang, Songruoyao Wu, Jiaxing Yu, Kejun Zhang</dc:creator>
        <description><![CDATA[
            背景：多模态音乐生成作为新兴研究领域，应用广泛。方法：该论文从模态角度对音乐生成系统分类，涵盖模态表示、多模态数据对齐及利用其指导音乐生成，还讨论了当前数据集和评估方法。效果：指出该领域面临有效多模态整合、大规模综合数据集和系统评估方法等挑战，并展望了聚焦创造力、效率、多模态对齐和评估的未来研究方向。
            arXiv:2504.00837v2 Announce Type: replace 
Abstract: Multi-modal music generation, using multiple modalities like text, images, and video alongside musical scores and audio as guidance, is an emerging research area with broad applications. This paper reviews this field, categorizing music generation systems from the perspective of modalities. The review covers modality representation, multi-modal data alignment, and their utilization to guide music generation. Current datasets and evaluation methods are also discussed. Key challenges in this area include effective multi-modal integration, large-scale comprehensive datasets, and systematic evaluation methods. Finally, an outlook on future research directions is provided, focusing on creativity, efficiency, multi-modal alignment, and evaluation.
        ]]></description>
    </item>
</channel>
</rss>