<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
<channel>
    <title>arXiv Paper Filter</title>
    <link>https://github.com/None/arxiv_filter</link>
    <description>根据研究兴趣筛选的arXiv论文</description>
    <atom:link href="https://raw.githubusercontent.com/None/arxiv_filter/main/feed.xml" rel="self" type="application/rss+xml" />
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>zh-CN</language>
    <lastBuildDate>Thu, 10 Apr 2025 12:10:50 +0800</lastBuildDate>
    <managingEditor>None@github.com</managingEditor>
    <pubDate>Thu, 10 Apr 2025 12:10:50 +0800</pubDate>
    <skipDays>
        <day>Saturday</day>
        <day>Sunday</day>
    </skipDays>

    <item>
        <title>Unifying Autoregressive and Diffusion-Based Sequence Generation</title>
        <link>https://arxiv.org/abs/2504.06416</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.06416v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Nima Fathi, Torsten Scholak, Pierre-Andr\'e No\"el</dc:creator>
        <description><![CDATA[
            背景：旨在拓展基于扩散的序列生成模型，使其与自回归语言模型界限更模糊。方法：引入超调度，为单个令牌位置分配不同噪声调度；提出两种混合逐令牌噪声过程，能修正过往错误，还引入新推理算法；设计与KV缓存兼容的注意力掩码。效果：在标准基准测试中，该方法达到了最先进的困惑度，生成了多样且高质量的序列，为基于自回归扩散的序列生成提供了有前景的方向。
            arXiv:2504.06416v1 Announce Type: new 
Abstract: We present significant extensions to diffusion-based sequence generation models, blurring the line with autoregressive language models. We introduce hyperschedules, which assign distinct noise schedules to individual token positions, generalizing both autoregressive models (e.g., GPT) and conventional diffusion models (e.g., SEDD, MDLM) as special cases. Second, we propose two hybrid token-wise noising processes that interpolate between absorbing and uniform processes, enabling the model to fix past mistakes, and we introduce a novel inference algorithm that leverages this new feature in a simplified context inspired from MDLM. To support efficient training and inference, we design attention masks compatible with KV-caching. Our methods achieve state-of-the-art perplexity and generate diverse, high-quality sequences across standard benchmarks, suggesting a promising path for autoregressive diffusion-based sequence generation.
        ]]></description>
    </item>
    <item>
        <title>S'MoRE: Structural Mixture of Residual Experts for LLM Fine-tuning</title>
        <link>https://arxiv.org/abs/2504.06426</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.06426v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hanqing Zeng, Yinglong Xia, Zhuokai Zhao, Gilbert Jiang, Qiang Zhang, Jiayi Liu, Lizhu Zhang, Xiangjun Fan, Benyu Zhang</dc:creator>
        <description><![CDATA[
            预训练大语言模型微调面临平衡参数效率和模型容量的挑战，现有方法如LoRA高效但缺乏灵活性，MoE架构虽提升容量但参数利用不足。为此提出S'MoRE框架，将LoRA的高效与MoE的灵活无缝结合。它采用专家权重的分层低秩分解，构建多层结构的残差。通过将输入令牌路由到残差子树，用少量低秩矩阵模拟大量专家的能力，其残差的层间传播设计为特殊GNN。理论分析和实验表明，在相似参数预算下，S'MoRE指数级提升传统MoE灵活性，微调性能更优。
            arXiv:2504.06426v1 Announce Type: new 
Abstract: Fine-tuning pre-trained large language models (LLMs) presents a dual challenge of balancing parameter efficiency and model capacity. Existing methods like low-rank adaptations (LoRA) are efficient but lack flexibility, while Mixture-of-Experts (MoE) architectures enhance model capacity at the cost of more & under-utilized parameters. To address these limitations, we propose Structural Mixture of Residual Experts (S'MoRE), a novel framework that seamlessly integrates the efficiency of LoRA with the flexibility of MoE. Specifically, S'MoRE employs hierarchical low-rank decomposition of expert weights, yielding residuals of varying orders interconnected in a multi-layer structure. By routing input tokens through sub-trees of residuals, S'MoRE emulates the capacity of many experts by instantiating and assembling just a few low-rank matrices. We craft the inter-layer propagation of S'MoRE's residuals as a special type of Graph Neural Network (GNN), and prove that under similar parameter budget, S'MoRE improves "structural flexibility" of traditional MoE (or Mixture-of-LoRA) by exponential order. Comprehensive theoretical analysis and empirical results demonstrate that S'MoRE achieves superior fine-tuning performance, offering a transformative approach for efficient LLM adaptation.
        ]]></description>
    </item>
    <item>
        <title>Mind the Gap: Evaluating Vision Systems in Small Data Applications</title>
        <link>https://arxiv.org/abs/2504.06486</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.06486v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Samuel Stevens, S M Rayeed, Jenna Kline</dc:creator>
        <description><![CDATA[
            背景：特定计算机视觉任务的AI工具实际应用依赖数百到数千个标注样本的小数据机制，但当前研究多关注零样本和少样本学习，忽略了小数据机制。方法：使用NeWT基准，比较多模态大语言模型（MLLMs）和仅视觉方法在不同训练集规模下的表现。效果：MLLMs性能早期达到平稳，仅视觉方法在小数据机制下持续提升，训练样本超10个后性能差距扩大。研究首次全面比较两者在小数据场景的表现，呼吁开展小数据评估。
            arXiv:2504.06486v1 Announce Type: new 
Abstract: The practical application of AI tools for specific computer vision tasks relies on the "small-data regime" of hundreds to thousands of labeled samples. This small-data regime is vital for applications requiring expensive expert annotations, such as ecological monitoring, medical diagnostics or industrial quality control. We find, however, that computer vision research has ignored the small data regime as evaluations increasingly focus on zero- and few-shot learning. We use the Natural World Tasks (NeWT) benchmark to compare multi-modal large language models (MLLMs) and vision-only methods across varying training set sizes. MLLMs exhibit early performance plateaus, while vision-only methods improve throughout the small-data regime, with performance gaps widening beyond 10 training examples. We provide the first comprehensive comparison between these approaches in small-data contexts and advocate for explicit small-data evaluations in AI research to better bridge theoretical advances with practical deployments.
        ]]></description>
    </item>
    <item>
        <title>GTS-LUM: Reshaping User Behavior Modeling with LLMs in Telecommunications Industry</title>
        <link>https://arxiv.org/abs/2504.06511</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.06511v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Liu Shi, Tianwu Zhou, Wei Xu, Li Liu, Zhexin Cui, Shaoyi Liang, Haoxing Niu, Yichong Tian, Jianwei Guo</dc:creator>
        <description><![CDATA[
            背景：电信服务提供商需分析用户行为，但缺乏统一框架处理多粒度、多模态输入和异构标签的用户行为序列。方法：提出GTS - LUM模型，采用（多模态）编码器 - 适配器 - 大语言模型解码器架构，有电信领域特定创新，如先进时间戳处理法、支持多模态输入并通过Q - former结构与语义信息对齐、集成前置目标感知机制。效果：在工业数据集实验验证其有效性，优于推荐系统流行的LLM4Rec方法，为电信用户行为建模提供有效通用方案。
            arXiv:2504.06511v1 Announce Type: new 
Abstract: As telecommunication service providers shifting their focus to analyzing user behavior for package design and marketing interventions, a critical challenge lies in developing a unified, end-to-end framework capable of modeling long-term and periodic user behavior sequences with diverse time granularities, multi-modal data inputs, and heterogeneous labels. This paper introduces GTS-LUM, a novel user behavior model that redefines modeling paradigms in telecommunication settings. GTS-LUM adopts a (multi-modal) encoder-adapter-LLM decoder architecture, enhanced with several telecom-specific innovations. Specifically, the model incorporates an advanced timestamp processing method to handle varying time granularities. It also supports multi-modal data inputs -- including structured tables and behavior co-occurrence graphs -- and aligns these with semantic information extracted by a tokenizer using a Q-former structure. Additionally, GTS-LUM integrates a front-placed target-aware mechanism to highlight historical behaviors most relevant to the target. Extensive experiments on industrial dataset validate the effectiveness of this end-to-end framework and also demonstrate that GTS-LUM outperforms LLM4Rec approaches which are popular in recommendation systems, offering an effective and generalizing solution for user behavior modeling in telecommunications.
        ]]></description>
    </item>
    <item>
        <title>Flexible Graph Similarity Computation With A Proactive Optimization Strategy</title>
        <link>https://arxiv.org/abs/2504.06533</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.06533v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhouyang Liu, Ning Liu, Yixin Chen, Jiezhong He, Dongsheng Li</dc:creator>
        <description><![CDATA[
            背景：图编辑距离（GED）是图检索中重要的相似度度量，但现有基于学习的方法难以处理可变操作成本，且依赖孤立节点距离指导，需低效的映射改进。方法：提出图编辑网络（GEN），在建立映射前纳入操作成本，提出从图角度主动优化指导的策略，通过难度传播机制捕捉图内和图间匹配的相互依赖。效果：在真实和合成数据集上，与现有模型相比，误差最多降低37.8%，推理时间最多减少72.7%，在不同成本设置和图大小下表现稳健。
            arXiv:2504.06533v1 Announce Type: new 
Abstract: Graph Edit Distance (GED) is an important similarity measure in graph retrieval, which quantifies the minimum cost of transforming one graph into another through edit operations, and offers flexibility by allowing customizable operation costs. Recent learning-based approaches approximate GEDs with the distances between representations in vector spaces. However, these methods often struggle with varying operation costs due to neglecting the impact of these costs on determining optimal graph mappings. Furthermore, they rely on isolated node distances as guidance, necessitating inefficient reactive refinements of mappings. To address these issues, we propose Graph Edit Network (GEN), a novel learning-based approach for flexible GED computation. By identifying the limitations of existing methods in capturing flexibility of GED, we introduce a principled yet simple solution that incorporates the operation costs before establishing mappings. To improve matching efficiency, we propose a strategy that proactively optimizes guidance from a graph perspective. This strategy initializes guidance as each node's alignment difficulty and captures the interdependencies between matches within and across graphs through a difficulty propagation mechanism, enabling more informed decisions. As a result, GEN selects optimal matches in a single step, minimizing the need for costly refinements. Results on real-world and synthetic datasets demonstrate the effectiveness, time efficiency, and adaptability of GEN, achieving up to 37.8\% error reduction and 72.7\% inference time reduction compared with state-of-the-art models, while performing robustly under varying cost settings and graph sizes.
        ]]></description>
    </item>
    <item>
        <title>NeedleInATable: Exploring Long-Context Capability of Large Language Models towards Long-Structured Tables</title>
        <link>https://arxiv.org/abs/2504.06560</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.06560v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Lanrui Wang, Mingyu Zheng, Hongyin Tang, Zheng Lin, Yanan Cao, Jingang Wang, Xunliang Cai, Weiping Wang</dc:creator>
        <description><![CDATA[
            处理结构化表格数据尤其是长表格，是大语言模型的基础且具挑战性的任务。现有长上下文基准主要关注非结构化文本，忽略了长且复杂表格的挑战。为此，研究提出NeedleInATable任务，让模型在不同查询下提取目标单元格。评估显示主流大模型缺乏长表格理解能力。研究提出数据合成方法提升模型长表格理解能力，实验表明合成训练数据显著提升大模型在该任务上的表现，优于长上下文大模型和长表格代理方法。
            arXiv:2504.06560v1 Announce Type: new 
Abstract: Processing structured tabular data, particularly lengthy tables, constitutes a fundamental yet challenging task for large language models (LLMs). However, existing long-context benchmarks primarily focus on unstructured text, neglecting the challenges of long and complex structured tables. To address this gap, we introduce NeedleInATable (NIAT), a novel task that treats each table cell as a "needle" and requires the model to extract the target cell under different queries. Evaluation results of mainstream LLMs on this benchmark show they lack robust long-table comprehension, often relying on superficial correlations or shortcuts for complex table understanding tasks, revealing significant limitations in processing intricate tabular data. To this end, we propose a data synthesis method to enhance models' long-table comprehension capabilities. Experimental results show that our synthesized training data significantly enhances LLMs' performance on the NIAT task, outperforming both long-context LLMs and long-table agent methods. This work advances the evaluation of LLMs' genuine long-structured table comprehension capabilities and paves the way for progress in long-context and table understanding applications.
        ]]></description>
    </item>
    <item>
        <title>Benchmarking Multimodal CoT Reward Model Stepwise by Visual Program</title>
        <link>https://arxiv.org/abs/2504.06606</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.06606v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Minghe Gao, Xuqi Liu, Zhongqi Yue, Yang Wu, Shuang Chen, Juncheng Li, Siliang Tang, Fei Wu, Tat-Seng Chua, Yueting Zhuang</dc:creator>
        <description><![CDATA[
            背景：大语言模型奖励信号向多模态领域迁移存在标注繁琐、依赖单步奖励和评估不足等问题。方法：提出SVIP方法，自动训练步骤级多维思维链奖励模型，生成解决视觉任务的代码并将代码块分析转化为思维链步骤评估作为训练样本，用TriAtt - CoT多头注意力机制训练SVIP - Reward模型，还引入思维链奖励模型训练和测试基准。效果：提升了多模态大语言模型在训练和推理时的性能，减少幻觉并增强推理能力。
            arXiv:2504.06606v1 Announce Type: new 
Abstract: Recent advancements in reward signal usage for Large Language Models (LLMs) are remarkable. However, significant challenges exist when transitioning reward signal to the multimodal domain, including labor-intensive annotations, over-reliance on one-step rewards, and inadequate evaluation. To address these issues, we propose SVIP, a novel approach to train a step-level multi-dimensional Chain-of-Thought~(CoT) reward model automatically. It generates code for solving visual tasks and transforms the analysis of code blocks into the evaluation of CoT step as training samples. Then, we train SVIP-Reward model using a multi-head attention mechanism called TriAtt-CoT. The advantages of SVIP-Reward are evident throughout the entire process of MLLM. We also introduce a benchmark for CoT reward model training and testing. Experimental results demonstrate that SVIP-Reward improves MLLM performance across training and inference-time scaling, yielding better results on benchmarks while reducing hallucinations and enhancing reasoning ability.
        ]]></description>
    </item>
    <item>
        <title>SCI-Reason: A Dataset with Chain-of-Thought Rationales for Complex Multimodal Reasoning in Academic Areas</title>
        <link>https://arxiv.org/abs/2504.06637</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.06637v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chenghao Ma, Haihong E., Junpeng Ding, Jun Zhang, Ziyan Ma, Huang Qing, Bofei Gao, Liang Chen, Meina Song</dc:creator>
        <description><![CDATA[
            背景：大语言模型和大模态模型在多任务和领域展现解决问题能力，但在学术领域复杂图像推理能力未被系统研究。方法：提出数据集SCI - Reason，含12066张图像和12626个问答对，每个问答对有推理链，用其评估8个知名模型。效果：最佳模型Claude - 3.7 - Sonnet准确率仅55.19%，超半数失败因多步推理链中断。实验表明该数据集能提升推理能力和跨领域泛化能力。
            arXiv:2504.06637v1 Announce Type: new 
Abstract: Large Language Models (LLMs) and Large Multimodal Models (LMMs) demonstrate impressive problem-solving skills in many tasks and domains. However, their ability to reason with complex images in academic domains has not been systematically investigated. To bridge this gap, we present SCI-Reason, a dataset for complex multimodel reasoning in academic areas. SCI-Reason aims to test and improve the reasoning ability of large multimodal models using real complex images in academic domains. The dataset contains 12,066 images and 12,626 question-answer pairs extracted from PubMed, divided into training, validation and test splits. Each question-answer pair also contains an accurate and efficient inference chain as a guide to improving the inference properties of the dataset. With SCI-Reason, we performed a comprehensive evaluation of 8 well-known models. The best performing model, Claude-3.7-Sonnet, only achieved an accuracy of 55.19%. Error analysis shows that more than half of the model failures are due to breakdowns in multi-step inference chains rather than errors in primary visual feature extraction. This finding underscores the inherent limitations in reasoning capabilities exhibited by current multimodal models when processing complex image analysis tasks within authentic academic contexts. Experiments on open-source models show that SCI-Reason not only enhances reasoning ability but also demonstrates cross-domain generalization in VQA tasks. We also explore future applications of model inference capabilities in this domain, highlighting its potential for future research.
        ]]></description>
    </item>
    <item>
        <title>ThoughtProbe: Classifier-Guided Thought Space Exploration Leveraging LLM Intrinsic Reasoning</title>
        <link>https://arxiv.org/abs/2504.06650</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.06650v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zijian Wang, Chang Xu</dc:creator>
        <description><![CDATA[
            背景：预训练大语言模型具备内在推理能力，但相关神经表征机制和利用方法尚不清楚。方法：发现简单线性分类器可检测模型激活空间中的内在推理能力，提出分类器引导的搜索框架，探索树状响应空间，在节点扩展时用分类器打分排序，树扩展完成后收集答案形成候选池，再用分支聚合选择法确定最优答案。效果：在多个算术推理基准测试中取得显著提升。
            arXiv:2504.06650v1 Announce Type: new 
Abstract: Pre-trained large language models (LLMs) have been demonstrated to possess intrinsic reasoning capabilities that can emerge naturally when expanding the response space. However, the neural representation mechanisms underlying these intrinsic capabilities and approaches for their optimal utilization remain inadequately understood. In this work, we make the key discovery that a simple linear classifier can effectively detect intrinsic reasoning capabilities in LLMs' activation space, particularly within specific representation types and network layers. Based on this finding, we propose a classifier-guided search framework that strategically explore a tree-structured response space. In each node expansion, the classifier serves as a scoring and ranking mechanism that efficiently allocates computational resources by identifying and prioritizing more thoughtful reasoning directions for continuation. After completing the tree expansion, we collect answers from all branches to form a candidate answer pool. We propose a branch-aggregation selection method that marginalizes over all supporting branches by aggregating their thoughtfulness scores, thereby identifying the optimal answer from the pool. Experimental results show that our framework's comprehensive exploration not only covers valid reasoning chains but also effectively identifies them, achieving significant improvements across multiple arithmetic reasoning benchmarks.
        ]]></description>
    </item>
    <item>
        <title>Classifying the Unknown: In-Context Learning for Open-Vocabulary Text and Symbol Recognition</title>
        <link>https://arxiv.org/abs/2504.06841</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.06841v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tom Simon, William Mocaer, Pierrick Tranouez, Clement Chatelain, Thierry Paquet</dc:creator>
        <description><![CDATA[
            背景：传统模型处理新脚本模式序列分类需重新训练。方法：提出多模态模型Rosetta，利用多模态上下文学习（MICL），通过少量示例分类新脚本模式序列；设计数据集生成过程提升上下文学习能力；使用上下文感知分词器（CAT）实现开放词汇分类。效果：实验表明，Rosetta能成功分类分布外视觉模式及多种字母和脚本，如中文、希腊文等，扩展了模型分类能力。
            arXiv:2504.06841v1 Announce Type: new 
Abstract: We introduce Rosetta, a multimodal model that leverages Multimodal In-Context Learning (MICL) to classify sequences of novel script patterns in documents by leveraging minimal examples, thus eliminating the need for explicit retraining. To enhance contextual learning, we designed a dataset generation process that ensures varying degrees of contextual informativeness, improving the model's adaptability in leveraging context across different scenarios. A key strength of our method is the use of a Context-Aware Tokenizer (CAT), which enables open-vocabulary classification. This allows the model to classify text and symbol patterns across an unlimited range of classes, extending its classification capabilities beyond the scope of its training alphabet of patterns. As a result, it unlocks applications such as the recognition of new alphabets and languages. Experiments on synthetic datasets demonstrate the potential of Rosetta to successfully classify Out-Of-Distribution visual patterns and diverse sets of alphabets and scripts, including but not limited to Chinese, Greek, Russian, French, Spanish, and Japanese.
        ]]></description>
    </item>
    <item>
        <title>MovSAM: A Single-image Moving Object Segmentation Framework Based on Deep Thinking</title>
        <link>https://arxiv.org/abs/2504.06863</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.06863v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chang Nie, Yiqing Xu, Guangming Wang, Zhe Liu, Yanzi Miao, Hesheng Wang</dc:creator>
        <description><![CDATA[
            背景：现有单图像运动目标分割方法因缺乏时间线索而效果不佳。方法：提出MovSAM框架，利用增强思维链提示的多模态大模型搜索运动目标并生成文本提示，与视觉特征交叉融合，进行逻辑驱动的分割，分割结果经深度思考细化循环。效果：在自动驾驶场景验证了实用性，在公共基准上达92.5%的J&F值，实现了单图像运动目标分割的最优性能。
            arXiv:2504.06863v1 Announce Type: new 
Abstract: Moving object segmentation plays a vital role in understanding dynamic visual environments. While existing methods rely on multi-frame image sequences to identify moving objects, single-image MOS is critical for applications like motion intention prediction and handling camera frame drops. However, segmenting moving objects from a single image remains challenging for existing methods due to the absence of temporal cues. To address this gap, we propose MovSAM, the first framework for single-image moving object segmentation. MovSAM leverages a Multimodal Large Language Model (MLLM) enhanced with Chain-of-Thought (CoT) prompting to search the moving object and generate text prompts based on deep thinking for segmentation. These prompts are cross-fused with visual features from the Segment Anything Model (SAM) and a Vision-Language Model (VLM), enabling logic-driven moving object segmentation. The segmentation results then undergo a deep thinking refinement loop, allowing MovSAM to iteratively improve its understanding of the scene context and inter-object relationships with logical reasoning. This innovative approach enables MovSAM to segment moving objects in single images by considering scene understanding. We implement MovSAM in the real world to validate its practical application and effectiveness for autonomous driving scenarios where the multi-frame methods fail. Furthermore, despite the inherent advantage of multi-frame methods in utilizing temporal information, MovSAM achieves state-of-the-art performance across public MOS benchmarks, reaching 92.5\% on J\&amp;F. Our implementation will be available at https://github.com/IRMVLab/MovSAM.
        ]]></description>
    </item>
    <item>
        <title>To Backtrack or Not to Backtrack: When Sequential Search Limits Model Reasoning</title>
        <link>https://arxiv.org/abs/2504.07052</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.07052v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tian Qin, David Alvarez-Melis, Samy Jelassi, Eran Malach</dc:creator>
        <description><![CDATA[
            背景：大语言模型推理能力提升，回溯和并行采样是扩展测试时计算的两种策略，但在固定计算预算下两者优劣尚不明确。方法：在CountDown和Sudoku两个推理任务上系统比较这两种方法。效果：顺序搜索在CountDown上不如并行采样，在Sudoku上则更优。还发现训练固定搜索轨迹和显式思维链监督会使回溯性能下降。强化学习微调对有回溯能力的模型有益，对无回溯能力的模型效果有限。研究挑战了回溯普遍提升推理能力的假设。
            arXiv:2504.07052v1 Announce Type: new 
Abstract: Recent advancements in large language models have significantly improved their reasoning abilities, particularly through techniques involving search and backtracking. Backtracking naturally scales test-time compute by enabling sequential, linearized exploration via long chain-of-thought (CoT) generation. However, this is not the only strategy for scaling test-time compute: parallel sampling with best-of-n selection provides an alternative that generates diverse solutions simultaneously. Despite the growing adoption of sequential search, its advantages over parallel sampling--especially under a fixed compute budget remain poorly understood. In this paper, we systematically compare these two approaches on two challenging reasoning tasks: CountDown and Sudoku. Surprisingly, we find that sequential search underperforms parallel sampling on CountDown but outperforms it on Sudoku, suggesting that backtracking is not universally beneficial. We identify two factors that can cause backtracking to degrade performance: (1) training on fixed search traces can lock models into suboptimal strategies, and (2) explicit CoT supervision can discourage "implicit" (non-verbalized) reasoning. Extending our analysis to reinforcement learning (RL), we show that models with backtracking capabilities benefit significantly from RL fine-tuning, while models without backtracking see limited, mixed gains. Together, these findings challenge the assumption that backtracking universally enhances LLM reasoning, instead revealing a complex interaction between task structure, training data, model scale, and learning paradigm.
        ]]></description>
    </item>
    <item>
        <title>DeduCE: Deductive Consistency as a Framework to Evaluate LLM Reasoning</title>
        <link>https://arxiv.org/abs/2504.07080</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.07080v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Atharva Pandey, Kshitij Dubey, Rahul Sharma, Amit Sharma</dc:creator>
        <description><![CDATA[
            背景：前沿大语言模型在解决标准基准外的高中数学新问题时仍有困难。方法：提出演绎一致性指标分析语言模型思维链输出，研究模型理解输入前提和多步推理得出结论的能力，并开发评估模型在基准问题扰动版本上演绎一致性的流程。效果：在新的小学数学问题上，模型对增加输入前提较稳健，但推理步数增加时准确率显著下降，多步预测是主要误差来源，该分析为表征大模型推理提供新视角。
            arXiv:2504.07080v1 Announce Type: new 
Abstract: Despite great performance on Olympiad-level reasoning problems, frontier large language models can still struggle on high school math when presented with novel problems outside standard benchmarks. Going beyond final accuracy, we propose a deductive consistency metric to analyze chain-of-thought output from language models (LMs).Formally, deductive reasoning involves two subtasks: understanding a set of input premises and inferring the conclusions that follow from them. The proposed metric studies LMs' performance on these subtasks, with the goal of explaining LMs' reasoning errors on novel problems: how well do LMs understand input premises with increasing context lengths, and how well can they infer conclusions over multiple reasoning hops? Since existing benchmarks may be memorized, we develop a pipeline to evaluate LMs' deductive consistency on novel, perturbed versions of benchmark problems. On novel grade school math problems (GSM-8k), we find that LMs are fairly robust to increasing number of input premises, but suffer significant accuracy decay as the number of reasoning hops is increased. Interestingly, these errors are masked in the original benchmark as all models achieve near 100% accuracy. As we increase the number of solution steps using a synthetic dataset, prediction over multiple hops still remains the major source of error compared to understanding input premises. Other factors, such as shifts in language style or natural propagation of early errors do not explain the trends. Our analysis provides a new view to characterize LM reasoning -- as computations over a window of input premises and reasoning hops -- that can provide unified evaluation across problem domains.
        ]]></description>
    </item>
    <item>
        <title>Self-Steering Language Models</title>
        <link>https://arxiv.org/abs/2504.07081</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.07081v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Gabriel Grand, Joshua B. Tenenbaum, Vikash K. Mansinghka, Alexander K. Lew, Jacob Andreas</dc:creator>
        <description><![CDATA[
            背景：测试时推理使语言模型能处理复杂任务，但自然语言搜索或规划存在慢、成本高和易出错问题。方法：提出DisCIPL方法，让规划器模型生成特定任务推理程序，由跟随者模型群体执行，使语言模型具备编写递归搜索程序引导推理的能力。效果：在受限生成任务中，使用小的跟随者模型时，DisCIPL表现与甚至优于GPT - 4o等大模型，还开辟了高性能蒙特卡罗推理策略设计空间，无需微调且现有模型可自动实现。
            arXiv:2504.07081v1 Announce Type: new 
Abstract: While test-time reasoning enables language models to tackle complex tasks, searching or planning in natural language can be slow, costly, and error-prone. But even when LMs struggle to emulate the precise reasoning steps needed to solve a problem, they often excel at describing its abstract structure--both how to verify solutions and how to search for them. This paper introduces DisCIPL, a method for "self-steering" LMs where a Planner model generates a task-specific inference program that is executed by a population of Follower models. Our approach equips LMs with the ability to write recursive search procedures that guide LM inference, enabling new forms of verifiable and efficient reasoning. When instantiated with a small Follower (e.g., Llama-3.2-1B), DisCIPL matches (and sometimes outperforms) much larger models, including GPT-4o and o1, on challenging constrained generation tasks. In decoupling planning from execution, our work opens up a design space of highly-parallelized Monte Carlo inference strategies that outperform standard best-of-N sampling, require no finetuning, and can be implemented automatically by existing LMs.
        ]]></description>
    </item>
    <item>
        <title>KG-LLM-Bench: A Scalable Benchmark for Evaluating LLM Reasoning on Textualized Knowledge Graphs</title>
        <link>https://arxiv.org/abs/2504.07087</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.07087v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Elan Markowitz, Krupa Galiya, Greg Ver Steeg, Aram Galstyan</dc:creator>
        <description><![CDATA[
            背景：知识图谱是向大语言模型注入最新事实知识的常用方法，通常将其转化为文本让模型处理，但文本化过程对大模型性能的影响研究不足。方法：提出KG - LLM - Bench，这是一个涵盖五项知识图谱理解任务的综合可扩展基准，评估不同编码策略对各基础模型性能的影响。效果：通过对七种语言模型和五种文本化策略的大量实验，为优化大模型在知识图谱推理任务上的性能提供了见解。
            arXiv:2504.07087v1 Announce Type: new 
Abstract: Knowledge graphs have emerged as a popular method for injecting up-to-date, factual knowledge into large language models (LLMs). This is typically achieved by converting the knowledge graph into text that the LLM can process in context. While multiple methods of encoding knowledge graphs have been proposed, the impact of this textualization process on LLM performance remains under-explored. We introduce KG-LLM-Bench, a comprehensive and extensible benchmark spanning five knowledge graph understanding tasks, and evaluate how different encoding strategies affect performance across various base models. Our extensive experiments with seven language models and five textualization strategies provide insights for optimizing LLM performance on KG reasoning tasks.
        ]]></description>
    </item>
    <item>
        <title>OmniCaptioner: One Captioner to Rule Them All</title>
        <link>https://arxiv.org/abs/2504.07089</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.07089v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yiting Lu, Jiakang Yuan, Zhen Li, Shitian Zhao, Qi Qin, Xinyue Li, Le Zhuo, Licheng Wen, Dongyang Liu, Yuewen Cao, Xiangchao Yan, Xin Li, Botian Shi, Tao Chen, Zhibo Chen, Lei Bai, Bo Zhang, Peng Gao</dc:creator>
        <description><![CDATA[
            背景：以往视觉描述方法局限于特定图像类型。方法：提出OmniCaptioner，一个通用视觉描述框架，可将低层次像素信息转化为语义丰富文本表示，为自然图像、视觉文本和结构化视觉等多种视觉领域生成细粒度文本描述。效果：有三方面优势，一是增强大语言模型视觉推理能力，助力其在多模态场景有效推理；二是改进图像生成任务；三是实现高效监督微调，用更少数据更快收敛，为弥合语言与视觉模态差距提供新视角。 
            arXiv:2504.07089v1 Announce Type: new 
Abstract: We propose OmniCaptioner, a versatile visual captioning framework for generating fine-grained textual descriptions across a wide variety of visual domains. Unlike prior methods limited to specific image types (e.g., natural images or geometric visuals), our framework provides a unified solution for captioning natural images, visual text (e.g., posters, UIs, textbooks), and structured visuals (e.g., documents, tables, charts). By converting low-level pixel information into semantically rich textual representations, our framework bridges the gap between visual and textual modalities. Our results highlight three key advantages: (i) Enhanced Visual Reasoning with LLMs, where long-context captions of visual modalities empower LLMs, particularly the DeepSeek-R1 series, to reason effectively in multimodal scenarios; (ii) Improved Image Generation, where detailed captions improve tasks like text-to-image generation and image transformation; and (iii) Efficient Supervised Fine-Tuning (SFT), which enables faster convergence with less data. We believe the versatility and adaptability of OmniCaptioner can offer a new perspective for bridging the gap between language and visual modalities.
        ]]></description>
    </item>
    <item>
        <title>MultiDelete for Multimodal Machine Unlearning</title>
        <link>https://arxiv.org/abs/2311.12047</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2311.12047v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiali Cheng, Hadi Amiri</dc:creator>
        <description><![CDATA[
            背景：多模态环境下的模型遗忘因数据模态间复杂依赖及训练成本高而面临挑战。方法：提出首个多模态数据和模型的遗忘方法MultiDelete，该方法在遗忘时解耦单模态数据点关联，具备模态解耦、多模态知识保留和单模态知识保留三个关键特性，且训练高效，不受强凸损失约束。效果：在两种架构和四个数据集（含图 - 文数据集）实验显示，相比最佳基线，遗忘多模态样本平均提升17.6分，能保留原模型知识，更好抵御对抗攻击。
            arXiv:2311.12047v2 Announce Type: cross 
Abstract: Machine Unlearning removes specific knowledge about training data samples from an already trained model. It has significant practical benefits, such as purging private, inaccurate, or outdated information from trained models without the need for complete re-training. Unlearning within a multimodal setting presents unique challenges due to the complex dependencies between different data modalities and the expensive cost of training on large multimodal datasets and architectures. This paper presents the first machine unlearning approach for multimodal data and models, titled MultiDelete, which is designed to decouple associations between unimodal data points during unlearning without losing the overall representation strength of the trained model. MultiDelete advocates for three key properties for effective multimodal unlearning: (a): modality decoupling, which effectively decouples the association between individual unimodal data points marked for deletion, rendering them as unrelated data points, (b): multimodal knowledge retention, which retains the multimodal representation post-unlearning, and (c): unimodal knowledge retention, which retains the unimodal representation postunlearning. MultiDelete is efficient to train and is not constrained by using a strongly convex loss -- a common restriction among existing baselines. Experiments on two architectures and four datasets, including image-text and graph-text datasets, show that MultiDelete gains an average improvement of 17.6 points over best performing baseline in unlearning multimodal samples, can maintain the multimodal and unimodal knowledge of the original model post unlearning, and can provide better protection to unlearned data against adversarial attacks.
        ]]></description>
    </item>
    <item>
        <title>ER-RAG: Enhance RAG with ER-Based Unified Modeling of Heterogeneous Data Sources</title>
        <link>https://arxiv.org/abs/2504.06271</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.06271v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yikuan Xia, Jiazun Chen, Yirui Zhan, Suifeng Zhao, Weipeng Jiang, Chaorui Zhang, Wei Han, Bo Bai, Jun Gao</dc:creator>
        <description><![CDATA[
            背景：大语言模型在问答任务表现出色，检索增强生成（RAG）可提高其精度，但当前RAG方法针对不同数据源采用特定策略，在低资源或黑盒环境有挑战。方法：提出ER - RAG框架，用实体 - 关系（ER）模型统一异构数据源的证据集成，通过基于ER的API进行实体检索和关系查询，采用两阶段生成过程。效果：在2024 KDDCup CRAG挑战赛中获胜，用8B大模型骨干达到与商业RAG管道相当性能，LLM得分比混合竞争对手高3.1%，检索加速5.5倍。
            arXiv:2504.06271v1 Announce Type: cross 
Abstract: Large language models (LLMs) excel in question-answering (QA) tasks, and retrieval-augmented generation (RAG) enhances their precision by incorporating external evidence from diverse sources like web pages, databases, and knowledge graphs. However, current RAG methods rely on agent-specific strategies for individual data sources, posing challenges low-resource or black-box environments and complicates operations when evidence is fragmented across sources. To address these limitations, we propose ER-RAG, a framework that unifies evidence integration across heterogeneous data sources using the Entity-Relationship (ER) model. ER-RAG standardizes entity retrieval and relationship querying through ER-based APIs with GET and JOIN operations. It employs a two-stage generation process: first, a preference optimization module selects optimal sources; second, another module constructs API chains based on source schemas. This unified approach allows efficient fine-tuning and seamless integration across diverse data sources. ER-RAG demonstrated its effectiveness by winning all three tracks of the 2024 KDDCup CRAG Challenge, achieving performance on par with commercial RAG pipelines using an 8B LLM backbone. It outperformed hybrid competitors by 3.1% in LLM score and accelerated retrieval by 5.5X.
        ]]></description>
    </item>
    <item>
        <title>ASHiTA: Automatic Scene-grounded HIerarchical Task Analysis</title>
        <link>https://arxiv.org/abs/2504.06553</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.06553v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yun Chang, Leonor Fermoselle, Duy Ta, Bernadette Bucher, Luca Carlone, Jiuguang Wang</dc:creator>
        <description><![CDATA[
            背景：现有场景重建和理解研究在将自然语言与物理3D环境关联方面有进展，但将抽象高级指令关联到3D场景仍具挑战，高级任务分解依赖环境。方法：提出ASHiTA框架，通过将高级任务分解为具体子任务生成与3D场景图关联的任务层次结构，交替进行大语言模型辅助的层次任务分析和任务驱动的3D场景图构建。效果：在将高级任务分解为依赖环境的子任务方面显著优于大语言模型基线，接地性能与现有最优方法相当。
            arXiv:2504.06553v1 Announce Type: cross 
Abstract: While recent work in scene reconstruction and understanding has made strides in grounding natural language to physical 3D environments, it is still challenging to ground abstract, high-level instructions to a 3D scene. High-level instructions might not explicitly invoke semantic elements in the scene, and even the process of breaking a high-level task into a set of more concrete subtasks, a process called hierarchical task analysis, is environment-dependent. In this work, we propose ASHiTA, the first framework that generates a task hierarchy grounded to a 3D scene graph by breaking down high-level tasks into grounded subtasks. ASHiTA alternates LLM-assisted hierarchical task analysis, to generate the task breakdown, with task-driven 3D scene graph construction to generate a suitable representation of the environment. Our experiments show that ASHiTA performs significantly better than LLM baselines in breaking down high-level tasks into environment-dependent subtasks and is additionally able to achieve grounding performance comparable to state-of-the-art methods.
        ]]></description>
    </item>
    <item>
        <title>FamilyTool: A Multi-hop Personalized Tool Use Benchmark</title>
        <link>https://arxiv.org/abs/2504.06766</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.06766v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuxin Wang, Yiran Guo, Yining Zheng, Zhangyue Yin, Shuo Chen, Jie Yang, Jiajun Chen, Xuanjing Huang, Xipeng Qiu</dc:creator>
        <description><![CDATA[
            背景：现有大语言模型工具学习基准难以处理现实个性化场景，尤其是多跳推理和动态环境知识适应。方法：提出基于家庭知识图谱的FamilyTool基准，涵盖1 - 3跳关系查询及归纳设置，还提出KGETool评估流程。效果：实验显示，现有大模型性能存在显著差距，随着跳数复杂度增加准确率急剧下降，归纳场景下泛化能力不足，凸显当前大模型在处理复杂动态环境的局限。
            arXiv:2504.06766v1 Announce Type: cross 
Abstract: The integration of tool learning with Large Language Models (LLMs) has expanded their capabilities in handling complex tasks by leveraging external tools. However, existing benchmarks for tool learning inadequately address critical real-world personalized scenarios, particularly those requiring multi-hop reasoning and inductive knowledge adaptation in dynamic environments. To bridge this gap, we introduce FamilyTool, a novel benchmark grounded in a family-based knowledge graph (KG) that simulates personalized, multi-hop tool use scenarios. FamilyTool challenges LLMs with queries spanning 1 to 3 relational hops (e.g., inferring familial connections and preferences) and incorporates an inductive KG setting where models must adapt to unseen user preferences and relationships without re-training, a common limitation in prior approaches that compromises generalization. We further propose KGETool: a simple KG-augmented evaluation pipeline to systematically assess LLMs' tool use ability in these settings. Experiments reveal significant performance gaps in state-of-the-art LLMs, with accuracy dropping sharply as hop complexity increases and inductive scenarios exposing severe generalization deficits. These findings underscore the limitations of current LLMs in handling personalized, evolving real-world contexts and highlight the urgent need for advancements in tool-learning frameworks. FamilyTool serves as a critical resource for evaluating and advancing LLM agents' reasoning, adaptability, and scalability in complex, dynamic environments. Code and dataset are available at Github.
        ]]></description>
    </item>
    <item>
        <title>Optimizing LLM Queries in Relational Data Analytics Workloads</title>
        <link>https://arxiv.org/abs/2403.05821</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2403.05821v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Shu Liu, Asim Biswal, Amog Kamsetty, Audrey Cheng, Luis Gaspar Schroeder, Liana Patel, Shiyi Cao, Xiangxi Mo, Ion Stoica, Joseph E. Gonzalez, Matei Zaharia</dc:creator>
        <description><![CDATA[
            背景：大语言模型（LLMs）在批量数据分析应用中发展迅速，但推理成本高且速度慢。方法：本文提出新技术，开发高效算法对输入表的行和每行内的字段重新排序，以在执行LLM服务时最大化键值（KV）缓存重用，且该方法易应用于现有分析系统和服务平台。效果：评估显示，在使用Llama 3模型的多样LLM查询基准测试中，作业完成时间最多可提升3.4倍，在OpenAI和Anthropic定价模型下可节省32%的成本。
            arXiv:2403.05821v2 Announce Type: replace 
Abstract: Batch data analytics is a growing application for Large Language Models (LLMs). LLMs enable users to perform a wide range of natural language tasks, such as classification, entity extraction, and translation, over large datasets. However, LLM inference is highly costly and slow: for example, an NVIDIA L4 GPU running Llama3-8B can only process 6 KB of text per second, taking about a day to handle 15 GB of data; processing a similar amount of data costs around $10K on OpenAI's GPT-4o. In this paper, we propose novel techniques that can significantly reduce the cost of LLM calls for relational data analytics workloads. Our key contribution is developing efficient algorithms for reordering the rows and the fields within each row of an input table to maximize key-value (KV) cache reuse when performing LLM serving. As such, our approach can be easily applied to existing analytics systems and serving platforms. Our evaluation shows that our solution can yield up to 3.4x improvement in job completion time on a benchmark of diverse LLM-based queries using Llama 3 models. Our solution also achieves a 32% cost savings under OpenAI and Anthropic pricing models.
        ]]></description>
    </item>
    <item>
        <title>Prompting or Fine-tuning? Exploring Large Language Models for Causal Graph Validation</title>
        <link>https://arxiv.org/abs/2406.16899</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2406.16899v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuni Susanti, Nina Holsmoelle</dc:creator>
        <description><![CDATA[
            传统统计因果发现方法生成的因果图的因果关系评估依赖人工，本研究探索大语言模型（LLMs）在该任务上的能力。采用两种方法，一是基于提示的零样本和少样本因果推理，二是针对因果关系预测任务微调语言模型。在生物医学和通用领域数据集上实验，结果显示微调模型表现更优，即便使用小参数语言模型，F1分数最高也能提升20.5分，为因果图评估的两种方法提供了优劣势见解。
            arXiv:2406.16899v2 Announce Type: replace 
Abstract: This study explores the capability of Large Language Models (LLMs) to evaluate causality in causal graphs generated by conventional statistical causal discovery methods-a task traditionally reliant on manual assessment by human subject matter experts. To bridge this gap in causality assessment, LLMs are employed to evaluate the causal relationships by determining whether a causal connection between variable pairs can be inferred from textual context. Our study compares two approaches: (1) prompting-based method for zero-shot and few-shot causal inference and, (2) fine-tuning language models for the causal relation prediction task. While prompt-based LLMs have demonstrated versatility across various NLP tasks, our experiments on biomedical and general-domain datasets show that fine-tuned models consistently outperform them, achieving up to a 20.5-point improvement in F1 score-even when using smaller-parameter language models. These findings provide valuable insights into the strengths and limitations of both approaches for causal graph evaluation.
        ]]></description>
    </item>
    <item>
        <title>MemoRAG: Boosting Long Context Processing with Global Memory-Enhanced Retrieval Augmentation</title>
        <link>https://arxiv.org/abs/2409.05591</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2409.05591v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hongjin Qian, Zheng Liu, Peitian Zhang, Kelong Mao, Defu Lian, Zhicheng Dou, Tiejun Huang</dc:creator>
        <description><![CDATA[
            处理长文本是大语言模型面临的挑战，虽有进展但计算成本高且仍不足，传统RAG方法因需明确查询和结构化知识而受限。为此，本文提出MemoRAG框架，采用双系统架构，先由轻量级长程系统创建全局记忆并生成草稿答案，再由表达性强的系统生成最终答案，还通过KV压缩实现记忆模块并利用反馈增强记忆和线索能力。实验表明，该框架在各类长文本评估任务中表现出色。
            arXiv:2409.05591v3 Announce Type: replace 
Abstract: Processing long contexts presents a significant challenge for large language models (LLMs). While recent advancements allow LLMs to handle much longer contexts than before (e.g., 32K or 128K tokens), it is computationally expensive and can still be insufficient for many applications. Retrieval-Augmented Generation (RAG) is considered a promising strategy to address this problem. However, conventional RAG methods face inherent limitations because of two underlying requirements: 1) explicitly stated queries, and 2) well-structured knowledge. These conditions, however, do not hold in general long-context processing tasks.
  In this work, we propose MemoRAG, a novel RAG framework empowered by global memory-augmented retrieval. MemoRAG features a dual-system architecture. First, it employs a light but long-range system to create a global memory of the long context. Once a task is presented, it generates draft answers, providing useful clues for the retrieval tools to locate relevant information within the long context. Second, it leverages an expensive but expressive system, which generates the final answer based on the retrieved information. Building upon this fundamental framework, we realize the memory module in the form of KV compression, and reinforce its memorization and cluing capacity from the Generation quality's Feedback (a.k.a. RLGF). In our experiments, MemoRAG achieves superior performances across a variety of long-context evaluation tasks, not only complex scenarios where traditional RAG methods struggle, but also simpler ones where RAG is typically applied.
        ]]></description>
    </item>
    <item>
        <title>Replacing Paths with Connection-Biased Attention for Knowledge Graph Completion</title>
        <link>https://arxiv.org/abs/2410.00876</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.00876v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sharmishtha Dutta, Alex Gittens, Mohammed J. Zaki, Charu C. Aggarwal</dc:creator>
        <description><![CDATA[
            背景：知识图谱补全旨在从现有事实推断额外事实，当前归纳式设置下的高效模型采用路径编码模块，但该模块耗时且需大量超参数优化。方法：仅使用基于Transformer的子图编码模块，引入连接偏置注意力和实体角色嵌入来消除路径编码模块。效果：在标准归纳式知识图谱补全基准数据集上，CBLiP模型比不使用路径信息的模型性能更优，与使用路径信息的模型相比，性能相当或更优且速度更快，在传导式设置的关系预测任务中也表现良好。
            arXiv:2410.00876v4 Announce Type: replace 
Abstract: Knowledge graph (KG) completion aims to identify additional facts that can be inferred from the existing facts in the KG. Recent developments in this field have explored this task in the inductive setting, where at test time one sees entities that were not present during training; the most performant models in the inductive setting have employed path encoding modules in addition to standard subgraph encoding modules. This work similarly focuses on KG completion in the inductive setting, without the explicit use of path encodings, which can be time-consuming and introduces several hyperparameters that require costly hyperparameter optimization. Our approach uses a Transformer-based subgraph encoding module only; we introduce connection-biased attention and entity role embeddings into the subgraph encoding module to eliminate the need for an expensive and time-consuming path encoding module. Evaluations on standard inductive KG completion benchmark datasets demonstrate that our \textbf{C}onnection-\textbf{B}iased \textbf{Li}nk \textbf{P}rediction (CBLiP) model has superior performance to models that do not use path information. Compared to models that utilize path information, CBLiP shows competitive or superior performance while being faster. Additionally, to show that the effectiveness of connection-biased attention and entity role embeddings also holds in the transductive setting, we compare CBLiP's performance on the relation prediction task in the transductive setting.
        ]]></description>
    </item>
    <item>
        <title>CLaSP: Learning Concepts for Time-Series Signals from Natural Language Supervision</title>
        <link>https://arxiv.org/abs/2411.08397</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2411.08397v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Aoi Ito, Kota Dohi, Yohei Kawaguchi</dc:creator>
        <description><![CDATA[
            背景：在工业诊断等领域，基于描述性查询搜索时间序列信号很重要，但现有方法依赖草图输入、预定义同义词词典或特定领域手动设计，限制了可扩展性和适应性。方法：提出CLaSP模型，采用对比学习将时间序列信号映射到自然语言描述，利用大语言模型的上下文知识，无需预定义同义词词典。效果：在TRUCE和SUSHI数据集上，CLaSP基于自然语言查询检索各种时间序列模式时达到了较高的准确率。
            arXiv:2411.08397v2 Announce Type: replace 
Abstract: This paper presents CLaSP, a novel model for retrieving time-series signals using natural language queries that describe signal characteristics. The ability to search time-series signals based on descriptive queries is essential in domains such as industrial diagnostics, where data scientists often need to find signals with specific characteristics. However, existing methods rely on sketch-based inputs, predefined synonym dictionaries, or domain-specific manual designs, limiting their scalability and adaptability. CLaSP addresses these challenges by employing contrastive learning to map time-series signals to natural language descriptions. Unlike prior approaches, it eliminates the need for predefined synonym dictionaries and leverages the rich contextual knowledge of large language models (LLMs). Using the TRUCE and SUSHI datasets, which pair time-series signals with natural language descriptions, we demonstrate that CLaSP achieves high accuracy in retrieving a variety of time series patterns based on natural language queries.
        ]]></description>
    </item>
    <item>
        <title>Quantized symbolic time series approximation</title>
        <link>https://arxiv.org/abs/2411.15209</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2411.15209v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Erin Carson, Xinye Chen, Cheng Kang</dc:creator>
        <description><![CDATA[
            时间序列在众多领域广泛存在，此前符号时间序列表示法因存储高效等优势被应用于工程。受高性能硬件发展启发，本文提出基于量化的ABBA符号近似技术QABBA。该方法在保持原符号重建速度和精度的同时，提高了存储效率，证明了量化误差上限并讨论比特数选择。将其用于大语言模型的时间序列回归，避免从头训练嵌入，在Monash回归数据集上达新最优。多数据集实验验证了QABBA用于符号近似的优势。
            arXiv:2411.15209v2 Announce Type: replace 
Abstract: Time series are ubiquitous in numerous science and engineering domains, e.g., signal processing, bioinformatics, and astronomy. Previous work has verified the efficacy of symbolic time series representation in a variety of engineering applications due to its storage efficiency and numerosity reduction. The most recent symbolic aggregate approximation technique, ABBA, has been shown to preserve essential shape information of time series and improve downstream applications, e.g., neural network inference regarding prediction and anomaly detection in time series.
  Motivated by the emergence of high-performance hardware which enables efficient computation for low bit-width representations, we present a new quantization-based ABBA symbolic approximation technique, QABBA, which exhibits improved storage efficiency while retaining the original speed and accuracy of symbolic reconstruction. We prove an upper bound for the error arising from quantization and discuss how the number of bits should be chosen to balance this with other errors.
  An application of QABBA with large language models (LLMs) for time series regression is also presented, and its utility is investigated. By representing the symbolic chain of patterns on time series, QABBA not only avoids the training of embedding from scratch, but also achieves a new state-of-the-art on Monash regression dataset. The symbolic approximation to the time series offers a more efficient way to fine-tune LLMs on the time series regression task which contains various application domains. We further present a set of extensive experiments performed across various well-established datasets to demonstrate the advantages of the QABBA method for symbolic approximation.
        ]]></description>
    </item>
    <item>
        <title>EzSQL: An SQL intermediate representation for improving SQL-to-text Generation</title>
        <link>https://arxiv.org/abs/2411.18923</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2411.18923v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Meher Bhardwaj, Hrishikesh Ethari, Dennis Singh Moirangthem</dc:creator>
        <description><![CDATA[
            背景：传统SQL到文本生成任务采用多种模型，当前在Seq2Seq框架下利用预训练生成式语言模型，但将SQL作为输入序列并非最优。方法：提出新的SQL中间表示EzSQL，通过修改运算符和关键词简化SQL查询，使其更接近自然语言文本，并去除集合运算符，以EzSQL作为预训练生成式语言模型输入生成文本描述。效果：在WikiSQL和Spider数据集上是生成文本叙述的有效方法，还能提升文本到SQL解析器性能。
            arXiv:2411.18923v2 Announce Type: replace 
Abstract: The SQL-to-text generation task traditionally uses template base, Seq2Seq, tree-to-sequence, and graph-to-sequence models. Recent models take advantage of pre-trained generative language models for this task in the Seq2Seq framework. However, treating SQL as a sequence of inputs to the pre-trained models is not optimal. In this work, we put forward a new SQL intermediate representation called EzSQL to align SQL with the natural language text sequence. EzSQL simplifies the SQL queries and brings them closer to natural language text by modifying operators and keywords, which can usually be described in natural language. EzSQL also removes the need for set operators. Our proposed SQL-to-text generation model uses EzSQL as the input to a pre-trained generative language model for generating the text descriptions. We demonstrate that our model is an effective state-of-the-art method to generate text narrations from SQL queries on the WikiSQL and Spider datasets. We also show that by generating pretraining data using our SQL-to-text generation model, we can enhance the performance of Text-to-SQL parsers.
        ]]></description>
    </item>
    <item>
        <title>Preference-Based Alignment of Discrete Diffusion Models</title>
        <link>https://arxiv.org/abs/2503.08295</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.08295v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Umberto Borso, Davide Paglieri, Jude Wells, Tim Rockt\"aschel</dc:creator>
        <description><![CDATA[
            背景：扩散模型在多领域表现出色，应用已拓展到离散数据，但使离散扩散模型与特定任务偏好对齐仍具挑战。方法：提出Discrete Diffusion DPO（D2 - DPO），将直接偏好优化（DPO）应用于离散扩散模型，推导新损失函数，用偏好数据微调生成过程并保持与参考分布的一致性。效果：在结构化二进制序列生成任务上验证，该方法能有效使模型输出与偏好对齐并保持结构有效性，无需显式奖励模型，可替代基于强化学习的方法。
            arXiv:2503.08295v2 Announce Type: replace 
Abstract: Diffusion models have achieved state-of-the-art performance across multiple domains, with recent advancements extending their applicability to discrete data. However, aligning discrete diffusion models with task-specific preferences remains challenging, particularly in scenarios where explicit reward functions are unavailable. In this work, we introduce Discrete Diffusion DPO (D2-DPO), the first adaptation of Direct Preference Optimization (DPO) to discrete diffusion models formulated as continuous-time Markov chains. Our approach derives a novel loss function that directly fine-tunes the generative process using preference data while preserving fidelity to a reference distribution. We validate D2-DPO on a structured binary sequence generation task, demonstrating that the method effectively aligns model outputs with preferences while maintaining structural validity. Our results highlight that D2-DPO enables controlled fine-tuning without requiring explicit reward models, making it a practical alternative to reinforcement learning-based approaches. Future research will explore extending D2-DPO to more complex generative tasks, including language modeling and protein sequence generation, as well as investigating alternative noise schedules, such as uniform noising, to enhance flexibility across different applications.
        ]]></description>
    </item>
    <item>
        <title>Mesh Mamba: A Unified State Space Model for Saliency Prediction in Non-Textured and Textured Meshes</title>
        <link>https://arxiv.org/abs/2504.01466</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.01466v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kaiwei Zhang, Dandan Zhu, Xiongkuo Min, Guangtao Zhai</dc:creator>
        <description><![CDATA[
            背景：网格显著性通过识别和强调吸引视觉注意的区域，增强3D视觉适应性，需研究几何结构与纹理在塑造视觉注意中的相互作用。方法：建立全面的网格显著性数据集，引入基于状态空间模型（SSM）的统一显著性预测模型Mesh Mamba，通过子图嵌入和双向SSM实现局部几何和纹理的全局上下文建模。效果：经理论和实证验证，该模型提升了不同类型网格的性能，具有高可扩展性和通用性。
            arXiv:2504.01466v2 Announce Type: replace 
Abstract: Mesh saliency enhances the adaptability of 3D vision by identifying and emphasizing regions that naturally attract visual attention. To investigate the interaction between geometric structure and texture in shaping visual attention, we establish a comprehensive mesh saliency dataset, which is the first to systematically capture the differences in saliency distribution under both textured and non-textured visual conditions. Furthermore, we introduce mesh Mamba, a unified saliency prediction model based on a state space model (SSM), designed to adapt across various mesh types. Mesh Mamba effectively analyzes the geometric structure of the mesh while seamlessly incorporating texture features into the topological framework, ensuring coherence throughout appearance-enhanced modeling. More importantly, by subgraph embedding and a bidirectional SSM, the model enables global context modeling for both local geometry and texture, preserving the topological structure and improving the understanding of visual details and structural complexity. Through extensive theoretical and empirical validation, our model not only improves performance across various mesh types but also demonstrates high scalability and versatility, particularly through cross validations of various visual features.
        ]]></description>
    </item>
    <item>
        <title>Sequential-NIAH: A Needle-In-A-Haystack Benchmark for Extracting Sequential Needles from Long Contexts</title>
        <link>https://arxiv.org/abs/2504.04713</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.04713v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yifei Yu, Qian-Wen Zhang, Lingfeng Qiao, Di Yin, Fang Li, Jie Wang, Zengxi Chen, Suncong Zheng, Xiaolong Liang, Xing Sun</dc:creator>
        <description><![CDATA[
            背景：评估大语言模型处理长文本及提取特定信息能力很关键。方法：提出Sequential - NIAH基准，含三种信息生成管道，有8K到128K词元长度的文本，共14000个样本。训练了基于合成数据的评估模型。效果：评估模型在合成测试数据上准确率达99.49%，对六种知名大模型实验显示，最佳模型准确率仅63.15%，凸显长文本和多信息提取挑战大，该基准可靠，为提升长文本提取能力研究提供重要参考。
            arXiv:2504.04713v2 Announce Type: replace 
Abstract: Evaluating the ability of large language models (LLMs) to handle extended contexts is critical, particularly for retrieving information relevant to specific queries embedded within lengthy inputs. We introduce Sequential-NIAH, a benchmark specifically designed to evaluate the capability of LLMs to extract sequential information items (known as needles) from long contexts. The benchmark comprises three types of needle generation pipelines: synthetic, real, and open-domain QA. It includes contexts ranging from 8K to 128K tokens in length, with a dataset of 14,000 samples (2,000 reserved for testing). To facilitate evaluation on this benchmark, we trained a synthetic data-driven evaluation model capable of evaluating answer correctness based on chronological or logical order, achieving an accuracy of 99.49% on synthetic test data. We conducted experiments on six well-known LLMs, revealing that even the best-performing model achieved a maximum accuracy of only 63.15%. Further analysis highlights the growing challenges posed by increasing context lengths and the number of needles, underscoring substantial room for improvement. Additionally, noise robustness experiments validate the reliability of the benchmark, making Sequential-NIAH an important reference for advancing research on long text extraction capabilities of LLMs.
        ]]></description>
    </item>
    <item>
        <title>MedPix 2.0: A Comprehensive Multimodal Biomedical Data set for Advanced AI Applications with Retrieval Augmented Generation and Knowledge Graphs</title>
        <link>https://arxiv.org/abs/2407.02994</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2407.02994v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Irene Siragusa, Salvatore Contino, Massimo La Ciura, Rosario Alicata, Roberto Pirrone</dc:creator>
        <description><![CDATA[
            背景：医学领域开发AI应用因隐私问题缺乏高质量数据集，且视觉语言模型的发展需要多模态医学数据集。方法：以MedPix为基础，开发半自动流程提取视觉和文本数据，经人工清理创建MongoDB数据库，还开发GUI用于获取数据；先回顾基于RAG的VLM模型DR - Minerva，再用Llama 3.1 Instruct 8B和MedPix 2.0扩展其知识图谱。效果：构建的架构可作为医疗决策支持系统进行端到端查询，数据集已开源。
            arXiv:2407.02994v3 Announce Type: replace-cross 
Abstract: The increasing interest in developing Artificial Intelligence applications in the medical domain, suffers from the lack of high-quality data set, mainly due to privacy-related issues. In addition, the recent increase in Vision Language Models (VLM) leads to the need for multimodal medical data sets, where clinical reports and findings are attached to the corresponding medical scans. This paper illustrates the entire workflow for building the MedPix 2.0 data set. Starting with the well-known multimodal data set MedPix, mainly used by physicians, nurses, and healthcare students for Continuing Medical Education purposes, a semi-automatic pipeline was developed to extract visual and textual data followed by a manual curing procedure in which noisy samples were removed, thus creating a MongoDB database. Along with the data set, we developed a Graphical User Interface aimed at navigating efficiently the MongoDB instance and obtaining the raw data that can be easily used for training and/or fine-tuning VLMs. To enforce this point, in this work, we first recall DR-Minerva, a Retrieve Augmented Generation-based VLM model trained upon MedPix 2.0. DR-Minerva predicts the body part and the modality used to scan its input image. We also propose the extension of DR-Minerva with a Knowledge Graph that uses Llama 3.1 Instruct 8B, and leverages MedPix 2.0. The resulting architecture can be queried in a end-to-end manner, as a medical decision support system. MedPix 2.0 is available on GitHub https://github.com/CHILab1/MedPix-2.0
        ]]></description>
    </item>
    <item>
        <title>Design2GarmentCode: Turning Design Concepts to Tangible Garments Through Program Synthesis</title>
        <link>https://arxiv.org/abs/2412.08603</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2412.08603v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Feng Zhou, Ruiyang Liu, Chen Liu, Gaofeng He, Yong-Lu Li, Xiaogang Jin, Huamin Wang</dc:creator>
        <description><![CDATA[
            背景：现有单模态缝纫图案生成模型难以编码多模态设计概念并与具有精确几何结构和复杂缝纫关系的矢量化图案关联。方法：提出基于大多模态模型（LMMs）的缝纫图案生成方法Design2GarmentCode，从多模态设计概念生成参数化制版程序，LMM用于解释设计输入，制版程序连接跨领域制版知识与矢量化图案。效果：能灵活处理多种复杂设计表达，转换为尺寸精确、缝线正确的图案，相比以往方法，显著提升训练效率、生成质量和创作灵活性。
            arXiv:2412.08603v3 Announce Type: replace-cross 
Abstract: Sewing patterns, the essential blueprints for fabric cutting and tailoring, act as a crucial bridge between design concepts and producible garments. However, existing uni-modal sewing pattern generation models struggle to effectively encode complex design concepts with a multi-modal nature and correlate them with vectorized sewing patterns that possess precise geometric structures and intricate sewing relations. In this work, we propose a novel sewing pattern generation approach \textbf{Design2GarmentCode} based on Large Multimodal Models (LMMs), to generate parametric pattern-making programs from multi-modal design concepts. LMM offers an intuitive interface for interpreting diverse design inputs, while pattern-making programs could serve as well-structured and semantically meaningful representations of sewing patterns, and act as a robust bridge connecting the cross-domain pattern-making knowledge embedded in LMMs with vectorized sewing patterns. Experimental results demonstrate that our method can flexibly handle various complex design expressions such as images, textual descriptions, designer sketches, or their combinations, and convert them into size-precise sewing patterns with correct stitches. Compared to previous methods, our approach significantly enhances training efficiency, generation quality, and authoring flexibility.
        ]]></description>
    </item>
    <item>
        <title>Large Language Model Can Be a Foundation for Hidden Rationale-Based Retrieval</title>
        <link>https://arxiv.org/abs/2412.16615</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2412.16615v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Luo Ji, Feixiang Guo, Teng Chen, Qingqing Gu, Xiaoyu Wang, Ningyuan Xi, Yihong Wang, Peng Yu, Yue Zhao, Hongyang Lei, Zhonglin Jiang, Yong Chen</dc:creator>
        <description><![CDATA[
            背景：现有检索增强生成（RAG）系统多用于事实检索，假设查询和正文档语义相似，本文研究更具挑战性的隐藏理由检索。方法：采用交叉编码器架构的指令调优大语言模型（LLM），设计特殊指令将检索任务转化为生成任务，用直接偏好优化（DPO）微调模型，且优化框架以提高计算效率。效果：提出的RaHoRe框架在情感支持对话（ESC）上零样本和微调性能均优于以往检索工作，表明LLM可用于更广泛检索任务。
            arXiv:2412.16615v2 Announce Type: replace-cross 
Abstract: Despite the recent advancement in Retrieval-Augmented Generation (RAG) systems, most retrieval methodologies are often developed for factual retrieval, which assumes query and positive documents are semantically similar. In this paper, we instead propose and study a more challenging type of retrieval task, called hidden rationale retrieval, in which query and document are not similar but can be inferred by reasoning chains, logic relationships, or empirical experiences. To address such problems, an instruction-tuned Large language model (LLM) with a cross-encoder architecture could be a reasonable choice. To further strengthen pioneering LLM-based retrievers, we design a special instruction that transforms the retrieval task into a generative task by prompting LLM to answer a binary-choice question. The model can be fine-tuned with direct preference optimization (DPO). The framework is also optimized for computational efficiency with no performance degradation. We name this retrieval framework by RaHoRe and verify its zero-shot and fine-tuned performance superiority on Emotional Support Conversation (ESC), compared with previous retrieval works. Our study suggests the potential to employ LLM as a foundation for a wider scope of retrieval tasks. Our codes, models, and datasets are available on https://github.com/flyfree5/LaHoRe.
        ]]></description>
    </item>
    <item>
        <title>Towards Reasoning Era: A Survey of Long Chain-of-Thought for Reasoning Large Language Models</title>
        <link>https://arxiv.org/abs/2503.09567</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.09567v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qiguang Chen, Libo Qin, Jinhao Liu, Dengyun Peng, Jiannan Guan, Peng Wang, Mengkang Hu, Yuhang Zhou, Te Gao, Wanxiang Che</dc:creator>
        <description><![CDATA[
            背景：大语言模型在推理方面取得进展，长思维链（Long CoT）提升了推理能力，但缺乏相关全面调研。方法：本文对Long CoT提供统一视角，区分其与短思维链，提出新分类法；探讨其深度推理等关键特征；研究相关现象；指出研究差距与未来方向，如多模态推理融合等。效果：为人工智能逻辑推理发展提供结构化概述，有望启发后续研究。
            arXiv:2503.09567v3 Announce Type: replace-cross 
Abstract: Recent advancements in reasoning with large language models (RLLMs), such as OpenAI-O1 and DeepSeek-R1, have demonstrated their impressive capabilities in complex domains like mathematics and coding. A central factor in their success lies in the application of long chain-of-thought (Long CoT) characteristics, which enhance reasoning abilities and enable the solution of intricate problems. However, despite these developments, a comprehensive survey on Long CoT is still lacking, limiting our understanding of its distinctions from traditional short chain-of-thought (Short CoT) and complicating ongoing debates on issues like "overthinking" and "test-time scaling." This survey seeks to fill this gap by offering a unified perspective on Long CoT. (1) We first distinguish Long CoT from Short CoT and introduce a novel taxonomy to categorize current reasoning paradigms. (2) Next, we explore the key characteristics of Long CoT: deep reasoning, extensive exploration, and feasible reflection, which enable models to handle more complex tasks and produce more efficient, coherent outcomes compared to the shallower Short CoT. (3) We then investigate key phenomena such as the emergence of Long CoT with these characteristics, including overthinking, and test-time scaling, offering insights into how these processes manifest in practice. (4) Finally, we identify significant research gaps and highlight promising future directions, including the integration of multi-modal reasoning, efficiency improvements, and enhanced knowledge frameworks. By providing a structured overview, this survey aims to inspire future research and further the development of logical reasoning in artificial intelligence.
        ]]></description>
    </item>
    <item>
        <title>A Streamable Neural Audio Codec with Residual Scalar-Vector Quantization for Real-Time Communication</title>
        <link>https://arxiv.org/abs/2504.06561</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.06561v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiao-Hang Jiang, Yang Ai, Rui-Chen Zheng, Zhen-Hua Ling</dc:creator>
        <description><![CDATA[
            背景：实时通信需要低延迟、高效的音频编解码器。方法：本文提出StreamCodec，采用全因果、对称的编解码器结构，在MDCT域工作，引入残差标量 - 矢量量化器（RSVQ），以提升码本利用率和补偿结构因果性导致的音频质量损失。效果：在16 kHz LibriTTS数据集上，1.5 kbps时ViSQOL分数达4.30，固定延迟仅20 ms，CPU上生成速度近实时20倍，模型仅7M参数，解码音频质量与先进非流式神经音频编解码器相当，适合实时通信。
            arXiv:2504.06561v1 Announce Type: new 
Abstract: This paper proposes StreamCodec, a streamable neural audio codec designed for real-time communication. StreamCodec adopts a fully causal, symmetric encoder-decoder structure and operates in the modified discrete cosine transform (MDCT) domain, aiming for low-latency inference and real-time efficient generation. To improve codebook utilization efficiency and compensate for the audio quality loss caused by structural causality, StreamCodec introduces a novel residual scalar-vector quantizer (RSVQ). The RSVQ sequentially connects scalar quantizers and improved vector quantizers in a residual manner, constructing coarse audio contours and refining acoustic details, respectively. Experimental results confirm that the proposed StreamCodec achieves decoded audio quality comparable to advanced non-streamable neural audio codecs. Specifically, on the 16 kHz LibriTTS dataset, StreamCodec attains a ViSQOL score of 4.30 at 1.5 kbps. It has a fixed latency of only 20 ms and achieves a generation speed nearly 20 times real-time on a CPU, with a lightweight model size of just 7M parameters, making it highly suitable for real-time communication applications.
        ]]></description>
    </item>
    <item>
        <title>Detect All-Type Deepfake Audio: Wavelet Prompt Tuning for Enhanced Auditory Perception</title>
        <link>https://arxiv.org/abs/2504.06753</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.06753v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuankun Xie, Ruibo Fu, Zhiyong Wang, Xiaopeng Wang, Songjun Cao, Long Ma, Haonan Cheng, Long Ye</dc:creator>
        <description><![CDATA[
            背景：音频生成技术发展使多类型恶意深度伪造音频威胁多媒体安全，现有检测方法在跨类型场景表现不佳。方法：本文首次构建全类型深度伪造音频检测基准，提出提示调优自监督学习（PT - SSL）范式，以较少可训练参数优化自监督学习前端；提出小波提示调优（WPT） - SSL方法，从频域捕获类型不变的听觉深度伪造信息；利用所有类型深度伪造音频共同训练。效果：WPT - XLSR - AASIST表现最佳，在所有评估集上平均等错误率为3.58%。
            arXiv:2504.06753v1 Announce Type: new 
Abstract: The rapid advancement of audio generation technologies has escalated the risks of malicious deepfake audio across speech, sound, singing voice, and music, threatening multimedia security and trust. While existing countermeasures (CMs) perform well in single-type audio deepfake detection (ADD), their performance declines in cross-type scenarios. This paper is dedicated to studying the alltype ADD task. We are the first to comprehensively establish an all-type ADD benchmark to evaluate current CMs, incorporating cross-type deepfake detection across speech, sound, singing voice, and music. Then, we introduce the prompt tuning self-supervised learning (PT-SSL) training paradigm, which optimizes SSL frontend by learning specialized prompt tokens for ADD, requiring 458x fewer trainable parameters than fine-tuning (FT). Considering the auditory perception of different audio types,we propose the wavelet prompt tuning (WPT)-SSL method to capture type-invariant auditory deepfake information from the frequency domain without requiring additional training parameters, thereby enhancing performance over FT in the all-type ADD task. To achieve an universally CM, we utilize all types of deepfake audio for co-training. Experimental results demonstrate that WPT-XLSR-AASIST achieved the best performance, with an average EER of 3.58% across all evaluation sets. The code is available online.
        ]]></description>
    </item>
    <item>
        <title>Controllable Automatic Foley Artist</title>
        <link>https://arxiv.org/abs/2504.06778</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.06778v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Roi Benita, Michael Finkelson, Tavi Halperin, Gleb Sterkin, Yossi Adi</dc:creator>
        <description><![CDATA[
            背景：Foley是视频制作关键环节，近年个性化内容创作及自动视频转音频模型发展，使人们对音频生成过程的用户可控性需求增加。方法：提出CAFA模型，基于文本转音频模型，通过模态适配器机制整合视频信息，以文本引导为给定视频生成语义和时间对齐的音频。效果：实验表明，该方法在语义对齐和视听同步方面质量出色，主客观评估显示其具有较高文本可控性。 
            arXiv:2504.06778v1 Announce Type: new 
Abstract: Foley is a key element in video production, refers to the process of adding an audio signal to a silent video while ensuring semantic and temporal alignment. In recent years, the rise of personalized content creation and advancements in automatic video-to-audio models have increased the demand for greater user control in the process. One possible approach is to incorporate text to guide audio generation. While supported by existing methods, challenges remain in ensuring compatibility between modalities, particularly when the text introduces additional information or contradicts the sounds naturally inferred from the visuals. In this work, we introduce CAFA (Controllable Automatic Foley Artist) a video-and-text-to-audio model that generates semantically and temporally aligned audio for a given video, guided by text input. CAFA is built upon a text-to-audio model and integrates video information through a modality adapter mechanism. By incorporating text, users can refine semantic details and introduce creative variations, guiding the audio synthesis beyond the expected video contextual cues. Experiments show that besides its superior quality in terms of semantic alignment and audio-visual synchronization the proposed method enable high textual controllability as demonstrated in subjective and objective evaluations.
        ]]></description>
    </item>
    <item>
        <title>TASTE: Text-Aligned Speech Tokenization and Embedding for Spoken Language Modeling</title>
        <link>https://arxiv.org/abs/2504.07053</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.07053v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Liang-Hsuan Tseng, Yi-Chang Chen, Kuan-Yi Lee, Da-Shan Shiu, Hung-yi Lee</dc:creator>
        <description><![CDATA[
            大语言模型在基于文本的自然语言处理任务中表现出色，但受限于文本输入输出。为实现更自然的人机交互，开展语音 - 文本联合建模是有前景的方向，但现有口语语言模型（SLM）因模态不匹配落后于文本大模型。本文提出TASTE方法，在分词阶段使语音标记与对应文本转录对齐，通过特殊聚合机制和语音重建目标训练。实验表明，TASTE能保留关键副语言信息，大幅缩短标记序列长度，基于TASTE的SLM在基准任务上表现与之前全微调方法相当。
            arXiv:2504.07053v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) excel in text-based natural language processing tasks but remain constrained by their reliance on textual inputs and outputs. To enable more natural human-LLM interaction, recent progress have focused on deriving a spoken language model (SLM) that can not only listen but also generate speech. To achieve this, a promising direction is to conduct speech-text joint modeling. However, recent SLM still lag behind text LLM due to the modality mismatch. One significant mismatch can be the sequence lengths between speech and text tokens. To address this, we introduce Text-Aligned Speech Tokenization and Embedding (TASTE), a method that directly addresses the modality gap by aligning speech token with the corresponding text transcription during the tokenization stage. We propose a method that can achieve this through the special aggregation mechanism and with speech reconstruction as the training objective. We conduct extensive experiments and show that TASTE can preserve essential paralinguistic information while dramatically reducing the token sequence length. Furthermore, by leveraging TASTE, we can adapt text-based LLMs into effective SLMs with parameter-efficient fine-tuning techniques such as Low-Rank Adaptation (LoRA). Experimental results on benchmark tasks, including SALMON and StoryCloze, demonstrate that TASTE-based SLMs perform similarly to previous full-finetuning methods. To our knowledge, TASTE is the first end-to-end approach that utilizes a reconstruction objective to automatically learn a text-aligned speech tokenization and embedding suitable for spoken language modeling. Our demo, code, and models are publicly available at https://github.com/mtkresearch/TASTE-SpokenLM.
        ]]></description>
    </item>
    <item>
        <title>F5R-TTS: Improving Flow-Matching based Text-to-Speech with Group Relative Policy Optimization</title>
        <link>https://arxiv.org/abs/2504.02407</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.02407v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiaohui Sun, Ruitong Xiao, Jianye Mo, Bowen Wu, Qun Yu, Baoxun Wang</dc:creator>
        <description><![CDATA[
            背景：传统基于流匹配的文本到语音（TTS）系统存在一定不足。方法：提出F5R - TTS系统，将梯度奖励策略优化（GRPO）集成到基于流匹配的架构中，把流匹配TTS的确定性输出转化为概率高斯分布以融入强化学习算法，先预训练基于流匹配的模型，再用GRPO进行强化学习，采用自动语音识别计算的字错误率（WER）和验证模型评估的说话人相似度（SIM）作为双奖励指标。效果：零样本语音克隆实验显示，相比传统系统，WER相对降低29.5%，SIM分数相对提高4.6%。
            arXiv:2504.02407v2 Announce Type: replace 
Abstract: We present F5R-TTS, a novel text-to-speech (TTS) system that integrates Gradient Reward Policy Optimization (GRPO) into a flow-matching based architecture. By reformulating the deterministic outputs of flow-matching TTS into probabilistic Gaussian distributions, our approach enables seamless integration of reinforcement learning algorithms. During pretraining, we train a probabilistically reformulated flow-matching based model which is derived from F5-TTS with an open-source dataset. In the subsequent reinforcement learning (RL) phase, we employ a GRPO-driven enhancement stage that leverages dual reward metrics: word error rate (WER) computed via automatic speech recognition and speaker similarity (SIM) assessed by verification models. Experimental results on zero-shot voice cloning demonstrate that F5R-TTS achieves significant improvements in both speech intelligibility (a 29.5% relative reduction in WER) and speaker similarity (a 4.6% relative increase in SIM score) compared to conventional flow-matching based TTS systems. Audio samples are available at https://frontierlabs.github.io/F5R.
        ]]></description>
    </item>
    <item>
        <title>STAGE: Stemmed Accompaniment Generation through Prefix-Based Conditioning</title>
        <link>https://arxiv.org/abs/2504.05690</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.05690v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Giorgio Strano, Chiara Ballanti, Donato Crisostomi, Michele Mancusi, Luca Cosmo, Emanuele Rodol\`a</dc:creator>
        <description><![CDATA[
            背景：现有生成模型多专注于从头生成音乐，难以融入人类迭代创作流程。方法：提出STAGE模型，基于MusicGen微调，通过扩展变压器嵌入矩阵加入上下文令牌，以给定混音为条件生成单声道乐器伴奏。效果：与基线相比，生成的伴奏与输入混音更连贯、音频质量更高、与文本提示更契合；以类似节拍器音轨为条件时，能实现与目标节奏结构的先进对齐，无需额外的特定节奏模块，为交互式音乐创作提供实用工具。 
            arXiv:2504.05690v2 Announce Type: replace 
Abstract: Recent advances in generative models have made it possible to create high-quality, coherent music, with some systems delivering production-level output. Yet, most existing models focus solely on generating music from scratch, limiting their usefulness for musicians who want to integrate such models into a human, iterative composition workflow. In this paper we introduce STAGE, our STemmed Accompaniment GEneration model, fine-tuned from the state-of-the-art MusicGen to generate single-stem instrumental accompaniments conditioned on a given mixture. Inspired by instruction-tuning methods for language models, we extend the transformer's embedding matrix with a context token, enabling the model to attend to a musical context through prefix-based conditioning. Compared to the baselines, STAGE yields accompaniments that exhibit stronger coherence with the input mixture, higher audio quality, and closer alignment with textual prompts. Moreover, by conditioning on a metronome-like track, our framework naturally supports tempo-constrained generation, achieving state-of-the-art alignment with the target rhythmic structure--all without requiring any additional tempo-specific module. As a result, STAGE offers a practical, versatile tool for interactive music creation that can be readily adopted by musicians in real-world workflows.
        ]]></description>
    </item>
    <item>
        <title>A Simple but Strong Baseline for Sounding Video Generation: Effective Adaptation of Audio and Video Diffusion Models for Joint Generation</title>
        <link>https://arxiv.org/abs/2409.17550</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2409.17550v3</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Masato Ishii, Akio Hayakawa, Takashi Shibuya, Yuki Mitsufuji</dc:creator>
        <description><![CDATA[
            背景：需要构建用于有声视频生成的强大基线。方法：将音频和视频基础扩散模型与额外模块集成到单一模型中进行联合训练。为增强音视频对的对齐，引入两种机制，一是时间步调整，为各基础模型提供不同时间步信息；二是新的额外模块设计Cross - Modal Conditioning as Positional Encoding（CMC - PE），将跨模态信息嵌入为时间位置信息。效果：实验验证了两种机制的有效性，且该方法优于现有方法。
            arXiv:2409.17550v3 Announce Type: replace-cross 
Abstract: In this work, we build a simple but strong baseline for sounding video generation. Given base diffusion models for audio and video, we integrate them with additional modules into a single model and train it to make the model jointly generate audio and video. To enhance alignment between audio-video pairs, we introduce two novel mechanisms in our model. The first one is timestep adjustment, which provides different timestep information to each base model. It is designed to align how samples are generated along with timesteps across modalities. The second one is a new design of the additional modules, termed Cross-Modal Conditioning as Positional Encoding (CMC-PE). In CMC-PE, cross-modal information is embedded as if it represents temporal position information, and the embeddings are fed into the model like positional encoding. Compared with the popular cross-attention mechanism, CMC-PE provides a better inductive bias for temporal alignment in the generated data. Experimental results validate the effectiveness of the two newly introduced mechanisms and also demonstrate that our method outperforms existing methods.
        ]]></description>
    </item>
</channel>
</rss>