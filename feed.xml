<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
<channel>
    <title>arXiv Paper Filter</title>
    <link>https://github.com/None/arxiv_filter</link>
    <description>根据研究兴趣筛选的arXiv论文</description>
    <atom:link href="https://raw.githubusercontent.com/None/arxiv_filter/main/feed.xml" rel="self" type="application/rss+xml" />
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>zh-CN</language>
    <lastBuildDate>Tue, 05 Aug 2025 12:28:44 +0800</lastBuildDate>
    <managingEditor>None@github.com</managingEditor>
    <pubDate>Tue, 05 Aug 2025 12:28:44 +0800</pubDate>
    <skipDays>
        <day>Saturday</day>
        <day>Sunday</day>
    </skipDays>

    <item>
        <title>Rethinking Graph-Based Document Classification: Learning Data-Driven Structures Beyond Heuristic Approaches</title>
        <link>https://arxiv.org/abs/2508.00864</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.00864v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Margarita Bugue\~no, Gerard de Melo</dc:creator>
        <description><![CDATA[
            在文档分类中，基于图的模型能有效捕捉文档结构，但现有图文档表示多依赖启发式、特定领域规则或专家知识。本文提出学习数据驱动的图结构的方法，构建以句子为节点的同质加权图，通过自注意力模型学习边以识别句子对间依赖关系，用统计过滤策略保留强相关句子。实验表明，该方法在三个数据集上表现优于基于启发式的图，准确率和F1分数更高，统计过滤还提高了分类鲁棒性。
            arXiv:2508.00864v1 Announce Type: new 
Abstract: In document classification, graph-based models effectively capture document structure, overcoming sequence length limitations and enhancing contextual understanding. However, most existing graph document representations rely on heuristics, domain-specific rules, or expert knowledge. Unlike previous approaches, we propose a method to learn data-driven graph structures, eliminating the need for manual design and reducing domain dependence. Our approach constructs homogeneous weighted graphs with sentences as nodes, while edges are learned via a self-attention model that identifies dependencies between sentence pairs. A statistical filtering strategy aims to retain only strongly correlated sentences, improving graph quality while reducing the graph size. Experiments on three document classification datasets demonstrate that learned graphs consistently outperform heuristic-based graphs, achieving higher accuracy and $F_1$ score. Furthermore, our study demonstrates the effectiveness of the statistical filtering in improving classification robustness. These results highlight the potential of automatic graph generation over traditional heuristic approaches and open new directions for broader applications in NLP.
        ]]></description>
    </item>
    <item>
        <title>FRAM: Frobenius-Regularized Assignment Matching with Mixed-Precision Computing</title>
        <link>https://arxiv.org/abs/2508.00887</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.00887v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Binrui Shen, Yuan Liang, Shengxin Zhu</dc:creator>
        <description><![CDATA[
            背景：图匹配常被建模为二次分配问题（QAP），现有投影松弛方法会扩大可行集，带来数值尺度敏感和几何失准误差。方法：提出新的松弛框架，将投影步骤重新表述为Frobenius正则化线性分配（FRA）问题，用可调正则项缓解可行区域膨胀；提出缩放双随机归一化（SDSN）算法求解FRA，并开发混合精度架构加速。效果：CPU基准测试显示FRAM表现优于基线方法，结合GPU混合精度架构，比CPU - FP64版本提速达370倍，精度损失可忽略。
            arXiv:2508.00887v1 Announce Type: new 
Abstract: Graph matching, typically formulated as a Quadratic Assignment Problem (QAP), seeks to establish node correspondences between two graphs. To address the NP-hardness of QAP, some existing methods adopt projection-based relaxations that embed the problem into the convex hull of the discrete domain. However, these relaxations inevitably enlarge the feasible set, introducing two sources of error: numerical scale sensitivity and geometric misalignment between the relaxed and original domains. To alleviate these errors, we propose a novel relaxation framework by reformulating the projection step as a Frobenius-regularized Linear Assignment (FRA) problem, where a tunable regularization term mitigates feasible region inflation. This formulation enables normalization-based operations to preserve numerical scale invariance without compromising accuracy. To efficiently solve FRA, we propose the Scaling Doubly Stochastic Normalization (SDSN) algorithm. Building on its favorable computational properties, we develop a theoretically grounded mixed-precision architecture to achieve substantial acceleration. Comprehensive CPU-based benchmarks demonstrate that FRAM consistently outperforms all baseline methods under identical precision settings. When combined with a GPU-based mixed-precision architecture, FRAM achieves up to 370X speedup over its CPU-FP64 counterpart, with negligible loss in solution accuracy.
        ]]></description>
    </item>
    <item>
        <title>Hybrid Hypergraph Networks for Multimodal Sequence Data Classification</title>
        <link>https://arxiv.org/abs/2508.00926</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.00926v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Feng Xu, Hui Wang, Yuting Huang, Danwei Zhang, Zizhu Fan</dc:creator>
        <description><![CDATA[
            这是一篇关于多模态序列数据分类的论文。背景是现有方法在处理时序多模态数据分类时，多独立处理各模态且采用浅层融合策略，忽略了时间依赖和复杂结构关系。方法上，提出混合超图网络（HHN），先分割后构图，将序列拆分为带时间戳的段作为异构图节点，通过最大熵差准则的超边捕获模态内结构，再经超图卷积提取高阶依赖，通过时间对齐和图注意力建立模态间连接进行语义融合。该模型在四个多模态数据集上取得了最优结果。
            arXiv:2508.00926v1 Announce Type: new 
Abstract: Modeling temporal multimodal data poses significant challenges in classification tasks, particularly in capturing long-range temporal dependencies and intricate cross-modal interactions. Audiovisual data, as a representative example, is inherently characterized by strict temporal order and diverse modalities. Effectively leveraging the temporal structure is essential for understanding both intra-modal dynamics and inter-modal correlations. However, most existing approaches treat each modality independently and rely on shallow fusion strategies, which overlook temporal dependencies and hinder the model's ability to represent complex structural relationships. To address the limitation, we propose the hybrid hypergraph network (HHN), a novel framework that models temporal multimodal data via a segmentation-first, graph-later strategy. HHN splits sequences into timestamped segments as nodes in a heterogeneous graph. Intra-modal structures are captured via hyperedges guided by a maximum entropy difference criterion, enhancing node heterogeneity and structural discrimination, followed by hypergraph convolution to extract high-order dependencies. Inter-modal links are established through temporal alignment and graph attention for semantic fusion. HHN achieves state-of-the-art (SOTA) results on four multimodal datasets, demonstrating its effectiveness in complex classification tasks.
        ]]></description>
    </item>
    <item>
        <title>OKG-LLM: Aligning Ocean Knowledge Graph with Observation Data via LLMs for Global Sea Surface Temperature Prediction</title>
        <link>https://arxiv.org/abs/2508.00933</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.00933v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hanchen Yang, Jiaqi Wang, Jiannong Cao, Wengen Li, Jialun Zheng, Yangning Li, Chunyu Miao, Jihong Guan, Shuigeng Zhou, Philip S. Yu</dc:creator>
        <description><![CDATA[
            海表温度（SST）预测在海洋科学中至关重要，但现有数据驱动方法常忽略领域知识，限制了预测精度提升。大语言模型虽有潜力，但在SST预测中应用不足，主要因海洋领域知识与数值数据融合困难。为此，本文提出OKG - LLM框架。先构建海洋知识图谱（OKG），再用图嵌入网络学习其语义和结构知识，最后将其与SST数值数据对齐融合，用预训练LLM建模预测。实验表明，该方法优于现有技术，有效且稳健。
            arXiv:2508.00933v1 Announce Type: new 
Abstract: Sea surface temperature (SST) prediction is a critical task in ocean science, supporting various applications, such as weather forecasting, fisheries management, and storm tracking. While existing data-driven methods have demonstrated significant success, they often neglect to leverage the rich domain knowledge accumulated over the past decades, limiting further advancements in prediction accuracy. The recent emergence of large language models (LLMs) has highlighted the potential of integrating domain knowledge for downstream tasks. However, the application of LLMs to SST prediction remains underexplored, primarily due to the challenge of integrating ocean domain knowledge and numerical data. To address this issue, we propose Ocean Knowledge Graph-enhanced LLM (OKG-LLM), a novel framework for global SST prediction. To the best of our knowledge, this work presents the first systematic effort to construct an Ocean Knowledge Graph (OKG) specifically designed to represent diverse ocean knowledge for SST prediction. We then develop a graph embedding network to learn the comprehensive semantic and structural knowledge within the OKG, capturing both the unique characteristics of individual sea regions and the complex correlations between them. Finally, we align and fuse the learned knowledge with fine-grained numerical SST data and leverage a pre-trained LLM to model SST patterns for accurate prediction. Extensive experiments on the real-world dataset demonstrate that OKG-LLM consistently outperforms state-of-the-art methods, showcasing its effectiveness, robustness, and potential to advance SST prediction. The codes are available in the online repository.
        ]]></description>
    </item>
    <item>
        <title>From Generator to Embedder: Harnessing Innate Abilities of Multimodal LLMs via Building Zero-Shot Discriminative Embedding Model</title>
        <link>https://arxiv.org/abs/2508.00955</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.00955v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yeong-Joon Ju, Seong-Whan Lee</dc:creator>
        <description><![CDATA[
            多模态大语言模型在通用嵌入任务中潜力巨大，但将其生成特性用于判别式表示学习存在挑战，现有大规模对比预训练范式效率低。为此，本文提出高效的通用多模态嵌入框架，包含分层嵌入提示模板和自我感知难负样本采样两部分。实验表明，分层提示实现了与对比训练基线相当的零样本性能，在MMEB基准上使简单的批内负样本基线提升4.8分，自我感知难负样本采样进一步提升性能，减少了训练时间。
            arXiv:2508.00955v1 Announce Type: new 
Abstract: Multimodal Large Language Models (MLLMs) have emerged as a promising solution for universal embedding tasks, yet adapting their generative nature for discriminative representation learning remains a significant challenge. The dominant paradigm of large-scale contrastive pre-training suffers from critical inefficiencies, including prohibitive computational costs and a failure to leverage the intrinsic, instruction-following capabilities of MLLMs. To overcome these limitations, we propose an efficient framework for universal multimodal embeddings, which bridges this gap by centering on two synergistic components. First, our hierarchical embedding prompt template employs a two-level instruction architecture that forces the model to produce discriminative representations. Building on this strong foundation, our second component, self-aware hard negative sampling, redefines the fine-tuning process by leveraging the model's own understanding to efficiently mine challenging negatives while actively filtering out potential false negatives. Our comprehensive experiments show that our hierarchical prompt achieves zero-shot performance competitive with contrastively trained baselines and enhances the fine-tuning process by lifting a simple in-batch negative baseline by 4.8 points on the MMEB benchmark. We further boost the performance via our self-aware hard negative sampling, achieving the state-of-the-art performance without the contrative pre-training. Our work presents an effective and efficient pathway to adapt MLLMs for universal embedding tasks, significantly reducing training time.
        ]]></description>
    </item>
    <item>
        <title>FinKario: Event-Enhanced Automated Construction of Financial Knowledge Graph</title>
        <link>https://arxiv.org/abs/2508.00961</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.00961v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiang Li, Penglei Sun, Wanyun Zhou, Zikai Wei, Yongqi Zhang, Xiaowen Chu</dc:creator>
        <description><![CDATA[
            背景：个人投资者在金融市场中信息处理能力弱，大语言模型利用研报辅助决策时面临知识库更新慢、报告非结构化难题。方法：构建含超305360个实体等的金融知识图谱FinKario，自动整合实时信息；提出两阶段图检索策略FinKario - RAG。效果：实验表明，FinKario结合FinKario - RAG在股票趋势预测准确性上表现优异，回测中平均超金融大语言模型18.81%、超机构策略17.85%。
            arXiv:2508.00961v1 Announce Type: new 
Abstract: Individual investors are significantly outnumbered and disadvantaged in financial markets, overwhelmed by abundant information and lacking professional analysis. Equity research reports stand out as crucial resources, offering valuable insights. By leveraging these reports, large language models (LLMs) can enhance investors' decision-making capabilities and strengthen financial analysis. However, two key challenges limit their effectiveness: (1) the rapid evolution of market events often outpaces the slow update cycles of existing knowledge bases, (2) the long-form and unstructured nature of financial reports further hinders timely and context-aware integration by LLMs. To address these challenges, we tackle both data and methodological aspects. First, we introduce the Event-Enhanced Automated Construction of Financial Knowledge Graph (FinKario), a dataset comprising over 305,360 entities, 9,625 relational triples, and 19 distinct relation types. FinKario automatically integrates real-time company fundamentals and market events through prompt-driven extraction guided by professional institutional templates, providing structured and accessible financial insights for LLMs. Additionally, we propose a Two-Stage, Graph-Based retrieval strategy (FinKario-RAG), optimizing the retrieval of evolving, large-scale financial knowledge to ensure efficient and precise data access. Extensive experiments show that FinKario with FinKario-RAG achieves superior stock trend prediction accuracy, outperforming financial LLMs by 18.81% and institutional strategies by 17.85% on average in backtesting.
        ]]></description>
    </item>
    <item>
        <title>MAO-ARAG: Multi-Agent Orchestration for Adaptive Retrieval-Augmented Generation</title>
        <link>https://arxiv.org/abs/2508.01005</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01005v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yiqun Chen, Erhan Zhang, Lingyong Yan, Shuaiqiang Wang, Jizhou Huang, Dawei Yin, Jiaxin Mao</dc:creator>
        <description><![CDATA[
            在问答系统中，检索增强生成（RAG）对提高回答准确性和减少幻觉问题至关重要，但固定的RAG管道难以平衡不同查询的性能和成本。为此，本文提出自适应RAG框架MAO - ARAG，采用多智能体编排。它是多轮框架，定义多个执行器智能体，规划器智能体用强化学习训练，根据结果奖励（F1分数）和成本惩罚选择合适智能体组成工作流。实验表明，该方法能动态规划工作流，保证答案质量，且成本和延迟在可接受范围内。
            arXiv:2508.01005v1 Announce Type: new 
Abstract: In question-answering (QA) systems, Retrieval-Augmented Generation (RAG) has become pivotal in enhancing response accuracy and reducing hallucination issues. The architecture of RAG systems varies significantly, encompassing single-round RAG, iterative RAG, and reasoning RAG, each tailored to address different types of queries. Due to the varying complexity of real-world queries, a fixed RAG pipeline often struggles to balance performance and cost efficiency across different queries. To address this challenge, we propose an adaptive RAG framework called MAO-ARAG, which leverages multi-agent orchestration. Our adaptive RAG is conceived as a multi-turn framework. Specifically, we define multiple executor agents, representing typical RAG modules such as query reformulation agents, document selection agent, and generation agents. A planner agent intelligently selects and integrates the appropriate agents from these executors into a suitable workflow tailored for each query, striving for high-quality answers while maintaining reasonable costs. During each turn, the planner agent is trained using reinforcement learning, guided by an outcome-based reward (F1 score) and a cost-based penalty, continuously improving answer quality while keeping costs within a reasonable range. Experiments conducted on multiple QA datasets demonstrate that our approach, which dynamically plans workflows for each query, not only achieves high answer quality but also maintains both cost and latency within acceptable limits.The code of MAO-ARAG is on https://github.com/chenyiqun/Agentic-RAG.
        ]]></description>
    </item>
    <item>
        <title>Structured Spectral Graph Learning for Anomaly Classification in 3D Chest CT Scans</title>
        <link>https://arxiv.org/abs/2508.01045</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01045v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Theo Di Piazza, Carole Lazarus, Olivier Nempont, Loic Boussel</dc:creator>
        <description><![CDATA[
            背景：CT扫描检查增多，3D CT扫描多标签分类因数据复杂空间关系和多样异常情况，仍是关键且具挑战的任务，现有方法存在局限。方法：提出基于图的新方法，将CT扫描建模为结构化图，利用经谱域卷积处理的轴向切片三元组节点增强多标签异常分类性能。效果：方法具有强跨数据集泛化能力，性能有竞争力，对z轴平移具鲁棒性，消融实验评估了各组件贡献。
            arXiv:2508.01045v1 Announce Type: new 
Abstract: With the increasing number of CT scan examinations, there is a need for automated methods such as organ segmentation, anomaly detection and report generation to assist radiologists in managing their increasing workload. Multi-label classification of 3D CT scans remains a critical yet challenging task due to the complex spatial relationships within volumetric data and the variety of observed anomalies. Existing approaches based on 3D convolutional networks have limited abilities to model long-range dependencies while Vision Transformers suffer from high computational costs and often require extensive pre-training on large-scale datasets from the same domain to achieve competitive performance. In this work, we propose an alternative by introducing a new graph-based approach that models CT scans as structured graphs, leveraging axial slice triplets nodes processed through spectral domain convolution to enhance multi-label anomaly classification performance. Our method exhibits strong cross-dataset generalization, and competitive performance while achieving robustness to z-axis translation. An ablation study evaluates the contribution of each proposed component.
        ]]></description>
    </item>
    <item>
        <title>FGBench: A Dataset and Benchmark for Molecular Property Reasoning at Functional Group-Level in Large Language Models</title>
        <link>https://arxiv.org/abs/2508.01055</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01055v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xuan Liu, Siru Ouyang, Xianrui Zhong, Jiawei Han, Huimin Zhao</dc:creator>
        <description><![CDATA[
            大语言模型在化学领域受关注，但现有数据集多聚焦分子级属性预测，忽视细粒度官能团信息。本文引入FGBench数据集，含62.5万个带官能团信息的分子属性推理问题，官能团标注精准，可促进多模态应用。数据集涵盖回归和分类任务，包括单官能团影响等三类分子属性推理。对7000条数据的基准测试显示，当前大语言模型在官能团级属性推理上表现不佳。该数据集构建方法有望为大模型理解分子结构 - 属性关系提供基础框架。
            arXiv:2508.01055v1 Announce Type: new 
Abstract: Large language models (LLMs) have gained significant attention in chemistry. However, most existing datasets center on molecular-level property prediction and overlook the role of fine-grained functional group (FG) information. Incorporating FG-level data can provide valuable prior knowledge that links molecular structures with textual descriptions, which can be used to build more interpretable, structure-aware LLMs for reasoning on molecule-related tasks. Moreover, LLMs can learn from such fine-grained information to uncover hidden relationships between specific functional groups and molecular properties, thereby advancing molecular design and drug discovery. Here, we introduce FGBench, a dataset comprising 625K molecular property reasoning problems with functional group information. Functional groups are precisely annotated and localized within the molecule, which ensures the dataset's interoperability thereby facilitating further multimodal applications. FGBench includes both regression and classification tasks on 245 different functional groups across three categories for molecular property reasoning: (1) single functional group impacts, (2) multiple functional group interactions, and (3) direct molecular comparisons. In the benchmark of state-of-the-art LLMs on 7K curated data, the results indicate that current LLMs struggle with FG-level property reasoning, highlighting the need to enhance reasoning capabilities in LLMs for chemistry tasks. We anticipate that the methodology employed in FGBench to construct datasets with functional group-level information will serve as a foundational framework for generating new question-answer pairs, enabling LLMs to better understand fine-grained molecular structure-property relationships. The dataset and evaluation code are available at \href{https://github.com/xuanliugit/FGBench}{https://github.com/xuanliugit/FGBench}.
        ]]></description>
    </item>
    <item>
        <title>Graph-based Interaction Augmentation Network for Robust Multimodal Sentiment Analysis</title>
        <link>https://arxiv.org/abs/2508.01168</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01168v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hu Zhangfeng, Shi mengxin</dc:creator>
        <description><![CDATA[
            现实场景中模态缺失给多模态情感分析（MSA）带来挑战，现有方法多忽视模态内和模态间复杂依赖关系，无法充分利用可用模态捕捉互补语义。为此，本文提出基于图的框架，先设计可学习超图建模模态内时间依赖，再用有向图基于注意力机制探索模态间相关性，最后整合完整样本知识监督交互过程。在MOSI和MOSEI数据集上的实验证明了该方法的有效性。
            arXiv:2508.01168v1 Announce Type: new 
Abstract: The inevitable modality imperfection in real-world scenarios poses significant challenges for Multimodal Sentiment Analysis (MSA). While existing methods tailor reconstruction or joint representation learning strategies to restore missing semantics, they often overlook complex dependencies within and across modalities. Consequently, they fail to fully leverage available modalities to capture complementary semantics. To this end, this paper proposes a novel graph-based framework to exploit both intra- and inter-modality interactions, enabling imperfect samples to derive missing semantics from complementary parts for robust MSA. Specifically, we first devise a learnable hypergraph to model intra-modality temporal dependencies to exploit contextual information within each modality. Then, a directed graph is employed to explore inter-modality correlations based on attention mechanism, capturing complementary information across different modalities. Finally, the knowledge from perfect samples is integrated to supervise our interaction processes, guiding the model toward learning reliable and robust joint representations. Extensive experiments on MOSI and MOSEI datasets demonstrate the effectiveness of our method.
        ]]></description>
    </item>
    <item>
        <title>Prompting Large Language Models with Partial Knowledge for Answering Questions with Unseen Entities</title>
        <link>https://arxiv.org/abs/2508.01290</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01290v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhichao Yan, Jiapu Wang, Jiaoyan Chen, Yanyan Wang, Hongye Tan, Jiye Liang, Xiaoli Li, Ru Li, Jeff Z. Pan</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）系统有效利用部分相关知识仍是关键挑战，尤其是在不完整知识库检索中。方法：提出可通过大语言模型（LLMs）中已嵌入的部分相关知识唤醒LLMs，用位于黄金推理路径的三元组及其变体构建部分相关知识，还提出新任务“未见实体知识图谱问答”。效果：对LLMs的唤醒效果进行了理论分析，并在两个知识图谱问答数据集上实验验证，该基于唤醒的方法在实际应用中效果更好，优于基于嵌入相似性、易返回噪声信息的传统方法。
            arXiv:2508.01290v1 Announce Type: new 
Abstract: Retrieval-Augmented Generation (RAG) shows impressive performance by supplementing and substituting parametric knowledge in Large Language Models (LLMs). Retrieved knowledge can be divided into three types: explicit answer evidence, implicit answer clue, and insufficient answer context which can be further categorized into totally irrelevant and partially relevant information. Effectively utilizing partially relevant knowledge remains a key challenge for RAG systems, especially in incomplete knowledge base retrieval. Contrary to the conventional view, we propose a new perspective: LLMs can be awakened via partially relevant knowledge already embedded in LLMs. To comprehensively investigate this phenomenon, the triplets located in the gold reasoning path and their variants are used to construct partially relevant knowledge by removing the path that contains the answer. We provide theoretical analysis of the awakening effect in LLMs and support our hypothesis with experiments on two Knowledge Graphs (KGs) Question Answering (QA) datasets. Furthermore, we present a new task, Unseen Entity KGQA, simulating real-world challenges where entity linking fails due to KG incompleteness. Our awakening-based approach demonstrates greater efficacy in practical applications, outperforms traditional methods that rely on embedding-based similarity which are prone to returning noisy information.
        ]]></description>
    </item>
    <item>
        <title>LinkQA: Synthesizing Diverse QA from Multiple Seeds Strongly Linked by Knowledge Points</title>
        <link>https://arxiv.org/abs/2508.01317</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01317v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xuemiao Zhang, Can Ren, Chengying Tu, Rongxiang Weng, Hongfei Yan, Jingang Wang, Xunliang Cai</dc:creator>
        <description><![CDATA[
            大语言模型发展受限于高质量、多样化训练数据的匮乏。为此提出LinkSyn框架，基于知识要点（KP）图合成数据。该框架从问答种子数据中提取KPs构建图，通过知识分布价值函数平衡KP覆盖与流行度，利用DeepSeek - R1基于多种子扩散合成，并灵活调整难度增强高难度问答。合成了含50B标记的多学科问答数据集LinkQA。在Llama - 3 8B上实验显示，用LinkQA持续预训练使MMLU和CMMLU平均提升11.51%，在不同模型规模和初始FLOPs下都提升性能。
            arXiv:2508.01317v1 Announce Type: new 
Abstract: The advancement of large language models (LLMs) struggles with the scarcity of high-quality, diverse training data. To address this limitation, we propose LinkSyn, a novel knowledge point (KP) graph-based synthesis framework that enables flexible control over discipline and difficulty distributions while balancing KP coverage and popularity. LinkSyn extracts KPs from question-answering (QA) seed data and constructs a KP graph to synthesize diverse QA data from multiple seeds strongly linked by KPs and sampled from graph walks. Specifically, LinkSyn incorporates (1) a knowledge distribution value function to guide the adjustment of path sampling probability and balance KP coverage and popularity during graph walks; (2) diffusion-based synthesis via DeepSeek-R1 by leveraging multiple seeds with dense logical associations along each path; and (3) high-difficulty QA enhancement within given disciplines by flexible difficulty adjustments. By executing LinkSyn, we synthesize LinkQA, a diverse multi-disciplinary QA dataset with 50B tokens. Extensive experiments on Llama-3 8B demonstrate that continual pre-training with LinkQA yields an average improvement of $\mathbf{11.51\%}$ on MMLU and CMMLU, establishing new SOTA results. LinkQA consistently enhances performance across model size and initial FLOPs scales.
        ]]></description>
    </item>
    <item>
        <title>CPformer -- Concept and Physics enhanced Transformer for Time Series Forecasting</title>
        <link>https://arxiv.org/abs/2508.01407</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01407v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hongwei Ma, Junbin Gao, Minh-Ngoc Tran</dc:creator>
        <description><![CDATA[
            背景：多元时间序列在不同领域统计特性不同，准确、可解释且符合物理规律的预测是持续挑战。方法：提出CPformer，通过五个自监督、与领域无关的概念进行预测，并引入基于第一性原理约束的可微残差，结合潜在透明度与科学指导，保留长上下文注意力。效果：在六个公开数据集上测试，在12个均方误差/平均绝对误差指标中有8个达到最低误差，相对最强基线模型，在电力、交通和疾病数据上均方误差分别降低23%、44%和61%。
            arXiv:2508.01407v1 Announce Type: new 
Abstract: Accurate, explainable and physically-credible forecasting remains a persistent challenge for multivariate time-series whose statistical properties vary across domains. We present CPformer, a Concept- and Physics-enhanced Transformer that channels every prediction through five self-supervised, domain-agnostic concepts while enforcing differentiable residuals drawn from first-principle constraints. Unlike prior efficiency-oriented Transformers that rely purely on sparsity or frequency priors , CPformer combines latent transparency with hard scientific guidance while retaining attention for long contexts. We tested CPformer on six publicly-available datasets: sub-hourly Electricity and Traffic, hourly ETT, high-dimensional Weather, weekly Influenza-like Illness, and minute-level Exchange Rate, and CPformer achieves the lowest error in eight of twelve MSE/MAE cells. Relative to the strongest Transformer baseline (FEDformer), CPformer reduces mean-squared-error by 23% on Electricity, 44% on Traffic and 61% on Illness, while matching performance on strictly periodic Weather and ETT series.
        ]]></description>
    </item>
    <item>
        <title>From Query to Logic: Ontology-Driven Multi-Hop Reasoning in LLMs</title>
        <link>https://arxiv.org/abs/2508.01424</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01424v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Haonan Bian, Yutao Qi, Rui Yang, Yuanxi Che, Jiaqian Wang, Heming Xia, Ranran Zhen</dc:creator>
        <description><![CDATA[
            大语言模型在复杂多跳问答任务中存在不足，因其难以捕捉实体间深层概念关系。为此提出ORACLE框架，该框架无需训练，结合大模型生成能力与知识图谱结构优势。分三步：用大模型动态构建特定问题的知识本体；将本体转化为一阶逻辑推理链；把原查询分解为逻辑连贯的子问题。在多跳问答基准测试中，该框架表现出色，与先进模型相当，且推理链更具逻辑性和可解释性。
            arXiv:2508.01424v1 Announce Type: new 
Abstract: Large Language Models (LLMs), despite their success in question answering, exhibit limitations in complex multi-hop question answering (MQA) tasks that necessitate non-linear, structured reasoning. This limitation stems from their inability to adequately capture deep conceptual relationships between entities. To overcome this challenge, we present **ORACLE** (**O**ntology-driven **R**easoning **A**nd **C**hain for **L**ogical **E**ucidation), a training-free framework that combines LLMs' generative capabilities with the structural benefits of knowledge graphs. Our approach operates through three stages: (1) dynamic construction of question-specific knowledge ontologies using LLMs, (2) transformation of these ontologies into First-Order Logic reasoning chains, and (3) systematic decomposition of the original query into logically coherent sub-questions. Experimental results on several standard MQA benchmarks show that our framework achieves highly competitive performance, rivaling current state-of-the-art models like DeepSeek-R1. Detailed analyses further confirm the effectiveness of each component, while demonstrating that our method generates more logical and interpretable reasoning chains than existing approaches.
        ]]></description>
    </item>
    <item>
        <title>EfficientGFormer: Multimodal Brain Tumor Segmentation via Pruned Graph-Augmented Transformer</title>
        <link>https://arxiv.org/abs/2508.01465</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01465v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Fatemeh Ziaeetabar</dc:creator>
        <description><![CDATA[
            背景：脑肿瘤亚区域异质性及容积推理计算成本高，使准确高效的脑肿瘤分割成为神经影像领域的挑战。方法：提出EfficientGFormer架构，结合预训练基础模型、基于图的推理和轻量级高效机制；用nnFormer作模态感知编码器，将多模态MRI体积转换为块级嵌入，构建双边缘图，采用剪枝的图注意力网络进行关系推理，蒸馏模块实现知识转移。效果：在相关数据集上，该模型精度达最优，显著降低内存和推理时间，优于基线模型。
            arXiv:2508.01465v1 Announce Type: new 
Abstract: Accurate and efficient brain tumor segmentation remains a critical challenge in neuroimaging due to the heterogeneous nature of tumor subregions and the high computational cost of volumetric inference. In this paper, we propose EfficientGFormer, a novel architecture that integrates pretrained foundation models with graph-based reasoning and lightweight efficiency mechanisms for robust 3D brain tumor segmentation. Our framework leverages nnFormer as a modality-aware encoder, transforming multi-modal MRI volumes into patch-level embeddings. These features are structured into a dual-edge graph that captures both spatial adjacency and semantic similarity. A pruned, edge-type-aware Graph Attention Network (GAT) enables efficient relational reasoning across tumor subregions, while a distillation module transfers knowledge from a full-capacity teacher to a compact student model for real-time deployment. Experiments on the MSD Task01 and BraTS 2021 datasets demonstrate that EfficientGFormer achieves state-of-the-art accuracy with significantly reduced memory and inference time, outperforming recent transformer-based and graph-based baselines. This work offers a clinically viable solution for fast and accurate volumetric tumor delineation, combining scalability, interpretability, and generalization.
        ]]></description>
    </item>
    <item>
        <title>TreeDiff: AST-Guided Code Generation with Diffusion LLMs</title>
        <link>https://arxiv.org/abs/2508.01473</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01473v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yiming Zeng, Jinghan Cao, Zexin Li, Yiming Chen, Tao Ren, Dawei Xiang, Xidong Wu, Shangqian Gao, Tingting Yu</dc:creator>
        <description><![CDATA[
            背景：基于扩散的语言模型为可控双向序列生成带来新可能，但应用于源代码等结构化领域面临挑战，标准训练中的标记级损坏技术常忽略代码结构。方法：提出一种语法感知扩散框架，将抽象语法树（AST）的结构先验融入去噪过程，选择性损坏从AST子树派生的语法上有意义的代码片段。效果：实验表明，语法感知损坏显著提高了语法正确性、重构准确性以及对未见代码模式的泛化能力。
            arXiv:2508.01473v1 Announce Type: new 
Abstract: Recent advances in diffusion-based language models have opened new possibilities for controllable and bidirectional sequence generation. These models provide an alternative to traditional autoregressive approaches by framing text generation as an iterative denoising process. However, applying diffusion models to structured domains such as source code remains a significant challenge. Programming languages differ from natural language in that they follow strict syntactic and semantic rules, with hierarchical organization that must be preserved for correctness. Standard token-level corruption techniques used during training often ignore this structure, which may hinder the model's ability to learn meaningful representations of code. To address this limitation, we propose a syntax-aware diffusion framework that incorporates structural priors from Abstract Syntax Trees (ASTs) into the denoising process. Instead of masking individual tokens at random, we selectively corrupt syntactically meaningful code spans derived from AST subtrees. This enables the model to reconstruct programs in a way that respects grammatical boundaries and captures long-range dependencies. Experimental results demonstrate that syntax-aware corruption significantly improves syntactic correctness, reconstruction accuracy, and generalization to unseen code patterns. These findings highlight the potential of incorporating structural information into diffusion-based training and suggest that syntax-guided denoising is a promising direction for advancing diffusion-based language models in code generation tasks.
        ]]></description>
    </item>
    <item>
        <title>HT-Transformer: Event Sequences Classification by Accumulating Prefix Information with History Tokens</title>
        <link>https://arxiv.org/abs/2508.01474</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01474v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ivan Karpukhin, Andrey Savchenko</dc:creator>
        <description><![CDATA[
            背景：深度学习在序列数据建模上成果显著，transformers逐渐取代循环网络，但在预测未来目标的分类任务中表现不如RNN，且性能差距原因不明。方法：指出transformers缺乏能紧凑有效表示整个序列的状态向量，对比预训练无法捕捉局部上下文，引入历史标记来在预测下一个标记的预训练中积累历史信息。效果：显著提升基于transformers的模型，在金融、电商和医疗任务中取得出色结果。
            arXiv:2508.01474v1 Announce Type: new 
Abstract: Deep learning has achieved remarkable success in modeling sequential data, including event sequences, temporal point processes, and irregular time series. Recently, transformers have largely replaced recurrent networks in these tasks. However, transformers often underperform RNNs in classification tasks where the objective is to predict future targets. The reason behind this performance gap remains largely unexplored. In this paper, we identify a key limitation of transformers: the absence of a single state vector that provides a compact and effective representation of the entire sequence. Additionally, we show that contrastive pretraining of embedding vectors fails to capture local context, which is crucial for accurate prediction. To address these challenges, we introduce history tokens, a novel concept that facilitates the accumulation of historical information during next-token prediction pretraining. Our approach significantly improves transformer-based models, achieving impressive results in finance, e-commerce, and healthcare tasks. The code is publicly available on GitHub.
        ]]></description>
    </item>
    <item>
        <title>Instruction-based Time Series Editing</title>
        <link>https://arxiv.org/abs/2508.01504</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01504v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiaxing Qiu, Dongliang Guo, Brynne Sullivan, Teague R. Henry, Tom Hartvigsen</dc:creator>
        <description><![CDATA[
            时间序列编辑旨在修改序列部分属性而保持其他不变，但现有基于扩散的编辑器存在条件格式不灵活、编辑强度不可控的问题。为此，本文提出基于指令的时间序列编辑方法，用户可用自然语言指定编辑内容。研究推出首个基于指令的编辑器InstructTime，将时间序列和指令嵌入共享多模态表示空间并解码生成编辑后的序列，还提出多分辨率编码器处理局部和全局编辑。实验表明，InstructTime能实现高质量、强度可控的编辑，可泛化到未见指令，且能通过少样本学习适应新条件。
            arXiv:2508.01504v1 Announce Type: new 
Abstract: In time series editing, we aim to modify some properties of a given time series without altering others. For example, when analyzing a hospital patient's blood pressure, we may add a sudden early drop and observe how it impacts their future while preserving other conditions. Existing diffusion-based editors rely on rigid, predefined attribute vectors as conditions and produce all-or-nothing edits through sampling. This attribute- and sampling-based approach limits flexibility in condition format and lacks customizable control over editing strength. To overcome these limitations, we introduce Instruction-based Time Series Editing, where users specify intended edits using natural language. This allows users to express a wider range of edits in a more accessible format. We then introduce InstructTime, the first instruction-based time series editor. InstructTime takes in time series and instructions, embeds them into a shared multi-modal representation space, then decodes their embeddings to generate edited time series. By learning a structured multi-modal representation space, we can easily interpolate between embeddings to achieve varying degrees of edit. To handle local and global edits together, we propose multi-resolution encoders. In our experiments, we use synthetic and real datasets and find that InstructTime is a state-of-the-art time series editor: InstructTime achieves high-quality edits with controllable strength, can generalize to unseen instructions, and can be easily adapted to unseen conditions through few-shot learning.
        ]]></description>
    </item>
    <item>
        <title>The Bidirectional Process Reward Model</title>
        <link>https://arxiv.org/abs/2508.01682</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01682v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Lingyin Zhang, Jun Gao, Xiaoxue Ren, Ziqiang Cao</dc:creator>
        <description><![CDATA[
            背景：现有过程奖励模型（PRMs）多采用单向从左到右的评估范式，难以利用全局上下文，较难验证早期推理步骤的一致性。方法：提出双向过程奖励模型（BiPRM），在传统从左到右评估流基础上，无缝融入从右到左的评估流，仅通过修改提示来实现从右到左评估，不引入额外参数和推理延迟。效果：在两个数学推理基准测试上实验，BiPRM在各设置下均优于单向基线，逐步奖励评估提升最高达31.9%。
            arXiv:2508.01682v1 Announce Type: new 
Abstract: Process Reward Models (PRMs) have emerged as a promising approach to enhance the reasoning quality of Large Language Models (LLMs) by assigning fine-grained scores to intermediate reasoning steps within a solution trajectory. However, existing PRMs predominantly adopt a unidirectional left-to-right (L2R) evaluation paradigm, which limits their ability to leverage global context, making it challenging to verify the consistency of earlier steps based on later ones. In light of these challenges, we propose a novel bidirectional evaluation paradigm, named Bidirectional Process Reward Model (BiPRM). BiPRM seamlessly incorporates a parallel right-to-left (R2L) evaluation stream alongside the conventional L2R flow, enabling later reasoning steps to help assess earlier ones in real time. Notably, the built-in R2L evaluation is implemented solely through prompt modifications that reverse the original reasoning trajectory, without any additional parameters or inference latency introduced. This ensures BiPRM remains both efficient and broadly compatible with existing PRM studies. We conduct extensive experiments on two mathematical reasoning benchmarks using samples generated by three different policy models. Our method, BiPRM, is evaluated across three backbones and three distinct PRM objectives. Across all settings, BiPRM consistently outperforms unidirectional baselines, achieving up to a 31.9% improvement in stepwise reward evaluation. Generally, our results highlight BiPRM's effectiveness, robustness, and general applicability, offering a promising new direction for process-based reward modeling.
        ]]></description>
    </item>
    <item>
        <title>Innovative tokenisation of structured data for LLM training</title>
        <link>https://arxiv.org/abs/2508.01685</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01685v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kayvan Karim, Hani Ragab Hassen. Hadj Batatia</dc:creator>
        <description><![CDATA[
            在机器学习中，数据表示是一大挑战，尤其在将基于序列的架构用于结构化表格数据时，现有方法难以对特征进行有效编码或保留表格结构。本文提出一种混合标记化方法，结合预定义固定标记和字节对编码学习的子词词汇表，将表格数据转换为适合大语言模型训练的统一序列格式。以大规模网络流量数据集验证，该方法效率高，5 小时内处理超 3100 万个网络流，数据压缩比达 6.18:1，为结构化数据训练基础模型提供可行途径。
            arXiv:2508.01685v1 Announce Type: new 
Abstract: Data representation remains a fundamental challenge in machine learning, particularly when adapting sequence-based architectures like Transformers and Large Language Models (LLMs) for structured tabular data. Existing methods often fail to cohesively encode the mix of numerical and categorical features or preserve the inherent structure of tables. This paper introduces a novel, hybrid tokenisation methodology designed to convert tabular data into a unified, sequential format suitable for LLM training. Our approach combines predefined fixed tokens to represent structural elements and low-cardinality categorical features, with a learned subword vocabulary using Byte-Pair Encoding (BPE) for high-cardinality and continuous values. We demonstrate the efficacy of this technique by applying it to a large-scale NetFlow dataset (CIDDS-001), preparing a corpus for a Network Intrusion Detection System (NIDS) foundation model. The evaluation shows that our method is highly efficient, processing over 31 million network flows in under five hours and achieving a significant data compression ratio of 6.18:1. This process resulted in a computationally manageable corpus of over one billion tokens, establishing a viable and generalisable pathway for training foundation models on structured data.
        ]]></description>
    </item>
    <item>
        <title>From SHAP to Rules: Distilling Expert Knowledge from Post-hoc Model Explanations in Time Series Classification</title>
        <link>https://arxiv.org/abs/2508.01687</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01687v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Maciej Mozolewski, Szymon Bobek, Grzegorz J. Nalepa</dc:creator>
        <description><![CDATA[
            时间序列分类的机器学习模型解释因原始序列难解读和高维性而颇具挑战。本文提出将事后实例级解释器的数值特征归因转化为结构化、易读规则的框架，规则定义适用区间以提升透明度。该方法表现与原生基于规则的方法相当，且更适配长序列、覆盖更多实例。通过规则融合平衡覆盖度、置信度和简洁性，引入可视化技术权衡特异性和通用性。实验表明，该框架增强了时间序列分类的可解释性、决策透明度和实用性。
            arXiv:2508.01687v1 Announce Type: new 
Abstract: Explaining machine learning (ML) models for time series (TS) classification is challenging due to inherent difficulty in raw time series interpretation and doubled down by the high dimensionality. We propose a framework that converts numeric feature attributions from post-hoc, instance-wise explainers (e.g., LIME, SHAP) into structured, human-readable rules. These rules define intervals indicating when and where they apply, improving transparency. Our approach performs comparably to native rule-based methods like Anchor while scaling better to long TS and covering more instances. Rule fusion integrates rule sets through methods such as weighted selection and lasso-based refinement to balance coverage, confidence, and simplicity, ensuring all instances receive an unambiguous, metric-optimized rule. It enhances explanations even for a single explainer. We introduce visualization techniques to manage specificity-generalization trade-offs. By aligning with expert-system principles, our framework consolidates conflicting or overlapping explanations - often resulting from the Rashomon effect - into coherent and domain-adaptable insights. Experiments on UCI datasets confirm that the resulting rule-based representations improve interpretability, decision transparency, and practical applicability for TS classification.
        ]]></description>
    </item>
    <item>
        <title>Collaborative Chain-of-Agents for Parametric-Retrieved Knowledge Synergy</title>
        <link>https://arxiv.org/abs/2508.01696</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01696v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yi Jiang, Sendong Zhao, Jianbo Li, Haochun Wang, Lizhe Zhang, Yan Liu, Bin Qin</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）可提升大语言模型能力，但当前RAG方法在生成时难以充分利用知识，模型内部参数知识与外部检索知识协同有限。方法：提出协作智能体链框架，先引入CoCoA - zero多智能体RAG框架进行条件知识归纳和答案推理，在此基础上开发CoCoA长链训练策略，合成扩展多智能体推理轨迹微调大模型。效果：CoCoA - zero和CoCoA在开放领域和多跳问答任务上表现更优。
            arXiv:2508.01696v1 Announce Type: new 
Abstract: Retrieval-Augmented Generation (RAG) has emerged as a promising framework for enhancing the capabilities of Large Language Models (LLMs), especially in knowledge-intensive tasks. Despite its advantages, current RAG methods often struggle to *fully exploit knowledge during generation*. In particular, the synergy between the model's internal parametric knowledge and external retrieved knowledge remains limited. Retrieved contents may sometimes mislead generation, while certain generated content can guide the model toward more accurate outputs. In this work, we propose Collaborative Chain-of-Agents, a framework designed to enhance explicitly synergy over both parametric and retrieved knowledge. Specifically, we first introduce CoCoA-zero, a multi-agent RAG framework that first performs conditional knowledge induction and then reasons answers. Building on this, we develop CoCoA, a long-chain training strategy that synthesizes extended multi-agent reasoning trajectories from CoCoA-zero to fine-tune the LLM. This strategy enhances the model's capability to explicitly integrate and jointly leverage parametric and retrieved knowledge. Experiments results show that CoCoA-zero and CoCoA achieve superior performance on open-domain and multi-hop QA tasks.
        ]]></description>
    </item>
    <item>
        <title>OccamVTS: Distilling Vision Models to 1% Parameters for Time Series Forecasting</title>
        <link>https://arxiv.org/abs/2508.01727</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01727v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sisuo Lyu, Siru Zhong, Weilin Ruan, Qingxiang Liu, Qingsong Wen, Hui Xiong, Yuxuan Liang</dc:creator>
        <description><![CDATA[
            时间序列预测在多种应用中至关重要，现有方法借助大视觉模型通过视觉表征捕捉时间模式，但该模型99%的参数对时间序列任务不必要。研究发现，时间序列与低级纹理特征匹配，高级语义会损害预测精度。为此提出OccamVTS知识蒸馏框架，将大视觉模型中1%的关键预测信息提取到轻量级网络。它采用金字塔式特征对齐结合相关性和特征蒸馏，过滤语义噪声。实验表明，仅用原模型1%的参数，OccamVTS在多基准数据集上达最优，尤其在少样本和零样本场景表现出色。
            arXiv:2508.01727v1 Announce Type: new 
Abstract: Time series forecasting is fundamental to diverse applications, with recent approaches leverage large vision models (LVMs) to capture temporal patterns through visual representations. We reveal that while vision models enhance forecasting performance, 99% of their parameters are unnecessary for time series tasks. Through cross-modal analysis, we find that time series align with low-level textural features but not high-level semantics, which can impair forecasting accuracy. We propose OccamVTS, a knowledge distillation framework that extracts only the essential 1% of predictive information from LVMs into lightweight networks. Using pre-trained LVMs as privileged teachers, OccamVTS employs pyramid-style feature alignment combined with correlation and feature distillation to transfer beneficial patterns while filtering out semantic noise. Counterintuitively, this aggressive parameter reduction improves accuracy by eliminating overfitting to irrelevant visual features while preserving essential temporal patterns. Extensive experiments across multiple benchmark datasets demonstrate that OccamVTS consistently achieves state-of-the-art performance with only 1% of the original parameters, particularly excelling in few-shot and zero-shot scenarios.
        ]]></description>
    </item>
    <item>
        <title>Semantically-Guided Inference for Conditional Diffusion Models: Enhancing Covariate Consistency in Time Series Forecasting</title>
        <link>https://arxiv.org/abs/2508.01761</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01761v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Rui Ding, Hanyang Meng, Zeyang Zhang, Jielong Yang</dc:creator>
        <description><![CDATA[
            背景：扩散模型在时间序列预测中表现出色，但生成轨迹与条件协变量常存在语义不对齐问题，尤其在复杂或多模态条件下。方法：提出SemGuide，一种即插即用的推理时方法，引入评分网络评估中间扩散状态与未来协变量的语义对齐度，在逐步重要性重新加权过程中以分数作为代理似然，调整采样路径且不改变原训练过程，该方法与模型无关。效果：在实际预测任务实验中，预测准确性和协变量对齐性均有提升，复杂条件场景下表现尤佳。
            arXiv:2508.01761v1 Announce Type: new 
Abstract: Diffusion models have demonstrated strong performance in time series forecasting, yet often suffer from semantic misalignment between generated trajectories and conditioning covariates, especially under complex or multimodal conditions. To address this issue, we propose SemGuide, a plug-and-play, inference-time method that enhances covariate consistency in conditional diffusion models. Our approach introduces a scoring network to assess the semantic alignment between intermediate diffusion states and future covariates. These scores serve as proxy likelihoods in a stepwise importance reweighting procedure, which progressively adjusts the sampling path without altering the original training process. The method is model-agnostic and compatible with any conditional diffusion framework. Experiments on real-world forecasting tasks show consistent gains in both predictive accuracy and covariate alignment, with especially strong performance under complex conditioning scenarios.
        ]]></description>
    </item>
    <item>
        <title>AGENTICT$^2$S:Robust Text-to-SPARQL via Agentic Collaborative Reasoning over Heterogeneous Knowledge Graphs for the Circular Economy</title>
        <link>https://arxiv.org/abs/2508.01815</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01815v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yang Zhao, Chengxiao Dai, Wei Zhuo, Tan Chuan Fu, Yue Xiu, Dusit Niyato, Jonathan Z. Low, Eugene Ho Hong Zhuang, Daren Zong Loong Tan</dc:creator>
        <description><![CDATA[
            异构知识图谱问答（KGQA）面临跨多样模式、对齐不完整等挑战，现有文本到SPARQL方法存在泛化性不足等问题。本文提出AgenticT$^2$S模块化框架，将KGQA分解为子任务，由专门代理负责检索、查询生成和验证，调度器用弱到强对齐策略分配子目标，两阶段验证器检测无效和语义不明确查询。实验表明，该框架在真实循环经济知识图谱上执行准确率提升17.3%，三元组F$_1$提升25.4%，平均提示长度减少46.4%。
            arXiv:2508.01815v1 Announce Type: new 
Abstract: Question answering over heterogeneous knowledge graphs (KGQA) involves reasoning across diverse schemas, incomplete alignments, and distributed data sources. Existing text-to-SPARQL approaches rely on large-scale domain-specific fine-tuning or operate within single-graph settings, limiting their generalizability in low-resource domains and their ability to handle queries spanning multiple graphs. These challenges are particularly relevant in domains such as the circular economy, where information about classifications, processes, and emissions is distributed across independently curated knowledge graphs (KGs). We present AgenticT$^2$S, a modular framework that decomposes KGQA into subtasks managed by specialized agents responsible for retrieval, query generation, and verification. A scheduler assigns subgoals to different graphs using weak-to-strong alignment strategies. A two-stage verifier detects structurally invalid and semantically underspecified queries through symbolic validation and counterfactual consistency checks. Experiments on real-world circular economy KGs demonstrate that AgenticT$^2$S improves execution accuracy by 17.3% and triple level F$_1$ by 25.4% over the best baseline, while reducing the average prompt length by 46.4%. These results demonstrate the benefits of agent-based schema-aware reasoning for scalable KGQA and support decision-making in sustainability domains through robust cross-graph reasoning.
        ]]></description>
    </item>
    <item>
        <title>Web-CogReasoner: Towards Knowledge-Induced Cognitive Reasoning for Web Agents</title>
        <link>https://arxiv.org/abs/2508.01858</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01858v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuhan Guo, Cong Guo, Aiwen Sun, Hongliang He, Xinyu Yang, Yue Lu, Yingji Zhang, Xuntao Guo, Dong Zhang, Jianzhuang Liu, Jiang Duan, Yijia Xiao, Liangjian Wen, Hai-Ming Xu, Yong Dai</dc:creator>
        <description><![CDATA[
            背景：多模态大模型推动了网络智能体发展，但有效认知推理需先获取足够知识。方法：将网络智能体能力分解为知识内容学习和认知过程两阶段，提出Web - CogKnowledge框架对知识分类；构建Web - CogDataset助力知识获取；通过知识驱动的思维链推理框架开发并训练Web - CogReasoner。效果：实验显示其明显优于现有模型，在结构化知识起关键作用的未见任务泛化中表现出色，还推出Web - CogBench用于评估。
            arXiv:2508.01858v1 Announce Type: new 
Abstract: Multimodal large-scale models have significantly advanced the development of web agents, enabling perception and interaction with digital environments akin to human cognition. In this paper, we argue that web agents must first acquire sufficient knowledge to effectively engage in cognitive reasoning. Therefore, we decompose a web agent's capabilities into two essential stages: knowledge content learning and cognitive processes. To formalize this, we propose Web-CogKnowledge Framework, categorizing knowledge as Factual, Conceptual, and Procedural. In this framework, knowledge content learning corresponds to the agent's processes of Memorizing and Understanding, which rely on the first two knowledge types, representing the "what" of learning. Conversely, cognitive processes correspond to Exploring, grounded in Procedural knowledge, defining the "how" of reasoning and action. To facilitate knowledge acquisition, we construct the Web-CogDataset, a structured resource curated from 14 real-world websites, designed to systematically instill core knowledge necessary for web agent. This dataset serves as the agent's conceptual grounding-the "nouns" upon which comprehension is built-as well as the basis for learning how to reason and act. Building on this foundation, we operationalize these processes through a novel knowledge-driven Chain-of-Thought (CoT) reasoning framework, developing and training our proposed agent, the Web-CogReasoner. Extensive experimentation reveals its significant superiority over existing models, especially in generalizing to unseen tasks where structured knowledge is decisive. To enable rigorous evaluation, we introduce the Web-CogBench, a comprehensive evaluation suite designed to assess and compare agent performance across the delineated knowledge domains and cognitive capabilities. Our code and data is open sourced at https://github.com/Gnonymous/Web-CogReasoner
        ]]></description>
    </item>
    <item>
        <title>Improving Hospital Risk Prediction with Knowledge-Augmented Multimodal EHR Modeling</title>
        <link>https://arxiv.org/abs/2508.01970</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01970v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Rituparna Datta, Jiaming Cui, Zihan Guan, Rupesh Silwal, Joshua C Eby, Gregory Madden, Anil Vullikanti</dc:creator>
        <description><![CDATA[
            利用电子健康记录（EHRs）准确预测临床结果对医疗至关重要。EHRs包含多模态数据。该研究提出统一框架，采用两阶段架构进行临床风险预测。第一阶段，微调大语言模型从临床笔记提取信息，并结合图检索外部知识；第二阶段，融合非结构化表示和结构化数据特征生成最终预测。实验在30天再入院和院内死亡预测任务上验证了其有效性，AUC分别达0.84和0.92，优于现有基线和临床实践。
            arXiv:2508.01970v1 Announce Type: new 
Abstract: Accurate prediction of clinical outcomes using Electronic Health Records (EHRs) is critical for early intervention, efficient resource allocation, and improved patient care. EHRs contain multimodal data, including both structured data and unstructured clinical notes that provide rich, context-specific information. In this work, we introduce a unified framework that seamlessly integrates these diverse modalities, leveraging all relevant available information through a two-stage architecture for clinical risk prediction. In the first stage, a fine-tuned Large Language Model (LLM) extracts crucial, task-relevant information from clinical notes, which is enhanced by graph-based retrieval of external domain knowledge from sources such as a medical corpus like PubMed, grounding the LLM's understanding. The second stage combines both unstructured representations and features derived from the structured data to generate the final predictions. This approach supports a wide range of clinical tasks. Here, we demonstrate its effectiveness on 30-day readmission and in-hospital mortality prediction. Experimental results show that our framework achieves strong performance, with AUC scores of $0.84$ and $0.92$, respectively, despite these tasks involving severely imbalanced datasets, with positive rates ranging from approximately $4\%$ to $13\%$. Moreover, it outperforms all existing baselines and clinical practices, including established risk scoring systems. To the best of our knowledge, this is one of the first frameworks for healthcare prediction which enhances the power of an LLM-based graph-guided knowledge retrieval method by combining it with structured data for improved clinical outcome prediction.
        ]]></description>
    </item>
    <item>
        <title>Revitalizing Canonical Pre-Alignment for Irregular Multivariate Time Series Forecasting</title>
        <link>https://arxiv.org/abs/2508.01971</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01971v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ziyu Zhou, Yiming Huang, Yanyun Wang, Yuankai Wu, James Kwok, Yuxuan Liang</dc:creator>
        <description><![CDATA[
            背景：不规则多变量时间序列（IMTS）虽在预测应用广泛，但高效建模困难。现有规范预对齐（CPA）方法存在计算开销大问题，基于图的模型又难以捕捉全局变量间相关性。方法：提出KAFNet架构，包括用于序列平滑和减少稀疏性的预卷积模块、用于学习压缩和建模序列内不规则性的时间核聚合模块，以及在频域低成本建模序列间相关性的频率线性注意力块。效果：在多个IMTS数据集上达最优预测性能，参数减少7.2倍，训练推理加速8.4倍。
            arXiv:2508.01971v1 Announce Type: new 
Abstract: Irregular multivariate time series (IMTS), characterized by uneven sampling and inter-variate asynchrony, fuel many forecasting applications yet remain challenging to model efficiently. Canonical Pre-Alignment (CPA) has been widely adopted in IMTS modeling by padding zeros at every global timestamp, thereby alleviating inter-variate asynchrony and unifying the series length, but its dense zero-padding inflates the pre-aligned series length, especially when numerous variates are present, causing prohibitive compute overhead. Recent graph-based models with patching strategies sidestep CPA, but their local message passing struggles to capture global inter-variate correlations. Therefore, we posit that CPA should be retained, with the pre-aligned series properly handled by the model, enabling it to outperform state-of-the-art graph-based baselines that sidestep CPA. Technically, we propose KAFNet, a compact architecture grounded in CPA for IMTS forecasting that couples (1) Pre-Convolution module for sequence smoothing and sparsity mitigation, (2) Temporal Kernel Aggregation module for learnable compression and modeling of intra-series irregularity, and (3) Frequency Linear Attention blocks for the low-cost inter-series correlations modeling in the frequency domain. Experiments on multiple IMTS datasets show that KAFNet achieves state-of-the-art forecasting performance, with a 7.2$\times$ parameter reduction and a 8.4$\times$ training-inference acceleration.
        ]]></description>
    </item>
    <item>
        <title>IMoRe: Implicit Program-Guided Reasoning for Human Motion Q&A</title>
        <link>https://arxiv.org/abs/2508.01984</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01984v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chen Li, Chinthani Sugandhika, Yeo Keat Ee, Eric Peh, Hao Zhang, Hong Yang, Deepu Rajan, Basura Fernando</dc:creator>
        <description><![CDATA[
            背景：现有人体运动问答方法依赖显式程序执行，手动定义功能模块限制了可扩展性和适应性。方法：提出隐式程序引导的运动推理（IMoRe）框架，无需手动设计模块统一多种查询类型的推理；模型直接基于结构化程序函数，引入程序引导阅读机制动态选择多级运动表示，推理模块迭代细化记忆表示。效果：在Babel - QA上达最优性能，能泛化到新构建数据集，展示了跨数据集的适应性。
            arXiv:2508.01984v1 Announce Type: new 
Abstract: Existing human motion Q\&amp;A methods rely on explicit program execution, where the requirement for manually defined functional modules may limit the scalability and adaptability. To overcome this, we propose an implicit program-guided motion reasoning (IMoRe) framework that unifies reasoning across multiple query types without manually designed modules. Unlike existing implicit reasoning approaches that infer reasoning operations from question words, our model directly conditions on structured program functions, ensuring a more precise execution of reasoning steps. Additionally, we introduce a program-guided reading mechanism, which dynamically selects multi-level motion representations from a pretrained motion Vision Transformer (ViT), capturing both high-level semantics and fine-grained motion cues. The reasoning module iteratively refines memory representations, leveraging structured program functions to extract relevant information for different query types. Our model achieves state-of-the-art performance on Babel-QA and generalizes to a newly constructed motion Q\&amp;A dataset based on HuMMan, demonstrating its adaptability across different motion reasoning datasets. Code and dataset are available at: https://github.com/LUNAProject22/IMoRe.
        ]]></description>
    </item>
    <item>
        <title>Contextually Aware E-Commerce Product Question Answering using RAG</title>
        <link>https://arxiv.org/abs/2508.01990</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01990v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Praveen Tangarajan, Anand A. Rajasekar, Manish Rathi, Vinay Rao Dandin, Ozan Ersoy</dc:creator>
        <description><![CDATA[
            背景：电商产品页面信息繁杂，易致用户认知过载，现有产品问答系统难以有效利用用户上下文和多样产品信息。方法：提出基于检索增强生成（RAG）的端到端电商产品问答框架，深度融合上下文理解，利用对话历史、用户画像和产品属性提供答案，处理不同类型查询，识别信息缺口。效果：能提供相关且个性化答案，还引入可广泛用于RAG系统评估的新指标。
            arXiv:2508.01990v1 Announce Type: new 
Abstract: E-commerce product pages contain a mix of structured specifications, unstructured reviews, and contextual elements like personalized offers or regional variants. Although informative, this volume can lead to cognitive overload, making it difficult for users to quickly and accurately find the information they need. Existing Product Question Answering (PQA) systems often fail to utilize rich user context and diverse product information effectively. We propose a scalable, end-to-end framework for e-commerce PQA using Retrieval Augmented Generation (RAG) that deeply integrates contextual understanding. Our system leverages conversational history, user profiles, and product attributes to deliver relevant and personalized answers. It adeptly handles objective, subjective, and multi-intent queries across heterogeneous sources, while also identifying information gaps in the catalog to support ongoing content improvement. We also introduce novel metrics to measure the framework's performance which are broadly applicable for RAG system evaluations.
        ]]></description>
    </item>
    <item>
        <title>Diagnosing Memorization in Chain-of-Thought Reasoning, One Token at a Time</title>
        <link>https://arxiv.org/abs/2508.02037</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.02037v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Huihan Li, You Chen, Siyuan Wang, Yixin He, Ninareh Mehrabi, Rahul Gupta, Xiang Ren</dc:creator>
        <description><![CDATA[
            大语言模型在推理基准测试中表现良好，但输入稍有变化就易出错，链式思维推理中记忆问题尤为突出。为此，研究团队提出STIM框架，基于预训练语料库中词元的统计共现情况，将推理链中的每个词元归因于局部、中程或远程等记忆源。分析表明，模型在复杂或长尾情况下更依赖记忆，局部记忆常是错误主因，导致多达67%的错误词元。此外，STIM的记忆分数可有效预测推理步骤中的错误词元，有助于诊断和改进模型推理。
            arXiv:2508.02037v1 Announce Type: new 
Abstract: Large Language Models (LLMs) perform well on reasoning benchmarks but often fail when inputs alter slightly, raising concerns about the extent to which their success relies on memorization. This issue is especially acute in Chain-of-Thought (CoT) reasoning, where spurious memorized patterns can trigger intermediate errors that cascade into incorrect final answers. We introduce STIM, a novel framework for Source-aware Token-level Identification of Memorization, which attributes each token in a reasoning chain to one of multiple memorization sources - local, mid-range, or long-range - based on their statistical co-occurrence with the token in the pretraining corpus. Our token-level analysis across tasks and distributional settings reveals that models rely more on memorization in complex or long-tail cases, and that local memorization is often the dominant driver of errors, leading to up to 67% of wrong tokens. We also show that memorization scores from STIM can be effective in predicting the wrong tokens in the wrong reasoning step. STIM offers a powerful tool for diagnosing and improving model reasoning and can generalize to other structured step-wise generation tasks.
        ]]></description>
    </item>
    <item>
        <title>MolReasoner: Toward Effective and Interpretable Reasoning for Molecular LLMs</title>
        <link>https://arxiv.org/abs/2508.02066</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.02066v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Guojiang Zhao, Sihang Li, Zixiang Lu, Zheng Cheng, Haitao Lin, Lirong Wu, Hanchen Xia, Hengxing Cai, Wentao Guo, Hongshuai Wang, Mingjun Xu, Siyu Zhu, Guolin Ke, Linfeng Zhang, Zhifeng Gao</dc:creator>
        <description><![CDATA[
            大语言模型在各领域表现出色，但在分子推理能力上探索不足。现有方法或缺乏特定领域语义，或面临可解释性和推理深度问题。为此提出MolReasoner两阶段框架，先通过GPT - 4o生成合成思维链样本初始化模型推理能力，再用强化学习使化学结构与语言描述对齐。该方法增强了可解释性，提升模型分子理解和泛化能力。实验表明，它优于现有方法，推动模型从基于记忆输出转向强大的化学推理。
            arXiv:2508.02066v1 Announce Type: new 
Abstract: Large Language Models(LLMs) have demonstrated remarkable performance across various domains, yet their capabilities in molecular reasoning remain insufficiently explored. Current approaches tend to rely heavily on general-purpose prompting, which lacks domain-specific molecular semantics, while those that use fine-tuning strategies often face challenges with interpretability and reasoning depth. To address these issues, we introduce MolReasoner, a two-stage framework designed to transition LLMs from memorization towards chemical reasoning. First, we propose Mol-SFT, which initializes the model's reasoning abilities via synthetic Chain-of-Thought(CoT) samples generated by GPT-4o and verified for chemical accuracy. Subsequently, Mol-RL applies reinforcement learning with specialized reward functions designed explicitly to align chemical structures with linguistic descriptions, thereby enhancing molecular reasoning capabilities. Our approach notably enhances interpretability, improving the model 's molecular understanding and enabling better generalization. Extensive experiments demonstrate that MolReasoner outperforms existing methods, and marking a significant shift from memorization-based outputs to robust chemical reasoning.
        ]]></description>
    </item>
    <item>
        <title>SpikeSTAG: Spatial-Temporal Forecasting via GNN-SNN Collaboration</title>
        <link>https://arxiv.org/abs/2508.02069</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.02069v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Bang Hu, Changze Lv, Mingjie Li, Yunpeng Liu, Xiaoqing Zheng, Fengzhe Zhang, Wei cao, Fan Zhang</dc:creator>
        <description><![CDATA[
            背景：脉冲神经网络（SNNs）在多元时间序列预测的空间建模潜力待挖掘。方法：提出全新SNN架构，先嵌入时间特征和自适应矩阵，再通过OBS块学习序列特征；用多尺度脉冲聚合（MSSA）分层聚合邻域信息；提出双路径脉冲融合（DSF）块，通过脉冲门控机制整合空间图特征和时间动态。效果：实验表明，该模型在所有数据集上超越基于SNN的iSpikformer，在长预测期优于传统时间模型。
            arXiv:2508.02069v1 Announce Type: new 
Abstract: Spiking neural networks (SNNs), inspired by the spiking behavior of biological neurons, offer a distinctive approach for capturing the complexities of temporal data. However, their potential for spatial modeling in multivariate time-series forecasting remains largely unexplored. To bridge this gap, we introduce a brand new SNN architecture, which is among the first to seamlessly integrate graph structural learning with spike-based temporal processing for multivariate time-series forecasting. Specifically, we first embed time features and an adaptive matrix, eliminating the need for predefined graph structures. We then further learn sequence features through the Observation (OBS) Block. Building upon this, our Multi-Scale Spike Aggregation (MSSA) hierarchically aggregates neighborhood information through spiking SAGE layers, enabling multi-hop feature extraction while eliminating the need for floating-point operations. Finally, we propose a Dual-Path Spike Fusion (DSF) Block to integrate spatial graph features and temporal dynamics via a spike-gated mechanism, combining LSTM-processed sequences with spiking self-attention outputs, effectively improve the model accuracy of long sequence datasets. Experiments show that our model surpasses the state-of-the-art SNN-based iSpikformer on all datasets and outperforms traditional temporal models at long horizons, thereby establishing a new paradigm for efficient spatial-temporal modeling.
        ]]></description>
    </item>
    <item>
        <title>S-RRG-Bench: Structured Radiology Report Generation with Fine-Grained Evaluation Framework</title>
        <link>https://arxiv.org/abs/2508.02082</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.02082v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yingshu Li, Yunyi Liu, Zhanyu Wang, Xinyu Liang, Lingqiao Liu, Lei Wang, Luping Zhou</dc:creator>
        <description><![CDATA[
            背景：传统放射学报告存在冗余、语言不一致问题，现有结构化报告生成方法有局限。方法：提出结构化放射学报告生成新方法，构建含多种信息的胸部X光数据集MIMIC - STRUC，训练基于大语言模型的报告生成模型，提出专门评估指标S - Score。效果：S - Score不仅能测疾病预测准确性，还能评估疾病细节精确性，与人工评估更相符，为报告质量提供更具临床相关性的衡量标准。
            arXiv:2508.02082v1 Announce Type: new 
Abstract: Radiology report generation (RRG) for diagnostic images, such as chest X-rays, plays a pivotal role in both clinical practice and AI. Traditional free-text reports suffer from redundancy and inconsistent language, complicating the extraction of critical clinical details. Structured radiology report generation (S-RRG) offers a promising solution by organizing information into standardized, concise formats. However, existing approaches often rely on classification or visual question answering (VQA) pipelines that require predefined label sets and produce only fragmented outputs. Template-based approaches, which generate reports by replacing keywords within fixed sentence patterns, further compromise expressiveness and often omit clinically important details. In this work, we present a novel approach to S-RRG that includes dataset construction, model training, and the introduction of a new evaluation framework. We first create a robust chest X-ray dataset (MIMIC-STRUC) that includes disease names, severity levels, probabilities, and anatomical locations, ensuring that the dataset is both clinically relevant and well-structured. We train an LLM-based model to generate standardized, high-quality reports. To assess the generated reports, we propose a specialized evaluation metric (S-Score) that not only measures disease prediction accuracy but also evaluates the precision of disease-specific details, thus offering a clinically meaningful metric for report quality that focuses on elements critical to clinical decision-making and demonstrates a stronger alignment with human assessments. Our approach highlights the effectiveness of structured reports and the importance of a tailored evaluation metric for S-RRG, providing a more clinically relevant measure of report quality.
        ]]></description>
    </item>
    <item>
        <title>AURORA: Augmented Understanding via Structured Reasoning and Reinforcement Learning for Reference Audio-Visual Segmentation</title>
        <link>https://arxiv.org/abs/2508.02149</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.02149v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ziyang Luo, Nian Liu, Fahad Shahbaz Khan, Junwei Han</dc:creator>
        <description><![CDATA[
            参考视听分割任务需模型结合多模态线索定位发声对象，现有方法缺乏语义理解、联合训练会影响像素精度。为此提出AURORA框架，采用结构化思维链提示机制引导逐步推理，引入分割特征蒸馏损失融合推理能力；还设计两阶段训练策略，先进行自我修正训练提升推理路径质量，再通过强化学习增强鲁棒性。实验表明，该框架在相关基准测试中达最优，且能有效泛化到无参考分割任务。
            arXiv:2508.02149v1 Announce Type: new 
Abstract: Reference Audio-Visual Segmentation (Ref-AVS) tasks challenge models to precisely locate sounding objects by integrating visual, auditory, and textual cues. Existing methods often lack genuine semantic understanding, tending to memorize fixed reasoning patterns. Furthermore, jointly training for reasoning and segmentation can compromise pixel-level precision. To address these issues, we introduce AURORA, a novel framework designed to enhance genuine reasoning and language comprehension in reference audio-visual segmentation. We employ a structured Chain-of-Thought (CoT) prompting mechanism to guide the model through a step-by-step reasoning process and introduce a novel segmentation feature distillation loss to effectively integrate these reasoning abilities without sacrificing segmentation performance. To further cultivate the model's genuine reasoning capabilities, we devise a further two-stage training strategy: first, a ``corrective reflective-style training" stage utilizes self-correction to enhance the quality of reasoning paths, followed by reinforcement learning via Group Reward Policy Optimization (GRPO) to bolster robustness in challenging scenarios. Experiments demonstrate that AURORA achieves state-of-the-art performance on Ref-AVS benchmarks and generalizes effectively to unreferenced segmentation.
        ]]></description>
    </item>
    <item>
        <title>Patho-AgenticRAG: Towards Multimodal Agentic Retrieval-Augmented Generation for Pathology VLMs via Reinforcement Learning</title>
        <link>https://arxiv.org/abs/2508.02258</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.02258v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wenchuan Zhang, Jingru Guo, Hengzhe Zhang, Penghao Zhang, Jie Chen, Shuwan Zhang, Zhang Zhang, Yuhao Yi, Hong Bu</dc:creator>
        <description><![CDATA[
            背景：视觉语言模型在医学影像中泛化能力强，但病理学因超高分辨率、复杂组织结构和细微临床语义，使病理VLMs易产生幻觉，现有RAG方法依赖文本知识库，难以利用诊断视觉线索。方法：提出Patho - AgenticRAG，构建基于权威病理教科书页面级嵌入的数据库，支持图文联合搜索、推理、任务分解和多轮搜索交互。效果：在复杂病理任务中显著优于现有多模态模型。
            arXiv:2508.02258v1 Announce Type: new 
Abstract: Although Vision Language Models (VLMs) have shown strong generalization in medical imaging, pathology presents unique challenges due to ultra-high resolution, complex tissue structures, and nuanced clinical semantics. These factors make pathology VLMs prone to hallucinations, i.e., generating outputs inconsistent with visual evidence, which undermines clinical trust. Existing RAG approaches in this domain largely depend on text-based knowledge bases, limiting their ability to leverage diagnostic visual cues. To address this, we propose Patho-AgenticRAG, a multimodal RAG framework with a database built on page-level embeddings from authoritative pathology textbooks. Unlike traditional text-only retrieval systems, it supports joint text-image search, enabling direct retrieval of textbook pages that contain both the queried text and relevant visual cues, thus avoiding the loss of critical image-based information. Patho-AgenticRAG also supports reasoning, task decomposition, and multi-turn search interactions, improving accuracy in complex diagnostic scenarios. Experiments show that Patho-AgenticRAG significantly outperforms existing multimodal models in complex pathology tasks like multiple-choice diagnosis and visual question answering. Our project is available at the Patho-AgenticRAG repository: https://github.com/Wenchuan-Zhang/Patho-AgenticRAG.
        ]]></description>
    </item>
    <item>
        <title>Graph Embedding in the Graph Fractional Fourier Transform Domain</title>
        <link>https://arxiv.org/abs/2508.02383</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.02383v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Changjie Sheng, Zhichao Zhang, Wei Yao</dc:creator>
        <description><![CDATA[
            背景：传统谱嵌入方法的嵌入空间表达能力有限，难以全面捕捉不同变换域潜在结构特征。方法：使用图分数阶傅里叶变换将广义频率滤波嵌入（GEFFE）扩展到分数域，得到广义分数滤波嵌入（GEFRFE），利用图分数域滤波和特征向量分量的非线性组合，还引入基于搜索的优化和基于ResNet18的自适应学习两种策略确定分数阶。效果：在六个基准数据集上实验表明，GEFRFE能捕捉更丰富结构特征，显著提升分类性能，且计算复杂度与GEFFE相当。
            arXiv:2508.02383v1 Announce Type: new 
Abstract: Spectral graph embedding plays a critical role in graph representation learning by generating low-dimensional vector representations from graph spectral information. However, the embedding space of traditional spectral embedding methods often exhibit limited expressiveness, failing to exhaustively capture latent structural features across alternative transform domains. To address this issue, we use the graph fractional Fourier transform to extend the existing state-of-the-art generalized frequency filtering embedding (GEFFE) into fractional domains, giving birth to the generalized fractional filtering embedding (GEFRFE), which enhances embedding informativeness via the graph fractional domain. The GEFRFE leverages graph fractional domain filtering and a nonlinear composition of eigenvector components derived from a fractionalized graph Laplacian. To dynamically determine the fractional order, two parallel strategies are introduced: search-based optimization and a ResNet18-based adaptive learning. Extensive experiments on six benchmark datasets demonstrate that the GEFRFE captures richer structural features and significantly enhance classification performance. Notably, the proposed method retains computational complexity comparable to GEFFE approaches.
        ]]></description>
    </item>
    <item>
        <title>HGTS-Former: Hierarchical HyperGraph Transformer for Multivariate Time Series Analysis</title>
        <link>https://arxiv.org/abs/2508.02411</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.02411v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiao Wang, Hao Si, Fan Zhang, Xiaoya Zhou, Dengdi Sun, Wanli Lyu, Qingquan Yang, Jin Tang</dc:creator>
        <description><![CDATA[
            多元时间序列分析是人工智能领域关键研究课题，但因数据高维、动态及变量间复杂交互，分析复杂时间序列仍是难题。本文受超图强结构建模能力启发，提出基于超图的时间序列Transformer骨干网络HGTS - Former。先将多元时间序列信号归一化并嵌入为标记，用多头自注意力增强时间表征，构建分层超图聚合通道内时间模式和变量间细粒度关系，通过EdgeToNode模块转换超边为节点特征，用前馈网络增强输出特征。在两个任务和八个数据集上实验验证了其有效性。
            arXiv:2508.02411v1 Announce Type: new 
Abstract: Multivariate time series analysis has long been one of the key research topics in the field of artificial intelligence. However, analyzing complex time series data remains a challenging and unresolved problem due to its high dimensionality, dynamic nature, and complex interactions among variables. Inspired by the strong structural modeling capability of hypergraphs, this paper proposes a novel hypergraph-based time series transformer backbone network, termed HGTS-Former, to address the multivariate coupling in time series data. Specifically, given the multivariate time series signal, we first normalize and embed each patch into tokens. Then, we adopt the multi-head self-attention to enhance the temporal representation of each patch. The hierarchical hypergraphs are constructed to aggregate the temporal patterns within each channel and fine-grained relations between different variables. After that, we convert the hyperedge into node features through the EdgeToNode module and adopt the feed-forward network to further enhance the output features. Extensive experiments conducted on two multivariate time series tasks and eight datasets fully validated the effectiveness of our proposed HGTS-Former. The source code will be released on https://github.com/Event-AHU/Time_Series_Analysis.
        ]]></description>
    </item>
    <item>
        <title>Learning to Evolve: Bayesian-Guided Continual Knowledge Graph Embedding</title>
        <link>https://arxiv.org/abs/2508.02426</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.02426v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Linyu Li, Zhi Jin, Yuanpeng He, Dongming Jin, Yichi Zhang, Haoran Duan, Nyima Tash</dc:creator>
        <description><![CDATA[
            背景：现实中知识图谱不断演变，传统知识图谱嵌入（KGE）模型只适用于静态图谱，持续知识图谱嵌入（CKGE）面临‘灾难性遗忘’问题。方法：提出新CKGE模型BAKE，将每批新数据视为模型先验的贝叶斯更新，利用贝叶斯后验更新原理抵抗知识遗忘；还提出持续聚类方法，约束新旧知识演变差异。效果：在多数据集上实验表明，BAKE显著优于现有基线模型。
            arXiv:2508.02426v1 Announce Type: new 
Abstract: Since knowledge graphs (KG) will continue to evolve in real scenarios, traditional KGE models are only suitable for static knowledge graphs. Therefore, continual knowledge graph embedding (CKGE) has attracted the attention of researchers. Currently, a key challenge facing CKGE is that the model is prone to "catastrophic forgetting", resulting in the loss of previously learned knowledge. In order to effectively alleviate this problem, we propose a new CKGE model BAKE. First, we note that the Bayesian posterior update principle provides a natural continual learning strategy that is insensitive to data order and can theoretically effectively resist the forgetting of previous knowledge during data evolution. Different from the existing CKGE method, BAKE regards each batch of new data as a Bayesian update of the model prior. Under this framework, as long as the posterior distribution of the model is maintained, the model can better preserve the knowledge of early snapshots even after evolving through multiple time snapshots. Secondly, we propose a continual clustering method for CKGE, which further directly combats knowledge forgetting by constraining the evolution difference (or change amplitude) between new and old knowledge between different snapshots. We conduct extensive experiments on BAKE on multiple datasets, and the results show that BAKE significantly outperforms existing baseline models.
        ]]></description>
    </item>
    <item>
        <title>Contextual Graph Transformer: A Small Language Model for Enhanced Engineering Document Information Extraction</title>
        <link>https://arxiv.org/abs/2508.02532</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.02532v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Karan Reddy, Mayukha Pal</dc:creator>
        <description><![CDATA[
            背景：标准基于Transformer的语言模型处理复杂工程文档时存在困难，技术领域需有更强上下文和结构感知能力的专业模型。方法：提出上下文图Transformer（CGT），结合图神经网络和Transformer，为输入构建动态图，经GATv2Conv层学习局部结构，再用Transformer编码器捕获全局依赖，采用两阶段训练。效果：集成到RAG流程中，比GPT - 2准确率高24.7%，参数少62.4%，能更好适应技术语言。
            arXiv:2508.02532v1 Announce Type: new 
Abstract: Standard transformer-based language models, while powerful for general text, often struggle with the fine-grained syntax and entity relationships in complex technical, engineering documents. To address this, we propose the Contextual Graph Transformer (CGT), a hybrid neural architecture that combines Graph Neural Networks (GNNs) and Transformers for domain-specific question answering. CGT constructs a dynamic graph over input tokens using sequential, skip-gram, and semantic similarity edges, which is processed by GATv2Conv layers for local structure learning. These enriched embeddings are then passed to a Transformer encoder to capture global dependencies. Unlike generic large models, technical domains often require specialized language models with stronger contextualization and structure awareness. CGT offers a parameter-efficient solution for such use cases. Integrated into a Retrieval-Augmented Generation (RAG) pipeline, CGT outperforms baselines like GPT-2 and BERT, achieving 24.7% higher accuracy than GPT-2 with 62.4% fewer parameters. This gain stems from CGTs ability to jointly model structural token interactions and long-range semantic coherence. The model is trained from scratch using a two-phase approach: pretraining on general text followed by fine-tuning on domain-specific manuals. This highlights CGTs adaptability to technical language, enabling better grounding, entity tracking, and retrieval-augmented responses in real-world applications.
        ]]></description>
    </item>
    <item>
        <title>StructSynth: Leveraging LLMs for Structure-Aware Tabular Data Synthesis in Low-Data Regimes</title>
        <link>https://arxiv.org/abs/2508.02601</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.02601v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Siyi Liu, Yujia Zheng, Yongqi Zhang</dc:creator>
        <description><![CDATA[
            在专业领域的表格数据中，数据稀缺严重限制了机器学习应用。传统生成模型在低数据场景表现不佳，大语言模型常忽略表格数据的依赖结构。为此提出StructSynth框架，采用两阶段架构，先从数据中学习有向无环图（DAG），再用该结构引导大语言模型生成数据。实验表明，StructSynth生成的数据在结构完整性和下游应用效用上显著优于现有方法，在低数据场景能平衡隐私保护和统计保真。
            arXiv:2508.02601v1 Announce Type: new 
Abstract: The application of machine learning on tabular data in specialized domains is severely limited by data scarcity. While generative models offer a solution, traditional methods falter in low-data regimes, and recent Large Language Models (LLMs) often ignore the explicit dependency structure of tabular data, leading to low-fidelity synthetics. To address these limitations, we introduce StructSynth, a novel framework that integrates the generative power of LLMs with robust structural control. StructSynth employs a two-stage architecture. First, it performs explicit structure discovery to learn a Directed Acyclic Graph (DAG) from the available data. Second, this learned structure serves as a high-fidelity blueprint to steer the LLM's generation process, forcing it to adhere to the learned feature dependencies and thereby ensuring the generated data respects the underlying structure by design. Our extensive experiments demonstrate that StructSynth produces synthetic data with significantly higher structural integrity and downstream utility than state-of-the-art methods. It proves especially effective in challenging low-data scenarios, successfully navigating the trade-off between privacy preservation and statistical fidelity.
        ]]></description>
    </item>
    <item>
        <title>DeepKoopFormer: A Koopman Enhanced Transformer Based Architecture for Time Series Forecasting</title>
        <link>https://arxiv.org/abs/2508.02616</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.02616v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ali Forootani, Mohammad Khosravi, Masoud Barati</dc:creator>
        <description><![CDATA[
            时间序列预测在多领域至关重要，基于Transformer的模型虽在长程预测中表现出色，但存在可解释性差和噪声下不稳定问题。本文提出DeepKoopFormer，将Transformer的表征能力与Koopman算子理论结合，采用模块化编-传-解码器结构，在潜在空间通过谱约束线性Koopman算子学习时间动态，并施加结构保证以确保稳定性和可解释性。实验表明，其在多数据集上的准确性、抗噪性和长期预测稳定性均优于LSTM和基线Transformer模型。
            arXiv:2508.02616v1 Announce Type: new 
Abstract: Time series forecasting plays a vital role across scientific, industrial, and environmental domains, especially when dealing with high-dimensional and nonlinear systems. While Transformer-based models have recently achieved state-of-the-art performance in long-range forecasting, they often suffer from interpretability issues and instability in the presence of noise or dynamical uncertainty. In this work, we propose DeepKoopFormer, a principled forecasting framework that combines the representational power of Transformers with the theoretical rigor of Koopman operator theory. Our model features a modular encoder-propagator-decoder structure, where temporal dynamics are learned via a spectrally constrained, linear Koopman operator in a latent space. We impose structural guarantees-such as bounded spectral radius, Lyapunov based energy regularization, and orthogonal parameterization to ensure stability and interpretability. Comprehensive evaluations are conducted on both synthetic dynamical systems, real-world climate dataset (wind speed and surface pressure), financial time series (cryptocurrency), and electricity generation dataset using the Python package that is prepared for this purpose. Across all experiments, DeepKoopFormer consistently outperforms standard LSTM and baseline Transformer models in terms of accuracy, robustness to noise, and long-term forecasting stability. These results establish DeepKoopFormer as a flexible, interpretable, and robust framework for forecasting in high dimensional and dynamical settings.
        ]]></description>
    </item>
    <item>
        <title>Pointer: Linear-Complexity Long-Range Modeling without Pre-training</title>
        <link>https://arxiv.org/abs/2508.02631</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.02631v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zixi Li</dc:creator>
        <description><![CDATA[
            背景：长距离序列建模中标准注意力机制复杂度高。方法：提出Pointer架构，采用逐层指针链接，每层指针选择依赖上一层指针位置，通过指针链创建显式长距离连接，实现线性$O(NK)$复杂度，且无需预训练。效果：相比标准Transformer，在长序列上实现2 - 10倍加速；在最长2048个标记的复制任务中保持超95%准确率，还能学习到可解释的指针模式，揭示结构化依赖建模。
            arXiv:2508.02631v1 Announce Type: new 
Abstract: We introduce Pointer, a novel architecture that achieves linear $O(NK)$ complexity for long-range sequence modeling while maintaining superior performance without requiring pre-training. Unlike standard attention mechanisms that compute $O(N^2)$ pairwise interactions, our approach uses layer-wise pointer chaining where each layer's pointer selection depends on previous layer's pointer positions, creating explicit long-distance connections through pointer chains. We demonstrate that this architecture achieves $2$--$10\times$ speedup on long sequences compared to standard transformers, maintains $>95\%$ accuracy on copy tasks at distances up to 2048 tokens, and learns interpretable pointer patterns that reveal structured dependency modeling. Our experiments on efficiency benchmarks, long-range dependency tasks, and interpretability analysis show that Pointer offers a compelling alternative to attention mechanisms for scenarios requiring efficient long-range modeling without pre-training dependencies.
        ]]></description>
    </item>
    <item>
        <title>MedVLThinker: Simple Baselines for Multimodal Medical Reasoning</title>
        <link>https://arxiv.org/abs/2508.02669</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.02669v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiaoke Huang, Juncheng Wu, Hui Liu, Xianfeng Tang, Yuyin Zhou</dc:creator>
        <description><![CDATA[
            背景：大型推理模型虽可通过思维链推理实现“先思考后作答”，但缺乏构建以推理为中心的医学多模态大模型的公开可复现方案。方法：提出MedVLThinker，包括系统整理不同推理难度的纯文本和图文医学数据，采用监督微调（SFT）和基于答案正确性的可验证奖励强化学习（RLVR）两种训练范式。效果：实验表明RLVR显著优于SFT，纯文本推理数据训练效果更佳。7B模型创现有公开视觉问答基准新纪录，32B模型性能与GPT - 4o相当。
            arXiv:2508.02669v1 Announce Type: new 
Abstract: Large Reasoning Models (LRMs) have introduced a new paradigm in AI by enabling models to ``think before responding" via chain-of-thought reasoning. However, the absence of open and reproducible recipes for building reasoning-centric medical LMMs hinders community-wide research, analysis, and comparison. In this paper, we present MedVLThinker, a suite of simple yet strong baselines. Our fully open recipe consists of: (1) systematic data curation for both text-only and image-text medical data, filtered according to varying levels of reasoning difficulty, and (2) two training paradigms: Supervised Fine-Tuning (SFT) on distilled reasoning traces and Reinforcement Learning with Verifiable Rewards (RLVR) based on final answer correctness. Across extensive experiments on the Qwen2.5-VL model family (3B, 7B) and six medical QA benchmarks, we find that RLVR consistently and significantly outperforms SFT. Additionally, under the RLVR framework, a key, counter-intuitive finding is that training on our curated text-only reasoning data provides a more substantial performance boost than training on multimodal image-text data. Our best open 7B model, trained using the RLVR recipe on text-only data, establishes a new state-of-the-art on existing public VQA benchmarks, surpassing all previous open-source medical LMMs. Furthermore, scaling our model to 32B achieves performance on par with the proprietary GPT-4o. We release all curated data, models, and code to provide the community with a strong, open foundation for future research in multimodal medical reasoning.
        ]]></description>
    </item>
    <item>
        <title>Towards Bridging Review Sparsity in Recommendation with Textual Edge Graph Representation</title>
        <link>https://arxiv.org/abs/2508.01128</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01128v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Leyao Wang, Xutao Mao, Xuhui Zhan, Yuying Zhao, Bo Ni, Ryan A. Rossi, Nesreen K. Ahmed, Tyler Derr</dc:creator>
        <description><![CDATA[
            背景：文本评论能丰富推荐系统，但现实中评论稀疏，传统填补技术存在丢失语义或忽略结构依赖的问题。方法：提出TWISTER框架，将用户 - 项目交互表示为文本边缘图，构建线图视图并利用大语言模型作为图感知聚合器，为缺少评论的交互生成个性化评论。效果：在亚马逊和Goodreads数据集上实验表明，该方法优于传统基线，生成的评论质量更高，推荐性能也得到增强。
            arXiv:2508.01128v1 Announce Type: cross 
Abstract: Textual reviews enrich recommender systems with fine-grained preference signals and enhanced explainability. However, in real-world scenarios, users rarely leave reviews, resulting in severe sparsity that undermines the effectiveness of existing models. A natural solution is to impute or generate missing reviews to enrich the data. However, conventional imputation techniques -- such as matrix completion and LLM-based augmentation -- either lose contextualized semantics by embedding texts into vectors, or overlook structural dependencies among user-item interactions. To address these shortcomings, we propose TWISTER (ToWards Imputation on Sparsity with Textual Edge Graph Representation), a unified framework that imputes missing reviews by jointly modeling semantic and structural signals. Specifically, we represent user-item interactions as a Textual-Edge Graph (TEG), treating reviews as edge attributes. To capture relational context, we construct line-graph views and employ a large language model as a graph-aware aggregator. For each interaction lacking a textual review, our model aggregates the neighborhood's natural-language representations to generate a coherent and personalized review. Experiments on the Amazon and Goodreads datasets show that TWISTER consistently outperforms traditional numeric, graph-based, and LLM baselines, delivering higher-quality imputed reviews and, more importantly, enhanced recommendation performance. In summary, TWISTER generates reviews that are more helpful, authentic, and specific, while smoothing structural signals for improved recommendations.
        ]]></description>
    </item>
    <item>
        <title>DBAIOps: A Reasoning LLM-Enhanced Database Operation and Maintenance System using Knowledge Graphs</title>
        <link>https://arxiv.org/abs/2508.01136</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01136v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wei Zhou, Peng Sun, Xuanhe Zhou, Qianglei Zang, Ji Xu, Tieying Zhang, Guoliang Li, Fan Wu</dc:creator>
        <description><![CDATA[
            数据库系统运维对保障系统可用性和性能至关重要，但现有自动运维方法无法有效利用专家经验。为此提出DBAIOps系统，结合推理大语言模型与知识图谱实现类似数据库管理员的诊断。其方法包括：引入异构图模型表示诊断经验并半自动构建图；开发800多个可复用异常模型；提出两阶段图演化机制探索诊断路径。实验表明，在四个主流数据库系统上，该系统的根因和人工评估准确率分别比现有基线高34.85%和47.22%。
            arXiv:2508.01136v1 Announce Type: cross 
Abstract: The operation and maintenance (O&amp;M) of database systems is critical to ensuring system availability and performance, typically requiring expert experience (e.g., identifying metric-to-anomaly relations) for effective diagnosis and recovery. However, existing automatic database O&amp;M methods, including commercial products, cannot effectively utilize expert experience. On the one hand, rule-based methods only support basic O&amp;M tasks (e.g., metric-based anomaly detection), which are mostly numerical equations and cannot effectively incorporate literal O&amp;M experience (e.g., troubleshooting guidance in manuals). On the other hand, LLM-based methods, which retrieve fragmented information (e.g., standard documents + RAG), often generate inaccurate or generic results. To address these limitations, we present DBAIOps, a novel hybrid database O&amp;M system that combines reasoning LLMs with knowledge graphs to achieve DBA-style diagnosis. First, DBAIOps introduces a heterogeneous graph model for representing the diagnosis experience, and proposes a semi-automatic graph construction algorithm to build that graph from thousands of documents. Second, DBAIOps develops a collection of (800+) reusable anomaly models that identify both directly alerted metrics and implicitly correlated experience and metrics. Third, for each anomaly, DBAIOps proposes a two-stage graph evolution mechanism to explore relevant diagnosis paths and identify missing relations automatically. It then leverages a reasoning LLM (e.g., DeepSeek-R1) to infer root causes and generate clear diagnosis reports for both DBAs and common users. Our evaluation over four mainstream database systems (Oracle, MySQL, PostgreSQL, and DM8) demonstrates that DBAIOps outperforms state-of-the-art baselines, 34.85% and 47.22% higher in root cause and human evaluation accuracy, respectively.
        ]]></description>
    </item>
    <item>
        <title>Is Chain-of-Thought Reasoning of LLMs a Mirage? A Data Distribution Lens</title>
        <link>https://arxiv.org/abs/2508.01191</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01191v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chengshuai Zhao, Zhen Tan, Pingchuan Ma, Dawei Li, Bohan Jiang, Yancheng Wang, Yingzhen Yang, Huan Liu</dc:creator>
        <description><![CDATA[
            背景：思维链（CoT）提示可提升大语言模型（LLM）在多任务上的表现，但有研究认为其推理可能较表面。方法：从数据分布视角研究CoT推理，通过任务、长度和格式三个维度剖析，设计DataAlchemy环境从零训练LLM并在不同分布条件下探究。效果：发现CoT推理在超出训练分布时会失效，该研究加深了对CoT推理失败原因和时机的理解，凸显实现真正通用推理的挑战。
            arXiv:2508.01191v1 Announce Type: cross 
Abstract: Chain-of-Thought (CoT) prompting has been shown to improve Large Language Model (LLM) performance on various tasks. With this approach, LLMs appear to produce human-like reasoning steps before providing answers (a.k.a., CoT reasoning), which often leads to the perception that they engage in deliberate inferential processes. However, some initial findings suggest that CoT reasoning may be more superficial than it appears, motivating us to explore further. In this paper, we study CoT reasoning via a data distribution lens and investigate if CoT reasoning reflects a structured inductive bias learned from in-distribution data, allowing the model to conditionally generate reasoning paths that approximate those seen during training. Thus, its effectiveness is fundamentally bounded by the degree of distribution discrepancy between the training data and the test queries. With this lens, we dissect CoT reasoning via three dimensions: task, length, and format. To investigate each dimension, we design DataAlchemy, an isolated and controlled environment to train LLMs from scratch and systematically probe them under various distribution conditions. Our results reveal that CoT reasoning is a brittle mirage that vanishes when it is pushed beyond training distributions. This work offers a deeper understanding of why and when CoT reasoning fails, emphasizing the ongoing challenge of achieving genuine and generalizable reasoning.
        ]]></description>
    </item>
    <item>
        <title>MeshLLM: Empowering Large Language Models to Progressively Understand and Generate 3D Mesh</title>
        <link>https://arxiv.org/abs/2508.01242</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01242v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Shuangkang Fang, I-Chao Shen, Yufeng Wang, Yi-Hsuan Tsai, Yi Yang, Shuchang Zhou, Wenrui Ding, Takeo Igarashi, Ming-Hsuan Yang</dc:creator>
        <description><![CDATA[
            这是一篇关于多模态大模型处理结构化数据的研究。背景是现有方法在适配大语言模型时数据集规模有限、序列化丢失3D结构信息。方法上，提出Primitive - Mesh分解策略，将3D网格分解为有结构意义的子单元，构建1500k + 样本的大规模数据集；还提出从顶点推断面连接和局部网格组装训练策略。效果上，MeshLLM在网格生成质量和形状理解上优于LLaMA - Mesh，展现了处理文本序列化3D网格的潜力。
            arXiv:2508.01242v1 Announce Type: cross 
Abstract: We present MeshLLM, a novel framework that leverages large language models (LLMs) to understand and generate text-serialized 3D meshes. Our approach addresses key limitations in existing methods, including the limited dataset scale when catering to LLMs' token length and the loss of 3D structural information during mesh serialization. We introduce a Primitive-Mesh decomposition strategy, which divides 3D meshes into structurally meaningful subunits. This enables the creation of a large-scale dataset with 1500k+ samples, almost 50 times larger than previous methods, which aligns better with the LLM scaling law principles. Furthermore, we propose inferring face connectivity from vertices and local mesh assembly training strategies, significantly enhancing the LLMs' ability to capture mesh topology and spatial structures. Experiments show that MeshLLM outperforms the state-of-the-art LLaMA-Mesh in both mesh generation quality and shape understanding, highlighting its great potential in processing text-serialized 3D meshes.
        ]]></description>
    </item>
    <item>
        <title>AgentArmor: Enforcing Program Analysis on Agent Runtime Trace to Defend Against Prompt Injection</title>
        <link>https://arxiv.org/abs/2508.01249</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01249v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Peiran Wang, Yang Liu, Yunfei Lu, Yifeng Cai, Hongbo Chen, Qingyou Yang, Jie Zhang, Jue Hong, Ye Wu</dc:creator>
        <description><![CDATA[
            大语言模型（LLM）代理结合自然语言推理和外部工具执行来解决问题，但动态非透明行为带来安全风险，尤其是提示注入攻击。本文提出将代理运行时跟踪视为有可分析语义的结构化程序，提出AgentArmor框架。它将代理跟踪转换为基于图的中间表示，通过类型系统执行安全策略，含图构造器、属性注册表和类型系统三个组件。在AgentDojo基准测试中，TPR达95.75%，FPR仅3.66%，能检测提示注入漏洞并实施细粒度安全约束。
            arXiv:2508.01249v1 Announce Type: cross 
Abstract: Large Language Model (LLM) agents offer a powerful new paradigm for solving various problems by combining natural language reasoning with the execution of external tools. However, their dynamic and non-transparent behavior introduces critical security risks, particularly in the presence of prompt injection attacks. In this work, we propose a novel insight that treats the agent runtime traces as structured programs with analyzable semantics. Thus, we present AgentArmor, a program analysis framework that converts agent traces into graph intermediate representation-based structured program dependency representations (e.g., CFG, DFG, and PDG) and enforces security policies via a type system. AgentArmor consists of three key components: (1) a graph constructor that reconstructs the agent's working traces as graph-based intermediate representations with control flow and data flow described within; (2) a property registry that attaches security-relevant metadata of interacted tools & data, and (3) a type system that performs static inference and checking over the intermediate representation. By representing agent behavior as structured programs, AgentArmor enables program analysis over sensitive data flow, trust boundaries, and policy violations. We evaluate AgentArmor on the AgentDojo benchmark, the results show that AgentArmor can achieve 95.75% of TPR, with only 3.66% of FPR. Our results demonstrate AgentArmor's ability to detect prompt injection vulnerabilities and enforce fine-grained security constraints.
        ]]></description>
    </item>
    <item>
        <title>End-to-End Personalization: Unifying Recommender Systems with Large Language Models</title>
        <link>https://arxiv.org/abs/2508.01514</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01514v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Danial Ebrat, Tina Aminian, Sepideh Ahmadian, Luis Rueda</dc:creator>
        <description><![CDATA[
            推荐系统在提供个性化内容推荐时，提升个性化和可解释性存在挑战，尤其是在用户反馈有限或物品属性异构的场景中。本文提出结合图注意力网络（GATs）和大语言模型（LLMs）的混合推荐框架。先利用LLMs基于元数据生成有语义的用户和物品特征，作为二分图节点初始特征，用GAT协同过滤模型处理；引入混合损失函数提升排序准确性；用LLM对GAT生成的推荐结果重排序并给出解释。在基准数据集上，该模型优于基线模型，消融实验表明LLM嵌入和余弦相似度项对性能提升贡献大。
            arXiv:2508.01514v1 Announce Type: cross 
Abstract: Recommender systems are essential for guiding users through the vast and diverse landscape of digital content by delivering personalized and relevant suggestions. However, improving both personalization and interpretability remains a challenge, particularly in scenarios involving limited user feedback or heterogeneous item attributes. In this article, we propose a novel hybrid recommendation framework that combines Graph Attention Networks (GATs) with Large Language Models (LLMs) to address these limitations. LLMs are first used to enrich user and item representations by generating semantically meaningful profiles based on metadata such as titles, genres, and overviews. These enriched embeddings serve as initial node features in a user and movie bipartite graph, which is processed using a GAT based collaborative filtering model. To enhance ranking accuracy, we introduce a hybrid loss function that combines Bayesian Personalized Ranking (BPR), cosine similarity, and robust negative sampling. Post-processing involves reranking the GAT-generated recommendations using the LLM, which also generates natural-language justifications to improve transparency. We evaluated our model on benchmark datasets, including MovieLens 100k and 1M, where it consistently outperforms strong baselines. Ablation studies confirm that LLM-based embeddings and the cosine similarity term significantly contribute to performance gains. This work demonstrates the potential of integrating LLMs to improve both the accuracy and interpretability of recommender systems.
        ]]></description>
    </item>
    <item>
        <title>Agent-Based Feature Generation from Clinical Notes for Outcome Prediction</title>
        <link>https://arxiv.org/abs/2508.01956</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01956v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiayi Wang, Jacqueline Jil Vallon, Neil Panjwani, Xi Ling, Sushmita Vij, Sandy Srinivas, John Leppert, Mark K. Buyyounouski, Mohsen Bayati</dc:creator>
        <description><![CDATA[
            电子健康记录中的非结构化临床笔记能提升预测模型性能，但提取有意义特征颇具挑战。现有方法各有不足。为此，研究引入由大语言模型驱动的模块化多智能体系统SNOW，可自动从非结构化笔记生成结构化临床特征。在预测147名患者5年前列腺癌复发情况中，手动生成特征表现最佳（AUC - ROC：0.771），SNOW无临床专业知识辅助也达到0.761，显著优于基线特征（0.691）和其他自动特征生成方法，证明其可大规模复制专家级特征工程。
            arXiv:2508.01956v1 Announce Type: cross 
Abstract: Electronic health records (EHRs) contain rich unstructured clinical notes that could enhance predictive modeling, yet extracting meaningful features from these notes remains challenging. Current approaches range from labor-intensive manual clinician feature generation (CFG) to fully automated representational feature generation (RFG) that lack interpretability and clinical relevance. Here we introduce SNOW (Scalable Note-to-Outcome Workflow), a modular multi-agent system powered by large language models (LLMs) that autonomously generates structured clinical features from unstructured notes without human intervention. We evaluated SNOW against manual CFG, clinician-guided LLM approaches, and RFG methods for predicting 5-year prostate cancer recurrence in 147 patients from Stanford Healthcare. While manual CFG achieved the highest performance (AUC-ROC: 0.771), SNOW matched this performance (0.761) without requiring any clinical expertise, significantly outperforming both baseline features alone (0.691) and all RFG approaches. The clinician-guided LLM method also performed well (0.732) but still required expert input. SNOW's specialized agents handle feature discovery, extraction, validation, post-processing, and aggregation, creating interpretable features that capture complex clinical information typically accessible only through manual review. Our findings demonstrate that autonomous LLM systems can replicate expert-level feature engineering at scale, potentially transforming how clinical ML models leverage unstructured EHR data while maintaining the interpretability essential for clinical deployment.
        ]]></description>
    </item>
    <item>
        <title>REACT-KD: Region-Aware Cross-modal Topological Knowledge Distillation for Interpretable Medical Image Classification</title>
        <link>https://arxiv.org/abs/2508.02104</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.02104v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hongzhao Chen, Hexiao Ding, Yufeng Jiang, Jing Lan, Ka Chun Li, Gerald W. Y. Cheng, Sam Ng, Chi Lai Ho, Jing Cai, Liang-ting Lin, Jung Sun Yoo</dc:creator>
        <description><![CDATA[
            临床影像肿瘤分类面临模态质量不均、标注有限和缺乏结构化解剖指导等挑战。为此提出REACT - KD框架，将高保真多模态监督信息迁移至轻量级CT学生模型。采用双教师设计，从不同角度引导学生模型，通过逻辑蒸馏实现语义对齐、区域图蒸馏建模解剖拓扑。引入模态丢弃提升推理可靠性。以肝癌分期任务为例，该框架在内部PET/CT队列平均AUC达93.4%，外部CT测试不同剂量水平下AUC保持在76.6% - 81.5%，临床效益高。
            arXiv:2508.02104v1 Announce Type: cross 
Abstract: Reliable and interpretable tumor classification from clinical imaging remains a core challenge due to heterogeneous modality quality, limited annotations, and the lack of structured anatomical guidance. We introduce REACT-KD, a Region-Aware Cross-modal Topological Knowledge Distillation framework that transfers rich supervision from high-fidelity multi-modal sources into a lightweight CT-based student model. The framework uses a dual teacher design: one branch captures structure-function relationships using dual-tracer PET/CT, and the other models dose-aware features through synthetically degraded low-dose CT data. These branches jointly guide the student model through two complementary objectives. The first focuses on semantic alignment via logits distillation, while the second models anatomical topology using region graph distillation. A shared CBAM-3D module is employed to maintain consistent attention across modalities. To improve reliability for deployment, REACT-KD introduces modality dropout during training, allowing inference under partial or noisy inputs. The staging task for hepatocellular carcinoma (HCC) is conducted as a case study. REACT-KD achieves an average AUC of 93.4% on an internal PET/CT cohort and maintains 76.6% to 81.5% AUC across varying dose levels in external CT testing. Decision curve analysis shows that REACT-KD consistently provides the highest clinical benefit across decision thresholds, supporting its potential in real-world diagnostics. Code is available at https://github.com/Kinetics-JOJO/REACT-KD.
        ]]></description>
    </item>
    <item>
        <title>Test-time Prompt Intervention</title>
        <link>https://arxiv.org/abs/2508.02511</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.02511v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chenxu Yang, Qingyi Si, Mz Dai, Dingyu Yao, Mingyu Zheng, Minghui Chen, Zheng Lin, Weiping Wang</dc:creator>
        <description><![CDATA[
            在大语言模型领域，测试时计算虽提升了推理能力，但推理模型生成的思维链常冗余严重，根源在于其过度依赖结果奖励范式，过程奖励范式数据难大规模构建。为此提出Test-time Prompt Intervention（PI）框架，通过适时、恰当干预及干预后采样，动态引导和调控推理路径，将人类解题经验和认知科学原理融入推理过程。实验表明，PI能显著缩短思维链、减少幻觉，使推理更简洁可靠。
            arXiv:2508.02511v1 Announce Type: cross 
Abstract: Test-time compute has led to remarkable success in the large language model (LLM) community, particularly for complex tasks, where longer chains of thought (CoTs) are generated to enhance reasoning capabilities. However, growing evidence reveals that such reasoning models often produce CoTs plagued by excessive redundancy, including unnecessary verification steps and repetitive reasoning shifts. The root cause lies in post-training of them that overly rely on outcome reward paradigms, as the data of process reward paradigms, which regulate intermediate reasoning steps, is difficult to construct at scale. To address this, we propose PI, a novel framework for Test-time Prompt Intervention. PI provides an interface to dynamically guide and regulate reasoning paths during inference through timely (When module) and proper (How module) interventions and post-intervention sampling (Which module). This allows human problem-solving expertise and cognitive science principles to be seamlessly integrated into LLMs' reasoning processes, enhancing controllability and interpretability. Extensive experiments across multiple models and datasets demonstrate that PI significantly shortens CoTs while reducing hallucination, yielding more concise and reliable reasoning.
        ]]></description>
    </item>
    <item>
        <title>CAMA: Enhancing Mathematical Reasoning in Large Language Models with Causal Knowledge</title>
        <link>https://arxiv.org/abs/2508.02583</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.02583v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Lei Zan, Keli Zhang, Ruichu Cai, Lujia Pan</dc:creator>
        <description><![CDATA[
            大语言模型在复杂数学推理任务上存在困难，根源在于深层结构依赖。为此提出CAMA两阶段因果框架，为模型赋予显式、可复用的数学结构。学习阶段，结合模型先验与因果发现算法构建数学因果图，编码知识要点及因果依赖，并通过反馈迭代优化；推理阶段，根据问题和推理痕迹动态提取子图，引导模型推理。实验表明，CAMA显著提升模型在复杂数学问题上的表现，结构化引导优于非结构化方式。
            arXiv:2508.02583v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) have demonstrated strong performance across a wide range of tasks, yet they still struggle with complex mathematical reasoning, a challenge fundamentally rooted in deep structural dependencies. To address this challenge, we propose \textbf{CA}usal \textbf{MA}thematician (\textbf{CAMA}), a two-stage causal framework that equips LLMs with explicit, reusable mathematical structure. In the learning stage, CAMA first constructs the \textbf{M}athematical \textbf{C}ausal \textbf{G}raph (\textbf{MCG}), a high-level representation of solution strategies, by combining LLM priors with causal discovery algorithms applied to a corpus of question-solution pairs. The resulting MCG encodes essential knowledge points and their causal dependencies. To better align the graph with downstream reasoning tasks, CAMA further refines the MCG through iterative feedback derived from a selected subset of the question-solution pairs. In the reasoning stage, given a new question, CAMA dynamically extracts a task-relevant subgraph from the MCG, conditioned on both the question content and the LLM's intermediate reasoning trace. This subgraph, which encodes the most pertinent knowledge points and their causal dependencies, is then injected back into the LLM to guide its reasoning process. Empirical results on real-world datasets show that CAMA significantly improves LLM performance on challenging mathematical problems. Furthermore, our experiments demonstrate that structured guidance consistently outperforms unstructured alternatives, and that incorporating asymmetric causal relationships yields greater improvements than using symmetric associations alone.
        ]]></description>
    </item>
    <item>
        <title>HyCodePolicy: Hybrid Language Controllers for Multimodal Monitoring and Decision in Embodied Agents</title>
        <link>https://arxiv.org/abs/2508.02629</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.02629v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yibin Liu, Zhixuan Liang, Zanxin Chen, Tianxing Chen, Mengkang Hu, Wanxi Dong, Congsheng Xu, Zhaoming Han, Yusen Qin, Yao Mu</dc:creator>
        <description><![CDATA[
            背景：当前多模态大语言模型虽助力具身智能体代码策略生成，但多数系统缺乏有效机制来自适应监控策略执行和修复代码。方法：提出HyCodePolicy混合语言控制框架，将代码合成、几何基础、感知监控和迭代修复集成到具身智能体的闭环编程周期中，结合结构化执行轨迹与视觉语言模型感知反馈来推断失败原因并修复程序。效果：显著提高了机器人操作策略的鲁棒性和样本效率，为将多模态推理集成到自主决策流程提供可扩展策略。
            arXiv:2508.02629v1 Announce Type: cross 
Abstract: Recent advances in multimodal large language models (MLLMs) have enabled richer perceptual grounding for code policy generation in embodied agents. However, most existing systems lack effective mechanisms to adaptively monitor policy execution and repair codes during task completion. In this work, we introduce HyCodePolicy, a hybrid language-based control framework that systematically integrates code synthesis, geometric grounding, perceptual monitoring, and iterative repair into a closed-loop programming cycle for embodied agents. Technically, given a natural language instruction, our system first decomposes it into subgoals and generates an initial executable program grounded in object-centric geometric primitives. The program is then executed in simulation, while a vision-language model (VLM) observes selected checkpoints to detect and localize execution failures and infer failure reasons. By fusing structured execution traces capturing program-level events with VLM-based perceptual feedback, HyCodePolicy infers failure causes and repairs programs. This hybrid dual feedback mechanism enables self-correcting program synthesis with minimal human supervision. Our results demonstrate that HyCodePolicy significantly improves the robustness and sample efficiency of robot manipulation policies, offering a scalable strategy for integrating multimodal reasoning into autonomous decision-making pipelines.
        ]]></description>
    </item>
    <item>
        <title>Joint Generative Modeling of Grounded Scene Graphs and Images via Diffusion Models</title>
        <link>https://arxiv.org/abs/2401.01130</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2401.01130v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Bicheng Xu, Qi Yan, Renjie Liao, Lele Wang, Leonid Sigal</dc:creator>
        <description><![CDATA[
            这是一篇关于联合生成场景图和图像的研究。背景是处理高维多模态结构化数据的联合生成具有挑战性。方法上，采用分解方法，先生成场景图，再基于此生成图像；提出DiffuseSG模型联合建模异质节点和边属性，用图变换器作为去噪器，还引入基于IoU的正则化项。效果方面，在VG和COCO - Stuff数据集上，该模型在场景图生成上超越现有方法，在下游场景图补全和检测任务中也表现出色。
            arXiv:2401.01130v2 Announce Type: replace 
Abstract: We introduce a framework for joint grounded scene graph - image generation, a challenging task involving high-dimensional, multi-modal structured data. To effectively model this complex joint distribution, we adopt a factorized approach: first generating a grounded scene graph, followed by image generation conditioned on the generated grounded scene graph. While conditional image generation has been widely explored in the literature, our primary focus is on the generation of grounded scene graphs from noise, which provides efficient and interpretable control over the image generation process. This task requires generating plausible grounded scene graphs with heterogeneous attributes for both nodes (objects) and edges (relations among objects), encompassing continuous attributes (e.g., object bounding boxes) and discrete attributes (e.g., object and relation categories). To address this challenge, we introduce DiffuseSG, a novel diffusion model that jointly models the heterogeneous node and edge attributes. We explore different encoding strategies to effectively handle the categorical data. Leveraging a graph transformer as the denoiser, DiffuseSG progressively refines grounded scene graph representations in a continuous space before discretizing them to generate structured outputs. Additionally, we introduce an IoU-based regularization term to enhance empirical performance. Our model outperforms existing methods in grounded scene graph generation on the VG and COCO-Stuff datasets, excelling in both standard and newly introduced metrics that more accurately capture the task's complexity. Furthermore, we demonstrate the broader applicability of DiffuseSG in two important downstream tasks: 1) achieving superior results in a range of grounded scene graph completion tasks, and 2) enhancing grounded scene graph detection models by leveraging additional training samples generated by DiffuseSG.
        ]]></description>
    </item>
    <item>
        <title>THREAD: Thinking Deeper with Recursive Spawning</title>
        <link>https://arxiv.org/abs/2405.17402</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2405.17402v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Philip Schroeder, Nathaniel Morgan, Hongyin Luo, James Glass</dc:creator>
        <description><![CDATA[
            背景：大语言模型在长且复杂上下文处理上存在困难。方法：提出Thinking Recursively and Dynamically (ThReaD)，将模型生成视为执行线程，可根据上下文完成或生成新线程，把工作分配给子线程，在任务解决和问答场景中递归分解问题。效果：在多种基准测试中，用少样本学习方法实现的THREAD，在GPT - 4和GPT - 3.5上达最优性能；在小模型上比现有框架绝对得分高10% - 50%。
            arXiv:2405.17402v2 Announce Type: replace 
Abstract: Large language models (LLMs) have shown impressive capabilities across diverse settings, but still struggle as the length and complexity of the context increases. To address this challenge, we propose Thinking Recursively and Dynamically (ThReaD). THREAD frames model generation as a thread of execution that, based on the context, can run to completion or dynamically spawn new threads. By spawning, threads can offload work (e.g., thinking, retrieving information) to child threads, which only return tokens needed for the parent thread to do its work. In effect, this enables the model to adapt, as needed, the amount of intermediate work used to produce tokens. We apply THREAD in the settings of LLM task solving and question answering, where the dynamic threading allows the model to recursively decompose the given task or question into progressively simpler sub-problems that can be solved by separate child threads. We test THREAD, implemented using a few-shot learning approach, on diverse benchmarks for agent tasks and data-grounded question answering. THREAD achieves state-of-the-art performance with GPT-4 and GPT-3.5 on these benchmarks, including ALFWorld, TextCraft, and WebShop, along with two new benchmarks, DataCommons QA and MIMIC-III ICU QA. In addition, THREAD outperforms existing frameworks by 10% to 50% absolute points with smaller models, including Llama-3-8b and CodeLlama-7b.
        ]]></description>
    </item>
    <item>
        <title>InstructLayout: Instruction-Driven 2D and 3D Layout Synthesis with Semantic Graph Prior</title>
        <link>https://arxiv.org/abs/2407.07580</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2407.07580v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chenguo Lin, Yuchen Lin, Panwang Pan, Xuanyang Zhang, Yadong Mu</dc:creator>
        <description><![CDATA[
            背景：现有2D和3D布局合成系统理解自然语言指令时，因隐式建模物体联合分布和表达物体关系，限制了生成的可控性。方法：提出InstructLayout框架，集成语义图先验和布局解码器，语义图先验可同时学习布局外观和物体分布；还利用大语言和多模态模型从公共网络资源整理出两个高质量布局 - 指令对数据集用于基准测试。效果：在2D和3D布局合成任务中大幅超越现有最优方法，消融实验证实关键设计组件有效。
            arXiv:2407.07580v3 Announce Type: replace 
Abstract: Comprehending natural language instructions is a charming property for both 2D and 3D layout synthesis systems. Existing methods implicitly model object joint distributions and express object relations, hindering generation's controllability. We introduce InstructLayout, a novel generative framework that integrates a semantic graph prior and a layout decoder to improve controllability and fidelity for 2D and 3D layout synthesis. The proposed semantic graph prior learns layout appearances and object distributions simultaneously, demonstrating versatility across various downstream tasks in a zero-shot manner. To facilitate the benchmarking for text-driven 2D and 3D scene synthesis, we respectively curate two high-quality datasets of layout-instruction pairs from public Internet resources with large language and multimodal models. Extensive experimental results reveal that the proposed method outperforms existing state-of-the-art approaches by a large margin in both 2D and 3D layout synthesis tasks. Thorough ablation studies confirm the efficacy of crucial design components.
        ]]></description>
    </item>
    <item>
        <title>Path-LLM: A Shortest-Path-based LLM Learning for Unified Graph Representation</title>
        <link>https://arxiv.org/abs/2408.05456</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2408.05456v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wenbo Shang, Xuliang Zhu, Xin Huang</dc:creator>
        <description><![CDATA[
            这是一篇关于统一图表示学习的论文。现有基于图神经网络和语言模型的研究存在训练需求大、泛化性差或语义特征浅等问题。为此提出Path - LLM模型，其框架包含四项技术，如长到短最短路径选择、路径文本化等，将文本输入自监督大语言模型训练以学习图表示。理论分析了算法复杂度，实验表明，该模型在节点分类、边验证和关键字搜索等任务上优于现有方法，在百万级图上比WalkLM节省超90%训练路径，运行速度最多快35倍。
            arXiv:2408.05456v2 Announce Type: replace 
Abstract: Unified graph representation learning aims to generate node embeddings, which can be applied to multiple downstream applications of graph analytics. However, existing studies based on graph neural networks and language models either suffer from the limitations of numerous training needs toward specific downstream predictions, poor generalization, or shallow semantic features. In this work, we propose a novel Path-LLM model to efficiently learn unified graph representation, which leverages a powerful large language model (LLM) to incorporate our proposed path features. Our Path-LLM framework consists of four well-designed techniques. First, we develop a new mechanism of long-to-short shortest path (L2SP) selection, which can cover key connections between different dense groups. An in-depth analysis and comparison of different path selections is conducted to justify the rationale behind our designed L2SP method. Next, we design path textualization to obtain L2SP-based training texts with key phrase selection from node text attributes. We then feed the texts into a self-supervised LLM training process to align next node/edge generation in L2SP with next token generation in causal language modeling for graph representation learning and finally extract the unified graph embeddings. We theoretically analyze the algorithm complexity of our Path-LLM approach. Extensive experiments on large-scale graph benchmarks validate the superiority of Path-LLM against state-of-the-art methods WalkLM, GraphGPT, OFA, and GraphTranslator on two classical graph learning tasks (node classification and edge validation) and one NP-hard graph query processing task (keyword search). Compared with WalkLM, our approach saves more than 90% of training paths on millions-scale graphs and runs at most 35x faster.
        ]]></description>
    </item>
    <item>
        <title>FARM: Functional Group-Aware Representations for Small Molecules</title>
        <link>https://arxiv.org/abs/2410.02082</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.02082v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Thao Nguyen, Kuan-Hao Huang, Ge Liu, Martin D. Burke, Ying Diao, Heng Ji</dc:creator>
        <description><![CDATA[
            该研究背景是需弥合SMILES、自然语言和分子图间的差距。为此提出小分子功能团感知表示模型FARM，方法上采用功能团感知标记化，将功能团信息融入SMILES；从原子级特征和分子拓扑结构两视角表示分子，并利用对比学习统一两种表示。效果上，在MoleculeNet数据集13个任务中的11个上达到了最先进水平，展现出强大的迁移学习能力，为药物发现等研究提供了新思路。
            arXiv:2410.02082v3 Announce Type: replace 
Abstract: We introduce Functional Group-Aware Representations for Small Molecules (FARM), a novel foundation model designed to bridge the gap between SMILES, natural language, and molecular graphs. The key innovation of FARM lies in its functional group-aware tokenization, which directly incorporates functional group information into SMILES, enriching SMILES with detailed chemical context. For example, instead of using "O" to represent all oxygen atoms, we use specific tokens like "O_ketone" and "O_hydroxyl" to differentiate oxygen atoms belonging to distinct functional groups. This tokenization expands the chemical lexicon, effectively bridging the gap between SMILES and natural language in terms of vocabulary size, ultimately enhancing the model's ability to predict molecular properties. FARM also represents molecules from two perspectives: by (1) using masked language modeling to capture atom-level features and (2) employing graph neural networks to encode the whole molecule topology. FARM leverages contrastive learning to aligns these two views of representations into a unified molecular embedding. We rigorously evaluate FARM on the MoleculeNet dataset, where it achieves state-of-the-art performance on 11 out of 13 tasks. These results highlight FARM's potential to improve molecular representation learning and demonstrate its strong transfer learning capabilities, paving the way for promising applications in drug discovery and pharmaceutical research.
        ]]></description>
    </item>
    <item>
        <title>Machines and Mathematical Mutations: Using GNNs to Characterize Quiver Mutation Classes</title>
        <link>https://arxiv.org/abs/2411.07467</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2411.07467v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jesse He, Helen Jenne, Herman Chau, Davis Brown, Mark Raugas, Sara Billey, Henry Kvinge</dc:creator>
        <description><![CDATA[
            背景：机器学习在数学研究中价值渐显，箭图突变是簇代数理论核心操作，突变等价问题受关注。方法：本文用图神经网络和AI可解释性技术，研究箭图突变，独立探索$	ilde{D}$型箭图的突变等价准则。效果：模型即便未经明确训练，也能在隐藏表示中捕捉结构，重构$D$型已知准则，表明现代机器学习模型能从数学数据中学习抽象规则。 
            arXiv:2411.07467v3 Announce Type: replace 
Abstract: Machine learning is becoming an increasingly valuable tool in mathematics, enabling one to identify subtle patterns across collections of examples so vast that they would be impossible for a single researcher to feasibly review and analyze. In this work, we use graph neural networks to investigate \emph{quiver mutation} -- an operation that transforms one quiver (or directed multigraph) into another -- which is central to the theory of cluster algebras with deep connections to geometry, topology, and physics. In the study of cluster algebras, the question of \emph{mutation equivalence} is of fundamental concern: given two quivers, can one efficiently determine if one quiver can be transformed into the other through a sequence of mutations? In this paper, we use graph neural networks and AI explainability techniques to independently discover mutation equivalence criteria for quivers of type $\tilde{D}$. Along the way, we also show that even without explicit training to do so, our model captures structure within its hidden representation that allows us to reconstruct known criteria from type $D$, adding to the growing evidence that modern machine learning models are capable of learning abstract and parsimonious rules from mathematical data.
        ]]></description>
    </item>
    <item>
        <title>AtomThink: Multimodal Slow Thinking with Atomic Step Reasoning</title>
        <link>https://arxiv.org/abs/2411.11930</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2411.11930v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kun Xiang, Zhili Liu, Terry Jingchen Zhang, Yinya Huang, Yunshuang Nie, Kaixin Cai, Yiyang Yin, Runhui Huang, Hanhui Li, Yihan Zeng, Yu-Jie Yuan, Jianhua Han, Lanqing Hong, Hang Xu, Xiaodan Liang</dc:creator>
        <description><![CDATA[
            背景：多模态数学推理任务具有挑战性。方法：将‘慢思考’概念融入多模态大语言模型，提出自结构化思维链（SCoT）范式，包含最小语义原子步骤；设计AtomThink框架，有数据引擎、监督微调、策略引导多轮推理、原子能力指标四个关键模块。效果：显著提升基线模型性能，在MathVista和MathVerse上平均准确率提高超10%，较先进结构化CoT方法，准确率更高，数据利用率提升5倍，推理效率提高85.3%。
            arXiv:2411.11930v4 Announce Type: replace 
Abstract: In this paper, we address the challenging task of multimodal mathematical reasoning by incorporating the notion of ``slow thinking'' into multimodal large language models (MLLMs). Our core idea is that models can learn to adaptively use different levels of reasoning to tackle questions of different complexity. We propose a novel paradigm of Self-structured Chain of Thought (SCoT), which comprises of minimal semantic atomic steps. Different from existing methods that rely on structured templates or free-form paradigms, our method can not only generate cognitive CoT structures for various complex tasks but also mitigates the phenomena of overthinking for easier tasks. To introduce structured reasoning into visual cognition, we further design a novel AtomThink framework with four key modules, including (i) a data engine to generate high-quality multimodal reasoning paths; (ii) a supervised fine-tuning (SFT) process with serialized inference data; (iii) a policy-guided multi-turn inference method; and (iv) an atomic capability metric to evaluate the single step utilization rate. We conduct extensive experiments to show that the proposed AtomThink significantly improves the performance of baseline MLLMs, achieving more than 10\% average accuracy gains on MathVista and MathVerse. Compared to state-of-the-art structured CoT approaches, our method not only achieves higher accuracy but also improves data utilization by 5 times and boosts inference efficiency by 85.3\%. Our code is now public available in https://github.com/Quinn777/AtomThink.
        ]]></description>
    </item>
    <item>
        <title>Multimodal 3D Reasoning Segmentation with Complex Scenes</title>
        <link>https://arxiv.org/abs/2411.13927</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2411.13927v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xueying Jiang, Lewei Lu, Ling Shao, Shijian Lu</dc:creator>
        <description><![CDATA[
            多模态学习推动了3D场景理解研究，但现有研究存在缺乏推理能力、忽视复杂场景等问题。为此，本文提出3D推理分割任务，可生成3D分割掩码和详细文本解释。创建了大规模高质量基准ReasonSeg3D，设计了适用于3D场景理解的推理网络MORE3D，它能学习3D关系解释，捕捉物体空间信息并推理文本输出。实验表明，MORE3D在复杂多物体3D场景的推理和分割上表现出色，ReasonSeg3D为后续研究提供了平台。
            arXiv:2411.13927v4 Announce Type: replace 
Abstract: The recent development in multimodal learning has greatly advanced the research in 3D scene understanding in various real-world tasks such as embodied AI. However, most existing studies are facing two common challenges: 1) they are short of reasoning ability for interaction and interpretation of human intentions and 2) they focus on scenarios with single-category objects and over-simplified textual descriptions and neglect multi-object scenarios with complicated spatial relations among objects. We address the above challenges by proposing a 3D reasoning segmentation task for reasoning segmentation with multiple objects in scenes. The task allows producing 3D segmentation masks and detailed textual explanations as enriched by 3D spatial relations among objects. To this end, we create ReasonSeg3D, a large-scale and high-quality benchmark that integrates 3D segmentation masks and 3D spatial relations with generated question-answer pairs. In addition, we design MORE3D, a novel 3D reasoning network that works with queries of multiple objects and is tailored for 3D scene understanding. MORE3D learns detailed explanations on 3D relations and employs them to capture spatial information of objects and reason textual outputs. Extensive experiments show that MORE3D excels in reasoning and segmenting complex multi-object 3D scenes. In addition, the created ReasonSeg3D offers a valuable platform for future exploration of 3D reasoning segmentation. The data and code will be released.
        ]]></description>
    </item>
    <item>
        <title>KnowRA: Knowledge Retrieval Augmented Method for Document-level Relation Extraction with Comprehensive Reasoning Abilities</title>
        <link>https://arxiv.org/abs/2501.00571</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2501.00571v5</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chengcheng Mai, Yuxiang Wang, Ziyu Gong, Hanxiang Wang, Yihua Huang</dc:creator>
        <description><![CDATA[
            文档级关系抽取（Doc - RE）需像人类一样具备更全面的推理能力，但现有方法多聚焦单一推理能力，缺乏利用外部知识进行长文档综合推理的能力。为此，提出知识检索增强方法KnowRA。该方法先构建文档图进行语义编码，集成共指消解模型增强推理能力；再通过检索外部知识库扩展为文档知识图，并过滤无关知识；最后提出轴注意力机制实现跨句逻辑推理。实验表明，该方法在两个数据集上优于现有基线模型。
            arXiv:2501.00571v5 Announce Type: replace 
Abstract: Document-level relation extraction (Doc-RE) aims to extract relations between entities across multiple sentences. Therefore, Doc-RE requires more comprehensive reasoning abilities like humans, involving complex cross-sentence interactions between entities, contexts, and external general knowledge, compared to the sentence-level RE. However, most existing Doc-RE methods focus on optimizing single reasoning ability, but lack the ability to utilize external knowledge for comprehensive reasoning on long documents. To solve these problems, a knowledge retrieval augmented method, named KnowRA, was proposed with comprehensive reasoning to autonomously determine whether to accept external knowledge to assist DocRE. Firstly, we constructed a document graph for semantic encoding and integrated the co-reference resolution model to augment the co-reference reasoning ability. Then, we expanded the document graph into a document knowledge graph by retrieving the external knowledge base for common-sense reasoning and a novel knowledge filtration method was presented to filter out irrelevant knowledge. Finally, we proposed the axis attention mechanism to build direct and indirect associations with intermediary entities for achieving cross-sentence logical reasoning. Extensive experiments conducted on two datasets verified the effectiveness of our method compared to the state-of-the-art baselines. Our code is available at https://anonymous.4open.science/r/KnowRA.
        ]]></description>
    </item>
    <item>
        <title>Rethinking Table Instruction Tuning</title>
        <link>https://arxiv.org/abs/2501.14693</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2501.14693v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Naihao Deng, Rada Mihalcea</dc:creator>
        <description><![CDATA[
            背景：现有表格理解研究聚焦于指令微调大语言模型，但忽视超参数选择影响，且缺乏对域外表格理解能力和通用能力的全面评估。方法：评估现有表格大语言模型相关能力，经系统分析发现学习率等超参数影响显著，小学习率和少训练实例可增强表格理解并保留通用能力，据此推出TAMA。效果：TAMA在表格任务上表现比肩或超越GPT - 3.5和GPT - 4，保持强域外泛化和通用能力，可降低数据标注成本。
            arXiv:2501.14693v4 Announce Type: replace 
Abstract: Recent advances in table understanding have focused on instruction-tuning large language models (LLMs) for table-related tasks. However, existing research has overlooked the impact of hyperparameter choices, and also lacks a comprehensive evaluation of the out-of-domain table understanding ability and the general capabilities of these table LLMs. In this paper, we evaluate these abilities in existing table LLMs, and find significant declines in both out-of-domain table understanding and general capabilities as compared to their base models. Through systematic analysis, we show that hyperparameters, such as learning rate, can significantly influence both table-specific and general capabilities. Contrary to the previous table instruction-tuning work, we demonstrate that smaller learning rates and fewer training instances can enhance table understanding while preserving general capabilities. Based on our findings, we introduce TAMA, a TAble LLM instruction-tuned from LLaMA 3.1 8B Instruct, which achieves performance on par with, or surpassing GPT-3.5 and GPT-4 on table tasks, while maintaining strong out-of-domain generalization and general capabilities. Our findings highlight the potential for reduced data annotation costs and more efficient model development through careful hyperparameter selection. We open-source the project and our models.
        ]]></description>
    </item>
    <item>
        <title>Emergent Response Planning in LLMs</title>
        <link>https://arxiv.org/abs/2502.06258</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.06258v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhichen Dong, Zhanhui Zhou, Zhixuan Liu, Chao Yang, Chaochao Lu</dc:creator>
        <description><![CDATA[
            背景：大语言模型虽按预测下一标记训练，但其隐藏表征或有超出下一标记的规划行为。方法：通过简单探测，发现大语言模型提示表征能编码整个响应的全局属性，如结构、内容和行为属性。还探究其规划能力随模型规模的变化及生成过程中的演变。效果：研究表明大语言模型在隐藏表征中提前规划未来，为提高透明度和生成控制提供潜在应用。
            arXiv:2502.06258v3 Announce Type: replace 
Abstract: In this work, we argue that large language models (LLMs), though trained to predict only the next token, exhibit emergent planning behaviors: $\textbf{their hidden representations encode future outputs beyond the next token}$. Through simple probing, we demonstrate that LLM prompt representations encode global attributes of their entire responses, including $\textit{structure attributes}$ (e.g., response length, reasoning steps), $\textit{content attributes}$ (e.g., character choices in storywriting, multiple-choice answers at the end of response), and $\textit{behavior attributes}$ (e.g., answer confidence, factual consistency). In addition to identifying response planning, we explore how it scales with model size across tasks and how it evolves during generation. The findings that LLMs plan ahead for the future in their hidden representations suggest potential applications for improving transparency and generation control.
        ]]></description>
    </item>
    <item>
        <title>Towards Question Answering over Large Semi-structured Tables</title>
        <link>https://arxiv.org/abs/2502.13422</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.13422v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuxiang Wang, Junhao Gan, Jianzhong Qi</dc:creator>
        <description><![CDATA[
            背景：半结构化表格形式的网络信息盛行，表问答（TableQA）受关注，但大表格的表问答仍是难题，现有方法有程序生成和执行错误且难以保证分解质量。方法：提出TaDRe模型，结合表分解前后的优化来确保表分解质量。效果：构建两个新的大表表问答基准进行评估，在新基准和公开基准上的大量实验表明，TaDRe在大表表问答任务上达到了最先进的性能。
            arXiv:2502.13422v2 Announce Type: replace 
Abstract: Table Question Answering (TableQA) attracts strong interests due to the prevalence of web information presented in the form of semi-structured tables. Despite many efforts, TableQA over large tables remains an open challenge. This is because large tables may overwhelm models that try to comprehend them in full to locate question answers. Recent studies reduce input table size by decomposing tables into smaller, question-relevant sub-tables via generating programs to parse the tables. However, such solutions are subject to program generation and execution errors and are difficult to ensure decomposition quality. To address this issue, we propose TaDRe, a TableQA model that incorporates both pre- and post-table decomposition refinements to ensure table decomposition quality, hence achieving highly accurate TableQA results. To evaluate TaDRe, we construct two new large-table TableQA benchmarks via LLM-driven table expansion and QA pair generation. Extensive experiments on both the new and public benchmarks show that TaDRe achieves state-of-the-art performance on large-table TableQA tasks.
        ]]></description>
    </item>
    <item>
        <title>Enhancing Time Series Forecasting via Multi-Level Text Alignment with LLMs</title>
        <link>https://arxiv.org/abs/2504.07360</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.07360v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Taibiao Zhao, Xiaobing Chen, Mingxuan Sun</dc:creator>
        <description><![CDATA[
            将大语言模型应用于时间序列预测存在挑战，因时间序列数据连续，而大语言模型处理离散标记，现有将时间序列数据转化为文本形式的方法难以得到有意义、可解释的结果。本文提出多级别文本对齐框架，将时间序列分解为趋势、季节和残差分量，转化为特定分量文本表示，引入多级别对齐机制，使特定分量嵌入与预训练词标记对齐。实验表明，该方法在多个数据集上准确率超现有模型，且有良好可解释性。
            arXiv:2504.07360v2 Announce Type: replace 
Abstract: The adaptation of large language models (LLMs) to time series forecasting poses unique challenges, as time series data is continuous in nature, while LLMs operate on discrete tokens. Despite the success of LLMs in natural language processing (NLP) and other structured domains, aligning time series data with language-based representations while maintaining both predictive accuracy and interpretability remains a significant hurdle. Existing methods have attempted to reprogram time series data into text-based forms, but these often fall short in delivering meaningful, interpretable results. In this paper, we propose a multi-level text alignment framework for time series forecasting using LLMs that not only improves prediction accuracy but also enhances the interpretability of time series representations. Our method decomposes time series into trend, seasonal, and residual components, which are then reprogrammed into component-specific text representations. We introduce a multi-level alignment mechanism, where component-specific embeddings are aligned with pre-trained word tokens, enabling more interpretable forecasts. Experiments on multiple datasets demonstrate that our method outperforms state-of-the-art models in accuracy while providing good interpretability.
        ]]></description>
    </item>
    <item>
        <title>Between Linear and Sinusoidal: Rethinking the Time Encoder in Dynamic Graph Learning</title>
        <link>https://arxiv.org/abs/2504.08129</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.08129v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hsing-Huan Chung, Shravan Chaudhari, Xing Han, Yoav Wald, Suchi Saria, Joydeep Ghosh</dc:creator>
        <description><![CDATA[
            动态图学习对涉及时间网络的应用至关重要，现有基于注意力的模型多采用正弦时间编码器捕捉边事件间的时间依赖，但正弦编码会因多对一特性丢失时间信息且需高维编码。本文研究更简单的线性时间编码器，它能避免信息丢失、减少对高维编码的需求。自注意力机制可从线性编码中有效学习计算事件时间跨度、提取时间模式。实验表明，线性编码器大多情况下能提升模型性能，还能显著节省参数，如二维线性编码器让TGAT节省43%参数且在五个数据集上平均精度更高。
            arXiv:2504.08129v2 Announce Type: replace 
Abstract: Dynamic graph learning is essential for applications involving temporal networks and requires effective modeling of temporal relationships. Seminal attention-based models like TGAT and DyGFormer rely on sinusoidal time encoders to capture temporal dependencies between edge events. Prior work justified sinusoidal encodings because their inner products depend on the time spans between events, which are crucial features for modeling inter-event relations. However, sinusoidal encodings inherently lose temporal information due to their many-to-one nature and therefore require high dimensions. In this paper, we rigorously study a simpler alternative: the linear time encoder, which avoids temporal information loss caused by sinusoidal functions and reduces the need for high-dimensional time encoders. We show that the self-attention mechanism can effectively learn to compute time spans between events from linear time encodings and extract relevant temporal patterns. Through extensive experiments on six dynamic graph datasets, we demonstrate that the linear time encoder improves the performance of TGAT and DyGFormer in most cases. Moreover, the linear time encoder can lead to significant savings in model parameters with minimal performance loss. For example, compared to a 100-dimensional sinusoidal time encoder, TGAT with a 2-dimensional linear time encoder saves 43% of parameters and achieves higher average precision on five datasets. While both encoders can be used simultaneously, our study highlights the often-overlooked advantages of linear time features in modern dynamic graph models. These findings can positively impact the design choices of various dynamic graph learning architectures and eventually benefit temporal network applications such as recommender systems, communication networks, and traffic forecasting.
        ]]></description>
    </item>
    <item>
        <title>LayoutCoT: Unleashing the Deep Reasoning Potential of Large Language Models for Layout Generation</title>
        <link>https://arxiv.org/abs/2504.10829</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.10829v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hengyu Shi, Junhao Su, Junfeng Luo, Jialin Gao</dc:creator>
        <description><![CDATA[
            背景：现有条件布局生成方法存在需大量训练数据、推理能力有限等问题。方法：提出LayoutCoT，结合检索增强生成（RAG）和思维链（CoT）技术，将布局表示转换为适合大语言模型处理的格式，用布局感知RAG检索并生成粗布局，再通过CoT推理模块迭代细化。效果：在五个公共数据集上实验，无需训练或微调就达到了最先进水平，CoT推理模块让普通大语言模型超越专业深度推理模型。
            arXiv:2504.10829v2 Announce Type: replace 
Abstract: Conditional layout generation aims to automatically generate visually appealing and semantically coherent layouts from user-defined constraints. While recent methods based on generative models have shown promising results, they typically require substantial amounts of training data or extensive fine-tuning, limiting their versatility and practical applicability. Alternatively, some training-free approaches leveraging in-context learning with Large Language Models (LLMs) have emerged, but they often suffer from limited reasoning capabilities and overly simplistic ranking mechanisms, which restrict their ability to generate consistently high-quality layouts. To this end, we propose LayoutCoT, a novel approach that leverages the reasoning capabilities of LLMs through a combination of Retrieval-Augmented Generation (RAG) and Chain-of-Thought (CoT) techniques. Specifically, LayoutCoT transforms layout representations into a standardized serialized format suitable for processing by LLMs. A Layout-aware RAG is used to facilitate effective retrieval and generate a coarse layout by LLMs. This preliminary layout, together with the selected exemplars, is then fed into a specially designed CoT reasoning module for iterative refinement, significantly enhancing both semantic coherence and visual quality. We conduct extensive experiments on five public datasets spanning three conditional layout generation tasks. Experimental results demonstrate that LayoutCoT achieves state-of-the-art performance without requiring training or fine-tuning. Notably, our CoT reasoning module enables standard LLMs, even those without explicit deep reasoning abilities, to outperform specialized deep-reasoning models such as deepseek-R1, highlighting the potential of our approach in unleashing the deep reasoning capabilities of LLMs for layout generation tasks.
        ]]></description>
    </item>
    <item>
        <title>Thought Manipulation: External Thought Can Be Efficient for Large Reasoning Models</title>
        <link>https://arxiv.org/abs/2504.13626</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.13626v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yule Liu, Jingyi Zheng, Zhen Sun, Zifan Peng, Wenhan Dong, Zeyang Sha, Shiwen Cui, Weiqiang Wang, Xinlei He</dc:creator>
        <description><![CDATA[
            大推理模型（LRMs）虽可通过扩展测试时计算提升推理能力，但存在“过度思考”问题，产生冗余推理步骤且性能提升有限。本文实证发现，将小模型生成的外部思维链置于思维标记间，可有效减少大模型的思考步骤。基于此提出简单高效的方法，使LRMs绕过不必要的中间步骤，降低计算成本。实验表明，该方法用于QwQ - 32B时，能保持性能，输出令牌数减少约30%，还可通过简单措施进一步提升性能。
            arXiv:2504.13626v2 Announce Type: replace 
Abstract: Recent advancements in large reasoning models (LRMs) have demonstrated the effectiveness of scaling test-time computation to enhance reasoning capabilities on various tasks. However, LRMs often suffer from an ``overthinking'' problem, where the model generates excessively redundant reasoning steps with limited performance gains. In this work, we empirically reveal an important characteristic of LRM behaviors that placing external CoTs generated by smaller models between the thinking token (\texttt{} and \texttt{}) can effectively manipulate the model to generate fewer thoughts. Building on this finding, we propose a simple yet efficient pipeline, \Method, to enable LRMs to bypass unnecessary intermediate steps, thereby significantly reducing computational costs. We conduct extensive experiments to evaluate the utility and efficiency of \Method. For instance, when applied to QwQ-32B on the LiveBench/Code dataset, \Method keeps the original performance while reducing output token counts by approximately 30\%, with minimal overhead introduced by the CoT generator. Furthermore, we identify two suboptimal modes, blindly following flawed external thoughts and unnecessary rethinking, and show that simple mitigations, such as difficulty-aware fallbacks, can further improve performance. Overall, \Method offers a practical, general, and efficient way to optimize LRM inference, making powerful reasoning models more accessible and scalable for real-world applications.
        ]]></description>
    </item>
    <item>
        <title>Informed Forecasting: Leveraging Auxiliary Knowledge to Boost LLM Performance on Time Series Forecasting</title>
        <link>https://arxiv.org/abs/2505.10213</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.10213v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mohammadmahdi Ghasemloo, Alireza Moradi</dc:creator>
        <description><![CDATA[
            背景：大语言模型广泛应用，需探索其在传统自然语言任务外的应用。方法：提出跨领域知识迁移框架，将结构化时间信息融入大语言模型，提升其在时间序列预测任务中的表现。效果：在真实时间序列数据集上评估，与无辅助信息的基线对比，结果显示该方法在预测准确性和泛化能力上显著优于基线，表明知识迁移策略能缩小大语言模型与特定领域预测任务的差距。
            arXiv:2505.10213v2 Announce Type: replace 
Abstract: With the widespread adoption of Large Language Models (LLMs), there is a growing need to establish best practices for leveraging their capabilities beyond traditional natural language tasks. In this paper, a novel cross-domain knowledge transfer framework is proposed to enhance the performance of LLMs in time series forecasting -- a task of increasing relevance in fields such as energy systems, finance, and healthcare. The approach systematically infuses LLMs with structured temporal information to improve their forecasting accuracy. This study evaluates the proposed method on a real-world time series dataset and compares it to a naive baseline where the LLM receives no auxiliary information. Results show that knowledge-informed forecasting significantly outperforms the uninformed baseline in terms of predictive accuracy and generalization. These findings highlight the potential of knowledge transfer strategies to bridge the gap between LLMs and domain-specific forecasting tasks.
        ]]></description>
    </item>
    <item>
        <title>CoT-Vid: Dynamic Chain-of-Thought Routing with Self Verification for Training-Free Video Reasoning</title>
        <link>https://arxiv.org/abs/2505.11830</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.11830v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hongbo Jin, Ruyang Liu, Wenhao Zhang, Guibo Luo, Ge Li</dc:creator>
        <description><![CDATA[
            背景：随着深度思维模型和思维链技术出现，System2推理发展迅速，但复杂视频推理研究相对滞后。方法：提出CoT - Vid，一种无训练的视频领域范式，有动态推理路径路由、问题解耦策略和视频自一致性验证三个主要组件，还提出视频问题分类新标准。效果：在多个基准测试中表现出色，在Egochema上比基础模型性能提升9.3%，在VideoEspresso上提升5.6%，可与甚至超越GPT - 4V等大模型。
            arXiv:2505.11830v2 Announce Type: replace 
Abstract: System2 reasoning is developing rapidly these days with the emergence of Deep- Thinking Models and chain-of-thought technology, which has become a centralized discussion point in the AI community. However, there is a relative gap in the research on complex video reasoning at present. In this work, we propose CoT-Vid, a novel training-free paradigm for the video domain with a multistage complex reasoning design. Distinguishing from existing video LLMs, which rely heavily on perceptual abilities, it achieved surprising performance gain with explicit reasoning mechanism. The paradigm consists of three main components: dynamic inference path routing, problem decoupling strategy, and video self-consistency verification. In addition, we propose a new standard for categorization of video questions. CoT- Vid showed outstanding results on a wide range of benchmarks, and outperforms its base model by 9.3% on Egochema and 5.6% on VideoEspresso, rivalling or even surpassing larger and proprietary models, such as GPT-4V, GPT-4o and Gemini-1.5-flash. Our codebase will be publicly available soon.
        ]]></description>
    </item>
    <item>
        <title>ChartEdit: How Far Are MLLMs From Automating Chart Analysis? Evaluating MLLMs' Capability via Chart Editing</title>
        <link>https://arxiv.org/abs/2505.11935</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.11935v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xuanle Zhao, Xuexin Liu, Haoyue Yang, Xianzhen Luo, Fanhu Zeng, Jianling Li, Qi Shi, Chi Chen</dc:creator>
        <description><![CDATA[
            这是一篇关于多模态大模型的研究。背景是多模态大模型在图表编辑任务中面临挑战，且缺乏全面评估框架。方法上，提出了名为ChartEdit的新基准，含1405条编辑指令和233张真实图表，并手动标注验证。通过该基准对10个主流多模态大模型进行两级实验评估。结果显示，大模型能生成部分匹配的图像代码，但按指令精确编辑能力有限，SOTA模型得分仅59.96，小模型表现更差，表明该领域仍需发展。
            arXiv:2505.11935v2 Announce Type: replace 
Abstract: Although multimodal large language models (MLLMs) show promise in generating chart rendering code, editing charts via code presents a greater challenge. This task demands MLLMs to integrate chart understanding and reasoning capacities, which are labor-intensive. While many MLLMs claim such editing capabilities, current evaluations rely on limited case studies, highlighting the urgent need for a comprehensive evaluation framework. In this work, we propose \textsc{ChartEdit}, a novel benchmark designed for chart editing tasks, featuring $1405$ diverse editing instructions applied to $233$ real-world charts, each manually annotated and validated for accuracy. Utilizing \textsc{ChartEdit}, we evaluate the performance of 10 mainstream MLLMs across two types of experiments at both the code and chart levels. The results suggest that large-scale models can generate code to produce images that partially match the reference images. However, their ability to generate accurate edits according to the instructions remains limited. The state-of-the-art (SOTA) model achieves a score of only $59.96$, highlighting significant challenges in precise modification. In contrast, small-scale models, including chart-domain models, struggle both with following editing instructions and generating overall chart images, underscoring the need for further development in this area. Code is available at https://github.com/xxlllz/ChartEdit.
        ]]></description>
    </item>
    <item>
        <title>Action2Dialogue: Generating Character-Centric Narratives from Scene-Level Prompts</title>
        <link>https://arxiv.org/abs/2505.16819</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.16819v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Taewon Kang, Ming C. Lin</dc:creator>
        <description><![CDATA[
            背景：基于场景的视频生成虽能从结构化提示合成连贯视觉叙事，但角色驱动的对话和语音这一关键维度研究不足。方法：提出模块化流程，用预训练视觉语言编码器从画面提取语义特征，与结构化提示结合引导大语言模型合成对话，引入递归叙事库确保场景间一致性，最后将话语渲染为语音。效果：该免训练框架能跨多种故事场景，为视听叙事提供可扩展解决方案。
            arXiv:2505.16819v2 Announce Type: replace 
Abstract: Recent advances in scene-based video generation have enabled systems to synthesize coherent visual narratives from structured prompts. However, a crucial dimension of storytelling -- character-driven dialogue and speech -- remains underexplored. In this paper, we present a modular pipeline that transforms action-level prompts into visually and auditorily grounded narrative dialogue, enriching visual storytelling with natural voice and character expression. Our method takes as input a pair of prompts per scene, where the first defines the setting and the second specifies a character's behavior. While a story generation model such as Text2Story produces the corresponding visual scene, we focus on generating expressive, character-consistent utterances grounded in both the prompts and the scene image. A pretrained vision-language encoder extracts high-level semantic features from a representative frame, capturing salient visual context. These features are then integrated with structured prompts to guide a large language model in synthesizing natural dialogue. To ensure contextual and emotional consistency across scenes, we introduce a Recursive Narrative Bank -- a speaker-aware, temporally structured memory that recursively accumulates each character's dialogue history. Inspired by Script Theory in cognitive psychology, this design enables characters to speak in ways that reflect their evolving goals, social context, and narrative roles throughout the story. Finally, we render each utterance as expressive, character-conditioned speech, resulting in fully-voiced, multimodal video narratives. Our training-free framework generalizes across diverse story settings -- from fantasy adventures to slice-of-life episodes -- offering a scalable solution for coherent, character-grounded audiovisual storytelling.
        ]]></description>
    </item>
    <item>
        <title>Hypergraph Mamba for Efficient Whole Slide Image Understanding</title>
        <link>https://arxiv.org/abs/2505.17457</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17457v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiaxuan Lu, Yuhui Lin, Junyan Shi, Fang Yan, Dongzhan Zhou, Yue Gao, Xiaosong Wang</dc:creator>
        <description><![CDATA[
            背景：组织病理学全切片图像（WSIs）因超高分辨率、大规模和复杂空间关系，给医学图像分析带来挑战，现有方法存在可扩展性和计算成本问题。方法：提出WSI - HGMamba框架，将超图神经网络高阶关系建模能力与状态空间模型的线性时间序列建模效率结合，核心是HGMamba块，集成消息传递等操作。效果：与Transformer等相比，FLOPs最多降低7倍，在多个WSI基准上表现出色，为切片级理解提供有效解决方案。
            arXiv:2505.17457v2 Announce Type: replace 
Abstract: Whole Slide Images (WSIs) in histopathology pose a significant challenge for extensive medical image analysis due to their ultra-high resolution, massive scale, and intricate spatial relationships. Although existing Multiple Instance Learning (MIL) approaches like Graph Neural Networks (GNNs) and Transformers demonstrate strong instance-level modeling capabilities, they encounter constraints regarding scalability and computational expenses. To overcome these limitations, we introduce the WSI-HGMamba, a novel framework that unifies the high-order relational modeling capabilities of the Hypergraph Neural Networks (HGNNs) with the linear-time sequential modeling efficiency of the State Space Models. At the core of our design is the HGMamba block, which integrates message passing, hypergraph scanning & flattening, and bidirectional state space modeling (Bi-SSM), enabling the model to retain both relational and contextual cues while remaining computationally efficient. Compared to Transformer and Graph Transformer counterparts, WSI-HGMamba achieves superior performance with up to 7* reduction in FLOPs. Extensive experiments on multiple public and private WSI benchmarks demonstrate that our method provides a scalable, accurate, and efficient solution for slide-level understanding, making it a promising backbone for next-generation pathology AI systems.
        ]]></description>
    </item>
    <item>
        <title>Hypercube-Based Retrieval-Augmented Generation for Scientific Question-Answering</title>
        <link>https://arxiv.org/abs/2505.19288</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.19288v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jimeng Shi, Sizhe Zhou, Bowen Jin, Wei Hu, Runchu Tian, Shaowen Wang, Giri Narasimhan, Jiawei Han</dc:creator>
        <description><![CDATA[
            大语言模型解决特定主题问题时需结合外部知识，现有检索增强生成（RAG）方法大多基于稀疏或密集检索，忽略了文档中的结构化语义信息。为此，本文引入多维结构“超立方体”，并提出新的RAG框架Hypercube - RAG。该框架先分解查询，再通过组件与维度对齐检索文档。实验表明，其在三个不同领域数据集上，响应准确率提高3.7%，检索准确率提高5.3%，检索效率比基于图的RAG快一到两个数量级，且具有可解释性。
            arXiv:2505.19288v2 Announce Type: replace 
Abstract: Large language models (LLMs) often need to incorporate external knowledge to solve theme-specific problems. Retrieval-augmented generation (RAG) has shown its high promise, empowering LLMs to generate more qualified responses with retrieved external data and knowledge. However, most RAG methods retrieve relevant documents based on either sparse or dense retrieval methods or their combinations, which overlooks the essential, multi-dimensional, and structured semantic information present in documents. This structured information plays a critical role in finding concise yet highly relevant information for domain knowledge-intensive tasks, such as scientific question-answering (QA). In this work, we introduce a multi-dimensional (cube) structure, Hypercube, which can index and allocate documents in a pre-defined multi-dimensional space. Built on the hypercube, we further propose Hypercube-RAG, a novel RAG framework for precise and efficient retrieval. Given a query, Hypercube-RAG first decomposes it based on its entities, phrases, and topics along with pre-defined hypercube dimensions, and then retrieves relevant documents from cubes by aligning these decomposed components with corresponding dimensions. Experiments on three datasets across different domains demonstrate that our method improves response accuracy by 3.7% and retrieval accuracy by 5.3% over the strongest RAG baseline. It also boosts retrieval efficiency (speed) by one or two magnitudes faster than graph-based RAG. Notably, our Hypercube-RAG inherently offers explainability by revealing those underlying dimensions used for retrieval. The code and data are available at https://github.com/JimengShi/Hypercube-RAG.
        ]]></description>
    </item>
    <item>
        <title>Leaps Beyond the Seen: Reinforced Reasoning Augmented Generation for Clinical Notes</title>
        <link>https://arxiv.org/abs/2506.05386</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.05386v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Lo Pang-Yun Ting, Chengshuai Zhao, Yu-Hua Zeng, Yuan Jee Lim, Kun-Ta Chuang, Huan Liu</dc:creator>
        <description><![CDATA[
            临床笔记生成旨在总结患者情况和诊断过程，但现有基于大语言模型（LLM）的方法难以从有限患者信息生成长篇笔记。本文提出ReinRAG，基于入院前信息生成长篇出院指导。它从医学知识图谱检索推理路径为LLM提供语义指导，还提出基于组的检索器优化（GRO）提升检索质量。真实数据集实验表明，ReinRAG在临床效果和自然语言生成指标上均优于基线模型，能填补语义空白，避免临床误判。
            arXiv:2506.05386v2 Announce Type: replace 
Abstract: Clinical note generation aims to produce free-text summaries of a patient's condition and diagnostic process, with discharge instructions being a representative long-form example. While recent LLM-based methods pre-trained on general clinical corpora show promise in clinical text generation, they fall short in producing long-form notes from limited patient information. In this paper, we propose ReinRAG, a reinforced reasoning augmented generation (RAG) for long-form discharge instructions based on pre-admission information. ReinRAG retrieves reasoning paths from a medical knowledge graph to provide explicit semantic guidance to the LLM. To bridge the information gap, we propose group-based retriever optimization (GRO) which improves retrieval quality with group-normalized rewards, encouraging reasoning leaps for deeper inference by the LLM. Comprehensive experiments on the real-world dataset show that ReinRAG outperforms baselines in both clinical efficacy and natural language generation metrics. Further analysis reveals that ReinRAG fills semantic gaps in sparse input scenarios, and retrieved reasoning paths help LLMs avoid clinical misinterpretation by focusing on key evidence and following coherent reasoning.
        ]]></description>
    </item>
    <item>
        <title>RAISE: Enhancing Scientific Reasoning in LLMs via Step-by-Step Retrieval</title>
        <link>https://arxiv.org/abs/2506.08625</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08625v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Minhae Oh, Jeonghye Kim, Nakyung Lee, Donggeon Seo, Taeuk Kim, Jungwoo Lee</dc:creator>
        <description><![CDATA[
            科学推理需长链推理过程、领域术语知识及适应新发现。为应对这些挑战，本文提出RAISE，一个逐步检索增强框架，可从自然语料库中检索逻辑相关文档。该框架分问题分解、逻辑查询生成和逻辑检索三步。实验表明，RAISE在科学推理基准测试中始终优于其他基线模型，因其能检索到不仅领域知识相似、逻辑上也更相关的文档。
            arXiv:2506.08625v2 Announce Type: replace 
Abstract: Scientific reasoning requires not only long-chain reasoning processes, but also knowledge of domain-specific terminologies and adaptation to updated findings. To deal with these challenges for scientific reasoning, we introduce RAISE, a step-by-step retrieval-augmented framework which retrieves logically relevant documents from in-the-wild corpus. RAISE is divided into three steps: problem decomposition, logical query generation, and logical retrieval. We observe that RAISE consistently outperforms other baselines on scientific reasoning benchmarks. We analyze that unlike other baselines, RAISE retrieves documents that are not only similar in terms of the domain knowledge, but also documents logically more relevant.
        ]]></description>
    </item>
    <item>
        <title>FinCoT: Grounding Chain-of-Thought in Expert Financial Reasoning</title>
        <link>https://arxiv.org/abs/2506.16123</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.16123v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Natapong Nitarach, Warit Sirichotedumrong, Panop Pitchayarthorn, Pittawat Taveekitworachai, Potsawee Manakul, Kunat Pipatanakul</dc:creator>
        <description><![CDATA[
            这是一篇关于多模态大模型思维链的研究。此前金融NLP主要关注标准提示和非结构化思维链，结构化思维链缺乏领域专业知识。本文提出FinCoT框架，在十个CFA风格金融领域评估三种提示方法。该框架能将通用模型Qwen3 - 8B - Base准确率从63.2%提升到80.5%，将金融特定模型Fin - R1(7B)从65.7%提升到75.7%，还能减少输出长度，尤其对缺乏金融后训练的模型效果更佳。
            arXiv:2506.16123v2 Announce Type: replace 
Abstract: This paper presents FinCoT, a structured chain-of-thought (CoT) prompting framework that embeds domain-specific expert financial reasoning blueprints to guide large language models' behaviors. We identify three main prompting styles in financial NLP (FinNLP): (1) standard prompting (zero-shot), (2) unstructured CoT (free-form reasoning), and (3) structured CoT (with explicitly structured reasoning steps). Prior work has mainly focused on the first two, while structured CoT remains underexplored and lacks domain expertise incorporation. Therefore, we evaluate all three prompting approaches across ten CFA-style financial domains and introduce FinCoT as the first structured finance-specific prompting approach incorporating blueprints from domain experts. FinCoT improves the accuracy of a general-purpose model, Qwen3-8B-Base, from 63.2% to 80.5%, and boosts Fin-R1 (7B), a finance-specific model, from 65.7% to 75.7%, while reducing output length by up to 8.9x and 1.16x compared to structured CoT methods, respectively. We find that FinCoT proves most effective for models lacking financial post-training. Our findings show that FinCoT does not only improve performance and reduce inference costs but also yields more interpretable and expert-aligned reasoning traces.
        ]]></description>
    </item>
    <item>
        <title>Large Language Models in Argument Mining: A Survey</title>
        <link>https://arxiv.org/abs/2506.16383</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.16383v5</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hao Li, Viktor Schlegel, Yizheng Sun, Riza Batista-Navarro, Goran Nenadic</dc:creator>
        <description><![CDATA[
            论证挖掘（AM）是自然语言处理关键子领域，大语言模型（LLM）的出现深刻变革了AM。该论文系统性综述了基于LLM的AM最新进展，回顾基础理论与标注框架，整理数据集。提出AM子任务分类法，阐明提示、思维链推理和检索增强等LLM技术对其执行的重构。详述当前LLM架构与方法，评估实践并指出长上下文推理、可解释性等挑战。最后指明趋势，提出研究方向，为相关研究提供指引。
            arXiv:2506.16383v5 Announce Type: replace 
Abstract: Argument Mining (AM), a critical subfield of Natural Language Processing (NLP), focuses on extracting argumentative structures from text. The advent of Large Language Models (LLMs) has profoundly transformed AM, enabling advanced in-context learning, prompt-based generation, and robust cross-domain adaptability. This survey systematically synthesizes recent advancements in LLM-driven AM. We provide a concise review of foundational theories and annotation frameworks, alongside a meticulously curated catalog of datasets. A key contribution is our comprehensive taxonomy of AM subtasks, elucidating how contemporary LLM techniques -- such as prompting, chain-of-thought reasoning, and retrieval augmentation -- have reconfigured their execution. We further detail current LLM architectures and methodologies, critically assess evaluation practices, and delineate pivotal challenges including long-context reasoning, interpretability, and annotation bottlenecks. Conclusively, we highlight emerging trends and propose a forward-looking research agenda for LLM-based computational argumentation, aiming to strategically guide researchers in this rapidly evolving domain.
        ]]></description>
    </item>
    <item>
        <title>ActAlign: Zero-Shot Fine-Grained Video Classification via Language-Guided Sequence Alignment</title>
        <link>https://arxiv.org/abs/2506.22967</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.22967v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Amir Aghdam, Vincent Tao Hu, Bj\"orn Ommer</dc:creator>
        <description><![CDATA[
            背景：现有图像 - 语言模型缺乏视频理解所需的时间建模能力，难以完成零样本细粒度视频分类任务。方法：提出ActAlign，将视频分类转化为序列对齐问题，用大语言模型为每个类别生成子动作有序序列，通过动态时间规整（DTW）在共享嵌入空间将其与视频帧对齐。效果：在ActionAtlas上准确率达30.5%，人类表现仅61.6%，参数少8倍却优于十亿参数的视频 - 语言模型，证明结构化语言先验结合经典对齐方法的有效性。
            arXiv:2506.22967v2 Announce Type: replace 
Abstract: We address the task of zero-shot video classification for extremely fine-grained actions (e.g., Windmill Dunk in basketball), where no video examples or temporal annotations are available for unseen classes. While image-language models (e.g., CLIP, SigLIP) show strong open-set recognition, they lack temporal modeling needed for video understanding. We propose ActAlign, a truly zero-shot, training-free method that formulates video classification as a sequence alignment problem, preserving the generalization strength of pretrained image-language models. For each class, a large language model (LLM) generates an ordered sequence of sub-actions, which we align with video frames using Dynamic Time Warping (DTW) in a shared embedding space. Without any video-text supervision or fine-tuning, ActAlign achieves 30.5% accuracy on ActionAtlas--the most diverse benchmark of fine-grained actions across multiple sports--where human performance is only 61.6%. ActAlign outperforms billion-parameter video-language models while using 8x fewer parameters. Our approach is model-agnostic and domain-general, demonstrating that structured language priors combined with classical alignment methods can unlock the open-set recognition potential of image-language models for fine-grained video understanding.
        ]]></description>
    </item>
    <item>
        <title>What to Keep and What to Drop: Adaptive Table Filtering Framework</title>
        <link>https://arxiv.org/abs/2506.23463</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.23463v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>WonJune Jang</dc:creator>
        <description><![CDATA[
            背景：基于表格推理的大语言模型因输入长度限制，处理大表格时面临困难。方法：提出自适应表格过滤框架（ATF），这是一个模块化且能感知问题的过滤流程，利用大语言模型生成的列描述、聚类和稀疏-密集对齐分数来修剪无信息的列和行，且能与现有模型无缝集成，无需重新训练。效果：实验表明，ATF能减少70%的表格单元格，提升域外表格问答任务的性能，在表格事实验证任务中性能略有下降。
            arXiv:2506.23463v3 Announce Type: replace 
Abstract: Large language models (LLMs) for table-based reasoning often struggle with large tables due to input length limits. We propose ATF (Adaptive Table Filtering Framework), a modular and question-aware filtering pipeline that prunes uninformative columns and rows using LLM-generated column descriptions, clustering, and sparse-dense alignment scores. ATF integrates seamlessly with existing models (e.g., TAPAS, TAPEX) without retraining. Experiments show that ATF reduces table cells by 70%, boosting performance on out-of-domain TableQA tasks while causing slight performance drops on Table Fact Verification, where full-table context is more critical. These results highlight ATF's ability to adaptively balance informativeness and minimalism across tasks. Our code available at: https://github.com/torijune/ATF-Adaptive-Table-Filtering-Framework
        ]]></description>
    </item>
    <item>
        <title>Hierarchical Multi-Label Contrastive Learning for Protein-Protein Interaction Prediction Across Organisms</title>
        <link>https://arxiv.org/abs/2507.02724</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.02724v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Shiyi Liu, Buwen Liang, Yuetong Fang, Zixuan Jiang, Renjing Xu</dc:creator>
        <description><![CDATA[
            背景：当前人工智能助力科学领域中，对比学习在融合异构生物数据模态方面展现强大能力。方法：提出HIPPO框架，通过多层级生物表征匹配来对齐蛋白质序列及其层次属性，引入层次对比损失函数，还利用数据驱动惩罚机制融入领域和家族知识。效果：在基准数据集实验中，HIPPO达最优性能，超越现有方法，在低数据场景下表现稳健，有强零样本迁移能力，层次特征融合对捕捉保守相互作用决定因素至关重要。
            arXiv:2507.02724v3 Announce Type: replace 
Abstract: Recent advances in AI for science have highlighted the power of contrastive learning in bridging heterogeneous biological data modalities. Building on this paradigm, we propose HIPPO (HIerarchical Protein-Protein interaction prediction across Organisms), a hierarchical contrastive framework for protein-protein interaction(PPI) prediction, where protein sequences and their hierarchical attributes are aligned through multi-tiered biological representation matching. The proposed approach incorporates hierarchical contrastive loss functions that emulate the structured relationship among functional classes of proteins. The framework adaptively incorporates domain and family knowledge through a data-driven penalty mechanism, enforcing consistency between the learned embedding space and the intrinsic hierarchy of protein functions. Experiments on benchmark datasets demonstrate that HIPPO achieves state-of-the-art performance, outperforming existing methods and showing robustness in low-data regimes. Notably, the model demonstrates strong zero-shot transferability to other species without retraining, enabling reliable PPI prediction and functional inference even in less characterized or rare organisms where experimental data are limited. Further analysis reveals that hierarchical feature fusion is critical for capturing conserved interaction determinants, such as binding motifs and functional annotations. This work advances cross-species PPI prediction and provides a unified framework for interaction prediction in scenarios with sparse or imbalanced multi-species data.
        ]]></description>
    </item>
    <item>
        <title>Multi-Modal Semantic Parsing for the Interpretation of Tombstone Inscriptions</title>
        <link>https://arxiv.org/abs/2507.04377</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.04377v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiao Zhang, Johan Bos</dc:creator>
        <description><![CDATA[
            背景：墓碑面临诸多保存挑战，需更好地解读、组织和检索其内容。方法：提出新颖的多模态框架用于墓碑数字化，利用视觉语言模型将墓碑图像转化为结构化的墓碑意义表征，同时结合检索增强生成融入外部依赖元素。效果：相比传统基于OCR的流程，解析准确率的F1分数从36.1提升到89.5，还评估了模型在不同语言文化铭文及噪声损坏条件下的性能，对遗产保护有重要意义。
            arXiv:2507.04377v2 Announce Type: replace 
Abstract: Tombstones are historically and culturally rich artifacts, encapsulating individual lives, community memory, historical narratives and artistic expression. Yet, many tombstones today face significant preservation challenges, including physical erosion, vandalism, environmental degradation, and political shifts. In this paper, we introduce a novel multi-modal framework for tombstones digitization, aiming to improve the interpretation, organization and retrieval of tombstone content. Our approach leverages vision-language models (VLMs) to translate tombstone images into structured Tombstone Meaning Representations (TMRs), capturing both image and text information. To further enrich semantic parsing, we incorporate retrieval-augmented generation (RAG) for integrate externally dependent elements such as toponyms, occupation codes, and ontological concepts. Compared to traditional OCR-based pipelines, our method improves parsing accuracy from an F1 score of 36.1 to 89.5. We additionally evaluate the model's robustness across diverse linguistic and cultural inscriptions, and simulate physical degradation through image fusion to assess performance under noisy or damaged conditions. Our work represents the first attempt to formalize tombstone understanding using large vision-language models, presenting implications for heritage preservation.
        ]]></description>
    </item>
    <item>
        <title>Fourier Basis Mapping: A Time-Frequency Learning Framework for Time Series Forecasting</title>
        <link>https://arxiv.org/abs/2507.09445</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.09445v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Runze Yang, Longbing Cao, Xin You, Kun Fang, Jianxun Li, Jie Yang</dc:creator>
        <description><![CDATA[
            背景：傅里叶变换与深度学习结合为时间序列预测带来新途径，但现有基于傅里叶的方法存在起始周期和序列长度不一致等问题。方法：提出傅里叶基映射（FBM）方法，通过傅里叶基扩展和时频空间映射整合时频特征，还提出FBM - L、FBM - NL、FBM - NP分别增强不同模型，以及协同模型架构FBM - S，并引入多种时频特征处理技术。效果：在多种真实数据集的长短预测任务中达SOTA水平。
            arXiv:2507.09445v2 Announce Type: replace 
Abstract: The integration of Fourier transform and deep learning opens new avenues for time series forecasting. We reconsider the Fourier transform from a basis functions perspective. Specifically, the real and imaginary parts of the frequency components can be regarded as the coefficients of cosine and sine basis functions at tiered frequency levels, respectively. We find that existing Fourier-based methods face inconsistent starting cycles and inconsistent series length issues. They fail to interpret frequency components precisely and overlook temporal information. Accordingly, the novel Fourier Basis Mapping (FBM) method addresses these issues by integrating time-frequency features through Fourier basis expansion and mapping in the time-frequency space. Our approach extracts explicit frequency features while preserving temporal characteristics. FBM supports plug-and-play integration with various types of neural networks by only adjusting the first initial projection layer for better performance. First, we propose FBM-L, FBM-NL, and FBM-NP to enhance linear, MLP-based, and Transformer-based models, respectively, demonstrating the effectiveness of time-frequency features. Next, we propose a synergetic model architecture, termed FBM-S, which decomposes the seasonal, trend, and interaction effects into three separate blocks, each designed to model time-frequency features in a specialized manner. Finally, we introduce several techniques tailored for time-frequency features, including interaction masking, centralization, patching, rolling window projection, and multi-scale down-sampling. The results are validated on diverse real-world datasets for both long-term and short-term forecasting tasks with SOTA performance.
        ]]></description>
    </item>
    <item>
        <title>HuggingGraph: Understanding the Supply Chain of LLM Ecosystem</title>
        <link>https://arxiv.org/abs/2507.14240</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.14240v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mohammad Shahedur Rahman, Runbang Hu, Peng Gao, Yuede Ji</dc:creator>
        <description><![CDATA[
            背景：大语言模型开发、训练和部署的规模与复杂性增加，需大量资源和数据集，且现有模型易继承风险。方法：本研究设计方法系统收集大语言模型供应链信息，构建含402,654个节点和462,524条边的有向异构大图来建模模型与数据集关系，并进行分析。效果：取得了多项有趣发现，有助于检测潜在风险、提升模型公平性和确保合规。
            arXiv:2507.14240v2 Announce Type: replace 
Abstract: Large language models (LLMs) leverage deep learning architectures to process and predict sequences of words based on context, enabling them to perform a wide range of natural language processing tasks, such as translation, summarization, question answering, and content generation. However, the increasing size and complexity of developing, training, and deploying cutting-edge LLMs demand extensive computational resources and large-scale datasets. This creates a significant barrier for researchers and practitioners. Because of that, platforms that host models and datasets have gained widespread popularity. For example, on one of the most popular platforms, i.e., Hugging Face, there are more than 1.8 million models and more than 450K datasets by the end of June 2025, and the trend does not show any slowdown.
  As existing LLMs are often built from base models or other pretrained models and use external datasets, they can inevitably inherit vulnerabilities, biases, or malicious components that exist in previous models or datasets. Therefore, it is critical to understand these components' origin and development process to detect potential risks better, improve model fairness, and ensure compliance with regulatory frameworks. Motivated by that, this project aims to study such relationships between models and datasets, which are the central parts of the LLM supply chain. First, we design a methodology to collect LLMs' supply chain information systematically. With the collected information, we design a new graph to model the relationships between models and datasets, which is a large directed heterogeneous graph having 402,654 nodes and 462,524 edges. Then, on top of this graph, we perform different types of analysis and make multiple interesting findings.
        ]]></description>
    </item>
    <item>
        <title>Towards Temporal-Aware Multi-Modal Retrieval Augmented Generation in Finance</title>
        <link>https://arxiv.org/abs/2503.05185</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.05185v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Fengbin Zhu, Junfeng Li, Liangming Pan, Wenjie Wang, Fuli Feng, Chao Wang, Huanbo Luan, Tat-Seng Chua</dc:creator>
        <description><![CDATA[
            金融决策依赖多源数据分析。本文推出首个评估金融中时间感知多模态检索增强生成（RAG）系统的综合基准FinTMMBench，其基于纳斯达克100家公司的异源数据构建，具有多模态语料、时间感知问题、多样金融分析任务三大优势。还提出TMMHybridRAG方法，先利用大语言模型将其他模态数据转为文本格式，构建图和密集索引时融入时间信息。大量实验验证了其有效性，但仍有差距，凸显该基准带来的挑战。
            arXiv:2503.05185v2 Announce Type: replace-cross 
Abstract: Finance decision-making often relies on in-depth data analysis across various data sources, including financial tables, news articles, stock prices, etc. In this work, we introduce FinTMMBench, the first comprehensive benchmark for evaluating temporal-aware multi-modal Retrieval-Augmented Generation (RAG) systems in finance. Built from heterologous data of NASDAQ 100 companies, FinTMMBench offers three significant advantages. 1) Multi-modal Corpus: It encompasses a hybrid of financial tables, news articles, daily stock prices, and visual technical charts as the corpus. 2) Temporal-aware Questions: Each question requires the retrieval and interpretation of its relevant data over a specific time period, including daily, weekly, monthly, quarterly, and annual periods. 3) Diverse Financial Analysis Tasks: The questions involve 10 different financial analysis tasks designed by domain experts, including information extraction, trend analysis, sentiment analysis and event detection, etc. We further propose a novel TMMHybridRAG method, which first leverages LLMs to convert data from other modalities (e.g., tabular, visual and time-series data) into textual format and then incorporates temporal information in each node when constructing graphs and dense indexes. Its effectiveness has been validated in extensive experiments, but notable gaps remain, highlighting the challenges presented by our FinTMMBench.
        ]]></description>
    </item>
    <item>
        <title>R1-VL: Learning to Reason with Multimodal Large Language Models via Step-wise Group Relative Policy Optimization</title>
        <link>https://arxiv.org/abs/2503.12937</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.12937v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jingyi Zhang, Jiaxing Huang, Huanjin Yao, Shunyu Liu, Xikun Zhang, Shijian Lu, Dacheng Tao</dc:creator>
        <description><![CDATA[
            背景：现有研究通过在高质量思维链推理数据上进行监督微调提升多模态大语言模型（MLLMs）推理能力，易使模型只模仿成功推理路径。方法：设计逐步组相对策略优化（StepGRPO）这一在线强化学习框架，引入逐步推理准确性奖励（StepRAR）和逐步推理有效性奖励（StepRVR），推出R1 - VL模型。效果：在8个基准测试上的大量实验证明了方法的优越性，使模型具备出色的逐步推理能力。
            arXiv:2503.12937v2 Announce Type: replace-cross 
Abstract: Recent studies generally enhance MLLMs' reasoning capabilities via supervised fine-tuning on high-quality chain-of-thought reasoning data, which often leads models to merely imitate successful reasoning paths without understanding what the wrong reasoning paths are. In this work, we aim to enhance the MLLMs' reasoning ability beyond passively imitating positive reasoning paths. To this end, we design Step-wise Group Relative Policy Optimization (StepGRPO), a new online reinforcement learning framework that enables MLLMs to self-improve reasoning ability via simple, effective and dense step-wise rewarding. Specifically, StepGRPO introduces two novel rule-based reasoning rewards: Step-wise Reasoning Accuracy Reward (StepRAR) and Step-wise Reasoning Validity Reward (StepRVR). StepRAR rewards the reasoning paths that contain necessary intermediate reasoning steps via a soft key-step matching technique, while StepRAR rewards reasoning paths that follow a well-structured and logically consistent reasoning process through a reasoning completeness and logic evaluation strategy. With the proposed StepGRPO, we introduce R1-VL, a series of MLLMs with outstanding capabilities in step-by-step reasoning. Extensive experiments over 8 benchmarks demonstrate the superiority of our methods.
        ]]></description>
    </item>
    <item>
        <title>GateLens: A Reasoning-Enhanced LLM Agent for Automotive Software Release Analytics</title>
        <link>https://arxiv.org/abs/2503.21735</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.21735v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Arsham Gholamzadeh Khoee, Shuai Wang, Yinan Yu, Robert Feldt, Dhasarathy Parthasarathy</dc:creator>
        <description><![CDATA[
            在汽车制造等安全关键领域，确保可靠的软件发布决策至关重要。传统人工分析表格数据速度慢、成本高且易出错，大语言模型在分析推理、处理结构化数据等方面有挑战。本文提出GateLens系统，将自然语言查询转换为关系代数表达式并生成优化Python代码。实验表明，它在处理复杂模糊查询上优于现有基于思维链+自一致性的系统。工业部署中，分析时间减少超80%，且能保持高精度，在零样本设置下也有效。
            arXiv:2503.21735v2 Announce Type: replace-cross 
Abstract: Ensuring reliable software release decisions is critical in safety-critical domains such as automotive manufacturing. Release validation relies on large tabular datasets, yet manual analysis is slow, costly, and error-prone. While Large Language Models (LLMs) offer promising automation potential, they face challenges in analytical reasoning, structured data handling, and ambiguity resolution. This paper introduces GateLens, an LLM-based system for analyzing tabular data in the automotive domain. GateLens translates natural language queries into Relational Algebra (RA) expressions and generates optimized Python code. Unlike traditional multi-agent or planning-based systems that can be slow, opaque, and costly to maintain, GateLens emphasizes speed, transparency, and reliability. Experimental results show that GateLens outperforms the existing Chain-of-Thought (CoT) + Self-Consistency (SC) based system on real-world datasets, particularly in handling complex and ambiguous queries. Ablation studies confirm the essential role of the RA layer. Industrial deployment shows over 80% reduction in analysis time while maintaining high accuracy across test result interpretation, impact assessment, and release candidate evaluation. GateLens operates effectively in zero-shot settings without requiring few-shot examples or agent orchestration. This work advances deployable LLM system design by identifying key architectural features-intermediate formal representations, execution efficiency, and low configuration overhead-crucial for safety-critical industrial applications.
        ]]></description>
    </item>
    <item>
        <title>A Brain Graph Foundation Model: Pre-Training and Prompt-Tuning for Any Atlas and Disorder</title>
        <link>https://arxiv.org/abs/2506.02044</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02044v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xinxu Wei, Kanhao Zhao, Yong Jiao, Lifang He, Yu Zhang</dc:creator>
        <description><![CDATA[
            背景：大语言模型发展促使构建脑基础模型成为热点，现有模型多基于时间序列信号或连接组特征预训练。方法：提出基于图的预训练范式构建脑图基础模型BrainGFM，利用图对比学习和图掩码自编码器进行大规模功能磁共振成像（fMRI）预训练，融合图提示和语言提示，采用元学习优化图提示。效果：模型在27个神经影像数据集上预训练，能跨异构fMRI脑表征泛化，可灵活适应多种情况，在少样本和零样本学习下对未见疾病有强泛化能力。
            arXiv:2506.02044v2 Announce Type: replace-cross 
Abstract: As large language models (LLMs) continue to revolutionize AI research, there is a growing interest in building large-scale brain foundation models to advance neuroscience. While most existing brain foundation models are pre-trained on time-series signals or connectome features, we propose a novel graph-based pre-training paradigm for constructing a brain graph foundation model. In this paper, we introduce the Brain Graph Foundation Model, termed BrainGFM, a unified framework that leverages graph contrastive learning and graph masked autoencoders for large-scale fMRI-based pre-training. BrainGFM is pre-trained on a diverse mixture of brain atlases with varying parcellations, significantly expanding the pre-training corpus and enhancing the model's ability to generalize across heterogeneous fMRI-derived brain representations. To support efficient and versatile downstream transfer, we integrate both graph prompts and language prompts into the model design, enabling BrainGFM to flexibly adapt to a wide range of atlases, neurological and psychiatric disorders, and task settings. Furthermore, we employ meta-learning to optimize the graph prompts, facilitating strong generalization to previously unseen disorders under both few-shot and zero-shot learning conditions via language-guided prompting. BrainGFM is pre-trained on 27 neuroimaging datasets spanning 25 common neurological and psychiatric disorders, encompassing 2 types of brain atlases (functional and anatomical) across 8 widely-used parcellations, and covering over 25,000 subjects, 60,000 fMRI scans, and a total of 400,000 graph samples aggregated across all atlases and parcellations. The code is available at: https://github.com/weixinxu666/BrainGFM
        ]]></description>
    </item>
    <item>
        <title>Hierarchical Reasoning Model</title>
        <link>https://arxiv.org/abs/2506.21734</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.21734v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Guan Wang, Jin Li, Yuhao Sun, Xing Chen, Changling Liu, Yue Wu, Meng Lu, Sen Song, Yasin Abbasi Yadkori</dc:creator>
        <description><![CDATA[
            当前大语言模型的思维链技术在推理任务中存在任务分解脆弱、数据需求大、延迟高等问题。为此，本文受人类大脑分层和多时间尺度处理机制启发，提出分层推理模型（HRM）。该模型通过两个相互依存的循环模块在单次前向传播中执行顺序推理任务。仅2700万个参数的HRM，用1000个训练样本就在复杂推理任务中表现出色，在多项挑战性任务中近乎完美，还在ARC基准测试中超越大模型，具有变革潜力。
            arXiv:2506.21734v3 Announce Type: replace-cross 
Abstract: Reasoning, the process of devising and executing complex goal-oriented action sequences, remains a critical challenge in AI. Current large language models (LLMs) primarily employ Chain-of-Thought (CoT) techniques, which suffer from brittle task decomposition, extensive data requirements, and high latency. Inspired by the hierarchical and multi-timescale processing in the human brain, we propose the Hierarchical Reasoning Model (HRM), a novel recurrent architecture that attains significant computational depth while maintaining both training stability and efficiency. HRM executes sequential reasoning tasks in a single forward pass without explicit supervision of the intermediate process, through two interdependent recurrent modules: a high-level module responsible for slow, abstract planning, and a low-level module handling rapid, detailed computations. With only 27 million parameters, HRM achieves exceptional performance on complex reasoning tasks using only 1000 training samples. The model operates without pre-training or CoT data, yet achieves nearly perfect performance on challenging tasks including complex Sudoku puzzles and optimal path finding in large mazes. Furthermore, HRM outperforms much larger models with significantly longer context windows on the Abstraction and Reasoning Corpus (ARC), a key benchmark for measuring artificial general intelligence capabilities. These results underscore HRM's potential as a transformative advancement toward universal computation and general-purpose reasoning systems.
        ]]></description>
    </item>
    <item>
        <title>Automated Label Placement on Maps via Large Language Models</title>
        <link>https://arxiv.org/abs/2507.22952</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.22952v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Harry Shomer, Jiejun Xu</dc:creator>
        <description><![CDATA[
            地图标签放置是地图设计关键环节，当前多为手动操作且难扩展，现有自动系统难以融入制图规范、适应上下文或解读标注指令。本文提出将自动标签放置任务转化为数据编辑问题，利用大语言模型进行上下文感知空间标注的新范式。构建MAPLE基准数据集，采用检索增强生成（RAG）获取地标标签指南并融入提示，用指令调优的大语言模型生成标签坐标。评估四个开源大语言模型，结果表明其能在结构化提示和特定领域检索引导下，使输出符合制图标准，为地图绘制及结构化数据编辑提供了可扩展框架。
            arXiv:2507.22952v2 Announce Type: replace-cross 
Abstract: Label placement is a critical aspect of map design, serving as a form of spatial annotation that directly impacts clarity and interpretability. Despite its importance, label placement remains largely manual and difficult to scale, as existing automated systems struggle to integrate cartographic conventions, adapt to context, or interpret labeling instructions. In this work, we introduce a new paradigm for automatic label placement (ALP) that formulates the task as a data editing problem and leverages large language models (LLMs) for context-aware spatial annotation. To support this direction, we curate MAPLE, the first known benchmarking dataset for evaluating ALP on real-world maps, encompassing diverse landmark types and label placement annotations from open-source data. Our method retrieves labeling guidelines relevant to each landmark type leveraging retrieval-augmented generation (RAG), integrates them into prompts, and employs instruction-tuned LLMs to generate ideal label coordinates. We evaluate four open-source LLMs on MAPLE, analyzing both overall performance and generalization across different types of landmarks. This includes both zero-shot and instruction-tuned performance. Our results demonstrate that LLMs, when guided by structured prompts and domain-specific retrieval, can learn to perform accurate spatial edits, aligning the generated outputs with expert cartographic standards. Overall, our work presents a scalable framework for AI-assisted map finishing and demonstrates the potential of foundation models in structured data editing tasks. The code and data can be found at https://github.com/HarryShomer/MAPLE.
        ]]></description>
    </item>
    <item>
        <title>Hearing More with Less: Multi-Modal Retrieval-and-Selection Augmented Conversational LLM-Based ASR</title>
        <link>https://arxiv.org/abs/2508.01166</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01166v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Bingshen Mu, Hexin Liu, Hongfei Xue, Kun Wei, Lei Xie</dc:creator>
        <description><![CDATA[
            自动语音识别（ASR）在对话场景中利用上下文可提升准确率，基于大语言模型的ASR（LLM - ASR）可利用历史上下文识别对话语音，但现有方法存在大量无关冗余信息，导致识别混乱和计算成本高。本文提出多模态检索与选择方法MARS，先进行多模态检索获取候选历史上下文，再进行多模态选择选出最佳历史上下文。在Interspeech 2025数据集上评估显示，仅用1.5K小时数据训练且配备MARS的LLM - ASR，优于用179K小时数据训练的现有最优系统。
            arXiv:2508.01166v1 Announce Type: new 
Abstract: Automatic Speech Recognition (ASR) aims to convert human speech content into corresponding text. In conversational scenarios, effectively utilizing context can enhance its accuracy. Large Language Models' (LLMs) exceptional long-context understanding and reasoning abilities enable LLM-based ASR (LLM-ASR) to leverage historical context for recognizing conversational speech, which has a high degree of contextual relevance. However, existing conversational LLM-ASR methods use a fixed number of preceding utterances or the entire conversation history as context, resulting in significant ASR confusion and computational costs due to massive irrelevant and redundant information. This paper proposes a multi-modal retrieval-and-selection method named MARS that augments conversational LLM-ASR by enabling it to retrieve and select the most relevant acoustic and textual historical context for the current utterance. Specifically, multi-modal retrieval obtains a set of candidate historical contexts, each exhibiting high acoustic or textual similarity to the current utterance. Multi-modal selection calculates the acoustic and textual similarities for each retrieved candidate historical context and, by employing our proposed near-ideal ranking method to consider both similarities, selects the best historical context. Evaluations on the Interspeech 2025 Multilingual Conversational Speech Language Model Challenge dataset show that the LLM-ASR, when trained on only 1.5K hours of data and equipped with the MARS, outperforms the state-of-the-art top-ranking system trained on 179K hours of data.
        ]]></description>
    </item>
    <item>
        <title>Advancing the Foundation Model for Music Understanding</title>
        <link>https://arxiv.org/abs/2508.01178</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01178v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yi Jiang, Wei Wang, Xianwen Guo, Huiyun Liu, Hanrui Wang, Youri Xu, Haoqi Gu, Zhongqian Xie, Chuanjiang Luo</dc:creator>
        <description><![CDATA[
            音乐信息检索领域碎片化，各模型专注单一任务。本文提出统一基础模型MuFun用于整体音乐理解，其架构可联合处理乐器和歌词内容，并在涵盖流派分类、音乐标签和问答等多样任务的大规模数据集上训练。同时提出新的多面音乐理解基准MuCUE。实验表明，该模型在MuCUE任务中显著优于现有音频大语言模型，展现出先进的有效性和泛化能力。
            arXiv:2508.01178v1 Announce Type: new 
Abstract: The field of Music Information Retrieval (MIR) is fragmented, with specialized models excelling at isolated tasks. In this work, we challenge this paradigm by introducing a unified foundation model named MuFun for holistic music understanding. Our model features a novel architecture that jointly processes instrumental and lyrical content, and is trained on a large-scale dataset covering diverse tasks such as genre classification, music tagging, and question answering. To facilitate robust evaluation, we also propose a new benchmark for multi-faceted music understanding called MuCUE (Music Comprehensive Understanding Evaluation). Experiments show our model significantly outperforms existing audio large language models across the MuCUE tasks, demonstrating its state-of-the-art effectiveness and generalization ability.
        ]]></description>
    </item>
    <item>
        <title>Foundation Models for Bioacoustics -- a Comparative Review</title>
        <link>https://arxiv.org/abs/2508.01277</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01277v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Raphael Schwinger, Paria Vali Zadeh, Lukas Rauch, Mats Kurz, Tom Hauschild, Sam Lapp, Sven Tomforde</dc:creator>
        <description><![CDATA[
            这是一篇关于生物声学基础模型的综述文章。背景是自动化生物声学分析对生物多样性监测和保护至关重要，需先进深度学习模型。方法上，全面回顾大规模预训练生物声学基础模型，研究其在多分类任务中的可迁移性，还评估所选模型在BEANS和BirdSet基准分类任务上的表现。效果显示，BirdMAE在BirdSet基准上表现最佳，BEATs$_{NLM}$在BEANS上稍优，这些发现为从业者选择合适模型提供指导。
            arXiv:2508.01277v1 Announce Type: new 
Abstract: Automated bioacoustic analysis is essential for biodiversity monitoring and conservation, requiring advanced deep learning models that can adapt to diverse bioacoustic tasks. This article presents a comprehensive review of large-scale pretrained bioacoustic foundation models and systematically investigates their transferability across multiple bioacoustic classification tasks. We overview bioacoustic representation learning including major pretraining data sources and benchmarks. On this basis, we review bioacoustic foundation models by thoroughly analysing design decisions such as model architecture, pretraining scheme, and training paradigm. Additionally, we evaluate selected foundation models on classification tasks from the BEANS and BirdSet benchmarks, comparing the generalisability of learned representations under both linear and attentive probing strategies. Our comprehensive experimental analysis reveals that BirdMAE, trained on large-scale bird song data with a self-supervised objective, achieves the best performance on the BirdSet benchmark. On BEANS, BEATs$_{NLM}$, the extracted encoder of the NatureLM-audio large audio model, is slightly better. Both transformer-based models require attentive probing to extract the full performance of their representations. ConvNext$_{BS}$ and Perch models trained with supervision on large-scale bird song data remain competitive for passive acoustic monitoring classification tasks of BirdSet in linear probing settings. Training a new linear classifier has clear advantages over evaluating these models without further training. While on BEANS, the baseline model BEATs trained with self-supervision on AudioSet outperforms bird-specific models when evaluated with attentive probing. These findings provide valuable guidance for practitioners selecting appropriate models to adapt them to new bioacoustic classification tasks via probing.
        ]]></description>
    </item>
    <item>
        <title>Via Score to Performance: Efficient Human-Controllable Long Song Generation with Bar-Level Symbolic Notation</title>
        <link>https://arxiv.org/abs/2508.01394</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01394v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tongxi Wang, Yang Yu, Qing Wang, Junlang Qian</dc:creator>
        <description><![CDATA[
            歌曲生成是音乐AIGC中极具挑战的问题，现有方法存在可控性、泛化性、感知质量和时长等方面的局限，原因在于直接从原始音频学习音乐理论难度大。为此，研究人员提出Bar - level AI Composing Helper（BACH）模型，它通过可编辑的符号乐谱生成歌曲，采用适合层次化歌曲结构的分词策略和符号生成程序。实验表明，小模型规模的BACH在效率、时长和感知质量上表现出色，成为公开报道系统中的新SOTA，超越商业方案，且在多主观指标上获人类评估认可。
            arXiv:2508.01394v1 Announce Type: new 
Abstract: Song generation is regarded as the most challenging problem in music AIGC; nonetheless, existing approaches have yet to fully overcome four persistent limitations: controllability, generalizability, perceptual quality, and duration. We argue that these shortcomings stem primarily from the prevailing paradigm of attempting to learn music theory directly from raw audio, a task that remains prohibitively difficult for current models. To address this, we present Bar-level AI Composing Helper (BACH), the first model explicitly designed for song generation through human-editable symbolic scores. BACH introduces a tokenization strategy and a symbolic generative procedure tailored to hierarchical song structure. Consequently, it achieves substantial gains in the efficiency, duration, and perceptual quality of song generation. Experiments demonstrate that BACH, with a small model size, establishes a new SOTA among all publicly reported song generation systems, even surpassing commercial solutions such as Suno. Human evaluations further confirm its superiority across multiple subjective metrics.
        ]]></description>
    </item>
    <item>
        <title>Lumename: Wearable Device for Hearing Impaired with Personalized ML-Based Auditory Detection and Haptic-Visual Alerts</title>
        <link>https://arxiv.org/abs/2508.01576</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01576v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jeanelle Dao, Jadelynn Dao</dc:creator>
        <description><![CDATA[
            背景：世界卫生组织指出，4.3亿人有听力障碍，难以识别语音指令。方法：Lumename智能手表利用设备端机器学习检测用户自定义名字并发出触觉-视觉警报；训练时采用新型音频调制技术扩充样本，用受限随机迭代寻找模型架构的最优参数。效果：构建了低资源、低功耗的TinyML模型，能快速推断各种关键词样本，在基于Arduino Nano 33 BLE Sense的定制智能手表上准确率达91.67%。
            arXiv:2508.01576v1 Announce Type: new 
Abstract: According to the World Health Organization, 430 million people experience disabling hearing loss. For them, recognizing spoken commands such as one's name is difficult. To address this issue, Lumename, a real-time smartwatch, utilizes on-device machine learning to detect a user-customized name before generating a haptic-visual alert. During training, to overcome the need for large datasets, Lumename uses novel audio modulation techniques to augment samples from one user and generate additional samples to represent diverse genders and ages. Constrained random iterations were used to find optimal parameters within the model architecture. This approach resulted in a low-resource and low-power TinyML model that could quickly infer various keyword samples while remaining 91.67\% accurate on a custom-built smartwatch based on an Arduino Nano 33 BLE Sense.
        ]]></description>
    </item>
    <item>
        <title>From Contrast to Commonality: Audio Commonality Captioning for Enhanced Audio-Text Cross-modal Understanding in Multimodal LLMs</title>
        <link>https://arxiv.org/abs/2508.01659</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01659v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuhang Jia, Xu Zhang, Yong Qin</dc:creator>
        <description><![CDATA[
            音频字幕（AC）对多模态大语言模型（MLLMs）的预训练和微调中的音频 - 文本跨模态理解至关重要。近期音频差异字幕（ADC）虽促进细粒度音频区分，但造成输入音频与输出字幕的语义差距，导致微调时灾难性遗忘。为此，提出音频共性字幕（ACC），鼓励模型捕捉音频片段的共享语义。实验表明，ACC不仅有效提升主要字幕基准上的音频 - 文本理解，在语音和音乐相关下游任务中也能更好保留通用能力，实现了泛化与特定任务性能的更好平衡。
            arXiv:2508.01659v1 Announce Type: new 
Abstract: Audio Captioning (AC) plays a pivotal role in enhancing audio-text cross-modal understanding during the pretraining and finetuning of multimodal large language models (MLLMs). To further strengthen this alignment, recent works have proposed Audio Difference Captioning (ADC), which takes multiple audio inputs and encourages the model to describe their differences, thereby promoting fine-grained audio discrimination. However, despite its effectiveness in enabling difference-telling and detailed discrimination, ADC introduces a notable semantic gap between the input audios-often rich in diverse sound events-and the relatively brief, difference-focused output captions. This deviation from AC-style descriptions leads to a mismatch with the pretraining objective, resulting in catastrophic forgetting during finetuning. To mitigate this issue, we propose Audio Commonality Captioning (ACC), a comparably challenging but gentler alternative that encourages the model to capture the shared semantics across audio clips rather than emphasizing their detailed differences. Experimental results demonstrate that ACC not only effectively enhances audio-text understanding on primary captioning benchmarks but also better preserves general capabilities across diverse speech and music-related downstream tasks, such as vocal sound classification (VSC), speech emotion recognition (SER), musical instrument classification (MIC), and music genre classification (MGC), compared to ADC. These findings validate that ACC contributes to more robust cross-modal understanding and achieves a better balance between generalization and task-specific performance in the context of MLLMs.
        ]]></description>
    </item>
    <item>
        <title>Enhancing Spectrogram Realism in Singing Voice Synthesis via Explicit Bandwidth Extension Prior to Vocoder</title>
        <link>https://arxiv.org/abs/2508.01796</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01796v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Runxuan Yang, Kai Li, Guo Chen, Xiaolin Hu</dc:creator>
        <description><![CDATA[
            背景：当前声码器生成的歌声音频在高频频谱分量上与真实录音有明显差异，影响音频真实感。方法：结合两项创新，一是用基于DiT架构的去噪扩散过程进行线性频谱图估计，二是重新设计基于Vocos的声码器处理高频谱分量。效果：生成的音频频谱图高保真，人耳和机器分类器都难以区分其与真实录音，客观和主观评估显示该方法在保证音质的同时提升了真实感，克服了现有声码技术的局限。
            arXiv:2508.01796v1 Announce Type: new 
Abstract: This paper addresses the challenge of enhancing the realism of vocoder-generated singing voice audio by mitigating the distinguishable disparities between synthetic and real-life recordings, particularly in high-frequency spectrogram components. Our proposed approach combines two innovations: an explicit linear spectrogram estimation step using denoising diffusion process with DiT-based neural network architecture optimized for time-frequency data, and a redesigned vocoder based on Vocos specialized in handling large linear spectrograms with increased frequency bins. This integrated method can produce audio with high-fidelity spectrograms that are challenging for both human listeners and machine classifiers to differentiate from authentic recordings. Objective and subjective evaluations demonstrate that our streamlined approach maintains high audio quality while achieving this realism. This work presents a substantial advancement in overcoming the limitations of current vocoding techniques, particularly in the context of adversarial attacks on fake spectrogram detection.
        ]]></description>
    </item>
    <item>
        <title>Unsupervised Multi-channel Speech Dereverberation via Diffusion</title>
        <link>https://arxiv.org/abs/2508.02071</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.02071v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yulun Wu, Zhongweiyang Xu, Jianchong Chen, Zhong-Qiu Wang, Romit Roy Choudhury</dc:creator>
        <description><![CDATA[
            本文聚焦多通道单说话人盲去混响问题，即利用多通道混合信号恢复干净无回声语音。为此提出USD - DPS方法，借助无条件干净语音扩散模型作为强先验，通过后验采样解决问题。在每个扩散采样步骤中，估计各麦克风通道的房间脉冲响应（RIR），并用于实施多通道混合一致性约束。多通道RIR估计时，用Adam优化器优化子带RIR信号模型参数估计参考通道RIR，用前向卷积预测（FCP）解析估计非参考通道RIR。该方法在采样效率和RIR先验建模间取得平衡，在无监督去混响方法中表现出色。
            arXiv:2508.02071v1 Announce Type: new 
Abstract: We consider the problem of multi-channel single-speaker blind dereverberation, where multi-channel mixtures are used to recover the clean anechoic speech. To solve this problem, we propose USD-DPS, {U}nsupervised {S}peech {D}ereverberation via {D}iffusion {P}osterior {S}ampling. USD-DPS uses an unconditional clean speech diffusion model as a strong prior to solve the problem by posterior sampling. At each diffusion sampling step, we estimate all microphone channels' room impulse responses (RIRs), which are further used to enforce a multi-channel mixture consistency constraint for diffusion guidance. For multi-channel RIR estimation, we estimate reference-channel RIR by optimizing RIR parameters of a sub-band RIR signal model, with the Adam optimizer. We estimate non-reference channels' RIRs analytically using forward convolutive prediction (FCP). We found that this combination provides a good balance between sampling efficiency and RIR prior modeling, which shows superior performance among unsupervised dereverberation approaches. An audio demo page is provided in https://usddps.github.io/USDDPS_demo/.
        ]]></description>
    </item>
    <item>
        <title>Hidden in the Noise: Unveiling Backdoors in Audio LLMs Alignment through Latent Acoustic Pattern Triggers</title>
        <link>https://arxiv.org/abs/2508.02175</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.02175v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Liang Lin, Miao Yu, Kaiwen Luo, Yibo Zhang, Lilan Peng, Dexian Wang, Xuehai Tang, Yuanhe Zhang, Xikang Yang, Zhenhong Zhou, Kun Wang, Yang Liu</dc:creator>
        <description><![CDATA[
            随着音频大语言模型（ALLMs）用于语音处理，其安全问题亟待关注。现有研究多聚焦文本和视觉安全，而音频特性带来新挑战。本文提出“Hidden in the Noise”（HIN）后门攻击框架，通过修改原始音频波形，如改变时间动态、注入定制噪声，嵌入触发模式。同时开发AudioSafe基准评估ALLMs对基于音频特征触发器的鲁棒性。实验表明，现有ALLMs存在关键漏洞，环境噪声等音频特征平均攻击成功率超90%，对不同声学特征敏感度不同，攻击隐蔽性强。
            arXiv:2508.02175v1 Announce Type: new 
Abstract: As Audio Large Language Models (ALLMs) emerge as powerful tools for speech processing, their safety implications demand urgent attention. While considerable research has explored textual and vision safety, audio's distinct characteristics present significant challenges. This paper first investigates: Is ALLM vulnerable to backdoor attacks exploiting acoustic triggers? In response to this issue, we introduce Hidden in the Noise (HIN), a novel backdoor attack framework designed to exploit subtle, audio-specific features. HIN applies acoustic modifications to raw audio waveforms, such as alterations to temporal dynamics and strategic injection of spectrally tailored noise. These changes introduce consistent patterns that an ALLM's acoustic feature encoder captures, embedding robust triggers within the audio stream. To evaluate ALLM robustness against audio-feature-based triggers, we develop the AudioSafe benchmark, assessing nine distinct risk types. Extensive experiments on AudioSafe and three established safety datasets reveal critical vulnerabilities in existing ALLMs: (I) audio features like environment noise and speech rate variations achieve over 90% average attack success rate. (II) ALLMs exhibit significant sensitivity differences across acoustic features, particularly showing minimal response to volume as a trigger, and (III) poisoned sample inclusion causes only marginal loss curve fluctuations, highlighting the attack's stealth.
        ]]></description>
    </item>
    <item>
        <title>Inference-time Scaling for Diffusion-based Audio Super-resolution</title>
        <link>https://arxiv.org/abs/2508.02391</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.02391v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yizhu Jin, Zhen Ye, Zeyue Tian, Haohe Liu, Qiuqiang Kong, Yike Guo, Wei Xue</dc:creator>
        <description><![CDATA[
            这是一篇关于基于扩散模型的音频超分辨率研究。背景是现有扩散方法增加采样步数提升质量效果有限。方法上，提出推理时缩放范式，探索多个解轨迹，开发任务特定验证器，引入随机搜索和零阶搜索两种算法，通过验证器 - 算法组合引导高维解空间探索。效果显著，在多种音频领域和频率范围验证，语音超分辨率从4kHz到24kHz时，美学提升达9.70%，说话人相似度提升5.88%，字错误率改善15.20%，频谱距离改善46.98%。
            arXiv:2508.02391v1 Announce Type: new 
Abstract: Diffusion models have demonstrated remarkable success in generative tasks, including audio super-resolution (SR). In many applications like movie post-production and album mastering, substantial computational budgets are available for achieving superior audio quality. However, while existing diffusion approaches typically increase sampling steps to improve quality, the performance remains fundamentally limited by the stochastic nature of the sampling process, leading to high-variance and quality-limited outputs. Here, rather than simply increasing the number of sampling steps, we propose a different paradigm through inference-time scaling for SR, which explores multiple solution trajectories during the sampling process. Different task-specific verifiers are developed, and two search algorithms, including the random search and zero-order search for SR, are introduced. By actively guiding the exploration of the high-dimensional solution space through verifier-algorithm combinations, we enable more robust and higher-quality outputs. Through extensive validation across diverse audio domains (speech, music, sound effects) and frequency ranges, we demonstrate consistent performance gains, achieving improvements of up to 9.70% in aesthetics, 5.88% in speaker similarity, 15.20% in word error rate, and 46.98% in spectral distance for speech SR from 4kHz to 24kHz, showcasing the effectiveness of our approach. Audio samples are available at: https://racerk.github.io/tt-scale-audiosr/.
        ]]></description>
    </item>
    <item>
        <title>EgoTrigger: Toward Audio-Driven Image Capture for Human Memory Enhancement in All-Day Energy-Efficient Smart Glasses</title>
        <link>https://arxiv.org/abs/2508.01915</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.01915v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Akshay Paruchuri, Sinan Hersek, Lavisha Aggarwal, Qiao Yang, Xin Liu, Achin Kulshrestha, Andrea Colaco, Henry Fuchs, Ishan Chatterjee</dc:creator>
        <description><![CDATA[
            背景：全天使用的智能眼镜在集成多模态AI以增强人类记忆时，面临能源效率挑战。方法：提出EgoTrigger方法，利用麦克风音频线索选择性激活高能耗相机，采用轻量级音频模型YAMNet和自定义分类头，依据手与物体交互音频线索触发图像捕捉，并在两个数据集上评估。效果：EgoTrigger平均可减少54%的帧数，显著节省能耗，在情景记忆任务数据集上表现相当，为实现全天可用的节能智能眼镜提供了方向。
            arXiv:2508.01915v1 Announce Type: cross 
Abstract: All-day smart glasses are likely to emerge as platforms capable of continuous contextual sensing, uniquely positioning them for unprecedented assistance in our daily lives. Integrating the multi-modal AI agents required for human memory enhancement while performing continuous sensing, however, presents a major energy efficiency challenge for all-day usage. Achieving this balance requires intelligent, context-aware sensor management. Our approach, EgoTrigger, leverages audio cues from the microphone to selectively activate power-intensive cameras, enabling efficient sensing while preserving substantial utility for human memory enhancement. EgoTrigger uses a lightweight audio model (YAMNet) and a custom classification head to trigger image capture from hand-object interaction (HOI) audio cues, such as the sound of a drawer opening or a medication bottle being opened. In addition to evaluating on the QA-Ego4D dataset, we introduce and evaluate on the Human Memory Enhancement Question-Answer (HME-QA) dataset. Our dataset contains 340 human-annotated first-person QA pairs from full-length Ego4D videos that were curated to ensure that they contained audio, focusing on HOI moments critical for contextual understanding and memory. Our results show EgoTrigger can use 54% fewer frames on average, significantly saving energy in both power-hungry sensing components (e.g., cameras) and downstream operations (e.g., wireless transmission), while achieving comparable performance on datasets for an episodic memory task. We believe this context-aware triggering strategy represents a promising direction for enabling energy-efficient, functional smart glasses capable of all-day use -- supporting applications like helping users recall where they placed their keys or information about their routine activities (e.g., taking medications).
        ]]></description>
    </item>
    <item>
        <title>Marco-Voice Technical Report</title>
        <link>https://arxiv.org/abs/2508.02038</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.02038v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Fengping Tian, Chenyang Lyu, Xuanfan Ni, Haoqin Sun, Qingjuan Li, Zhiqiang Qian, Haijun Li, Longyue Wang, Zhao Xu, Weihua Luo, Kaifu Zhang</dc:creator>
        <description><![CDATA[
            背景：长期以来，实现高表现力、可控制且自然的语音生成，并在不同语言和情感语境中保留说话者身份存在挑战。方法：提出一种带批量内对比学习的有效说话者 - 情感解缠机制，实现对说话者身份和情感风格的独立操控，还采用旋转情感嵌入集成方法实现平滑情感控制，构建高质量情感语音数据集CSEMOTIONS。效果：系统Marco - Voice在主客观指标上均有显著提升，在语音清晰度和情感丰富度方面表现出色。
            arXiv:2508.02038v1 Announce Type: cross 
Abstract: This paper presents a multifunctional speech synthesis system that integrates voice cloning and emotion control speech synthesis within a unified framework. The goal of this work is to address longstanding challenges in achieving highly expressive, controllable, and natural speech generation that faithfully preserves speaker identity across diverse linguistic and emotional contexts. Our approach introduces an effective speaker-emotion disentanglement mechanism with in-batch contrastive learning, enabling independent manipulation of speaker identity and eemotional style, as well as rotational emotional embedding integration method for smooth emotion control. To support comprehensive training and evaluation, we construct CSEMOTIONS, a high-quality emotional speech dataset containing 10 hours of Mandarin speech from six professional speakers across seven emotional categories. Extensive experiments demonstrate that our system, Marco-Voice, achieves substantial improvements in both objective and subjective metrics. Comprehensive evaluations and analysis were conducted, results show that MarcoVoice delivers competitive performance in terms of speech clarity and emotional richness, representing a substantial advance in the field of expressive neural speech synthesis.
        ]]></description>
    </item>
    <item>
        <title>CAK: Emergent Audio Effects from Minimal Deep Learning</title>
        <link>https://arxiv.org/abs/2508.02643</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.02643v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Austin Rockman</dc:creator>
        <description><![CDATA[
            本文背景是探索从少量数据中发现音频变换。方法上，通过两种关键技术实现：一是条件感知核（CAK），采用输出 = 输入 +（学习模式×控制）的方式，有软门机制支持零控制时保留特征；二是AuGAN，将对抗训练从判断真伪转变为验证是否应用指定值。效果方面，学习到的核呈对角结构，能根据输入特征产生频率相关的时间偏移和音乐效果，展示了对抗训练从少量数据发现音频变换的潜力，为效果设计提供新途径。
            arXiv:2508.02643v1 Announce Type: cross 
Abstract: We demonstrate that a single 3x3 convolutional kernel can produce emergent audio effects when trained on 200 samples from a personalized corpus. We achieve this through two key techniques: (1) Conditioning Aware Kernels (CAK), where output = input + (learned_pattern x control), with a soft-gate mechanism supporting identity preservation at zero control; and (2) AuGAN (Audit GAN), which reframes adversarial training from "is this real?" to "did you apply the requested value?" Rather than learning to generate or detect forgeries, our networks cooperate to verify control application, discovering unique transformations. The learned kernel exhibits a diagonal structure creating frequency-dependent temporal shifts that are capable of producing musical effects based on input characteristics. Our results show the potential of adversarial training to discover audio transformations from minimal data, enabling new approaches to effect design.
        ]]></description>
    </item>
    <item>
        <title>Benchmarking Sub-Genre Classification For Mainstage Dance Music</title>
        <link>https://arxiv.org/abs/2409.06690</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2409.06690v3</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hongzhi Shu, Xinglin Li, Hongyu Jiang, Minghao Fu, Xinyu Li</dc:creator>
        <description><![CDATA[
            音乐分类是音乐信息检索的基础，现有主舞台舞曲子流派分类缺乏全面数据集与有效方法。为此，本文引入新基准，包含新数据集与基线模型。数据集扩大子流派范围，反映全球音乐节中主舞台电子舞曲的多样性。采用连续软标签法处理融合多子流派的曲目。实验表明，即使是最先进的多模态大语言模型也难以完成此任务，而专门的基线模型能达到较高准确率。该基准可用于音乐推荐等应用，代码和数据已开源。
            arXiv:2409.06690v3 Announce Type: replace 
Abstract: Music classification, a cornerstone of music information retrieval, supports a wide array of applications. To address the lack of comprehensive datasets and effective methods for sub-genre classification in mainstage dance music, we introduce a novel benchmark featuring a new dataset and baseline. Our dataset expands the scope of sub-genres to reflect the diversity of recent mainstage live sets performed by leading DJs at global music festivals, capturing the vibrant and rapidly evolving electronic dance music (EDM) scene that engages millions of fans worldwide. We employ a continuous soft labeling approach to accommodate tracks blending multiple sub-genres, preserving their inherent complexity. Experiments demonstrate that even state-of-the-art multimodal large language models (MLLMs) struggle with this task, while our specialized baseline models achieve high accuracy. This benchmark supports applications such as music recommendation, DJ set curation, and interactive multimedia systems, with video demos provided. Our code and data are all open-sourced at https://github.com/Gariscat/housex-v2.git.
        ]]></description>
    </item>
    <item>
        <title>Token Pruning in Audio Transformers: Optimizing Performance and Decoding Patch Importance</title>
        <link>https://arxiv.org/abs/2504.01690</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.01690v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Taehan Lee, Hyukjun Lee</dc:creator>
        <description><![CDATA[
            背景：视觉Transformer在计算机视觉任务中表现出色，但计算成本高，令牌剪枝可降低成本，然而应用到音频任务有挑战。方法：首次将令牌剪枝应用于基于ViT的音频分类模型，分析模型性能和计算成本的权衡。效果：TopK令牌剪枝可使AudioMAE和AST的MAC操作减少30 - 40%，准确率下降不到1%。研究还揭示了不同强度和变化的令牌对模型的重要性，以及AudioMAE和AST保留低强度令牌的差异。
            arXiv:2504.01690v2 Announce Type: replace 
Abstract: Vision Transformers (ViTs) have achieved state-of-the-art performance across various computer vision tasks, but their high computational cost remains a challenge. Token pruning has been proposed to reduce this cost by selectively removing less important tokens. While effective in vision tasks by discarding non-object regions, applying this technique to audio tasks presents unique challenges, as distinguishing relevant from irrelevant regions in time-frequency representations is less straightforward. In this study, for the first time, we applied token pruning to ViT-based audio classification models using Mel-spectrograms and analyzed the trade-offs between model performance and computational cost: TopK token pruning can reduce MAC operations of AudioMAE and AST by 30-40%, with less than a 1% drop in accuracy. Our analysis reveals that while high-intensity or high-variation tokens contribute significantly to model accuracy, low-intensity or low variation tokens also remain important when token pruning is applied; pruning solely based on the intensity or variation of signals in a patch leads to a noticeable drop in accuracy. We support our claim by measuring high correlation between attention scores and these statistical features and by showing retained tokens consistently receive distinct attention compared to pruned ones. We also show that AudioMAE retains more low-intensity tokens than AST. This can be explained by AudioMAE's self-supervised reconstruction objective, which encourages attention to all patches, whereas AST's supervised training focuses on label-relevant tokens.
        ]]></description>
    </item>
    <item>
        <title>VoiceCloak: A Multi-Dimensional Defense Framework against Unauthorized Diffusion-based Voice Cloning</title>
        <link>https://arxiv.org/abs/2505.12332</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12332v3</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qianyue Hu, Junyan Wu, Wei Lu, Xiangyang Luo</dc:creator>
        <description><![CDATA[
            这是一篇关于音频生成领域的研究。背景是扩散模型在语音克隆取得成功的同时也带来恶意滥用风险，现有防御方法与扩散模型不兼容。方法上，提出多维主动防御框架VoiceCloak，通过分析扩散模型漏洞，在参考音频中引入对抗扰动，如扭曲表征学习嵌入、破坏条件引导过程、放大分数幅度、采用噪声引导语义破坏等。效果上，大量实验表明该框架在抵御基于扩散的非法语音克隆方面有出色的成功率。
            arXiv:2505.12332v3 Announce Type: replace 
Abstract: Diffusion Models (DMs) have achieved remarkable success in realistic voice cloning (VC), while they also increase the risk of malicious misuse. Existing proactive defenses designed for traditional VC models aim to disrupt the forgery process, but they have been proven incompatible with DMs due to the intricate generative mechanisms of diffusion. To bridge this gap, we introduce VoiceCloak, a multi-dimensional proactive defense framework with the goal of obfuscating speaker identity and degrading perceptual quality in potential unauthorized VC. To achieve these goals, we conduct a focused analysis to identify specific vulnerabilities within DMs, allowing VoiceCloak to disrupt the cloning process by introducing adversarial perturbations into the reference audio. Specifically, to obfuscate speaker identity, VoiceCloak first targets speaker identity by distorting representation learning embeddings to maximize identity variation, which is guided by auditory perception principles. Additionally, VoiceCloak disrupts crucial conditional guidance processes, particularly attention context, thereby preventing the alignment of vocal characteristics that are essential for achieving convincing cloning. Then, to address the second objective, VoiceCloak introduces score magnitude amplification to actively steer the reverse trajectory away from the generation of high-quality speech. Noise-guided semantic corruption is further employed to disrupt structural speech semantics captured by DMs, degrading output quality. Extensive experiments highlight VoiceCloak's outstanding defense success rate against unauthorized diffusion-based voice cloning. Audio samples of VoiceCloak are available at https://voice-cloak.github.io/VoiceCloak/.
        ]]></description>
    </item>
    <item>
        <title>Codec-Based Deepfake Source Tracing via Neural Audio Codec Taxonomy</title>
        <link>https://arxiv.org/abs/2505.12994</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12994v3</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xuanjun Chen, I-Ming Lin, Lin Zhang, Jiawei Du, Haibin Wu, Hung-yi Lee, Jyh-Shing Roger Jang</dc:creator>
        <description><![CDATA[
            背景：基于神经音频编解码器的语音生成模型（CoSG）产生了逼真的音频深度伪造，现有研究多关注验证音频样本真实性，鲜少追踪生成深度伪造的CoSG。方法：提出通过神经音频编解码器分类对基于编解码器的深度伪造语音（CodecFake）进行源追踪，剖析神经音频编解码器以追踪CoSG。效果：在CodecFake+数据集上的实验初步证明了CodecFake源追踪的可行性，同时也指出了一些待进一步研究的挑战。
            arXiv:2505.12994v3 Announce Type: replace 
Abstract: Recent advances in neural audio codec-based speech generation (CoSG) models have produced remarkably realistic audio deepfakes. We refer to deepfake speech generated by CoSG systems as codec-based deepfake, or CodecFake. Although existing anti-spoofing research on CodecFake predominantly focuses on verifying the authenticity of audio samples, almost no attention was given to tracing the CoSG used in generating these deepfakes. In CodecFake generation, processes such as speech-to-unit encoding, discrete unit modeling, and unit-to-speech decoding are fundamentally based on neural audio codecs. Motivated by this, we introduce source tracing for CodecFake via neural audio codec taxonomy, which dissects neural audio codecs to trace CoSG. Our experimental results on the CodecFake+ dataset provide promising initial evidence for the feasibility of CodecFake source tracing while also highlighting several challenges that warrant further investigation.
        ]]></description>
    </item>
    <item>
        <title>FedMLAC: Mutual Learning Driven Heterogeneous Federated Audio Classification</title>
        <link>https://arxiv.org/abs/2506.10207</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.10207v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jun Bai, Rajib Rana, Di Wu, Youyang Qu, Xiaohui Tao, Ji Zhang, Carlos Busso, Shivakumara Palaiahnakote</dc:creator>
        <description><![CDATA[
            这是一篇关于音频分类的论文。联邦音频分类面临数据异构、模型异构和数据中毒三大挑战，现有方法常分开处理，缺乏统一方案。为此，研究者提出FedMLAC框架，让各客户端维护个性化本地模型和轻量级全局插件模型，通过双向知识蒸馏交互，同时引入分层剪枝聚合策略对抗数据中毒。在四个音频分类基准测试中，该方法在分类准确率和抗噪数据鲁棒性上均优于现有方法。
            arXiv:2506.10207v2 Announce Type: replace 
Abstract: Federated Learning (FL) offers a privacy-preserving framework for training audio classification (AC) models across decentralized clients without sharing raw data. However, Federated Audio Classification (FedAC) faces three major challenges: data heterogeneity, model heterogeneity, and data poisoning, which degrade performance in real-world settings. While existing methods often address these issues separately, a unified and robust solution remains underexplored. We propose FedMLAC, a mutual learning-based FL framework that tackles all three challenges simultaneously. Each client maintains a personalized local AC model and a lightweight, globally shared Plug-in model. These models interact via bidirectional knowledge distillation, enabling global knowledge sharing while adapting to local data distributions, thus addressing both data and model heterogeneity. To counter data poisoning, we introduce a Layer-wise Pruning Aggregation (LPA) strategy that filters anomalous Plug-in updates based on parameter deviations during aggregation. Extensive experiments on four diverse audio classification benchmarks, including both speech and non-speech tasks, show that FedMLAC consistently outperforms state-of-the-art baselines in classification accuracy and robustness to noisy data.
        ]]></description>
    </item>
    <item>
        <title>Abstract Sound Fusion with Unconditional Inversion Models</title>
        <link>https://arxiv.org/abs/2506.11811</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.11811v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jing Liu, Enqi Lian, Moyao Deng</dc:creator>
        <description><![CDATA[
            本文聚焦音频生成领域。背景是抽象声音融合旨在合成原始声音和参考声音以产生新声音。方法上，采用能保留原始样本关键特征且实现可控合成的反演技术，提出基于DPMSolver++采样器的SDE和ODE反演模型，通过将模型输出设为常量来反转采样过程，消除噪声预测项带来的循环依赖。其反演方法无需提示条件，采样时能灵活引导，实现了特定的抽象声音融合效果。
            arXiv:2506.11811v2 Announce Type: replace 
Abstract: An abstract sound is defined as a sound that does not disclose identifiable real-world sound events to a listener. Sound fusion aims to synthesize an original sound and a reference sound to generate a novel sound that exhibits auditory features beyond mere additive superposition of the sound constituents. To achieve this fusion, we employ inversion techniques that preserve essential features of the original sample while enabling controllable synthesis. We propose novel SDE and ODE inversion models based on DPMSolver++ samplers that reverse the sampling process by configuring model outputs as constants, eliminating circular dependencies incurred by noise prediction terms. Our inversion approach requires no prompt conditioning while maintaining flexible guidance during sampling.
        ]]></description>
    </item>
    <item>
        <title>MECAT: A Multi-Experts Constructed Benchmark for Fine-Grained Audio Understanding Tasks</title>
        <link>https://arxiv.org/abs/2507.23511</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.23511v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yadong Niu, Tianzi Wang, Heinrich Dinkel, Xingwei Sun, Jiahao Zhou, Gang Li, Jizhong Liu, Xunying Liu, Junbo Zhang, Jian Luan</dc:creator>
        <description><![CDATA[
            当前大音频语言模型在开放式音频理解上虽有进展，但仍达不到人类细致理解水平，现有基准受数据标注和评估指标限制，难以区分通用和详细模型输出。为此，本文提出MECAT基准，通过整合专家模型分析和大语言模型推理生成，提供多视角、细粒度描述及问答对。还引入DATE评估指标，结合单样本语义相似度和跨样本可区分性。对现有音频模型进行评估，揭示其能力和局限。数据和代码可在指定链接获取。
            arXiv:2507.23511v2 Announce Type: replace 
Abstract: While large audio-language models have advanced open-ended audio understanding, they still fall short of nuanced human-level comprehension. This gap persists largely because current benchmarks, limited by data annotations and evaluation metrics, fail to reliably distinguish between generic and highly detailed model outputs. To this end, this work introduces MECAT, a Multi-Expert Constructed Benchmark for Fine-Grained Audio Understanding Tasks. Generated via a pipeline that integrates analysis from specialized expert models with Chain-of-Thought large language model reasoning, MECAT provides multi-perspective, fine-grained captions and open-set question-answering pairs. The benchmark is complemented by a novel metric: DATE (Discriminative-Enhanced Audio Text Evaluation). This metric penalizes generic terms and rewards detailed descriptions by combining single-sample semantic similarity with cross-sample discriminability. A comprehensive evaluation of state-of-the-art audio models is also presented, providing new insights into their current capabilities and limitations. The data and code are available at https://github.com/xiaomi-research/mecat
        ]]></description>
    </item>
    <item>
        <title>AudioGen-Omni: A Unified Multimodal Diffusion Transformer for Video-Synchronized Audio, Speech, and Song Generation</title>
        <link>https://arxiv.org/abs/2508.00733</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2508.00733v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Le Wang, Jun Wang, Feng Deng, Chen Zhang, Di Zhang, Kun Gai</dc:creator>
        <description><![CDATA[
            这是一篇关于音频生成的论文。背景是现有音频生成技术在多模态同步及语义丰富度上有不足。方法上，提出基于多模态扩散变换器的AudioGen - Omni，采用联合训练范式整合视频 - 文本 - 音频语料，用统一编码器编码输入，通过增强的联合注意力机制融合特征，还采用解除模态冻结和掩码缺失输入的方法。效果上，提升了音频质量、语义对齐和唇同步精度，在文本到音频等任务达最优，8秒音频推理时间1.91秒，效率和通用性显著提升。
            arXiv:2508.00733v2 Announce Type: replace 
Abstract: We present AudioGen-Omni - a unified approach based on multimodal diffusion transformers (MMDit), capable of generating high-fidelity audio, speech, and songs coherently synchronized with the input video. AudioGen-Omni introduces a novel joint training paradigm that seamlessly integrates large-scale video-text-audio corpora, enabling a model capable of generating semantically rich, acoustically diverse audio conditioned on multimodal inputs and adaptable to a wide range of audio generation tasks. AudioGen-Omni employs a unified lyrics-transcription encoder that encodes graphemes and phonemes from both sung and spoken inputs into dense frame-level representations. Dense frame-level representations are fused using an AdaLN-based joint attention mechanism enhanced with phase-aligned anisotropic positional infusion (PAAPI), wherein RoPE is selectively applied to temporally structured modalities to ensure precise and robust cross-modal alignment. By unfreezing all modalities and masking missing inputs, AudioGen-Omni mitigates the semantic constraints of text-frozen paradigms, enabling effective cross-modal conditioning. This joint training approach enhances audio quality, semantic alignment, and lip-sync accuracy, while also achieving state-of-the-art results on Text-to-Audio/Speech/Song tasks. With an inference time of 1.91 seconds for 8 seconds of audio, it offers substantial improvements in both efficiency and generality.
        ]]></description>
    </item>
</channel>
</rss>