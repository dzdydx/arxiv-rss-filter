<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
<channel>
    <title>arXiv Paper Filter</title>
    <link>https://github.com/None/arxiv_filter</link>
    <description>根据研究兴趣筛选的arXiv论文</description>
    <atom:link href="https://raw.githubusercontent.com/None/arxiv_filter/main/feed.xml" rel="self" type="application/rss+xml" />
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>zh-CN</language>
    <lastBuildDate>Tue, 29 Jul 2025 12:28:31 +0800</lastBuildDate>
    <managingEditor>None@github.com</managingEditor>
    <pubDate>Tue, 29 Jul 2025 12:28:31 +0800</pubDate>
    <skipDays>
        <day>Saturday</day>
        <day>Sunday</day>
    </skipDays>

    <item>
        <title>Language Models for Controllable DNA Sequence Design</title>
        <link>https://arxiv.org/abs/2507.19523</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.19523v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xingyu Su, Xiner Li, Yuchao Lin, Ziqian Xie, Degui Zhi, Shuiwang Ji</dc:creator>
        <description><![CDATA[
            背景：语言模型在自然语言生成中成果显著，但在DNA序列生成方面探索较少。方法：提出ATGC - Gen，利用跨模态编码集成多种生物信号，采用仅解码器和仅编码器的变压器架构，可在自回归或掩码恢复目标下灵活训练和生成。效果：在启动子和增强子序列设计等任务上评估，引入新数据集。实验表明其能生成符合期望属性的序列，与先前方法相比，在可控性和功能相关性上有显著提升，推动可编程基因组设计。
            arXiv:2507.19523v1 Announce Type: new 
Abstract: We consider controllable DNA sequence design, where sequences are generated by conditioning on specific biological properties. While language models (LMs) such as GPT and BERT have achieved remarkable success in natural language generation, their application to DNA sequence generation remains largely underexplored. In this work, we introduce ATGC-Gen, an Automated Transformer Generator for Controllable Generation, which leverages cross-modal encoding to integrate diverse biological signals. ATGC-Gen is instantiated with both decoder-only and encoder-only transformer architectures, allowing flexible training and generation under either autoregressive or masked recovery objectives. We evaluate ATGC-Gen on representative tasks including promoter and enhancer sequence design, and further introduce a new dataset based on ChIP-Seq experiments for modeling protein binding specificity. Our experiments demonstrate that ATGC-Gen can generate fluent, diverse, and biologically relevant sequences aligned with the desired properties. Compared to prior methods, our model achieves notable improvements in controllability and functional relevance, highlighting the potential of language models in advancing programmable genomic design. The source code is released at (https://github.com/divelab/AIRS/blob/main/OpenBio/ATGC_Gen).
        ]]></description>
    </item>
    <item>
        <title>MMCircuitEval: A Comprehensive Multimodal Circuit-Focused Benchmark for Evaluating LLMs</title>
        <link>https://arxiv.org/abs/2507.19525</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.19525v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chenchen Zhao, Zhengyuan Shi, Xiangyu Wen, Chengjie Liu, Yi Liu, Yunhao Zhou, Yuxiang Zhao, Hefei Feng, Yinan Zhu, Gwok-Waa Wan, Xin Cheng, Weiyu Chen, Yongqi Fu, Chujie Chen, Chenhao Xue, Guangyu Sun, Ying Wang, Yibo Lin, Jun Yang, Ning Xu, Xi Wang, Qiang Xu</dc:creator>
        <description><![CDATA[
            多模态大语言模型（MLLMs）为电子设计自动化（EDA）带来机遇，但现有基准难以全面评估其在电路设计中的性能。为此提出MMCircuitEval，这是首个全面评估MLLMs在不同EDA任务中表现的多模态基准。它包含3614个精心策划的问答对，涵盖数字和模拟电路。该基准按设计阶段、电路类型等分类问题，方便分析模型能力与局限。评估显示现有LLMs存在性能差距，尤其在后端设计和复杂计算方面。MMCircuitEval为EDA领域推进MLLMs提供基础资源。
            arXiv:2507.19525v1 Announce Type: new 
Abstract: The emergence of multimodal large language models (MLLMs) presents promising opportunities for automation and enhancement in Electronic Design Automation (EDA). However, comprehensively evaluating these models in circuit design remains challenging due to the narrow scope of existing benchmarks. To bridge this gap, we introduce MMCircuitEval, the first multimodal benchmark specifically designed to assess MLLM performance comprehensively across diverse EDA tasks. MMCircuitEval comprises 3614 meticulously curated question-answer (QA) pairs spanning digital and analog circuits across critical EDA stages - ranging from general knowledge and specifications to front-end and back-end design. Derived from textbooks, technical question banks, datasheets, and real-world documentation, each QA pair undergoes rigorous expert review for accuracy and relevance. Our benchmark uniquely categorizes questions by design stage, circuit type, tested abilities (knowledge, comprehension, reasoning, computation), and difficulty level, enabling detailed analysis of model capabilities and limitations. Extensive evaluations reveal significant performance gaps among existing LLMs, particularly in back-end design and complex computations, highlighting the critical need for targeted training datasets and modeling approaches. MMCircuitEval provides a foundational resource for advancing MLLMs in EDA, facilitating their integration into real-world circuit design workflows. Our benchmark is available at https://github.com/cure-lab/MMCircuitEval.
        ]]></description>
    </item>
    <item>
        <title>Quantizing Text-attributed Graphs for Semantic-Structural Integration</title>
        <link>https://arxiv.org/abs/2507.19526</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.19526v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jianyuan Bo, Hao Wu, Yuan Fang</dc:creator>
        <description><![CDATA[
            文本属性图（TAGs）能建模多领域复杂关系，随着大语言模型（LLMs）兴起，利用其能力进行图学习备受关注。但现有方法在将结构信息嵌入与LLM兼容格式时面临挑战，且需源域标记数据，限制了适应性。为此提出STAG自监督框架，用冻结码本将图结构信息量化为离散令牌，采用软分配和KL散度引导量化应对图数据无自然分词结构的问题。该框架支持零样本迁移学习，实验显示在多节点分类基准测试中达最优性能，且与不同LLM架构兼容，为图学习与LLMs结合提供解决方案。
            arXiv:2507.19526v1 Announce Type: new 
Abstract: Text-attributed graphs (TAGs) have emerged as a powerful representation for modeling complex relationships across diverse domains. With the rise of large language models (LLMs), there is growing interest in leveraging their capabilities for graph learning. However, current approaches face significant challenges in embedding structural information into LLM-compatible formats, requiring either computationally expensive alignment mechanisms or manual graph verbalization techniques that often lose critical structural details. Moreover, these methods typically require labeled data from source domains for effective transfer learning, significantly constraining their adaptability. We propose STAG, a novel self-supervised framework that directly quantizes graph structural information into discrete tokens using a frozen codebook. Unlike traditional quantization approaches, our method employs soft assignment and KL divergence guided quantization to address the unique challenges of graph data, which lacks natural tokenization structures. Our framework enables both LLM-based and traditional learning approaches, supporting true zero-shot transfer learning without requiring labeled data even in the source domain. Extensive experiments demonstrate state-of-the-art performance across multiple node classification benchmarks while maintaining compatibility with different LLM architectures, offering an elegant solution to bridging graph learning with LLMs.
        ]]></description>
    </item>
    <item>
        <title>Research on the application of graph data structure and graph neural network in node classification/clustering tasks</title>
        <link>https://arxiv.org/abs/2507.19527</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.19527v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yihan Wang, Jianing Zhao</dc:creator>
        <description><![CDATA[
            图结构数据在多领域广泛存在，其非欧特性给传统机器学习方法带来挑战。该研究对图数据结构、经典图算法和图神经网络（GNN）进行探究，开展理论分析与对比评估。通过对比实验，定量评估传统算法和GNN在节点分类与聚类任务中的性能差异，结果显示GNN比传统方法的准确率大幅提升43% - 70%。此外，还探索经典算法与GNN架构的融合策略，为推进图表示学习研究提供理论指导。
            arXiv:2507.19527v1 Announce Type: new 
Abstract: Graph-structured data are pervasive across domains including social networks, biological networks, and knowledge graphs. Due to their non-Euclidean nature, such data pose significant challenges to conventional machine learning methods. This study investigates graph data structures, classical graph algorithms, and Graph Neural Networks (GNNs), providing comprehensive theoretical analysis and comparative evaluation. Through comparative experiments, we quantitatively assess performance differences between traditional algorithms and GNNs in node classification and clustering tasks. Results show GNNs achieve substantial accuracy improvements of 43% to 70% over traditional methods. We further explore integration strategies between classical algorithms and GNN architectures, providing theoretical guidance for advancing graph representation learning research.
        ]]></description>
    </item>
    <item>
        <title>Graph Learning Metallic Glass Discovery from Wikipedia</title>
        <link>https://arxiv.org/abs/2507.19536</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.19536v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>K. -C. Ouyang, S. -Y. Zhang, S. -L. Liu, J. Tian, Y. -H. Li, H. Tong, H. -Y. Bai, W. -H. Wang, Y. -C. Hu</dc:creator>
        <description><![CDATA[
            在各研究领域，高效合成新材料需求迫切，但过程缓慢且成本高，特别是金属玻璃，其形成依赖多元素最优组合。传统表格数据因数据稀缺和材料编码不成熟，用统计学习算法挖掘，模型预测和泛化能力有限。本文提出从材料网络表征进行数据学习，用语言模型从维基百科对节点元素编码，设计多种架构的图神经网络作为推荐系统探索材料关系，还评估不同语言的维基百科嵌入在材料设计中的能力，为新材料发现提供新范式。
            arXiv:2507.19536v1 Announce Type: new 
Abstract: Synthesizing new materials efficiently is highly demanded in various research fields. However, this process is usually slow and expensive, especially for metallic glasses, whose formation strongly depends on the optimal combinations of multiple elements to resist crystallization. This constraint renders only several thousands of candidates explored in the vast material space since 1960. Recently, data-driven approaches armed by advanced machine learning techniques provided alternative routes for intelligent materials design. Due to data scarcity and immature material encoding, the conventional tabular data is usually mined by statistical learning algorithms, giving limited model predictability and generalizability. Here, we propose sophisticated data learning from material network representations. The node elements are encoded from the Wikipedia by a language model. Graph neural networks with versatile architectures are designed to serve as recommendation systems to explore hidden relationships among materials. By employing Wikipedia embeddings from different languages, we assess the capability of natural languages in materials design. Our study proposes a new paradigm to harvesting new amorphous materials and beyond with artificial intelligence.
        ]]></description>
    </item>
    <item>
        <title>Mitigating Geospatial Knowledge Hallucination in Large Language Models: Benchmarking and Dynamic Factuality Aligning</title>
        <link>https://arxiv.org/abs/2507.19586</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.19586v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Shengyuan Wang, Jie Feng, Tianhui Liu, Dan Pei, Yong Li</dc:creator>
        <description><![CDATA[
            背景：大语言模型在地理空间任务应用广泛，但常产生地理空间知识幻觉，影响可靠性，且系统评估和缓解方法研究不足。方法：提出地理空间幻觉综合评估框架，利用结构化地理空间知识图谱评估；引入基于Kahneman - Tversky优化的动态事实对齐方法。效果：经对20个先进大模型评估，发现其地理空间知识幻觉，该方法使基准测试性能提升超29.6%，实验证明能增强大模型在地理空间知识和推理任务的可信度。
            arXiv:2507.19586v1 Announce Type: new 
Abstract: Large language models (LLMs) possess extensive world knowledge, including geospatial knowledge, which has been successfully applied to various geospatial tasks such as mobility prediction and social indicator prediction. However, LLMs often generate inaccurate geospatial knowledge, leading to geospatial hallucinations (incorrect or inconsistent representations of geospatial information) that compromise their reliability. While the phenomenon of general knowledge hallucination in LLMs has been widely studied, the systematic evaluation and mitigation of geospatial hallucinations remain largely unexplored. To address this gap, we propose a comprehensive evaluation framework for geospatial hallucinations, leveraging structured geospatial knowledge graphs for controlled assessment. Through extensive evaluation across 20 advanced LLMs, we uncover the hallucinations in their geospatial knowledge. Building on these insights, we introduce a dynamic factuality aligning method based on Kahneman-Tversky Optimization (KTO) to mitigate geospatial hallucinations in LLMs, leading to a performance improvement of over 29.6% on the proposed benchmark. Extensive experimental results demonstrate the effectiveness of our benchmark and learning algorithm in enhancing the trustworthiness of LLMs in geospatial knowledge and reasoning tasks.
        ]]></description>
    </item>
    <item>
        <title>HITSZ's End-To-End Speech Translation Systems Combining Sequence-to-Sequence Auto Speech Recognition Model and Indic Large Language Model for IWSLT 2025 in Indic Track</title>
        <link>https://arxiv.org/abs/2507.19616</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.19616v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xuchen Wei, Yangxin Wu, Yaoyin Zhang, Henglyu Liu, Kehai Chen, Xuefeng Bai, Min Zhang</dc:creator>
        <description><![CDATA[
            本文背景是提升低资源场景下英印及印英语音翻译质量。方法上，提出将预训练的Whisper自动语音识别模型与印地语专用大语言模型Krutrim集成的端到端系统，还研究了思维链方法。效果方面，端到端系统英印方向平均BLEU得分为28.88，印英方向为27.86；思维链方法在成功解析输出上有提升潜力，如泰米尔语到英语BLEU提升13.84，但在确保模型遵循思维链输出格式上存在挑战。
            arXiv:2507.19616v1 Announce Type: new 
Abstract: This paper presents HITSZ's submission for the IWSLT 2025 Indic track, focusing on speech-to-text translation (ST) for English-to-Indic and Indic-to-English language pairs. To enhance translation quality in this low-resource scenario, we propose an end-to-end system integrating the pre-trained Whisper automated speech recognition (ASR) model with Krutrim, an Indic-specialized large language model (LLM). Experimental results demonstrate that our end-to-end system achieved average BLEU scores of $28.88$ for English-to-Indic directions and $27.86$ for Indic-to-English directions. Furthermore, we investigated the Chain-of-Thought (CoT) method. While this method showed potential for significant translation quality improvements on successfully parsed outputs (e.g. a $13.84$ BLEU increase for Tamil-to-English), we observed challenges in ensuring the model consistently adheres to the required CoT output format.
        ]]></description>
    </item>
    <item>
        <title>Ta-G-T: Subjectivity Capture in Table to Text Generation via RDF Graphs</title>
        <link>https://arxiv.org/abs/2507.19710</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.19710v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ronak Upasham, Tathagata Dey, Pushpak Bhattacharyya</dc:creator>
        <description><![CDATA[
            在表格到文本（T2T）生成中，现有方法多侧重对表格数据进行客观描述，而生成包含主观性解读的文本研究不足。为此，本文提出新的三阶段流程，即提取资源描述框架（RDF）三元组、聚合文本成连贯叙述、注入主观性丰富文本。该方法利用RDF提升事实准确性和可解释性，采用微调后的小模型T5，性能与GPT - 3.5相当，在多个指标上优于Mistral - 7B和Llama - 2，有效平衡了事实准确性和主观解读。
            arXiv:2507.19710v1 Announce Type: new 
Abstract: In Table-to-Text (T2T) generation, existing approaches predominantly focus on providing objective descriptions of tabular data. However, generating text that incorporates subjectivity, where subjectivity refers to interpretations beyond raw numerical data, remains underexplored. To address this, we introduce a novel pipeline that leverages intermediate representations to generate both objective and subjective text from tables. Our three-stage pipeline consists of: 1) extraction of Resource Description Framework (RDF) triples, 2) aggregation of text into coherent narratives, and 3) infusion of subjectivity to enrich the generated text. By incorporating RDFs, our approach enhances factual accuracy while maintaining interpretability. Unlike large language models (LLMs) such as GPT-3.5, Mistral-7B, and Llama-2, our pipeline employs smaller, fine-tuned T5 models while achieving comparable performance to GPT-3.5 and outperforming Mistral-7B and Llama-2 in several metrics. We evaluate our approach through quantitative and qualitative analyses, demonstrating its effectiveness in balancing factual accuracy with subjective interpretation. To the best of our knowledge, this is the first work to propose a structured pipeline for T2T generation that integrates intermediate representations to enhance both factual correctness and subjectivity.
        ]]></description>
    </item>
    <item>
        <title>Beyond Nearest Neighbors: Semantic Compression and Graph-Augmented Retrieval for Enhanced Vector Search</title>
        <link>https://arxiv.org/abs/2507.19715</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.19715v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Rahul Raja, Arpita Vats</dc:creator>
        <description><![CDATA[
            背景：传统向量数据库的近似最近邻搜索易产生语义冗余结果，无法满足检索增强生成等应用对多样性和上下文丰富度的需求。方法：引入语义压缩新范式，用子模优化和信息几何原理选择能捕捉查询周围更广泛语义结构的向量集；提出图增强向量检索，在向量空间上叠加语义图实现多跳、上下文感知搜索。效果：理论分析了高维集中下基于邻近性检索的局限，表明图结构可提高语义覆盖度，为以意义为中心的向量搜索系统奠定基础。
            arXiv:2507.19715v1 Announce Type: new 
Abstract: Vector databases typically rely on approximate nearest neighbor (ANN) search to retrieve the top-k closest vectors to a query in embedding space. While effective, this approach often yields semantically redundant results, missing the diversity and contextual richness required by applications such as retrieval-augmented generation (RAG), multi-hop QA, and memory-augmented agents. We introduce a new retrieval paradigm: semantic compression, which aims to select a compact, representative set of vectors that captures the broader semantic structure around a query. We formalize this objective using principles from submodular optimization and information geometry, and show that it generalizes traditional top-k retrieval by prioritizing coverage and diversity. To operationalize this idea, we propose graph-augmented vector retrieval, which overlays semantic graphs (e.g., kNN or knowledge-based links) atop vector spaces to enable multi-hop, context-aware search. We theoretically analyze the limitations of proximity-based retrieval under high-dimensional concentration and highlight how graph structures can improve semantic coverage. Our work outlines a foundation for meaning-centric vector search systems, emphasizing hybrid indexing, diversity-aware querying, and structured semantic retrieval. We make our implementation publicly available to foster future research in this area.
        ]]></description>
    </item>
    <item>
        <title>JT-Math: A Multi-Stage Framework for Advanced Mathematical Reasoning in Large Language Models</title>
        <link>https://arxiv.org/abs/2507.19748</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.19748v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yifan Hao, Fangning Chao, Yaqian Hao, Zhaojun Cui, Huan Bai, Haiyu Zhang, Yankai Liu, Chao Deng, Junlan Feng</dc:creator>
        <description><![CDATA[
            数学推理是通用人工智能的基石，也是评估大语言模型能力的重要基准。现有模型在处理复杂问题时存在不足。为此，研究团队提出多阶段优化框架，构建了包含基础、指令和思维版本的开源模型JT - Math - 8B。其预训练语料通过专门数据管道精心挑选。指令模型采用监督微调与基于GRPO的强化学习方法优化；思维模型使用长思维链方法，结合监督微调与多阶段强化学习课程训练。该模型在同规模开源模型中取得了最优结果，超越了O1 - mini和GPT - 4o等模型，在竞赛级数学任务中表现出色。
            arXiv:2507.19748v1 Announce Type: new 
Abstract: Mathematical reasoning is a cornerstone of artificial general intelligence and a primary benchmark for evaluating the capabilities of Large Language Models (LLMs). While state-of-the-art models show promise, they often falter when faced with complex problems that demand deep conceptual understanding and intricate, multi-step deliberation. To address this challenge, we introduce JT-Math-8B, a series of open-source models comprising base, instruct, and thinking versions, built upon a systematic, multi-stage optimization framework. Our pre-training corpus is a high-quality, 210B-token dataset curated through a dedicated data pipeline that uses model-based validation to ensure quality and diversity. The Instruct Model is optimized for direct, concise answers through Supervised Fine-Tuning (SFT) and a GRPO-based reinforcement learning (RL) method. The Thinking Model is trained for complex problem-solving using a Long Chain-of-Thought (Long CoT) approach, combining SFT with a novel, multi-stage RL curriculum that progressively increases task difficulty and context length up to 32K tokens. JT-Math-8B achieves state-of-the-art results among open-source models of similar size, surpassing prominent models like OpenAI's O1-mini and GPT-4o , and demonstrating superior performance on competition-level mathematics.
        ]]></description>
    </item>
    <item>
        <title>UloRL:An Ultra-Long Output Reinforcement Learning Approach for Advancing Large Language Models' Reasoning Abilities</title>
        <link>https://arxiv.org/abs/2507.19766</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.19766v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Dong Du, Shulin Liu, Tao Yang, Shaohua Chen, Yang Li</dc:creator>
        <description><![CDATA[
            背景：大语言模型借助可验证奖励的强化学习提升推理能力，但传统强化学习框架处理超长输出时，因长尾序列分布和训练时的熵坍塌而效率低下。方法：提出UloRL方法，将超长输出解码拆分为短片段以减轻长尾样本延迟，引入动态掩码防止熵坍塌。效果：在Qwen3 - 30B - A3B模型上，分段滚动强化学习使训练速度提升2.06倍；128k标记输出的强化学习使模型在AIME2025上的表现从70.9%提升到85.1%，在BeyondAIME上从50.7%提升到61.9%，超越Qwen3 - 235B - A22B。
            arXiv:2507.19766v1 Announce Type: new 
Abstract: Recent advances in large language models (LLMs) have highlighted the potential of reinforcement learning with verifiable rewards (RLVR) to enhance reasoning capabilities through extended output sequences. However, traditional RL frameworks face inefficiencies when handling ultra-long outputs due to long-tail sequence distributions and entropy collapse during training. To address these challenges, we propose an Ultra-Long Output Reinforcement Learning (UloRL) approach for advancing large language models' reasoning abilities. Specifically, we divide ultra long output decoding into short segments, enabling efficient training by mitigating delays caused by long-tail samples. Additionally, we introduce dynamic masking of well-Mastered Positive Tokens (MPTs) to prevent entropy collapse. Experimental results demonstrate the effectiveness of our approach. On the Qwen3-30B-A3B model, RL with segment rollout achieved 2.06x increase in training speed, while RL training with 128k-token outputs improves the model's performance on AIME2025 from 70.9\% to 85.1\% and on BeyondAIME from 50.7\% to 61.9\%, even surpassing Qwen3-235B-A22B with remarkable gains. These findings underscore the potential of our methods to advance the reasoning capabilities of LLMs with ultra-long sequence generation. We will release our code and model for further use by the community.
        ]]></description>
    </item>
    <item>
        <title>Large Language Model Agent for Structural Drawing Generation Using ReAct Prompt Engineering and Retrieval Augmented Generation</title>
        <link>https://arxiv.org/abs/2507.19771</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.19771v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xin Zhang, Lissette Iturburu, Juan Nicolas Villamizar, Xiaoyu Liu, Manuel Salmeron, Shirley J. Dyke, Julio Ramirez</dc:creator>
        <description><![CDATA[
            背景：结构图纸在多领域广泛应用，但生成过程耗费工程师大量时间和精力。方法：引入基于生成式AI的方法，利用大语言模型（LLM）智能体，结合检索增强生成（RAG）技术，借助外部事实提升语言模型准确性和可靠性，理解自然语言描述、提取信息并生成代码在AutoCAD中绘制图纸。效果：能将自然语言描述高效转化为AutoCAD图纸，大幅减轻人工绘图工作量，简化工程师表达设计思路的迭代过程。
            arXiv:2507.19771v1 Announce Type: new 
Abstract: Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. In civil engineering, structural drawings serve as the main communication tool between architects, engineers, and builders to avoid conflicts, act as legal documentation, and provide a reference for future maintenance or evaluation needs. They are often organized using key elements such as title/subtitle blocks, scales, plan views, elevation view, sections, and detailed sections, which are annotated with standardized symbols and line types for interpretation by engineers and contractors. Despite advances in software capabilities, the task of generating a structural drawing remains labor-intensive and time-consuming for structural engineers. Here we introduce a novel generative AI-based method for generating structural drawings employing a large language model (LLM) agent. The method incorporates a retrieval-augmented generation (RAG) technique using externally-sourced facts to enhance the accuracy and reliability of the language model. This method is capable of understanding varied natural language descriptions, processing these to extract necessary information, and generating code to produce the desired structural drawing in AutoCAD. The approach developed, demonstrated and evaluated herein enables the efficient and direct conversion of a structural drawing's natural language description into an AutoCAD drawing, significantly reducing the workload compared to current working process associated with manual drawing production, facilitating the typical iterative process of engineers for expressing design ideas in a simplified way.
        ]]></description>
    </item>
    <item>
        <title>Text2Vis: A Challenging and Diverse Benchmark for Generating Multimodal Visualizations from Text</title>
        <link>https://arxiv.org/abs/2507.19969</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.19969v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mizanur Rahman, Md Tahmid Rahman Laskar, Shafiq Joty, Enamul Hoque</dc:creator>
        <description><![CDATA[
            自动化数据可视化意义重大，但缺乏全面基准限制了大语言模型（LLMs）可视化生成能力的评估。为此，本文推出Text2Vis基准，涵盖20多种图表类型和多样数据科学查询，含1985个样本。对11个模型进行基准测试，发现性能差距。提出跨模态演员-评论家代理框架，使GPT - 4o通过率从26%提升到42%，提高图表质量。还引入自动化评估框架，可无人工标注评估大量样本。
            arXiv:2507.19969v1 Announce Type: new 
Abstract: Automated data visualization plays a crucial role in simplifying data interpretation, enhancing decision-making, and improving efficiency. While large language models (LLMs) have shown promise in generating visualizations from natural language, the absence of comprehensive benchmarks limits the rigorous evaluation of their capabilities. We introduce Text2Vis, a benchmark designed to assess text-to-visualization models, covering 20+ chart types and diverse data science queries, including trend analysis, correlation, outlier detection, and predictive analytics. It comprises 1,985 samples, each with a data table, natural language query, short answer, visualization code, and annotated charts. The queries involve complex reasoning, conversational turns, and dynamic data retrieval. We benchmark 11 open-source and closed-source models, revealing significant performance gaps, highlighting key challenges, and offering insights for future advancements. To close this gap, we propose the first cross-modal actor-critic agentic framework that jointly refines the textual answer and visualization code, increasing GPT-4o`s pass rate from 26% to 42% over the direct approach and improving chart quality. We also introduce an automated LLM-based evaluation framework that enables scalable assessment across thousands of samples without human annotation, measuring answer correctness, code execution success, visualization readability, and chart accuracy. We release Text2Vis at https://github.com/vis-nlp/Text2Vis.
        ]]></description>
    </item>
    <item>
        <title>FROSS: Faster-than-Real-Time Online 3D Semantic Scene Graph Generation from RGB-D Images</title>
        <link>https://arxiv.org/abs/2507.19993</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.19993v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hao-Yu Hou, Chun-Yi Lee, Motoharu Sonogashira, Yasutomo Kawanishi</dc:creator>
        <description><![CDATA[
            将复杂3D环境抽象为结构化表示在多领域至关重要，3D语义场景图可助力实现这一目标，但现有生成方法存在计算量大、非增量处理等问题，不适用于实时开放世界应用。为此，提出FROSS方法，利用将2D场景图直接提升到3D空间、将对象表示为3D高斯分布的方式生成3D语义场景图，消除对精确且计算密集的点云处理的依赖。还扩展了数据集用于评估。实验表明，FROSS性能更优，速度比现有方法快很多。
            arXiv:2507.19993v1 Announce Type: new 
Abstract: The ability to abstract complex 3D environments into simplified and structured representations is crucial across various domains. 3D semantic scene graphs (SSGs) achieve this by representing objects as nodes and their interrelationships as edges, facilitating high-level scene understanding. Existing methods for 3D SSG generation, however, face significant challenges, including high computational demands and non-incremental processing that hinder their suitability for real-time open-world applications. To address this issue, we propose FROSS (Faster-than-Real-Time Online 3D Semantic Scene Graph Generation), an innovative approach for online and faster-than-real-time 3D SSG generation that leverages the direct lifting of 2D scene graphs to 3D space and represents objects as 3D Gaussian distributions. This framework eliminates the dependency on precise and computationally-intensive point cloud processing. Furthermore, we extend the Replica dataset with inter-object relationship annotations, creating the ReplicaSSG dataset for comprehensive evaluation of FROSS. The experimental results from evaluations on ReplicaSSG and 3DSSG datasets show that FROSS can achieve superior performance while operating significantly faster than prior 3D SSG generation methods. Our implementation and dataset are publicly available at https://github.com/Howardkhh/FROSS.
        ]]></description>
    </item>
    <item>
        <title>RAG in the Wild: On the (In)effectiveness of LLMs with Mixture-of-Knowledge Retrieval Augmentation</title>
        <link>https://arxiv.org/abs/2507.20059</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.20059v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ran Xu, Yuchen Zhuang, Yue Yu, Haoyu Wang, Wenqi Shi, Carl Yang</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）能增强大语言模型，但在现实多样检索场景下的有效性待探索。方法：用含混合知识的大规模数据存储库MassiveDS评估RAG系统。效果：发现检索主要使小模型受益，重排器作用小，无单一检索源始终表现出色，且当前大语言模型难以跨异构知识源路由查询。研究强调在现实场景部署RAG前需有自适应检索策略。
            arXiv:2507.20059v1 Announce Type: new 
Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs) by integrating external knowledge retrieved at inference time. While RAG demonstrates strong performance on benchmarks largely derived from general-domain corpora like Wikipedia, its effectiveness under realistic, diverse retrieval scenarios remains underexplored. We evaluated RAG systems using MassiveDS, a large-scale datastore with mixture of knowledge, and identified critical limitations: retrieval mainly benefits smaller models, rerankers add minimal value, and no single retrieval source consistently excels. Moreover, current LLMs struggle to route queries across heterogeneous knowledge sources. These findings highlight the need for adaptive retrieval strategies before deploying RAG in real-world settings. Our code and data can be found at https://github.com/ritaranx/RAG_in_the_Wild.
        ]]></description>
    </item>
    <item>
        <title>Graded Transformers: A Symbolic-Geometric Approach to Structured Learning</title>
        <link>https://arxiv.org/abs/2507.20108</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.20108v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tony Shaska Sr</dc:creator>
        <description><![CDATA[
            本文提出了分级Transformer框架，属于新型序列模型。背景是为处理结构化数据。方法上，扩展分级神经网络理论，提出线性分级Transformer和指数分级Transformer两种架构，通过参数化缩放算子将分层结构融入注意力和表示层。该框架有严格理论保障，如通用逼近定理等，还可自适应特征优先级。效果上，其在多领域有应用潜力，融合几何、代数原理与注意力机制，为复杂领域提供可解释、高效系统，推动结构化深度学习发展。
            arXiv:2507.20108v1 Announce Type: new 
Abstract: We introduce the Graded Transformer framework, a novel class of sequence models that embeds algebraic inductive biases through grading transformations on vector spaces. Extending the theory of Graded Neural Networks (GNNs), we propose two architectures: the Linearly Graded Transformer (LGT) and the Exponentially Graded Transformer (EGT). These models apply parameterized scaling operators-governed by fixed or learnable grading tuples and, for EGT, exponential factors to infuse hierarchical structure into attention and representation layers, enhancing efficiency for structured data.
  We derive rigorous theoretical guarantees, including universal approximation theorems for continuous and Sobolev functions, reduced sample complexity via effective VC dimension bounds, Lipschitz continuity of graded operations, and robustness to adversarial perturbations. A graded loss function ensures gradient stability and alignment with domain priors during optimization. By treating grades as differentiable parameters, the framework enables adaptive feature prioritization, overcoming limitations of fixed grades in prior work.
  The Graded Transformer holds transformative potential for hierarchical learning and neurosymbolic reasoning, with applications spanning algebraic geometry (e.g., moduli spaces and zeta functions), physics (e.g., multiscale simulations), natural language processing (e.g., syntactic parsing), biological sequence analysis (e.g., variant prediction), and emerging areas like graph neural networks and financial modeling. This work advances structured deep learning by fusing geometric and algebraic principles with attention mechanisms, offering a mathematically grounded alternative to data-driven models and paving the way for interpretable, efficient systems in complex domains.
        ]]></description>
    </item>
    <item>
        <title>MoL-RL: Distilling Multi-Step Environmental Feedback into LLMs for Feedback-Independent Reasoning</title>
        <link>https://arxiv.org/abs/2507.20278</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.20278v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kang Yang, Jingxue Chen, Qingkun Tang, Tianxiang Zhang, Qianchun Lu</dc:creator>
        <description><![CDATA[
            大语言模型在利用顺序环境反馈信号进行独立于反馈的思维链推理时面临挑战。现有方法存在丢失上下文信息或未充分利用反馈交互特性的问题。为此，提出MoL - RL训练范式，通过双目标优化框架将多步环境反馈信号整合进大语言模型。该方法结合MoL持续训练和基于GRPO的后训练，实现将顺序环境反馈交互提炼为单步推理。实验结果显示，在数学推理和代码生成基准测试中，使用Qwen3 - 8B模型时MoL - RL达最优性能，且在不同模型规模上泛化能力强。
            arXiv:2507.20278v1 Announce Type: new 
Abstract: Large language models (LLMs) face significant challenges in effectively leveraging sequential environmental feedback (EF) signals, such as natural language evaluations, for feedback-independent chain-of-thought (CoT) reasoning. Existing approaches either convert EF into scalar rewards, losing rich contextual information, or employ refinement datasets, failing to exploit the multi-step and discrete nature of EF interactions. To address these limitations, we propose MoL-RL, a novel training paradigm that integrates multi-step EF signals into LLMs through a dual-objective optimization framework. Our method combines MoL (Mixture-of-Losses) continual training, which decouples domain-specific EF signals (optimized via cross-entropy loss) and general language capabilities (preserved via Kullback-Leibler divergence), with GRPO-based post-training to distill sequential EF interactions into single-step inferences. This synergy enables robust feedback-independent reasoning without relying on external feedback loops. Experimental results on mathematical reasoning (MATH-500, AIME24/AIME25) and code generation (CodeAgent-Test) benchmarks demonstrate that MoL-RL achieves state-of-the-art performance with the Qwen3-8B model, while maintaining strong generalization across model scales (Qwen3-4B). This work provides a promising approach for leveraging multi-step textual feedback to enhance LLMs' reasoning capabilities in diverse domains.
        ]]></description>
    </item>
    <item>
        <title>MIPS: a Multimodal Infinite Polymer Sequence Pre-training Framework for Polymer Property Prediction</title>
        <link>https://arxiv.org/abs/2507.20326</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.20326v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiaxi Wang, Yaosen Min, Xun Zhu, Miao Li, Ji Wu</dc:creator>
        <description><![CDATA[
            背景：现有聚合物建模方法难以捕捉其整体特性，因聚合过程中性质会改变。方法：提出多模态无限聚合物序列（MIPS）预训练框架，将聚合物表示为单体的无限序列，整合拓扑和空间信息。拓扑上，推广消息传递和图注意力机制并提出局部图注意力；用重复和移位不变性测试验证策略，用骨干嵌入解决含环结构问题。空间上，提取重复单体的3D描述符。设计跨模态融合机制统一信息。效果：在八项任务中达最优性能。
            arXiv:2507.20326v1 Announce Type: new 
Abstract: Polymers, composed of repeating structural units called monomers, are fundamental materials in daily life and industry. Accurate property prediction for polymers is essential for their design, development, and application. However, existing modeling approaches, which typically represent polymers by the constituent monomers, struggle to capture the whole properties of polymer, since the properties change during the polymerization process. In this study, we propose a Multimodal Infinite Polymer Sequence (MIPS) pre-training framework, which represents polymers as infinite sequences of monomers and integrates both topological and spatial information for comprehensive modeling. From the topological perspective, we generalize message passing mechanism (MPM) and graph attention mechanism (GAM) to infinite polymer sequences. For MPM, we demonstrate that applying MPM to infinite polymer sequences is equivalent to applying MPM on the induced star-linking graph of monomers. For GAM, we propose to further replace global graph attention with localized graph attention (LGA). Moreover, we show the robustness of the "star linking" strategy through Repeat and Shift Invariance Test (RSIT). Despite its robustness, "star linking" strategy exhibits limitations when monomer side chains contain ring structures, a common characteristic of polymers, as it fails the Weisfeiler-Lehman~(WL) test. To overcome this issue, we propose backbone embedding to enhance the capability of MPM and LGA on infinite polymer sequences. From the spatial perspective, we extract 3D descriptors of repeating monomers to capture spatial information. Finally, we design a cross-modal fusion mechanism to unify the topological and spatial information. Experimental validation across eight diverse polymer property prediction tasks reveals that MIPS achieves state-of-the-art performance.
        ]]></description>
    </item>
    <item>
        <title>From Observations to Causations: A GNN-based Probabilistic Prediction Framework for Causal Discovery</title>
        <link>https://arxiv.org/abs/2507.20349</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.20349v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Rezaur Rashid, Gabriel Terejanu</dc:creator>
        <description><![CDATA[
            背景：从观测数据中进行因果发现具有挑战性，传统方法在扩展性和捕捉全局结构信息方面存在不足。方法：提出基于图神经网络（GNN）的概率框架，学习因果图空间上的概率分布，将节点和边属性编码为统一图表示，用合成数据集训练，把因果发现作为监督学习问题预测图结构。效果：在合成和真实数据集上，相比传统和非GNN方法及一种GNN方法，在准确性和扩展性上表现更优，无需进一步训练，显著提升因果结构学习能力。
            arXiv:2507.20349v1 Announce Type: new 
Abstract: Causal discovery from observational data is challenging, especially with large datasets and complex relationships. Traditional methods often struggle with scalability and capturing global structural information. To overcome these limitations, we introduce a novel graph neural network (GNN)-based probabilistic framework that learns a probability distribution over the entire space of causal graphs, unlike methods that output a single deterministic graph. Our framework leverages a GNN that encodes both node and edge attributes into a unified graph representation, enabling the model to learn complex causal structures directly from data. The GNN model is trained on a diverse set of synthetic datasets augmented with statistical and information-theoretic measures, such as mutual information and conditional entropy, capturing both local and global data properties. We frame causal discovery as a supervised learning problem, directly predicting the entire graph structure. Our approach demonstrates superior performance, outperforming both traditional and recent non-GNN-based methods, as well as a GNN-based approach, in terms of accuracy and scalability on synthetic and real-world datasets without further training. This probabilistic framework significantly improves causal structure learning, with broad implications for decision-making and scientific discovery across various fields.
        ]]></description>
    </item>
    <item>
        <title>Cognitive Chain-of-Thought: Structured Multimodal Reasoning about Social Situations</title>
        <link>https://arxiv.org/abs/2507.20409</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.20409v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Eunkyu Park, Wesley Hanwen Deng, Gunhee Kim, Motahhare Eslami, Maarten Sap</dc:creator>
        <description><![CDATA[
            背景：思维链（CoT）提示虽能助模型逐步思考，但在需同时进行视觉感知、理解和判断的社会情境视觉任务中常失效。方法：提出认知思维链（CoCoT）提示策略，通过感知、情境和规范三个受认知启发的阶段支撑视觉语言模型（VLM）推理。效果：在多个多模态基准测试中，CoCoT平均比CoT和直接提示高出8%，能增强VLM的可解释性和社会意识，为更安全可靠的多模态系统奠定基础。
            arXiv:2507.20409v1 Announce Type: new 
Abstract: Chain-of-Thought (CoT) prompting helps models think step by step. But what happens when they must see, understand, and judge-all at once? In visual tasks grounded in social context, where bridging perception with norm-grounded judgments is essential, flat CoT often breaks down. We introduce Cognitive Chain-of-Thought (CoCoT), a prompting strategy that scaffolds VLM reasoning through three cognitively inspired stages: perception, situation, and norm. Our experiments show that, across multiple multimodal benchmarks (including intent disambiguation, commonsense reasoning, and safety), CoCoT consistently outperforms CoT and direct prompting (+8\% on average). Our findings demonstrate that cognitively grounded reasoning stages enhance interpretability and social awareness in VLMs, paving the way for safer and more reliable multimodal systems.
        ]]></description>
    </item>
    <item>
        <title>BioNeuralNet: A Graph Neural Network based Multi-Omics Network Data Analysis Tool</title>
        <link>https://arxiv.org/abs/2507.20440</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.20440v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Vicente Ramos (Department of Computer Science and Engineering, University of Colorado Denver, Denver, USA), Sundous Hussein (Department of Computer Science and Engineering, University of Colorado Denver, Denver, USA), Mohamed Abdel-Hafiz (Department of Computer Science and Engineering, University of Colorado Denver, Denver, USA), Arunangshu Sarkar (Department of Biostatistics and Informatics, University of Colorado Anschutz Medical Campus, Aurora, USA), Weixuan Liu (Department of Biostatistics and Informatics, University of Colorado Anschutz Medical Campus, Aurora, USA), Katerina J. Kechris (Department of Biostatistics and Informatics, University of Colorado Anschutz Medical Campus, Aurora, USA), Russell P. Bowler (Genomic Medicine Institute, Cleveland Clinic, Cleveland, USA), Leslie Lange (Division of Biomedical Informatics and Personalized Medicine, University of Colorado Anschutz Medical Campus, Aurora, USA), Farnoush Banaei-Kashani (Department of Computer Science and Engineering, University of Colorado Denver, Denver, USA)</dc:creator>
        <description><![CDATA[
            背景：多组学数据虽能助力解析复杂生物系统，但高维、稀疏和复杂交互给分析带来挑战，现有方法缺乏跨下游分析有效利用网络表征的工具。方法：推出BioNeuralNet，这一基于图神经网络的Python框架，能从多组学网络学习低维表征，支持多组学网络分析各阶段。效果：它实用工具丰富、与主流Python包兼容，是开源、易用且文档详尽的框架，可支持精准医学中灵活、可重复的多组学网络分析。
            arXiv:2507.20440v1 Announce Type: new 
Abstract: Multi-omics data offer unprecedented insights into complex biological systems, yet their high dimensionality, sparsity, and intricate interactions pose significant analytical challenges. Network-based approaches have advanced multi-omics research by effectively capturing biologically relevant relationships among molecular entities. While these methods are powerful for representing molecular interactions, there remains a need for tools specifically designed to effectively utilize these network representations across diverse downstream analyses. To fulfill this need, we introduce BioNeuralNet, a flexible and modular Python framework tailored for end-to-end network-based multi-omics data analysis. BioNeuralNet leverages Graph Neural Networks (GNNs) to learn biologically meaningful low-dimensional representations from multi-omics networks, converting these complex molecular networks into versatile embeddings. BioNeuralNet supports all major stages of multi-omics network analysis, including several network construction techniques, generation of low-dimensional representations, and a broad range of downstream analytical tasks. Its extensive utilities, including diverse GNN architectures, and compatibility with established Python packages (e.g., scikit-learn, PyTorch, NetworkX), enhance usability and facilitate quick adoption. BioNeuralNet is an open-source, user-friendly, and extensively documented framework designed to support flexible and reproducible multi-omics network analysis in precision medicine.
        ]]></description>
    </item>
    <item>
        <title>HIAL: A New Paradigm for Hypergraph Active Learning via Influence Maximization</title>
        <link>https://arxiv.org/abs/2507.20490</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.20490v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yanheng Hou, Xunkai Li, Zhenjun Li, Bing Zhou, Ronghua Li, Guoren Wang</dc:creator>
        <description><![CDATA[
            背景：超图神经网络处理高阶交互复杂系统潜力大，但获取大规模高质量标注数据成本高，现有图主动学习方法应用于超图时会破坏高阶结构信息，影响性能。方法：提出专为超图设计的主动学习框架 HIAL，将超图主动学习问题转化为影响最大化任务，核心是基于“高阶交互感知”传播机制的双视角影响函数，并证明目标函数的特性以使用高效贪心算法。效果：在七个公开数据集上实验表明，HIAL 在性能、效率等方面显著优于现有基线。
            arXiv:2507.20490v1 Announce Type: new 
Abstract: In recent years, Hypergraph Neural Networks (HNNs) have demonstrated immense potential in handling complex systems with high-order interactions. However, acquiring large-scale, high-quality labeled data for these models is costly, making Active Learning (AL) a critical technique. Existing Graph Active Learning (GAL) methods, when applied to hypergraphs, often rely on techniques like "clique expansion," which destroys the high-order structural information crucial to a hypergraph's success, thereby leading to suboptimal performance. To address this challenge, we introduce HIAL (Hypergraph Active Learning), a native active learning framework designed specifically for hypergraphs. We innovatively reformulate the Hypergraph Active Learning (HAL) problem as an Influence Maximization task. The core of HIAL is a dual-perspective influence function that, based on our novel "High-Order Interaction-Aware (HOI-Aware)" propagation mechanism, synergistically evaluates a node's feature-space coverage (via Magnitude of Influence, MoI) and its topological influence (via Expected Diffusion Value, EDV). We prove that this objective function is monotone and submodular, thus enabling the use of an efficient greedy algorithm with a formal (1-1/e) approximation guarantee. Extensive experiments on seven public datasets demonstrate that HIAL significantly outperforms state-of-the-art baselines in terms of performance, efficiency, generality, and robustness, establishing an efficient and powerful new paradigm for active learning on hypergraphs.
        ]]></description>
    </item>
    <item>
        <title>Speaking in Words, Thinking in Logic: A Dual-Process Framework in QA Systems</title>
        <link>https://arxiv.org/abs/2507.20491</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.20491v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tuan Bui, Trong Le, Phat Thai, Sang Nguyen, Minh Hua, Ngan Pham, Thang Bui, Tho Quan</dc:creator>
        <description><![CDATA[
            背景：大语言模型提升了开放域问答能力，但封闭域场景下用户还需透明推理和可解释决策过程，现有神经符号框架存在依赖大模型、自然语言转形式逻辑效率低的问题。方法：引入轻量级Text - JEPA框架将自然语言转换为一阶逻辑，结合双系统认知理论，Text - JEPA生成逻辑表示，Z3求解器进行推理，并提出综合评估框架。效果：在特定领域数据集上，Text - JEPA计算开销低且性能有竞争力，为构建高效可解释问答系统提供可能。
            arXiv:2507.20491v1 Announce Type: new 
Abstract: Recent advances in large language models (LLMs) have significantly enhanced question-answering (QA) capabilities, particularly in open-domain contexts. However, in closed-domain scenarios such as education, healthcare, and law, users demand not only accurate answers but also transparent reasoning and explainable decision-making processes. While neural-symbolic (NeSy) frameworks have emerged as a promising solution, leveraging LLMs for natural language understanding and symbolic systems for formal reasoning, existing approaches often rely on large-scale models and exhibit inefficiencies in translating natural language into formal logic representations.
  To address these limitations, we introduce Text-JEPA (Text-based Joint-Embedding Predictive Architecture), a lightweight yet effective framework for converting natural language into first-order logic (NL2FOL). Drawing inspiration from dual-system cognitive theory, Text-JEPA emulates System 1 by efficiently generating logic representations, while the Z3 solver operates as System 2, enabling robust logical inference. To rigorously evaluate the NL2FOL-to-reasoning pipeline, we propose a comprehensive evaluation framework comprising three custom metrics: conversion score, reasoning score, and Spearman rho score, which collectively capture the quality of logical translation and its downstream impact on reasoning accuracy.
  Empirical results on domain-specific datasets demonstrate that Text-JEPA achieves competitive performance with significantly lower computational overhead compared to larger LLM-based systems. Our findings highlight the potential of structured, interpretable reasoning frameworks for building efficient and explainable QA systems in specialized domains.
        ]]></description>
    </item>
    <item>
        <title>Mixture of Length and Pruning Experts for Knowledge Graphs Reasoning</title>
        <link>https://arxiv.org/abs/2507.20498</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.20498v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Enjun Du, Siyi Liu, Yongqi Zhang</dc:creator>
        <description><![CDATA[
            知识图谱推理对自然语言处理系统至关重要，其效果依赖于构建推理路径。但现有图神经网络路径探索策略缺乏灵活性，限制了对不同语言和语义的适应能力。为此提出MoKGR框架，包含长度专家混合体和剪枝专家混合体，前者根据查询复杂度自适应选择和加权候选路径长度，后者从互补视角评估候选路径。在多个基准测试中，MoKGR在归纳和直推设置下均表现出色，验证了个性化路径探索的有效性。
            arXiv:2507.20498v1 Announce Type: new 
Abstract: Knowledge Graph (KG) reasoning, which aims to infer new facts from structured knowledge repositories, plays a vital role in Natural Language Processing (NLP) systems. Its effectiveness critically depends on constructing informative and contextually relevant reasoning paths. However, existing graph neural networks (GNNs) often adopt rigid, query-agnostic path-exploration strategies, limiting their ability to adapt to diverse linguistic contexts and semantic nuances. To address these limitations, we propose \textbf{MoKGR}, a mixture-of-experts framework that personalizes path exploration through two complementary components: (1) a mixture of length experts that adaptively selects and weights candidate path lengths according to query complexity, providing query-specific reasoning depth; and (2) a mixture of pruning experts that evaluates candidate paths from a complementary perspective, retaining the most informative paths for each query. Through comprehensive experiments on diverse benchmark, MoKGR demonstrates superior performance in both transductive and inductive settings, validating the effectiveness of personalized path exploration in KGs reasoning.
        ]]></description>
    </item>
    <item>
        <title>Attributed Graph Clustering with Multi-Scale Weight-Based Pairwise Coarsening and Contrastive Learning</title>
        <link>https://arxiv.org/abs/2507.20505</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.20505v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Binxiong Li, Yuefei Wang, Binyu Zhao, Heyang Gao, Benhan Yang, Quanzhou Luo, Xue Li, Xu Xiang, Yujie Liu, Huijie Tang</dc:creator>
        <description><![CDATA[
            该研究背景是现有属性图聚类方法存在长距离依赖、特征崩溃和信息丢失等问题。为此提出MPCCL模型，其方法是采用创新的多尺度粗化策略，优先合并关键边以保留结构信息，引入一对多对比学习范式增强特征多样性，还在自监督学习框架中加入图重建损失和KL散度确保节点表示的跨尺度一致性。实验效果显著，在ACM数据集上NMI提升15.24%，在Citeseer等小尺度数据集上也有稳健提升。
            arXiv:2507.20505v1 Announce Type: new 
Abstract: This study introduces the Multi-Scale Weight-Based Pairwise Coarsening and Contrastive Learning (MPCCL) model, a novel approach for attributed graph clustering that effectively bridges critical gaps in existing methods, including long-range dependency, feature collapse, and information loss. Traditional methods often struggle to capture high-order graph features due to their reliance on low-order attribute information, while contrastive learning techniques face limitations in feature diversity by overemphasizing local neighborhood structures. Similarly, conventional graph coarsening methods, though reducing graph scale, frequently lose fine-grained structural details. MPCCL addresses these challenges through an innovative multi-scale coarsening strategy, which progressively condenses the graph while prioritizing the merging of key edges based on global node similarity to preserve essential structural information. It further introduces a one-to-many contrastive learning paradigm, integrating node embeddings with augmented graph views and cluster centroids to enhance feature diversity, while mitigating feature masking issues caused by the accumulation of high-frequency node weights during multi-scale coarsening. By incorporating a graph reconstruction loss and KL divergence into its self-supervised learning framework, MPCCL ensures cross-scale consistency of node representations. Experimental evaluations reveal that MPCCL achieves a significant improvement in clustering performance, including a remarkable 15.24% increase in NMI on the ACM dataset and notable robust gains on smaller-scale datasets such as Citeseer, Cora and DBLP.
        ]]></description>
    </item>
    <item>
        <title>Ontology-Enhanced Knowledge Graph Completion using Large Language Models</title>
        <link>https://arxiv.org/abs/2507.20643</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.20643v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wenbin Guo, Xin Wang, Jiaoyan Chen, Zhao Li, Zirui Chen</dc:creator>
        <description><![CDATA[
            大语言模型在知识图谱补全（KGC）领域应用广泛，但现有基于大语言模型的KGC方法作为黑盒模型，依赖隐式知识表示且会传播错误知识，影响推理效果。为此提出本体增强的KGC方法OL - KGC，先利用神经感知机制将结构信息嵌入文本空间，再从待补全的知识图谱中提取本体知识并转化为文本格式为大语言模型提供逻辑指导。在三个基准数据集上实验表明，该方法在多个评估指标上显著优于现有主流方法，达到了当前最优性能。
            arXiv:2507.20643v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have been extensively adopted in Knowledge Graph Completion (KGC), showcasing significant research advancements. However, as black-box models driven by deep neural architectures, current LLM-based KGC methods rely on implicit knowledge representation with parallel propagation of erroneous knowledge, thereby hindering their ability to produce conclusive and decisive reasoning outcomes. We aim to integrate neural-perceptual structural information with ontological knowledge, leveraging the powerful capabilities of LLMs to achieve a deeper understanding of the intrinsic logic of the knowledge. We propose an ontology enhanced KGC method using LLMs -- OL-KGC. It first leverages neural perceptual mechanisms to effectively embed structural information into the textual space, and then uses an automated extraction algorithm to retrieve ontological knowledge from the knowledge graphs (KGs) that needs to be completed, which is further transformed into a textual format comprehensible to LLMs for providing logic guidance. We conducted extensive experiments on three widely-used benchmarks -- FB15K-237, UMLS and WN18RR. The experimental results demonstrate that OL-KGC significantly outperforms existing mainstream KGC methods across multiple evaluation metrics, achieving state-of-the-art performance.
        ]]></description>
    </item>
    <item>
        <title>Dark Side of Modalities: Reinforced Multimodal Distillation for Multimodal Knowledge Graph Reasoning</title>
        <link>https://arxiv.org/abs/2507.20738</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.20738v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yu Zhao, Ying Zhang, Xuhui Sui, Baohang Zhou, Haoze Zhu, Jeff Z. Pan, Xiaojie Yuan</dc:creator>
        <description><![CDATA[
            多模态知识图谱推理（MKGR）任务旨在利用实体的辅助图像和描述预测不完整多模态知识图谱中缺失的事实。现有方法用单目标训练，忽略实体标签概率相关性，且未考虑无用模态负面影响。为此提出强化多模态蒸馏框架DSoM。一是利用非目标实体的暗知识，通过对数蒸馏训练单模态KGR模型以模仿预训练多模态教师模型的软标签；二是处理无用模态，引入强化教师组合机制动态选择最优教师集。实验表明该框架在5个MKGR数据集上有效。
            arXiv:2507.20738v1 Announce Type: new 
Abstract: The multimodal knowledge graph reasoning (MKGR) task aims to predict the missing facts in the incomplete MKGs by leveraging auxiliary images and descriptions of entities. Existing approaches are trained with single-target objectives, which neglect the probabilistic correlations of entity labels, especially in non-target entities. Moreover, previous studies incorporate all modalities statically or adaptively, overlooking the negative impacts of irrelevant or misleading information in the incompetent modalities. To address these issues, we introduce a novel Reinforced Multimodal Distillation framework, exploiting the Dark Side of Modalities (DSoM) from two perspectives: (1) Dark knowledge from non-target entities: We propose to train a unimodal KGR model through logit distillation to mimic the multimodal soft labels provided by pre-trained multimodal teacher models. The multimodal soft labels could provide rich supervision signals with subtle correlations among both target and non-target entities from multiple perspectives. We further decouple logits into neighbor entities and non-neighbor entities to divide into two types of correlations. (2) Dark side in unhelpful modalities: To exclude the adverse effects of unhelpful modalities, we introduce a reinforced teacher combination mechanism that dynamically selects the optimal set of multimodal teachers for each triple. The agent is trained to maximize the rewards, which are only assigned to the beneficial multimodal combination strategies for the student model. Comprehensive experiments demonstrate the effectiveness of DSoM framework on 5 MKGR datasets. Codes are available at github.com/OreOZhao/DSoM.
        ]]></description>
    </item>
    <item>
        <title>Zero-Shot Learning with Subsequence Reordering Pretraining for Compound-Protein Interaction</title>
        <link>https://arxiv.org/abs/2507.20925</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.20925v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hongzhi Zhang, Zhonglie Liu, Kun Meng, Jiameng Chen, Jia Wu, Bo Du, Di Lin, Yan Che, Wenbin Hu</dc:creator>
        <description><![CDATA[
            背景：零样本化合物 - 蛋白质相互作用（CPI）预测更贴合实际药物开发需求，但现有方法存在忽视子序列依赖、依赖大规模数据集等问题。方法：提出用子序列重排预训练蛋白质表示的新方法，明确捕捉蛋白质子序列间依赖关系，并应用可变长度蛋白质增强确保小数据集上的预训练效果。效果：结合多种基线方法评估，结果显示该方法能提升CPI任务性能，尤其在零样本场景表现出色，在数据稀缺场景优于现有预训练模型。
            arXiv:2507.20925v1 Announce Type: new 
Abstract: Given the vastness of chemical space and the ongoing emergence of previously uncharacterized proteins, zero-shot compound-protein interaction (CPI) prediction better reflects the practical challenges and requirements of real-world drug development. Although existing methods perform adequately during certain CPI tasks, they still face the following challenges: (1) Representation learning from local or complete protein sequences often overlooks the complex interdependencies between subsequences, which are essential for predicting spatial structures and binding properties. (2) Dependence on large-scale or scarce multimodal protein datasets demands significant training data and computational resources, limiting scalability and efficiency. To address these challenges, we propose a novel approach that pretrains protein representations for CPI prediction tasks using subsequence reordering, explicitly capturing the dependencies between protein subsequences. Furthermore, we apply length-variable protein augmentation to ensure excellent pretraining performance on small training datasets. To evaluate the model's effectiveness and zero-shot learning ability, we combine it with various baseline methods. The results demonstrate that our approach can improve the baseline model's performance on the CPI task, especially in the challenging zero-shot scenario. Compared to existing pre-training models, our model demonstrates superior performance, particularly in data-scarce scenarios where training samples are limited. Our implementation is available at https://github.com/Hoch-Zhang/PSRP-CPI.
        ]]></description>
    </item>
    <item>
        <title>ARC-Hunyuan-Video-7B: Structured Video Comprehension of Real-World Shorts</title>
        <link>https://arxiv.org/abs/2507.20939</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.20939v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuying Ge, Yixiao Ge, Chen Li, Teng Wang, Junfu Pu, Yizhuo Li, Lu Qiu, Jin Ma, Lisheng Duan, Xinyu Zuo, Jinwen Luo, Weibo Gu, Zexuan Li, Xiaojing Zhang, Yangyu Tao, Han Hu, Di Wang, Ying Shan</dc:creator>
        <description><![CDATA[
            背景：当前大模型缺乏对现实世界短视频的结构化理解能力，而理解这类视频因元素复杂、信息密度高颇具挑战。方法：提出多模态模型ARC - Hunyuan - Video，端到端处理视频的视觉、音频和文本信号；利用自动化标注管道的高质量数据，通过预训练、指令微调等流程训练7B参数模型。效果：在ShortVid - Bench基准测试中表现出色，支持多种下游应用；实际部署提升了用户参与度和满意度，推理效率高，1分钟视频推理仅需10秒。
            arXiv:2507.20939v1 Announce Type: new 
Abstract: Real-world user-generated short videos, especially those distributed on platforms such as WeChat Channel and TikTok, dominate the mobile internet. However, current large multimodal models lack essential temporally-structured, detailed, and in-depth video comprehension capabilities, which are the cornerstone of effective video search and recommendation, as well as emerging video applications. Understanding real-world shorts is actually challenging due to their complex visual elements, high information density in both visuals and audio, and fast pacing that focuses on emotional expression and viewpoint delivery. This requires advanced reasoning to effectively integrate multimodal information, including visual, audio, and text. In this work, we introduce ARC-Hunyuan-Video, a multimodal model that processes visual, audio, and textual signals from raw video inputs end-to-end for structured comprehension. The model is capable of multi-granularity timestamped video captioning and summarization, open-ended video question answering, temporal video grounding, and video reasoning. Leveraging high-quality data from an automated annotation pipeline, our compact 7B-parameter model is trained through a comprehensive regimen: pre-training, instruction fine-tuning, cold start, reinforcement learning (RL) post-training, and final instruction fine-tuning. Quantitative evaluations on our introduced benchmark ShortVid-Bench and qualitative comparisons demonstrate its strong performance in real-world video comprehension, and it supports zero-shot or fine-tuning with a few samples for diverse downstream applications. The real-world production deployment of our model has yielded tangible and measurable improvements in user engagement and satisfaction, a success supported by its remarkable efficiency, with stress tests indicating an inference time of just 10 seconds for a one-minute video on H20 GPU.
        ]]></description>
    </item>
    <item>
        <title>PROVCREATOR: Synthesizing Complex Heterogenous Graphs with Node and Edge Attributes</title>
        <link>https://arxiv.org/abs/2507.20967</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.20967v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tianhao Wang, Simon Klancher, Kunal Mukherjee, Josh Wiedemeier, Feng Chen, Murat Kantarcioglu, Kangkook Jee</dc:creator>
        <description><![CDATA[
            背景：图结构数据兴起推动图学习与合成数据生成，但合成图生成仍具挑战，现有研究多关注简单同质结构。方法：提出ProvCreator，将图合成视为序列生成任务，利用基于Transformer的大语言模型，采用通用的图到序列编解码器，能无损编码图结构与属性、高效压缩大图、支持端到端可学习的图生成。效果：在网络安全系统溯源图和知识图谱两个领域验证，能捕捉结构与语义间复杂依赖，生成逼真且注重隐私的合成数据集。
            arXiv:2507.20967v1 Announce Type: new 
Abstract: The rise of graph-structured data has driven interest in graph learning and synthetic data generation. While successful in text and image domains, synthetic graph generation remains challenging -- especially for real-world graphs with complex, heterogeneous schemas. Existing research has focused mostly on homogeneous structures with simple attributes, limiting their usefulness and relevance for application domains requiring semantic fidelity.
  In this research, we introduce ProvCreator, a synthetic graph framework designed for complex heterogeneous graphs with high-dimensional node and edge attributes. ProvCreator formulates graph synthesis as a sequence generation task, enabling the use of transformer-based large language models. It features a versatile graph-to-sequence encoder-decoder that 1. losslessly encodes graph structure and attributes, 2. efficiently compresses large graphs for contextual modeling, and 3. supports end-to-end, learnable graph generation.
  To validate our research, we evaluate ProvCreator on two challenging domains: system provenance graphs in cybersecurity and knowledge graphs from IntelliGraph Benchmark Dataset. In both cases, ProvCreator captures intricate dependencies between structure and semantics, enabling the generation of realistic and privacy-aware synthetic datasets.
        ]]></description>
    </item>
    <item>
        <title>LoRA-PAR: A Flexible Dual-System LoRA Partitioning Approach to Efficient LLM Fine-Tuning</title>
        <link>https://arxiv.org/abs/2507.20999</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.20999v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yining Huang, Bin Li, Keke Tang, Meilian Chen</dc:creator>
        <description><![CDATA[
            背景：大规模生成模型利用思维链推理提升性能需大量数据、大模型规模和全参数微调，现有参数高效微调方法未针对不同响应需求定制数据和参数。方法：受“快思慢想”启发，提出LoRA - PAR双系统LoRA框架，按系统1和系统2需求划分数据和参数，通过多模型角色扮演和投票分类任务数据、基于重要性得分划分参数，采用监督微调训练系统1任务、强化学习优化系统2任务的两阶段微调策略。效果：降低活跃参数使用量，性能达到或超越现有参数高效微调基线。
            arXiv:2507.20999v1 Announce Type: new 
Abstract: Large-scale generative models like DeepSeek-R1 and OpenAI-O1 benefit substantially from chain-of-thought (CoT) reasoning, yet pushing their performance typically requires vast data, large model sizes, and full-parameter fine-tuning. While parameter-efficient fine-tuning (PEFT) helps reduce cost, most existing approaches primarily address domain adaptation or layer-wise allocation rather than explicitly tailoring data and parameters to different response demands. Inspired by "Thinking, Fast and Slow," which characterizes two distinct modes of thought-System 1 (fast, intuitive, often automatic) and System 2 (slower, more deliberative and analytic)-we draw an analogy that different "subregions" of an LLM's parameters might similarly specialize for tasks that demand quick, intuitive responses versus those requiring multi-step logical reasoning. Therefore, we propose LoRA-PAR, a dual-system LoRA framework that partitions both data and parameters by System 1 or System 2 demands, using fewer yet more focused parameters for each task. Specifically, we classify task data via multi-model role-playing and voting, and partition parameters based on importance scoring, then adopt a two-stage fine-tuning strategy of training System 1 tasks with supervised fine-tuning (SFT) to enhance knowledge and intuition and refine System 2 tasks with reinforcement learning (RL) to reinforce deeper logical deliberation next. Extensive experiments show that the two-stage fine-tuning strategy, SFT and RL, lowers active parameter usage while matching or surpassing SOTA PEFT baselines.
        ]]></description>
    </item>
    <item>
        <title>Transformers as Unrolled Inference in Probabilistic Laplacian Eigenmaps: An Interpretation and Potential Improvements</title>
        <link>https://arxiv.org/abs/2507.21040</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.21040v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Aditya Ravuri, Neil D. Lawrence</dc:creator>
        <description><![CDATA[
            背景：旨在对transformers进行概率解释。方法：假设基于ProbDR框架的概率拉普拉斯特征映射模型，将transformers视为展开的推理步骤，推导发现初始化时transformers进行“线性”降维，且在transformer块中出现图拉普拉斯项而非注意力矩阵。效果：通过从注意力矩阵中减去单位矩阵（进行图扩散步骤），提升了语言模型和简单视觉transformer的验证性能。
            arXiv:2507.21040v1 Announce Type: new 
Abstract: We propose a probabilistic interpretation of transformers as unrolled inference steps assuming a probabilistic Laplacian Eigenmaps model from the ProbDR framework. Our derivation shows that at initialisation, transformers perform "linear" dimensionality reduction. We also show that within the transformer block, a graph Laplacian term arises from our arguments, rather than an attention matrix (which we interpret as an adjacency matrix). We demonstrate that simply subtracting the identity from the attention matrix (and thereby taking a graph diffusion step) improves validation performance on a language model and a simple vision transformer.
        ]]></description>
    </item>
    <item>
        <title>HypKG: Hypergraph-based Knowledge Graph Contextualization for Precision Healthcare</title>
        <link>https://arxiv.org/abs/2507.19726</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.19726v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuzhang Xie, Xu Han, Ran Xu, Xiao Hu, Jiaying Lu, Carl Yang</dc:creator>
        <description><![CDATA[
            知识图谱在医疗领域应用广泛，但存储通用事实信息的知识图谱缺乏特定患者状态等重要上下文信息，而电子健康记录可提供自然上下文。为此，本文提出HypKG框架，将电子健康记录中的患者信息集成到知识图谱中。通过先进实体链接技术连接相关知识与患者信息，利用超图模型进行上下文处理，采用超图变换器联合学习知识图谱和患者的上下文表示。实验表明，在多个评估指标上，HypKG在医疗预测任务中显著提升，还能调整知识图谱中实体和关系的表示，提高知识质量和实用性。
            arXiv:2507.19726v1 Announce Type: cross 
Abstract: Knowledge graphs (KGs) are important products of the semantic web, which are widely used in various application domains. Healthcare is one of such domains where KGs are intensively used, due to the high requirement for knowledge accuracy and interconnected nature of healthcare data. However, KGs storing general factual information often lack the ability to account for important contexts of the knowledge such as the status of specific patients, which are crucial in precision healthcare. Meanwhile, electronic health records (EHRs) provide rich personal data, including various diagnoses and medications, which provide natural contexts for general KGs. In this paper, we propose HypKG, a framework that integrates patient information from EHRs into KGs to generate contextualized knowledge representations for accurate healthcare predictions. Using advanced entity-linking techniques, we connect relevant knowledge from general KGs with patient information from EHRs, and then utilize a hypergraph model to "contextualize" the knowledge with the patient information. Finally, we employ hypergraph transformers guided by downstream prediction tasks to jointly learn proper contextualized representations for both KGs and patients, fully leveraging existing knowledge in KGs and patient contexts in EHRs. In experiments using a large biomedical KG and two real-world EHR datasets, HypKG demonstrates significant improvements in healthcare prediction tasks across multiple evaluation metrics. Additionally, by integrating external contexts, HypKG can learn to adjust the representations of entities and relations in KG, potentially improving the quality and real-world utility of knowledge.
        ]]></description>
    </item>
    <item>
        <title>Leveraging Fine-Tuned Large Language Models for Interpretable Pancreatic Cystic Lesion Feature Extraction and Risk Categorization</title>
        <link>https://arxiv.org/abs/2507.19973</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.19973v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ebrahim Rasromani, Stella K. Kang, Yanqi Xu, Beisong Liu, Garvit Luhadia, Wan Fung Chui, Felicia L. Pasadyn, Yu Chih Hung, Julie Y. An, Edwin Mathieu, Zehui Gu, Carlos Fernandez-Granda, Ammar A. Javed, Greg D. Sacks, Tamas Gonda, Chenchan Huang, Yiqiu Shen</dc:creator>
        <description><![CDATA[
            背景：从放射学报告中手动提取胰腺囊性病变（PCL）特征费力，限制了PCL研究。目的是开发自动提取特征并分类风险的大语言模型。方法：整理6000份报告作为训练集，用思维链（CoT）提示GPT - 4o生成标签，用QLoRA微调两个开源大模型，映射特征到风险类别。在285份报告上评估。结果：CoT微调使特征提取准确率大幅提升，风险分类F1分数提高，与GPT - 4o相当，模型与放射科医生一致性高。
            arXiv:2507.19973v1 Announce Type: cross 
Abstract: Background: Manual extraction of pancreatic cystic lesion (PCL) features from radiology reports is labor-intensive, limiting large-scale studies needed to advance PCL research. Purpose: To develop and evaluate large language models (LLMs) that automatically extract PCL features from MRI/CT reports and assign risk categories based on guidelines. Materials and Methods: We curated a training dataset of 6,000 abdominal MRI/CT reports (2005-2024) from 5,134 patients that described PCLs. Labels were generated by GPT-4o using chain-of-thought (CoT) prompting to extract PCL and main pancreatic duct features. Two open-source LLMs were fine-tuned using QLoRA on GPT-4o-generated CoT data. Features were mapped to risk categories per institutional guideline based on the 2017 ACR White Paper. Evaluation was performed on 285 held-out human-annotated reports. Model outputs for 100 cases were independently reviewed by three radiologists. Feature extraction was evaluated using exact match accuracy, risk categorization with macro-averaged F1 score, and radiologist-model agreement with Fleiss' Kappa. Results: CoT fine-tuning improved feature extraction accuracy for LLaMA (80% to 97%) and DeepSeek (79% to 98%), matching GPT-4o (97%). Risk categorization F1 scores also improved (LLaMA: 0.95; DeepSeek: 0.94), closely matching GPT-4o (0.97), with no statistically significant differences. Radiologist inter-reader agreement was high (Fleiss' Kappa = 0.888) and showed no statistically significant difference with the addition of DeepSeek-FT-CoT (Fleiss' Kappa = 0.893) or GPT-CoT (Fleiss' Kappa = 0.897), indicating that both models achieved agreement levels on par with radiologists. Conclusion: Fine-tuned open-source LLMs with CoT supervision enable accurate, interpretable, and efficient phenotyping for large-scale PCL research, achieving performance comparable to GPT-4o.
        ]]></description>
    </item>
    <item>
        <title>A Multi-Agent System for Information Extraction from the Chemical Literature</title>
        <link>https://arxiv.org/abs/2507.20230</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.20230v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yufan Chen, Ching Ting Leung, Bowen Yu, Jianwei Sun, Yong Huang, Linyan Li, Hao Chen, Hanyu Gao</dc:creator>
        <description><![CDATA[
            高质量化学数据库是推动人工智能化学研究的基础，从文献中自动提取化学信息构建反应数据库受限于信息多模态和风格多变性。为此，研究人员开发了基于多模态大模型的多智能体系统用于自动提取化学信息。利用大模型强大推理能力理解复杂化学图形结构，将提取任务分解并协调专业智能体解决。该系统在复杂化学反应图形基准数据集上F1得分达80.8%，远超先前模型的35.6%，各子任务表现也有提升，推动了化学信息结构化提取。
            arXiv:2507.20230v1 Announce Type: cross 
Abstract: To fully expedite AI-powered chemical research, high-quality chemical databases are the cornerstone. Automatic extraction of chemical information from the literature is essential for constructing reaction databases, but it is currently limited by the multimodality and style variability of chemical information. In this work, we developed a multimodal large language model (MLLM)-based multi-agent system for automatic chemical information extraction. We used the MLLM's strong reasoning capability to understand the structure of complex chemical graphics, decompose the extraction task into sub-tasks and coordinate a set of specialized agents to solve them. Our system achieved an F1 score of 80.8% on a benchmark dataset of complex chemical reaction graphics from the literature, surpassing the previous state-of-the-art model (F1 score: 35.6%) by a significant margin. Additionally, it demonstrated consistent improvements in key sub-tasks, including molecular image recognition, reaction image parsing, named entity recognition and text-based reaction extraction. This work is a critical step toward automated chemical information extraction into structured datasets, which will be a strong promoter of AI-driven chemical research.
        ]]></description>
    </item>
    <item>
        <title>SciToolAgent: A Knowledge Graph-Driven Scientific Agent for Multi-Tool Integration</title>
        <link>https://arxiv.org/abs/2507.20280</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.20280v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Keyan Ding, Jing Yu, Junjie Huang, Yuchen Yang, Qiang Zhang, Huajun Chen</dc:creator>
        <description><![CDATA[
            背景：科研依赖专业计算工具，大语言模型虽可实现工具自动化，但在复杂科研流程中集成和编排多工具存在困难。方法：提出SciToolAgent，借助科学工具知识图谱，通过基于图的检索增强生成实现智能工具选择与执行，还设有安全检查模块。效果：在基准测试中显著优于现有方法，在多个科研案例中展现出自动化复杂科研流程的能力，让专家和非专家都能使用高级研究工具。
            arXiv:2507.20280v1 Announce Type: cross 
Abstract: Scientific research increasingly relies on specialized computational tools, yet effectively utilizing these tools demands substantial domain expertise. While Large Language Models (LLMs) show promise in tool automation, they struggle to seamlessly integrate and orchestrate multiple tools for complex scientific workflows. Here, we present SciToolAgent, an LLM-powered agent that automates hundreds of scientific tools across biology, chemistry, and materials science. At its core, SciToolAgent leverages a scientific tool knowledge graph that enables intelligent tool selection and execution through graph-based retrieval-augmented generation. The agent also incorporates a comprehensive safety-checking module to ensure responsible and ethical tool usage. Extensive evaluations on a curated benchmark demonstrate that SciToolAgent significantly outperforms existing approaches. Case studies in protein engineering, chemical reactivity prediction, chemical synthesis, and metal-organic framework screening further demonstrate SciToolAgent's capability to automate complex scientific workflows, making advanced research tools accessible to both experts and non-experts.
        ]]></description>
    </item>
    <item>
        <title>Complementarity-driven Representation Learning for Multi-modal Knowledge Graph Completion</title>
        <link>https://arxiv.org/abs/2507.20620</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.20620v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Lijian Li</dc:creator>
        <description><![CDATA[
            多模态知识图谱补全（MMKGC）旨在利用多模态和实体结构信息挖掘隐藏知识，但多模态知识图谱中模态分布不平衡，现有方法忽视多模态数据互补性。为此，本文提出互补模态专家混合（MoCME）框架，包含互补性引导的模态知识融合（CMKF）模块和熵引导的负采样（EGNS）机制。CMKF模块利用模态内和模态间互补性融合嵌入，EGNS机制动态筛选负样本。在五个基准数据集上实验表明，MoCME性能达最优。
            arXiv:2507.20620v1 Announce Type: cross 
Abstract: Multi-modal Knowledge Graph Completion (MMKGC) aims to uncover hidden world knowledge in multimodal knowledge graphs by leveraging both multimodal and structural entity information. However, the inherent imbalance in multimodal knowledge graphs, where modality distributions vary across entities, poses challenges in utilizing additional modality data for robust entity representation. Existing MMKGC methods typically rely on attention or gate-based fusion mechanisms but overlook complementarity contained in multi-modal data. In this paper, we propose a novel framework named Mixture of Complementary Modality Experts (MoCME), which consists of a Complementarity-guided Modality Knowledge Fusion (CMKF) module and an Entropy-guided Negative Sampling (EGNS) mechanism. The CMKF module exploits both intra-modal and inter-modal complementarity to fuse multi-view and multi-modal embeddings, enhancing representations of entities. Additionally, we introduce an Entropy-guided Negative Sampling mechanism to dynamically prioritize informative and uncertain negative samples to enhance training effectiveness and model robustness. Extensive experiments on five benchmark datasets demonstrate that our MoCME achieves state-of-the-art performance, surpassing existing approaches.
        ]]></description>
    </item>
    <item>
        <title>MeTHanol: Modularized Thinking Language Models with Intermediate Layer Thinking, Decoding and Bootstrapping Reasoning</title>
        <link>https://arxiv.org/abs/2409.12059</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2409.12059v5</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ningyuan Xi, Xiaoyu Wang, Yetao Wu, Teng Chen, Qingqing Gu, Yue Zhao, Jinxian Qu, Zhonglin Jiang, Yong Chen, Luo Ji</dc:creator>
        <description><![CDATA[
            当前研究多通过提示、数据驱动涌现和推理时计算来增强大语言模型（LLM）的思考和推理能力。本文从模块化视角出发，模仿人类大脑架构激发语言模型的思考和认知能力。通过选择特定中间注意力层并添加新语言头，用标注样本进行双层微调，设计两阶段推理机制。所提出的模块化思维语言模型MeTHanol经实验表明能增强LLM的认知行为，案例显示其能规划、自我反思，生成类人思考和答案，还能适应个性化提示，有显著认知提升潜力。
            arXiv:2409.12059v5 Announce Type: replace 
Abstract: Current research efforts are focused on enhancing the thinking and reasoning capability of large language model (LLM) by prompting, data-driven emergence and inference-time computation. In this study, we consider stimulating language model's thinking and cognitive abilities from a modular perspective, which mimics the human brain architecture. We select a specific intermediate attention layer with newly implemented language heads. We conduct dual-layer fine-tuning by annotated (query, thought, answer) samples and show that the intermediate layer can also learn to decode fluent and reasonable language tokens. A two-pass inference mechanism is designed to generate thoughts then formal responses. The entire framework is called modularized thinking language model (MeTHanol) which can enhance LLM's cognitive behaviors as indicated by Theory of Mind (ToM) and Vignette-based experiments. Case studies also show that MeTHanol can plan and self-reflect and generate human-like thoughts and answers, even on unseen and open-domain tasks. MeTHanol can also adapt to a personalized prompt and behave as the specified character. Our study holds promise for significant cognitive gains from a modular perspective. Our code, model and data are available at https://bachozean.github.io/methanol-page
        ]]></description>
    </item>
    <item>
        <title>How to Bridge Spatial and Temporal Heterogeneity in Link Prediction? A Contrastive Method</title>
        <link>https://arxiv.org/abs/2411.00612</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2411.00612v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yu Tai, Xinglong Wu, Hongwei Yang, Hui He, Duanjing Chen, Yuanming Shao, Weizhe Zhang</dc:creator>
        <description><![CDATA[
            背景：时间异质网络对链路预测研究意义重大，但现有方法无法捕捉细粒度差异分布和时间动态特征。方法：提出基于对比学习的链路预测模型CLP，采用多视图分层自监督架构编码时空异质性，设计空间特征和时间信息建模层分别捕捉空间和时间特征，并从对比学习角度编码时空分布异质性。效果：在四个数据集上实验，CLP比现有模型表现更优，AUC和AP平均提升10.10%、13.44%。
            arXiv:2411.00612v2 Announce Type: replace 
Abstract: Temporal Heterogeneous Networks play a crucial role in capturing the dynamics and heterogeneity inherent in various real-world complex systems, rendering them a noteworthy research avenue for link prediction. However, existing methods fail to capture the fine-grained differential distribution patterns and temporal dynamic characteristics, which we refer to as spatial heterogeneity and temporal heterogeneity. To overcome such limitations, we propose a novel \textbf{C}ontrastive Learning-based \textbf{L}ink \textbf{P}rediction model, \textbf{CLP}, which employs a multi-view hierarchical self-supervised architecture to encode spatial and temporal heterogeneity. Specifically, aiming at spatial heterogeneity, we develop a spatial feature modeling layer to capture the fine-grained topological distribution patterns from node- and edge-level representations, respectively. Furthermore, aiming at temporal heterogeneity, we devise a temporal information modeling layer to perceive the evolutionary dependencies of dynamic graph topologies from time-level representations. Finally, we encode the spatial and temporal distribution heterogeneity from a contrastive learning perspective, enabling a comprehensive self-supervised hierarchical relation modeling for the link prediction task. Extensive experiments conducted on four real-world dynamic heterogeneous network datasets verify that our \mymodel consistently outperforms the state-of-the-art models, demonstrating an average improvement of 10.10\%, 13.44\% in terms of AUC and AP, respectively.
        ]]></description>
    </item>
    <item>
        <title>Automating Mathematical Proof Generation Using Large Language Model Agents and Knowledge Graphs</title>
        <link>https://arxiv.org/abs/2503.11657</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.11657v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Vincent Li, Tim Knappe, Yule Fu, Kevin Han, Kevin Zhu</dc:creator>
        <description><![CDATA[
            大语言模型在需要多步逻辑推理的自然语言处理任务（如自动定理证明）中展现出强大能力，但定理证明仍存在识别关键数学概念、理解概念关系和正确形式化证明等挑战。为此提出KG - prover框架，利用从权威数学文本中挖掘的知识图增强通用大语言模型构建和形式化数学证明。研究了基于图的测试时计算扩展的效果，在多个数据集上显著优于基线。通用大语言模型结合KG - prover在miniF2F - test上提升达21%，在多个数据集上稳定提升2 - 11%，o4 - mini版的KG - prover在miniF2F - test上超过50%。
            arXiv:2503.11657v2 Announce Type: replace 
Abstract: Large language models have demonstrated remarkable capabilities in natural language processing tasks requiring multi-step logical reasoning capabilities, such as automated theorem proving. However, challenges persist within theorem proving, such as the identification of key mathematical concepts, understanding their interrelationships, and formalizing proofs correctly within natural language. We present KG-prover, a novel framework that leverages knowledge graphs mined from reputable mathematical texts to augment general-purpose LLMs to construct and formalize mathematical proofs. We also study the effects of scaling graph-based, test-time compute using KG-Prover, demonstrating significant performance improvements over baselines across multiple datasets. General-purpose LLMs improve up to 21\% on miniF2F-test when combined with KG-Prover, with consistent improvements ranging from 2-11\% on the ProofNet, miniF2F-test, and MUSTARD datasets without additional scaling. Furthermore, KG-Prover with o4-mini achieves over 50% miniF2F-test. This work provides a promising approach for augmenting natural language proof reasoning with knowledge graphs without the need for additional finetuning.
        ]]></description>
    </item>
    <item>
        <title>TinySQL: A Progressive Text-to-SQL Dataset for Mechanistic Interpretability Research</title>
        <link>https://arxiv.org/abs/2503.12730</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.12730v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Abir Harrasse, Philip Quirke, Clement Neo, Dhruv Nathawani, Luke Marks, Amir Abdullah</dc:creator>
        <description><![CDATA[
            背景：机械可解释性研究在分析简单任务和大模型特征方面存在差距。方法：提出文本到 SQL 生成作为研究任务，引入从基础到高级 SQL 操作的合成数据集 TinySQL，训练不同参数模型构建测试平台，应用多种可解释性技术识别支持 SQL 生成的电路和组件，比较不同 SQL 子技能电路，进行分层逻辑透镜分析。效果：提供了在结构化、逐步复杂环境中探究和比较可解释性方法的强大框架。
            arXiv:2503.12730v4 Announce Type: replace 
Abstract: Mechanistic interpretability research faces a gap between analyzing simple circuits in toy tasks and discovering features in large models. To bridge this gap, we propose text-to-SQL generation as an ideal task to study, as it combines the formal structure of toy tasks with real-world complexity. We introduce TinySQL, a synthetic dataset, progressing from basic to advanced SQL operations, and train models ranging from 33M to 1B parameters to establish a comprehensive testbed for interpretability. We apply multiple complementary interpretability techniques, including Edge Attribution Patching and Sparse Autoencoders, to identify minimal circuits and components supporting SQL generation. We compare circuits for different SQL subskills, evaluating their minimality, reliability, and identifiability. Finally, we conduct a layerwise logit lens analysis to reveal how models compose SQL queries across layers: from intent recognition to schema resolution to structured generation. Our work provides a robust framework for probing and comparing interpretability methods in a structured, progressively complex setting.
        ]]></description>
    </item>
    <item>
        <title>Interpretable Graph Kolmogorov-Arnold Networks for Multi-Cancer Classification and Biomarker Identification using Multi-Omics Data</title>
        <link>https://arxiv.org/abs/2503.22939</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.22939v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Fadi Alharbi, Nishant Budhiraja, Aleksandar Vakanski, Boyu Zhang, Murtada K. Elbashir, Harshith Guduru, Mohanad Mohammed</dc:creator>
        <description><![CDATA[
            在精准癌症诊断中，系统层面整合多组学数据是一大挑战。本文提出多组学图柯尔莫哥洛夫 - 阿诺德网络（MOGKAN），结合信使 - RNA、微 - RNA 序列、DNA 甲基化样本及蛋白质 - 蛋白质相互作用网络进行 31 种癌症分类。该方法结合多种分析手段降维并保留生物特征，基于柯尔莫哥洛夫 - 阿诺德定理，用可训练单变量函数增强可解释性。MOGKAN 分类准确率达 96.28%，实验变异性低，鉴定的生物标志物也得到验证，有潜力用于临床癌症诊断。
            arXiv:2503.22939v3 Announce Type: replace 
Abstract: The integration of heterogeneous multi-omics datasets at a systems level remains a central challenge for developing analytical and computational models in precision cancer diagnostics. This paper introduces Multi-Omics Graph Kolmogorov-Arnold Network (MOGKAN), a deep learning framework that utilizes messenger-RNA, micro-RNA sequences, and DNA methylation samples together with Protein-Protein Interaction (PPI) networks for cancer classification across 31 different cancer types. The proposed approach combines differential gene expression with DESeq2, Linear Models for Microarray (LIMMA), and Least Absolute Shrinkage and Selection Operator (LASSO) regression to reduce multi-omics data dimensionality while preserving relevant biological features. The model architecture is based on the Kolmogorov-Arnold theorem principle and uses trainable univariate functions to enhance interpretability and feature analysis. MOGKAN achieves classification accuracy of 96.28 percent and exhibits low experimental variability in comparison to related deep learning-based models. The biomarkers identified by MOGKAN were validated as cancer-related markers through Gene Ontology (GO) and Kyoto Encyclopedia of Genes and Genomes (KEGG) enrichment analysis. By integrating multi-omics data with graph-based deep learning, our proposed approach demonstrates robust predictive performance and interpretability with potential to enhance the translation of complex multi-omics data into clinically actionable cancer diagnostics.
        ]]></description>
    </item>
    <item>
        <title>VisualCloze: A Universal Image Generation Framework via Visual In-Context Learning</title>
        <link>https://arxiv.org/abs/2504.07960</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.07960v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhong-Yu Li, Ruoyi Du, Juncheng Yan, Le Zhuo, Zhen Li, Peng Gao, Zhanyu Ma, Ming-Ming Cheng</dc:creator>
        <description><![CDATA[
            背景：当前主流图像生成方法构建特定任务模型效率有限，通用模型面临任务指令、分布和架构设计等挑战。方法：提出VisualCloze通用图像生成框架，集成视觉上下文学习让模型从视觉示例识别任务，引入图结构数据集Graph200K增强任务密度和可迁移知识，利用预训练填充模型生成先验。效果：支持多种领域内任务、泛化到未见任务、统一多任务及反向生成，且无需修改架构就能利用填充模型先验。
            arXiv:2504.07960v2 Announce Type: replace 
Abstract: Recent progress in diffusion models significantly advances various image generation tasks. However, the current mainstream approach remains focused on building task-specific models, which have limited efficiency when supporting a wide range of different needs. While universal models attempt to address this limitation, they face critical challenges, including generalizable task instruction, appropriate task distributions, and unified architectural design. To tackle these challenges, we propose VisualCloze, a universal image generation framework, which supports a wide range of in-domain tasks, generalization to unseen ones, unseen unification of multiple tasks, and reverse generation. Unlike existing methods that rely on language-based task instruction, leading to task ambiguity and weak generalization, we integrate visual in-context learning, allowing models to identify tasks from visual demonstrations. Meanwhile, the inherent sparsity of visual task distributions hampers the learning of transferable knowledge across tasks. To this end, we introduce Graph200K, a graph-structured dataset that establishes various interrelated tasks, enhancing task density and transferable knowledge. Furthermore, we uncover that our unified image generation formulation shared a consistent objective with image infilling, enabling us to leverage the strong generative priors of pre-trained infilling models without modifying the architectures.
        ]]></description>
    </item>
    <item>
        <title>EventVAD: Training-Free Event-Aware Video Anomaly Detection</title>
        <link>https://arxiv.org/abs/2504.13092</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.13092v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yihua Shao, Haojin He, Sijie Li, Siyu Chen, Xinwei Long, Fanhu Zeng, Yuxuan Fan, Muyang Zhang, Ziyang Yan, Ao Ma, Xiaochen Wang, Hao Tang, Yan Wang, Shuyan Li</dc:creator>
        <description><![CDATA[
            视频异常检测中，有监督方法需大量数据且泛化性差，免训练方法存在定位细粒度视觉过渡和多样事件的挑战。为此提出EventVAD框架，结合定制动态图架构和多模态大语言模型进行时间事件推理。先通过带时间衰减约束的动态时空图建模捕捉视频特征，再进行自适应噪声过滤和信号比阈值检测事件边界，最后用分层提示策略引导推理。实验表明，采用7B多模态大语言模型的EventVAD在免训练设置下达最优，超越使用7B及更大模型的基线。
            arXiv:2504.13092v3 Announce Type: replace 
Abstract: Video Anomaly Detection~(VAD) focuses on identifying anomalies within videos. Supervised methods require an amount of in-domain training data and often struggle to generalize to unseen anomalies. In contrast, training-free methods leverage the intrinsic world knowledge of large language models (LLMs) to detect anomalies but face challenges in localizing fine-grained visual transitions and diverse events. Therefore, we propose EventVAD, an event-aware video anomaly detection framework that combines tailored dynamic graph architectures and multimodal LLMs through temporal-event reasoning. Specifically, EventVAD first employs dynamic spatiotemporal graph modeling with time-decay constraints to capture event-aware video features. Then, it performs adaptive noise filtering and uses signal ratio thresholding to detect event boundaries via unsupervised statistical features. The statistical boundary detection module reduces the complexity of processing long videos for MLLMs and improves their temporal reasoning through event consistency. Finally, it utilizes a hierarchical prompting strategy to guide MLLMs in performing reasoning before determining final decisions. We conducted extensive experiments on the UCF-Crime and XD-Violence datasets. The results demonstrate that EventVAD with a 7B MLLM achieves state-of-the-art (SOTA) in training-free settings, outperforming strong baselines that use 7B or larger MLLMs.
        ]]></description>
    </item>
    <item>
        <title>Guide your favorite protein sequence generative model</title>
        <link>https://arxiv.org/abs/2505.04823</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.04823v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Junhao Xiong, Hunter Nisonoff, Maria Lukarska, Ishan Gaur, Luke M. Oltrogge, David F. Savage, Jennifer Listgarten</dc:creator>
        <description><![CDATA[
            背景：序列生成机器学习模型正变革蛋白质工程，但缺乏将辅助信息如实验数据以即插即用方式融入模型的框架。方法：提出ProteinGuide，将多种蛋白质生成模型统一在一个框架下进行条件设定。效果：通过引导ProteinMPNN和ESM3两个蛋白质生成模型，依据用户指定属性生成氨基酸和结构标记序列；还结合逆折叠模型与实验分析，设计出高活性的腺嘌呤碱基编辑器序列。
            arXiv:2505.04823v3 Announce Type: replace 
Abstract: Generative machine learning models on sequences are transforming protein engineering. However, no principled framework exists for conditioning these models on auxiliary information, such as experimental data, in a plug-and-play manner. Herein, we present ProteinGuide -- a principled and general method for conditioning -- by unifying a broad class of protein generative models under a single framework. We demonstrate the applicability of ProteinGuide by guiding two protein generative models, ProteinMPNN and ESM3, to generate amino acid and structure token sequences, conditioned on several user-specified properties such as enhanced stability, enzyme classes, and CATH-labeled folds. We also used ProteinGuide with inverse folding models and our own experimental assay to design adenine base editor sequences for high activity.
        ]]></description>
    </item>
    <item>
        <title>Benchmarking Graph Neural Networks for Document Layout Analysis in Public Affairs</title>
        <link>https://arxiv.org/abs/2505.14699</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14699v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Miguel Lopez-Duran, Julian Fierrez, Aythami Morales, Ruben Tolosana, Oscar Delgado-Mohatar, Alvaro Ortigosa</dc:creator>
        <description><![CDATA[
            背景：数字PDF文档中，文本与非文本元素排列异构、文本元数据不精确，导致文档布局自动分析困难。方法：针对数字原生文档文本块细粒度布局分类任务，引入k近邻图和全连接图两种图构建结构，通过预训练文本和视觉模型生成节点特征，评估单模态、拼接多模态和双分支多模态三种实验框架。效果：在公共事务文档丰富数据集上实验，双分支配置下基于k近邻图的GraphSAGE模型在各类别和整体准确率最高，部分来源表现优于基线。
            arXiv:2505.14699v2 Announce Type: replace 
Abstract: The automatic analysis of document layouts in digital-born PDF documents remains a challenging problem due to the heterogeneous arrangement of textual and nontextual elements and the imprecision of the textual metadata in the Portable Document Format. In this work, we benchmark Graph Neural Network (GNN) architectures for the task of fine-grained layout classification of text blocks from digital native documents. We introduce two graph construction structures: a k-closest-neighbor graph and a fully connected graph, and generate node features via pre-trained text and vision models, thus avoiding manual feature engineering. Three experimental frameworks are evaluated: single-modality (text or visual), concatenated multimodal, and dual-branch multimodal. We evaluated four foundational GNN models and compared them with the baseline. Our experiments are specifically conducted on a rich dataset of public affairs documents that includes more than 20 sources (e.g., regional and national-level official gazettes), 37K PDF documents, with 441K pages in total. Our results demonstrate that GraphSAGE operating on the k-closest-neighbor graph in a dual-branch configuration achieves the highest per-class and overall accuracy, outperforming the baseline in some sources. These findings confirm the importance of local layout relationships and multimodal fusion exploited through GNNs for the analysis of native digital document layouts.
        ]]></description>
    </item>
    <item>
        <title>Causal Sufficiency and Necessity Improves Chain-of-Thought Reasoning</title>
        <link>https://arxiv.org/abs/2506.09853</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.09853v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiangning Yu, Zhuohan Wang, Linyi Yang, Haoxuan Li, Anjie Liu, Xiao Xue, Jun Wang, Mengyue Yang</dc:creator>
        <description><![CDATA[
            思维链（CoT）提示对赋予大语言模型复杂推理能力至关重要，但目前面临充分性和必要性两大挑战。为此，研究提出一个因果框架，从充分性和必要性双视角表征CoT推理。通过引入因果充分性和必要性概率，不仅能判断哪些步骤对预测结果逻辑上充分或必要，还能量化不同干预场景下其对最终推理结果的实际影响，实现自动添加缺失步骤和修剪冗余步骤。实验表明，该方法显著提高推理效率、减少token使用且不降低准确率，为提升大模型推理性能和成本效益提供方向。
            arXiv:2506.09853v2 Announce Type: replace 
Abstract: Chain-of-Thought (CoT) prompting plays an indispensable role in endowing large language models (LLMs) with complex reasoning capabilities. However, CoT currently faces two fundamental challenges: (1) Sufficiency, which ensures that the generated intermediate inference steps comprehensively cover and substantiate the final conclusion; and (2) Necessity, which identifies the inference steps that are truly indispensable for the soundness of the resulting answer. We propose a causal framework that characterizes CoT reasoning through the dual lenses of sufficiency and necessity. Incorporating causal Probability of Sufficiency and Necessity allows us not only to determine which steps are logically sufficient or necessary to the prediction outcome, but also to quantify their actual influence on the final reasoning outcome under different intervention scenarios, thereby enabling the automated addition of missing steps and the pruning of redundant ones. Extensive experimental results on various mathematical and commonsense reasoning benchmarks confirm substantial improvements in reasoning efficiency and reduced token usage without sacrificing accuracy. Our work provides a promising direction for improving LLM reasoning performance and cost-effectiveness.
        ]]></description>
    </item>
    <item>
        <title>FreeQ-Graph: Free-form Querying with Semantic Consistent Scene Graph for 3D Scene Understanding</title>
        <link>https://arxiv.org/abs/2506.13629</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.13629v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chenlu Zhan, Yufei Zhang, Gaoang Wang, Hongwei Wang</dc:creator>
        <description><![CDATA[
            复杂3D场景中通过自由形式语言进行语义查询是一大挑战，现有方法依赖训练数据的预定义词汇先验，且先进方法缺乏3D场景信息、忽视输出不一致性。本文提出FreeQ - Graph，通过三步实现：在无预定义词汇下从完整准确的3D场景图编码自由查询并与3D一致语义标签对齐；利用合并超点的3D语义对齐特征使图节点与准确语义标签对齐；设计基于LLM的推理算法结合场景和对象级信息推理。在6个数据集实验显示，该模型在复杂自由语义查询和关系推理上表现出色。
            arXiv:2506.13629v2 Announce Type: replace 
Abstract: Semantic querying in complex 3D scenes through free-form language presents a significant challenge. Existing 3D scene understanding methods use large-scale training data and CLIP to align text queries with 3D semantic features. However, their reliance on predefined vocabulary priors from training data hinders free-form semantic querying. Besides, recent advanced methods rely on LLMs for scene understanding but lack comprehensive 3D scene-level information and often overlook the potential inconsistencies in LLM-generated outputs. In our paper, we propose FreeQ-Graph, which enables Free-form Querying with a semantic consistent scene Graph for 3D scene understanding. The core idea is to encode free-form queries from a complete and accurate 3D scene graph without predefined vocabularies, and to align them with 3D consistent semantic labels, which accomplished through three key steps. We initiate by constructing a complete and accurate 3D scene graph that maps free-form objects and their relations through LLM and LVLM guidance, entirely free from training data or predefined priors. Most importantly, we align graph nodes with accurate semantic labels by leveraging 3D semantic aligned features from merged superpoints, enhancing 3D semantic consistency. To enable free-form semantic querying, we then design an LLM-based reasoning algorithm that combines scene-level and object-level information to intricate reasoning. We conducted extensive experiments on 3D semantic grounding, segmentation, and complex querying tasks, while also validating the accuracy of graph generation. Experiments on 6 datasets show that our model excels in both complex free-form semantic queries and intricate relational reasoning.
        ]]></description>
    </item>
    <item>
        <title>Machine Learning Model Integration with Open World Temporal Logic for Process Automation</title>
        <link>https://arxiv.org/abs/2506.17776</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.17776v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Dyuman Aditya, Colton Payne, Mario Leiva, Paulo Shakarian</dc:creator>
        <description><![CDATA[
            背景：当前机器学习虽能从复杂数据源提取结构化信息，但将输出转化为复杂工作流的决策仍面临挑战。方法：提出将多种机器学习模型输出与开放世界时态逻辑编程推理引擎PyReason框架集成的新方法，它能无缝融合模型实值输出，以Python实现持续轮询、转换为逻辑事实并动态重新计算最小模型。效果：可实现实时自适应决策，支持时态推理、知识图谱集成和可解释界面跟踪，能分析时间敏感数据和组织知识，适用于制造、医疗和商业等领域。
            arXiv:2506.17776v2 Announce Type: replace 
Abstract: Recent advancements in Machine Learning (ML) have yielded powerful models capable of extracting structured information from diverse and complex data sources. However, a significant challenge lies in translating these perceptual or extractive outputs into actionable, reasoned decisions within complex operational workflows. To address these challenges, this paper introduces a novel approach that integrates the outputs from various machine learning models directly with the PyReason framework, an open-world temporal logic programming reasoning engine. PyReason's foundation in generalized annotated logic allows for the seamless incorporation of real-valued outputs (e.g., probabilities, confidence scores) from diverse ML models, treating them as truth intervals within its logical framework. Crucially, PyReason provides mechanisms, implemented in Python, to continuously poll ML model outputs, convert them into logical facts, and dynamically recompute the minimal model, ensuring real-tine adaptive decision-making. Furthermore, its native support for temporal reasoning, knowledge graph integration, and fully explainable interface traces enables sophisticated analysis over time-sensitive process data and existing organizational knowledge. By combining the strengths of perception and extraction from ML models with the logical deduction and transparency of PyReason, we aim to create a powerful system for automating complex processes. This integration finds utility across numerous domains, including manufacturing, healthcare, and business operations.
        ]]></description>
    </item>
    <item>
        <title>From Answers to Rationales: Self-Aligning Multimodal Reasoning with Answer-Oriented Chain-of-Thought</title>
        <link>https://arxiv.org/abs/2507.02984</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.02984v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wentao Tan, Qiong Cao, Yibing Zhan, Chao Xue, Changxing Ding</dc:creator>
        <description><![CDATA[
            实现多模态大语言模型（MLLMs）类人推理能力是长期目标。现有方法多关注合成正向推理依据，且忽视负向推理，限制了模型泛化与鲁棒性。为此提出SMART框架，采用面向答案的思维链（AoT）提示自动构建高质量数据，借鉴人类基于证明的策略，利用正误答案提取关键视觉信息。用AoT生成数据训练的模型推理能力优于人工标注数据集训练的模型。实验表明，SMART显著提升各类MLLMs性能。
            arXiv:2507.02984v2 Announce Type: replace 
Abstract: Achieving human-like reasoning capabilities in Multimodal Large Language Models (MLLMs) has long been a goal. Current methods primarily focus on synthesizing positive rationales, typically relying on manual annotations or complex systems. Moreover, they often overlook negative reasoning, which limits the model's generalization ability and robustness in multimodal inference. To address this gap, we propose a novel framework: \textbf{S}elf-Aligning \textbf{M}ultimodal Reasoning with \textbf{A}nswer-O\textbf{r}iented Chain-of-\textbf{T}hought (SMART). SMART employs an answer-oriented chain-of-thought (AoT) prompt to automatically construct high-quality data. Drawing inspiration from human proof-based strategies, AoT leverages both correct and incorrect answers to extract key visual information that links questions and answers. When provided with correct answers, the model produces strong positive rationales. Conversely, when correct answers are replaced with incorrect alternatives, the model generates an erroneous yet compelling reasoning path, serving as a form of discriminative negative rationale. Models trained with AoT-generated data outperform those trained on manually annotated datasets, demonstrating superior reasoning capabilities. Consequently, SMART establishes an iterative generation-optimization method that continually enhances the model's reasoning skills. Experiments indicate that the SMART framework significantly improves various MLLMs, regardless of model architecture, parameter size, or pre-training dataset. The code is available at https://github.com/WentaoTan/SMART.
        ]]></description>
    </item>
    <item>
        <title>PUMA: Layer-Pruned Language Model for Efficient Unified Multimodal Retrieval with Modality-Adaptive Learning</title>
        <link>https://arxiv.org/abs/2507.08064</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.08064v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yibo Lyu, Rui Shao, Gongwei Chen, Yijie Zhu, Weili Guan, Liqiang Nie</dc:creator>
        <description><![CDATA[
            随着多媒体内容增多，实际应用对统一多模态检索（UMR）需求增大，但现有多模态大语言模型（MLLMs）参数多、训练成本高且推理效率低。为此提出PUMA模型，从结构和学习两方面改进UMR。结构上，采用层剪枝自蒸馏，保留浅层并将深层特征作为教师信号，减少参数并保留表征能力；学习上，引入模态自适应对比学习损失，根据目标模态分组负样本并分配不同温度策略提升效率。实验表明该方法显著降低资源消耗且性能良好。
            arXiv:2507.08064v2 Announce Type: replace 
Abstract: As multimedia content expands, the demand for unified multimodal retrieval (UMR) in real-world applications increases. Recent work leverages multimodal large language models (MLLMs) to tackle this task. However, their large parameter size results in high training costs and low inference efficiency. To address this, we propose PUMA: a Layer-Pruned Language Model for Efficient Unified Multimodal Retrieval with Modality-Adaptive Learning. Our approach improves UMR from both structural and learning perspectives. (1) Structurally, we propose Layer-Pruned Self-Distillation, which prunes MLLMs by keeping only shallow layers while distilling features from dropped deep layers as teacher signals. This reduces parameters and preserves representation capability. (2) On the learning side, we introduce Modality-Adaptive Contrastive Learning Loss (MAC-Loss), which separates in-batch negatives into harder intra-modality and easier inter-modality groups based on the target modality, assigning different temperature strategies to enhance learning efficiency. Experiments show our method significantly reduces resource usage while maintaining strong performance.
        ]]></description>
    </item>
    <item>
        <title>A Survey of Deep Learning for Geometry Problem Solving</title>
        <link>https://arxiv.org/abs/2507.11936</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.11936v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jianzhe Ma, Wenxuan Wang, Qin Jin</dc:creator>
        <description><![CDATA[
            几何问题求解是数学推理的关键领域，涉及教育、人工智能数学能力评估等多领域。近年来，深度学习尤其是多模态大模型的发展引发研究热潮。该论文对深度学习在几何问题求解中的应用进行综述，全面总结相关任务、深入回顾深度学习方法、详细分析评估指标和方法，并探讨当前挑战与未来方向，旨在为该领域发展提供全面实用参考，还在GitHub创建论文列表持续更新。
            arXiv:2507.11936v4 Announce Type: replace 
Abstract: Geometry problem solving is a key area of mathematical reasoning, which is widely involved in many important fields such as education, mathematical ability assessment of artificial intelligence, and multimodal ability assessment. In recent years, the rapid development of deep learning technology, especially the rise of multimodal large language models, has triggered a widespread research boom. This paper provides a survey of the applications of deep learning in geometry problem solving, including (i) a comprehensive summary of the relevant tasks in geometry problem solving; (ii) a thorough review of related deep learning methods; (iii) a detailed analysis of evaluation metrics and methods; and (iv) a critical discussion of the current challenges and future directions that can be explored. Our goal is to provide a comprehensive and practical reference of deep learning for geometry problem solving to promote further developments in this field. We create a continuously updated list of papers on GitHub: https://github.com/majianz/dl4gps.
        ]]></description>
    </item>
    <item>
        <title>Learning to Extract Rational Evidence via Reinforcement Learning for Retrieval-Augmented Generation</title>
        <link>https://arxiv.org/abs/2507.15586</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.15586v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xinping Zhao, Shouzheng Huang, Yan Zhong, Xinshuo Hu, Meishan Zhang, Baotian Hu, Min Zhang</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）能提升大语言模型准确性，但检索噪声影响生成质量，且以往方法提取证据无显式思考，有过滤关键线索和泛化难问题。方法：提出LEAR，先显式推理识别检索内容中潜在线索，再有意识提取以避免遗漏关键线索；将证据推理和提取统一训练，用知识令牌掩码解纠缠，设计三种可验证奖励函数更新模型。效果：在三个基准数据集实验表明，能提供紧凑高质量证据，提升下游任务准确性，促进在线RAG系统有效应用。
            arXiv:2507.15586v3 Announce Type: replace 
Abstract: Retrieval-Augmented Generation (RAG) effectively improves the accuracy of Large Language Models (LLMs). However, retrieval noises significantly impact the quality of LLMs' generation, necessitating the development of denoising mechanisms. Previous methods extract evidence straightforwardly without explicit thinking, which risks filtering out key clues and struggles with generalization. To this end, we propose LEAR, which learns to extract rational evidence by (1) explicitly reasoning to identify potential cues within retrieval contents first, and then (2) consciously extracting to avoid omitting any key cues helpful for answering questions. Specifically, we frame evidence reasoning and evidence extraction into one unified response for end-to-end training; apply knowledge token masks for disentanglement to derive reasoning-based and extraction-based answers; and devise three types of verifiable reward functions, including answer, length, and format, to update the model via the policy optimization algorithm. Extensive experiments on three benchmark datasets show the effectiveness of LEAR, providing compact and high-quality evidence, improving the accuracy of downstream tasks, and promoting effective application in online RAG systems.
        ]]></description>
    </item>
    <item>
        <title>GUI-G$^2$: Gaussian Reward Modeling for GUI Grounding</title>
        <link>https://arxiv.org/abs/2507.15846</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.15846v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Fei Tang, Zhangxuan Gu, Zhengxi Lu, Xuyang Liu, Shuheng Shen, Changhua Meng, Wen Wang, Wenqi Zhang, Yongliang Shen, Weiming Lu, Jun Xiao, Yueting Zhuang</dc:creator>
        <description><![CDATA[
            背景：当前图形用户界面（GUI）接地的强化学习方法采用二元奖励，忽略了空间交互的连续性。方法：引入GUI高斯接地奖励（GUI - G²）框架，将GUI元素建模为连续高斯分布，包含高斯点奖励和覆盖奖励两种协同机制，还开发了自适应方差机制。该框架将GUI接地从稀疏二元分类转变为密集连续优化。效果：在多个基准测试中，GUI - G²显著优于最先进方法UI - TARS - 72B，在ScreenSpot - Pro上提升达24.7%，对界面变化更具鲁棒性，泛化能力更强。
            arXiv:2507.15846v3 Announce Type: replace 
Abstract: Graphical User Interface (GUI) grounding maps natural language instructions to precise interface locations for autonomous interaction. Current reinforcement learning approaches use binary rewards that treat elements as hit-or-miss targets, creating sparse signals that ignore the continuous nature of spatial interactions. Motivated by human clicking behavior that naturally forms Gaussian distributions centered on target elements, we introduce GUI Gaussian Grounding Rewards (GUI-G$^2$), a principled reward framework that models GUI elements as continuous Gaussian distributions across the interface plane. GUI-G$^2$ incorporates two synergistic mechanisms: Gaussian point rewards model precise localization through exponentially decaying distributions centered on element centroids, while coverage rewards assess spatial alignment by measuring the overlap between predicted Gaussian distributions and target regions. To handle diverse element scales, we develop an adaptive variance mechanism that calibrates reward distributions based on element dimensions. This framework transforms GUI grounding from sparse binary classification to dense continuous optimization, where Gaussian distributions generate rich gradient signals that guide models toward optimal interaction positions. Extensive experiments across ScreenSpot, ScreenSpot-v2, and ScreenSpot-Pro benchmarks demonstrate that GUI-G$^2$, substantially outperforms state-of-the-art method UI-TARS-72B, with the most significant improvement of 24.7% on ScreenSpot-Pro. Our analysis reveals that continuous modeling provides superior robustness to interface variations and enhanced generalization to unseen layouts, establishing a new paradigm for spatial reasoning in GUI interaction tasks.
        ]]></description>
    </item>
    <item>
        <title>ReasonVQA: A Multi-hop Reasoning Benchmark with Structural Knowledge for Visual Question Answering</title>
        <link>https://arxiv.org/abs/2507.16403</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.16403v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Duong T. Tran, Trung-Kien Tran, Manfred Hauswirth, Danh Le Phuoc</dc:creator>
        <description><![CDATA[
            该论文聚焦视觉问答（VQA）任务，背景是缺乏能结合结构化知识进行复杂推理的数据集。为此，提出新数据集ReasonVQA，它自动集成结构化百科知识，用低成本框架构建，可生成复杂多跳问题。在该数据集上评估了先进VQA模型，结果显示其对这些模型构成挑战，有用于基准测试和推动VQA领域发展的潜力，且当前版本规模比现有需外部知识的最大数据集大一个数量级。
            arXiv:2507.16403v2 Announce Type: replace 
Abstract: In this paper, we propose a new dataset, ReasonVQA, for the Visual Question Answering (VQA) task. Our dataset is automatically integrated with structured encyclopedic knowledge and constructed using a low-cost framework, which is capable of generating complex, multi-hop questions. We evaluated state-of-the-art VQA models on ReasonVQA, and the empirical results demonstrate that ReasonVQA poses significant challenges to these models, highlighting its potential for benchmarking and advancing the field of VQA. Additionally, our dataset can be easily scaled with respect to input images; the current version surpasses the largest existing datasets requiring external knowledge by more than an order of magnitude.
        ]]></description>
    </item>
    <item>
        <title>PyG 2.0: Scalable Learning on Real World Graphs</title>
        <link>https://arxiv.org/abs/2507.16991</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.16991v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Matthias Fey, Jinu Sunil, Akihiro Nitta, Rishi Puri, Manan Shah, Bla\v{z} Stojanovi\v{c}, Ramona Bendias, Alexandria Barghi, Vid Kocijan, Zecheng Zhang, Xinwei He, Jan Eric Lenssen, Jure Leskovec</dc:creator>
        <description><![CDATA[
            背景：PyG自发布后发展显著，是图神经网络领先框架。方法：本文推出PyG 2.0及其后续小版本，对框架架构进行全面更新，支持异质和时态图，有可扩展特征/图存储及多种优化。效果：能有效解决大规模图学习问题，支持多领域图学习，还深入探讨了关系深度学习和大语言模型等重要领域。
            arXiv:2507.16991v2 Announce Type: replace 
Abstract: PyG (PyTorch Geometric) has evolved significantly since its initial release, establishing itself as a leading framework for Graph Neural Networks. In this paper, we present Pyg 2.0 (and its subsequent minor versions), a comprehensive update that introduces substantial improvements in scalability and real-world application capabilities. We detail the framework's enhanced architecture, including support for heterogeneous and temporal graphs, scalable feature/graph stores, and various optimizations, enabling researchers and practitioners to tackle large-scale graph learning problems efficiently. Over the recent years, PyG has been supporting graph learning in a large variety of application areas, which we will summarize, while providing a deep dive into the important areas of relational deep learning and large language modeling.
        ]]></description>
    </item>
    <item>
        <title>Eyes Will Shut: A Vision-Based Next GPS Location Prediction Model by Reinforcement Learning from Visual Map Feed Back</title>
        <link>https://arxiv.org/abs/2507.18661</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.18661v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ruixing Zhang, Yang Zhang, Tongyu Zhu, Leilei Sun, Weifeng Lv</dc:creator>
        <description><![CDATA[
            在人类移动性研究中，下一位置预测是基础任务，但现有多数模型无法像人类一样基于地图推理。鉴于视觉语言模型（VLMs）在视觉感知和推理方面的能力，研究先提出Vision - Guided Location Search（VGLS）评估通用VLM的轨迹推理能力，后提出VLMLocPredictor。它分两阶段，先设计监督微调任务让VLM理解道路和轨迹结构，再引入强化学习使其与环境交互提升预测能力。在四个城市数据集实验显示，该方法达最优且跨城市泛化能力强。
            arXiv:2507.18661v2 Announce Type: replace 
Abstract: Next Location Prediction is a fundamental task in the study of human mobility, with wide-ranging applications in transportation planning, urban governance, and epidemic forecasting. In practice, when humans attempt to predict the next location in a trajectory, they often visualize the trajectory on a map and reason based on road connectivity and movement trends. However, the vast majority of existing next-location prediction models do not reason over maps \textbf{in the way that humans do}. Fortunately, the recent development of Vision-Language Models (VLMs) has demonstrated strong capabilities in visual perception and even visual reasoning. This opens up a new possibility: by rendering both the road network and trajectory onto an image and leveraging the reasoning abilities of VLMs, we can enable models to perform trajectory inference in a human-like manner. To explore this idea, we first propose a method called Vision-Guided Location Search (VGLS), which evaluates whether a general-purpose VLM is capable of trajectory-based reasoning without modifying any of its internal parameters. Based on insights from the VGLS results, we further propose our main approach: VLMLocPredictor, which is composed of two stages: In the first stage, we design two Supervised Fine-Tuning (SFT) tasks that help the VLM understand road network and trajectory structures and acquire basic reasoning ability on such visual inputs. In the second stage, we introduce Reinforcement Learning from Visual Map Feedback, enabling the model to self-improve its next-location prediction ability through interaction with the environment. Experiments conducted on datasets from four different cities show that our method achieves state-of-the-art (SOTA) performance and exhibits superior cross-city generalization compared to other LLM-based approaches.
        ]]></description>
    </item>
    <item>
        <title>Faithful Differentiable Reasoning with Reshuffled Region-based Embeddings</title>
        <link>https://arxiv.org/abs/2406.09529</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2406.09529v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Aleksandar Pavlovic, Emanuel Sallinger, Steven Schockaert</dc:creator>
        <description><![CDATA[
            背景：知识图谱（KG）嵌入方法学习实体和关系的几何表示来预测缺失知识，但对其能捕获的推理模式的理论理解有限，现有模型可捕获的规则库类型受限。方法：提出基于排序约束的RESHUFFLE模型，其实体嵌入可由图神经网络（GNN）学习。效果：相比现有方法，能更忠实地捕获更大类别的规则库，尤其能捕获关于任意闭路径规则集的有界推理。
            arXiv:2406.09529v2 Announce Type: replace-cross 
Abstract: Knowledge graph (KG) embedding methods learn geometric representations of entities and relations to predict plausible missing knowledge. These representations are typically assumed to capture rule-like inference patterns. However, our theoretical understanding of which inference patterns can be captured remains limited. Ideally, KG embedding methods should be expressive enough such that for any set of rules, there exist relation embeddings that exactly capture these rules. This principle has been studied within the framework of region-based embeddings, but existing models are severely limited in the kinds of rule bases that can be captured. We argue that this stems from the fact that entity embeddings are only compared in a coordinate-wise fashion. As an alternative, we propose RESHUFFLE, a simple model based on ordering constraints that can faithfully capture a much larger class of rule bases than existing approaches. Most notably, RESHUFFLE can capture bounded inference w.r.t. arbitrary sets of closed path rules. The entity embeddings in our framework can be learned by a Graph Neural Network (GNN), which effectively acts as a differentiable rule base.
        ]]></description>
    </item>
    <item>
        <title>OrthoInsight: Rib Fracture Diagnosis and Report Generation Based on Multi-Modal Large Models</title>
        <link>https://arxiv.org/abs/2507.13993</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.13993v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ningyong Wu, Jinzhi Wang, Wenhong Zhao, Chenzhan Yu, Zhigang Xiu, Duwei Dai</dc:creator>
        <description><![CDATA[
            背景：医疗影像数据增多，对自动化诊断工具需求增长，手动解读肋骨骨折 CT 扫描耗时且易出错。方法：提出多模态深度学习框架 OrthoInsight，集成 YOLOv9 模型检测骨折、医学知识图谱获取临床背景、微调 LLaVA 语言模型生成诊断报告，结合 CT 图像视觉特征与专家文本数据。效果：在 28675 个标注 CT 图像和专家报告上评估，在多项指标上表现出色，平均得分 4.28，优于 GPT - 4 等模型。
            arXiv:2507.13993v2 Announce Type: replace-cross 
Abstract: The growing volume of medical imaging data has increased the need for automated diagnostic tools, especially for musculoskeletal injuries like rib fractures, commonly detected via CT scans. Manual interpretation is time-consuming and error-prone. We propose OrthoInsight, a multi-modal deep learning framework for rib fracture diagnosis and report generation. It integrates a YOLOv9 model for fracture detection, a medical knowledge graph for retrieving clinical context, and a fine-tuned LLaVA language model for generating diagnostic reports. OrthoInsight combines visual features from CT images with expert textual data to deliver clinically useful outputs. Evaluated on 28,675 annotated CT images and expert reports, it achieves high performance across Diagnostic Accuracy, Content Completeness, Logical Coherence, and Clinical Guidance Value, with an average score of 4.28, outperforming models like GPT-4 and Claude-3. This study demonstrates the potential of multi-modal learning in transforming medical image analysis and providing effective support for radiologists.
        ]]></description>
    </item>
    <item>
        <title>Assemble Your Crew: Automatic Multi-agent Communication Topology Design via Autoregressive Graph Generation</title>
        <link>https://arxiv.org/abs/2507.18224</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.18224v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Shiyuan Li, Yixin Liu, Qingsong Wen, Chengqi Zhang, Shirui Pan</dc:creator>
        <description><![CDATA[
            这是一篇关于多智能体系统（MAS）设计的研究。基于大语言模型的MAS是处理复杂问题的有力方案，其协作拓扑设计是研究重点，但现有方法依赖模板图修改范式，适应性受限。为此，研究将MAS设计重构为条件自回归图生成任务，提出ARG - Designer模型，根据自然语言任务查询，从零构建协作图，动态确定智能体数量、选择角色并建立通信链接。实验表明，该模型性能达最优，具更高的token效率和扩展性。
            arXiv:2507.18224v2 Announce Type: replace-cross 
Abstract: Multi-agent systems (MAS) based on large language models (LLMs) have emerged as a powerful solution for dealing with complex problems across diverse domains. The effectiveness of MAS is critically dependent on its collaboration topology, which has become a focal point for automated design research. However, existing approaches are fundamentally constrained by their reliance on a template graph modification paradigm with a predefined set of agents and hard-coded interaction structures, significantly limiting their adaptability to task-specific requirements. To address these limitations, we reframe MAS design as a conditional autoregressive graph generation task, where both the system composition and structure are designed jointly. We propose ARG-Designer, a novel autoregressive model that operationalizes this paradigm by constructing the collaboration graph from scratch. Conditioned on a natural language task query, ARG-Designer sequentially and dynamically determines the required number of agents, selects their appropriate roles from an extensible pool, and establishes the optimal communication links between them. This generative approach creates a customized topology in a flexible and extensible manner, precisely tailored to the unique demands of different tasks. Extensive experiments across six diverse benchmarks demonstrate that ARG-Designer not only achieves state-of-the-art performance but also enjoys significantly greater token efficiency and enhanced extensibility. The source code of ARG-Designer is available at https://github.com/Shiy-Li/ARG-Designer.
        ]]></description>
    </item>
    <item>
        <title>Joint Feature and Output Distillation for Low-complexity Acoustic Scene Classification</title>
        <link>https://arxiv.org/abs/2507.19557</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.19557v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Haowen Li, Ziyi Yang, Mou Wang, Ee-Leng Tan, Junwei Yeow, Santi Peksi, Woon-Seng Gan</dc:creator>
        <description><![CDATA[
            该论文针对DCASE2025任务1中的低复杂度声学场景分类问题，提出一种多教师指导的双级知识蒸馏框架。背景是解决低复杂度声学场景分类难题。方法上，提出联合转移软对数和中间特征表示的蒸馏策略，预训练PaSST和CP - ResNet为教师模型，平均教师的对数生成软目标，选一个CP - ResNet进行特征级蒸馏，让紧凑的学生模型（CP - Mobile）学习教师的语义分布和结构信息。实验表明，在TAU Urban Acoustic Scenes 2022移动数据集开发集上，提交系统的准确率达59.30%。
            arXiv:2507.19557v1 Announce Type: new 
Abstract: This report presents a dual-level knowledge distillation framework with multi-teacher guidance for low-complexity acoustic scene classification (ASC) in DCASE2025 Task 1. We propose a distillation strategy that jointly transfers both soft logits and intermediate feature representations. Specifically, we pre-trained PaSST and CP-ResNet models as teacher models. Logits from teachers are averaged to generate soft targets, while one CP-ResNet is selected for feature-level distillation. This enables the compact student model (CP-Mobile) to capture both semantic distribution and structural information from teacher guidance. Experiments on the TAU Urban Acoustic Scenes 2022 Mobile dataset (development set) demonstrate that our submitted systems achieve up to 59.30\% accuracy.
        ]]></description>
    </item>
    <item>
        <title>SonicGauss: Position-Aware Physical Sound Synthesis for 3D Gaussian Representations</title>
        <link>https://arxiv.org/abs/2507.19835</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.19835v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chunshi Wang, Hongxing Li, Yawei Luo</dc:creator>
        <description><![CDATA[
            背景：3D高斯表示（3DGS）在物体几何和外观建模有效，但在捕捉声音等物理属性方面待探索。方法：提出SonicGauss框架，将基于扩散的声音合成模型与基于PointTransformer的特征提取器结合，从高斯椭球直接推断材料特性和空间声学相关性。效果：该方法支持基于撞击位置的空间变化声音响应，能跨多种物体类别泛化。在ObjectFolder数据集和真实录音实验中，能产生逼真、位置感知的听觉反馈，展示了框架的鲁棒性和泛化能力。
            arXiv:2507.19835v1 Announce Type: new 
Abstract: While 3D Gaussian representations (3DGS) have proven effective for modeling the geometry and appearance of objects, their potential for capturing other physical attributes-such as sound-remains largely unexplored. In this paper, we present a novel framework dubbed SonicGauss for synthesizing impact sounds from 3DGS representations by leveraging their inherent geometric and material properties. Specifically, we integrate a diffusion-based sound synthesis model with a PointTransformer-based feature extractor to infer material characteristics and spatial-acoustic correlations directly from Gaussian ellipsoids. Our approach supports spatially varying sound responses conditioned on impact locations and generalizes across a wide range of object categories. Experiments on the ObjectFolder dataset and real-world recordings demonstrate that our method produces realistic, position-aware auditory feedback. The results highlight the framework's robustness and generalization ability, offering a promising step toward bridging 3D visual representations and interactive sound synthesis. Project page: https://chunshi.wang/SonicGauss
        ]]></description>
    </item>
    <item>
        <title>Efficient Vocal-Conditioned Music Generation via Soft Alignment Attention and Latent Diffusion</title>
        <link>https://arxiv.org/abs/2507.19991</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.19991v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hei Shing Cheung, Boya Zhang</dc:creator>
        <description><![CDATA[
            本文背景是现有音乐AI系统存在局限，为此提出用于人声条件下音乐伴奏生成的轻量级潜在扩散模型。方法上引入了新颖的软对齐注意力机制，基于扩散时间步自适应结合局部和全局时间依赖，在预训练变分自编码器的压缩潜在空间中运行。效果显著，与现有技术相比参数减少220倍，推理速度快52倍，仅1500万参数就有出色表现，在制作质量和内容统一性上超越OpenAI Jukebox，且架构轻量可在消费级硬件上实时部署。
            arXiv:2507.19991v1 Announce Type: new 
Abstract: We present a lightweight latent diffusion model for vocal-conditioned musical accompaniment generation that addresses critical limitations in existing music AI systems. Our approach introduces a novel soft alignment attention mechanism that adaptively combines local and global temporal dependencies based on diffusion timesteps, enabling efficient capture of multi-scale musical structure. Operating in the compressed latent space of a pre-trained variational autoencoder, the model achieves a 220 times parameter reduction compared to state-of-the-art systems while delivering 52 times faster inference. Experimental evaluation demonstrates competitive performance with only 15M parameters, outperforming OpenAI Jukebox in production quality and content unity while maintaining reasonable musical coherence. The ultra-lightweight architecture enables real-time deployment on consumer hardware, making AI-assisted music creation accessible for interactive applications and resource-constrained environments.
        ]]></description>
    </item>
    <item>
        <title>Improving Audio Classification by Transitioning from Zero- to Few-Shot</title>
        <link>https://arxiv.org/abs/2507.20036</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.20036v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>James Taylor, Wolfgang Mack</dc:creator>
        <description><![CDATA[
            当前音频分类常采用零样本方法，即对比音频嵌入和描述音频类别的文本嵌入，但确定音频类别的最佳文本描述较难，尤其是类别包含多种声音时。本文研究了能提升分类准确率的少样本方法，具体是按类别对音频嵌入分组并处理，以取代有噪声的文本嵌入。结果表明，少样本分类通常优于零样本基线。
            arXiv:2507.20036v1 Announce Type: new 
Abstract: State-of-the-art audio classification often employs a zero-shot approach, which involves comparing audio embeddings with embeddings from text describing the respective audio class. These embeddings are usually generated by neural networks trained through contrastive learning to align audio and text representations. Identifying the optimal text description for an audio class is challenging, particularly when the class comprises a wide variety of sounds. This paper examines few-shot methods designed to improve classification accuracy beyond the zero-shot approach. Specifically, audio embeddings are grouped by class and processed to replace the inherently noisy text embeddings. Our results demonstrate that few-shot classification typically outperforms the zero-shot baseline.
        ]]></description>
    </item>
    <item>
        <title>Diffusion-based Symbolic Music Generation with Structured State Space Models</title>
        <link>https://arxiv.org/abs/2507.20128</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.20128v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Shenghua Yuan, Xing Tang, Jiatao Chen, Tianming Xie, Jing Wang, Bing Shi</dc:creator>
        <description><![CDATA[
            背景：现有扩散模型虽提升了符号音乐生成效果，但基于自注意力机制的Transformer架构计算复杂度高，限制长序列处理能力。方法：提出SMDIM，结合结构化状态空间模型进行高效全局上下文建模，采用MFA块保留局部细节，平衡可扩展性与音乐表现力。效果：实现近线性复杂度，在FolkDB等数据集上，生成质量和计算效率超现有模型，且架构适用于多种长序列生成任务。 
            arXiv:2507.20128v1 Announce Type: new 
Abstract: Recent advancements in diffusion models have significantly improved symbolic music generation. However, most approaches rely on transformer-based architectures with self-attention mechanisms, which are constrained by quadratic computational complexity, limiting scalability for long sequences. To address this, we propose Symbolic Music Diffusion with Mamba (SMDIM), a novel diffusion-based architecture integrating Structured State Space Models (SSMs) for efficient global context modeling and the Mamba-FeedForward-Attention Block (MFA) for precise local detail preservation. The MFA Block combines the linear complexity of Mamba layers, the non-linear refinement of FeedForward layers, and the fine-grained precision of self-attention mechanisms, achieving a balance between scalability and musical expressiveness. SMDIM achieves near-linear complexity, making it highly efficient for long-sequence tasks. Evaluated on diverse datasets, including FolkDB, a collection of traditional Chinese folk music that represents an underexplored domain in symbolic music generation, SMDIM outperforms state-of-the-art models in both generation quality and computational efficiency. Beyond symbolic music, SMDIM's architectural design demonstrates adaptability to a broad range of long-sequence generation tasks, offering a scalable and efficient solution for coherent sequence modeling.
        ]]></description>
    </item>
    <item>
        <title>Do Not Mimic My Voice: Speaker Identity Unlearning for Zero-Shot Text-to-Speech</title>
        <link>https://arxiv.org/abs/2507.20140</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.20140v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Taesoo Kim, Jinju Kim, Dongchan Kim, Jong Hwan Ko, Gyeong-Moon Park</dc:creator>
        <description><![CDATA[
            零样本文本转语音（ZS - TTS）技术发展迅速，但引发了隐私和伦理问题，目前尚未有从预训练模型参数中选择性移除特定说话人身份知识的研究。本文提出ZS - TTS系统的说话人身份遗忘新挑战，并设计了首个ZS - TTS机器遗忘框架，尤其是教师引导遗忘（TGU），还提出新评估指标spk - ZRF。实验表明，TGU能让模型遗忘指定说话人身份，同时保持对其他说话人的高质量语音生成。
            arXiv:2507.20140v1 Announce Type: new 
Abstract: The rapid advancement of Zero-Shot Text-to-Speech (ZS-TTS) technology has enabled high-fidelity voice synthesis from minimal audio cues, raising significant privacy and ethical concerns. Despite the threats to voice privacy, research to selectively remove the knowledge to replicate unwanted individual voices from pre-trained model parameters has not been explored. In this paper, we address the new challenge of speaker identity unlearning for ZS-TTS systems. To meet this goal, we propose the first machine unlearning frameworks for ZS-TTS, especially Teacher-Guided Unlearning (TGU), designed to ensure the model forgets designated speaker identities while retaining its ability to generate accurate speech for other speakers. Our proposed methods incorporate randomness to prevent consistent replication of forget speakers' voices, assuring unlearned identities remain untraceable. Additionally, we propose a new evaluation metric, speaker-Zero Retrain Forgetting (spk-ZRF). This assesses the model's ability to disregard prompts associated with forgotten speakers, effectively neutralizing its knowledge of these voices. The experiments conducted on the state-of-the-art model demonstrate that TGU prevents the model from replicating forget speakers' voices while maintaining high quality for other speakers. The demo is available at https://speechunlearn.github.io/
        ]]></description>
    </item>
    <item>
        <title>Self-Improvement for Audio Large Language Model using Unlabeled Speech</title>
        <link>https://arxiv.org/abs/2507.20169</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.20169v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Shaowen Wang, Xinyuan Chen, Yao Xu</dc:creator>
        <description><![CDATA[
            背景：近期音频大语言模型发展迅速，但因语音信号复杂，在特定目标领域性能会下降。方法：提出无标注数据下增强目标领域音频大语言模型的自提升方法SI - SDA，利用大模型解码信息评估伪标签质量，基于强化学习优化进行领域自适应。效果：实验表明该方法持续显著提升音频大语言模型性能，在自动语音识别、口语问答和语音到文本翻译等多个公开数据集上，WER和BLEU指标优于现有基线，且数据效率高，有实际应用潜力。
            arXiv:2507.20169v1 Announce Type: new 
Abstract: Recent audio LLMs have emerged rapidly, demonstrating strong generalization across various speech tasks. However, given the inherent complexity of speech signals, these models inevitably suffer from performance degradation in specific target domains. To address this, we focus on enhancing audio LLMs in target domains without any labeled data. We propose a self-improvement method called SI-SDA, leveraging the information embedded in large-model decoding to evaluate the quality of generated pseudo labels and then perform domain adaptation based on reinforcement learning optimization. Experimental results show that our method consistently and significantly improves audio LLM performance, outperforming existing baselines in WER and BLEU across multiple public datasets of automatic speech recognition (ASR), spoken question-answering (SQA), and speech-to-text translation (S2TT). Furthermore, our approach exhibits high data efficiency, underscoring its potential for real-world deployment.
        ]]></description>
    </item>
    <item>
        <title>Binaural Sound Event Localization and Detection based on HRTF Cues for Humanoid Robots</title>
        <link>https://arxiv.org/abs/2507.20530</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.20530v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Gyeong-Tae Lee, Hyeonuk Nam, Yong-Hwa Park</dc:creator>
        <description><![CDATA[
            该论文聚焦于人形机器人的双耳声音事件定位与检测（BiSELD）任务。背景是受人类空间听觉机制启发。方法上，提出合成基准数据集Binaural Set，设计新输入特征表示BTFF，编码双耳信号多种线索；开发基于CRNN的BiSELDnet模型学习相关模式和线索。实验表明，BTFF各子特征提升性能，最终系统SELD误差0.110，F分数87.1%，定位误差4.4°，证明框架在模拟类人听觉感知上有效。
            arXiv:2507.20530v1 Announce Type: new 
Abstract: This paper introduces Binaural Sound Event Localization and Detection (BiSELD), a task that aims to jointly detect and localize multiple sound events using binaural audio, inspired by the spatial hearing mechanism of humans. To support this task, we present a synthetic benchmark dataset, called the Binaural Set, which simulates realistic auditory scenes using measured head-related transfer functions (HRTFs) and diverse sound events. To effectively address the BiSELD task, we propose a new input feature representation called the Binaural Time-Frequency Feature (BTFF), which encodes interaural time difference (ITD), interaural level difference (ILD), and high-frequency spectral cues (SC) from binaural signals. BTFF is composed of eight channels, including left and right mel-spectrograms, velocity-maps, SC-maps, and ITD-/ILD-maps, designed to cover different spatial cues across frequency bands and spatial axes. A CRNN-based model, BiSELDnet, is then developed to learn both spectro-temporal patterns and HRTF-based localization cues from BTFF. Experiments on the Binaural Set show that each BTFF sub-feature enhances task performance: V-map improves detection, ITD-/ILD-maps enable accurate horizontal localization, and SC-map captures vertical spatial cues. The final system achieves a SELD error of 0.110 with 87.1% F-score and 4.4{\deg} localization error, demonstrating the effectiveness of the proposed framework in mimicking human-like auditory perception.
        ]]></description>
    </item>
    <item>
        <title>Hyperbolic Embeddings for Order-Aware Classification of Audio Effect Chains</title>
        <link>https://arxiv.org/abs/2507.20624</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.20624v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Aogu Wada, Tomohiko Nakamura, Hiroshi Saruwatari</dc:creator>
        <description><![CDATA[
            音频效果（AFXs）常用于音乐制作中塑造音色和动态，AFX链中效果器顺序对最终声音影响大，但多数相关研究只关注从湿信号估计效果类型和参数。本文将AFX链识别定义为从湿信号联合估计AFX类型和顺序的任务，提出基于神经网络的方法，将湿信号嵌入双曲空间对AFX链分类。双曲空间适合建模AFX组合特性。实验表明，合适曲率下该方法优于欧氏空间方法，分析也凸显其捕捉AFX顺序的有效性。
            arXiv:2507.20624v1 Announce Type: new 
Abstract: Audio effects (AFXs) are essential tools in music production, frequently applied in chains to shape timbre and dynamics. The order of AFXs in a chain plays a crucial role in determining the final sound, particularly when non-linear (e.g., distortion) or time-variant (e.g., chorus) processors are involved. Despite its importance, most AFX-related studies have primarily focused on estimating effect types and their parameters from a wet signal. To address this gap, we formulate AFX chain recognition as the task of jointly estimating AFX types and their order from a wet signal. We propose a neural-network-based method that embeds wet signals into a hyperbolic space and classifies their AFX chains. Hyperbolic space can represent tree-structured data more efficiently than Euclidean space due to its exponential expansion property. Since AFX chains can be represented as trees, with AFXs as nodes and edges encoding effect order, hyperbolic space is well-suited for modeling the exponentially growing and non-commutative nature of ordered AFX combinations, where changes in effect order can result in different final sounds. Experiments using guitar sounds demonstrate that, with an appropriate curvature, the proposed method outperforms its Euclidean counterpart. Further analysis based on AFX type and chain length highlights the effectiveness of the proposed method in capturing AFX order.
        ]]></description>
    </item>
    <item>
        <title>MIMII-Agent: Leveraging LLMs with Function Calling for Relative Evaluation of Anomalous Sound Detection</title>
        <link>https://arxiv.org/abs/2507.20666</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.20666v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Harsh Purohit, Tomoya Nishida, Kota Dohi, Takashi Endo, Yohei Kawaguchi</dc:creator>
        <description><![CDATA[
            背景：传统基于关键词的数据增强方法生成的异常声音不真实，可扩展性受限，高级音频生成模型依赖异常训练数据。方法：提出一种利用大语言模型（LLMs）的合成方法，让LLMs解读故障文本描述并自动选择音频转换函数，将正常机器声音转换为多样且合理的异常声音。效果：通过评估仅用五种机器正常声音训练的无监督异常声音检测（UASD）系统，发现合成和真实异常的相对检测难度趋势一致，证明该方法有效。
            arXiv:2507.20666v1 Announce Type: new 
Abstract: This paper proposes a method for generating machine-type-specific anomalies to evaluate the relative performance of unsupervised anomalous sound detection (UASD) systems across different machine types, even in the absence of real anomaly sound data. Conventional keyword-based data augmentation methods often produce unrealistic sounds due to their reliance on manually defined labels, limiting scalability as machine types and anomaly patterns diversify. Advanced audio generative models, such as MIMII-Gen, show promise but typically depend on anomalous training data, making them less effective when diverse anomalous examples are unavailable. To address these limitations, we propose a novel synthesis approach leveraging large language models (LLMs) to interpret textual descriptions of faults and automatically select audio transformation functions, converting normal machine sounds into diverse and plausible anomalous sounds. We validate this approach by evaluating a UASD system trained only on normal sounds from five machine types, using both real and synthetic anomaly data. Experimental results reveal consistent trends in relative detection difficulty across machine types between synthetic and real anomalies. This finding supports our hypothesis and highlights the effectiveness of the proposed LLM-based synthesis approach for relative evaluation of UASD systems.
        ]]></description>
    </item>
    <item>
        <title>Learning Neural Vocoder from Range-Null Space Decomposition</title>
        <link>https://arxiv.org/abs/2507.20731</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.20731v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Andong Li, Tong Lei, Zhihang Sun, Rilin Chen, Erwei Yin, Xiaodong Li, Chengshi Zheng</dc:creator>
        <description><![CDATA[
            近年来神经声码器发展迅速，但存在建模不透明、参数与性能难以平衡等问题。本文提出一种基于时频域的创新神经声码器。将经典信号的范围-零空间分解（RND）理论与声码器任务相结合，把目标频谱图重建分解为范围空间和零空间叠加。提出双路径框架，对频谱进行分层编解码，设计了跨带和窄带模块。在LJSpeech和LibriTTS基准上实验，结果表明该方法参数轻量，性能达现有先进水平。
            arXiv:2507.20731v1 Announce Type: new 
Abstract: Despite the rapid development of neural vocoders in recent years, they usually suffer from some intrinsic challenges like opaque modeling, and parameter-performance trade-off. In this study, we propose an innovative time-frequency (T-F) domain-based neural vocoder to resolve the above-mentioned challenges. To be specific, we bridge the connection between the classical signal range-null decomposition (RND) theory and vocoder task, and the reconstruction of target spectrogram can be decomposed into the superimposition between the range-space and null-space, where the former is enabled by a linear domain shift from the original mel-scale domain to the target linear-scale domain, and the latter is instantiated via a learnable network for further spectral detail generation. Accordingly, we propose a novel dual-path framework, where the spectrum is hierarchically encoded/decoded, and the cross- and narrow-band modules are elaborately devised for efficient sub-band and sequential modeling. Comprehensive experiments are conducted on the LJSpeech and LibriTTS benchmarks. Quantitative and qualitative results show that while enjoying lightweight network parameters, the proposed approach yields state-of-the-art performance among existing advanced methods. Our code and the pretrained model weights are available at https://github.com/Andong-Li-speech/RNDVoC.
        ]]></description>
    </item>
    <item>
        <title>JAM: A Tiny Flow-based Song Generator with Fine-grained Controllability and Aesthetic Alignment</title>
        <link>https://arxiv.org/abs/2507.20880</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.20880v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Renhang Liu, Chia-Yu Hung, Navonil Majumder, Taylor Gautreaux, Amir Ali Bagherzadeh, Chuan Li, Dorien Herremans, Soujanya Poria</dc:creator>
        <description><![CDATA[
            背景：扩散和流匹配模型推动了文本到音频自动生成发展，但音乐创作音频生成仍有提升空间，现有歌词到歌曲模型缺乏细粒度控制。方法：提出基于流匹配的JAM，实现歌词生成歌曲时的词级时间和时长控制；通过直接偏好优化实现审美对齐，利用合成数据集迭代优化模型；发布公开评估数据集JAME。效果：JAM在音乐特定属性上优于现有模型。
            arXiv:2507.20880v1 Announce Type: new 
Abstract: Diffusion and flow-matching models have revolutionized automatic text-to-audio generation in recent times. These models are increasingly capable of generating high quality and faithful audio outputs capturing to speech and acoustic events. However, there is still much room for improvement in creative audio generation that primarily involves music and songs. Recent open lyrics-to-song models, such as, DiffRhythm, ACE-Step, and LeVo, have set an acceptable standard in automatic song generation for recreational use. However, these models lack fine-grained word-level controllability often desired by musicians in their workflows. To the best of our knowledge, our flow-matching-based JAM is the first effort toward endowing word-level timing and duration control in song generation, allowing fine-grained vocal control. To enhance the quality of generated songs to better align with human preferences, we implement aesthetic alignment through Direct Preference Optimization, which iteratively refines the model using a synthetic dataset, eliminating the need or manual data annotations. Furthermore, we aim to standardize the evaluation of such lyrics-to-song models through our public evaluation dataset JAME. We show that JAM outperforms the existing models in terms of the music-specific attributes.
        ]]></description>
    </item>
    <item>
        <title>Music Arena: Live Evaluation for Text-to-Music</title>
        <link>https://arxiv.org/abs/2507.20900</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.20900v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yonghyun Kim, Wayne Chi, Anastasios N. Angelopoulos, Wei-Lin Chiang, Koichi Saito, Shinji Watanabe, Yuki Mitsufuji, Chris Donahue</dc:creator>
        <description><![CDATA[
            本文背景是当前文本到音乐（TTM）模型的人工偏好评估成本高、难对比，且缺乏开放的偏好数据源。为此提出Music Arena平台，让真实用户输入文本提示并比较两个TTM系统的输出，其偏好用于生成排行榜。该平台有基于大语言模型的路由系统和收集详细偏好等音乐领域特定设计，还提出滚动数据发布政策保障用户隐私。它解决了TTM评估中的关键挑战，展示了实时评估在特定AI领域的适应性。
            arXiv:2507.20900v1 Announce Type: new 
Abstract: We present Music Arena, an open platform for scalable human preference evaluation of text-to-music (TTM) models. Soliciting human preferences via listening studies is the gold standard for evaluation in TTM, but these studies are expensive to conduct and difficult to compare, as study protocols may differ across systems. Moreover, human preferences might help researchers align their TTM systems or improve automatic evaluation metrics, but an open and renewable source of preferences does not currently exist. We aim to fill these gaps by offering *live* evaluation for TTM. In Music Arena, real-world users input text prompts of their choosing and compare outputs from two TTM systems, and their preferences are used to compile a leaderboard. While Music Arena follows recent evaluation trends in other AI domains, we also design it with key features tailored to music: an LLM-based routing system to navigate the heterogeneous type signatures of TTM systems, and the collection of *detailed* preferences including listening data and natural language feedback. We also propose a rolling data release policy with user privacy guarantees, providing a renewable source of preference data and increasing platform transparency. Through its standardized evaluation protocol, transparent data access policies, and music-specific features, Music Arena not only addresses key challenges in the TTM ecosystem but also demonstrates how live evaluation can be thoughtfully adapted to unique characteristics of specific AI domains.
  Music Arena is available at: https://music-arena.org
        ]]></description>
    </item>
    <item>
        <title>ProsodyLM: Uncovering the Emerging Prosody Processing Capabilities in Speech Language Models</title>
        <link>https://arxiv.org/abs/2507.20091</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.20091v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kaizhi Qian, Xulin Fan, Junrui Ni, Slava Shechtman, Mark Hasegawa-Johnson, Chuang Gan, Yang Zhang</dc:creator>
        <description><![CDATA[
            这是一篇关于语音语言模型韵律处理能力的研究。现有主流训练范式在学习韵律信息方面欠佳，预训练后的大模型未展现明显韵律处理能力。为此提出ProsodyLM，采用利于学习韵律的简单分词方案，先将语音转录为文本，再转换为词级韵律标记序列。该方案保留更完整韵律信息，更易被基于文本的大模型理解。经预训练，ProsodyLM展现出多样韵律处理能力，如把握生成语音韵律细节、理解语句情感和重音、保持长上下文韵律一致。
            arXiv:2507.20091v1 Announce Type: cross 
Abstract: Speech language models refer to language models with speech processing and understanding capabilities. One key desirable capability for speech language models is the ability to capture the intricate interdependency between content and prosody. The existing mainstream paradigm of training speech language models, which converts speech into discrete tokens before feeding them into LLMs, is sub-optimal in learning prosody information -- we find that the resulting LLMs do not exhibit obvious emerging prosody processing capabilities via pre-training alone. To overcome this, we propose ProsodyLM, which introduces a simple tokenization scheme amenable to learning prosody. Each speech utterance is first transcribed into text, followed by a sequence of word-level prosody tokens. Compared with conventional speech tokenization schemes, the proposed tokenization scheme retains more complete prosody information, and is more understandable to text-based LLMs. We find that ProsodyLM can learn surprisingly diverse emerging prosody processing capabilities through pre-training alone, ranging from harnessing the prosody nuances in generated speech, such as contrastive focus, understanding emotion and stress in an utterance, to maintaining prosody consistency in long contexts.
        ]]></description>
    </item>
    <item>
        <title>Controllable Video-to-Music Generation with Multiple Time-Varying Conditions</title>
        <link>https://arxiv.org/abs/2507.20627</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.20627v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Junxian Wu, Weitao You, Heda Zuo, Dengming Zhang, Pei Chen, Lingyun Sun</dc:creator>
        <description><![CDATA[
            背景：音乐能增强视频叙事与情感，自动视频到音乐（V2M）生成需求大，但现有方法多以黑盒方式生成，难符用户期望。方法：提出多条件引导的V2M生成框架，采用两阶段训练策略。第一阶段引入细粒度特征选择和渐进时间对齐注意力机制；第二阶段开发动态条件融合和控制引导解码器模块。效果：实验表明，该方法在主客观评估上均优于现有V2M管道，显著提升可控性和符合用户期望程度。
            arXiv:2507.20627v1 Announce Type: cross 
Abstract: Music enhances video narratives and emotions, driving demand for automatic video-to-music (V2M) generation. However, existing V2M methods relying solely on visual features or supplementary textual inputs generate music in a black-box manner, often failing to meet user expectations. To address this challenge, we propose a novel multi-condition guided V2M generation framework that incorporates multiple time-varying conditions for enhanced control over music generation. Our method uses a two-stage training strategy that enables learning of V2M fundamentals and audiovisual temporal synchronization while meeting users' needs for multi-condition control. In the first stage, we introduce a fine-grained feature selection module and a progressive temporal alignment attention mechanism to ensure flexible feature alignment. For the second stage, we develop a dynamic conditional fusion module and a control-guided decoder module to integrate multiple conditions and accurately guide the music composition process. Extensive experiments demonstrate that our method outperforms existing V2M pipelines in both subjective and objective evaluations, significantly enhancing control and alignment with user expectations.
        ]]></description>
    </item>
    <item>
        <title>Computer Audition: From Task-Specific Machine Learning to Foundation Models</title>
        <link>https://arxiv.org/abs/2407.15672</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2407.15672v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Andreas Triantafyllopoulos, Iosif Tsangko, Alexander Gebhard, Annamaria Mesaros, Tuomas Virtanen, Bj\"orn Schuller</dc:creator>
        <description><![CDATA[
            背景：基础模型（FMs）正引领计算机听觉领域发展，其在多方面优于传统方法，引发音频界关注。方法：本文概述了计算音频分析从传统流程向听觉基础模型的转变，强调了这些模型的关键操作原理。效果：展示了该模型能整合音频界此前单独处理的多个任务，可将多任务合并于单一模型，还能利用其他模态知识并方便与人类用户交互。
            arXiv:2407.15672v2 Announce Type: replace 
Abstract: Foundation models (FMs) are increasingly spearheading recent advances on a variety of tasks that fall under the purview of computer audition -- the use of machines to understand sounds. They feature several advantages over traditional pipelines: among others, the ability to consolidate multiple tasks in a single model, the option to leverage knowledge from other modalities, and the readily-available interaction with human users. Naturally, these promises have created substantial excitement in the audio community, and have led to a wave of early attempts to build new, general-purpose foundation models for audio. In the present contribution, we give an overview of computational audio analysis as it transitions from traditional pipelines towards auditory foundation models. Our work highlights the key operating principles that underpin those models, and showcases how they can accommodate multiple tasks that the audio community previously tackled separately.
        ]]></description>
    </item>
    <item>
        <title>TAIL: Text-Audio Incremental Learning</title>
        <link>https://arxiv.org/abs/2503.04258</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.04258v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yingfei Sun, Xu Gu, Wei Ji, Hanbin Zhao, Yifang Yin, Roger Zimmermann</dc:creator>
        <description><![CDATA[
            背景：现有文本与音频结合研究忽视模型在新数据集上的泛化能力，引入新数据集会导致灾难性遗忘，且大模型参数影响训练性能。方法：提出文本 - 音频增量学习（TAIL）任务及PTAT方法，利用提示调优优化模型参数，结合音频 - 文本相似度和特征蒸馏模块缓解遗忘。效果：在多个数据集上测试，该方法显著优于先前方法，对旧数据集抗遗忘能力更强，仅需全参数微调方法2.42%的参数，性能高出4.46%。
            arXiv:2503.04258v2 Announce Type: replace 
Abstract: Many studies combine text and audio to capture multi-modal information but they overlook the model's generalization ability on new datasets. Introducing new datasets may affect the feature space of the original dataset, leading to catastrophic forgetting. Meanwhile, large model parameters can significantly impact training performance. To address these limitations, we introduce a novel task called Text-Audio Incremental Learning (TAIL) task for text-audio retrieval, and propose a new method, PTAT, Prompt Tuning for Audio-Text incremental learning. This method utilizes prompt tuning to optimize the model parameters while incorporating an audio-text similarity and feature distillation module to effectively mitigate catastrophic forgetting. We benchmark our method and previous incremental learning methods on AudioCaps, Clotho, BBC Sound Effects and Audioset datasets, and our method outperforms previous methods significantly, particularly demonstrating stronger resistance to forgetting on older datasets. Compared to the full-parameters Finetune (Sequential) method, our model only requires 2.42\% of its parameters, achieving 4.46\% higher performance.
        ]]></description>
    </item>
    <item>
        <title>Neural Spectral Band Generation for Audio Coding</title>
        <link>https://arxiv.org/abs/2506.06732</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06732v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Woongjib Choi, Byeong Hyeon Kim, Hyungseob Lim, Inseon Jang, Hong-Goo Kang</dc:creator>
        <description><![CDATA[
            背景：传统频谱带复制（SBR）仅利用粗频谱特征，对不同声学信号适应性有限。方法：提出基于深度神经网络（DNN）的高频带编码生成方法——神经频谱带生成（n - SBG），采用DNN编解码器结构提取量化高频分量相关边信息，结合解码的核心频带信号生成高频分量，用生成对抗准则优化编码流程。效果：以AAC为核心编解码器实验表明，该方法比HE - AAC - v1感知质量更好，且所需边信息少。
            arXiv:2506.06732v2 Announce Type: replace 
Abstract: Spectral band replication (SBR) enables bit-efficient coding by generating high-frequency bands from the low-frequency ones. However, it only utilizes coarse spectral features upon a subband-wise signal replication, limiting adaptability to diverse acoustic signals. In this paper, we explore the efficacy of a deep neural network (DNN)-based generative approach for coding the high-frequency bands, which we call neural spectral band generation (n-SBG). Specifically, we propose a DNN-based encoder-decoder structure to extract and quantize the side information related to the high-frequency components and generate the components given both the side information and the decoded core-band signals. The whole coding pipeline is optimized with generative adversarial criteria to enable the generation of perceptually plausible sound. From experiments using AAC as the core codec, we show that the proposed method achieves a better perceptual quality than HE-AAC-v1 with much less side information.
        ]]></description>
    </item>
    <item>
        <title>SpecASR: Accelerating LLM-based Automatic Speech Recognition via Speculative Decoding</title>
        <link>https://arxiv.org/abs/2507.18181</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.18181v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Linye Wei, Shuzhang Zhong, Songqiang Xu, Runsheng Wang, Ru Huang, Meng Li</dc:creator>
        <description><![CDATA[
            基于大语言模型（LLM）的自动语音识别（ASR）因高识别准确率和多方言支持能力受关注，但LLM解码延迟高，难以满足实时ASR需求。虽已有推测解码方法，但未考虑ASR任务特性，加速效果有限。为此，本文提出适用于ASR的SpecASR框架。它利用ASR解码受音频条件约束、大小模型输出对齐度高的特点，采用自适应草稿序列生成、草稿序列复用和二通稀疏令牌树生成算法。实验表明，SpecASR在不损失识别准确率的情况下，较基线自回归解码和推测解码分别实现3.04 - 3.79倍和1.25 - 1.84倍加速。
            arXiv:2507.18181v2 Announce Type: replace 
Abstract: Large language model (LLM)-based automatic speech recognition (ASR) has recently attracted a lot of attention due to its high recognition accuracy and enhanced multi-dialect support. However, the high decoding latency of LLMs challenges the real-time ASR requirements. Although speculative decoding has been explored for better decoding efficiency, they usually ignore the key characteristics of the ASR task and achieve limited speedup. To further reduce the real-time ASR latency, in this paper, we propose a novel speculative decoding framework specialized for ASR, dubbed SpecASR. SpecASR is developed based on our core observation that ASR decoding is audio-conditioned, which results in high output alignment between small and large ASR models, even given output mismatches in intermediate decoding steps. Therefore, SpecASR features an adaptive draft sequence generation process that dynamically modifies the draft sequence length to maximize the token acceptance length. SpecASR further proposes a draft sequence recycling strategy that reuses the previously generated draft sequence to reduce the draft ASR model latency. Moreover, a two-pass sparse token tree generation algorithm is also proposed to balance the latency of draft and target ASR models. With extensive experimental results, we demonstrate SpecASR achieves 3.04x-3.79x and 1.25x-1.84x speedup over the baseline autoregressive decoding and speculative decoding, respectively, without any loss in recognition accuracy.
        ]]></description>
    </item>
    <item>
        <title>Benchmarking Open-ended Audio Dialogue Understanding for Large Audio-Language Models</title>
        <link>https://arxiv.org/abs/2412.05167</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2412.05167v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kuofeng Gao, Shu-Tao Xia, Ke Xu, Philip Torr, Jindong Gu</dc:creator>
        <description><![CDATA[
            背景：大型音频语言模型（LALMs）具备音频对话能力，但缺乏评估其开放式音频对话理解性能的综合基准。方法：提出由4个基准数据集组成的音频对话理解基准（ADU - Bench），在3种通用场景、12项技能、9种语言和4类歧义处理方面评估LALMs。首次提出评估音频对话中处理歧义的能力。效果：ADU - Bench含超2万条开放式音频对话，实验表明现有LALMs在处理数学符号、理解人类行为、多语言理解和处理音频歧义方面存在困难。
            arXiv:2412.05167v2 Announce Type: replace-cross 
Abstract: Large Audio-Language Models (LALMs), such as GPT-4o, have recently unlocked audio dialogue capabilities, enabling direct spoken exchanges with humans. The potential of LALMs broadens their applicability across a wide range of practical scenarios supported by audio dialogues. However, given these advancements, a comprehensive benchmark to evaluate the performance of LALMs in the open-ended audio dialogue understanding remains absent currently. To address this gap, we propose an Audio Dialogue Understanding Benchmark (ADU-Bench), which consists of 4 benchmark datasets. They assess the open-ended audio dialogue ability for LALMs in 3 general scenarios, 12 skills, 9 multilingual languages, and 4 categories of ambiguity handling. Notably, we firstly propose the evaluation of ambiguity handling in audio dialogues that expresses different intentions beyond the same literal meaning of sentences, e.g., "Really!?" with different intonations. In summary, ADU-Bench includes over 20,000 open-ended audio dialogues for the assessment of LALMs. Through extensive experiments on 16 LALMs, our analysis reveals that existing LALMs struggle with mathematical symbols and formulas, understanding human behavior such as roleplay, comprehending multiple languages, and handling audio dialogue ambiguities from different phonetic elements, such as intonations, pause positions, and homophones. The benchmark is available at https://adu-bench.github.io/.
        ]]></description>
    </item>
</channel>
</rss>