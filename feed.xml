<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
<channel>
    <title>arXiv Paper Filter</title>
    <link>https://github.com/None/arxiv_filter</link>
    <description>根据研究兴趣筛选的arXiv论文</description>
    <atom:link href="https://raw.githubusercontent.com/None/arxiv_filter/main/feed.xml" rel="self" type="application/rss+xml" />
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>zh-CN</language>
    <lastBuildDate>Mon, 07 Apr 2025 12:10:45 +0800</lastBuildDate>
    <managingEditor>None@github.com</managingEditor>
    <pubDate>Mon, 07 Apr 2025 12:10:45 +0800</pubDate>
    <skipDays>
        <day>Saturday</day>
        <day>Sunday</day>
    </skipDays>

    <item>
        <title>OpenFACADES: An Open Framework for Architectural Caption and Attribute Data Enrichment via Street View Imagery</title>
        <link>https://arxiv.org/abs/2504.02866</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.02866v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiucheng Liang, Jinheng Xie, Tianhong Zhao, Rudi Stouffs, Filip Biljecki</dc:creator>
        <description><![CDATA[
            背景：建筑属性数据在城市应用中至关重要，但许多城市地区数据稀缺，整合多源数据、获取建筑图像并推断属性存在挑战。方法：提出OpenFACADES框架，利用多模态众包数据和多模态大语言模型丰富建筑信息，分三步进行，整合图像元数据与地图几何信息、自动检测建筑立面并转换视角、利用开源大视觉语言模型进行多属性预测和字幕生成。效果：微调后的大视觉语言模型在多属性推理上表现出色，优于单属性计算机视觉模型和零样本ChatGPT - 4o。
            arXiv:2504.02866v1 Announce Type: new 
Abstract: Building properties, such as height, usage, and material composition, play a crucial role in spatial data infrastructures, supporting applications such as energy simulation, risk assessment, and environmental modeling. Despite their importance, comprehensive and high-quality building attribute data remain scarce in many urban areas. Recent advances have enabled the extraction and tagging of objective building attributes using remote sensing and street-level imagery. However, establishing a method and pipeline that integrates diverse open datasets, acquires holistic building imagery at scale, and infers comprehensive building attributes remains a significant challenge. Among the first, this study bridges the gaps by introducing OpenFACADES, an open framework that leverages multimodal crowdsourced data to enrich building profiles with both objective attributes and semantic descriptors through multimodal large language models. Our methodology proceeds in three major steps. First, we integrate street-level image metadata from Mapillary with OpenStreetMap geometries via isovist analysis, effectively identifying images that provide suitable vantage points for observing target buildings. Second, we automate the detection of building facades in panoramic imagery and tailor a reprojection approach to convert objects into holistic perspective views that approximate real-world observation. Third, we introduce an innovative approach that harnesses and systematically investigates the capabilities of open-source large vision-language models (VLMs) for multi-attribute prediction and open-vocabulary captioning in building-level analytics, leveraging a globally sourced dataset of 30,180 labeled images from seven cities. Evaluation shows that fine-tuned VLM excel in multi-attribute inference, outperforming single-attribute computer vision models and zero-shot ChatGPT-4o.
        ]]></description>
    </item>
    <item>
        <title>Embedding Method for Knowledge Graph with Densely Defined Ontology</title>
        <link>https://arxiv.org/abs/2504.02889</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.02889v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Takanori Ugai</dc:creator>
        <description><![CDATA[
            背景：知识图谱嵌入（KGE）可增强知识图谱，但现有KGE模型未充分利用本体，特别是属性间关系。方法：提出适用于定义良好且包含属性关系本体的知识图谱的KGE模型TransU，将属性视为实体子集以实现统一表示。效果：在标准数据集和实际数据集上进行了实验，虽摘要未提及具体定量效果指标，但验证了该方法的可行性。
            arXiv:2504.02889v1 Announce Type: new 
Abstract: Knowledge graph embedding (KGE) is a technique that enhances knowledge graphs by addressing incompleteness and improving knowledge retrieval. A limitation of the existing KGE models is their underutilization of ontologies, specifically the relationships between properties. This study proposes a KGE model, TransU, designed for knowledge graphs with well-defined ontologies that incorporate relationships between properties. The model treats properties as a subset of entities, enabling a unified representation. We present experimental results using a standard dataset and a practical dataset.
        ]]></description>
    </item>
    <item>
        <title>Enhancing Chart-to-Code Generation in Multimodal Large Language Models via Iterative Dual Preference Learning</title>
        <link>https://arxiv.org/abs/2504.02906</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.02906v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhihan Zhang, Yixin Cao, Lizi Liao</dc:creator>
        <description><![CDATA[
            背景：图表转代码生成需模型准确捕捉和总结视觉与结构元素，多模态大语言模型在该任务上表现不佳。方法：提出Chart2Code迭代双偏好学习框架，通过结构化代码变体生成和细粒度双奖励信号增强模型能力。效果：在三个多模态大语言模型上验证，迭代偏好学习持续提升分布外图表转代码生成质量，双评分方法即便减少偏好数据集规模也能带来更大性能提升，还为图表理解研究奠定基础。
            arXiv:2504.02906v1 Announce Type: new 
Abstract: Chart-to-code generation, the process of converting chart images into executable plotting scripts, provides a lossless representation of chart information, requiring models to accurately capture and summarize all visual and structural elements. However, this remains a significant challenge for multimodal large language models (MLLMs), which are not inherently well-aligned with code generation tasks. To bridge this gap, we introduce Chart2Code, a novel iterative dual preference learning framework designed to enhance MLLMs' chart-to-code generation capabilities through structured code variant generation and fine-grained dual reward signals. We validate Chart2Code across three MLLMs and find that iterative preference learning consistently improves out-of-distribution chart-to-code generation quality. Throughout this process, our dual scoring method, which evaluates both the textual code structure and its visual representation, leads to greater performance improvements, even with a reduced preference dataset size. Further analysis explores the key components of our framework and highlights the interplay between chart-to-code generation and broader chart reasoning, paving the way for future advancements in chart comprehension.
        ]]></description>
    </item>
    <item>
        <title>HyperRAG: Enhancing Quality-Efficiency Tradeoffs in Retrieval-Augmented Generation with Reranker KV-Cache Reuse</title>
        <link>https://arxiv.org/abs/2504.02921</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.02921v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuwei An, Yihua Cheng, Seo Jin Park, Junchen Jiang</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）可将外部知识融入大语言模型生成过程，但重排器在提升回复质量的同时带来计算挑战。方法：提出HyperRAG系统，利用KV缓存重用优化RAG管道质量与效率的权衡，还加入一系列系统级优化提升效率和可扩展性。效果：实验表明，使用仅解码器重排器时，HyperRAG吞吐量提升2 - 3倍，且下游性能高于传统RAG服务。
            arXiv:2504.02921v1 Announce Type: new 
Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm for enhancing the performance of large language models (LLMs) by integrating external knowledge into the generation process. A key component of RAG pipelines is the reranker, which selects the most relevant documents from a pool of retrieved candidates and significantly improves the quality of the generated responses. While rerankers refine the selection of retrieved documents in RAG pipelines, they introduce computational challenges that hinder high throughput and low latency. To address this problem, we propose HyperRAG, a system that optimizes the trade-off between quality and efficiency in RAG pipelines by leveraging KV-cache reuse for efficient reranker inference. By reusing document-side KV-cache, HyperRAG achieves both high-quality generation and system-level efficiency. To fully realize the benefits of KV-cache reuse, HyperRAG incorporates a range of system-level optimizations designed to enhance efficiency and scalability. Experiments show that HyperRAG achieves a 2 - 3 throughput improvement with decoder-only rerankers while also delivering higher downstream performance compared with traditional RAG service.
        ]]></description>
    </item>
    <item>
        <title>Graph Attention for Heterogeneous Graphs with Positional Encoding</title>
        <link>https://arxiv.org/abs/2504.02938</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.02938v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Nikhil Shivakumar Nayak</dc:creator>
        <description><![CDATA[
            背景：图神经网络（GNNs）是处理图数据的常用方法，但在异构图上表现复杂，通常不如同构图。方法：对各种GNN架构进行基准测试，发现图注意力网络在节点分类和链接预测任务中表现出色，并通过整合节点嵌入的位置编码对其进行改进，利用完整拉普拉斯谱来捕捉节点相对和绝对位置。效果：进一步提升了节点分类和链接预测等下游任务的性能。
            arXiv:2504.02938v1 Announce Type: new 
Abstract: Graph Neural Networks (GNNs) have emerged as the de facto standard for modeling graph data, with attention mechanisms and transformers significantly enhancing their performance on graph-based tasks. Despite these advancements, the performance of GNNs on heterogeneous graphs often remains complex, with networks generally underperforming compared to their homogeneous counterparts. This work benchmarks various GNN architectures to identify the most effective methods for heterogeneous graphs, with a particular focus on node classification and link prediction. Our findings reveal that graph attention networks excel in these tasks. As a main contribution, we explore enhancements to these attention networks by integrating positional encodings for node embeddings. This involves utilizing the full Laplacian spectrum to accurately capture both the relative and absolute positions of each node within the graph, further enhancing performance on downstream tasks such as node classification and link prediction.
        ]]></description>
    </item>
    <item>
        <title>Why Reasoning Matters? A Survey of Advancements in Multimodal Reasoning (v1)</title>
        <link>https://arxiv.org/abs/2504.03151</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.03151v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jing Bi, Susan Liang, Xiaofei Zhou, Pinxin Liu, Junjia Guo, Yunlong Tang, Luchuan Song, Chao Huang, Guangyu Sun, Jinxi He, Jiarui Wu, Shu Yang, Daoan Zhang, Chen Chen, Lianggong Bruce Wen, Zhang Liu, Jiebo Luo, Chenliang Xu</dc:creator>
        <description><![CDATA[
            背景：推理对人类智能至关重要，大语言模型虽在算术等领域推理能力提升，但拓展到多模态场景仍面临挑战，如处理模态间冲突信息。方法：论文对文本和多模态大语言模型的推理技术进行概述，通过全面且最新的对比，明确核心推理挑战与机遇，强调后训练优化和测试时推理的实用方法。效果：为理论框架和实际应用搭建桥梁，为未来研究指明方向。
            arXiv:2504.03151v1 Announce Type: new 
Abstract: Reasoning is central to human intelligence, enabling structured problem-solving across diverse tasks. Recent advances in large language models (LLMs) have greatly enhanced their reasoning abilities in arithmetic, commonsense, and symbolic domains. However, effectively extending these capabilities into multimodal contexts-where models must integrate both visual and textual inputs-continues to be a significant challenge. Multimodal reasoning introduces complexities, such as handling conflicting information across modalities, which require models to adopt advanced interpretative strategies. Addressing these challenges involves not only sophisticated algorithms but also robust methodologies for evaluating reasoning accuracy and coherence. This paper offers a concise yet insightful overview of reasoning techniques in both textual and multimodal LLMs. Through a thorough and up-to-date comparison, we clearly formulate core reasoning challenges and opportunities, highlighting practical methods for post-training optimization and test-time inference. Our work provides valuable insights and guidance, bridging theoretical frameworks and practical implementations, and sets clear directions for future research.
        ]]></description>
    </item>
    <item>
        <title>Efficient Dynamic Clustering-Based Document Compression for Retrieval-Augmented-Generation</title>
        <link>https://arxiv.org/abs/2504.03165</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.03165v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Weitao Li, Kaiming Liu, Xiangyu Zhang, Xuanyu Lei, Weizhi Ma, Yang Liu</dc:creator>
        <description><![CDATA[
            背景：近年来检索增强生成（RAG）在大语言模型推理的知识整合中广泛应用，但当前RAG实现难以有效处理检索内容中的噪声、重复和冗余信息。方法：提出基于高效动态聚类的文档压缩框架（EDC² - RAG），有效利用文档间潜在关系，同时去除无关和冗余信息。效果：在知识问答和幻觉检测数据集上验证，基于GPT - 3.5构建的该方法在不同场景和实验设置下性能均有提升，展现出强鲁棒性和适用性。
            arXiv:2504.03165v1 Announce Type: new 
Abstract: Retrieval-Augmented Generation (RAG) has emerged as a widely adopted approach for knowledge integration during large language model (LLM) inference in recent years. However, current RAG implementations face challenges in effectively addressing noise, repetition and redundancy in retrieved content, primarily due to their limited ability to exploit fine-grained inter-document relationships. To address these limitations, we propose an \textbf{E}fficient \textbf{D}ynamic \textbf{C}lustering-based document \textbf{C}ompression framework (\textbf{EDC\textsuperscript{2}-RAG}) that effectively utilizes latent inter-document relationships while simultaneously removing irrelevant information and redundant content. We validate our approach, built upon GPT-3.5, on widely used knowledge-QA and hallucination-detected datasets. The results show that this method achieves consistent performance improvements across various scenarios and experimental settings, demonstrating strong robustness and applicability. Our code and datasets can be found at https://github.com/Tsinghua-dhy/EDC-2-RAG.
        ]]></description>
    </item>
    <item>
        <title>Think When You Need: Self-Adaptive Chain-of-Thought Learning</title>
        <link>https://arxiv.org/abs/2504.03234</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.03234v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Junjie Yang, Ke Lin, Xing Yu</dc:creator>
        <description><![CDATA[
            背景：思维链推理虽提升语言模型性能，但在简单问题上易导致低效“过度思考”，且现有直接惩罚推理长度的方法未考虑问题复杂度差异。方法：通过长度和质量比较构建奖励，基于理论假设共同提升解答正确性与简洁性，还将方法拓展到无标准答案的模糊任务。效果：在多个推理基准测试中，该方法在保持准确率的同时，能生成更简洁的解释，有效让模型“按需思考”。
            arXiv:2504.03234v1 Announce Type: new 
Abstract: Chain of Thought (CoT) reasoning enhances language models' performance but often leads to inefficient "overthinking" on simple problems. We identify that existing approaches directly penalizing reasoning length fail to account for varying problem complexity. Our approach constructs rewards through length and quality comparisons, guided by theoretical assumptions that jointly enhance solution correctness with conciseness. Moreover, we further demonstrate our method to fuzzy tasks where ground truth is unavailable. Experiments across multiple reasoning benchmarks demonstrate that our method maintains accuracy while generating significantly more concise explanations, effectively teaching models to "think when needed."
        ]]></description>
    </item>
    <item>
        <title>Optimal Embedding Guided Negative Sample Generation for Knowledge Graph Link Prediction</title>
        <link>https://arxiv.org/abs/2504.03327</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.03327v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Makoto Takamoto, Daniel O\~noro-Rubio, Wiem Ben Rim, Takashi Maruyama, Bhushan Kotnis</dc:creator>
        <description><![CDATA[
            背景：知识图谱嵌入（KGE）模型需精准区分正负样本以预测新链接，识别高质量负样本是难题。方法：理论研究负样本实现最优图谱嵌入的条件，提出Embedding Mutation（EMU）框架来生成满足该条件的负样本，可与现有KGE模型和负采样方法集成。效果：在多数据集实验中，显著提升了各KGE模型和负采样方法的链接预测性能，效果相当于将嵌入维度扩大五倍的模型。
            arXiv:2504.03327v1 Announce Type: new 
Abstract: Knowledge graph embedding (KGE) models encode the structural information of knowledge graphs to predicting new links. Effective training of these models requires distinguishing between positive and negative samples with high precision. Although prior research has shown that improving the quality of negative samples can significantly enhance model accuracy, identifying high-quality negative samples remains a challenging problem. This paper theoretically investigates the condition under which negative samples lead to optimal KG embedding and identifies a sufficient condition for an effective negative sample distribution. Based on this theoretical foundation, we propose \textbf{E}mbedding \textbf{MU}tation (\textsc{EMU}), a novel framework that \emph{generates} negative samples satisfying this condition, in contrast to conventional methods that focus on \emph{identifying} challenging negative samples within the training data. Importantly, the simplicity of \textsc{EMU} ensures seamless integration with existing KGE models and negative sampling methods. To evaluate its efficacy, we conducted comprehensive experiments across multiple datasets. The results consistently demonstrate significant improvements in link prediction performance across various KGE models and negative sampling methods. Notably, \textsc{EMU} enables performance improvements comparable to those achieved by models with embedding dimension five times larger. An implementation of the method and experiments are available at https://github.com/nec-research/EMU-KG.
        ]]></description>
    </item>
    <item>
        <title>Diverse In-Context Example Selection After Decomposing Programs and Aligned Utterances Improves Semantic Parsing</title>
        <link>https://arxiv.org/abs/2504.03541</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.03541v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mayank Kothyari, Sunita Sarawagi, Soumen Chakrabarti, Gaurav Arora, Srujana Merugu</dc:creator>
        <description><![CDATA[
            背景：大语言模型（LLMs）常作为自然语言到结构化程序的翻译器，但程序的抽象语法树（AST）结构表示给上下文示例（ICEs）设计和选择带来新问题。方法：将可用的ICE树分解成片段，用带语法约束的LLM自动将片段映射到对应语句，适配扩展一种多样化ICE选择方法。效果：在语义解析基准测试中，所提的SCUD4ICL系统通过分解多样化示范方法提升了准确率，尤其在小LLMs、大标签树ICE池和低资源语言程序中效果显著。
            arXiv:2504.03541v1 Announce Type: new 
Abstract: LLMs are increasingly used as seq2seq translators from natural language utterances to structured programs, a process called semantic interpretation. Unlike atomic labels or token sequences, programs are naturally represented as abstract syntax trees (ASTs). Such structured representation raises novel issues related to the design and selection of in-context examples (ICEs) presented to the LLM. We focus on decomposing the pool of available ICE trees into fragments, some of which may be better suited to solving the test instance. Next, we propose how to use (additional invocations of) an LLM with prompted syntax constraints to automatically map the fragments to corresponding utterances. Finally, we adapt and extend a recent method for diverse ICE selection to work with whole and fragmented ICE instances. We evaluate our system, SCUD4ICL, on popular diverse semantic parsing benchmarks, showing visible accuracy gains from our proposed decomposed diverse demonstration method. Benefits are particularly notable for smaller LLMs, ICE pools having larger labeled trees, and programs in lower resource languages.
        ]]></description>
    </item>
    <item>
        <title>LightPROF: A Lightweight Reasoning Framework for Large Language Model on Knowledge Graph</title>
        <link>https://arxiv.org/abs/2504.03137</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.03137v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tu Ao, Yanhua Yu, Yuling Wang, Yang Deng, Zirui Guo, Liang Pang, Pinghui Wang, Tat-Seng Chua, Xiao Zhang, Zhen Cai</dc:creator>
        <description><![CDATA[
            大语言模型在知识更新延迟时推理易出错，知识图谱能为其提供可靠信息，但现有基于知识图谱的推理方法忽略结构信息且资源消耗大。为此提出LightPROF框架，采用“检索 - 嵌入 - 推理”流程，先从知识图谱中检索推理图，再用基于Transformer的适配器提取整合信息并映射到模型嵌入空间生成提示。该框架只需训练适配器且兼容开源模型。在两个基准测试中，用小模型就取得优异表现，在输入标记数和推理时间上优势明显。
            arXiv:2504.03137v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) have impressive capabilities in text understanding and zero-shot reasoning. However, delays in knowledge updates may cause them to reason incorrectly or produce harmful results. Knowledge Graphs (KGs) provide rich and reliable contextual information for the reasoning process of LLMs by structurally organizing and connecting a wide range of entities and relations. Existing KG-based LLM reasoning methods only inject KGs' knowledge into prompts in a textual form, ignoring its structural information. Moreover, they mostly rely on close-source models or open-source models with large parameters, which poses challenges to high resource consumption. To address this, we propose a novel Lightweight and efficient Prompt learning-ReasOning Framework for KGQA (LightPROF), which leverages the full potential of LLMs to tackle complex reasoning tasks in a parameter-efficient manner. Specifically, LightPROF follows a "Retrieve-Embed-Reason process", first accurately, and stably retrieving the corresponding reasoning graph from the KG through retrieval module. Next, through a Transformer-based Knowledge Adapter, it finely extracts and integrates factual and structural information from the KG, then maps this information to the LLM's token embedding space, creating an LLM-friendly prompt to be used by the LLM for the final reasoning. Additionally, LightPROF only requires training Knowledge Adapter and can be compatible with any open-source LLM. Extensive experiments on two public KGQA benchmarks demonstrate that LightPROF achieves superior performance with small-scale LLMs. Furthermore, LightPROF shows significant advantages in terms of input token count and reasoning time.
        ]]></description>
    </item>
    <item>
        <title>Do Larger Language Models Imply Better Reasoning? A Pretraining Scaling Law for Reasoning</title>
        <link>https://arxiv.org/abs/2504.03635</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.03635v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xinyi Wang, Shawn Tan, Mingyu Jin, William Yang Wang, Rameswar Panda, Yikang Shen</dc:creator>
        <description><![CDATA[
            背景：大语言模型在复杂推理任务中表现出色，但规模扩展对其推理能力的影响尚不清楚。方法：构建合成多跳推理环境，模拟真实大规模知识图谱结构和分布，让语言模型仅在不完整图的三元组上从头预训练，完成图中缺失边推理任务，还研究影响U型损失曲线的因素。效果：发现过参数化因过度记忆会损害推理性能，找到将知识图谱搜索熵线性映射到最优模型大小的经验缩放关系，为优化推理性能提供新思路。
            arXiv:2504.03635v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across a wide range of tasks requiring complex reasoning. However, the effects of scaling on their reasoning abilities remain insufficiently understood. In this paper, we introduce a synthetic multihop reasoning environment designed to closely replicate the structure and distribution of real-world large-scale knowledge graphs. Our reasoning task involves completing missing edges in the graph, which requires advanced multi-hop reasoning and mimics real-world reasoning scenarios. To evaluate this, we pretrain language models (LMs) from scratch solely on triples from the incomplete graph and assess their ability to infer the missing edges. Interestingly, we observe that overparameterization can impair reasoning performance due to excessive memorization. We investigate different factors that affect this U-shaped loss curve, including graph structure, model size, and training steps. To predict the optimal model size for a specific knowledge graph, we find an empirical scaling that linearly maps the knowledge graph search entropy to the optimal model size. This work provides new insights into the relationship between scaling and reasoning in LLMs, shedding light on possible ways to optimize their performance for reasoning tasks.
        ]]></description>
    </item>
    <item>
        <title>TILP: Differentiable Learning of Temporal Logical Rules on Knowledge Graphs</title>
        <link>https://arxiv.org/abs/2402.12309</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2402.12309v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Siheng Xiong, Yuan Yang, Faramarz Fekri, James Clayton Kerce</dc:creator>
        <description><![CDATA[
            背景：相比静态知识图谱，能捕捉信息随时间演变的时序知识图谱更具现实性，但时间概念给规则学习带来复杂性，准确的图推理仍是难题。方法：提出可微框架TILP，设计约束随机游走机制并引入时间算子，对时序特征建模并融入学习过程。效果：在两个基准数据集上与现有方法对比，TILP能提升基线方法性能且结果可解释，在训练样本有限、数据有偏差等场景下表现远超现有方法。
            arXiv:2402.12309v2 Announce Type: replace 
Abstract: Compared with static knowledge graphs, temporal knowledge graphs (tKG), which can capture the evolution and change of information over time, are more realistic and general. However, due to the complexity that the notion of time introduces to the learning of the rules, an accurate graph reasoning, e.g., predicting new links between entities, is still a difficult problem. In this paper, we propose TILP, a differentiable framework for temporal logical rules learning. By designing a constrained random walk mechanism and the introduction of temporal operators, we ensure the efficiency of our model. We present temporal features modeling in tKG, e.g., recurrence, temporal order, interval between pair of relations, and duration, and incorporate it into our learning process. We compare TILP with state-of-the-art methods on two benchmark datasets. We show that our proposed framework can improve upon the performance of baseline methods while providing interpretable results. In particular, we consider various scenarios in which training samples are limited, data is biased, and the time range between training and inference are different. In all these cases, TILP works much better than the state-of-the-art methods.
        ]]></description>
    </item>
    <item>
        <title>LLMs Prompted for Graphs: Hallucinations and Generative Capabilities</title>
        <link>https://arxiv.org/abs/2409.00159</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2409.00159v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Gurvan Richardeau, Samy Chali, Erwan Le Merrer, Camilla Penzo, Gilles Tredan</dc:creator>
        <description><![CDATA[
            背景：大语言模型（LLMs）被用于多种任务，本文探究其在图的背诵和生成方面的能力。方法：先研究LLMs复述文献中著名图的能力，再通过要求生成Erdos - Renyi随机图探究其生成能力，还提出用幻觉视角评估误差的指标。效果：发现图幻觉幅度可体现部分LLMs的优越性，复述任务中，图幻觉与幻觉排行榜相关；生成任务中，多数LLMs有良好且可重复的结果，为深入研究和改进提供了起点与挑战基准。
            arXiv:2409.00159v3 Announce Type: replace 
Abstract: Large Language Models (LLMs) are nowadays prompted for a wide variety of tasks. In this article, we investigate their ability in reciting and generating graphs. We first study the ability of LLMs to regurgitate well known graphs from the literature (e.g. Karate club or the graph atlas)4. Secondly, we question the generative capabilities of LLMs by asking for Erdos-Renyi random graphs. As opposed to the possibility that they could memorize some Erdos-Renyi graphs included in their scraped training set, this second investigation aims at studying a possible emergent property of LLMs. For both tasks, we propose a metric to assess their errors with the lens of hallucination (i.e. incorrect information returned as facts). We most notably find that the amplitude of graph hallucinations can characterize the superiority of some LLMs. Indeed, for the recitation task, we observe that graph hallucinations correlate with the Hallucination Leaderboard, a hallucination rank that leverages 10, 000 times more prompts to obtain its ranking. For the generation task, we find surprisingly good and reproducible results in most of LLMs. We believe this to constitute a starting point for more in-depth studies of this emergent capability and a challenging benchmark for their improvements. Altogether, these two aspects of LLMs capabilities bridge a gap between the network science and machine learning communities.
        ]]></description>
    </item>
    <item>
        <title>BioX-CPath: Biologically-driven Explainable Diagnostics for Multistain IHC Computational Pathology</title>
        <link>https://arxiv.org/abs/2503.20880</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.20880v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Amaya Gallagher-Syed, Henry Senior, Omnia Alwazzan, Elena Pontarini, Michele Bombardieri, Costantino Pitzalis, Myles J. Lewis, Michael R. Barnes, Luca Rossi, Gregory Slabaugh</dc:creator>
        <description><![CDATA[
            在计算病理学中，开发具有生物学可解释性的模型是关键挑战，尤其在多染色免疫组织化学分析方面。本文提出BioX - CPath，一种用于全切片图像分类的可解释图神经网络架构，利用多染色的空间和语义特征。核心是引入新型染色感知注意力池化（SAAP）模块生成有生物学意义的患者嵌入。该方法在类风湿性关节炎和干燥综合征多染色数据集上达州 - 先进水平，还通过染色注意力分数等提供可解释见解，适合对可解释性要求高的临床应用。
            arXiv:2503.20880v2 Announce Type: replace 
Abstract: The development of biologically interpretable and explainable models remains a key challenge in computational pathology, particularly for multistain immunohistochemistry (IHC) analysis. We present BioX-CPath, an explainable graph neural network architecture for whole slide image (WSI) classification that leverages both spatial and semantic features across multiple stains. At its core, BioX-CPath introduces a novel Stain-Aware Attention Pooling (SAAP) module that generates biologically meaningful, stain-aware patient embeddings. Our approach achieves state-of-the-art performance on both Rheumatoid Arthritis and Sjogren's Disease multistain datasets. Beyond performance metrics, BioX-CPath provides interpretable insights through stain attention scores, entropy measures, and stain interaction scores, that permit measuring model alignment with known pathological mechanisms. This biological grounding, combined with strong classification performance, makes BioX-CPath particularly suitable for clinical applications where interpretability is key. Source code and documentation can be found at: https://github.com/AmayaGS/BioX-CPath.
        ]]></description>
    </item>
    <item>
        <title>Assessing SPARQL capabilities of Large Language Models</title>
        <link>https://arxiv.org/abs/2409.05925</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2409.05925v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Lars-Peter Meyer, Johannes Frey, Felix Brei, Natanael Arndt</dc:creator>
        <description><![CDATA[
            背景：大语言模型（LLMs）与知识图谱（KGs）集成对知识驱动应用有重要潜力，SPARQL是访问KGs的核心技术。方法：采用定量方法，在LLM - KG - Bench框架中实现多种基准测试任务，对多个LLMs自动执行和评估，从语法、语义读取、语义创建及知识图谱提示作用等维度评估。效果：评估了GPT、Gemini和Claude等模型，发现LLMs处理SPARQL SELECT查询仍具挑战性，创建语义正确的查询在很多情况下较难。
            arXiv:2409.05925v2 Announce Type: replace-cross 
Abstract: The integration of Large Language Models (LLMs) with Knowledge Graphs (KGs) offers significant synergistic potential for knowledge-driven applications. One possible integration is the interpretation and generation of formal languages, such as those used in the Semantic Web, with SPARQL being a core technology for accessing KGs. In this paper, we focus on measuring out-of-the box capabilities of LLMs to work with SPARQL and more specifically with SPARQL SELECT queries applying a quantitative approach.
  We implemented various benchmarking tasks in the LLM-KG-Bench framework for automated execution and evaluation with several LLMs. The tasks assess capabilities along the dimensions of syntax, semantic read, semantic create, and the role of knowledge graph prompt inclusion.
  With this new benchmarking tasks, we evaluated a selection of GPT, Gemini, and Claude models. Our findings indicate that working with SPARQL SELECT queries is still challenging for LLMs and heavily depends on the specific LLM as well as the complexity of the task. While fixing basic syntax errors seems to pose no problems for the best of the current LLMs evaluated, creating semantically correct SPARQL SELECT queries is difficult in several cases.
        ]]></description>
    </item>
    <item>
        <title>MatterChat: A Multi-Modal LLM for Material Science</title>
        <link>https://arxiv.org/abs/2502.13107</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.13107v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yingheng Tang, Wenbin Xu, Jie Cao, Jianzhu Ma, Weilu Gao, Steve Farrell, Benjamin Erichson, Michael W. Mahoney, Andy Nonaka, Zhi Yao</dc:creator>
        <description><![CDATA[
            背景：利用多模态大模型将材料结构数据与语言信息融合，对加速材料科学发展有重要意义，但全分辨率原子结构融入大模型是挑战。方法：提出MatterChat，用桥接模块将预训练的机器学习原子间势与预训练大语言模型有效对齐。效果：显著提升材料属性预测和人机交互性能，超越GPT - 4等通用大模型，在科学推理和材料合成步骤设计等应用中也展现出实用性。
            arXiv:2502.13107v2 Announce Type: replace-cross 
Abstract: Understanding and predicting the properties of inorganic materials is crucial for accelerating advancements in materials science and driving applications in energy, electronics, and beyond. Integrating material structure data with language-based information through multi-modal large language models (LLMs) offers great potential to support these efforts by enhancing human-AI interaction. However, a key challenge lies in integrating atomic structures at full resolution into LLMs. In this work, we introduce MatterChat, a versatile structure-aware multi-modal LLM that unifies material structural data and textual inputs into a single cohesive model. MatterChat employs a bridging module to effectively align a pretrained machine learning interatomic potential with a pretrained LLM, reducing training costs and enhancing flexibility. Our results demonstrate that MatterChat significantly improves performance in material property prediction and human-AI interaction, surpassing general-purpose LLMs such as GPT-4. We also demonstrate its usefulness in applications such as more advanced scientific reasoning and step-by-step material synthesis.
        ]]></description>
    </item>
    <item>
        <title>Generating Diverse Audio-Visual 360 Soundscapes for Sound Event Localization and Detection</title>
        <link>https://arxiv.org/abs/2504.02988</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.02988v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Adrian S. Roman, Aiden Chang, Gerardo Meza, Iran R. Roman</dc:creator>
        <description><![CDATA[
            背景：为音频视觉声音事件定位与检测（SELD）生成合成视频数据。方法：提出SELDVisualSynth工具，结合真实世界背景图像提升合成视听SELD数据的真实感，确保视听空间对齐，创建360度合成视频，使物体移动与合成SELD音频数据及标注匹配。效果：用该数据训练的模型在多个指标上有性能提升，定位召回率达56.4 LR，定位误差为21.9度LE。该数据生成工具已开源。
            arXiv:2504.02988v1 Announce Type: new 
Abstract: We present SELDVisualSynth, a tool for generating synthetic videos for audio-visual sound event localization and detection (SELD). Our approach incorporates real-world background images to improve realism in synthetic audio-visual SELD data while also ensuring audio-visual spatial alignment. The tool creates 360 synthetic videos where objects move matching synthetic SELD audio data and its annotations. Experimental results demonstrate that a model trained with this data attains performance gains across multiple metrics, achieving superior localization recall (56.4 LR) and competitive localization error (21.9deg LE). We open-source our data generation tool for maximal use by members of the SELD research community.
        ]]></description>
    </item>
    <item>
        <title>Mind the Prompt: Prompting Strategies in Audio Generations for Improving Sound Classification</title>
        <link>https://arxiv.org/abs/2504.03329</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.03329v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Francesca Ronchini, Ho-Hsiang Wu, Wei-Cheng Lin, Fabio Antonacci</dc:creator>
        <description><![CDATA[
            背景：需设计有效提示策略用文本到音频（TTA）模型生成逼真数据集，并提升其在声音分类任务中的效用。方法：评估两个声音分类数据集和两个TTA模型，应用多种提示策略，分析不同组合数据集的技术。效果：特定任务提示策略在数据生成上显著优于基本提示方法；合并不同TTA模型生成的数据集比单纯增加训练集规模更能有效提升分类性能，证明该方法作为合成数据增强技术的优势。
            arXiv:2504.03329v1 Announce Type: new 
Abstract: This paper investigates the design of effective prompt strategies for generating realistic datasets using Text-To-Audio (TTA) models. We also analyze different techniques for efficiently combining these datasets to enhance their utility in sound classification tasks. By evaluating two sound classification datasets with two TTA models, we apply a range of prompt strategies. Our findings reveal that task-specific prompt strategies significantly outperform basic prompt approaches in data generation. Furthermore, merging datasets generated using different TTA models proves to enhance classification performance more effectively than merely increasing the training dataset size. Overall, our results underscore the advantages of these methods as effective data augmentation techniques using synthetic data.
        ]]></description>
    </item>
    <item>
        <title>Ichigo: Mixed-Modal Early-Fusion Realtime Voice Assistant</title>
        <link>https://arxiv.org/abs/2410.15316</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.15316v3</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Alan Dao (Gia Tuan Dao), Dinh Bach Vu, Huy Hoang Ha</dc:creator>
        <description><![CDATA[
            背景：大语言模型应用于语音任务时，音频和文本模态融合复杂。方法：提出混合模态模型Ichigo，采用标记化早期融合方法，将语音量化为离散标记，用统一的基于Transformer架构处理语音和文本，有全面训练方法。效果：在语音问答基准测试中达最优，超现有开源语音语言模型，与级联系统效果相当，首标记生成延迟仅111 ms，远低于当前模型，为多模态AI和开源语音语言模型研究提供框架。
            arXiv:2410.15316v3 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) have revolutionized natural language processing, but their application to speech-based tasks remains challenging due to the complexities of integrating audio and text modalities. This paper introduces Ichigo, a mixed-modal model that seamlessly processes interleaved sequences of speech and text. Utilizing a tokenized early-fusion approach, Ichigo quantizes speech into discrete tokens and employs a uniform transformer-based architecture for both speech and text modalities. This method enables joint reasoning and generation across modalities without the need for separate adapters. We present a comprehensive training methodology, including pre-training on multilingual speech recognition datasets and fine-tuning on a curated instruction dataset. Ichigo demonstrates state-of-the-art performance on speech question-answering benchmarks, outperforming existing open-source speech language models and achieving comparable results to cascaded systems. Notably, Ichigo exhibits a latency of just 111 ms to first token generation, significantly lower than current models. Our approach not only advances the field of multimodal AI but also provides a framework for smaller research teams to contribute effectively to open-source speech-language models.
        ]]></description>
    </item>
    <item>
        <title>FADA: Fast Diffusion Avatar Synthesis with Mixed-Supervised Multi-CFG Distillation</title>
        <link>https://arxiv.org/abs/2412.16915</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2412.16915v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tianyun Zhong, Chao Liang, Jianwen Jiang, Gaojie Lin, Jiaqi Yang, Zhou Zhao</dc:creator>
        <description><![CDATA[
            基于扩散的音频驱动说话头像方法效果好但推理慢，现有蒸馏技术应用效果不佳，蒸馏模型鲁棒性和音视频相关性降低。为此提出FADA方法，设计混合监督损失以提升模型能力和鲁棒性，提出带可学习令牌的多CFG蒸馏以利用音频和参考图像条件的相关性。多数据集实验表明，FADA生成的视频效果与基于扩散模型的方法相当，同时实现了4.17 - 12.5倍的NFE加速。
            arXiv:2412.16915v2 Announce Type: replace-cross 
Abstract: Diffusion-based audio-driven talking avatar methods have recently gained attention for their high-fidelity, vivid, and expressive results. However, their slow inference speed limits practical applications. Despite the development of various distillation techniques for diffusion models, we found that naive diffusion distillation methods do not yield satisfactory results. Distilled models exhibit reduced robustness with open-set input images and a decreased correlation between audio and video compared to teacher models, undermining the advantages of diffusion models. To address this, we propose FADA (Fast Diffusion Avatar Synthesis with Mixed-Supervised Multi-CFG Distillation). We first designed a mixed-supervised loss to leverage data of varying quality and enhance the overall model capability as well as robustness. Additionally, we propose a multi-CFG distillation with learnable tokens to utilize the correlation between audio and reference image conditions, reducing the threefold inference runs caused by multi-CFG with acceptable quality degradation. Extensive experiments across multiple datasets show that FADA generates vivid videos comparable to recent diffusion model-based methods while achieving an NFE speedup of 4.17-12.5 times. Demos are available at our webpage http://fadavatar.github.io.
        ]]></description>
    </item>
</channel>
</rss>