<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
<channel>
    <title>arXiv Paper Filter</title>
    <link>https://github.com/None/arxiv_filter</link>
    <description>根据研究兴趣筛选的arXiv论文</description>
    <atom:link href="https://raw.githubusercontent.com/None/arxiv_filter/main/feed.xml" rel="self" type="application/rss+xml" />
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>zh-CN</language>
    <lastBuildDate>Thu, 15 May 2025 12:12:25 +0800</lastBuildDate>
    <managingEditor>None@github.com</managingEditor>
    <pubDate>Thu, 15 May 2025 12:12:25 +0800</pubDate>
    <skipDays>
        <day>Saturday</day>
        <day>Sunday</day>
    </skipDays>

    <item>
        <title>The Geometry of Meaning: Perfect Spacetime Representations of Hierarchical Structures</title>
        <link>https://arxiv.org/abs/2505.08795</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.08795v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Andres Anabalon, Hugo Garces, Julio Oliva, Jose Cifuentes</dc:creator>
        <description><![CDATA[
            背景：需有效将结构化信息与语义空间对齐。方法：提出快速算法将层次结构嵌入三维闵可夫斯基时空，模型仅依赖定向标记对，不借助全局符号结构，还引入基于因果关系的检索机制。效果：将该方法应用于WordNet语料库，实现哺乳动物子树含歧义情况及最大无歧义子集的完美嵌入，结果表明所有离散数据都有三维完美几何表示，嵌入近乎共形不变，显示与广义相对论和场论有深层联系。
            arXiv:2505.08795v1 Announce Type: new 
Abstract: We show that there is a fast algorithm that embeds hierarchical structures in three-dimensional Minkowski spacetime. The correlation of data ends up purely encoded in the causal structure. Our model relies solely on oriented token pairs -- local hierarchical signals -- with no access to global symbolic structure. We apply our method to the corpus of \textit{WordNet}. We provide a perfect embedding of the mammal sub-tree including ambiguities (more than one hierarchy per node) in such a way that the hierarchical structures get completely codified in the geometry and exactly reproduce the ground-truth. We extend this to a perfect embedding of the maximal unambiguous subset of the \textit{WordNet} with 82{,}115 noun tokens and a single hierarchy per token. We introduce a novel retrieval mechanism in which causality, not distance, governs hierarchical access. Our results seem to indicate that all discrete data has a perfect geometrical representation that is three-dimensional. The resulting embeddings are nearly conformally invariant, indicating deep connections with general relativity and field theory. These results suggest that concepts, categories, and their interrelations, namely hierarchical meaning itself, is geometric.
        ]]></description>
    </item>
    <item>
        <title>DyGSSM: Multi-view Dynamic Graph Embeddings with State Space Model Gradient Update</title>
        <link>https://arxiv.org/abs/2505.09017</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.09017v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Bizhan Alipour Pijan, Serdar Bozdag</dc:creator>
        <description><![CDATA[
            背景：现有动态图表示学习方法存在无法同时提取全局和局部信息、参数更新时未考虑当前快照模型性能等局限。方法：提出DyGSSM方法，结合图卷积网络提取局部特征、随机游走与门控循环单元提取全局特征，用交叉注意力机制融合特征，还引入基于HiPPO算法的状态空间模型处理长期依赖。效果：在五个公开数据集的20个案例中，该方法有17个案例优于现有基线和最先进方法。
            arXiv:2505.09017v1 Announce Type: new 
Abstract: Most of the dynamic graph representation learning methods involve dividing a dynamic graph into discrete snapshots to capture the evolving behavior of nodes over time. Existing methods primarily capture only local or global structures of each node within a snapshot using message-passing and random walk-based methods. Then, they utilize sequence-based models (e.g., transformers) to encode the temporal evolution of node embeddings, and meta-learning techniques to update the model parameters. However, these approaches have two limitations. First, they neglect the extraction of global and local information simultaneously in each snapshot. Second, they fail to consider the model's performance in the current snapshot during parameter updates, resulting in a lack of temporal dependency management. Recently, HiPPO (High-order Polynomial Projection Operators) algorithm has gained attention for their ability to optimize and preserve sequence history in State Space Model (SSM). To address the aforementioned limitations in dynamic graph representation learning, we propose a novel method called Multi-view Dynamic Graph Embeddings with State Space Model Gradient Update (DyGSSM). Our approach combines Graph Convolution Networks (GCN) for local feature extraction and random walk with Gated Recurrent Unit (GRU) for global feature extraction in each snapshot. We then integrate the local and global features using a cross-attention mechanism. Additionally, we incorporate an SSM based on HiPPO algorithm to account for long-term dependencies when updating model parameters, ensuring that model performance in each snapshot informs subsequent updates. Experiments on five public datasets show that our method outperforms existing baseline and state-of-the-art (SOTA) methods in 17 out of 20 cases.
        ]]></description>
    </item>
    <item>
        <title>Block-Biased Mamba for Long-Range Sequence Processing</title>
        <link>https://arxiv.org/abs/2505.09022</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.09022v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Annan Yu, N. Benjamin Erichson</dc:creator>
        <description><![CDATA[
            背景：Mamba在多个领域表现出色，但在长序列任务上表现不佳，理解并解决此问题对提升其通用性很重要。方法：从表达能力、归纳偏置和训练稳定性三方面分析Mamba局限，提出$	ext{B}_2	ext{S}_6$，它是Mamba的S6单元的扩展，结合块级选择性动态和特定通道偏差。效果：理论证明该方法改善了归纳偏置、表达能力和稳定性，实证显示$	ext{B}_2	ext{S}_6$在长序列竞技场任务上优于S4和S4D，且在语言建模基准测试中保持Mamba的性能。
            arXiv:2505.09022v1 Announce Type: new 
Abstract: Mamba extends earlier state space models (SSMs) by introducing input-dependent dynamics, and has demonstrated strong empirical performance across a range of domains, including language modeling, computer vision, and foundation models. However, a surprising weakness remains: despite being built on architectures designed for long-range dependencies, Mamba performs poorly on long-range sequential tasks. Understanding and addressing this gap is important for improving Mamba's universality and versatility. In this work, we analyze Mamba's limitations through three perspectives: expressiveness, inductive bias, and training stability. Our theoretical results show how Mamba falls short in each of these aspects compared to earlier SSMs such as S4D. To address these issues, we propose $\text{B}_2\text{S}_6$, a simple extension of Mamba's S6 unit that combines block-wise selective dynamics with a channel-specific bias. We prove that these changes equip the model with a better-suited inductive bias and improve its expressiveness and stability. Empirically, $\text{B}_2\text{S}_6$ outperforms S4 and S4D on Long-Range Arena (LRA) tasks while maintaining Mamba's performance on language modeling benchmarks.
        ]]></description>
    </item>
    <item>
        <title>Seeing Beyond the Scene: Enhancing Vision-Language Models with Interactional Reasoning</title>
        <link>https://arxiv.org/abs/2505.09118</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.09118v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Dayong Liang, Changmeng Zheng, Zhiyuan Wen, Yi Cai, Xiao-Yong Wei, Qing Li</dc:creator>
        <description><![CDATA[
            背景：传统场景图聚焦空间关系，限制了视觉语言模型（VLMs）对视觉场景中复杂交互的推理能力，且传统方法存在生成关系集不聚焦、缺乏持久记忆等问题。方法：提出交互增强场景图推理（ISGR）框架，包括双流图构造器结合空间关系提取与交互感知字幕生成场景图、用目标交互查询激活VLMs知识、引入长期记忆强化学习策略。效果：在交互密集推理基准测试中显著优于基线方法，复杂场景理解任务提升明显。
            arXiv:2505.09118v1 Announce Type: new 
Abstract: Traditional scene graphs primarily focus on spatial relationships, limiting vision-language models' (VLMs) ability to reason about complex interactions in visual scenes. This paper addresses two key challenges: (1) conventional detection-to-construction methods produce unfocused, contextually irrelevant relationship sets, and (2) existing approaches fail to form persistent memories for generalizing interaction reasoning to new scenes. We propose Interaction-augmented Scene Graph Reasoning (ISGR), a framework that enhances VLMs' interactional reasoning through three complementary components. First, our dual-stream graph constructor combines SAM-powered spatial relation extraction with interaction-aware captioning to generate functionally salient scene graphs with spatial grounding. Second, we employ targeted interaction queries to activate VLMs' latent knowledge of object functionalities, converting passive recognition into active reasoning about how objects work together. Finally, we introduce a lone-term memory reinforcement learning strategy with a specialized interaction-focused reward function that transforms transient patterns into long-term reasoning heuristics. Extensive experiments demonstrate that our approach significantly outperforms baseline methods on interaction-heavy reasoning benchmarks, with particularly strong improvements on complex scene understanding tasks. The source code can be accessed at https://github.com/open_upon_acceptance.
        ]]></description>
    </item>
    <item>
        <title>AMSnet 2.0: A Large AMS Database with AI Segmentation for Net Detection</title>
        <link>https://arxiv.org/abs/2505.09155</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.09155v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yichen Shi, Zhuofu Tao, Yuhao Gao, Li Huang, Hongyang Wang, Zhiping Yu, Ting-Jung Lin, Lei He</dc:creator>
        <description><![CDATA[
            背景：当前多模态大语言模型理解电路原理图能力有限，原因在于缺乏高质量的原理图 - 网表训练数据，且现有方法难以处理复杂或有噪声的原理图。方法：提出基于分割的网检测机制，恢复位置信息以实现原理图数字重建，还扩充 AMSnet 数据集得到 AMSnet 2.0。效果：AMSnet 2.0 包含 2686 个电路，相比 AMSnet 的 792 个电路，数据更丰富，还增加了数字原理图等信息。
            arXiv:2505.09155v1 Announce Type: new 
Abstract: Current multimodal large language models (MLLMs) struggle to understand circuit schematics due to their limited recognition capabilities. This could be attributed to the lack of high-quality schematic-netlist training data. Existing work such as AMSnet applies schematic parsing to generate netlists. However, these methods rely on hard-coded heuristics and are difficult to apply to complex or noisy schematics in this paper. We therefore propose a novel net detection mechanism based on segmentation with high robustness. The proposed method also recovers positional information, allowing digital reconstruction of schematics. We then expand AMSnet dataset with schematic images from various sources and create AMSnet 2.0. AMSnet 2.0 contains 2,686 circuits with schematic images, Spectre-formatted netlists, OpenAccess digital schematics, and positional information for circuit components and nets, whereas AMSnet only includes 792 circuits with SPICE netlists but no digital schematics.
        ]]></description>
    </item>
    <item>
        <title>Towards Fair In-Context Learning with Tabular Foundation Models</title>
        <link>https://arxiv.org/abs/2505.09503</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.09503v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Patrik Kenfack, Samira Ebrahimi Kaho, Ulrich A\"ivodji</dc:creator>
        <description><![CDATA[
            背景：表格基础模型在结构化数据上展现出强大的上下文学习（ICL）能力，但传统机器学习模型中的偏差在表格ICL中的表现尚不明确。方法：论文研究表格ICL的公平性影响，并探索三种预处理策略，即去除相关性、组平衡示例选择和基于不确定性的示例选择来解决偏差问题。效果：综合实验表明，基于不确定性的示例选择能持续提升上下文预测的组公平性。代码见https://github.com/patrikken/Fair-TabICL 。
            arXiv:2505.09503v1 Announce Type: new 
Abstract: Tabular foundational models have exhibited strong in-context learning (ICL) capabilities on structured data, allowing them to make accurate predictions on test sets without parameter updates, using training examples as context. This emerging approach positions itself as a competitive alternative to traditional gradient-boosted tree methods. However, while biases in conventional machine learning models are well documented, it remains unclear how these biases manifest in tabular ICL. The paper investigates the fairness implications of tabular ICL and explores three preprocessing strategies--correlation removal, group-balanced demonstration selection, and uncertainty-based demonstration selection--to address bias. Comprehensive experiments indicate that uncertainty-based demonstration selection consistently enhances group fairness of in-context predictions. The source code for reproducing the results of this work can be found at https://github.com/patrikken/Fair-TabICL.
        ]]></description>
    </item>
    <item>
        <title>Improving the Reliability of LLMs: Combining CoT, RAG, Self-Consistency, and Self-Verification</title>
        <link>https://arxiv.org/abs/2505.09031</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.09031v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Adarsh Kumar, Hwiyoon Kim, Jawahar Sai Nathani, Neil Roy</dc:creator>
        <description><![CDATA[
            背景：大语言模型在复杂开放任务中存在幻觉问题，思维链提示虽能提升多步推理能力，但无法完全解决该问题。方法：研究将思维链（CoT）与检索增强生成（RAG）结合，同时应用自一致性和自验证策略，在推理中引入外部知识源，让模型验证或修正自身输出。效果：通过对比评估，凸显了各方法的有效性，确定了在保持流畅性和推理深度的同时，减少幻觉的最有效方法。
            arXiv:2505.09031v1 Announce Type: cross 
Abstract: Hallucination, where large language models (LLMs) generate confident but incorrect or irrelevant information, remains a key limitation in their application to complex, open-ended tasks. Chain-of-thought (CoT) prompting has emerged as a promising method for improving multistep reasoning by guiding models through intermediate steps. However, CoT alone does not fully address the hallucination problem. In this work, we investigate how combining CoT with retrieval-augmented generation (RAG), as well as applying self-consistency and self-verification strategies, can reduce hallucinations and improve factual accuracy. By incorporating external knowledge sources during reasoning and enabling models to verify or revise their own outputs, we aim to generate more accurate and coherent responses. We present a comparative evaluation of baseline LLMs against CoT, CoT+RAG, self-consistency, and self-verification techniques. Our results highlight the effectiveness of each method and identify the most robust approach for minimizing hallucinations while preserving fluency and reasoning depth.
        ]]></description>
    </item>
    <item>
        <title>Focus, Merge, Rank: Improved Question Answering Based on Semi-structured Knowledge Bases</title>
        <link>https://arxiv.org/abs/2505.09246</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.09246v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Derian Boer, Stephen Roth, Stefan Kramer</dc:creator>
        <description><![CDATA[
            背景：现实中机器学习模型和交互系统可获取结构化与非结构化知识，但多数仅依赖其一，半结构化知识库可弥合差距。方法：提出基于半结构化知识库的多跳问答框架FocusedRetriever，集成多种组件，利用大模型从非结构化文本提取关系事实和实体属性等。效果：在STaRK基准测试集上超越现有方法，平均首次命中率比次优方法高25.7%，且代码开源。
            arXiv:2505.09246v1 Announce Type: cross 
Abstract: In many real-world settings, machine learning models and interactive systems have access to both structured knowledge, e.g., knowledge graphs or tables, and unstructured content, e.g., natural language documents. However, most rely on either. Semi-Structured Knowledge Bases (SKBs) bridge this gap by linking unstructured content to nodes within structured data, thereby enabling new strategies for knowledge access and use. In this work, we present FocusedRetriever, a modular SKB-based framework for multi-hop question answering. It integrates components (VSS-based entity search, LLM-based generation of Cypher queries and pairwise re-ranking) in a way that enables it to outperform state-of-the-art methods across all three STaRK benchmark test sets, covering diverse domains and multiple performance metrics. The average first-hit rate exceeds that of the second-best method by 25.7%. FocusedRetriever leverages (1) the capacity of Large Language Models (LLMs) to extract relational facts and entity attributes from unstructured text, (2) node set joins to filter answer candidates based on these extracted triplets and constraints, (3) vector similarity search to retrieve and rank relevant unstructured content, and (4) the contextual capabilities of LLMs to finally rank the top-k answers. For generality, we only incorporate base LLMs in FocusedRetriever in our evaluation. However, our analysis of intermediate results highlights several opportunities for further upgrades including finetuning. The source code is publicly available at https://github.com/kramerlab/FocusedRetriever .
        ]]></description>
    </item>
    <item>
        <title>Construction and Application of Materials Knowledge Graph in Multidisciplinary Materials Science via Large Language Model</title>
        <link>https://arxiv.org/abs/2404.03080</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2404.03080v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yanpeng Ye, Jie Ren, Shaozhou Wang, Yuwei Wan, Imran Razzak, Bram Hoex, Haofen Wang, Tong Xie, Wenjie Zhang</dc:creator>
        <description><![CDATA[
            背景：材料科学知识分散，传统实验方法不利于快速创新，人工智能与材料科学结合需解决信息标注、提取和溯源问题。方法：引入材料知识图谱（MKG），利用自然语言处理和大模型从十年研究中提取结构化三元组，按精心设计的本体分类信息。效果：MKG包含162,605个节点和731,772条边，能高效进行链接预测，减少对传统实验方法的依赖，简化材料研究，为构建更复杂科学知识图谱奠定基础。
            arXiv:2404.03080v4 Announce Type: replace 
Abstract: Knowledge in materials science is widely dispersed across extensive scientific literature, posing significant challenges to the efficient discovery and integration of new materials. Traditional methods, often reliant on costly and time-consuming experimental approaches, further complicate rapid innovation. Addressing these challenges, the integration of artificial intelligence with materials science has opened avenues for accelerating the discovery process, though it also demands precise annotation, data extraction, and traceability of information. To tackle these issues, this article introduces the Materials Knowledge Graph (MKG), which utilizes advanced natural language processing techniques integrated with large language models to extract and systematically organize a decade's worth of high-quality research into structured triples, contains 162,605 nodes and 731,772 edges. MKG categorizes information into comprehensive labels such as Name, Formula, and Application, structured around a meticulously designed ontology, thus enhancing data usability and integration. By implementing network-based algorithms, MKG not only facilitates efficient link prediction but also significantly reduces reliance on traditional experimental methods. This structured approach not only streamlines materials research but also lays the groundwork for more sophisticated science knowledge graphs.
        ]]></description>
    </item>
    <item>
        <title>FAMMA: A Benchmark for Financial Domain Multilingual Multimodal Question Answering</title>
        <link>https://arxiv.org/abs/2410.04526</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.04526v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Siqiao Xue, Xiaojing Li, Fan Zhou, Qingyang Dai, Zhixuan Chu, Hongyuan Mei</dc:creator>
        <description><![CDATA[
            背景：为评估大语言模型回答需高级金融知识的复杂推理问题的能力，提出金融领域多语言多模态问答基准FAMMA。方法：该基准有两个版本，FAMMA - Basic含1945个从教材和考试提取的问题及答案、推理过程；FAMMA - LivePro有103个专家创建的新问题。问题覆盖金融8大子领域，部分含非文本数据。还整理推理轨迹微调开源Qwen模型。效果：实验表明FAMMA对大模型挑战大，基于推理轨迹训练模型可显著提升其在FAMMA - LivePro上的表现。
            arXiv:2410.04526v3 Announce Type: replace 
Abstract: In this paper, we introduce FAMMA, an open-source benchmark for \underline{f}in\underline{a}ncial \underline{m}ultilingual \underline{m}ultimodal question \underline{a}nswering (QA). Our benchmark aims to evaluate the abilities of large language models (LLMs) in answering complex reasoning questions that require advanced financial knowledge. The benchmark has two versions: FAMMA-Basic consists of 1,945 questions extracted from university textbooks and exams, along with human-annotated answers and rationales; FAMMA-LivePro consists of 103 novel questions created by human domain experts, with answers and rationales held out from the public for a contamination-free evaluation. These questions cover advanced knowledge of 8 major subfields in finance (e.g., corporate finance, derivatives, and portfolio management). Some are in Chinese or French, while a majority of them are in English. Each question has some non-text data such as charts, diagrams, or tables. Our experiments reveal that FAMMA poses a significant challenge on LLMs, including reasoning models such as GPT-o1 and DeepSeek-R1. Additionally, we curated 1,270 reasoning trajectories of DeepSeek-R1 on the FAMMA-Basic data, and fine-tuned a series of open-source Qwen models using this reasoning data. We found that training a model on these reasoning trajectories can significantly improve its performance on FAMMA-LivePro. We released our leaderboard, data, code, and trained models at https://famma-bench.github.io/famma/.
        ]]></description>
    </item>
    <item>
        <title>Improving Network Threat Detection by Knowledge Graph, Large Language Model, and Imbalanced Learning</title>
        <link>https://arxiv.org/abs/2501.16393</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2501.16393v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Lili Zhang, Quanyan Zhu, Herman Ray, Ying Xie</dc:creator>
        <description><![CDATA[
            背景：网络攻击活动复杂，历史威胁数据有限，网络威胁检测面临挑战。方法：提出集成建模框架，用知识图谱分析用户活动模式，采用不平衡学习技术修剪和加权知识图谱，利用大语言模型从知识图谱中检索和解读用户活动，并将该框架应用于在线序贯学习的敏捷威胁检测。效果：初步结果显示威胁捕获率提高3%-4%，基于用户活动的风险预测可解释性增强。
            arXiv:2501.16393v2 Announce Type: replace 
Abstract: Network threat detection has been challenging due to the complexities of attack activities and the limitation of historical threat data to learn from. To help enhance the existing practices of using analytics, machine learning, and artificial intelligence methods to detect the network threats, we propose an integrated modelling framework, where Knowledge Graph is used to analyze the users' activity patterns, Imbalanced Learning techniques are used to prune and weigh Knowledge Graph, and LLM is used to retrieve and interpret the users' activities from Knowledge Graph. The proposed framework is applied to Agile Threat Detection through Online Sequential Learning. The preliminary results show the improved threat capture rate by 3%-4% and the increased interpretabilities of risk predictions based on the users' activities.
        ]]></description>
    </item>
    <item>
        <title>Fusing Bidirectional Chains of Thought and Reward Mechanisms A Method for Enhancing Question-Answering Capabilities of Large Language Models for Chinese Intangible Cultural Heritage</title>
        <link>https://arxiv.org/abs/2505.08167</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.08167v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ruilin Liu, Zhixiao Zhao, Jieqiong Li, Chang Liu, Dongbo Wang</dc:creator>
        <description><![CDATA[
            大语言模型发展为特定领域模型带来机遇，但用非遗数据微调面临偏差、知识继承错误等挑战。为此，提出融合双向思维链和奖励机制的训练方法，基于非遗大模型ICH - Qwen，让模型能正向推理，还通过反向提问和推理激活潜在知识，并引入奖励机制优化决策。对比实验显示，该方法在问答任务的准确率、Bleu - 4和Rouge - L得分上优于其他方法，消融和泛化实验也证明其有效性和多领域适应性。
            arXiv:2505.08167v2 Announce Type: replace 
Abstract: The rapid development of large language models (LLMs) has provided significant support and opportunities for the advancement of domain-specific LLMs. However, fine-tuning these large models using Intangible Cultural Heritage (ICH) data inevitably faces challenges such as bias, incorrect knowledge inheritance, and catastrophic forgetting. To address these issues, we propose a novel training method that integrates a bidirectional chains of thought and a reward mechanism. This method is built upon ICH-Qwen, a large language model specifically designed for the field of intangible cultural heritage. The proposed method enables the model to not only perform forward reasoning but also enhances the accuracy of the generated answers by utilizing reverse questioning and reverse reasoning to activate the model's latent knowledge. Additionally, a reward mechanism is introduced during training to optimize the decision-making process. This mechanism improves the quality of the model's outputs through structural and content evaluations with different weighting schemes. We conduct comparative experiments on ICH-Qwen, with results demonstrating that our method outperforms 0-shot, step-by-step reasoning, knowledge distillation, and question augmentation methods in terms of accuracy, Bleu-4, and Rouge-L scores on the question-answering task. Furthermore, the paper highlights the effectiveness of combining the bidirectional chains of thought and reward mechanism through ablation experiments. In addition, a series of generalizability experiments are conducted, with results showing that the proposed method yields improvements on various domain-specific datasets and advanced models in areas such as Finance, Wikidata, and StrategyQA. This demonstrates that the method is adaptable to multiple domains and provides a valuable approach for model training in future applications across diverse fields.
        ]]></description>
    </item>
    <item>
        <title>OLinear: A Linear Model for Time Series Forecasting in Orthogonally Transformed Domain</title>
        <link>https://arxiv.org/abs/2505.08550</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.08550v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wenzhen Yue, Yong Liu, Haoxuan Li, Hao Wang, Xianghua Ying, Ruohao Guo, Bowei Xing, Ji Shi</dc:creator>
        <description><![CDATA[
            背景：现有时间序列预测模型多采用时域预测范式，序列数据中复杂的逐步依赖关系会影响预测性能。方法：提出基于线性的多元时间序列预测模型OLinear，在正交变换域操作，使用基于正交矩阵的数据自适应变换OrthoTrans，还引入定制线性层NormLin以学习多元时间序列表示。效果：NormLin模块比多头自注意力机制性能更优，计算量近减半。在24个基准和140个预测任务上，OLinear高效且达最优，NormLin可提升基于Transformer的预测器。
            arXiv:2505.08550v2 Announce Type: replace 
Abstract: This paper presents $\mathbf{OLinear}$, a $\mathbf{linear}$-based multivariate time series forecasting model that operates in an $\mathbf{o}$rthogonally transformed domain. Recent forecasting models typically adopt the temporal forecast (TF) paradigm, which directly encode and decode time series in the time domain. However, the entangled step-wise dependencies in series data can hinder the performance of TF. To address this, some forecasters conduct encoding and decoding in the transformed domain using fixed, dataset-independent bases (e.g., sine and cosine signals in the Fourier transform). In contrast, we utilize $\mathbf{OrthoTrans}$, a data-adaptive transformation based on an orthogonal matrix that diagonalizes the series' temporal Pearson correlation matrix. This approach enables more effective encoding and decoding in the decorrelated feature domain and can serve as a plug-in module to enhance existing forecasters. To enhance the representation learning for multivariate time series, we introduce a customized linear layer, $\mathbf{NormLin}$, which employs a normalized weight matrix to capture multivariate dependencies. Empirically, the NormLin module shows a surprising performance advantage over multi-head self-attention, while requiring nearly half the FLOPs. Extensive experiments on 24 benchmarks and 140 forecasting tasks demonstrate that OLinear consistently achieves state-of-the-art performance with high efficiency. Notably, as a plug-in replacement for self-attention, the NormLin module consistently enhances Transformer-based forecasters. The code and datasets are available at https://anonymous.4open.science/r/OLinear
        ]]></description>
    </item>
    <item>
        <title>Towards Autonomous UAV Visual Object Search in City Space: Benchmark and Agentic Methodology</title>
        <link>https://arxiv.org/abs/2505.08765</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.08765v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yatai Ji, Zhengqiu Zhu, Yong Zhao, Beidan Liu, Chen Gao, Yihao Zhao, Sihang Qiu, Yue Hu, Quanjun Yin, Yong Li</dc:creator>
        <description><![CDATA[
            背景：城市环境中的无人机视觉目标搜索任务面临冗余语义处理、相似目标区分等难题。方法：提出首个城市常见目标自主搜索基准数据集CityAVOS，涵盖2420个任务；提出基于多模态大模型的PRPSearcher方法，构建三种专用地图，采用去噪和IPT提示机制。效果：在CityAVOS上实验表明，PRPSearcher在成功率和搜索效率上超越现有基线，成功率平均提升37.69%，搜索路径长度平均提升28.96%等。
            arXiv:2505.08765v2 Announce Type: replace 
Abstract: Aerial Visual Object Search (AVOS) tasks in urban environments require Unmanned Aerial Vehicles (UAVs) to autonomously search for and identify target objects using visual and textual cues without external guidance. Existing approaches struggle in complex urban environments due to redundant semantic processing, similar object distinction, and the exploration-exploitation dilemma. To bridge this gap and support the AVOS task, we introduce CityAVOS, the first benchmark dataset for autonomous search of common urban objects. This dataset comprises 2,420 tasks across six object categories with varying difficulty levels, enabling comprehensive evaluation of UAV agents' search capabilities. To solve the AVOS tasks, we also propose PRPSearcher (Perception-Reasoning-Planning Searcher), a novel agentic method powered by multi-modal large language models (MLLMs) that mimics human three-tier cognition. Specifically, PRPSearcher constructs three specialized maps: an object-centric dynamic semantic map enhancing spatial perception, a 3D cognitive map based on semantic attraction values for target reasoning, and a 3D uncertainty map for balanced exploration-exploitation search. Also, our approach incorporates a denoising mechanism to mitigate interference from similar objects and utilizes an Inspiration Promote Thought (IPT) prompting mechanism for adaptive action planning. Experimental results on CityAVOS demonstrate that PRPSearcher surpasses existing baselines in both success rate and search efficiency (on average: +37.69% SR, +28.96% SPL, -30.69% MSS, and -46.40% NE). While promising, the performance gap compared to humans highlights the need for better semantic reasoning and spatial exploration capabilities in AVOS tasks. This work establishes a foundation for future advances in embodied target search. Dataset and source code are available at https://anonymous.4open.science/r/CityAVOS-3DF8.
        ]]></description>
    </item>
    <item>
        <title>PSPO*: An Effective Process-supervised Policy Optimization for Reasoning Alignment</title>
        <link>https://arxiv.org/abs/2411.11681</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2411.11681v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiawei Li, Xinyue Liang, Junlong Zhang, Yizhe Yang, Chong Feng, Yang Gao</dc:creator>
        <description><![CDATA[
            背景：过程监督能提升大语言模型推理任务表现，但现有方法不足，导致模型易出现逻辑错误和冗余推理。方法：提出新的过程监督范式PSPO*，明确从奖励模型训练到策略优化的工作流程，强调非线性奖励的重要性；基于此开发PSPO - WRS，考虑推理步骤数确定奖励分数，用调整后的威布尔分布进行非线性奖励塑造。效果：在六个数学推理数据集上，PSPO - WRS始终优于当前主流模型。
            arXiv:2411.11681v3 Announce Type: replace-cross 
Abstract: Process supervision enhances the performance of large language models in reasoning tasks by providing feedback at each step of chain-of-thought reasoning. However, due to the lack of effective process supervision methods, even advanced large language models are prone to logical errors and redundant reasoning. We claim that the effectiveness of process supervision significantly depends on both the accuracy and the length of reasoning chains. Moreover, we identify that these factors exhibit a nonlinear relationship with the overall reward score of the reasoning process. Inspired by these insights, we propose a novel process supervision paradigm, PSPO*, which systematically outlines the workflow from reward model training to policy optimization, and highlights the importance of nonlinear rewards in process supervision. Based on PSPO*, we develop the PSPO-WRS, which considers the number of reasoning steps in determining reward scores and utilizes an adjusted Weibull distribution for nonlinear reward shaping. Experimental results on six mathematical reasoning datasets demonstrate that PSPO-WRS consistently outperforms current mainstream models.
        ]]></description>
    </item>
    <item>
        <title>DPN-GAN: Inducing Periodic Activations in Generative Adversarial Networks for High-Fidelity Audio Synthesis</title>
        <link>https://arxiv.org/abs/2505.09091</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.09091v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zeeshan Ahmad, Shudi Bao, Meng Chen</dc:creator>
        <description><![CDATA[
            背景：现有生成对抗网络（GANs）生成音频时依赖带宽受限的梅尔频谱图，限制音频分辨率，且条件生成时易出现模式崩溃。方法：提出基于可变形周期网络的GAN（DPN - GAN），引入基于核的周期性ReLU激活函数，采用可变形卷积操作的DPN模块进行多分辨率生成，同时用可变形卷积增强判别器。效果：训练了大小两个版本模型，在五个数据集上实验，在分布外和噪声数据上表现出色，优于现有GAN架构，合成音频鲁棒性增强。
            arXiv:2505.09091v1 Announce Type: new 
Abstract: In recent years, generative adversarial networks (GANs) have made significant progress in generating audio sequences. However, these models typically rely on bandwidth-limited mel-spectrograms, which constrain the resolution of generated audio sequences, and lead to mode collapse during conditional generation. To address this issue, we propose Deformable Periodic Network based GAN (DPN-GAN), a novel GAN architecture that incorporates a kernel-based periodic ReLU activation function to induce periodic bias in audio generation. This innovative approach enhances the model's ability to capture and reproduce intricate audio patterns. In particular, our proposed model features a DPN module for multi-resolution generation utilizing deformable convolution operations, allowing for adaptive receptive fields that improve the quality and fidelity of the synthetic audio. Additionally, we enhance the discriminator network using deformable convolution to better distinguish between real and generated samples, further refining the audio quality. We trained two versions of the model: DPN-GAN small (38.67M parameters) and DPN-GAN large (124M parameters). For evaluation, we use five different datasets, covering both speech synthesis and music generation tasks, to demonstrate the efficiency of the DPN-GAN. The experimental results demonstrate that DPN-GAN delivers superior performance on both out-of-distribution and noisy data, showcasing its robustness and adaptability. Trained across various datasets, DPN-GAN outperforms state-of-the-art GAN architectures on standard evaluation metrics, and exhibits increased robustness in synthesized audio.
        ]]></description>
    </item>
    <item>
        <title>Adaptive Noise Resilient Keyword Spotting Using One-Shot Learning</title>
        <link>https://arxiv.org/abs/2505.09304</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.09304v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Luciano Sebastian Martinez-Rau, Quynh Nguyen Phuong Vu, Yuxuan Zhang, Bengt Oelmann, Sebastian Bader</dc:creator>
        <description><![CDATA[
            背景：关键词识别（KWS）是智能设备关键组件，但嵌入式设备上的标准KWS系统在现实环境中性能易下降，且在资源受限设备上部署低延迟的自适应KWS系统有挑战。方法：提出一种低计算量方法，对用于KWS分类的预训练神经网络进行连续噪声自适应，仅需一次学习和一个训练周期。效果：用两个预训练模型和三种真实噪声源在24至 -3 dB信噪比下评估，自适应模型在各场景均优于预训练模型，在信噪比≤18 dB时，准确率提升4.9% - 46.0%。
            arXiv:2505.09304v1 Announce Type: new 
Abstract: Keyword spotting (KWS) is a key component of smart devices, enabling efficient and intuitive audio interaction. However, standard KWS systems deployed on embedded devices often suffer performance degradation under real-world operating conditions. Resilient KWS systems address this issue by enabling dynamic adaptation, with applications such as adding or replacing keywords, adjusting to specific users, and improving noise robustness. However, deploying resilient, standalone KWS systems with low latency on resource-constrained devices remains challenging due to limited memory and computational resources. This study proposes a low computational approach for continuous noise adaptation of pretrained neural networks used for KWS classification, requiring only 1-shot learning and one epoch. The proposed method was assessed using two pretrained models and three real-world noise sources at signal-to-noise ratios (SNRs) ranging from 24 to -3 dB. The adapted models consistently outperformed the pretrained models across all scenarios, especially at SNR $\leq$ 18 dB, achieving accuracy improvements of 4.9% to 46.0%. These results highlight the efficacy of the proposed methodology while being lightweight enough for deployment on resource-constrained devices.
        ]]></description>
    </item>
    <item>
        <title>Omni-R1: Do You Really Need Audio to Fine-Tune Your Audio LLM?</title>
        <link>https://arxiv.org/abs/2505.09439</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.09439v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Andrew Rouditchenko, Saurabhchand Bhati, Edson Araujo, Samuel Thomas, Hilde Kuehne, Rogerio Feris, James Glass</dc:creator>
        <description><![CDATA[
            背景：在音频问答任务中提升多模态大语言模型性能。方法：提出Omni - R1，使用强化学习方法GRPO在音频问答数据集上微调多模态大语言模型Qwen2.5 - Omni。效果：在MMAU基准测试中达到新的最优水平，在Test - mini和Test - full分割中，在声音、音乐、语音及整体平均类别上均取得最高准确率。研究还发现GRPO性能提升多源于文本推理，且在仅文本数据集上无音频微调也能有效提升音频性能。
            arXiv:2505.09439v1 Announce Type: new 
Abstract: We propose Omni-R1 which fine-tunes a recent multi-modal LLM, Qwen2.5-Omni, on an audio question answering dataset with the reinforcement learning method GRPO. This leads to new State-of-the-Art performance on the recent MMAU benchmark. Omni-R1 achieves the highest accuracies on the sounds, music, speech, and overall average categories, both on the Test-mini and Test-full splits. To understand the performance improvement, we tested models both with and without audio and found that much of the performance improvement from GRPO could be attributed to better text-based reasoning. We also made a surprising discovery that fine-tuning without audio on a text-only dataset was effective at improving the audio-based performance.
        ]]></description>
    </item>
    <item>
        <title>Reinforcement Learning Outperforms Supervised Fine-Tuning: A Case Study on Audio Question Answering</title>
        <link>https://arxiv.org/abs/2503.11197</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.11197v4</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Gang Li, Jizhong Liu, Heinrich Dinkel, Yadong Niu, Junbo Zhang, Jian Luan</dc:creator>
        <description><![CDATA[
            背景：强化学习（RL）能提升大语言模型推理能力，且已应用于视觉多模态任务，但音频模态受忽视。方法：针对音频问答（AQA）任务，将群体相对策略优化（GRPO）算法应用于Qwen2 - Audio - 7B - Instruct。效果：在MMAU Test - mini基准测试中达64.5%准确率，仅用38k训练样本时，RL显著优于监督微调。研究还指出GRPO可用于小参数量模型，显式推理对AQA无明显益处，基于RL的方法仍待深入探索。
            arXiv:2503.11197v4 Announce Type: replace 
Abstract: Recently, reinforcement learning (RL) has been shown to greatly enhance the reasoning capabilities of large language models (LLMs), and RL-based approaches have been progressively applied to visual multimodal tasks. However, the audio modality has largely been overlooked in these developments. Thus, we conduct a series of RL explorations in audio understanding and reasoning, specifically focusing on the audio question answering (AQA) task. We leverage the group relative policy optimization (GRPO) algorithm to Qwen2-Audio-7B-Instruct, and our experiments demonstrated state-of-the-art performance on the MMAU Test-mini benchmark, achieving an accuracy rate of 64.5%. The main findings in this technical report are as follows: 1) The GRPO algorithm can be effectively applied to large audio language models (LALMs), even when the model has only 8.2B parameters; 2) With only 38k post-training samples, RL significantly outperforms supervised fine-tuning (SFT), indicating that RL-based approaches can be effective without large datasets; 3) The explicit reasoning process has not shown significant benefits for AQA tasks, and how to efficiently utilize deep thinking remains an open question for further research; 4) LALMs still lag far behind humans auditory-language reasoning, suggesting that the RL-based approaches warrant further exploration. Our project is available at https://github.com/xiaomi-research/r1-aqa and https://huggingface.co/mispeech/r1-aqa.
        ]]></description>
    </item>
    <item>
        <title>Fast Text-to-Audio Generation with Adversarial Post-Training</title>
        <link>https://arxiv.org/abs/2505.08175</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.08175v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zachary Novack, Zach Evans, Zack Zukowski, Josiah Taylor, CJ Carr, Julian Parker, Adnan Al-Sinan, Gian Marco Iodice, Julian McAuley, Taylor Berg-Kirkpatrick, Jordi Pons</dc:creator>
        <description><![CDATA[
            背景：文本到音频系统推理慢，延迟难以满足创意应用需求。方法：提出对抗性相对论对比（ARC）后训练，这是首个非基于蒸馏的扩散/流模型对抗加速算法，将相对论对抗公式扩展到扩散/流后训练，并结合新的对比判别器目标以更好贴合提示，还对Stable Audio Open进行多项优化。效果：在H100上约75ms生成约12s的44.1kHz立体声音频，在移动边缘设备上约7s，是已知最快的文本到音频模型。
            arXiv:2505.08175v2 Announce Type: replace 
Abstract: Text-to-audio systems, while increasingly performant, are slow at inference time, thus making their latency unpractical for many creative applications. We present Adversarial Relativistic-Contrastive (ARC) post-training, the first adversarial acceleration algorithm for diffusion/flow models not based on distillation. While past adversarial post-training methods have struggled to compare against their expensive distillation counterparts, ARC post-training is a simple procedure that (1) extends a recent relativistic adversarial formulation to diffusion/flow post-training and (2) combines it with a novel contrastive discriminator objective to encourage better prompt adherence. We pair ARC post-training with a number optimizations to Stable Audio Open and build a model capable of generating $\approx$12s of 44.1kHz stereo audio in $\approx$75ms on an H100, and $\approx$7s on a mobile edge-device, the fastest text-to-audio model to our knowledge.
        ]]></description>
    </item>
    <item>
        <title>Granite-speech: open-source speech-aware LLMs with strong English ASR capabilities</title>
        <link>https://arxiv.org/abs/2505.08699</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.08699v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>George Saon, Avihu Dekel, Alexander Brooks, Tohru Nagano, Abraham Daniels, Aharon Satt, Ashish Mittal, Brian Kingsbury, David Haws, Edmilson Morais, Gakuto Kurata, Hagai Aronowitz, Ibrahim Ibrahim, Jeff Kuo, Kate Soule, Luis Lastras, Masayuki Suzuki, Ron Hoory, Samuel Thomas, Sashi Novitasari, Takashi Fukuda, Vishal Sunder, Xiaodong Cui, Zvi Kons</dc:creator>
        <description><![CDATA[
            背景：为提升英语自动语音识别（ASR）和自动语音翻译（AST）能力，设计紧凑高效的语音语言模型。方法：在含音频输入和文本目标的开源语料上，对granite - 3.3 - instruct的2B和8B参数变体进行模态对齐训练，包含特定语音组件。效果：在英语ASR上，优于用大量专有数据训练的竞品模型；在英到多种语言的AST中表现相当。模型在HuggingFace开源，可用于科研和商业。 
            arXiv:2505.08699v2 Announce Type: replace 
Abstract: Granite-speech LLMs are compact and efficient speech language models specifically designed for English ASR and automatic speech translation (AST). The models were trained by modality aligning the 2B and 8B parameter variants of granite-3.3-instruct to speech on publicly available open-source corpora containing audio inputs and text targets consisting of either human transcripts for ASR or automatically generated translations for AST. Comprehensive benchmarking shows that on English ASR, which was our primary focus, they outperform several competitors' models that were trained on orders of magnitude more proprietary data, and they keep pace on English-to-X AST for major European languages, Japanese, and Chinese. The speech-specific components are: a conformer acoustic encoder using block attention and self-conditioning trained with connectionist temporal classification, a windowed query-transformer speech modality adapter used to do temporal downsampling of the acoustic embeddings and map them to the LLM text embedding space, and LoRA adapters to further fine-tune the text LLM. Granite-speech-3.3 operates in two modes: in speech mode, it performs ASR and AST by activating the encoder, projector, and LoRA adapters; in text mode, it calls the underlying granite-3.3-instruct model directly (without LoRA), essentially preserving all the text LLM capabilities and safety. Both models are freely available on HuggingFace (https://huggingface.co/ibm-granite/granite-speech-3.3-2b and https://huggingface.co/ibm-granite/granite-speech-3.3-8b) and can be used for both research and commercial purposes under a permissive Apache 2.0 license.
        ]]></description>
    </item>
</channel>
</rss>