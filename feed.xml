<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
<channel>
    <title>arXiv Paper Filter</title>
    <link>https://github.com/None/arxiv_filter</link>
    <description>根据研究兴趣筛选的arXiv论文</description>
    <atom:link href="https://raw.githubusercontent.com/None/arxiv_filter/main/feed.xml" rel="self" type="application/rss+xml" />
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>zh-CN</language>
    <lastBuildDate>Thu, 17 Jul 2025 12:32:02 +0800</lastBuildDate>
    <managingEditor>None@github.com</managingEditor>
    <pubDate>Thu, 17 Jul 2025 12:32:02 +0800</pubDate>
    <skipDays>
        <day>Saturday</day>
        <day>Sunday</day>
    </skipDays>

    <item>
        <title>Reprogramming Vision Foundation Models for Spatio-Temporal Forecasting</title>
        <link>https://arxiv.org/abs/2507.11558</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.11558v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Changlu Chen, Yanbin Liu, Chaoxi Niu, Ling Chen, Tianqing Zhu</dc:creator>
        <description><![CDATA[
            背景：基础模型在自然语言处理和计算机视觉中取得成功，但大语言模型难以对时空相关性建模。方法：提出ST - VFM框架，采用双分支架构，将原始时空输入与辅助时空流输入结合，引入预VFM和后VFM两个重编程阶段，前者嵌入时间上下文，后者实现分支间动态交互。效果：在十个时空数据集上的实验表明，ST - VFM优于现有基线模型，在不同VFM主干上展现出有效性和鲁棒性。
            arXiv:2507.11558v1 Announce Type: new 
Abstract: Foundation models have achieved remarkable success in natural language processing and computer vision, demonstrating strong capabilities in modeling complex patterns. While recent efforts have explored adapting large language models (LLMs) for time-series forecasting, LLMs primarily capture one-dimensional sequential dependencies and struggle to model the richer spatio-temporal (ST) correlations essential for accurate ST forecasting. In this paper, we present \textbf{ST-VFM}, a novel framework that systematically reprograms Vision Foundation Models (VFMs) for general-purpose spatio-temporal forecasting. While VFMs offer powerful spatial priors, two key challenges arise when applying them to ST tasks: (1) the lack of inherent temporal modeling capacity and (2) the modality gap between visual and ST data. To address these, ST-VFM adopts a \emph{dual-branch architecture} that integrates raw ST inputs with auxiliary ST flow inputs, where the flow encodes lightweight temporal difference signals interpretable as dynamic spatial cues. To effectively process these dual-branch inputs, ST-VFM introduces two dedicated reprogramming stages. The \emph{pre-VFM reprogramming} stage applies a Temporal-Aware Token Adapter to embed temporal context and align both branches into VFM-compatible feature spaces. The \emph{post-VFM reprogramming} stage introduces a Bilateral Cross-Prompt Coordination module, enabling dynamic interaction between branches through prompt-based conditioning, thus enriching joint representation learning without modifying the frozen VFM backbone. Extensive experiments on ten spatio-temporal datasets show that ST-VFM outperforms state-of-the-art baselines, demonstrating effectiveness and robustness across VFM backbones (e.g., DINO, CLIP, DEIT) and ablation studies, establishing it as a strong general framework for spatio-temporal forecasting.
        ]]></description>
    </item>
    <item>
        <title>Learning Representations of Event Time Series with Sparse Autoencoders for Anomaly Detection, Similarity Search, and Unsupervised Classification</title>
        <link>https://arxiv.org/abs/2507.11620</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.11620v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Steven Dillmann, Juan Rafael Mart\'inez-Galarza</dc:creator>
        <description><![CDATA[
            背景：事件时间序列在多领域常见，其非结构化和不规则结构使传统技术难以提取有意义模式。方法：提出新颖的二维和三维张量表示法，结合稀疏自动编码器学习有物理意义的潜在表示。效果：该嵌入支持多种下游任务，在X射线天文学真实数据集上验证，能成功捕捉时间和光谱特征，分离不同类别的X射线瞬变，为多领域复杂不规则事件时间序列分析提供灵活、可扩展和通用的解决方案。
            arXiv:2507.11620v1 Announce Type: new 
Abstract: Event time series are sequences of discrete events occurring at irregular time intervals, each associated with a domain-specific observational modality. They are common in domains such as high-energy astrophysics, computational social science, cybersecurity, finance, healthcare, neuroscience, and seismology. Their unstructured and irregular structure poses significant challenges for extracting meaningful patterns and identifying salient phenomena using conventional techniques. We propose novel two- and three-dimensional tensor representations for event time series, coupled with sparse autoencoders that learn physically meaningful latent representations. These embeddings support a variety of downstream tasks, including anomaly detection, similarity-based retrieval, semantic clustering, and unsupervised classification. We demonstrate our approach on a real-world dataset from X-ray astronomy, showing that these representations successfully capture temporal and spectral signatures and isolate diverse classes of X-ray transients. Our framework offers a flexible, scalable, and generalizable solution for analyzing complex, irregular event time series across scientific and industrial domains.
        ]]></description>
    </item>
    <item>
        <title>ExpliCIT-QA: Explainable Code-Based Image Table Question Answering</title>
        <link>https://arxiv.org/abs/2507.11694</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.11694v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Maximiliano Hormaz\'abal Lagos, \'Alvaro Bueno S\'aez, Pedro Alonso Doval, Jorge Alcalde Vesteiro, H\'ector Cerezo-Costas</dc:creator>
        <description><![CDATA[
            背景：现有端到端TableVQA系统存在可解释性不足问题。方法：提出ExpliCIT - QA系统，采用模块化设计，包含多模态表格理解（用思维链方法提取转换表格图像内容）、基于语言的推理（生成自然语言逐步解释）、自动代码生成（根据推理步骤创建脚本并处理错误）、代码执行和自然语言解释。效果：在TableVQA - Bench基准测试中，相比现有基线，该系统在可解释性和透明度上有提升，适用于金融和医疗等需审计结果的敏感领域。
            arXiv:2507.11694v1 Announce Type: new 
Abstract: We present ExpliCIT-QA, a system that extends our previous MRT approach for tabular question answering into a multimodal pipeline capable of handling complex table images and providing explainable answers. ExpliCIT-QA follows a modular design, consisting of: (1) Multimodal Table Understanding, which uses a Chain-of-Thought approach to extract and transform content from table images; (2) Language-based Reasoning, where a step-by-step explanation in natural language is generated to solve the problem; (3) Automatic Code Generation, where Python/Pandas scripts are created based on the reasoning steps, with feedback for handling errors; (4) Code Execution to compute the final answer; and (5) Natural Language Explanation that describes how the answer was computed. The system is built for transparency and auditability: all intermediate outputs, parsed tables, reasoning steps, generated code, and final answers are available for inspection. This strategy works towards closing the explainability gap in end-to-end TableVQA systems. We evaluated ExpliCIT-QA on the TableVQA-Bench benchmark, comparing it with existing baselines. We demonstrated improvements in interpretability and transparency, which open the door for applications in sensitive domains like finance and healthcare where auditing results are critical.
        ]]></description>
    </item>
    <item>
        <title>Subgraph Generation for Generalizing on Out-of-Distribution Links</title>
        <link>https://arxiv.org/abs/2507.11710</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.11710v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jay Revolinsky, Harry Shomer, Jiliang Tang</dc:creator>
        <description><![CDATA[
            背景：图神经网络在链接预测任务表现出色，但依赖同分布样本，图生成模型虽有生成新图能力，应用却局限于特定领域。方法：提出FLEX框架，利用结构条件图生成和自编码器与GNN的对抗协同训练两种机制，确保样本分布间的结构对齐。效果：能提升分布外（OOD）场景下的链接预测性能，且无需专家知识。通过合成和真实OOD实验证明其能力，并分析图数据增强对链接结构的影响。
            arXiv:2507.11710v1 Announce Type: new 
Abstract: Graphs Neural Networks (GNNs) demonstrate high-performance on the link prediction (LP) task. However, these models often rely on all dataset samples being drawn from the same distribution. In addition, graph generative models (GGMs) show a pronounced ability to generate novel output graphs. Despite this, GGM applications remain largely limited to domain-specific tasks. To bridge this gap, we propose FLEX as a GGM framework which leverages two mechanism: (1) structurally-conditioned graph generation, and (2) adversarial co-training between an auto-encoder and GNN. As such, FLEX ensures structural-alignment between sample distributions to enhance link-prediction performance in out-of-distribution (OOD) scenarios. Notably, FLEX does not require expert knowledge to function in different OOD scenarios. Numerous experiments are conducted in synthetic and real-world OOD settings to demonstrate FLEX's performance-enhancing ability, with further analysis for understanding the effects of graph data augmentation on link structures. The source code is available here: https://github.com/revolins/FlexOOD.
        ]]></description>
    </item>
    <item>
        <title>A Graph-in-Graph Learning Framework for Drug-Target Interaction Prediction</title>
        <link>https://arxiv.org/abs/2507.11757</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.11757v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuehua Song, Yong Gao</dc:creator>
        <description><![CDATA[
            准确预测药物-靶点相互作用（DTIs）对药物研发至关重要。现有机器学习方法在整合药物、靶点及其相互作用的多样特征方面存在困难。为此，研究提出一种新框架，结合直推式学习和归纳式学习，充分利用分子层面和药物-靶点相互作用网络层面的特征。框架内的Graph-in-Graph（GiG）模型将药物和靶点分子结构图表示为药物-靶点相互作用图中的元节点。实验表明，GiG模型在各项评估指标上显著优于现有方法。
            arXiv:2507.11757v1 Announce Type: new 
Abstract: Accurately predicting drug-target interactions (DTIs) is pivotal for advancing drug discovery and target validation techniques. While machine learning approaches including those that are based on Graph Neural Networks (GNN) have achieved notable success in DTI prediction, many of them have difficulties in effectively integrating the diverse features of drugs, targets and their interactions. To address this limitation, we introduce a novel framework to take advantage of the power of both transductive learning and inductive learning so that features at molecular level and drug-target interaction network level can be exploited. Within this framework is a GNN-based model called Graph-in-Graph (GiG) that represents graphs of drug and target molecular structures as meta-nodes in a drug-target interaction graph, enabling a detailed exploration of their intricate relationships. To evaluate the proposed model, we have compiled a special benchmark comprising drug SMILES, protein sequences, and their interaction data, which is interesting in its own right. Our experimental results demonstrate that the GiG model significantly outperforms existing approaches across all evaluation metrics, highlighting the benefits of integrating different learning paradigms and interaction data.
        ]]></description>
    </item>
    <item>
        <title>HyperEvent:Learning Cohesive Events for Large-scale Dynamic Link Prediction</title>
        <link>https://arxiv.org/abs/2507.11836</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.11836v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jian Gao, Jianshe Wu, JingYi Ding</dc:creator>
        <description><![CDATA[
            连续时间动态图中的动态链接预测是建模复杂演化系统的基础任务。现有方法难以捕捉复合超事件的结构内聚性。为此提出HyperEvent框架，将动态链接预测重构为超事件识别。该框架核心是用事件相关向量动态构建关联序列，量化查询事件与历史事件的依赖关系，判断能否形成有效超事件以预测查询事件。它在4/5官方数据集上优于现有方法，还引入并行训练算法。在大规模航班数据集上，平均倒数排名提升6.95%，仅用10.17%训练时间。
            arXiv:2507.11836v1 Announce Type: new 
Abstract: Dynamic link prediction in continuous-time dynamic graphs is a fundamental task for modeling evolving complex systems. Existing node-centric and event-centric methods focus on individual interactions or atomic states, failing to capture the structural cohesion of composite hyper-events, groups of causally related events. To address this, we propose HyperEvent, a framework reframing dynamic link prediction as hyper-event recognition. Central to HyperEvent is the dynamic construction of an association sequence using event correlation vectors. These vectors quantify pairwise dependencies between the query event and relevant historical events, thereby characterizing the structural cohesion of a potential hyper-event. The framework predicts the occurrence of the query event by evaluating whether it collectively forms a valid hyper-event with these historical events. Notably, HyperEvent outperforms state-of-the-art methods on 4 out of 5 datasets in the official leaderboard. For scalability, we further introduce an efficient parallel training algorithm that segments large event streams to enable concurrent training. Experiments validate HyperEvent's superior accuracy and efficiency on large-scale graphs. Among which HyperEvent achieves a 6.95% improvement in Mean Reciprocal Rank over state-of-the-art baseline on the large-scale Flight dataset while utilizing only 10.17% of the training time.
        ]]></description>
    </item>
    <item>
        <title>OrdShap: Feature Position Importance for Sequential Black-Box Models</title>
        <link>https://arxiv.org/abs/2507.11855</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.11855v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Davin Hill, Brian L. Hill, Aria Masoomi, Vijay S. Nori, Robert E. Tillman, Jennifer Dy</dc:creator>
        <description><![CDATA[
            背景：序列深度学习模型在处理时间或序列依赖问题时表现出色，但需事后特征归因方法理解其预测。现有技术量化特征重要性时，会混淆特征值和其在输入序列中位置的影响。方法：提出OrdShap，通过量化模型预测对特征位置排列的响应变化，分离这两种影响，并建立其与Sanchez - Bergantiños值的博弈论联系。效果：在健康、自然语言和合成数据集上，能有效捕捉特征值和位置归因，加深对模型行为的理解。
            arXiv:2507.11855v1 Announce Type: new 
Abstract: Sequential deep learning models excel in domains with temporal or sequential dependencies, but their complexity necessitates post-hoc feature attribution methods for understanding their predictions. While existing techniques quantify feature importance, they inherently assume fixed feature ordering - conflating the effects of (1) feature values and (2) their positions within input sequences. To address this gap, we introduce OrdShap, a novel attribution method that disentangles these effects by quantifying how a model's predictions change in response to permuting feature position. We establish a game-theoretic connection between OrdShap and Sanchez-Berganti\~nos values, providing a theoretically grounded approach to position-sensitive attribution. Empirical results from health, natural language, and synthetic datasets highlight OrdShap's effectiveness in capturing feature value and feature position attributions, and provide deeper insight into model behavior.
        ]]></description>
    </item>
    <item>
        <title>A Survey of Deep Learning for Geometry Problem Solving</title>
        <link>https://arxiv.org/abs/2507.11936</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.11936v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jianzhe Ma, Wenxuan Wang, Qin Jin</dc:creator>
        <description><![CDATA[
            几何问题求解是数学推理关键领域，在教育、人工智能数学能力评估等多领域广泛应用。近年来，深度学习尤其是多模态大语言模型发展引发研究热潮。该论文对深度学习在几何问题求解中的应用进行综述，全面总结相关任务、深入回顾学习方法、详细分析评估指标与方法，探讨当前挑战与未来方向，旨在为该领域发展提供参考，还在GitHub创建持续更新的论文列表。
            arXiv:2507.11936v1 Announce Type: new 
Abstract: Geometry problem solving is a key area of mathematical reasoning, which is widely involved in many important fields such as education, mathematical ability assessment of artificial intelligence, and multimodal ability assessment. In recent years, the rapid development of deep learning technology, especially the rise of multimodal large language models, has triggered a widespread research boom. This paper provides a survey of the applications of deep learning in geometry problem solving, including (i) a comprehensive summary of the relevant tasks in geometry problem solving; (ii) a thorough review of related deep learning methods; (iii) a detailed analysis of evaluation metrics and methods; and (iv) a critical discussion of the current challenges and future directions that can be explored. Our goal is to provide a comprehensive and practical reference of deep learning for geometry problem solving to promote further developments in this field. We create a continuously updated list of papers on GitHub: https://github.com/majianz/dl4gps.
        ]]></description>
    </item>
    <item>
        <title>The benefits of query-based KGQA systems for complex and temporal questions in LLM era</title>
        <link>https://arxiv.org/abs/2507.11954</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.11954v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Artem Alekseev, Mikhail Chaichuk, Miron Butko, Alexander Panchenko, Elena Tutubalina, Oleg Somov</dc:creator>
        <description><![CDATA[
            背景：大语言模型在问答方面表现出色，但在多跳推理和处理时间相关问题上仍有困难，基于查询的知识图谱问答（KGQA）是一种模块化替代方案。方法：探索用于WikiData问答的多阶段基于查询的框架，提出多阶段方法，还引入使用思维链（CoT）推理的实体链接和谓词匹配新方法。效果：该框架在具有挑战性的多跳和时间基准测试中提升了性能，证明了其用小语言模型改进多跳和时间问答的潜力。
            arXiv:2507.11954v1 Announce Type: new 
Abstract: Large language models excel in question-answering (QA) yet still struggle with multi-hop reasoning and temporal questions. Query-based knowledge graph QA (KGQA) offers a modular alternative by generating executable queries instead of direct answers. We explore multi-stage query-based framework for WikiData QA, proposing multi-stage approach that enhances performance on challenging multi-hop and temporal benchmarks. Through generalization and rejection studies, we evaluate robustness across multi-hop and temporal QA datasets. Additionally, we introduce a novel entity linking and predicate matching method using CoT reasoning. Our results demonstrate the potential of query-based multi-stage KGQA framework for improving multi-hop and temporal QA with small language models. Code and data: https://github.com/ar2max/NLDB-KGQA-System
        ]]></description>
    </item>
    <item>
        <title>Graph Representations for Reading Comprehension Analysis using Large Language Model and Eye-Tracking Biomarker</title>
        <link>https://arxiv.org/abs/2507.11972</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.11972v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuhong Zhang, Jialu Li, Shilai Yang, Yuchen Xu, Gert Cauwenberghs, Tzyy-Ping Jung</dc:creator>
        <description><![CDATA[
            背景：随着大语言模型发展，有必要对比人类和大模型在不同语境下理解语言的方式。此前研究聚焦单个单词限制了理解深度。方法：本研究用基于大语言模型的智能体将阅读段落中的单词分组为节点和边，形成基于语义和问题导向提示的图文本表示，再比较重要节点和边的眼动注视分布。效果：研究发现大语言模型在图拓扑结构层面的语言理解具有高度一致性，为有效人机协同学习策略提供了见解。
            arXiv:2507.11972v1 Announce Type: new 
Abstract: Reading comprehension is a fundamental skill in human cognitive development. With the advancement of Large Language Models (LLMs), there is a growing need to compare how humans and LLMs understand language across different contexts and apply this understanding to functional tasks such as inference, emotion interpretation, and information retrieval. Our previous work used LLMs and human biomarkers to study the reading comprehension process. The results showed that the biomarkers corresponding to words with high and low relevance to the inference target, as labeled by the LLMs, exhibited distinct patterns, particularly when validated using eye-tracking data. However, focusing solely on individual words limited the depth of understanding, which made the conclusions somewhat simplistic despite their potential significance. This study used an LLM-based AI agent to group words from a reading passage into nodes and edges, forming a graph-based text representation based on semantic meaning and question-oriented prompts. We then compare the distribution of eye fixations on important nodes and edges. Our findings indicate that LLMs exhibit high consistency in language understanding at the level of graph topological structure. These results build on our previous findings and offer insights into effective human-AI co-learning strategies.
        ]]></description>
    </item>
    <item>
        <title>Can LLMs Find Fraudsters? Multi-level LLM Enhanced Graph Fraud Detection</title>
        <link>https://arxiv.org/abs/2507.11997</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.11997v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tairan Huang, Yili Wang</dc:creator>
        <description><![CDATA[
            背景：图欺诈检测受关注，但现有方法忽略原始文本语义信息，且大语言模型与图结构的多模态融合是挑战。方法：提出多级别大语言模型增强的图欺诈检测框架MLED，利用大语言模型从文本中提取外部知识，设计类型级别和关系级别增强器，分别增强欺诈者与良性实体差异及不同关系中欺诈者的重要性。效果：在四个真实数据集上实验表明，MLED作为通用框架应用于现有方法，在图欺诈检测中达最优性能。
            arXiv:2507.11997v1 Announce Type: new 
Abstract: Graph fraud detection has garnered significant attention as Graph Neural Networks (GNNs) have proven effective in modeling complex relationships within multimodal data. However, existing graph fraud detection methods typically use preprocessed node embeddings and predefined graph structures to reveal fraudsters, which ignore the rich semantic cues contained in raw textual information. Although Large Language Models (LLMs) exhibit powerful capabilities in processing textual information, it remains a significant challenge to perform multimodal fusion of processed textual embeddings with graph structures. In this paper, we propose a \textbf{M}ulti-level \textbf{L}LM \textbf{E}nhanced Graph Fraud \textbf{D}etection framework called MLED. In MLED, we utilize LLMs to extract external knowledge from textual information to enhance graph fraud detection methods. To integrate LLMs with graph structure information and enhance the ability to distinguish fraudsters, we design a multi-level LLM enhanced framework including type-level enhancer and relation-level enhancer. One is to enhance the difference between the fraudsters and the benign entities, the other is to enhance the importance of the fraudsters in different relations. The experiments on four real-world datasets show that MLED achieves state-of-the-art performance in graph fraud detection as a generalized framework that can be applied to existing methods.
        ]]></description>
    </item>
    <item>
        <title>Contrastive Cascade Graph Learning for Classifying Real and Synthetic Information Diffusion Patterns</title>
        <link>https://arxiv.org/abs/2507.12063</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.12063v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Naoki Shibao, Sho Tsugawa</dc:creator>
        <description><![CDATA[
            背景：社交媒体上信息传播广泛，为抑制有害内容传播、促进可靠信息扩散，级联图挖掘研究受关注。方法：聚焦级联图挖掘中的级联分类任务，研究对比级联图学习（CCGL）方法在该任务中的有效性。效果：研究发现CCGL在捕捉级联图特定平台和模型的结构模式方面表现出色，显示出其在一系列下游信息扩散分析任务中的潜力。
            arXiv:2507.12063v1 Announce Type: new 
Abstract: A wide variety of information is disseminated through social media, and content that spreads at scale can have tangible effects on the real world. To curb the spread of harmful content and promote the dissemination of reliable information, research on cascade graph mining has attracted increasing attention. A promising approach in this area is Contrastive Cascade Graph Learning (CCGL). One important task in cascade graph mining is cascade classification, which involves categorizing cascade graphs based on their structural characteristics. Although CCGL is expected to be effective for this task, its performance has not yet been thoroughly evaluated. This study aims to investigate the effectiveness of CCGL for cascade classification. Our findings demonstrate the strong performance of CCGL in capturing platform- and model-specific structural patterns in cascade graphs, highlighting its potential for a range of downstream information diffusion analysis tasks.
        ]]></description>
    </item>
    <item>
        <title>Open-Vocabulary Indoor Object Grounding with 3D Hierarchical Scene Graph</title>
        <link>https://arxiv.org/abs/2507.12123</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.12123v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sergey Linok, Gleb Naumov</dc:creator>
        <description><![CDATA[
            背景：为解决室内物体定位问题。方法：提出OVIGo - 3DHSG方法，利用RGB - D帧序列构建三维分层场景图表示室内环境，明确建模各层级空间关系，将分层场景图与大语言模型集成进行多步推理，利用层间和层内连接增强空间上下文理解。效果：在Habitat Matterport 3D语义多楼层场景上，相比现有方法，该方法展现出高效的场景理解和强大的物体定位能力，在需要空间推理和室内环境理解的应用中潜力大。
            arXiv:2507.12123v1 Announce Type: new 
Abstract: We propose OVIGo-3DHSG method - Open-Vocabulary Indoor Grounding of objects using 3D Hierarchical Scene Graph. OVIGo-3DHSG represents an extensive indoor environment over a Hierarchical Scene Graph derived from sequences of RGB-D frames utilizing a set of open-vocabulary foundation models and sensor data processing. The hierarchical representation explicitly models spatial relations across floors, rooms, locations, and objects. To effectively address complex queries involving spatial reference to other objects, we integrate the hierarchical scene graph with a Large Language Model for multistep reasoning. This integration leverages inter-layer (e.g., room-to-object) and intra-layer (e.g., object-to-object) connections, enhancing spatial contextual understanding. We investigate the semantic and geometry accuracy of hierarchical representation on Habitat Matterport 3D Semantic multi-floor scenes. Our approach demonstrates efficient scene comprehension and robust object grounding compared to existing methods. Overall OVIGo-3DHSG demonstrates strong potential for applications requiring spatial reasoning and understanding of indoor environments. Related materials can be found at https://github.com/linukc/OVIGo-3DHSG.
        ]]></description>
    </item>
    <item>
        <title>Infherno: End-to-end Agent-based FHIR Resource Synthesis from Free-form Clinical Notes</title>
        <link>https://arxiv.org/abs/2507.12261</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.12261v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Johann Frei, Nils Feldhus, Lisa Raithel, Roland Roller, Alexander Meyer, Frank Kramer</dc:creator>
        <description><![CDATA[
            背景：HL7 FHIR标准是复杂健康数据互操作性的理想格式，以往将自由形式临床笔记自动转换为结构化FHIR资源的方法存在泛化性和结构一致性问题。方法：提出由大语言模型（LLM）代理、代码执行和医疗术语数据库工具驱动的端到端框架Infherno。效果：该框架符合FHIR文档模式，在从非结构化文本预测FHIR资源方面与人类基线表现相当，支持临床数据集成和机构间互操作性。
            arXiv:2507.12261v1 Announce Type: new 
Abstract: For clinical data integration and healthcare services, the HL7 FHIR standard has established itself as a desirable format for interoperability between complex health data. Previous attempts at automating the translation from free-form clinical notes into structured FHIR resources rely on modular, rule-based systems or LLMs with instruction tuning and constrained decoding. Since they frequently suffer from limited generalizability and structural inconformity, we propose an end-to-end framework powered by LLM agents, code execution, and healthcare terminology database tools to address these issues. Our solution, called Infherno, is designed to adhere to the FHIR document schema and competes well with a human baseline in predicting FHIR resources from unstructured text. The implementation features a front end for custom and synthetic data and both local and proprietary models, supporting clinical data integration processes and interoperability across institutions.
        ]]></description>
    </item>
    <item>
        <title>Thought Purity: Defense Paradigm For Chain-of-Thought Attack</title>
        <link>https://arxiv.org/abs/2507.12314</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.12314v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zihao Xue, Zhen Bi, Long Ma, Zhenlin Hu, Yan Wang, Zhenfang Liu, Qing Sheng, Jie Xiao, Jungang Lou</dc:creator>
        <description><![CDATA[
            背景：强化学习训练的大型推理模型在推理能力上表现出色，但在思维链生成过程中易受安全威胁，如后门提示攻击会破坏核心推理机制。方法：提出思维纯度（TP）防御范式，包含安全优化的数据处理流程、强化学习增强的规则约束和自适应监控指标。效果：建立了针对思维链攻击漏洞的综合防御机制，显著提升了下一代人工智能架构的安全与功能平衡。
            arXiv:2507.12314v1 Announce Type: new 
Abstract: While reinforcement learning-trained Large Reasoning Models (LRMs, e.g., Deepseek-R1) demonstrate advanced reasoning capabilities in the evolving Large Language Models (LLMs) domain, their susceptibility to security threats remains a critical vulnerability. This weakness is particularly evident in Chain-of-Thought (CoT) generation processes, where adversarial methods like backdoor prompt attacks can systematically subvert the model's core reasoning mechanisms. The emerging Chain-of-Thought Attack (CoTA) reveals this vulnerability through exploiting prompt controllability, simultaneously degrading both CoT safety and task performance with low-cost interventions. To address this compounded security-performance vulnerability, we propose Thought Purity (TP): a defense paradigm that systematically strengthens resistance to malicious content while preserving operational efficacy. Our solution achieves this through three synergistic components: (1) a safety-optimized data processing pipeline (2) reinforcement learning-enhanced rule constraints (3) adaptive monitoring metrics. Our approach establishes the first comprehensive defense mechanism against CoTA vulnerabilities in reinforcement learning-aligned reasoning systems, significantly advancing the security-functionality equilibrium for next-generation AI architectures.
        ]]></description>
    </item>
    <item>
        <title>Advancing Retrieval-Augmented Generation for Structured Enterprise and Internal Data</title>
        <link>https://arxiv.org/abs/2507.12425</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.12425v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chandana Cheerla</dc:creator>
        <description><![CDATA[
            背景：企业依赖专有数据决策，大语言模型处理异构数据有局限，传统RAG框架处理结构化和半结构化数据能力不足。方法：提出高级RAG框架，结合混合检索策略，采用语义分块、保留表格结构、量化索引，引入人工反馈和对话记忆。效果：企业数据集实验显示，Precision@5提升15%、Recall@5提升13%、Mean Reciprocal Rank提升16%；定性评估中，忠实度、完整性和相关性得分显著提高。
            arXiv:2507.12425v1 Announce Type: new 
Abstract: Organizations increasingly rely on proprietary enterprise data, including HR records, structured reports, and tabular documents, for critical decision-making. While Large Language Models (LLMs) have strong generative capabilities, they are limited by static pretraining, short context windows, and challenges in processing heterogeneous data formats. Conventional Retrieval-Augmented Generation (RAG) frameworks address some of these gaps but often struggle with structured and semi-structured data.
  This work proposes an advanced RAG framework that combines hybrid retrieval strategies using dense embeddings (all-mpnet-base-v2) and BM25, enhanced by metadata-aware filtering with SpaCy NER and cross-encoder reranking. The framework applies semantic chunking to maintain textual coherence and retains tabular data structures to preserve row-column integrity. Quantized indexing optimizes retrieval efficiency, while human-in-the-loop feedback and conversation memory improve adaptability.
  Experiments on enterprise datasets show notable improvements: Precision@5 increased by 15 percent (90 versus 75), Recall@5 by 13 percent (87 versus 74), and Mean Reciprocal Rank by 16 percent (0.85 versus 0.69). Qualitative evaluations show higher scores in Faithfulness (4.6 versus 3.0), Completeness (4.2 versus 2.5), and Relevance (4.5 versus 3.2) on a 5-point Likert scale. These results demonstrate the framework's effectiveness in delivering accurate, comprehensive, and contextually relevant responses for enterprise tasks. Future work includes extending to multimodal data and integrating agent-based retrieval. The source code will be released at https://github.com/CheerlaChandana/Enterprise-Chatbot
        ]]></description>
    </item>
    <item>
        <title>Can We Predict Alignment Before Models Finish Thinking? Towards Monitoring Misaligned Reasoning Models</title>
        <link>https://arxiv.org/abs/2507.12428</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.12428v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yik Siu Chan, Zheng-Xin Yong, Stephen H. Bach</dc:creator>
        <description><![CDATA[
            背景：开放权重推理语言模型生成思维链提升性能，但引入对齐风险，有害内容会出现在思维链和最终输出中。方法：评估包括人类、大语言模型和文本分类器等监测方法，使用思维链文本或激活值。效果：基于思维链激活值训练的简单线性探针在预测最终响应安全性上显著优于基于文本的方法；该探针在推理完成前就能准确预测，应用于早期思维链片段也有良好表现，适用于不同模型，可实现实时安全监测和早期干预。
            arXiv:2507.12428v1 Announce Type: new 
Abstract: Open-weights reasoning language models generate long chains-of-thought (CoTs) before producing a final response, which improves performance but introduces additional alignment risks, with harmful content often appearing in both the CoTs and the final outputs. In this work, we investigate if we can use CoTs to predict final response misalignment. We evaluate a range of monitoring approaches, including humans, highly-capable large language models, and text classifiers, using either CoT text or activations. First, we find that a simple linear probe trained on CoT activations can significantly outperform all text-based methods in predicting whether a final response will be safe or unsafe. CoT texts are often unfaithful and can mislead humans and classifiers, while model latents (i.e., CoT activations) offer a more reliable predictive signal. Second, the probe makes accurate predictions before reasoning completes, achieving strong performance even when applied to early CoT segments. These findings generalize across model sizes, families, and safety benchmarks, suggesting that lightweight probes could enable real-time safety monitoring and early intervention during generation.
        ]]></description>
    </item>
    <item>
        <title>Let's Think in Two Steps: Mitigating Agreement Bias in MLLMs with Self-Grounded Verification</title>
        <link>https://arxiv.org/abs/2507.11662</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.11662v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Moises Andrade, Joonhyuk Cha, Brandon Ho, Vriksha Srihari, Karmesh Yadav, Zsolt Kira</dc:creator>
        <description><![CDATA[
            在无明确成功标准的领域扩展验证器作用是挑战，多模态大语言模型（MLLMs）是有潜力的解决方案。研究发现MLLMs作为验证器存在一致性偏差问题，即倾向于支持上下文窗口信息。为此提出自基础验证（SGV）方法，分两步操作：先让MLLM检索任务完成的广泛先验知识，再基于此评估候选轨迹。增强后的MLLM验证器准确率和故障检测率最高提升20个点，能实时监督异构代理，超越先前最佳结果48%。
            arXiv:2507.11662v1 Announce Type: cross 
Abstract: Verifiers -- functions assigning rewards to agent behavior -- have been key for AI progress in domains like math and board games. However, extending these gains to domains without clear-cut success criteria (e.g.,computer use) remains a challenge: while humans can recognize suitable outcomes, translating this intuition into scalable rules is non-trivial. Multimodal Large Language Models(MLLMs) emerge as a promising solution, given their world knowledge, human-preference alignment, and reasoning skills. We evaluate MLLMs as verifiers of agent trajectories across web navigation, computer use, and robotic manipulation, and identify a critical limitation: agreement bias, a strong tendency for MLLMs to favor information in their context window, often generating chains of thought to rationalize flawed behavior. This bias is pervasive across models, resilient to test-time scaling, and can impact several methods using MLLMs as evaluators (e.g.,data filtering). Notably, it occurs despite MLLMs showing strong, human-aligned priors on desired behavior. To address this, we propose Self-Grounded Verification (SGV), a lightweight method that enables more effective use of MLLMs' knowledge and reasoning by harnessing their own sampling mechanisms via unconditional and conditional generation. SGV operates in two steps: first, the MLLM is elicited to retrieve broad priors about task completion, independent of the data under evaluation. Then, conditioned on self-generated priors, it reasons over and evaluates a candidate trajectory. Enhanced with SGV, MLLM verifiers show gains of up to 20 points in accuracy and failure detection rates, and can perform real-time supervision of heterogeneous agents, boosting task completion of a GUI specialist in OSWorld, a diffusion policy in robomimic, and a ReAct agent in VisualWebArena -- setting a new state of the art on the benchmark, surpassing the previous best by 48%.
        ]]></description>
    </item>
    <item>
        <title>LLMs are Bayesian, in Expectation, not in Realization</title>
        <link>https://arxiv.org/abs/2507.11768</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.11768v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Leon Chlon, Sarah Rashidi, Zein Khamis, MarcAntonio M. Awada</dc:creator>
        <description><![CDATA[
            背景：大语言模型虽有出色上下文学习能力且被建模为隐式贝叶斯推理，但transformers违背鞅属性，挑战不确定性量化理论基础。方法：理论分析得出四点成果，如位置编码致鞅违背、transformers达信息论最优等，还推导最优思维链长度。效果：在GPT - 3上实证验证部分预测，transformers在20个示例内达理论熵限的99%，框架为提取不确定性估计和优化计算效率提供实用方法。
            arXiv:2507.11768v1 Announce Type: cross 
Abstract: Large language models demonstrate remarkable in-context learning capabilities, adapting to new tasks without parameter updates. While this phenomenon has been successfully modeled as implicit Bayesian inference, recent empirical findings reveal a fundamental contradiction: transformers systematically violate the martingale property, a cornerstone requirement of Bayesian updating on exchangeable data. This violation challenges the theoretical foundations underlying uncertainty quantification in critical applications.
  Our theoretical analysis establishes four key results: (1) positional encodings induce martingale violations of order $\Theta(\log n / n)$; (2) transformers achieve information-theoretic optimality with excess risk $O(n^{-1/2})$ in expectation over orderings; (3) the implicit posterior representation converges to the true Bayesian posterior in the space of sufficient statistics; and (4) we derive the optimal chain-of-thought length as $k^* = \Theta(\sqrt{n}\log(1/\varepsilon))$ with explicit constants, providing a principled approach to reduce inference costs while maintaining performance. Empirical validation on GPT-3 confirms predictions (1)-(3), with transformers reaching 99\% of theoretical entropy limits within 20 examples. Our framework provides practical methods for extracting calibrated uncertainty estimates from position-aware architectures and optimizing computational efficiency in deployment.
        ]]></description>
    </item>
    <item>
        <title>Sparse Autoencoders for Sequential Recommendation Models: Interpretation and Flexible Control</title>
        <link>https://arxiv.org/abs/2507.12202</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.12202v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Anton Klenitskiy, Konstantin Polev, Daria Denisova, Alexey Vasilev, Dmitry Simakov, Gleb Gusev</dc:creator>
        <description><![CDATA[
            当前许多先进的序列推荐模型基于Transformer架构，解释这类黑盒模型是重要研究问题，理解其内部机制对实际应用很关键。近期稀疏自编码器（SAE）被证明是从语言模型提取可解释特征的有效无监督方法。本文将SAE应用于序列推荐领域，发现该方法能成功用于经序列推荐任务训练的Transformer，学习到的方向比原始隐藏状态维度更具可解释性和单语义性，且SAE学习的特征可有效灵活控制模型行为，让用户能根据不同场景调整推荐。
            arXiv:2507.12202v1 Announce Type: cross 
Abstract: Many current state-of-the-art models for sequential recommendations are based on transformer architectures. Interpretation and explanation of such black box models is an important research question, as a better understanding of their internals can help understand, influence, and control their behavior, which is very important in a variety of real-world applications. Recently sparse autoencoders (SAE) have been shown to be a promising unsupervised approach for extracting interpretable features from language models. These autoencoders learn to reconstruct hidden states of the transformer's internal layers from sparse linear combinations of directions in their activation space.
  This paper is focused on the application of SAE to the sequential recommendation domain. We show that this approach can be successfully applied to the transformer trained on a sequential recommendation task: learned directions turn out to be more interpretable and monosemantic than the original hidden state dimensions. Moreover, we demonstrate that the features learned by SAE can be used to effectively and flexibly control the model's behavior, providing end-users with a straightforward method to adjust their recommendations to different custom scenarios and contexts.
        ]]></description>
    </item>
    <item>
        <title>RAGGED: Towards Informed Design of Scalable and Stable RAG Systems</title>
        <link>https://arxiv.org/abs/2403.09040</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2403.09040v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jennifer Hsia, Afreen Shaikh, Zhiruo Wang, Graham Neubig</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）虽能增强语言模型，但效果高度依赖系统配置，不当设置会降低性能。方法：提出RAGGED框架，系统评估不同检索器 - 阅读器配置、检索深度和数据集下的RAG系统。效果：分析表明阅读器对噪声的鲁棒性是RAG稳定性和可扩展性的关键决定因素，不同阅读器对检索深度反应不同。大规模实验显示检索器、重排器和提示影响性能但不改变阅读器主导趋势，该框架为评估RAG系统提供指导。
            arXiv:2403.09040v3 Announce Type: replace 
Abstract: Retrieval-augmented generation (RAG) enhances language models by integrating external knowledge, but its effectiveness is highly dependent on system configuration. Improper retrieval settings can degrade performance, making RAG less reliable than closed-book generation. In this work, we introduce RAGGED, a framework for systematically evaluating RAG systems across diverse retriever-reader configurations, retrieval depths, and datasets. Our analysis reveals that reader robustness to noise is the key determinant of RAG stability and scalability. Some readers benefit from increased retrieval depth, while others degrade due to their sensitivity to distracting content. Through large-scale experiments on open-domain, multi-hop, and specialized-domain datasets, we show that retrievers, rerankers, and prompts influence performance but do not fundamentally alter these reader-driven trends. By providing a principled framework and new metrics to assess RAG stability and scalability, RAGGED enables systematic evaluation of retrieval-augmented generation systems, guiding future research on optimizing retrieval depth and model robustness.
        ]]></description>
    </item>
    <item>
        <title>Towards Understanding Link Predictor Generalizability Under Distribution Shifts</title>
        <link>https://arxiv.org/abs/2406.08788</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2406.08788v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jay Revolinsky, Harry Shomer, Jiliang Tang</dc:creator>
        <description><![CDATA[
            背景：现有的链接预测（LP）模型在基准测试中表现出色，但实际中训练、验证和测试样本分布常不一致，且当前图数据集偏移研究多关注节点和图级任务，忽视链接级任务。方法：提出一种新的分裂策略LPShift，利用结构特性诱导可控的分布偏移。效果：在16种LPShift变体上对SOTA LP模型进行实证评估，结果显示模型性能有显著变化，额外实验表明图结构对当前泛化方法的成功有很大影响。
            arXiv:2406.08788v3 Announce Type: replace 
Abstract: State-of-the-art link prediction (LP) models demonstrate impressive benchmark results. However, popular benchmark datasets often assume that training, validation, and testing samples are representative of the overall dataset distribution. In real-world situations, this assumption is often incorrect; uncontrolled factors lead new dataset samples to come from a different distribution than training samples. Additionally, the majority of recent work with graph dataset shift focuses on node- and graph-level tasks, largely ignoring link-level tasks. To bridge this gap, we introduce a novel splitting strategy, known as LPShift, which utilizes structural properties to induce a controlled distribution shift. We verify LPShift's effect through empirical evaluation of SOTA LP models on 16 LPShift variants of original dataset splits, with results indicating drastic changes to model performance. Additional experiments demonstrate graph structure has a strong influence on the success of current generalization methods. Source Code Available Here: https://github.com/revolins/LPShift
        ]]></description>
    </item>
    <item>
        <title>Bridging the Skeleton-Text Modality Gap: Diffusion-Powered Modality Alignment for Zero-shot Skeleton-based Action Recognition</title>
        <link>https://arxiv.org/abs/2411.10745</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2411.10745v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jeonghyeok Do, Munchurl Kim</dc:creator>
        <description><![CDATA[
            在零样本基于骨架的动作识别（ZSAR）中，将骨架特征与动作标签的文本特征对齐对预测未见动作至关重要，但两类特征的模态差距限制了模型泛化能力。以往方法聚焦直接对齐，效果不佳。本文提出基于扩散的骨架 - 文本对齐框架TDSM，利用扩散模型的交叉对齐能力而非生成能力，将文本特征融入反向扩散过程，形成统一的潜在空间。还引入三元组扩散损失增强判别力。TDSM显著优于现有方法，准确率提升2.36 - 13.05个百分点，在零样本场景下表现出良好的准确性和可扩展性。
            arXiv:2411.10745v4 Announce Type: replace 
Abstract: In zero-shot skeleton-based action recognition (ZSAR), aligning skeleton features with the text features of action labels is essential for accurately predicting unseen actions. ZSAR faces a fundamental challenge in bridging the modality gap between the two-kind features, which severely limits generalization to unseen actions. Previous methods focus on direct alignment between skeleton and text latent spaces, but the modality gaps between these spaces hinder robust generalization learning. Motivated by the success of diffusion models in multi-modal alignment (e.g., text-to-image, text-to-video), we firstly present a diffusion-based skeleton-text alignment framework for ZSAR. Our approach, Triplet Diffusion for Skeleton-Text Matching (TDSM), focuses on cross-alignment power of diffusion models rather than their generative capability. Specifically, TDSM aligns skeleton features with text prompts by incorporating text features into the reverse diffusion process, where skeleton features are denoised under text guidance, forming a unified skeleton-text latent space for robust matching. To enhance discriminative power, we introduce a triplet diffusion (TD) loss that encourages our TDSM to correct skeleton-text matches while pushing them apart for different action classes. Our TDSM significantly outperforms very recent state-of-the-art methods with significantly large margins of 2.36%-point to 13.05%-point, demonstrating superior accuracy and scalability in zero-shot settings through effective skeleton-text matching.
        ]]></description>
    </item>
    <item>
        <title>METIS: Fast Quality-Aware RAG Systems with Configuration Adaptation</title>
        <link>https://arxiv.org/abs/2412.10543</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2412.10543v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Siddhant Ray, Rui Pan, Zhuohan Gu, Kuntai Du, Shaoting Feng, Ganesh Ananthanarayanan, Ravi Netravali, Junchen Jiang</dc:creator>
        <description><![CDATA[
            背景：RAG可让大语言模型借助外部知识生成更好回复，但增加外部知识常以牺牲响应延迟为代价，此前研究难以平衡延迟与质量。方法：提出METIS系统，联合调度查询并调整关键RAG配置，如检索文本块数量和合成方法。效果：在4个流行RAG - QA数据集上，与现有RAG优化方案相比，METIS在不牺牲生成质量的情况下，将生成延迟降低1.64 - 2.54倍。
            arXiv:2412.10543v2 Announce Type: replace 
Abstract: RAG (Retrieval Augmented Generation) allows LLMs (large language models) to generate better responses with external knowledge, but using more external knowledge often improves generation quality at the expense of response delay. Prior work either reduces the response delay (through better scheduling of RAG queries) or strives to maximize quality (which involves tuning the RAG workflow), but they fall short in optimizing the tradeoff between the delay and quality of RAG responses. This paper presents METIS, the first RAG system that jointly schedules queries and adapts the key RAG configurations of each query, such as the number of retrieved text chunks and synthesis methods, in order to balance quality optimization and response delay reduction. Using 4 popular RAG-QA datasets, we show that compared with the state-of-the-art RAG optimization schemes, METIS reduces the generation latency by $1.64-2.54\times$ without sacrificing generation quality.
        ]]></description>
    </item>
    <item>
        <title>Flexible and Efficient Grammar-Constrained Decoding</title>
        <link>https://arxiv.org/abs/2502.05111</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.05111v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kanghee Park, Timothy Zhou, Loris D'Antoni</dc:creator>
        <description><![CDATA[
            背景：大语言模型常需生成符合精确句法规则的结构化输出，语法约束解码（GCD）可保证输出符合规则，但高效实现有挑战，现有算法预处理常见语法需数十分钟。方法：提出新的GCD算法及实现。效果：离线预处理速度比现有方法快17.71倍，同时在线掩码计算效率达当前最优水平。
            arXiv:2502.05111v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) are often asked to generate structured outputs that obey precise syntactic rules, such as code snippets or formatted data. Grammar-constrained decoding (GCD) can guarantee that LLM outputs matches such rules by masking out tokens that will provably lead to outputs that do not belong to a specified context-free grammar (CFG). To guarantee soundness, GCD algorithms have to compute how a given LLM subword tokenizer can align with the tokens used
  by a given context-free grammar and compute token masks based on this information. Doing so efficiently is challenging and existing GCD algorithms require tens of minutes to preprocess common grammars. We present a new GCD algorithm together with an implementation that offers 17.71x faster offline preprocessing than existing approaches while preserving state-of-the-art efficiency in online mask computation.
        ]]></description>
    </item>
    <item>
        <title>BRIDGE: Bootstrapping Text to Control Time-Series Generation via Multi-Agent Iterative Optimization and Diffusion Modeling</title>
        <link>https://arxiv.org/abs/2503.02445</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.02445v5</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hao Li, Yu-Hao Huang, Chang Xu, Viktor Schlegel, Renhe Jiang, Riza Batista-Navarro, Goran Nenadic, Jiang Bian</dc:creator>
        <description><![CDATA[
            时间序列生成（TSG）在多领域有广泛应用，但现有方法在跨领域可控生成方面不足。该文提出用文本引导和改进TSG，引入“文本控制TSG”任务。为解决数据稀缺问题，提出基于大语言模型的多智能体框架合成文本到时间序列数据集，还引入BRIDGE混合文本控制TSG框架结合语义原型与文本描述。该方法在12个数据集中的11个实现了最先进的生成保真度，相比无文本输入生成，在均方误差上可控性提升达12%，平均绝对误差提升6%。
            arXiv:2503.02445v5 Announce Type: replace 
Abstract: Time-series Generation (TSG) is a prominent research area with broad applications in simulations, data augmentation, and counterfactual analysis. While existing methods have shown promise in unconditional single-domain TSG, real-world applications demand for cross-domain approaches capable of controlled generation tailored to domain-specific constraints and instance-level requirements. In this paper, we argue that text can provide semantic insights, domain information and instance-specific temporal patterns, to guide and improve TSG. We introduce ``Text-Controlled TSG'', a task focused on generating realistic time series by incorporating textual descriptions. To address data scarcity in this setting, we propose a novel LLM-based Multi-Agent framework that synthesizes diverse, realistic text-to-TS datasets. Furthermore, we introduce BRIDGE, a hybrid text-controlled TSG framework that integrates semantic prototypes with text description for supporting domain-level guidance. This approach achieves state-of-the-art generation fidelity on 11 of 12 datasets, and improves controllability by up to 12% on MSE and 6% MAE compared to no text input generation, highlighting its potential for generating tailored time-series data.
        ]]></description>
    </item>
    <item>
        <title>AKReF: An argumentative knowledge representation framework for structured argumentation</title>
        <link>https://arxiv.org/abs/2506.00713</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.00713v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Debarati Bhattacharjee, Ashish Anand</dc:creator>
        <description><![CDATA[
            背景：将论证性文本转化为论证知识图（AKG）以助力推理任务。方法：提出论证知识表示框架AKReF，从论证组件和关系的基本注释出发，构建带元数据属性的知识库图丰富信息，应用假言推理形成论证并创建AKG，通过定位推理标记识别推理规则。效果：能识别现有数据集中难以检测的攻击，帮助推理模型学习隐含间接关系，还展示了在复杂分析中的应用。
            arXiv:2506.00713v3 Announce Type: replace 
Abstract: This paper presents a framework to convert argumentative texts into argument knowledge graphs (AKG). The proposed argumentative knowledge representation framework (AKReF) extends the theoretical foundation and enables the AKG to provide a graphical view of the argumentative structure that is easier to understand. Starting with basic annotations of argumentative components (ACs) and argumentative relations (ARs), we enrich the information by constructing a knowledge base (KB) graph with metadata attributes for nodes. Next, we apply modus ponens on premises and inference rules from the KB to form arguments. From these arguments, we create an AKG. The nodes and edges of the AKG have attributes capturing key argumentative features such as the type of premise (e.g., axiom, ordinary premise, assumption), the type of inference rule (e.g., strict, defeasible), preference order over defeasible rules, markers (e.g., "therefore", "however"), and the type of attack (e.g., undercut, rebuttal, undermining). We identify inference rules by locating a specific set of markers, called inference markers (IM). This, in turn, makes it possible to identify undercut attacks previously undetectable in existing datasets. AKG prepares the ground for reasoning tasks, including checking the coherence of arguments and identifying opportunities for revision. For this, it is essential to find indirect relations, many of which are implicit. Our proposed AKG format, with annotated inference rules and modus ponens, helps reasoning models learn the implicit, indirect relations that require inference over arguments and their interconnections. We use an essay from the AAEC dataset to illustrate the framework. We further show its application in complex analyses such as extracting a conflict-free set and a maximal set of admissible arguments.
        ]]></description>
    </item>
    <item>
        <title>Decoder-Hybrid-Decoder Architecture for Efficient Reasoning with Long Generation</title>
        <link>https://arxiv.org/abs/2507.06607</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.06607v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Liliang Ren, Congcong Chen, Haoran Xu, Young Jin Kim, Adam Atkinson, Zheng Zhan, Jiankai Sun, Baolin Peng, Liyuan Liu, Shuohang Wang, Hao Cheng, Jianfeng Gao, Weizhu Chen, Yelong Shen</dc:creator>
        <description><![CDATA[
            背景：现有语言建模中，虽Samba、YOCO等混合架构表现优于Transformers，但未探究状态空间模型（SSM）层间表征共享的效率潜力。方法：引入门控记忆单元（GMU）实现层间高效内存共享，创建解码器 - 混合 - 解码器架构SambaY，在交叉解码器中结合GMU共享自解码器内存读取状态。效果：显著提升解码效率，保持线性预填充时间复杂度，增强长上下文性能。最大模型在推理任务上表现更好，且在vLLM框架下解码吞吐量最高达10倍。
            arXiv:2507.06607v2 Announce Type: replace 
Abstract: Recent advances in language modeling have demonstrated the effectiveness of State Space Models (SSMs) for efficient sequence modeling. While hybrid architectures such as Samba and the decoder-decoder architecture, YOCO, have shown promising performance gains over Transformers, prior works have not investigated the efficiency potential of representation sharing between SSM layers. In this paper, we introduce the Gated Memory Unit (GMU), a simple yet effective mechanism for efficient memory sharing across layers. We apply it to create SambaY, a decoder-hybrid-decoder architecture that incorporates GMUs in the cross-decoder to share memory readout states from a Samba-based self-decoder. SambaY significantly enhances decoding efficiency, preserves linear pre-filling time complexity, and boosts long-context performance, all while eliminating the need for explicit positional encoding. Through extensive scaling experiments, we demonstrate that our model exhibits a significantly lower irreducible loss compared to a strong YOCO baseline, indicating superior performance scalability under large-scale compute regimes. Our largest model enhanced with Differential Attention, Phi4-mini-Flash-Reasoning, achieves significantly better performance than Phi4-mini-Reasoning on reasoning tasks such as Math500, AIME24/25, and GPQA Diamond without any reinforcement learning, while delivering up to 10x higher decoding throughput on 2K-length prompts with 32K generation length under the vLLM inference framework. We release our training codebase on open-source data at https://github.com/microsoft/ArchScale.
        ]]></description>
    </item>
    <item>
        <title>Towards Agentic RAG with Deep Reasoning: A Survey of RAG-Reasoning Systems in LLMs</title>
        <link>https://arxiv.org/abs/2507.09477</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.09477v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yangning Li, Weizhi Zhang, Yuyao Yang, Wei-Chieh Huang, Yaozu Wu, Junyu Luo, Yuanchen Bei, Henry Peng Zou, Xiao Luo, Yusheng Zhao, Chunkit Chan, Yankai Chen, Zhongfen Deng, Yinghui Li, Hai-Tao Zheng, Dongyuan Li, Renhe Jiang, Ming Zhang, Yangqiu Song, Philip S. Yu</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）虽能提升大语言模型事实性，但多步推理能力不足，纯推理方法易产生幻觉或事实错误。方法：从统一的推理 - 检索视角综合两者，先阐述高级推理对RAG各阶段的优化，再说明不同类型的检索知识为复杂推理提供前提和扩展上下文，最后聚焦新兴的协同RAG - 推理框架。效果：能在知识密集型基准测试中达到先进水平，还对方法、数据集等进行分类并指出研究方向。
            arXiv:2507.09477v2 Announce Type: replace 
Abstract: Retrieval-Augmented Generation (RAG) lifts the factuality of Large Language Models (LLMs) by injecting external knowledge, yet it falls short on problems that demand multi-step inference; conversely, purely reasoning-oriented approaches often hallucinate or mis-ground facts. This survey synthesizes both strands under a unified reasoning-retrieval perspective. We first map how advanced reasoning optimizes each stage of RAG (Reasoning-Enhanced RAG). Then, we show how retrieved knowledge of different type supply missing premises and expand context for complex inference (RAG-Enhanced Reasoning). Finally, we spotlight emerging Synergized RAG-Reasoning frameworks, where (agentic) LLMs iteratively interleave search and reasoning to achieve state-of-the-art performance across knowledge-intensive benchmarks. We categorize methods, datasets, and open challenges, and outline research avenues toward deeper RAG-Reasoning systems that are more effective, multimodally-adaptive, trustworthy, and human-centric. The collection is available at https://github.com/DavidZWZ/Awesome-RAG-Reasoning.
        ]]></description>
    </item>
    <item>
        <title>NeuTSFlow: Modeling Continuous Functions Behind Time Series Forecasting</title>
        <link>https://arxiv.org/abs/2507.09888</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.09888v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Huibo Xu, Likang Wu, Xianquan Wang, Haoning Dang, Chun-Wun Cheng, Angelica I Aviles-Rivero, Qi Liu</dc:creator>
        <description><![CDATA[
            时间序列预测是基础任务，但传统方法将数据视为离散序列，忽略其源于连续过程的本质。该研究将预测任务重新定义为学习历史函数族到未来函数族的转换，面临利用离散观测学习连续函数关系及建模转换路径两个挑战。为此提出NeuTSFlow框架，利用神经算子进行流匹配以学习函数族间测度路径，直接建模函数级特征。实验表明，NeuTSFlow在多样预测任务中准确性和鲁棒性更优。
            arXiv:2507.09888v2 Announce Type: replace 
Abstract: Time series forecasting is a fundamental task with broad applications, yet conventional methods often treat data as discrete sequences, overlooking their origin as noisy samples of continuous processes. Crucially, discrete noisy observations cannot uniquely determine a continuous function; instead, they correspond to a family of plausible functions. Mathematically, time series can be viewed as noisy observations of a continuous function family governed by a shared probability measure. Thus, the forecasting task can be framed as learning the transition from the historical function family to the future function family. This reframing introduces two key challenges: (1) How can we leverage discrete historical and future observations to learn the relationships between their underlying continuous functions? (2) How can we model the transition path in function space from the historical function family to the future function family? To address these challenges, we propose NeuTSFlow, a novel framework that leverages Neural Operators to facilitate flow matching for learning path of measure between historical and future function families. By parameterizing the velocity field of the flow in infinite-dimensional function spaces, NeuTSFlow moves beyond traditional methods that focus on dependencies at discrete points, directly modeling function-level features instead. Experiments on diverse forecasting tasks demonstrate NeuTSFlow's superior accuracy and robustness, validating the effectiveness of the function-family perspective.
        ]]></description>
    </item>
    <item>
        <title>Reasoning Strategies in Large Language Models: Can They Follow, Prefer, and Optimize?</title>
        <link>https://arxiv.org/abs/2507.11423</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.11423v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yanjian Zhang, Guillaume Wisniewski, Nadi Tomeh, Thierry Charnois</dc:creator>
        <description><![CDATA[
            背景：人类推理有不同策略，而大语言模型倾向单一策略，限制其在多样推理挑战中的效果。方法：研究提示能否控制大语言模型的推理策略，并评估其对逻辑问题解决的影响，还提出引导模型进行策略选择的方法。效果：实验表明，单一策略不能持续提高准确率，若模型能自适应选择最优策略，性能有望提升，为提升模型推理能力提供新途径。
            arXiv:2507.11423v2 Announce Type: replace 
Abstract: Human reasoning involves different strategies, each suited to specific problems. Prior work shows that large language model (LLMs) tend to favor a single reasoning strategy, potentially limiting their effectiveness in diverse reasoning challenges. In this work, we investigate whether prompting can control LLMs reasoning strategies and assess its impact on logical problem-solving. While our experiments show that no single strategy consistently improves accuracy, performance could be enhanced if models could adaptively choose the optimal strategy. We propose methods to guide LLMs in strategy selection, highlighting new ways to refine their reasoning abilities.
        ]]></description>
    </item>
    <item>
        <title>Data Augmentation in Time Series Forecasting through Inverted Framework</title>
        <link>https://arxiv.org/abs/2507.11439</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.11439v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hongming Tan, Ting Chen, Ruochong Jin, Wai Kin Chan</dc:creator>
        <description><![CDATA[
            背景：iTransformer是流行有效的多变量时间序列（MTS）预测模型，但其倒置框架存在减少时间依赖信息、在变量相关性不显著时引入噪声等局限。方法：提出一种新的数据增强方法DAIF，它是首个专为MTS预测倒置框架设计的实时增强方法，定义倒置序列到序列框架结构，提出频率过滤和交叉变异修补两种策略。效果：在多个数据集和倒置模型上的实验证明了DAIF的有效性。
            arXiv:2507.11439v2 Announce Type: replace 
Abstract: Currently, iTransformer is one of the most popular and effective models for multivariate time series (MTS) forecasting. Thanks to its inverted framework, iTransformer effectively captures multivariate correlation. However, the inverted framework still has some limitations. It diminishes temporal interdependency information, and introduces noise in cases of nonsignificant variable correlation. To address these limitations, we introduce a novel data augmentation method on inverted framework, called DAIF. Unlike previous data augmentation methods, DAIF stands out as the first real-time augmentation specifically designed for the inverted framework in MTS forecasting. We first define the structure of the inverted sequence-to-sequence framework, then propose two different DAIF strategies, Frequency Filtering and Cross-variation Patching to address the existing challenges of the inverted framework. Experiments across multiple datasets and inverted models have demonstrated the effectiveness of our DAIF.
        ]]></description>
    </item>
    <item>
        <title>Multi-view biomedical foundation models for molecule-target and property prediction</title>
        <link>https://arxiv.org/abs/2410.19704</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.19704v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Parthasarathy Suryanarayanan, Yunguang Qiu, Shreyans Sethi, Diwakar Mahajan, Hongyang Li, Yuxin Yang, Elif Eyigoz, Aldo Guzman Saenz, Daniel E. Platt, Timothy H. Rumbell, Kenney Ng, Sanjoy Dey, Myson Burch, Bum Chul Kwon, Pablo Meyer, Feixiong Cheng, Jianying Hu, Joseph A. Morrone</dc:creator>
        <description><![CDATA[
            在生物医学研究中，优质分子表征是基础模型开发的关键。以往研究多聚焦单表征或分子视图，在特定任务上有优劣。本文提出多视图分子嵌入后期融合法（MMELON），在基础模型中整合图、图像和文本视图，还可扩展至其他表征。单视图基础模型在最多2亿个分子数据集上预训练，多视图模型表现稳健，与最高排名单视图性能相当。经超120个任务验证，还用于筛选与阿尔茨海默病相关的GPCR强结合剂，预测结果经结构建模和关键结合基序鉴定验证。
            arXiv:2410.19704v4 Announce Type: replace-cross 
Abstract: Quality molecular representations are key to foundation model development in bio-medical research. Previous efforts have typically focused on a single representation or molecular view, which may have strengths or weaknesses on a given task. We develop Multi-view Molecular Embedding with Late Fusion (MMELON), an approach that integrates graph, image and text views in a foundation model setting and may be readily extended to additional representations. Single-view foundation models are each pre-trained on a dataset of up to 200M molecules. The multi-view model performs robustly, matching the performance of the highest-ranked single-view. It is validated on over 120 tasks, including molecular solubility, ADME properties, and activity against G Protein-Coupled receptors (GPCRs). We identify 33 GPCRs that are related to Alzheimer's disease and employ the multi-view model to select strong binders from a compound screen. Predictions are validated through structure-based modeling and identification of key binding motifs.
        ]]></description>
    </item>
    <item>
        <title>A Survey of Frontiers in LLM Reasoning: Inference Scaling, Learning to Reason, and Agentic Systems</title>
        <link>https://arxiv.org/abs/2504.09037</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09037v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zixuan Ke, Fangkai Jiao, Yifei Ming, Xuan-Phi Nguyen, Austin Xu, Do Xuan Long, Minzhi Li, Chengwei Qin, Peifeng Wang, Silvio Savarese, Caiming Xiong, Shafiq Joty</dc:creator>
        <description><![CDATA[
            推理是重要认知能力，随着大语言模型发展，推理成为区分先进AI与传统模型的关键。该综述从两个维度对现有方法分类：推理达成阶段和推理组件架构。在各维度下从输入、输出层面分析。此分类助于系统理解大语言模型推理发展态势，凸显从推理扩展到推理学习、向智能体工作流转变等趋势。还涵盖多种学习算法及智能体工作流关键设计。
            arXiv:2504.09037v2 Announce Type: replace-cross 
Abstract: Reasoning is a fundamental cognitive process that enables logical inference, problem-solving, and decision-making. With the rapid advancement of large language models (LLMs), reasoning has emerged as a key capability that distinguishes advanced AI systems from conventional models that empower chatbots. In this survey, we categorize existing methods along two orthogonal dimensions: (1) Regimes, which define the stage at which reasoning is achieved (either at inference time or through dedicated training); and (2) Architectures, which determine the components involved in the reasoning process, distinguishing between standalone LLMs and agentic compound systems that incorporate external tools, and multi-agent collaborations. Within each dimension, we analyze two key perspectives: (1) Input level, which focuses on techniques that construct high-quality prompts that the LLM condition on; and (2) Output level, which methods that refine multiple sampled candidates to enhance reasoning quality. This categorization provides a systematic understanding of the evolving landscape of LLM reasoning, highlighting emerging trends such as the shift from inference-scaling to learning-to-reason (e.g., DeepSeek-R1), and the transition to agentic workflows (e.g., OpenAI Deep Research, Manus Agent). Additionally, we cover a broad spectrum of learning algorithms, from supervised fine-tuning to reinforcement learning such as PPO and GRPO, and the training of reasoners and verifiers. We also examine key designs of agentic workflows, from established patterns like generator-evaluator and LLM debate to recent innovations. ...
        ]]></description>
    </item>
    <item>
        <title>Lost in Transmission: When and Why LLMs Fail to Reason Globally</title>
        <link>https://arxiv.org/abs/2505.08140</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.08140v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tobias Schnabel, Kiran Tomlinson, Adith Swaminathan, Jennifer Neville</dc:creator>
        <description><![CDATA[
            背景：基于Transformer的大语言模型在处理需对大量输入进行复杂推理的任务时仍存在困难。方法：引入有界注意力前缀预言机（BAPO）模型，以模拟大语言模型内部通信机制注意力头的带宽限制，定义BAPO难问题。实验验证理论预测，并证明思维链可将BAPO难问题转化为易问题。效果：为大语言模型的关键失败提供合理解释，为缓解带宽限制的架构和推理方法指明方向。
            arXiv:2505.08140v3 Announce Type: replace-cross 
Abstract: Despite their many successes, transformer-based large language models (LLMs) continue to struggle with tasks that require complex reasoning over large parts of their input. We argue that these failures arise due to capacity limits on the accurate flow of information within LLMs. To formalize this issue, we introduce the bounded attention prefix oracle (BAPO) model, a new computational framework that models bandwidth constraints on attention heads, the mechanism for internal communication in LLMs. We show that several important reasoning problems like graph reachability require high communication bandwidth for BAPOs to solve; we call these problems BAPO-hard. Our experiments corroborate our theoretical predictions: GPT-4o, Claude, and Gemini succeed on BAPO-easy tasks and fail even on relatively small BAPO-hard tasks. BAPOs also reveal another benefit of chain of thought (CoT): we prove that breaking down a task using CoT can turn any BAPO-hard problem into a BAPO-easy one. Our results offer principled explanations for key LLM failures and suggest directions for architectures and inference methods that mitigate bandwidth limits.
        ]]></description>
    </item>
    <item>
        <title>GeoChain: Multimodal Chain-of-Thought for Geographic Reasoning</title>
        <link>https://arxiv.org/abs/2506.00785</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.00785v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sahiti Yerramilli, Nilay Pande, Rynaa Grover, Jayant Sravan Tamarapalli</dc:creator>
        <description><![CDATA[
            该论文背景是缺乏评估多模态大语言模型地理逐步推理能力的基准。为此提出GeoChain基准，利用146万张街道图像，为每张图像配备21步思维链问题序列，涵盖视觉、空间等四类推理。图像还增加语义分割和视觉定位分数。对GPT - 4.1等模型在2088张图像子集上测试发现，模型在视觉定位、推理和准确本地化上存在不足。GeoChain为提升多模态大模型地理推理能力提供了有效诊断方法。
            arXiv:2506.00785v2 Announce Type: replace-cross 
Abstract: This paper introduces GeoChain, a large-scale benchmark for evaluating step-by-step geographic reasoning in multimodal large language models (MLLMs). Leveraging 1.46 million Mapillary street-level images, GeoChain pairs each image with a 21-step chain-of-thought (CoT) question sequence (over 30 million Q&amp;A pairs). These sequences guide models from coarse attributes to fine-grained localization across four reasoning categories - visual, spatial, cultural, and precise geolocation - annotated by difficulty. Images are also enriched with semantic segmentation (150 classes) and a visual locatability score. Our benchmarking of contemporary MLLMs (GPT-4.1 variants, Claude 3.7, Gemini 2.5 variants) on a diverse 2,088-image subset reveals consistent challenges: models frequently exhibit weaknesses in visual grounding, display erratic reasoning, and struggle to achieve accurate localization, especially as the reasoning complexity escalates. GeoChain offers a robust diagnostic methodology, critical for fostering significant advancements in complex geographic reasoning within MLLMs.
        ]]></description>
    </item>
    <item>
        <title>Stereo Sound Event Localization and Detection with Onscreen/offscreen Classification</title>
        <link>https://arxiv.org/abs/2507.12042</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.12042v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kazuki Shimada, Archontis Politis, Iran R. Roman, Parthasaarathy Sudarsanam, David Diaz-Guerra, Ruchi Pandey, Kengo Uchida, Yuichiro Koyama, Naoya Takahashi, Takashi Shibuya, Shusuke Takahashi, Tuomas Virtanen, Yuki Mitsufuji</dc:creator>
        <description><![CDATA[
            本文聚焦DCASE2025挑战赛任务3中声音事件定位与检测（SELD）。以往采用四通道音频格式，今年则研究立体声音频数据的SELD，使研究场景更常见。因立体声数据存在角度模糊性，任务聚焦方位平面的到达方向估计和距离估计。挑战赛分纯音频和视听两个赛道，视听赛道新增屏幕内外事件分类子任务。为此引入DCASE2025任务3立体声SELD数据集，设计了能处理立体声和视频帧的基线系统，修改评估指标引入屏幕内外准确率指标。实验显示，基线系统处理立体声数据表现良好。
            arXiv:2507.12042v1 Announce Type: new 
Abstract: This paper presents the objective, dataset, baseline, and metrics of Task 3 of the DCASE2025 Challenge on sound event localization and detection (SELD). In previous editions, the challenge used four-channel audio formats of first-order Ambisonics (FOA) and microphone array. In contrast, this year's challenge investigates SELD with stereo audio data (termed stereo SELD). This change shifts the focus from more specialized 360{\deg} audio and audiovisual scene analysis to more commonplace audio and media scenarios with limited field-of-view (FOV). Due to inherent angular ambiguities in stereo audio data, the task focuses on direction-of-arrival (DOA) estimation in the azimuth plane (left-right axis) along with distance estimation. The challenge remains divided into two tracks: audio-only and audiovisual, with the audiovisual track introducing a new sub-task of onscreen/offscreen event classification necessitated by the limited FOV. This challenge introduces the DCASE2025 Task3 Stereo SELD Dataset, whose stereo audio and perspective video clips are sampled and converted from the STARSS23 recordings. The baseline system is designed to process stereo audio and corresponding video frames as inputs. In addition to the typical SELD event classification and localization, it integrates onscreen/offscreen classification for the audiovisual track. The evaluation metrics have been modified to introduce an onscreen/offscreen accuracy metric, which assesses the models' ability to identify which sound sources are onscreen. In the experimental evaluation, the baseline system performs reasonably well with the stereo audio data.
        ]]></description>
    </item>
    <item>
        <title>Room Impulse Response Generation Conditioned on Acoustic Parameters</title>
        <link>https://arxiv.org/abs/2507.12136</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.12136v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Silvia Arellano, Chunghsin Yeh, Gautam Bhattacharya, Daniel Arteaga</dc:creator>
        <description><![CDATA[
            这是一篇关于音频生成的论文。现有基于房间物理描述生成房间脉冲响应（RIR）的方法，因依赖几何信息，在房间布局未知等场景下受限。本文提出直接基于一组RIR声学参数生成RIR的策略，能更灵活地实现感知驱动的RIR生成。研究探索了自回归和非自回归生成模型，选用四个模型评估。经主客观评估，所提模型表现与现有最优方法相当或更优，其中MaskGIT模型性能最佳。
            arXiv:2507.12136v1 Announce Type: new 
Abstract: The generation of room impulse responses (RIRs) using deep neural networks has attracted growing research interest due to its applications in virtual and augmented reality, audio postproduction, and related fields. Most existing approaches condition generative models on physical descriptions of a room, such as its size, shape, and surface materials. However, this reliance on geometric information limits their usability in scenarios where the room layout is unknown or when perceptual realism (how a space sounds to a listener) is more important than strict physical accuracy. In this study, we propose an alternative strategy: conditioning RIR generation directly on a set of RIR acoustic parameters. These parameters include various measures of reverberation time and direct sound to reverberation ratio, both broadband and bandwise. By specifying how the space should sound instead of how it should look, our method enables more flexible and perceptually driven RIR generation. We explore both autoregressive and non-autoregressive generative models operating in the Descript Audio Codec domain, using either discrete token sequences or continuous embeddings. Specifically, we have selected four models to evaluate: an autoregressive transformer, the MaskGIT model, a flow matching model, and a classifier-based approach. Objective and subjective evaluations are performed to compare these methods with state-of-the-art alternatives. Results show that the proposed models match or outperform state-of-the-art alternatives, with the MaskGIT model achieving the best performance.
        ]]></description>
    </item>
    <item>
        <title>Quantize More, Lose Less: Autoregressive Generation from Residually Quantized Speech Representations</title>
        <link>https://arxiv.org/abs/2507.12197</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.12197v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yichen Han, Xiaoyang Hao, Keming Chen, Weibo Xiong, Jun He, Ruonan Zhang, Junjie Cao, Yue Liu, Bowen Li, Dongrui Zhang, Hui Xia, Huilei Fu, Kai Jia, Kaixuan Guo, Mingli Jin, Qingyun Meng, Ruidong Ma, Ruiqian Fang, Shaotong Guo, Xuhui Li, Yang Xiang, Ying Zhang, Yulong Liu, Yunfeng Li, Yuyi Zhang, Yuze Zhou, Zhen Wang, Zhaowen Chen</dc:creator>
        <description><![CDATA[
            文本到语音（TTS）合成在离散建模范式下有新进展，但现有自回归方法多依赖单码本表示，信息损失大，难以恢复细粒度细节。为此提出QTTS框架，基于新音频编解码器QDAC。QDAC通过将基于ASR的自回归网络与GAN进行端到端训练，实现语义特征解缠。QTTS采用分层并行架构和延迟多头方法对离散码进行建模。实验表明，该框架合成质量更高，能更好保留表达内容，多码本建模是高保真音频生成的有前景方向。
            arXiv:2507.12197v1 Announce Type: new 
Abstract: Text-to-speech (TTS) synthesis has seen renewed progress under the discrete modeling paradigm. Existing autoregressive approaches often rely on single-codebook representations, which suffer from significant information loss. Even with post-hoc refinement techniques such as flow matching, these methods fail to recover fine-grained details (e.g., prosodic nuances, speaker-specific timbres), especially in challenging scenarios like singing voice or music synthesis. We propose QTTS, a novel TTS framework built upon our new audio codec, QDAC. The core innovation of QDAC lies in its end-to-end training of an ASR-based auto-regressive network with a GAN, which achieves superior semantic feature disentanglement for scalable, near-lossless compression. QTTS models these discrete codes using two innovative strategies: the Hierarchical Parallel architecture, which uses a dual-AR structure to model inter-codebook dependencies for higher-quality synthesis, and the Delay Multihead approach, which employs parallelized prediction with a fixed delay to accelerate inference speed. Our experiments demonstrate that the proposed framework achieves higher synthesis quality and better preserves expressive content compared to baseline. This suggests that scaling up compression via multi-codebook modeling is a promising direction for high-fidelity, general-purpose speech and audio generation.
        ]]></description>
    </item>
    <item>
        <title>Language-Guided Contrastive Audio-Visual Masked Autoencoder with Automatically Generated Audio-Visual-Text Triplets from Videos</title>
        <link>https://arxiv.org/abs/2507.11967</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.11967v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuchi Ishikawa, Shota Nakada, Hokuto Munakata, Kazuhiro Saito, Tatsuya Komatsu, Yoshimitsu Aoki</dc:creator>
        <description><![CDATA[
            这是一篇关于提升视听表征学习的论文。背景是需要更好的视听表征学习方法。方法上，提出语言引导的对比视听掩码自编码器（LG - CAV - MAE），将预训练文本编码器集成到对比视听掩码自编码器中，还引入自动方法从无标签视频生成视听文本三元组，先利用图像字幕模型生成帧级字幕，再用基于CLAP的过滤确保音频与字幕强对齐。效果上，在视听检索和分类任务中显著优于现有方法，检索任务的recall@10提升达5.6%，分类任务提升3.2%。
            arXiv:2507.11967v1 Announce Type: cross 
Abstract: In this paper, we propose Language-Guided Contrastive Audio-Visual Masked Autoencoders (LG-CAV-MAE) to improve audio-visual representation learning. LG-CAV-MAE integrates a pretrained text encoder into contrastive audio-visual masked autoencoders, enabling the model to learn across audio, visual and text modalities. To train LG-CAV-MAE, we introduce an automatic method to generate audio-visual-text triplets from unlabeled videos. We first generate frame-level captions using an image captioning model and then apply CLAP-based filtering to ensure strong alignment between audio and captions. This approach yields high-quality audio-visual-text triplets without requiring manual annotations. We evaluate LG-CAV-MAE on audio-visual retrieval tasks, as well as an audio-visual classification task. Our method significantly outperforms existing approaches, achieving up to a 5.6% improvement in recall@10 for retrieval tasks and a 3.2% improvement for the classification task.
        ]]></description>
    </item>
    <item>
        <title>Epic-Sounds: A Large-scale Dataset of Actions That Sound</title>
        <link>https://arxiv.org/abs/2302.00646</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2302.00646v3</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jaesung Huh, Jacob Chalk, Evangelos Kazakos, Dima Damen, Andrew Zisserman</dc:creator>
        <description><![CDATA[
            本文背景是缺乏大规模音频标注数据集。方法上，提出注释流程，标注者对音频片段标注并描述发声动作，将描述分组归类，对涉及物体碰撞的动作收集物体材料注释并从视频验证。该研究构建了EPIC - SOUNDS数据集，含78.4k分类音频事件和动作片段、39.2k未分类片段。在数据集上训练评估了音频识别和检测模型，还对音频事件时间重叠等进行分析，为音频分类研究提供了新资源。
            arXiv:2302.00646v3 Announce Type: replace 
Abstract: We introduce EPIC-SOUNDS, a large-scale dataset of audio annotations capturing temporal extents and class labels within the audio stream of the egocentric videos. We propose an annotation pipeline where annotators temporally label distinguishable audio segments and describe the action that could have caused this sound. We identify actions that can be discriminated purely from audio, through grouping these free-form descriptions of audio into classes. For actions that involve objects colliding, we collect human annotations of the materials of these objects (e.g. a glass object being placed on a wooden surface), which we verify from video, discarding ambiguities. Overall, EPIC-SOUNDS includes 78.4k categorised segments of audible events and actions, distributed across 44 classes as well as 39.2k non-categorised segments. We train and evaluate state-of-the-art audio recognition and detection models on our dataset, for both audio-only and audio-visual methods. We also conduct analysis on: the temporal overlap between audio events, the temporal and label correlations between audio and visual modalities, the ambiguities in annotating materials from audio-only input, the importance of audio-only labels and the limitations of current models to understand actions that sound.
        ]]></description>
    </item>
    <item>
        <title>Diffused Responsibility: Analyzing the Energy Consumption of Generative Text-to-Audio Diffusion Models</title>
        <link>https://arxiv.org/abs/2505.07615</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.07615v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Riccardo Passoni, Francesca Ronchini, Luca Comanducci, Romain Serizel, Fabio Antonacci</dc:creator>
        <description><![CDATA[
            这是一篇关于文本到音频生成模型能耗分析的论文。背景是文本到音频模型计算需求高，能耗及环境影响受关注。方法是分析7种基于扩散的文本到音频生成模型的能耗，评估生成参数变化对推理时能耗的影响，通过帕累托最优解确定音频质量和能耗间的最佳平衡。效果是揭示了性能与环境影响间的权衡关系，有助于开发更高效的音频生成模型。
            arXiv:2505.07615v2 Announce Type: replace 
Abstract: Text-to-audio models have recently emerged as a powerful technology for generating sound from textual descriptions. However, their high computational demands raise concerns about energy consumption and environmental impact. In this paper, we conduct an analysis of the energy usage of 7 state-of-the-art text-to-audio diffusion-based generative models, evaluating to what extent variations in generation parameters affect energy consumption at inference time. We also aim to identify an optimal balance between audio quality and energy consumption by considering Pareto-optimal solutions across all selected models. Our findings provide insights into the trade-offs between performance and environmental impact, contributing to the development of more efficient generative audio models.
        ]]></description>
    </item>
    <item>
        <title>Optimal Scalogram for Computational Complexity Reduction in Acoustic Recognition Using Deep Learning</title>
        <link>https://arxiv.org/abs/2505.13017</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13017v4</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Dang Thoai Phan, Tuan Anh Huynh, Van Tuan Pham, Cao Minh Tran, Van Thuan Mai, Ngoc Quy Tran</dc:creator>
        <description><![CDATA[
            这是一篇关于降低声学识别计算复杂度的论文。背景是连续小波变换（CWT）用于卷积神经网络（CNN）声学识别时计算成本高，导致研究者倾向使用短时傅里叶变换（STFT）。方法是通过优化小波核长度和输出尺度图的跳跃大小来降低CWT计算复杂度。效果是该方法能显著降低计算成本，且在声学识别任务中保持训练模型的鲁棒性能。
            arXiv:2505.13017v4 Announce Type: replace 
Abstract: The Continuous Wavelet Transform (CWT) is an effective tool for feature extraction in acoustic recognition using Convolutional Neural Networks (CNNs), particularly when applied to non-stationary audio. However, its high computational cost poses a significant challenge, often leading researchers to prefer alternative methods such as the Short-Time Fourier Transform (STFT). To address this issue, this paper proposes a method to reduce the computational complexity of CWT by optimizing the length of the wavelet kernel and the hop size of the output scalogram. Experimental results demonstrate that the proposed approach significantly reduces computational cost while maintaining the robust performance of the trained model in acoustic recognition tasks.
        ]]></description>
    </item>
    <item>
        <title>Learning Perceptually Relevant Temporal Envelope Morphing</title>
        <link>https://arxiv.org/abs/2506.01588</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.01588v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Satvik Dixit, Sungjoon Park, Chris Donahue, Laurie M. Heller</dc:creator>
        <description><![CDATA[
            这是一篇关于音频生成的论文。当前生成式音频系统中的时间包络变形问题缺乏感知基础，现有技术在输入声音时间结构不同时难以生成中间时间包络，结果不自然。该论文提出带感知引导的包络变形学习流程：先通过人类听力研究得出感知原则，再合成编码这些原则的大规模数据集，最后训练机器学习模型生成感知中间变形。实验表明，该方法在生成时间中间变形方面优于现有方法。
            arXiv:2506.01588v2 Announce Type: replace 
Abstract: Temporal envelope morphing, the process of interpolating between the amplitude dynamics of two audio signals, is an emerging problem in generative audio systems that lacks sufficient perceptual grounding. Morphing of temporal envelopes in a perceptually intuitive manner should enable new methods for sound blending in creative media and for probing perceptual organization in psychoacoustics. However, existing audio morphing techniques often fail to produce intermediate temporal envelopes when input sounds have distinct temporal structures; many morphers effectively overlay both temporal structures, leading to perceptually unnatural results. In this paper, we introduce a novel workflow for learning envelope morphing with perceptual guidance: we first derive perceptually grounded morphing principles through human listening studies, then synthesize large-scale datasets encoding these principles, and finally train machine learning models to create perceptually intermediate morphs. Specifically, we present: (1) perceptual principles that guide envelope morphing, derived from our listening studies, (2) a supervised framework to learn these principles, (3) an autoencoder that learns to compress temporal envelope structures into latent representations, and (4) benchmarks for evaluating audio envelope morphs, using both synthetic and naturalistic data, and show that our approach outperforms existing methods in producing temporally intermediate morphs. All code, models, and datasets will be made publicly available upon publication.
        ]]></description>
    </item>
    <item>
        <title>Efficient and Direct Duplex Modeling for Speech-to-Speech Language Model</title>
        <link>https://arxiv.org/abs/2505.15670</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.15670v3</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ke Hu, Ehsan Hosseini-Asl, Chen Chen, Edresson Casanova, Subhankar Ghosh, Piotr \.Zelasko, Zhehuai Chen, Jason Li, Jagadeesh Balam, Boris Ginsburg</dc:creator>
        <description><![CDATA[
            背景：口语对话是人机交互的直观形式，但现有语音语言模型多为轮替式交流，缺乏实时适应性。方法：提出新型双向语音到语音（S2S）架构，具有连续用户输入和编解码代理输出，采用预训练流式编码器处理用户输入，分别构建代理和用户建模架构。效果：代理语音编解码微调效果更好，比特率减半至0.6 kbps，在推理、轮替和插入能力上优于以往双向模型，所需语音数据大幅减少，还公开了训练和推理代码。
            arXiv:2505.15670v3 Announce Type: replace-cross 
Abstract: Spoken dialogue is an intuitive form of human-computer interaction, yet current speech language models often remain constrained to turn-based exchanges, lacking real-time adaptability such as user barge-in. We propose a novel duplex speech to speech (S2S) architecture featuring continuous user inputs and codec agent outputs with channel fusion that directly models simultaneous user and agent streams. Using a pretrained streaming encoder for user input enables the first duplex S2S model without requiring speech pretrain. Separate architectures for agent and user modeling facilitate codec fine-tuning for better agent voices and halve the bitrate (0.6 kbps) compared to previous works. Experimental results show that the proposed model outperforms previous duplex models in reasoning, turn-taking, and barge-in abilities. The model requires significantly less speech data, as speech pretrain is skipped, which markedly simplifies the process of building a duplex S2S model from any LLMs. Finally, it is the first openly available duplex S2S model with training and inference code to foster reproducibility.
        ]]></description>
    </item>
</channel>
</rss>