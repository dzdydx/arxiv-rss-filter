<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
<channel>
    <title>arXiv Paper Filter</title>
    <link>https://github.com/None/arxiv_filter</link>
    <description>根据研究兴趣筛选的arXiv论文</description>
    <atom:link href="https://raw.githubusercontent.com/None/arxiv_filter/main/feed.xml" rel="self" type="application/rss+xml" />
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>zh-CN</language>
    <lastBuildDate>Mon, 26 May 2025 12:15:14 +0800</lastBuildDate>
    <managingEditor>None@github.com</managingEditor>
    <pubDate>Mon, 26 May 2025 12:15:14 +0800</pubDate>
    <skipDays>
        <day>Saturday</day>
        <day>Sunday</day>
    </skipDays>

    <item>
        <title>Generalizing Large Language Model Usability Across Resource-Constrained</title>
        <link>https://arxiv.org/abs/2505.17040</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17040v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yun-Da Tsai</dc:creator>
        <description><![CDATA[
            背景：大语言模型在自然语言任务取得成功，现努力将其能力拓展到多模态和资源受限环境，但现有方法泛化性有限。方法：提出以文本为中心的对齐框架，让模型通过自然语言接口集成多模态；用对抗提示技术增强鲁棒性；研究推理时优化策略；为低资源领域设计合成数据管道和推理模型。效果：无需重新训练即可适应新模态，在Verilog代码生成等低资源领域用最少数据达最优性能。
            arXiv:2505.17040v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have achieved remarkable success across a wide range of natural language tasks, and recent efforts have sought to extend their capabilities to multimodal domains and resource-constrained environments. However, existing approaches often rely on costly supervised fine-tuning or assume fixed training conditions, limiting their generalization when facing unseen modalities, limited data, or restricted compute resources. This dissertation presents a systematic study toward generalizing LLM usability under real-world constraints. First, it introduces a robust text-centric alignment framework that enables LLMs to seamlessly integrate diverse modalities-including text, images, tables, and any modalities - via natural language interfaces. This approach supports in-context adaptation to unseen or dynamically changing modalities without requiring retraining. To enhance robustness against noisy and missing modalities, an adversarial prompting technique is proposed, generating semantically challenging perturbations at the prompt level to stress-test model reliability. Beyond multimodal setting, the dissertation investigates inference-time optimization strategies for LLMs, leveraging prompt search and uncertainty quantification to improve performance without additional model training. This perspective offers an efficient alternative to scaling model parameters or retraining from scratch. Additionally, the work addresses low-resource domains such as Verilog code generation by designing correct-by-construction synthetic data pipelines and logic-enhanced reasoning models, achieving state-of-the-art performance with minimal data. Together, these contributions form a unified effort to enhance the adaptability, scalability, and efficiency of large language models under practical constraints.
        ]]></description>
    </item>
    <item>
        <title>VLM-KG: Multimodal Radiology Knowledge Graph Generation</title>
        <link>https://arxiv.org/abs/2505.17042</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17042v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Abdullah Abdullah, Seong Tae Kim</dc:creator>
        <description><![CDATA[
            背景：视觉语言模型在自然语言生成方面表现出色，知识图谱对放射学很重要，但生成特定放射学知识图谱面临专业语言和数据有限等挑战，现有方案多为单模态且处理长数据能力有限。方法：提出基于多模态视觉语言模型的放射学知识图谱生成框架。效果：该方法优于先前方法，是首个放射学知识图谱生成的多模态解决方案。
            arXiv:2505.17042v1 Announce Type: new 
Abstract: Vision-Language Models (VLMs) have demonstrated remarkable success in natural language generation, excelling at instruction following and structured output generation. Knowledge graphs play a crucial role in radiology, serving as valuable sources of factual information and enhancing various downstream tasks. However, generating radiology-specific knowledge graphs presents significant challenges due to the specialized language of radiology reports and the limited availability of domain-specific data. Existing solutions are predominantly unimodal, meaning they generate knowledge graphs only from radiology reports while excluding radiographic images. Additionally, they struggle with long-form radiology data due to limited context length. To address these limitations, we propose a novel multimodal VLM-based framework for knowledge graph generation in radiology. Our approach outperforms previous methods and introduces the first multimodal solution for radiology knowledge graph generation.
        ]]></description>
    </item>
    <item>
        <title>Towards Robust Evaluation of STEM Education: Leveraging MLLMs in Project-Based Learning</title>
        <link>https://arxiv.org/abs/2505.17050</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17050v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yanhao Jia, Xinyi Wu, Qinglin Zhang, Yiran Qin, Luwei Xiao, Shuai Zhao</dc:creator>
        <description><![CDATA[
            背景：基于项目的学习（PBL）涉及多模态数据，多模态大语言模型（MLLMs）用于教育评估有潜力，但现有基准存在不足，且缺乏自动化评估流程。方法：提出新基准PBLBench评估模型复杂推理和长上下文理解能力，采用层次分析法（AHP）建立评估标准。效果：用PBLBench评估15个领先MLLMs/LLMs，最先进模型排名准确率仅59%，该基准有望促进AI发展，减轻教师负担、提高教育效率。
            arXiv:2505.17050v1 Announce Type: new 
Abstract: Project-Based Learning (PBL) involves a variety of highly correlated multimodal data, making it a vital educational approach within STEM disciplines. With the rapid development of multimodal large language models (MLLMs), researchers have begun exploring their potential to enhance tasks such as information retrieval, knowledge comprehension, and data generation in educational settings. However, existing benchmarks fall short in providing both a free-form output structure and a rigorous human expert validation process, limiting their effectiveness in evaluating real-world educational tasks. Additionally, few methods have developed automated pipelines to assist with the complex responsibilities of teachers leveraging MLLMs, largely due to model hallucination and instability, which lead to unreliable implementation. To address this gap, we introduce PBLBench, a novel benchmark designed to evaluate complex reasoning grounded in domain-specific knowledge and long-context understanding, thereby challenging models with tasks that closely resemble those handled by human experts. To establish reliable ground truth, we adopt the Analytic Hierarchy Process (AHP), utilizing expert-driven pairwise comparisons to derive structured and weighted evaluation criteria. We assess the performance of 15 leading MLLMs/LLMs using PBLBench and demonstrate that even the most advanced models achieve only 59% rank accuracy, underscoring the significant challenges presented by this benchmark. We believe PBLBench will serve as a catalyst for the development of more capable AI agents, ultimately aiming to alleviate teacher workload and enhance educational productivity.
        ]]></description>
    </item>
    <item>
        <title>METHOD: Modular Efficient Transformer for Health Outcome Discovery</title>
        <link>https://arxiv.org/abs/2505.17054</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17054v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Linglong Qian, Zina Ibrahim</dc:creator>
        <description><![CDATA[
            背景：Transformer架构在自然语言处理取得进展，但应用于医疗领域面临挑战，患者时间线有不规则采样等特点。方法：提出METHOD，集成患者感知注意力机制、自适应滑动窗口注意力方案和受U-Net启发的动态跳跃连接架构。效果：在MIMIC - IV数据库评估中，METHOD始终优于ETHOS模型，尤其在预测需紧急干预的高严重程度病例上表现出色，在不同推理长度下性能稳定，且学习的嵌入更好保留了临床层次和医学概念关系。
            arXiv:2505.17054v1 Announce Type: new 
Abstract: Recent advances in transformer architectures have revolutionised natural language processing, but their application to healthcare domains presents unique challenges. Patient timelines are characterised by irregular sampling, variable temporal dependencies, and complex contextual relationships that differ substantially from traditional language tasks. This paper introduces \METHOD~(Modular Efficient Transformer for Health Outcome Discovery), a novel transformer architecture specifically designed to address the challenges of clinical sequence modelling in electronic health records. \METHOD~integrates three key innovations: (1) a patient-aware attention mechanism that prevents information leakage whilst enabling efficient batch processing; (2) an adaptive sliding window attention scheme that captures multi-scale temporal dependencies; and (3) a U-Net inspired architecture with dynamic skip connections for effective long sequence processing. Evaluations on the MIMIC-IV database demonstrate that \METHOD~consistently outperforms the state-of-the-art \ETHOS~model, particularly in predicting high-severity cases that require urgent clinical intervention. \METHOD~exhibits stable performance across varying inference lengths, a crucial feature for clinical deployment where patient histories vary significantly in length. Analysis of learned embeddings reveals that \METHOD~better preserves clinical hierarchies and relationships between medical concepts. These results suggest that \METHOD~represents a significant advancement in transformer architectures optimised for healthcare applications, providing more accurate and clinically relevant predictions whilst maintaining computational efficiency.
        ]]></description>
    </item>
    <item>
        <title>DO-RAG: A Domain-Specific QA Framework Using Knowledge Graph-Enhanced Retrieval-Augmented Generation</title>
        <link>https://arxiv.org/abs/2505.17058</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17058v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>David Osei Opoku, Ming Sheng, Yong Zhang</dc:creator>
        <description><![CDATA[
            领域特定的问答系统需结合生成流畅性与事实准确性。现有检索增强生成（RAG）框架在整合异构数据和保持推理一致性方面存在挑战。为此，本文提出DO - RAG框架，将多级知识图谱构建与语义向量检索相结合，采用新的思维链架构从非结构化多模态文档中提取结构化关系，构建动态知识图谱。查询时融合图和向量检索结果生成响应并减少幻觉。实验显示，在数据库和电气领域召回率近乎完美，答案相关性超94%，比基线框架最高提升33.38%。
            arXiv:2505.17058v1 Announce Type: new 
Abstract: Domain-specific QA systems require not just generative fluency but high factual accuracy grounded in structured expert knowledge. While recent Retrieval-Augmented Generation (RAG) frameworks improve context recall, they struggle with integrating heterogeneous data and maintaining reasoning consistency. To address these challenges, we propose DO-RAG, a scalable and customizable hybrid QA framework that integrates multi-level knowledge graph construction with semantic vector retrieval. Our system employs a novel agentic chain-of-thought architecture to extract structured relationships from unstructured, multimodal documents, constructing dynamic knowledge graphs that enhance retrieval precision. At query time, DO-RAG fuses graph and vector retrieval results to generate context-aware responses, followed by hallucination mitigation via grounded refinement. Experimental evaluations in the database and electrical domains show near-perfect recall and over 94% answer relevancy, with DO-RAG outperforming baseline frameworks by up to 33.38%. By combining traceability, adaptability, and performance efficiency, DO-RAG offers a reliable foundation for multi-domain, high-precision QA at scale.
        ]]></description>
    </item>
    <item>
        <title>Reinforcing Question Answering Agents with Minimalist Policy Gradient Optimization</title>
        <link>https://arxiv.org/abs/2505.17086</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17086v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yihong Wu, Liheng Ma, Muzhi Li, Jiaming Zhou, Jianye Hao, Ho-fung Leung, Irwin King, Yingxue Zhang, Jian-Yun Nie</dc:creator>
        <description><![CDATA[
            背景：大语言模型用于问答任务时因缺乏事实知识易产生幻觉，现有检索增强生成方法依赖上下文学习，受限于模型推理能力。方法：提出Mujica，由将问题分解为子问题有向无环图的规划器和通过检索推理解决问题的执行器组成；还引入MyGO，用最大似然估计替代传统策略梯度更新。效果：多数据集实验表明，Mujica - MyGO能提升多种大模型的多跳问答性能，为复杂问答任务提供可扩展、高效的解决方案。
            arXiv:2505.17086v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have demonstrated remarkable versatility, due to the lack of factual knowledge, their application to Question Answering (QA) tasks remains hindered by hallucination.
  While Retrieval-Augmented Generation mitigates these issues by integrating external knowledge, existing approaches rely heavily on in-context learning, whose performance is constrained by the fundamental reasoning capabilities of LLMs.
  In this paper, we propose Mujica, a Multi-hop Joint Intelligence for Complex Question Answering, comprising a planner that decomposes questions into a directed acyclic graph of subquestions and a worker that resolves questions via retrieval and reasoning. Additionally, we introduce MyGO (Minimalist policy Gradient Optimization), a novel reinforcement learning method that replaces traditional policy gradient updates with Maximum Likelihood Estimation (MLE) by sampling trajectories from an asymptotically optimal policy. MyGO eliminates the need for gradient rescaling and reference models, ensuring stable and efficient training.
  Empirical results across multiple datasets demonstrate the effectiveness of Mujica-MyGO in enhancing multi-hop QA performance for various LLMs, offering a scalable and resource-efficient solution for complex QA tasks.
        ]]></description>
    </item>
    <item>
        <title>Informatics for Food Processing</title>
        <link>https://arxiv.org/abs/2505.17087</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17087v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Gordana Ispirova, Michael Sebek, Giulia Menichetti</dc:creator>
        <description><![CDATA[
            背景：传统食品加工分类框架存在主观性和可重复性问题，阻碍流行病学研究和公共政策制定。方法：提出新计算方法，如用营养成分数据训练随机森林模型FoodProX推断加工水平并生成FPro分数；用BERT等大语言模型对食品描述和成分列表进行语义嵌入；利用Open Food Facts数据库，让多模态AI模型整合结构化和非结构化数据进行食品分类。效果：为公共卫生和研究中的食品加工评估提供新范式。
            arXiv:2505.17087v1 Announce Type: new 
Abstract: This chapter explores the evolution, classification, and health implications of food processing, while emphasizing the transformative role of machine learning, artificial intelligence (AI), and data science in advancing food informatics. It begins with a historical overview and a critical review of traditional classification frameworks such as NOVA, Nutri-Score, and SIGA, highlighting their strengths and limitations, particularly the subjectivity and reproducibility challenges that hinder epidemiological research and public policy. To address these issues, the chapter presents novel computational approaches, including FoodProX, a random forest model trained on nutrient composition data to infer processing levels and generate a continuous FPro score. It also explores how large language models like BERT and BioBERT can semantically embed food descriptions and ingredient lists for predictive tasks, even in the presence of missing data. A key contribution of the chapter is a novel case study using the Open Food Facts database, showcasing how multimodal AI models can integrate structured and unstructured data to classify foods at scale, offering a new paradigm for food processing assessment in public health and research.
        ]]></description>
    </item>
    <item>
        <title>CAMA: Enhancing Multimodal In-Context Learning with Context-Aware Modulated Attention</title>
        <link>https://arxiv.org/abs/2505.17097</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17097v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yanshu Li, JianJiang Yang, Bozheng Li, Ruixiang Tang</dc:creator>
        <description><![CDATA[
            背景：多模态上下文学习（ICL）能让大视觉语言模型适应新任务，但不稳定，且当前研究多关注序列配置，忽视模型内部机制。方法：对多模态ICL中注意力动态进行理论分析，找出标准注意力影响性能的三个核心局限，提出上下文感知调制注意力（CAMA），这是一种直接校准模型注意力对数的免训练即插即用方法。效果：在四个模型、六个基准测试上评估，证明了其有效性和通用性，为多模态推理发展提供新机遇。
            arXiv:2505.17097v1 Announce Type: new 
Abstract: Multimodal in-context learning (ICL) enables large vision-language models (LVLMs) to efficiently adapt to novel tasks, supporting a wide array of real-world applications. However, multimodal ICL remains unstable, and current research largely focuses on optimizing sequence configuration while overlooking the internal mechanisms of LVLMs. In this work, we first provide a theoretical analysis of attentional dynamics in multimodal ICL and identify three core limitations of standard attention that ICL impair performance. To address these challenges, we propose Context-Aware Modulated Attention (CAMA), a simple yet effective plug-and-play method for directly calibrating LVLM attention logits. CAMA is training-free and can be seamlessly applied to various open-source LVLMs. We evaluate CAMA on four LVLMs across six benchmarks, demonstrating its effectiveness and generality. CAMA opens new opportunities for deeper exploration and targeted utilization of LVLM attention dynamics to advance multimodal reasoning.
        ]]></description>
    </item>
    <item>
        <title>TACO: Enhancing Multimodal In-context Learning via Task Mapping-Guided Sequence Configuration</title>
        <link>https://arxiv.org/abs/2505.17098</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17098v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yanshu Li, Tian Yun, Jianjiang Yang, Pinyuan Feng, Jinfa Huang, Ruixiang Tang</dc:creator>
        <description><![CDATA[
            背景：多模态上下文学习（ICL）是发挥大视觉语言模型能力的关键机制，但效果受输入上下文序列质量影响大，且对模型推理时如何利用序列理解有限。方法：从任务映射角度系统解释多模态 ICL，揭示示例内和示例间关系对模型推理的引导作用，提出基于轻量级 Transformer 的 TACO 模型，通过任务感知注意力动态配置上下文序列，在自回归解码中注入任务映射信号。效果：在五个 LVLMs 和九个数据集上实验表明，TACO 在不同 ICL 任务中均超越基线。
            arXiv:2505.17098v1 Announce Type: new 
Abstract: Multimodal in-context learning (ICL) has emerged as a key mechanism for harnessing the capabilities of large vision-language models (LVLMs). However, its effectiveness remains highly sensitive to the quality of input in-context sequences, particularly for tasks involving complex reasoning or open-ended generation. A major limitation is our limited understanding of how LVLMs actually exploit these sequences during inference. To bridge this gap, we systematically interpret multimodal ICL through the lens of task mapping, which reveals how local and global relationships within and among demonstrations guide model reasoning. Building on this insight, we present TACO, a lightweight transformer-based model equipped with task-aware attention that dynamically configures in-context sequences. By injecting task-mapping signals into the autoregressive decoding process, TACO creates a bidirectional synergy between sequence construction and task reasoning. Experiments on five LVLMs and nine datasets demonstrate that TACO consistently surpasses baselines across diverse ICL tasks. These results position task mapping as a valuable perspective for interpreting and improving multimodal ICL.
        ]]></description>
    </item>
    <item>
        <title>Forging Time Series with Language: A Large Language Model Approach to Synthetic Data Generation</title>
        <link>https://arxiv.org/abs/2505.17103</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17103v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>C\'ecile Rousseau, Tobia Boschi, Giandomenico Cornacchia, Dhaval Salwala, Alessandra Pascale, Juan Bernabe Moreno</dc:creator>
        <description><![CDATA[
            背景：需要一种高效方法生成高质量多元时间序列。方法：提出SDForger框架，利用紧凑数据表示，将单变量和多变量信号转换为表格嵌入，编码成文本微调自回归大语言模型，推理时采样新文本嵌入并解码为合成时间序列。效果：在多种数据集上，在基于相似度评估和下游预测任务中，SDForger在很多场景下优于现有生成模型，还为多模态建模及时间序列与文本信息集成提供了可能。
            arXiv:2505.17103v1 Announce Type: new 
Abstract: SDForger is a flexible and efficient framework for generating high-quality multivariate time series using LLMs. Leveraging a compact data representation, SDForger provides synthetic time series generation from a few samples and low-computation fine-tuning of any autoregressive LLM. Specifically, the framework transforms univariate and multivariate signals into tabular embeddings, which are then encoded into text and used to fine-tune the LLM. At inference, new textual embeddings are sampled and decoded into synthetic time series that retain the original data's statistical properties and temporal dynamics. Across a diverse range of datasets, SDForger outperforms existing generative models in many scenarios, both in similarity-based evaluations and downstream forecasting tasks. By enabling textual conditioning in the generation process, SDForger paves the way for multimodal modeling and the streamlined integration of time series with textual information. SDForger source code will be open-sourced soon.
        ]]></description>
    </item>
    <item>
        <title>Multi-Modality Expansion and Retention for LLMs through Parameter Merging and Decoupling</title>
        <link>https://arxiv.org/abs/2505.17110</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17110v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Junlin Li, Guodong DU, Jing Li, Sim Kuan Goh, Wenya Wang, Yequan Wang, Fangming Liu, Ho-Kin Tang, Saleh Alharbi, Daojing He, Min Zhang</dc:creator>
        <description><![CDATA[
            背景：用多模态编码器在特定模态数据上微调大语言模型（LLMs）可形成多模态大语言模型（MLLMs），但该范式依赖从头微调，资源消耗大且缺乏灵活性。方法：提出无训练方法MMER，复用MLLMs的多模态编码器并合并其LLM参数，通过比较生成二进制掩码分离各模态参数，还能对新任务微调的MLLMs缓解灾难性遗忘。效果：实验表明，MMER能有效扩展LLMs多模态能力，保留99%原性能，显著缓解灾难性遗忘。
            arXiv:2505.17110v1 Announce Type: new 
Abstract: Fine-tuning Large Language Models (LLMs) with multimodal encoders on modality-specific data expands the modalities that LLMs can handle, leading to the formation of Multimodal LLMs (MLLMs). However, this paradigm heavily relies on resource-intensive and inflexible fine-tuning from scratch with new multimodal data. In this paper, we propose MMER (Multi-modality Expansion and Retention), a training-free approach that integrates existing MLLMs for effective multimodal expansion while retaining their original performance. Specifically, MMER reuses MLLMs' multimodal encoders while merging their LLM parameters. By comparing original and merged LLM parameters, MMER generates binary masks to approximately separate LLM parameters for each modality. These decoupled parameters can independently process modality-specific inputs, reducing parameter conflicts and preserving original MLLMs' fidelity. MMER can also mitigate catastrophic forgetting by applying a similar process to MLLMs fine-tuned on new tasks. Extensive experiments show significant improvements over baselines, proving that MMER effectively expands LLMs' multimodal capabilities while retaining 99% of the original performance, and also markedly mitigates catastrophic forgetting.
        ]]></description>
    </item>
    <item>
        <title>Comparative Evaluation of Prompting and Fine-Tuning for Applying Large Language Models to Grid-Structured Geospatial Data</title>
        <link>https://arxiv.org/abs/2505.17116</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17116v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Akash Dhruv, Yangxinyu Xie, Jordan Branham, Tanwi Mallick</dc:creator>
        <description><![CDATA[
            背景：需研究大语言模型在解释网格结构地理空间数据方面的应用。方法：对基础模型进行结构化提示以评估其性能，并与在用户 - 助手交互数据集上微调的模型进行对比。效果：研究凸显了零样本提示的优缺点，证明了微调在结构化地理空间和时间推理中的优势，有助于明确不同方式处理网格结构地理空间数据的效果，为后续研究提供参考。 
            arXiv:2505.17116v1 Announce Type: new 
Abstract: This paper presents a comparative study of large language models (LLMs) in interpreting grid-structured geospatial data. We evaluate the performance of a base model through structured prompting and contrast it with a fine-tuned variant trained on a dataset of user-assistant interactions. Our results highlight the strengths and limitations of zero-shot prompting and demonstrate the benefits of fine-tuning for structured geospatial and temporal reasoning.
        ]]></description>
    </item>
    <item>
        <title>After Retrieval, Before Generation: Enhancing the Trustworthiness of Large Language Models in RAG</title>
        <link>https://arxiv.org/abs/2505.17118</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17118v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xinbang Dai, Huikang Hu, Yuncheng Hua, Jiaqi Li, Yongrui Chen, Rihui Jin, Nan Hu, Guilin Qi</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）系统在平衡内部和外部知识时面临挑战，现有方法缺乏统一框架处理不同情况。方法：构建含36266个问题的可信响应数据集（TRD），提出BRIDGE框架，利用软偏差自适应加权机制引导知识收集，通过最大软偏差决策树评估知识并选择响应策略。效果：实验表明，BRIDGE在准确率上比基线模型高5 - 15%，且在各场景下性能均衡，为RAG应用中大模型可信响应提供有效方案。
            arXiv:2505.17118v1 Announce Type: new 
Abstract: Retrieval-augmented generation (RAG) systems face critical challenges in balancing internal (parametric) and external (retrieved) knowledge, especially when these sources conflict or are unreliable. To analyze these scenarios comprehensively, we construct the Trustworthiness Response Dataset (TRD) with 36,266 questions spanning four RAG settings. We reveal that existing approaches address isolated scenarios-prioritizing one knowledge source, naively merging both, or refusing answers-but lack a unified framework to handle different real-world conditions simultaneously. Therefore, we propose the BRIDGE framework, which dynamically determines a comprehensive response strategy of large language models (LLMs). BRIDGE leverages an adaptive weighting mechanism named soft bias to guide knowledge collection, followed by a Maximum Soft-bias Decision Tree to evaluate knowledge and select optimal response strategies (trust internal/external knowledge, or refuse). Experiments show BRIDGE outperforms baselines by 5-15% in accuracy while maintaining balanced performance across all scenarios. Our work provides an effective solution for LLMs' trustworthy responses in real-world RAG applications.
        ]]></description>
    </item>
    <item>
        <title>NeSyGeo: A Neuro-Symbolic Framework for Multimodal Geometric Reasoning Data Generation</title>
        <link>https://arxiv.org/abs/2505.17121</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17121v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Weiming Wu, Zi-kang Wang, Jin Ye, Zhi Zhou, Yu-Feng Li, Lan-Zhe Guo</dc:creator>
        <description><![CDATA[
            获取带推理路径的大规模、高质量数据对提升多模态大语言模型几何推理能力至关重要，但现有数据生成方法有多样性和数值泛化局限。为此提出NeSyGeo神经符号框架，用特定领域语言表示平面几何组件，设计符号 - 视觉 - 文本流程生成问答对。构建含10万个样本的数据集，发布评估基准。实验表明，该框架显著提升多模态大语言模型性能，仅用4000个样本和两轮强化微调，基础模型在多个测试集上提升显著，4B模型在几何推理任务上可超同系列8B模型。
            arXiv:2505.17121v1 Announce Type: new 
Abstract: Obtaining large-scale, high-quality data with reasoning paths is crucial for improving the geometric reasoning capabilities of multi-modal large language models (MLLMs). However, existing data generation methods, whether based on predefined templates or constrained symbolic provers, inevitably face diversity and numerical generalization limitations. To address these limitations, we propose NeSyGeo, a novel neuro-symbolic framework for generating geometric reasoning data. First, we propose a domain-specific language grounded in the entity-relation-constraint paradigm to comprehensively represent all components of plane geometry, along with generative actions defined within this symbolic space. We then design a symbolic-visual-text pipeline that synthesizes symbolic sequences, maps them to corresponding visual and textual representations, and generates diverse question-answer (Q&amp;A) pairs using large language models (LLMs). To the best of our knowledge, we are the first to propose a neuro-symbolic approach in generating multimodal reasoning data. Based on this framework, we construct NeSyGeo-CoT and NeSyGeo-Caption datasets, containing 100k samples, and release a new benchmark NeSyGeo-Test for evaluating geometric reasoning abilities in MLLMs. Experiments demonstrate that the proposal significantly and consistently improves the performance of multiple MLLMs under both reinforcement and supervised fine-tuning. With only 4k samples and two epochs of reinforcement fine-tuning, base models achieve improvements of up to +15.8% on MathVision, +8.4% on MathVerse, and +7.3% on GeoQA. Notably, a 4B model can be improved to outperform an 8B model from the same series on geometric reasoning tasks.
        ]]></description>
    </item>
    <item>
        <title>Foundation Models for Geospatial Reasoning: Assessing Capabilities of Large Language Models in Understanding Geometries and Topological Spatial Relations</title>
        <link>https://arxiv.org/abs/2505.17136</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17136v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuhan Ji, Song Gao, Ying Nie, Ivan Maji\'c, Krzysztof Janowicz</dc:creator>
        <description><![CDATA[
            背景：将AI基础模型直接应用于地理空间数据集存在挑战，因其表示和推理地理实体能力有限。方法：研究将地理空间矢量数据输入大语言模型（如GPT-3.5-turbo等）时，几何及其空间关系的表示在空间推理中的保留情况，采用基于几何嵌入、提示工程和日常语言评估三种方法完成空间推理任务。效果：基于嵌入和提示工程的方法在地理空间问答任务中识别拓扑空间关系平均准确率超0.6，GPT - 4少样本提示推理准确率超0.66，还能完成多项推理任务。 
            arXiv:2505.17136v1 Announce Type: new 
Abstract: Applying AI foundation models directly to geospatial datasets remains challenging due to their limited ability to represent and reason with geographical entities, specifically vector-based geometries and natural language descriptions of complex spatial relations. To address these issues, we investigate the extent to which a well-known-text (WKT) representation of geometries and their spatial relations (e.g., topological predicates) are preserved during spatial reasoning when the geospatial vector data are passed to large language models (LLMs) including GPT-3.5-turbo, GPT-4, and DeepSeek-R1-14B. Our workflow employs three distinct approaches to complete the spatial reasoning tasks for comparison, i.e., geometry embedding-based, prompt engineering-based, and everyday language-based evaluation. Our experiment results demonstrate that both the embedding-based and prompt engineering-based approaches to geospatial question-answering tasks with GPT models can achieve an accuracy of over 0.6 on average for the identification of topological spatial relations between two geometries. Among the evaluated models, GPT-4 with few-shot prompting achieved the highest performance with over 0.66 accuracy on topological spatial relation inference. Additionally, GPT-based reasoner is capable of properly comprehending inverse topological spatial relations and including an LLM-generated geometry can enhance the effectiveness for geographic entity retrieval. GPT-4 also exhibits the ability to translate certain vernacular descriptions about places into formal topological relations, and adding the geometry-type or place-type context in prompts may improve inference accuracy, but it varies by instance. The performance of these spatial reasoning tasks offers valuable insights for the refinement of LLMs with geographical knowledge towards the development of geo-foundation models capable of geospatial reasoning.
        ]]></description>
    </item>
    <item>
        <title>Amplify Adjacent Token Differences: Enhancing Long Chain-of-Thought Reasoning with Shift-FFN</title>
        <link>https://arxiv.org/abs/2505.17153</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17153v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yao Xu, Mingyu Xu, Fangyu Lei, Wangtao Sun, Xiangrong Zeng, Bingning Wang, Guang Liu, Shizhu He, Jun Zhao, Kang Liu</dc:creator>
        <description><![CDATA[
            背景：当前大模型通过长思维链推理在复杂推理任务中表现出色，但用长思维链数据微调大模型易导致循环推理问题，且相邻标记表示差异小与循环推理倾向高相关。方法：提出Shift Feedforward Networks（Shift - FFN），在将当前标记表示输入前馈网络前用前一标记进行编辑，动态放大相邻标记表示差异。效果：实验表明，在多个数学推理任务中，LoRA结合Shift - FFN在不同数据规模下准确率更高、循环推理率更低。
            arXiv:2505.17153v1 Announce Type: new 
Abstract: Recently, models such as OpenAI-o1 and DeepSeek-R1 have demonstrated remarkable performance on complex reasoning tasks through Long Chain-of-Thought (Long-CoT) reasoning. Although distilling this capability into student models significantly enhances their performance, this paper finds that fine-tuning LLMs with full parameters or LoRA with a low rank on long CoT data often leads to Cyclical Reasoning, where models repeatedly reiterate previous inference steps until the maximum length limit. Further analysis reveals that smaller differences in representations between adjacent tokens correlates with a higher tendency toward Cyclical Reasoning. To mitigate this issue, this paper proposes Shift Feedforward Networks (Shift-FFN), a novel approach that edits the current token's representation with the previous one before inputting it to FFN. This architecture dynamically amplifies the representation differences between adjacent tokens. Extensive experiments on multiple mathematical reasoning tasks demonstrate that LoRA combined with Shift-FFN achieves higher accuracy and a lower rate of Cyclical Reasoning across various data sizes compared to full fine-tuning and standard LoRA. Our data and code are available at https://anonymous.4open.science/r/Shift-FFN
        ]]></description>
    </item>
    <item>
        <title>TrimR: Verifier-based Training-Free Thinking Compression for Efficient Test-Time Scaling</title>
        <link>https://arxiv.org/abs/2505.17155</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17155v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Weizhe Lin, Xing Li, Zhiyuan Yang, Xiaojin Fu, Hui-Ling Zhen, Yaoyuan Wang, Xianzhi Yu, Wulong Liu, Xiaosong Li, Mingxuan Yuan</dc:creator>
        <description><![CDATA[
            背景：大推理模型借助思维链推理解决复杂任务，但测试时扩展思维链会增加解码开销，且存在冗余思维链。方法：提出TrimR，这是基于验证器、无需训练的动态思维链压缩框架，用轻量级预训练、指令调优的验证器检测并截断冗余中间思维，还给出适用于高吞吐量工业应用的核心算法和异步在线系统。效果：在Ascend NPUs和vLLM上评估，大批次工作负载下推理效率显著提升，在四个基准测试中，部分模型推理运行时间最多改善70%，且准确率影响可忽略。
            arXiv:2505.17155v1 Announce Type: new 
Abstract: Large Reasoning Models (LRMs) demonstrate exceptional capability in tackling complex mathematical, logical, and coding tasks by leveraging extended Chain-of-Thought (CoT) reasoning. Test-time scaling methods, such as prolonging CoT with explicit token-level exploration, can push LRMs' accuracy boundaries, but they incur significant decoding overhead. A key inefficiency source is LRMs often generate redundant thinking CoTs, which demonstrate clear structured overthinking and underthinking patterns. Inspired by human cognitive reasoning processes and numerical optimization theories, we propose TrimR, a verifier-based, training-free, efficient framework for dynamic CoT compression to trim reasoning and enhance test-time scaling, explicitly tailored for production-level deployment. Our method employs a lightweight, pretrained, instruction-tuned verifier to detect and truncate redundant intermediate thoughts of LRMs without any LRM or verifier fine-tuning. We present both the core algorithm and asynchronous online system engineered for high-throughput industrial applications. Empirical evaluations on Ascend NPUs and vLLM show that our framework delivers substantial gains in inference efficiency under large-batch workloads. In particular, on the four MATH500, AIME24, AIME25, and GPQA benchmarks, the reasoning runtime of Pangu-R-38B, QwQ-32B, and DeepSeek-R1-Distill-Qwen-32B is improved by up to 70% with negligible impact on accuracy.
        ]]></description>
    </item>
    <item>
        <title>PersonaBOT: Bringing Customer Personas to Life with LLMs and RAG</title>
        <link>https://arxiv.org/abs/2505.17156</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17156v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Muhammed Rizwan, Lars Carlsson, Mohammad Loni</dc:creator>
        <description><![CDATA[
            背景：大语言模型推动客户画像分析发展，传统定性方法开发客户画像耗时且缺乏扩展性。方法：开发基于画像的RAG聊天机器人，用少样本和思维链提示技术生成合成画像，用McNemar检验评估，最后用合成画像和额外细分信息扩充知识库。效果：少样本提示生成画像更完整，思维链在响应时间和令牌使用上更高效。扩充知识库后，聊天机器人平均准确率从5.88（满分10分）提升到6.42，81.82%参与者认为更新系统对业务有用。
            arXiv:2505.17156v1 Announce Type: new 
Abstract: The introduction of Large Language Models (LLMs) has significantly transformed Natural Language Processing (NLP) applications by enabling more advanced analysis of customer personas. At Volvo Construction Equipment (VCE), customer personas have traditionally been developed through qualitative methods, which are time-consuming and lack scalability. The main objective of this paper is to generate synthetic customer personas and integrate them into a Retrieval-Augmented Generation (RAG) chatbot to support decision-making in business processes. To this end, we first focus on developing a persona-based RAG chatbot integrated with verified personas. Next, synthetic personas are generated using Few-Shot and Chain-of-Thought (CoT) prompting techniques and evaluated based on completeness, relevance, and consistency using McNemar's test. In the final step, the chatbot's knowledge base is augmented with synthetic personas and additional segment information to assess improvements in response accuracy and practical utility. Key findings indicate that Few-Shot prompting outperformed CoT in generating more complete personas, while CoT demonstrated greater efficiency in terms of response time and token usage. After augmenting the knowledge base, the average accuracy rating of the chatbot increased from 5.88 to 6.42 on a 10-point scale, and 81.82% of participants found the updated system useful in business contexts.
        ]]></description>
    </item>
    <item>
        <title>FB-RAG: Improving RAG with Forward and Backward Lookup</title>
        <link>https://arxiv.org/abs/2505.17206</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17206v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kushal Chawla, Alfy Samuel, Anoop Kumar, Daben Liu</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）系统性能受检索器质量和检索上下文大小影响，大上下文含无关信息，小上下文易丢失重要信息，复杂查询更难处理。方法：提出FB - RAG框架，结合反向查找（与查询重叠）和正向查找（与候选原因和答案重叠）来检索与回答输入查询最相关的特定上下文块。效果：在两个领先基准的9个数据集上，FB - RAG始终优于RAG和近期为这些基准开发的长上下文基线，还能在降低延迟的同时提升性能。
            arXiv:2505.17206v1 Announce Type: new 
Abstract: The performance of Retrieval Augmented Generation (RAG) systems relies heavily on the retriever quality and the size of the retrieved context. A large enough context ensures that the relevant information is present in the input context for the LLM, but also incorporates irrelevant content that has been shown to confuse the models. On the other hand, a smaller context reduces the irrelevant information, but it often comes at the risk of losing important information necessary to answer the input question. This duality is especially challenging to manage for complex queries that contain little information to retrieve the relevant chunks from the full context. To address this, we present a novel framework, called FB-RAG, which enhances the RAG pipeline by relying on a combination of backward lookup (overlap with the query) and forward lookup (overlap with candidate reasons and answers) to retrieve specific context chunks that are the most relevant for answering the input query. Our evaluations on 9 datasets from two leading benchmarks show that FB-RAG consistently outperforms RAG and Long Context baselines developed recently for these benchmarks. We further show that FB-RAG can improve performance while reducing latency. We perform qualitative analysis of the strengths and shortcomings of our approach, providing specific insights to guide future work.
        ]]></description>
    </item>
    <item>
        <title>CHAOS: Chart Analysis with Outlier Samples</title>
        <link>https://arxiv.org/abs/2505.17235</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17235v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Omar Moured, Yufan Chen, Ruiping Liu, Simon Rei{\ss}, Philip Torr, Jiaming Zhang, Rainer Stiefelhagen</dc:creator>
        <description><![CDATA[
            背景：图表在数据分析和可视化中至关重要，但现实中的“异常图表”对多模态大模型（MLLMs）的解读构成挑战。方法：提出CHAOS基准，包含五种文本和十种视觉扰动，分三个严重级别，涵盖13种先进MLLMs并按训练范围和数据分组，对两个下游任务进行综合分析。效果：通过大量实验和案例研究，深入了解模型在图表扰动下的鲁棒性，为图表理解领域的未来研究提供指导，数据和代码公开。
            arXiv:2505.17235v1 Announce Type: new 
Abstract: Charts play a critical role in data analysis and visualization, yet real-world applications often present charts with challenging or noisy features. However, "outlier charts" pose a substantial challenge even for Multimodal Large Language Models (MLLMs), which can struggle to interpret perturbed charts. In this work, we introduce CHAOS (CHart Analysis with Outlier Samples), a robustness benchmark to systematically evaluate MLLMs against chart perturbations. CHAOS encompasses five types of textual and ten types of visual perturbations, each presented at three levels of severity (easy, mid, hard) inspired by the study result of human evaluation. The benchmark includes 13 state-of-the-art MLLMs divided into three groups (i.e., general-, document-, and chart-specific models) according to the training scope and data. Comprehensive analysis involves two downstream tasks (ChartQA and Chart-to-Text). Extensive experiments and case studies highlight critical insights into robustness of models across chart perturbations, aiming to guide future research in chart understanding domain. Data and code are publicly available at: http://huggingface.co/datasets/omoured/CHAOS.
        ]]></description>
    </item>
    <item>
        <title>Optimal Policy Minimum Bayesian Risk</title>
        <link>https://arxiv.org/abs/2505.17242</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17242v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ram\'on Fernandez Astudillo, Md Arafat Sultan, Aashka Trivedi, Yousef El-Kurdi, Tahira Naseem, Radu Florian, Salim Roukos</dc:creator>
        <description><![CDATA[
            背景：推理扩展可助大语言模型解决复杂推理问题，现有推理时间技术能通过生成多候选解聚合提升准确率。方法：提出将奖励和风险/相似度信号融入最小贝叶斯风险解码（MBRD）的新方法，基于KL控制强化学习中最优策略概念，框架可利用信号，还有样本高效变体，能依问题难度调整样本数。效果：在数学和编码任务中，相比传统推理时间方法，更具鲁棒性、准确率更高，还对准确率 - 计算权衡进行了分析。
            arXiv:2505.17242v1 Announce Type: new 
Abstract: Inference scaling can help LLMs solve complex reasoning problems through extended runtime computation. On top of targeted supervision for long chain-of-thought (long-CoT) generation, purely inference-time techniques such as best-of-N (BoN) sampling, majority voting, or more generally, minimum Bayes risk decoding (MBRD), can further improve LLM accuracy by generating multiple candidate solutions and aggregating over them. These methods typically leverage additional signals in the form of reward models and risk/similarity functions that compare generated samples, e.g., exact match in some normalized space or standard similarity metrics such as Rouge. Here we present a novel method for incorporating reward and risk/similarity signals into MBRD. Based on the concept of optimal policy in KL-controlled reinforcement learning, our framework provides a simple and well-defined mechanism for leveraging such signals, offering several advantages over traditional inference-time methods: higher robustness, improved accuracy, and well-understood asymptotic behavior. In addition, it allows for the development of a sample-efficient variant of MBRD that can adjust the number of samples to generate according to the difficulty of the problem, without relying on majority vote counts. We empirically demonstrate the advantages of our approach on math (MATH-$500$) and coding (HumanEval) tasks using recent open-source models. We also present a comprehensive analysis of its accuracy-compute trade-offs.
        ]]></description>
    </item>
    <item>
        <title>ConciseRL: Conciseness-Guided Reinforcement Learning for Efficient Reasoning Models</title>
        <link>https://arxiv.org/abs/2505.17250</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17250v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Razvan-Gabriel Dumitru, Darius Peteleaza, Vikas Yadav, Liangming Pan</dc:creator>
        <description><![CDATA[
            背景：大语言模型虽能将问题分解为结构化推理步骤解决复杂任务，但推理轨迹常超出正确答案所需，导致计算浪费等问题。方法：引入无超参数的简洁性分数作为强化学习框架中的奖励信号，由大语言模型作为评判者评估该分数，提供动态、上下文感知的反馈。效果：在MATH数据集上实现了效率 - 准确率的最优权衡，简单问题减少达31倍的token使用且准确率提升7%，难题准确率提升7.5%且减少3.6倍token；在TheoremQA上用少12.5倍的token使准确率提升2.2%。
            arXiv:2505.17250v1 Announce Type: new 
Abstract: Large language models excel at complex tasks by breaking down problems into structured reasoning steps. However, reasoning traces often extend beyond reaching a correct answer, causing wasted computation, reduced readability, and hallucinations. To address this, we introduce a novel hyperparameter-free conciseness score used as a reward signal within a reinforcement learning framework to guide models toward generating correct and concise reasoning traces. This score is evaluated by a large language model acting as a judge, enabling dynamic, context-aware feedback beyond simple token length. Our method achieves state-of-the-art efficiency-accuracy trade-offs on the MATH dataset, reducing token usage by up to 31x on simple problems while improving accuracy by 7%, and on the hardest problems, it outperforms full reasoning by +7.5% accuracy with up to 3.6x fewer tokens. On TheoremQA, our method improves accuracy by +2.2% using 12.5x fewer tokens. We also conduct ablation studies on the judge model, reward composition, and problem difficulty, showing that our method dynamically adapts reasoning length based on problem difficulty and benefits significantly from stronger judges. The code, model weights, and datasets are open-sourced at https://github.com/RazvanDu/ConciseRL.
        ]]></description>
    </item>
    <item>
        <title>JanusDNA: A Powerful Bi-directional Hybrid DNA Foundation Model</title>
        <link>https://arxiv.org/abs/2505.17257</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17257v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qihao Duan, Bingding Huang, Zhenqiao Song, Irina Lehmann, Lei Gu, Roland Eils, Benjamin Wild</dc:creator>
        <description><![CDATA[
            背景：大语言模型应用于基因序列面临挑战，传统架构和训练范式难以捕捉长距离依赖，且标准训练方法不适用于DNA双向特性。方法：提出JanusDNA，采用结合自回归建模效率与掩码建模双向理解的预训练范式，采用混合Mamba、注意力和专家混合体（MoE）架构。效果：能在单块80GB GPU上以单核苷酸分辨率处理100万个碱基对，在三个基因组表征基准测试中取得新的最优结果，超越激活参数多250倍的模型。
            arXiv:2505.17257v1 Announce Type: new 
Abstract: Large language models (LLMs) have revolutionized natural language processing and are increasingly applied to other sequential data types, including genetic sequences. However, adapting LLMs to genomics presents significant challenges. Capturing complex genomic interactions requires modeling long-range dependencies within DNA sequences, where interactions often span over 10,000 base pairs, even within a single gene, posing substantial computational burdens under conventional model architectures and training paradigms. Moreover, standard LLM training approaches are suboptimal for DNA: autoregressive training, while efficient, supports only unidirectional understanding. However, DNA is inherently bidirectional, e.g., bidirectional promoters regulate transcription in both directions and account for nearly 11% of human gene expression. Masked language models (MLMs) allow bidirectional understanding but are inefficient, as only masked tokens contribute to the loss per step. To address these limitations, we introduce JanusDNA, the first bidirectional DNA foundation model built upon a novel pretraining paradigm that combines the optimization efficiency of autoregressive modeling with the bidirectional comprehension of masked modeling. JanusDNA adopts a hybrid Mamba, Attention and Mixture of Experts (MoE) architecture, combining long-range modeling of Attention with efficient sequential learning of Mamba. MoE layers further scale model capacity via sparse activation while keeping computational cost low. Notably, JanusDNA processes up to 1 million base pairs at single nucleotide resolution on a single 80GB GPU. Extensive experiments and ablations show JanusDNA achieves new SOTA results on three genomic representation benchmarks, outperforming models with 250x more activated parameters. Code: https://github.com/Qihao-Duan/JanusDNA
        ]]></description>
    </item>
    <item>
        <title>CaseReportBench: An LLM Benchmark Dataset for Dense Information Extraction in Clinical Case Reports</title>
        <link>https://arxiv.org/abs/2505.17265</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17265v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiao Yu Cindy Zhang (University of British Columbia), Carlos R. Ferreira (National Institutes of Health), Francis Rossignol (National Institutes of Health), Raymond T. Ng (University of British Columbia), Wyeth Wasserman (University of British Columbia), Jian Zhu (University of British Columbia)</dc:creator>
        <description><![CDATA[
            背景：罕见病诊断困难，病例报告信息提取有需求，但大语言模型在此任务上评估少。方法：引入专家标注数据集CaseReportBench，评估多种模型和提示策略，如类别特定提示和副标题过滤数据集成。效果：零样本思维链提示优势不大，类别特定提示提升与基准的对齐度，开源模型Qwen2.5 - 7B表现优于GPT - 4o，临床评估显示大模型能提取相关信息，但识别阴性结果有局限，推动了临床自然语言处理发展。
            arXiv:2505.17265v1 Announce Type: new 
Abstract: Rare diseases, including Inborn Errors of Metabolism (IEM), pose significant diagnostic challenges. Case reports serve as key but computationally underutilized resources to inform diagnosis. Clinical dense information extraction refers to organizing medical information into structured predefined categories. Large Language Models (LLMs) may enable scalable information extraction from case reports but are rarely evaluated for this task. We introduce CaseReportBench, an expert-annotated dataset for dense information extraction of case reports, focusing on IEMs. Using this dataset, we assess various models and prompting strategies, introducing novel approaches such as category-specific prompting and subheading-filtered data integration. Zero-shot chain-of-thought prompting offers little advantage over standard zero-shot prompting. Category-specific prompting improves alignment with the benchmark. The open-source model Qwen2.5-7B outperforms GPT-4o for this task. Our clinician evaluations show that LLMs can extract clinically relevant details from case reports, supporting rare disease diagnosis and management. We also highlight areas for improvement, such as LLMs' limitations in recognizing negative findings important for differential diagnosis. This work advances LLM-driven clinical natural language processing and paves the way for scalable medical AI applications.
        ]]></description>
    </item>
    <item>
        <title>Select2Reason: Efficient Instruction-Tuning Data Selection for Long-CoT Reasoning</title>
        <link>https://arxiv.org/abs/2505.17266</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17266v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Cehao Yang, Xueyuan Lin, Chengjin Xu, Xuhui Jiang, Xiaojun Wu, Honghao Liu, Hui Xiong, Jian Guo</dc:creator>
        <description><![CDATA[
            背景：预训练大语言模型激活长思维链推理能力常用监督微调，但大规模指令集训练开销大，自动长思维链指令选择策略待探索。方法：提出Select2Reason框架，从自我修正和回溯等反思行为出现的角度研究决定长思维链推理指令质量的指标，用量化器估计问题难度，结合基于推理轨迹长度的启发式方法对示例排序。效果：在OpenR1 - Math - 220k上，用Select2Reason选10%数据微调大模型，在多个数学基准测试中性能与全量数据调优相当或更优。
            arXiv:2505.17266v1 Announce Type: new 
Abstract: A practical approach to activate long chain-of-thoughts reasoning ability in pre-trained large language models is to perform supervised fine-tuning on instruction datasets synthesized by strong Large Reasoning Models such as DeepSeek-R1, offering a cost-effective alternative to reinforcement learning. However, large-scale instruction sets with more than 100k samples incur significant training overhead, while effective strategies for automatic long-CoT instruction selection still remain unexplored. In this work, we propose Select2Reason, a novel and efficient instruction-tuning data selection framework for long-CoT reasoning. From the perspective of emergence of rethinking behaviors like self-correction and backtracking, we investigate common metrics that may determine the quality of long-CoT reasoning instructions. Select2Reason leverages a quantifier to estimate difficulty of question and jointly incorporates a reasoning trace length-based heuristic through a weighted scheme for ranking to prioritize high-utility examples. Empirical results on OpenR1-Math-220k demonstrate that fine-tuning LLM on only 10% of the data selected by Select2Reason achieves performance competitive with or superior to full-data tuning and open-source baseline OpenR1-Qwen-7B across three competition-level and six comprehensive mathematical benchmarks. Further experiments highlight the scalability in varying data size, efficiency during inference, and its adaptability to other instruction pools with minimal cost.
        ]]></description>
    </item>
    <item>
        <title>Search Wisely: Mitigating Sub-optimal Agentic Searches By Reducing Uncertainty</title>
        <link>https://arxiv.org/abs/2505.17281</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17281v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Peilin Wu, Mian Zhang, Xinlu Zhang, Xinya Du, Zhiyu Zoey Chen</dc:creator>
        <description><![CDATA[
            背景：智能检索增强生成（RAG）系统能增强大语言模型能力，但常出现过度检索和检索不足等次优搜索行为，影响效率和可靠性。方法：该研究定义并量化这些行为，揭示其与模型对自身知识边界不确定性的关联，提出基于强化学习的训练方法β - GRPO，引入置信阈值奖励高确定性搜索决策。效果：在七个问答基准测试中，β - GRPO使30亿参数模型具备更好的RAG能力，平均精确匹配得分比其他强基线高4%。
            arXiv:2505.17281v1 Announce Type: new 
Abstract: Agentic Retrieval-Augmented Generation (RAG) systems enhance Large Language Models (LLMs) by enabling dynamic, multi-step reasoning and information retrieval. However, these systems often exhibit sub-optimal search behaviors like over-search (retrieving redundant information) and under-search (failing to retrieve necessary information), which hinder efficiency and reliability. This work formally defines and quantifies these behaviors, revealing their prevalence across multiple QA datasets and agentic RAG systems (e.g., one model could have avoided searching in 27.7% of its search steps). Furthermore, we demonstrate a crucial link between these inefficiencies and the models' uncertainty regarding their own knowledge boundaries, where response accuracy correlates with model's uncertainty in its search decisions. To address this, we propose $\beta$-GRPO, a reinforcement learning-based training method that incorporates confidence threshold to reward high-certainty search decisions. Experiments on seven QA benchmarks show that $\beta$-GRPO enable a 3B model with better agentic RAG ability, outperforming other strong baselines with a 4% higher average exact match score.
        ]]></description>
    </item>
    <item>
        <title>Harnessing EHRs for Diffusion-based Anomaly Detection on Chest X-rays</title>
        <link>https://arxiv.org/abs/2505.17311</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17311v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Harim Kim, Yuhan Wang, Minkyu Ahn, Heeyoul Choi, Yuyin Zhou, Charmgil Hong</dc:creator>
        <description><![CDATA[
            背景：医学影像的无监督异常检测很重要，但现有基于扩散的模型仅依赖影像特征，难以区分正常解剖变异和病理异常。方法：提出多模态扩散框架Diff3M，集成胸部X光和结构化电子健康记录（EHRs），引入图像 - EHR交叉注意力模块将临床信息融入图像生成，还开发静态掩码策略增强异常图像的正常重建。效果：在CheXpert和MIMIC - CXR/IV上评估，Diff3M达最优性能，优于现有医学影像UAD方法。
            arXiv:2505.17311v1 Announce Type: new 
Abstract: Unsupervised anomaly detection (UAD) in medical imaging is crucial for identifying pathological abnormalities without requiring extensive labeled data. However, existing diffusion-based UAD models rely solely on imaging features, limiting their ability to distinguish between normal anatomical variations and pathological anomalies. To address this, we propose Diff3M, a multi-modal diffusion-based framework that integrates chest X-rays and structured Electronic Health Records (EHRs) for enhanced anomaly detection. Specifically, we introduce a novel image-EHR cross-attention module to incorporate structured clinical context into the image generation process, improving the model's ability to differentiate normal from abnormal features. Additionally, we develop a static masking strategy to enhance the reconstruction of normal-like images from anomalies. Extensive evaluations on CheXpert and MIMIC-CXR/IV demonstrate that Diff3M achieves state-of-the-art performance, outperforming existing UAD methods in medical imaging. Our code is available at this http URL https://github.com/nth221/Diff3M
        ]]></description>
    </item>
    <item>
        <title>FS-DAG: Few Shot Domain Adapting Graph Networks for Visually Rich Document Understanding</title>
        <link>https://arxiv.org/abs/2505.17330</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17330v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Amit Agarwal, Srikant Panda, Kulbhushan Pachauri</dc:creator>
        <description><![CDATA[
            背景：在少样本场景下进行视觉丰富文档理解（VRDU）面临挑战。方法：提出Few Shot Domain Adapting Graph（FS - DAG），在模块化框架中利用特定领域和语言/视觉主干，以少量数据适应不同文档类型，还能应对OCR错误等实际问题。效果：模型参数少于90M，适用于计算资源有限的信息提取任务。实验表明，与现有方法相比，其在收敛速度和性能上有显著提升。
            arXiv:2505.17330v1 Announce Type: new 
Abstract: In this work, we propose Few Shot Domain Adapting Graph (FS-DAG), a scalable and efficient model architecture for visually rich document understanding (VRDU) in few-shot settings. FS-DAG leverages domain-specific and language/vision specific backbones within a modular framework to adapt to diverse document types with minimal data. The model is robust to practical challenges such as handling OCR errors, misspellings, and domain shifts, which are critical in real-world deployments. FS-DAG is highly performant with less than 90M parameters, making it well-suited for complex real-world applications for Information Extraction (IE) tasks where computational resources are limited. We demonstrate FS-DAG's capability through extensive experiments for information extraction task, showing significant improvements in convergence speed and performance compared to state-of-the-art methods. Additionally, this work highlights the ongoing progress in developing smaller, more efficient models that do not compromise on performance. Code : https://github.com/oracle-samples/fs-dag
        ]]></description>
    </item>
    <item>
        <title>Value-Guided Search for Efficient Chain-of-Thought Reasoning</title>
        <link>https://arxiv.org/abs/2505.17373</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17373v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kaiwen Wang, Jin Peng Zhou, Jonathan Chang, Zhaolin Gao, Nathan Kallus, Kiant\'e Brantley, Wen Sun</dc:creator>
        <description><![CDATA[
            背景：现有过程奖励模型在长上下文推理模型中难以定义“步骤”。方法：提出一种在长上下文推理轨迹上训练价值模型的高效方法，收集250万条推理轨迹数据集，训练15亿token级价值模型并应用于DeepSeek模型，采用块级价值引导搜索（VGS）结合最终加权多数投票。效果：VGS在测试时的扩展性优于标准方法，在64次生成的推理预算下，VGS结合DeepSeek - R1 - Distill - 1.5B在四个竞赛数学基准测试中平均准确率达45.7%，与o3 - mini - medium相当，还显著减少达到相同性能所需的推理FLOPs。
            arXiv:2505.17373v1 Announce Type: new 
Abstract: In this paper, we propose a simple and efficient method for value model training on long-context reasoning traces. Compared to existing process reward models (PRMs), our method does not require a fine-grained notion of "step," which is difficult to define for long-context reasoning models. By collecting a dataset of 2.5 million reasoning traces, we train a 1.5B token-level value model and apply it to DeepSeek models for improved performance with test-time compute scaling. We find that block-wise value-guided search (VGS) with a final weighted majority vote achieves better test-time scaling than standard methods such as majority voting or best-of-n. With an inference budget of 64 generations, VGS with DeepSeek-R1-Distill-1.5B achieves an average accuracy of 45.7% across four competition math benchmarks (AIME 2024 & 2025, HMMT Feb 2024 & 2025), reaching parity with o3-mini-medium. Moreover, VGS significantly reduces the inference FLOPs required to achieve the same performance of majority voting. Our dataset, model and codebase are open-sourced.
        ]]></description>
    </item>
    <item>
        <title>Curriculum Guided Reinforcement Learning for Efficient Multi Hop Retrieval Augmented Generation</title>
        <link>https://arxiv.org/abs/2505.17391</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17391v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuelyu Ji, Rui Meng, Zhuochun Li, Daqing He</dc:creator>
        <description><![CDATA[
            背景：现有多跳检索增强生成（RAG）管道存在冗余子查询、探索过浅或搜索链过长等问题。方法：提出EVO - RAG，这是一个课程引导的强化学习框架，让查询重写代理从早期广泛探索过渡到后期精确提炼，结合七因素步骤级奖励向量和时变调度器，通过直接偏好优化在多头奖励模型上训练代理。效果：在四个多跳问答基准测试中，相比强大的RAG基线，精确匹配率最高提升4.6个百分点，平均检索深度减少15%。
            arXiv:2505.17391v1 Announce Type: new 
Abstract: Retrieval-augmented generation (RAG) grounds large language models (LLMs) in up-to-date external evidence, yet existing multi-hop RAG pipelines still issue redundant subqueries, explore too shallowly, or wander through overly long search chains. We introduce EVO-RAG, a curriculum-guided reinforcement learning framework that evolves a query-rewriting agent from broad early-stage exploration to concise late-stage refinement. EVO-RAG couples a seven-factor, step-level reward vector (covering relevance, redundancy, efficiency, and answer correctness) with a time-varying scheduler that reweights these signals as the episode unfolds. The agent is trained with Direct Preference Optimization over a multi-head reward model, enabling it to learn when to search, backtrack, answer, or refuse. Across four multi-hop QA benchmarks (HotpotQA, 2WikiMultiHopQA, MuSiQue, and Bamboogle), EVO-RAG boosts Exact Match by up to 4.6 points over strong RAG baselines while trimming average retrieval depth by 15 %. Ablation studies confirm the complementary roles of curriculum staging and dynamic reward scheduling. EVO-RAG thus offers a general recipe for building reliable, cost-effective multi-hop RAG systems.
        ]]></description>
    </item>
    <item>
        <title>HyperIMTS: Hypergraph Neural Network for Irregular Multivariate Time Series Forecasting</title>
        <link>https://arxiv.org/abs/2505.17431</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17431v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Boyuan Li, Yicheng Luo, Zhen Liu, Junhao Zheng, Jianming Lv, Qianli Ma</dc:creator>
        <description><![CDATA[
            背景：不规则多变量时间序列（IMTS）存在变量内时间间隔不规则、变量间观测值未对齐问题，现有模型处理效率低且捕捉依赖有限。方法：提出HyperIMTS，将观测值转换为超图节点，通过时间和变量超边连接，实现不规则感知消息传递，以时间自适应方式捕捉变量依赖。效果：实验表明，HyperIMTS在IMTS预测中计算成本低，与现有先进模型相比有竞争力。
            arXiv:2505.17431v1 Announce Type: new 
Abstract: Irregular multivariate time series (IMTS) are characterized by irregular time intervals within variables and unaligned observations across variables, posing challenges in learning temporal and variable dependencies. Many existing IMTS models either require padded samples to learn separately from temporal and variable dimensions, or represent original samples via bipartite graphs or sets. However, the former approaches often need to handle extra padding values affecting efficiency and disrupting original sampling patterns, while the latter ones have limitations in capturing dependencies among unaligned observations. To represent and learn both dependencies from original observations in a unified form, we propose HyperIMTS, a Hypergraph neural network for Irregular Multivariate Time Series forecasting. Observed values are converted as nodes in the hypergraph, interconnected by temporal and variable hyperedges to enable message passing among all observations. Through irregularity-aware message passing, HyperIMTS captures variable dependencies in a time-adaptive way to achieve accurate forecasting. Experiments demonstrate HyperIMTS's competitive performance among state-of-the-art models in IMTS forecasting with low computational cost.
        ]]></description>
    </item>
    <item>
        <title>LeTS: Learning to Think-and-Search via Process-and-Outcome Reward Hybridization</title>
        <link>https://arxiv.org/abs/2505.17447</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17447v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qi Zhang, Shouqing Yang, Lirong Gao, Hao Chen, Xiaomeng Hu, Jinglei Chen, Jiexiang Wang, Sheng Guo, Bo Zheng, Haobo Wang, Junbo Zhao</dc:creator>
        <description><![CDATA[
            背景：大语言模型在推理方面展现出强大能力，但现有研究通过结果监督强化学习将推理能力融入检索增强生成（RAG）时，常忽略中间思考和搜索步骤的正确性。方法：设计过程级奖励模块，在无额外标注下缓解结果级监督对中间推理步骤的忽视，提出LeTS框架，将逐步过程奖励和基于结果的奖励与现有RAG的强化学习方法相结合。效果：实验表明LeTS在多种RAG基准测试中具有泛化性和推理效率，显示出过程和结果级奖励混合在提升大模型推理能力上的潜力。
            arXiv:2505.17447v1 Announce Type: new 
Abstract: Large language models (LLMs) have demonstrated impressive capabilities in reasoning with the emergence of reasoning models like OpenAI-o1 and DeepSeek-R1. Recent research focuses on integrating reasoning capabilities into the realm of retrieval-augmented generation (RAG) via outcome-supervised reinforcement learning (RL) approaches, while the correctness of intermediate think-and-search steps is usually neglected. To address this issue, we design a process-level reward module to mitigate the unawareness of intermediate reasoning steps in outcome-level supervision without additional annotation. Grounded on this, we propose Learning to Think-and-Search (LeTS), a novel framework that hybridizes stepwise process reward and outcome-based reward to current RL methods for RAG. Extensive experiments demonstrate the generalization and inference efficiency of LeTS across various RAG benchmarks. In addition, these results reveal the potential of process- and outcome-level reward hybridization in boosting LLMs' reasoning ability via RL under other scenarios. The code will be released soon.
        ]]></description>
    </item>
    <item>
        <title>Self-Training Large Language Models with Confident Reasoning</title>
        <link>https://arxiv.org/abs/2505.17454</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17454v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hyosoon Jang, Yunhui Jang, Sungjae Lee, Jungseul Ok, Sungsoo Ahn</dc:creator>
        <description><![CDATA[
            背景：大语言模型通过生成推理路径提升性能，但学习推理路径需大量人工监督，现有自训练方法多关注最终答案质量，可能忽略推理路径质量。方法：提出利用推理级置信度识别高质量推理路径，采用新的自训练方法CORE - PO，通过策略优化微调大模型，使其倾向高置信度推理路径。效果：实验表明，与现有自训练方法相比，CORE - PO在四个分布内和两个分布外基准测试中提高了输出准确率。
            arXiv:2505.17454v1 Announce Type: new 
Abstract: Large language models (LLMs) have shown impressive performance by generating reasoning paths before final answers, but learning such a reasoning path requires costly human supervision. To address this issue, recent studies have explored self-training methods that improve reasoning capabilities using pseudo-labels generated by the LLMs themselves. Among these, confidence-based self-training fine-tunes LLMs to prefer reasoning paths with high-confidence answers, where confidence is estimated via majority voting. However, such methods exclusively focus on the quality of the final answer and may ignore the quality of the reasoning paths, as even an incorrect reasoning path leads to a correct answer by chance. Instead, we advocate the use of reasoning-level confidence to identify high-quality reasoning paths for self-training, supported by our empirical observations. We then propose a new self-training method, CORE-PO, that fine-tunes LLMs to prefer high-COnfidence REasoning paths through Policy Optimization. Our experiments show that CORE-PO improves the accuracy of outputs on four in-distribution and two out-of-distribution benchmarks, compared to existing self-training methods.
        ]]></description>
    </item>
    <item>
        <title>Graph Mamba for Efficient Whole Slide Image Understanding</title>
        <link>https://arxiv.org/abs/2505.17457</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17457v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiaxuan Lu, Junyan Shi, Yuhui Lin, Fang Yan, Yue Gao, Shaoting Zhang, Xiaosong Wang</dc:creator>
        <description><![CDATA[
            背景：组织病理学全切片图像（WSIs）因高分辨率、大尺寸和复杂图块关系，给大规模医学图像分析带来挑战，现有多实例学习方法存在可扩展性和计算成本问题。方法：提出WSI - GMamba框架，结合图神经网络（GNNs）的关系建模能力和用于序列学习的状态空间模型Mamba的高效性，GMamba块通过双向状态空间模型进行消息传递、图扫描与扁平化及特征聚合。效果：实现了与Transformer相当的性能，浮点运算次数减少7倍，为大规模WSI分析提供可扩展方案，在切片级分类上兼具高精度和计算效率。
            arXiv:2505.17457v1 Announce Type: new 
Abstract: Whole Slide Images (WSIs) in histopathology present a significant challenge for large-scale medical image analysis due to their high resolution, large size, and complex tile relationships. Existing Multiple Instance Learning (MIL) methods, such as Graph Neural Networks (GNNs) and Transformer-based models, face limitations in scalability and computational cost. To bridge this gap, we propose the WSI-GMamba framework, which synergistically combines the relational modeling strengths of GNNs with the efficiency of Mamba, the State Space Model designed for sequence learning. The proposed GMamba block integrates Message Passing, Graph Scanning & Flattening, and feature aggregation via a Bidirectional State Space Model (Bi-SSM), achieving Transformer-level performance with 7* fewer FLOPs. By leveraging the complementary strengths of lightweight GNNs and Mamba, the WSI-GMamba framework delivers a scalable solution for large-scale WSI analysis, offering both high accuracy and computational efficiency for slide-level classification.
        ]]></description>
    </item>
    <item>
        <title>Towards Heterogeneous Continual Graph Learning via Meta-knowledge Distillation</title>
        <link>https://arxiv.org/abs/2505.17458</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17458v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Guiquan Sun, Xikun Zhang, Jingchao Ni, Dongjin Song</dc:creator>
        <description><![CDATA[
            背景：现实世界中的异构图是动态变化的，而现有研究多假设图是静态的，动态特性要求模型在适应新数据时保留现有知识。方法：提出基于元学习的知识蒸馏框架（MKD），结合元学习的快速任务适应和知识蒸馏，引入新采样策略，还添加语义级蒸馏模块。效果：在三个基准数据集上的综合评估验证了MKD在处理不断扩展的异构图持续学习场景中的有效性。
            arXiv:2505.17458v1 Announce Type: new 
Abstract: Machine learning on heterogeneous graphs has experienced rapid advancement in recent years, driven by the inherently heterogeneous nature of real-world data. However, existing studies typically assume the graphs to be static, while real-world graphs are continuously expanding. This dynamic nature requires models to adapt to new data while preserving existing knowledge. To this end, this work addresses the challenge of continual learning on heterogeneous graphs by introducing the Meta-learning based Knowledge Distillation framework (MKD), designed to mitigate catastrophic forgetting in evolving heterogeneous graph structures. MKD combines rapid task adaptation through meta-learning on limited samples with knowledge distillation to achieve an optimal balance between incorporating new information and maintaining existing knowledge. To improve the efficiency and effectiveness of sample selection, MKD incorporates a novel sampling strategy that selects a small number of target-type nodes based on node diversity and maintains fixed-size buffers for other types. The strategy retrieves first-order neighbors along metapaths and selects important neighbors based on their structural relevance, enabling the sampled subgraphs to retain key topological and semantic information. In addition, MKD introduces a semantic-level distillation module that aligns the attention distributions over different metapaths between teacher and student models, encouraging semantic consistency beyond the logit level. Comprehensive evaluations across three benchmark datasets validate MKD's effectiveness in handling continual learning scenarios on expanding heterogeneous graphs.
        ]]></description>
    </item>
    <item>
        <title>Hydra: Structured Cross-Source Enhanced Large Language Model Reasoning</title>
        <link>https://arxiv.org/abs/2505.17464</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17464v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xingyu Tan, Xiaoyang Wang, Qing Liu, Xiwei Xu, Xin Yuan, Liming Zhu, Wenjie Zhang</dc:creator>
        <description><![CDATA[
            背景：当前混合检索增强生成（RAG）系统从知识图谱和文本文档中检索证据支持大语言模型推理，但面临多跳推理、多实体问题、多源验证和有效利用图等挑战。方法：提出无训练框架Hydra，统一图拓扑、文档语义和来源可靠性，通过结合结构化和非结构化检索处理多跳和多实体问题，用三因素跨源验证解决多源验证问题。效果：在七个基准数据集上，Hydra用GPT - 3.5取得最优结果，平均比ToG - 2高20.3%，最高高30.1%，还能让小模型达到与GPT - 4 - Turbo相当的推理性能。
            arXiv:2505.17464v1 Announce Type: new 
Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs) by incorporating external knowledge. Current hybrid RAG system retrieves evidence from both knowledge graphs (KGs) and text documents to support LLM reasoning. However, it faces challenges like handling multi-hop reasoning, multi-entity questions, multi-source verification, and effective graph utilization. To address these limitations, we present Hydra, a training-free framework that unifies graph topology, document semantics, and source reliability to support deep, faithful reasoning in LLMs. Hydra handles multi-hop and multi-entity problems through agent-driven exploration that combines structured and unstructured retrieval, increasing both diversity and precision of evidence. To tackle multi-source verification, Hydra uses a tri-factor cross-source verification (source trustworthiness assessment, cross-source corroboration, and entity-path alignment), to balance topic relevance with cross-modal agreement. By leveraging graph structure, Hydra fuses heterogeneous sources, guides efficient exploration, and prunes noise early. Comprehensive experiments on seven benchmark datasets show that Hydra achieves overall state-of-the-art results on all benchmarks with GPT-3.5, outperforming the strong hybrid baseline ToG-2 by an average of 20.3% and up to 30.1%. Furthermore, Hydra enables smaller models (e.g., Llama-3.1-8B) to achieve reasoning performance comparable to that of GPT-4-Turbo.
        ]]></description>
    </item>
    <item>
        <title>FinRAGBench-V: A Benchmark for Multimodal RAG with Visual Citation in the Financial Domain</title>
        <link>https://arxiv.org/abs/2505.17471</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17471v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Suifeng Zhao, Zhuoran Jin, Sujian Li, Jun Gao</dc:creator>
        <description><![CDATA[
            背景：金融领域的检索增强生成（RAG）多聚焦文本数据，忽略了金融文档中的视觉内容。方法：提出金融领域多模态RAG基准FinRAGBench - V，整合多模态数据并提供可视化引用，含中英双语检索语料和高质量问答数据集；引入RGenCite作为RAG基线，提出自动引用评估方法。效果：对RGenCite的大量实验凸显了FinRAGBench - V的挑战性，为金融多模态RAG系统发展提供有价值见解。 
            arXiv:2505.17471v1 Announce Type: new 
Abstract: Retrieval-Augmented Generation (RAG) plays a vital role in the financial domain, powering applications such as real-time market analysis, trend forecasting, and interest rate computation. However, most existing RAG research in finance focuses predominantly on textual data, overlooking the rich visual content in financial documents, resulting in the loss of key analytical insights. To bridge this gap, we present FinRAGBench-V, a comprehensive visual RAG benchmark tailored for finance which effectively integrates multimodal data and provides visual citation to ensure traceability. It includes a bilingual retrieval corpus with 60,780 Chinese and 51,219 English pages, along with a high-quality, human-annotated question-answering (QA) dataset spanning heterogeneous data types and seven question categories. Moreover, we introduce RGenCite, an RAG baseline that seamlessly integrates visual citation with generation. Furthermore, we propose an automatic citation evaluation method to systematically assess the visual citation capabilities of Multimodal Large Language Models (MLLMs). Extensive experiments on RGenCite underscore the challenging nature of FinRAGBench-V, providing valuable insights for the development of multimodal RAG systems in finance.
        ]]></description>
    </item>
    <item>
        <title>CReSt: A Comprehensive Benchmark for Retrieval-Augmented Generation with Complex Reasoning over Structured Documents</title>
        <link>https://arxiv.org/abs/2505.17503</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17503v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Minsoo Khang, Sangjun Park, Teakgyu Hong, Dawoon Jung</dc:creator>
        <description><![CDATA[
            背景：大语言模型在检索增强生成（RAG）场景的评估存在挑战，实际应用要求模型具备复杂推理等能力，缺乏统一评估框架。方法：提出CReSt基准，含2245个英韩人工标注示例，模拟需对结构化文档复杂推理的RAG场景，还引入定制评估方法。效果：评估显示，即使先进大模型在多维度表现不稳定，凸显改进方向。数据集和代码见https://github.com/UpstageAI/CReSt。
            arXiv:2505.17503v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have made substantial progress in recent years, yet evaluating their capabilities in practical Retrieval-Augmented Generation (RAG) scenarios remains challenging. In practical applications, LLMs must demonstrate complex reasoning, refuse to answer appropriately, provide precise citations, and effectively understand document layout. These capabilities are crucial for advanced task handling, uncertainty awareness, maintaining reliability, and structural understanding. While some of the prior works address these aspects individually, there is a need for a unified framework that evaluates them collectively in practical RAG scenarios. To address this, we present CReSt (A Comprehensive Benchmark for Retrieval-Augmented Generation with Complex Reasoning over Structured Documents), a benchmark designed to assess these key dimensions holistically. CReSt comprises 2,245 human-annotated examples in English and Korean, designed to capture practical RAG scenarios that require complex reasoning over structured documents. It also introduces a tailored evaluation methodology to comprehensively assess model performance in these critical areas. Our evaluation shows that even advanced LLMs struggle to perform consistently across these dimensions, underscoring key areas for improvement. We release CReSt to support further research and the development of more robust RAG systems. The dataset and code are available at: https://github.com/UpstageAI/CReSt.
        ]]></description>
    </item>
    <item>
        <title>Multimodal Conversation Structure Understanding</title>
        <link>https://arxiv.org/abs/2505.17536</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17536v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kent K. Chang, Mackenzie Hanh Cramer, Anna Ho, Ti Ti Nguyen, Yilin Yuan, David Bamman</dc:creator>
        <description><![CDATA[
            背景：大语言模型在对话和推理方面能力出色，但在多模态、多方场景下对细粒度对话结构的理解能力研究不足。方法：提出聚焦对话角色归属和对话线程的任务集，构建含4398条说话者及回复关系、5755条受话者、3142条旁听者标注的数据集，在数据集上评估音视频大模型和视觉语言模型。效果：多模态对话结构理解仍具挑战，表现最佳的音视频大模型各指标均优于视觉语言模型，参与者匿名时性能显著下降，参与者数量与角色归属性能负相关，声学清晰度和人脸覆盖率正相关。
            arXiv:2505.17536v1 Announce Type: new 
Abstract: Conversations are usually structured by roles -- who is speaking, who's being addressed, and who's listening -- and unfold in threads that break with changes in speaker floor or topical focus. While large language models (LLMs) have shown incredible capabilities in dialogue and reasoning, their ability to understand fine-grained conversational structure, especially in multi-modal, multi-party settings, remains underexplored. To address this gap, we introduce a suite of tasks focused on conversational role attribution (speaker, addressees, side-participants) and conversation threading (utterance linking and clustering), drawing on conversation analysis and sociolinguistics. To support those tasks, we present a human annotated dataset of 4,398 annotations for speakers and reply-to relationship, 5,755 addressees, and 3,142 side-participants.
  We evaluate popular audio-visual LLMs and vision-language models on our dataset, and our experimental results suggest that multimodal conversational structure understanding remains challenging. The most performant audio-visual LLM outperforms all vision-language models across all metrics, especially in speaker and addressee recognition. However, its performance drops significantly when conversation participants are anonymized. The number of conversation participants in a clip is the strongest negative predictor of role-attribution performance, while acoustic clarity (measured by pitch and spectral centroid) and detected face coverage yield positive associations. We hope this work lays the groundwork for future evaluation and development of multimodal LLMs that can reason more effectively about conversation structure.
        ]]></description>
    </item>
    <item>
        <title>Graph Style Transfer for Counterfactual Explainability</title>
        <link>https://arxiv.org/abs/2505.17542</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17542v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Bardh Prenkaj, Efstratios Zaradoukas, Gjergji Kasneci</dc:creator>
        <description><![CDATA[
            背景：反事实可解释性旨在通过改变输入来揭示模型决策，对图数据而言，因需保留结构完整性和语义信息，该任务极具挑战。方法：提出图逆风格迁移（GIST）框架，将图反事实生成视为回溯过程，利用谱风格迁移，使全局结构与原输入谱对齐并保留局部内容忠实性。效果：在8个图分类基准测试中，生成反事实的有效性提升7.6%，解释真实类别分布的忠实度提升45.5%，还能减少与输入的谱差异，为图可解释性研究提供新视角。
            arXiv:2505.17542v1 Announce Type: new 
Abstract: Counterfactual explainability seeks to uncover model decisions by identifying minimal changes to the input that alter the predicted outcome. This task becomes particularly challenging for graph data due to preserving structural integrity and semantic meaning. Unlike prior approaches that rely on forward perturbation mechanisms, we introduce Graph Inverse Style Transfer (GIST), the first framework to re-imagine graph counterfactual generation as a backtracking process, leveraging spectral style transfer. By aligning the global structure with the original input spectrum and preserving local content faithfulness, GIST produces valid counterfactuals as interpolations between the input style and counterfactual content. Tested on 8 binary and multi-class graph classification benchmarks, GIST achieves a remarkable +7.6% improvement in the validity of produced counterfactuals and significant gains (+45.5%) in faithfully explaining the true class distribution. Additionally, GIST's backtracking mechanism effectively mitigates overshooting the underlying predictor's decision boundary, minimizing the spectral differences between the input and the counterfactuals. These results challenge traditional forward perturbation methods, offering a novel perspective that advances graph explainability.
        ]]></description>
    </item>
    <item>
        <title>PPT: A Process-based Preference Learning Framework for Self Improving Table Question Answering Models</title>
        <link>https://arxiv.org/abs/2505.17565</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17565v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wei Zhou, Mohsen Mesgar, Heike Adel, Annemarie Friedrich</dc:creator>
        <description><![CDATA[
            背景：用自生成数据改进大语言模型在数学推理和代码生成等任务已获成功，但在基于表格数据回答问题的表格问答（TQA）任务中尚未探索。方法：提出基于过程的偏好学习框架PPT，将推理链分解为离散状态，为每个状态打分，并采样对比步骤进行偏好学习。效果：仅用8000个偏好对，PPT能使TQA模型在领域内数据集上提升最多5%，领域外数据集上提升2.4%，推理效率是更复杂的先进TQA系统的5倍。
            arXiv:2505.17565v1 Announce Type: new 
Abstract: Improving large language models (LLMs) with self-generated data has demonstrated success in tasks such as mathematical reasoning and code generation. Yet, no exploration has been made on table question answering (TQA), where a system answers questions based on tabular data. Addressing this gap is crucial for TQA, as effective self-improvement can boost performance without requiring costly or manually annotated data. In this work, we propose PPT, a Process-based Preference learning framework for TQA. It decomposes reasoning chains into discrete states, assigns scores to each state, and samples contrastive steps for preference learning. Experimental results show that PPT effectively improves TQA models by up to 5% on in-domain datasets and 2.4% on out-of-domain datasets, with only 8,000 preference pairs. Furthermore, the resulting models achieve competitive results compared to more complex and larger state-of-the-art TQA systems, while being five times more efficient during inference.
        ]]></description>
    </item>
    <item>
        <title>Dynamic Text Bundling Supervision for Zero-Shot Inference on Text-Attributed Graphs</title>
        <link>https://arxiv.org/abs/2505.17599</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17599v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yusheng Zhao, Qixin Zhang, Xiao Luo, Weizhi Zhang, Zhiping Xiao, Wei Ju, Philip S. Yu, Ming Zhang</dc:creator>
        <description><![CDATA[
            背景：大语言模型用于文本属性图的零样本学习时，面临图结构信息有限和响应不可靠的挑战。方法：提出动态文本捆绑监督（DENSE）方法，通过文本捆绑查询大语言模型获取捆绑级标签，用这些标签监督图神经网络。具体是采样节点文本形成捆绑，查询大语言模型得到标签，用标签监督图神经网络优化并精炼捆绑。还进行了理论分析。效果：在十个数据集上的实验验证了该方法的有效性。
            arXiv:2505.17599v1 Announce Type: new 
Abstract: Large language models (LLMs) have been used in many zero-shot learning problems, with their strong generalization ability. Recently, adopting LLMs in text-attributed graphs (TAGs) has drawn increasing attention. However, the adoption of LLMs faces two major challenges: limited information on graph structure and unreliable responses. LLMs struggle with text attributes isolated from the graph topology. Worse still, they yield unreliable predictions due to both information insufficiency and the inherent weakness of LLMs (e.g., hallucination). Towards this end, this paper proposes a novel method named Dynamic Text Bundling Supervision (DENSE) that queries LLMs with bundles of texts to obtain bundle-level labels and uses these labels to supervise graph neural networks. Specifically, we sample a set of bundles, each containing a set of nodes with corresponding texts of close proximity. We then query LLMs with the bundled texts to obtain the label of each bundle. Subsequently, the bundle labels are used to supervise the optimization of graph neural networks, and the bundles are further refined to exclude noisy items. To justify our design, we also provide theoretical analysis of the proposed method. Extensive experiments across ten datasets validate the effectiveness of the proposed method.
        ]]></description>
    </item>
    <item>
        <title>Navigate the Unknown: Enhancing LLM Reasoning with Intrinsic Motivation Guided Exploration</title>
        <link>https://arxiv.org/abs/2505.17621</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17621v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jingtong Gao, Ling Pan, Yejing Wang, Rui Zhong, Chi Lu, Qingpeng Cai, Peng Jiang, Xiangyu Zhao</dc:creator>
        <description><![CDATA[
            背景：强化学习用于提升大语言模型推理能力，但现有方法依赖稀疏奖励、缺乏探索激励机制，影响多步推理引导。方法：提出i - MENTOR方法，引入轨迹感知探索奖励、动态奖励缩放和优势保留奖励实现，在强化学习训练范式中提供密集奖励并增强探索。效果：在三个公开数据集实验中表现有效，在困难数据集Countdown - 4上提升22.39%。
            arXiv:2505.17621v1 Announce Type: new 
Abstract: Reinforcement learning (RL) has emerged as a pivotal method for improving the reasoning capabilities of Large Language Models (LLMs). However, prevalent RL approaches such as Proximal Policy Optimization (PPO) and Group-Regularized Policy Optimization (GRPO) face critical limitations due to their reliance on sparse outcome-based rewards and inadequate mechanisms for incentivizing exploration. These limitations result in inefficient guidance for multi-step reasoning processes. Specifically, sparse reward signals fail to deliver effective or sufficient feedback, particularly for challenging problems. Furthermore, such reward structures induce systematic biases that prioritize exploitation of familiar trajectories over novel solution discovery. These shortcomings critically hinder performance in complex reasoning tasks, which inherently demand iterative refinement across ipntermediate steps. To address these challenges, we propose an Intrinsic Motivation guidEd exploratioN meThOd foR LLM Reasoning (i-MENTOR), a novel method designed to both deliver dense rewards and amplify explorations in the RL-based training paradigm. i-MENTOR introduces three key innovations: trajectory-aware exploration rewards that mitigate bias in token-level strategies while maintaining computational efficiency; dynamic reward scaling to stabilize exploration and exploitation in large action spaces; and advantage-preserving reward implementation that maintains advantage distribution integrity while incorporating exploratory guidance. Experiments across three public datasets demonstrate i-MENTOR's effectiveness with a 22.39% improvement on the difficult dataset Countdown-4.
        ]]></description>
    </item>
    <item>
        <title>Enhancing Large Vision-Language Models with Layout Modality for Table Question Answering on Japanese Annual Securities Reports</title>
        <link>https://arxiv.org/abs/2505.17625</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17625v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hayato Aida, Kosuke Takahashi, Takahiro Omi</dc:creator>
        <description><![CDATA[
            背景：随着大语言模型和检索增强生成的发展，理解表格结构能力愈发重要，尤其在金融领域，但表格格式多样，提取结构信息难，现有多模态大视觉语言模型理解文档字符及空间关系有挑战。方法：提出结合表格内文本内容和布局特征增强基于大视觉语言模型的表格理解。效果：实验表明，这些辅助模态显著提升性能，无需依赖显式结构化输入格式，就能对复杂文档布局进行稳健解读。
            arXiv:2505.17625v1 Announce Type: new 
Abstract: With recent advancements in Large Language Models (LLMs) and growing interest in retrieval-augmented generation (RAG), the ability to understand table structures has become increasingly important. This is especially critical in financial domains such as securities reports, where highly accurate question answering (QA) over tables is required. However, tables exist in various formats-including HTML, images, and plain text-making it difficult to preserve and extract structural information. Therefore, multimodal LLMs are essential for robust and general-purpose table understanding. Despite their promise, current Large Vision-Language Models (LVLMs), which are major representatives of multimodal LLMs, still face challenges in accurately understanding characters and their spatial relationships within documents. In this study, we propose a method to enhance LVLM-based table understanding by incorporating in-table textual content and layout features. Experimental results demonstrate that these auxiliary modalities significantly improve performance, enabling robust interpretation of complex document layouts without relying on explicitly structured input formats.
        ]]></description>
    </item>
    <item>
        <title>Causal Spatio-Temporal Prediction: An Effective and Efficient Multi-Modal Approach</title>
        <link>https://arxiv.org/abs/2505.17637</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17637v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuting Huang, Ziquan Fang, Zhihao Zeng, Lu Chen, Yunjun Gao</dc:creator>
        <description><![CDATA[
            时空预测在多领域至关重要，当前多模态数据融合存在信息融合不足、因果关系受干扰、计算复杂度高等问题。为此，论文提出E^2 - CSTP框架，利用跨模态注意力和门控机制融合多模态数据，设计双分支因果推理方法，还结合GCN与Mamba架构加速时空编码。在4个真实数据集上的实验表明，该框架显著优于9种先进方法，准确率最高提升9.66%，计算开销降低17.37% - 56.11%。
            arXiv:2505.17637v1 Announce Type: new 
Abstract: Spatio-temporal prediction plays a crucial role in intelligent transportation, weather forecasting, and urban planning. While integrating multi-modal data has shown potential for enhancing prediction accuracy, key challenges persist: (i) inadequate fusion of multi-modal information, (ii) confounding factors that obscure causal relations, and (iii) high computational complexity of prediction models. To address these challenges, we propose E^2-CSTP, an Effective and Efficient Causal multi-modal Spatio-Temporal Prediction framework. E^2-CSTP leverages cross-modal attention and gating mechanisms to effectively integrate multi-modal data. Building on this, we design a dual-branch causal inference approach: the primary branch focuses on spatio-temporal prediction, while the auxiliary branch mitigates bias by modeling additional modalities and applying causal interventions to uncover true causal dependencies. To improve model efficiency, we integrate GCN with the Mamba architecture for accelerated spatio-temporal encoding. Extensive experiments on 4 real-world datasets show that E^2-CSTP significantly outperforms 9 state-of-the-art methods, achieving up to 9.66% improvements in accuracy as well as 17.37%-56.11% reductions in computational overhead.
        ]]></description>
    </item>
    <item>
        <title>A Network Science Approach to Granular Time Series Segmentation</title>
        <link>https://arxiv.org/abs/2505.17640</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17640v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ivana Kesi\'c, Carolina Fortuna, Mihael Mohor\v{c}i\v{c}, Bla\v{z} Bertalani\v{c}</dc:creator>
        <description><![CDATA[
            时间序列分割（TSS）受关注较少，现有深度学习方法因依赖滑动窗口限制了分割粒度。为此，论文提出更精细的TSS方法，将时间序列转化为加权双视角可见性图（WDPVG），并结合图注意力网络（GAT）。通过将时间序列转化为图，捕捉数据隐藏的结构信息，利用图神经网络的表征学习能力识别有意义的片段。实验表明，该方法在59个TSS基准数据集上平均F1分数达0.97，比基线方法高0.05，且减少了训练数据需求。
            arXiv:2505.17640v1 Announce Type: new 
Abstract: Time series segmentation (TSS) is one of the time series (TS) analysis techniques, that has received considerably less attention compared to other TS related tasks. In recent years, deep learning architectures have been introduced for TSS, however their reliance on sliding windows limits segmentation granularity due to fixed window sizes and strides. To overcome these challenges, we propose a new more granular TSS approach that utilizes the Weighted Dual Perspective Visbility Graph (WDPVG) TS into a graph and combines it with a Graph Attention Network (GAT). By transforming TS into graphs, we are able to capture different structural aspects of the data that would otherwise remain hidden. By utilizing the representation learning capabilities of Graph Neural Networks, our method is able to effectively identify meaningful segments within the TS. To better understand the potential of our approach, we also experimented with different TS-to-graph transformations and compared their performance. Our contributions include: a) formulating the TSS as a node classification problem on graphs; b) conducting an extensive analysis of various TS- to-graph transformations applied to TSS using benchmark datasets from the TSSB repository; c) providing the first detailed study on utilizing GNNs for analyzing graph representations of TS in the context of TSS; d) demonstrating the effectiveness of our method, which achieves an average F1 score of 0.97 across 59 diverse TSS benchmark datasets; e) outperforming the seq2point baseline method by 0.05 in terms of F1 score; and f) reducing the required training data compared to the baseline methods.
        ]]></description>
    </item>
    <item>
        <title>Bridging Electronic Health Records and Clinical Texts: Contrastive Learning for Enhanced Clinical Tasks</title>
        <link>https://arxiv.org/abs/2505.17643</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17643v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sara Ketabi, Dhanesh Ramachandram</dc:creator>
        <description><![CDATA[
            背景：传统机器学习模型处理电子健康记录（EHR）数据时，在需深度上下文理解的任务上表现不佳，因结构化EHR数据语义信息有限。方法：提出深度多模态对比学习（CL）框架，将结构化EHR数据与非结构化出院小结笔记的潜在表示对齐，拉近配对的EHR和文本嵌入，推远未配对的。效果：微调从该框架提取的预训练EHR编码器，显著提升下游任务性能，如30天再入院预测的AUROC比XGBoost提高4.1%。
            arXiv:2505.17643v1 Announce Type: new 
Abstract: Conventional machine learning models, particularly tree-based approaches, have demonstrated promising performance across various clinical prediction tasks using electronic health record (EHR) data. Despite their strengths, these models struggle with tasks that require deeper contextual understanding, such as predicting 30-day hospital readmission. This can be primarily due to the limited semantic information available in structured EHR data. To address this limitation, we propose a deep multimodal contrastive learning (CL) framework that aligns the latent representations of structured EHR data with unstructured discharge summary notes. It works by pulling together paired EHR and text embeddings while pushing apart unpaired ones. Fine-tuning the pretrained EHR encoder extracted from this framework significantly boosts downstream task performance, e.g., a 4.1% AUROC enhancement over XGBoost for 30-day readmission prediction. Such results demonstrate the effect of integrating domain knowledge from clinical notes into EHR-based pipelines, enabling more accurate and context-aware clinical decision support systems.
        ]]></description>
    </item>
    <item>
        <title>DAM-GT: Dual Positional Encoding-Based Attention Masking Graph Transformer for Node Classification</title>
        <link>https://arxiv.org/abs/2505.17660</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17660v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chenyang Li, Jinsong Chen, John E. Hopcroft, Kun He</dc:creator>
        <description><![CDATA[
            现有邻域感知的图Transformer在节点分类任务中存在不足，一是当前邻域标记生成方法难以充分捕捉邻域内属性关联，二是传统自注意力机制处理邻域标记时会出现注意力分散问题。为此提出DAM - GT，引入结合属性聚类策略的双位置编码方案，有效保留节点在拓扑和属性空间的相关性；制定带掩码策略的新注意力机制，克服注意力分散问题。在不同同质性和规模的图上实验表明，DAM - GT在节点分类任务上始终优于现有方法。
            arXiv:2505.17660v1 Announce Type: new 
Abstract: Neighborhood-aware tokenized graph Transformers have recently shown great potential for node classification tasks. Despite their effectiveness, our in-depth analysis of neighborhood tokens reveals two critical limitations in the existing paradigm. First, current neighborhood token generation methods fail to adequately capture attribute correlations within a neighborhood. Second, the conventional self-attention mechanism suffers from attention diversion when processing neighborhood tokens, where high-hop neighborhoods receive disproportionate focus, severely disrupting information interactions between the target node and its neighborhood tokens. To address these challenges, we propose DAM-GT, Dual positional encoding-based Attention Masking graph Transformer. DAM-GT introduces a novel dual positional encoding scheme that incorporates attribute-aware encoding via an attribute clustering strategy, effectively preserving node correlations in both topological and attribute spaces. In addition, DAM-GT formulates a new attention mechanism with a simple yet effective masking strategy to guide interactions between target nodes and their neighborhood tokens, overcoming the issue of attention diversion. Extensive experiments on various graphs with different homophily levels as well as different scales demonstrate that DAM-GT consistently outperforms state-of-the-art methods in node classification tasks.
        ]]></description>
    </item>
    <item>
        <title>FutureSightDrive: Thinking Visually with Spatio-Temporal CoT for Autonomous Driving</title>
        <link>https://arxiv.org/abs/2505.17685</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17685v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Shuang Zeng, Xinyuan Chang, Mengwei Xie, Xinran Liu, Yifan Bai, Zheng Pan, Mu Xu, Xing Wei</dc:creator>
        <description><![CDATA[
            背景：视觉语言模型（VLMs）因强大推理能力在自动驾驶领域受关注，但现有VLMs使用离散文本思维链，会导致时空关系模糊和细粒度信息丢失。方法：提出时空思维链推理方法，让模型进行视觉思考，用VLM生成统一图像帧预测未来世界状态，时空思维链作为中间推理步骤；还提出整合视觉生成与理解的预训练范式及渐进式视觉思维链增强自回归图像生成。效果：实验表明该方法有效，推动自动驾驶迈向视觉推理。
            arXiv:2505.17685v1 Announce Type: new 
Abstract: Visual language models (VLMs) have attracted increasing interest in autonomous driving due to their powerful reasoning capabilities. However, existing VLMs typically utilize discrete text Chain-of-Thought (CoT) tailored to the current scenario, which essentially represents highly abstract and symbolic compression of visual information, potentially leading to spatio-temporal relationship ambiguity and fine-grained information loss. Is autonomous driving better modeled on real-world simulation and imagination than on pure symbolic logic? In this paper, we propose a spatio-temporal CoT reasoning method that enables models to think visually. First, VLM serves as a world model to generate unified image frame for predicting future world states: where perception results (e.g., lane divider and 3D detection) represent the future spatial relationships, and ordinary future frame represent the temporal evolution relationships. This spatio-temporal CoT then serves as intermediate reasoning steps, enabling the VLM to function as an inverse dynamics model for trajectory planning based on current observations and future predictions. To implement visual generation in VLMs, we propose a unified pretraining paradigm integrating visual generation and understanding, along with a progressive visual CoT enhancing autoregressive image generation. Extensive experimental results demonstrate the effectiveness of the proposed method, advancing autonomous driving towards visual reasoning.
        ]]></description>
    </item>
    <item>
        <title>ELSPR: Evaluator LLM Training Data Self-Purification on Non-Transitive Preferences via Tournament Graph Reconstruction</title>
        <link>https://arxiv.org/abs/2505.17691</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17691v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yan Yu, Yilun Liu, Minggui He, Shimin Tao, Weibin Meng, Xinhua Yang, Li Zhang, Hongxia Ma, Chang Su, Hao Yang, Fuliang Li</dc:creator>
        <description><![CDATA[
            背景：大语言模型作评估器时，成对比较的非传递性问题未解决，低质量训练数据会降低评估器偏好的传递性。方法：提出图论框架，将成对偏好建模为竞赛图，量化非传递性并引入有向图结构熵，设计过滤策略ELSPR消除诱导非传递性的偏好数据。效果：经过滤数据微调的模型，非传递性降低13.78%，结构熵降低0.0879，与人类评估者更一致，人类同意率提高0.6%，斯皮尔曼相关性增加0.01。
            arXiv:2505.17691v1 Announce Type: new 
Abstract: Large language models (LLMs) are widely used as evaluators for open-ended tasks, while previous research has emphasized biases in LLM evaluations, the issue of non-transitivity in pairwise comparisons remains unresolved: non-transitive preferences for pairwise comparisons, where evaluators prefer A over B, B over C, but C over A. Our results suggest that low-quality training data may reduce the transitivity of preferences generated by the Evaluator LLM. To address this, We propose a graph-theoretic framework to analyze and mitigate this problem by modeling pairwise preferences as tournament graphs. We quantify non-transitivity and introduce directed graph structural entropy to measure the overall clarity of preferences. Our analysis reveals significant non-transitivity in advanced Evaluator LLMs (with Qwen2.5-Max exhibiting 67.96%), as well as high entropy values (0.8095 for Qwen2.5-Max), reflecting low overall clarity of preferences. To address this issue, we designed a filtering strategy, ELSPR, to eliminate preference data that induces non-transitivity, retaining only consistent and transitive preference data for model fine-tuning. Experiments demonstrate that models fine-tuned with filtered data reduce non-transitivity by 13.78% (from 64.28% to 50.50%), decrease structural entropy by 0.0879 (from 0.8113 to 0.7234), and align more closely with human evaluators (human agreement rate improves by 0.6% and Spearman correlation increases by 0.01).
        ]]></description>
    </item>
    <item>
        <title>Activation Control for Efficiently Eliciting Long Chain-of-thought Ability of Language Models</title>
        <link>https://arxiv.org/abs/2505.17697</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17697v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zekai Zhao, Qi Liu, Kun Zhou, Zihan Liu, Yifei Shao, Zhiting Hu, Biwei Huang</dc:creator>
        <description><![CDATA[
            背景：激发大语言模型的长思维链能力通常需高成本的强化学习或高质量蒸馏数据的监督微调。方法：研究发现模型后几层的少量高影响激活很大程度决定长推理属性，通过放大这些激活并插入“等待”标记，可在无需训练下激发长思维链能力；还引入无训练激活控制技术，利用对比示例识别关键激活，推理时用解析函数调节其值。效果：显著提高自反思率和准确率，参数高效微调方法在推理基准上以更少参数超越全LoRA微调。
            arXiv:2505.17697v1 Announce Type: new 
Abstract: Despite the remarkable reasoning performance, eliciting the long chain-of-thought (CoT) ability in large language models (LLMs) typically requires costly reinforcement learning or supervised fine-tuning on high-quality distilled data. We investigate the internal mechanisms behind this capability and show that a small set of high-impact activations in the last few layers largely governs long-form reasoning attributes, such as output length and self-reflection. By simply amplifying these activations and inserting "wait" tokens, we can invoke the long CoT ability without any training, resulting in significantly increased self-reflection rates and accuracy. Moreover, we find that the activation dynamics follow predictable trajectories, with a sharp rise after special tokens and a subsequent exponential decay. Building on these insights, we introduce a general training-free activation control technique. It leverages a few contrastive examples to identify key activations, and employs simple analytic functions to modulate their values at inference time to elicit long CoTs. Extensive experiments confirm the effectiveness of our method in efficiently eliciting long CoT reasoning in LLMs and improving their performance. Additionally, we propose a parameter-efficient fine-tuning method that trains only a last-layer activation amplification module and a few LoRA layers, outperforming full LoRA fine-tuning on reasoning benchmarks with significantly fewer parameters. Our code and data are publicly released.
        ]]></description>
    </item>
    <item>
        <title>Seek-CAD: A Self-refined Generative Modeling for 3D Parametric CAD Using Local Inference via DeepSeek</title>
        <link>https://arxiv.org/abs/2505.17702</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17702v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xueyang Li, Jiahao Li, Yu Song, Yunzhong Lou, Xiangdong Zhou</dc:creator>
        <description><![CDATA[
            背景：CAD生成式建模发展至大语言模型领域，但顶级闭源大模型成本高、本地部署受限。方法：Seek - CAD采用免训练方法，利用本地部署的开源推理大模型DeepSeek - R1生成CAD参数化模型，在自优化机制中引入视觉和思维链反馈，将初始生成模型渲染成图像，结合思维链由视觉语言模型评估，反馈给DeepSeek - R1进行优化；还提出基于SSR范式的3D CAD模型数据集。效果：大量实验验证了Seek - CAD在多种指标下的有效性。
            arXiv:2505.17702v1 Announce Type: new 
Abstract: The advent of Computer-Aided Design (CAD) generative modeling will significantly transform the design of industrial products. The recent research endeavor has extended into the realm of Large Language Models (LLMs). In contrast to fine-tuning methods, training-free approaches typically utilize the advanced closed-source LLMs, thereby offering enhanced flexibility and efficiency in the development of AI agents for generating CAD parametric models. However, the substantial cost and limitations of local deployment of the top-tier closed-source LLMs pose challenges in practical applications. The Seek-CAD is the pioneer exploration of locally deployed open-source inference LLM DeepSeek-R1 for CAD parametric model generation with a training-free methodology. This study is the first investigation to incorporate both visual and Chain-of-Thought (CoT) feedback within the self-refinement mechanism for generating CAD models. Specifically, the initial generated parametric CAD model is rendered into a sequence of step-wise perspective images, which are subsequently processed by a Vision Language Model (VLM) alongside the corresponding CoTs derived from DeepSeek-R1 to assess the CAD model generation. Then, the feedback is utilized by DeepSeek-R1 to refine the initial generated model for the next round of generation. Moreover, we present an innovative 3D CAD model dataset structured around the SSR (Sketch, Sketch-based feature, and Refinements) triple design paradigm. This dataset encompasses a wide range of CAD commands, thereby aligning effectively with industrial application requirements and proving suitable for the generation of LLMs. Extensive experiments validate the effectiveness of Seek-CAD under various metrics.
        ]]></description>
    </item>
    <item>
        <title>Slot-MLLM: Object-Centric Visual Tokenization for Multimodal LLM</title>
        <link>https://arxiv.org/abs/2505.17726</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17726v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Donghwan Chi, Hyomin Kim, Yoonjin Oh, Yongjin Kim, Donghoon Lee, Daejin Jo, Jongmin Kim, Junyeob Baek, Sungjin Ahn, Sungwoong Kim</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型是实现通用人工智能的关键，但现有的图像标记方法限制了模型理解和生成详细视觉内容的能力。方法：提出基于槽注意力的以对象为中心的视觉标记器，基于Q - Former编码器、扩散解码器和残差向量量化，生成的离散槽标记能编码局部视觉细节并保持高层语义，还可与文本数据对齐。效果：在各种需要局部细节理解和生成的视觉语言任务中，Slot - MLLM比使用先前视觉标记器的基线模型有显著性能提升。
            arXiv:2505.17726v1 Announce Type: new 
Abstract: Recently, multimodal large language models (MLLMs) have emerged as a key approach in achieving artificial general intelligence. In particular, vision-language MLLMs have been developed to generate not only text but also visual outputs from multimodal inputs. This advancement requires efficient image tokens that LLMs can process effectively both in input and output. However, existing image tokenization methods for MLLMs typically capture only global abstract concepts or uniformly segmented image patches, restricting MLLMs' capability to effectively understand or generate detailed visual content, particularly at the object level. To address this limitation, we propose an object-centric visual tokenizer based on Slot Attention specifically for MLLMs. In particular, based on the Q-Former encoder, diffusion decoder, and residual vector quantization, our proposed discretized slot tokens can encode local visual details while maintaining high-level semantics, and also align with textual data to be integrated seamlessly within a unified next-token prediction framework of LLMs. The resulting Slot-MLLM demonstrates significant performance improvements over baselines with previous visual tokenizers across various vision-language tasks that entail local detailed comprehension and generation. Notably, this work is the first demonstration of the feasibility of object-centric slot attention performed with MLLMs and in-the-wild natural images.
        ]]></description>
    </item>
    <item>
        <title>Fast Quiet-STaR: Thinking Without Thought Tokens</title>
        <link>https://arxiv.org/abs/2505.17746</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17746v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wei Huang, Yizhe Xiong, Xin Ye, Zhijie Deng, Hui Chen, Zijia Lin, Guiguang Ding</dc:creator>
        <description><![CDATA[
            背景：大语言模型在自然语言处理任务表现出色，但复杂推理任务仅靠扩大模型规模和数据量不够，Quiet STaR虽提升推理能力但有推理开销。方法：提出Fast Quiet STaR，采用基于课程学习的训练策略减少思考令牌数量，还通过强化学习微调扩展到标准NTP设置得到Fast Quiet - STaR NTP。效果：在四个基准数据集上，Fast Quiet - STaR在相同推理时间内平均准确率超Quiet - STaR，Fast Quiet - STaR NTP在Mistral 7B和Qwen2.5 7B上平均准确率分别提升9%和5.7%，且推理延迟不变。
            arXiv:2505.17746v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have achieved impressive performance across a range of natural language processing tasks. However, recent advances demonstrate that further gains particularly in complex reasoning tasks require more than merely scaling up model sizes or training data. One promising direction is to enable models to think during the reasoning process. Recently, Quiet STaR significantly improves reasoning by generating token-level thought traces, but incurs substantial inference overhead. In this work, we propose Fast Quiet STaR, a more efficient reasoning framework that preserves the benefits of token-level reasoning while reducing computational cost. Our method introduces a curriculum learning based training strategy that gradually reduces the number of thought tokens, enabling the model to internalize more abstract and concise reasoning processes. We further extend this approach to the standard Next Token Prediction (NTP) setting through reinforcement learning-based fine-tuning, resulting in Fast Quiet-STaR NTP, which eliminates the need for explicit thought token generation during inference. Experiments on four benchmark datasets with Mistral 7B and Qwen2.5 7B demonstrate that Fast Quiet-STaR consistently outperforms Quiet-STaR in terms of average accuracy under the same inference time budget. Notably, Fast Quiet-STaR NTP achieves an average accuracy improvement of 9\% on Mistral 7B and 5.7\% on Qwen2.5 7B, while maintaining the same inference latency. Our code will be available at https://github.com/huangwei200012/Fast-Quiet-STaR.
        ]]></description>
    </item>
    <item>
        <title>Structured Linear CDEs: Maximally Expressive and Parallel-in-Time Sequence Models</title>
        <link>https://arxiv.org/abs/2505.17761</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17761v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Benjamin Walker, Lingyi Yang, Nicola Muca Cirone, Cristopher Salvi, Terry Lyons</dc:creator>
        <description><![CDATA[
            背景：现有序列模型在计算效率和表达能力上存在挑战。方法：提出结构化线性受控微分方程（SLiCEs）框架，包含多种架构及基于稀疏性和沃尔什 - 哈达玛变换的新变体，其状态转移矩阵结构在保持稠密矩阵最大表达能力的同时降低计算成本。效果：SLiCEs单层即可解决$A_5$状态跟踪基准问题，在并行时间模型中对正则语言任务的长度泛化表现最佳，在六个多元时间序列分类数据集上达到对数神经受控微分方程的最优性能，且训练步平均时间缩短至二十分之一。
            arXiv:2505.17761v1 Announce Type: new 
Abstract: Structured Linear Controlled Differential Equations (SLiCEs) provide a unifying framework for sequence models with structured, input-dependent state-transition matrices that retain the maximal expressivity of dense matrices whilst being cheaper to compute. The framework encompasses existing architectures, such as input-dependent block-diagonal linear recurrent neural networks and DeltaNet's diagonal-plus-low-rank structure, as well as two novel variants based on sparsity and the Walsh--Hadamard transform. We prove that, unlike the diagonal state-transition matrices of S4 and Mamba, SLiCEs employing block-diagonal, sparse, or Walsh--Hadamard matrices match the maximal expressivity of dense matrices. Empirically, SLiCEs solve the $A_5$ state-tracking benchmark with a single layer, achieve best-in-class length generalisation on regular language tasks among parallel-in-time models, and match the state-of-the-art performance of log neural controlled differential equations on six multivariate time-series classification datasets while cutting the average time per training step by a factor of twenty.
        ]]></description>
    </item>
    <item>
        <title>Dynamic Graph Embedding through Hub-aware Random Walks</title>
        <link>https://arxiv.org/abs/2505.17764</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17764v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Aleksandar Tom\v{c}i\'c, Milo\v{s} Savi\'c, Du\v{s}an Simi\'c, Milo\v{s} Radovanovi\'c</dc:creator>
        <description><![CDATA[
            背景：在动态图嵌入中，高度节点（枢纽）的影响未得到充分研究，现有基于随机游走的图表示学习方法常忽略枢纽对游走轨迹和嵌入稳定性的影响。方法：提出DeepHub方法，将枢纽敏感性融入随机游走采样策略，以dynnode2vec为代表方法，在九个真实时间网络中系统分析枢纽偏置游走的效果。效果：标准随机游走会过度表示枢纽节点，而枢纽感知游走能平衡探索，更好保留时间邻域结构，提升下游任务性能。
            arXiv:2505.17764v1 Announce Type: new 
Abstract: The role of high-degree nodes, or hubs, in shaping graph dynamics and structure is well-recognized in network science, yet their influence remains underexplored in the context of dynamic graph embedding. Recent advances in representation learning for graphs have shown that random walk-based methods can capture both structural and temporal patterns, but often overlook the impact of hubs on walk trajectories and embedding stability. In this paper, we introduce DeepHub, a method for dynamic graph embedding that explicitly integrates hub sensitivity into random walk sampling strategies. Focusing on dynnode2vec as a representative dynamic embedding method, we systematically analyze the effect of hub-biased walks across nine real-world temporal networks. Our findings reveal that standard random walks tend to overrepresent hub nodes, leading to embeddings that underfit the evolving local context of less-connected nodes. By contrast, hub-aware walks can balance exploration, resulting in embeddings that better preserve temporal neighborhood structure and improve downstream task performance. These results suggest that hub-awareness is an important yet overlooked factor in dynamic graph embedding, and our work provides a foundation for more robust, structure-sensitive representation learning in evolving networks.
        ]]></description>
    </item>
    <item>
        <title>RECIPE-TKG: From Sparse History to Structured Reasoning for LLM-based Temporal Knowledge Graph Completion</title>
        <link>https://arxiv.org/abs/2505.17794</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17794v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>\"Omer Faruk Akg\"ul, Feiyu Zhu, Yuxin Yang, Rajgopal Kannan, Viktor Prasanna</dc:creator>
        <description><![CDATA[
            背景：时间知识图谱（TKGs）补全需模型对随时间演变的结构进行推理，现有基于大语言模型（LLMs）的方法常过度依赖监督微调，在历史证据有限时表现不佳。方法：提出RECIPE - TKG框架，结合基于规则的多跳检索、轻量级适配器的对比微调及测试时语义过滤。效果：在四个TKG基准测试中，RECIPE - TKG优于以往基于LLMs的方法，Hits@10相对提升达30.6%，即使在历史背景有限时也能产生语义更连贯的预测。
            arXiv:2505.17794v1 Announce Type: new 
Abstract: Temporal Knowledge Graphs (TKGs) represent dynamic facts as timestamped relations between entities. TKG completion involves forecasting missing or future links, requiring models to reason over time-evolving structure. While LLMs show promise for this task, existing approaches often overemphasize supervised fine-tuning and struggle particularly when historical evidence is limited or missing. We introduce RECIPE-TKG, a lightweight and data-efficient framework designed to improve accuracy and generalization in settings with sparse historical context. It combines (1) rule-based multi-hop retrieval for structurally diverse history, (2) contrastive fine-tuning of lightweight adapters to encode relational semantics, and (3) test-time semantic filtering to iteratively refine generations based on embedding similarity. Experiments on four TKG benchmarks show that RECIPE-TKG outperforms previous LLM-based approaches, achieving up to 30.6\% relative improvement in Hits@10. Moreover, our proposed framework produces more semantically coherent predictions, even for the samples with limited historical context.
        ]]></description>
    </item>
    <item>
        <title>Don't Overthink it. Preferring Shorter Thinking Chains for Improved LLM Reasoning</title>
        <link>https://arxiv.org/abs/2505.17813</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17813v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Michael Hassid, Gabriel Synnaeve, Yossi Adi, Roy Schwartz</dc:creator>
        <description><![CDATA[
            大语言模型推理依赖生成长思维链完成复杂推理任务，但成本高、耗时长。该研究挑战长思维链推理能力更强的假设，发现单个问题中短推理链更易得出正确答案，准确率比最长链高34.5%。基于此提出short - m@k推理方法，并行生成并提前停止计算。在低计算量下，short - 1@k表现与标准多数投票法相当或更优，使用思维令牌最多减少40%；short - 3@k效率稍低但始终优于多数投票法，耗时最多减少33%。微调实验显示短链训练效果更好。
            arXiv:2505.17813v1 Announce Type: new 
Abstract: Reasoning large language models (LLMs) heavily rely on scaling test-time compute to perform complex reasoning tasks by generating extensive "thinking" chains. While demonstrating impressive results, this approach incurs significant computational costs and inference time. In this work, we challenge the assumption that long thinking chains results in better reasoning capabilities. We first demonstrate that shorter reasoning chains within individual questions are significantly more likely to yield correct answers - up to 34.5% more accurate than the longest chain sampled for the same question. Based on these results, we suggest short-m@k, a novel reasoning LLM inference method. Our method executes k independent generations in parallel and halts computation once the first m thinking processes are done. The final answer is chosen using majority voting among these m chains. Basic short-1@k demonstrates similar or even superior performance over standard majority voting in low-compute settings - using up to 40% fewer thinking tokens. short-3@k, while slightly less efficient than short-1@k, consistently surpasses majority voting across all compute budgets, while still being substantially faster (up to 33% wall time reduction). Inspired by our results, we finetune an LLM using short, long, and randomly selected reasoning chains. We then observe that training on the shorter ones leads to better performance. Our findings suggest rethinking current methods of test-time compute in reasoning LLMs, emphasizing that longer "thinking" does not necessarily translate to improved performance and can, counter-intuitively, lead to degraded results.
        ]]></description>
    </item>
    <item>
        <title>Stepwise Reasoning Checkpoint Analysis: A Test Time Scaling Method to Enhance LLMs' Reasoning</title>
        <link>https://arxiv.org/abs/2505.17829</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17829v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zezhong Wang, Xingshan Zeng, Weiwen Liu, Yufei Wang, Liangyou Li, Yasheng Wang, Lifeng Shang, Xin Jiang, Qun Liu, Kam-Fai Wong</dc:creator>
        <description><![CDATA[
            背景：大语言模型（LLMs）通过思维链（CoT）进行数学推理能力强大，但现有测试时间缩放（TTS）方法如束搜索和DVTS虽能提升准确率，却存在路径同质化和中间结果利用低效问题。方法：提出逐步推理检查点分析（SRCA）框架，在推理步骤间引入检查点，采用答案聚类搜索和检查点候选增强两种策略。效果：实验表明，在多个数学数据集上，SRCA比现有TTS方法提高了推理准确率。
            arXiv:2505.17829v1 Announce Type: new 
Abstract: Mathematical reasoning through Chain-of-Thought (CoT) has emerged as a powerful capability of Large Language Models (LLMs), which can be further enhanced through Test-Time Scaling (TTS) methods like Beam Search and DVTS. However, these methods, despite improving accuracy by allocating more computational resources during inference, often suffer from path homogenization and inefficient use of intermediate results. To address these limitations, we propose Stepwise Reasoning Checkpoint Analysis (SRCA), a framework that introduces checkpoints between reasoning steps. It incorporates two key strategies: (1) Answer-Clustered Search, which groups reasoning paths by their intermediate checkpoint answers to maintain diversity while ensuring quality, and (2) Checkpoint Candidate Augmentation, which leverages all intermediate answers for final decision-making. Our approach effectively reduces path homogenization and creates a fault-tolerant mechanism by utilizing high-quality intermediate results. Experimental results show that SRCA improves reasoning accuracy compared to existing TTS methods across various mathematical datasets.
        ]]></description>
    </item>
    <item>
        <title>TransDF: Time-Series Forecasting Needs Transformed Label Alignment</title>
        <link>https://arxiv.org/abs/2505.17847</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17847v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hao Wang, Licheng Pan, Zhichao Chen, Xu Chen, Qingyang Dai, Lei Wang, Haoxuan Li, Zhouchen Lin</dc:creator>
        <description><![CDATA[
            背景：训练时间序列预测模型在设计有效学习目标上存在挑战，现有方法用的时间均方误差面临标签自相关、任务量过多问题。方法：提出Transform-enhanced Direct Forecast (TransDF)，将标签序列转换为具有区分性的去相关组件，训练模型对齐最重要组件。效果：大量实验表明，TransDF达到了最先进性能，且与多种预测模型兼容。代码见https://anonymous.4open.science/r/TransDF-88CF。
            arXiv:2505.17847v1 Announce Type: new 
Abstract: Training time-series forecasting models presents unique challenges in designing effective learning objectives. Existing methods predominantly utilize the temporal mean squared error, which faces two critical challenges: (1) label autocorrelation, which leads to bias from the label sequence likelihood; (2) excessive amount of tasks, which increases with the forecast horizon and complicates optimization. To address these challenges, we propose Transform-enhanced Direct Forecast (TransDF), which transforms the label sequence into decorrelated components with discriminated significance. Models are trained to align the most significant components, thereby effectively mitigating label autocorrelation and reducing task amount. Extensive experiments demonstrate that TransDF achieves state-of-the-art performance and is compatible with various forecasting models. Code is available at https://anonymous.4open.science/r/TransDF-88CF.
        ]]></description>
    </item>
    <item>
        <title>SpectraLDS: Provable Distillation for Linear Dynamical Systems</title>
        <link>https://arxiv.org/abs/2505.17868</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17868v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Devan Shah, Shlomo Fortgang, Sofiia Druchyna, Elad Hazan</dc:creator>
        <description><![CDATA[
            背景：现有方法在识别对称线性动态系统（LDS）时缺乏与系统状态维度或有效记忆无关的准确性保证。方法：该研究基于将对称LDS表示为可通过固定谱变换学习的卷积的工作，通过反转这种表示，从谱变换中恢复LDS模型，得到端到端的凸优化过程。效果：蒸馏过程能保持预测准确性，实现与序列长度无关的常量时间和空间推理。在序列预测架构中评估，如语言建模任务，证明可提升推理效率并保持准确性。
            arXiv:2505.17868v1 Announce Type: new 
Abstract: We present the first provable method for identifying symmetric linear dynamical systems (LDS) with accuracy guarantees that are independent of the systems' state dimension or effective memory. Our approach builds upon recent work that represents symmetric LDSs as convolutions learnable via fixed spectral transformations. We show how to invert this representation, thereby recovering an LDS model from its spectral transform and yielding an end-to-end convex optimization procedure. This distillation preserves predictive accuracy while enabling constant-time and constant-space inference per token, independent of sequence length. We evaluate our method, SpectraLDS, as a component in sequence prediction architectures and demonstrate that accuracy is preserved while inference efficiency is improved on tasks such as language modeling.
        ]]></description>
    </item>
    <item>
        <title>LLM Meeting Decision Trees on Tabular Data</title>
        <link>https://arxiv.org/abs/2505.17918</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17918v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hangting Ye, Jinmeng Li, He Zhao, Dandan Guo, Yi Chang</dc:creator>
        <description><![CDATA[
            背景：表格数据在各领域至关重要，现有基于大语言模型（LLM）处理表格数据的方法存在数据序列化缺乏普适性、有隐私风险，以及模型微调困难、上下文学习可扩展性受限等问题。方法：提出一种通过逻辑决策树规则作为中介将LLM集成到表格数据的新方法DeLTa，利用LLM推理能力改进决策树规则，并提供校准方法。效果：在多个表格基准测试中，该方法达到了最先进的性能。
            arXiv:2505.17918v1 Announce Type: new 
Abstract: Tabular data have been playing a vital role in diverse real-world fields, including healthcare, finance, etc. With the recent success of Large Language Models (LLMs), early explorations of extending LLMs to the domain of tabular data have been developed. Most of these LLM-based methods typically first serialize tabular data into natural language descriptions, and then tune LLMs or directly infer on these serialized data. However, these methods suffer from two key inherent issues: (i) data perspective: existing data serialization methods lack universal applicability for structured tabular data, and may pose privacy risks through direct textual exposure, and (ii) model perspective: LLM fine-tuning methods struggle with tabular data, and in-context learning scalability is bottle-necked by input length constraints (suitable for few-shot learning). This work explores a novel direction of integrating LLMs into tabular data throughough logical decision tree rules as intermediaries, proposes a decision tree enhancer with LLM-derived rule for tabular prediction, DeLTa. The proposed DeLTa avoids tabular data serialization, and can be applied to full data learning setting without LLM fine-tuning. Specifically, we leverage the reasoning ability of LLMs to redesign an improved rule given a set of decision tree rules. Furthermore, we provide a calibration method for original decision trees via new generated rule by LLM, which approximates the error correction vector to steer the original decision tree predictions in the direction of ``errors'' reducing. Finally, extensive experiments on diverse tabular benchmarks show that our method achieves state-of-the-art performance.
        ]]></description>
    </item>
    <item>
        <title>Language models can learn implicit multi-hop reasoning, but only if they have lots of training data</title>
        <link>https://arxiv.org/abs/2505.17923</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17923v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuekun Yao, Yupei Du, Dawei Zhu, Michael Hahn, Alexander Koller</dc:creator>
        <description><![CDATA[
            背景：隐式推理是语言模型在无思维链情况下单次前向传播解决多跳推理任务的能力。方法：研究人员用从零开始在可控 $k$ 跳推理数据集（$k = 2, 3, 4$）上训练的 GPT2 风格语言模型探究此能力，还给出深度增长必要性的理论解释，且尝试课程学习。效果：模型能学习隐式 $k$ 跳推理，但所需训练数据随 $k$ 指数增长，变压器层数随 $k$ 线性增长，课程学习可缓解但不能消除数据需求。 
            arXiv:2505.17923v1 Announce Type: new 
Abstract: Implicit reasoning is the ability of a language model to solve multi-hop reasoning tasks in a single forward pass, without chain of thought. We investigate this capability using GPT2-style language models trained from scratch on controlled $k$-hop reasoning datasets ($k = 2, 3, 4$). We show that while such models can indeed learn implicit $k$-hop reasoning, the required training data grows exponentially in $k$, and the required number of transformer layers grows linearly in $k$. We offer a theoretical explanation for why this depth growth is necessary. We further find that the data requirement can be mitigated, but not eliminated, through curriculum learning.
        ]]></description>
    </item>
    <item>
        <title>VeriThinker: Learning to Verify Makes Reasoning Model Efficient</title>
        <link>https://arxiv.org/abs/2505.17941</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17941v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zigeng Chen, Xinyin Ma, Gongfan Fang, Ruonan Yu, Xinchao Wang</dc:creator>
        <description><![CDATA[
            背景：大型推理模型（LRMs）用思维链（CoT）推理处理复杂任务时，过度思考导致推理链过长、推理成本大增。方法：提出VeriThinker，一种CoT压缩新方法，通过辅助验证任务微调模型，训练其验证CoT解决方案的正确性，抑制过度思考。效果：大量实验表明，该方法大幅缩短推理链长度，同时维持或略提升准确率。如在MATH500上推理令牌从3790减至2125，准确率从94.0%提至94.8%；在AIME25上令牌从14321减至10287，准确率从38.7%提至40.8%，还能零样本泛化到推测推理。
            arXiv:2505.17941v1 Announce Type: new 
Abstract: Large Reasoning Models (LRMs) excel at complex tasks using Chain-of-Thought (CoT) reasoning. However, their tendency to overthinking leads to unnecessarily lengthy reasoning chains, dramatically increasing inference costs. To mitigate this issue, we introduce VeriThinker, a novel approach for CoT compression. Unlike conventional methods that fine-tune LRMs directly on the original reasoning task using synthetic concise CoT data, we innovatively fine-tune the model solely through an auxiliary verification task. By training LRMs to accurately verify the correctness of CoT solutions, the LRMs inherently become more discerning about the necessity of subsequent self-reflection steps, thereby effectively suppressing overthinking. Extensive experiments validate that VeriThinker substantially reduces reasoning chain lengths while maintaining or even slightly improving accuracy. When applied to DeepSeek-R1-Distill-Qwen-7B, our approach reduces reasoning tokens on MATH500 from 3790 to 2125 while improving accuracy by 0.8% (94.0% to 94.8%), and on AIME25, tokens decrease from 14321 to 10287 with a 2.1% accuracy gain (38.7% to 40.8%). Additionally, our experiments demonstrate that VeriThinker can also be zero-shot generalized to speculative reasoning. Code is available at https://github.com/czg1225/VeriThinker
        ]]></description>
    </item>
    <item>
        <title>Few-Shot Learning from Gigapixel Images via Hierarchical Vision-Language Alignment and Modeling</title>
        <link>https://arxiv.org/abs/2505.17982</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17982v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Bryan Wong, Jong Woo Kim, Huazhu Fu, Mun Yong Yi</dc:creator>
        <description><![CDATA[
            背景：现有视觉语言模型用于全切片图像少样本弱监督分类时，存在跨尺度同模态交互建模不足、同尺度视觉与文本模态对齐不够的问题。方法：提出HiVE - MIL分层视觉语言框架，构建统一图捕捉层级关系，引入跨尺度边连接同尺度视觉和文本节点；采用两阶段文本引导动态过滤机制去除弱相关对，引入分层对比损失对齐跨尺度文本语义。效果：在多癌症数据集上，16样本设置下宏F1最高提升4.1%，优于传统和基于VLM的MIL方法。
            arXiv:2505.17982v1 Announce Type: new 
Abstract: Vision-language models (VLMs) have recently been integrated into multiple instance learning (MIL) frameworks to address the challenge of few-shot, weakly supervised classification of whole slide images (WSIs). A key trend involves leveraging multi-scale information to better represent hierarchical tissue structures. However, existing methods often face two key limitations: (1) insufficient modeling of interactions within the same modalities across scales (e.g., 5x and 20x) and (2) inadequate alignment between visual and textual modalities on the same scale. To address these gaps, we propose HiVE-MIL, a hierarchical vision-language framework that constructs a unified graph consisting of (1) parent-child links between coarse (5x) and fine (20x) visual/textual nodes to capture hierarchical relationships, and (2) heterogeneous intra-scale edges linking visual and textual nodes on the same scale. To further enhance semantic consistency, HiVE-MIL incorporates a two-stage, text-guided dynamic filtering mechanism that removes weakly correlated patch-text pairs, and introduces a hierarchical contrastive loss to align textual semantics across scales. Extensive experiments on TCGA breast, lung, and kidney cancer datasets demonstrate that HiVE-MIL consistently outperforms both traditional MIL and recent VLM-based MIL approaches, achieving gains of up to 4.1% in macro F1 under 16-shot settings. Our results demonstrate the value of jointly modeling hierarchical structure and multimodal alignment for efficient and scalable learning from limited pathology data. The code is available at https://github.com/bryanwong17/HiVE-MIL
        ]]></description>
    </item>
    <item>
        <title>ADLGen: Synthesizing Symbolic, Event-Triggered Sensor Sequences for Human Activity Modeling</title>
        <link>https://arxiv.org/abs/2505.17987</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17987v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Weihang You, Hanqi Jiang, Zishuai Liu, Zihang Xie, Tianming Liu, Jin Lu, Fei Dou</dc:creator>
        <description><![CDATA[
            背景：现实中收集日常生活活动数据面临隐私、部署和标注成本高以及数据稀疏不平衡等挑战。方法：提出ADLGen生成框架，将仅解码器的Transformer与基于符号的象征性时间编码、上下文和布局感知采样机制结合，还将大语言模型融入自动生成 - 评估 - 改进循环。效果：通过新评估指标实验，ADLGen在统计保真度、语义丰富度和下游活动识别方面优于基线生成器，为日常生活活动数据合成提供可扩展且保护隐私的方案。
            arXiv:2505.17987v1 Announce Type: new 
Abstract: Real world collection of Activities of Daily Living data is challenging due to privacy concerns, costly deployment and labeling, and the inherent sparsity and imbalance of human behavior. We present ADLGen, a generative framework specifically designed to synthesize realistic, event triggered, and symbolic sensor sequences for ambient assistive environments. ADLGen integrates a decoder only Transformer with sign based symbolic temporal encoding, and a context and layout aware sampling mechanism to guide generation toward semantically rich and physically plausible sensor event sequences. To enhance semantic fidelity and correct structural inconsistencies, we further incorporate a large language model into an automatic generate evaluate refine loop, which verifies logical, behavioral, and temporal coherence and generates correction rules without manual intervention or environment specific tuning. Through comprehensive experiments with novel evaluation metrics, ADLGen is shown to outperform baseline generators in statistical fidelity, semantic richness, and downstream activity recognition, offering a scalable and privacy-preserving solution for ADL data synthesis.
        ]]></description>
    </item>
    <item>
        <title>Towards Analyzing and Understanding the Limitations of VAPO: A Theoretical Perspective</title>
        <link>https://arxiv.org/abs/2505.17997</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17997v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jintian Shao, Yiming Cheng, Hongyi Huang, Beiwen Zhang, Zhiyu Wu, You Shan, Mingkai Zheng</dc:creator>
        <description><![CDATA[
            背景：VAPO框架在提升大语言模型长思维链推理任务的强化学习效率和可靠性方面取得显著实证成果，但缺乏对其底层机制和潜在局限的理论理解。方法：从理论角度探讨VAPO，研究复杂推理空间中价值函数近似、自适应优势估计的最优性、标记级优化的影响及探索和泛化挑战。效果：虽未提及定量效果，但旨在为开发更稳健、可泛化的推理智能体提供理论指导。 
            arXiv:2505.17997v1 Announce Type: new 
Abstract: The VAPO framework has demonstrated significant empirical success in enhancing the efficiency and reliability of reinforcement learning for long chain-of-thought (CoT) reasoning tasks with large language models (LLMs). By systematically addressing challenges such as value model bias, heterogeneous sequence lengths, and sparse reward signals, VAPO achieves state-of-the-art performance. While its practical benefits are evident, a deeper theoretical understanding of its underlying mechanisms and potential limitations is crucial for guiding future advancements. This paper aims to initiate such a discussion by exploring VAPO from a theoretical perspective, highlighting areas where its assumptions might be challenged and where further investigation could yield more robust and generalizable reasoning agents. We delve into the intricacies of value function approximation in complex reasoning spaces, the optimality of adaptive advantage estimation, the impact of token-level optimization, and the enduring challenges of exploration and generalization.
        ]]></description>
    </item>
    <item>
        <title>CXReasonBench: A Benchmark for Evaluating Structured Diagnostic Reasoning in Chest X-rays</title>
        <link>https://arxiv.org/abs/2505.18087</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.18087v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hyungyung Lee, Geon Choi, Jung-Oh Lee, Hangyul Yoon, Hyuk Gi Hong, Edward Choi</dc:creator>
        <description><![CDATA[
            背景：当前大视觉语言模型在医疗任务有应用，但现有基准主要关注最终诊断答案，难以评估模型是否进行有临床意义的推理。方法：提出CheXStruct和CXReasonBench，CheXStruct从胸部X光片自动推导中间推理步骤，CXReasonBench利用该流程评估模型是否能执行有效推理及从结构化指导中学习的程度。效果：基准包含18988个问答对，对10个模型评估发现，最强模型在结构化推理和泛化上也有困难，常无法关联抽象知识与视觉解读。
            arXiv:2505.18087v1 Announce Type: new 
Abstract: Recent progress in Large Vision-Language Models (LVLMs) has enabled promising applications in medical tasks, such as report generation and visual question answering. However, existing benchmarks focus mainly on the final diagnostic answer, offering limited insight into whether models engage in clinically meaningful reasoning. To address this, we present CheXStruct and CXReasonBench, a structured pipeline and benchmark built on the publicly available MIMIC-CXR-JPG dataset. CheXStruct automatically derives a sequence of intermediate reasoning steps directly from chest X-rays, such as segmenting anatomical regions, deriving anatomical landmarks and diagnostic measurements, computing diagnostic indices, and applying clinical thresholds. CXReasonBench leverages this pipeline to evaluate whether models can perform clinically valid reasoning steps and to what extent they can learn from structured guidance, enabling fine-grained and transparent assessment of diagnostic reasoning. The benchmark comprises 18,988 QA pairs across 12 diagnostic tasks and 1,200 cases, each paired with up to 4 visual inputs, and supports multi-path, multi-stage evaluation including visual grounding via anatomical region selection and diagnostic measurements. Even the strongest of 10 evaluated LVLMs struggle with structured reasoning and generalization, often failing to link abstract knowledge with anatomically grounded visual interpretation. The code is available at https://github.com/ttumyche/CXReasonBench
        ]]></description>
    </item>
    <item>
        <title>UNJOIN: Enhancing Multi-Table Text-to-SQL Generation via Schema Simplification</title>
        <link>https://arxiv.org/abs/2505.18122</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.18122v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Poojah Ganesan, Rajat Aayush Jha, Dan Roth, Vivek Gupta</dc:creator>
        <description><![CDATA[
            背景：大语言模型提升了单表文本转SQL性能，但多表数据库因复杂模式和关系操作仍具挑战，现有方法存在诸多问题。方法：提出UNJOIN两阶段框架，第一阶段将数据库所有表的列名合并为单表表示，让模型专注检索；第二阶段在简化模式上生成SQL查询并映射回原模式。效果：在SPIDER和BIRD数据集上评估，表现达到或超越现有最优基线，且仅用模式信息，无需数据访问和微调，可扩展适配不同数据库。
            arXiv:2505.18122v1 Announce Type: new 
Abstract: Recent advances in large language models (LLMs) have greatly improved Text-to-SQL performance for single-table queries. But, it remains challenging in multi-table databases due to complex schema and relational operations. Existing methods often struggle with retrieving the right tables and columns, generating accurate JOINs and UNIONs, and generalizing across diverse schemas. To address these issues, we introduce UNJOIN, a two-stage framework that decouples the retrieval of schema elements from SQL logic generation. In the first stage, we merge the column names of all tables in the database into a single-table representation by prefixing each column with its table name. This allows the model to focus purely on accurate retrieval without being distracted by the need to write complex SQL logic. In the second stage, the SQL query is generated on this simplified schema and mapped back to the original schema by reconstructing JOINs, UNIONs, and relational logic. Evaluations on SPIDER and BIRD datasets show that UNJOIN matches or exceeds the state-of-the-art baselines. UNJOIN uses only schema information, which does not require data access or fine-tuning, making it scalable and adaptable across databases.
        ]]></description>
    </item>
    <item>
        <title>TabSTAR: A Foundation Tabular Model With Semantically Target-Aware Representations</title>
        <link>https://arxiv.org/abs/2505.18125</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.18125v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Alan Arazi, Eilam Shapira, Roi Reichart</dc:creator>
        <description><![CDATA[
            背景：深度学习在表格学习任务上表现不如梯度提升决策树，现有结合语言模型能力的表格任务方法多采用静态、与目标无关的文本表示，效果受限。方法：提出TabSTAR，一种具有语义目标感知表示的基础表格模型，可对含文本特征的表格数据进行迁移学习，其架构无特定数据集参数，解冻预训练文本编码器并以目标令牌为输入学习特定任务嵌入。效果：在含文本特征的分类任务基准测试中，在中大型数据集上达最优，预训练阶段呈现数据集数量的缩放规律，有望进一步提升性能。
            arXiv:2505.18125v1 Announce Type: new 
Abstract: While deep learning has achieved remarkable success across many domains, it has historically underperformed on tabular learning tasks, which remain dominated by gradient boosting decision trees (GBDTs). However, recent advancements are paving the way for Tabular Foundation Models, which can leverage real-world knowledge and generalize across diverse datasets, particularly when the data contains free-text. Although incorporating language model capabilities into tabular tasks has been explored, most existing methods utilize static, target-agnostic textual representations, limiting their effectiveness. We introduce TabSTAR: a Foundation Tabular Model with Semantically Target-Aware Representations. TabSTAR is designed to enable transfer learning on tabular data with textual features, with an architecture free of dataset-specific parameters. It unfreezes a pretrained text encoder and takes as input target tokens, which provide the model with the context needed to learn task-specific embeddings. TabSTAR achieves state-of-the-art performance for both medium- and large-sized datasets across known benchmarks of classification tasks with text features, and its pretraining phase exhibits scaling laws in the number of datasets, offering a pathway for further performance improvements.
        ]]></description>
    </item>
    <item>
        <title>Graph-Linguistic Fusion: Using Language Models for Wikidata Vandalism Detection</title>
        <link>https://arxiv.org/abs/2505.18136</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.18136v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mykola Trokhymovych, Lydia Pintscher, Ricardo Baeza-Yates, Diego Saez-Trumper</dc:creator>
        <description><![CDATA[
            背景：Wikidata是网络上最大的开源结构化知识库之一，其项目包含大量事实三元组和多语言文本，编辑会改变结构化和文本内容。方法：提出Graph2Text方法，将所有编辑转换到单一空间，用单一多语言语言模型评估潜在破坏行为。效果：该统一方法提高了覆盖范围、简化维护，实验表明其性能优于当前生产系统，还开源代码和数据集，便于进一步研究。
            arXiv:2505.18136v1 Announce Type: new 
Abstract: We introduce a next-generation vandalism detection system for Wikidata, one of the largest open-source structured knowledge bases on the Web. Wikidata is highly complex: its items incorporate an ever-expanding universe of factual triples and multilingual texts. While edits can alter both structured and textual content, our approach converts all edits into a single space using a method we call Graph2Text. This allows for evaluating all content changes for potential vandalism using a single multilingual language model. This unified approach improves coverage and simplifies maintenance. Experiments demonstrate that our solution outperforms the current production system. Additionally, we are releasing the code under an open license along with a large dataset of various human-generated knowledge alterations, enabling further research.
        ]]></description>
    </item>
    <item>
        <title>Where You Go is Who You Are: Behavioral Theory-Guided LLMs for Inverse Reinforcement Learning</title>
        <link>https://arxiv.org/abs/2505.17249</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17249v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuran Sun, Susu Xu, Chenguang Wang, Xilei Zhao</dc:creator>
        <description><![CDATA[
            背景：大规模轨迹数据用于人类移动性分析时，因缺少旅行者社会人口属性信息而受限，且以往预测属性的研究忽视认知机制、准确率低。方法：提出SILIC框架，利用大语言模型（LLMs）结合逆强化学习（IRL）和认知链推理（CCR），依据计划行为理论（TPB）建模出行决策认知过程，用LLMs指导IRL奖励函数初始化和更新。效果：在2017年普吉特海湾地区家庭出行调查中，大幅超越现有基线方法。
            arXiv:2505.17249v1 Announce Type: cross 
Abstract: Big trajectory data hold great promise for human mobility analysis, but their utility is often constrained by the absence of critical traveler attributes, particularly sociodemographic information. While prior studies have explored predicting such attributes from mobility patterns, they often overlooked underlying cognitive mechanisms and exhibited low predictive accuracy. This study introduces SILIC, short for Sociodemographic Inference with LLM-guided Inverse Reinforcement Learning (IRL) and Cognitive Chain Reasoning (CCR), a theoretically grounded framework that leverages LLMs to infer sociodemographic attributes from observed mobility patterns by capturing latent behavioral intentions and reasoning through psychological constructs. Particularly, our approach explicitly follows the Theory of Planned Behavior (TPB), a foundational behavioral framework in transportation research, to model individuals' latent cognitive processes underlying travel decision-making. The LLMs further provide heuristic guidance to improve IRL reward function initialization and update by addressing its ill-posedness and optimization challenges arising from the vast and unstructured reward space. Evaluated in the 2017 Puget Sound Regional Council Household Travel Survey, our method substantially outperforms state-of-the-art baselines and shows great promise for enriching big trajectory data to support more behaviorally grounded applications in transportation planning and beyond.
        ]]></description>
    </item>
    <item>
        <title>AdaReasoner: Adaptive Reasoning Enables More Flexible Thinking</title>
        <link>https://arxiv.org/abs/2505.17312</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17312v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiangqi Wang, Yue Huang, Yanbo Wang, Xiaonan Luo, Kehan Guo, Yujun Zhou, Xiangliang Zhang</dc:creator>
        <description><![CDATA[
            背景：大语言模型处理复杂推理任务时需有效配置，但现有提示方法多采用通用固定配置，难达任务最优。方法：提出AdaReasoner，这是一种与大语言模型无关的插件，用强化学习框架训练，结合分解动作空间与目标探索策略，利用预训练奖励模型，仅需少量样本指导优化推理配置策略模型。效果：在六种大语言模型和多种推理任务中，持续优于标准基线，保持分布外鲁棒性，通过定制提示在知识密集型任务上取得增益。
            arXiv:2505.17312v1 Announce Type: cross 
Abstract: LLMs often need effective configurations, like temperature and reasoning steps, to handle tasks requiring sophisticated reasoning and problem-solving, ranging from joke generation to mathematical reasoning. Existing prompting approaches usually adopt general-purpose, fixed configurations that work 'well enough' across tasks but seldom achieve task-specific optimality. To address this gap, we introduce AdaReasoner, an LLM-agnostic plugin designed for any LLM to automate adaptive reasoning configurations for tasks requiring different types of thinking. AdaReasoner is trained using a reinforcement learning (RL) framework, combining a factorized action space with a targeted exploration strategy, along with a pretrained reward model to optimize the policy model for reasoning configurations with only a few-shot guide. AdaReasoner is backed by theoretical guarantees and experiments of fast convergence and a sublinear policy gap. Across six different LLMs and a variety of reasoning tasks, it consistently outperforms standard baselines, preserves out-of-distribution robustness, and yield gains on knowledge-intensive tasks through tailored prompts.
        ]]></description>
    </item>
    <item>
        <title>Chart-to-Experience: Benchmarking Multimodal LLMs for Predicting Experiential Impact of Charts</title>
        <link>https://arxiv.org/abs/2505.17374</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17374v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Seon Gyeom Kim, Jae Young Choi, Ryan Rossi, Eunyee Koh, Tak Yeon Lee</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型在视觉理解任务取得进展，但在预测图表感知和情感影响方面，很多应用基于少量示例的泛化假设，缺乏性能和有效性验证。方法：引入包含36张图表的基准数据集Chart - to - Experience，由众包人员评估其对七个体验因素的影响，以此为基准评估先进MLLMs在直接预测和图表两两比较两项任务的能力。效果：MLLMs评估单张图表时不如人类评估者敏感，但在两两比较中准确可靠。
            arXiv:2505.17374v1 Announce Type: cross 
Abstract: The field of Multimodal Large Language Models (MLLMs) has made remarkable progress in visual understanding tasks, presenting a vast opportunity to predict the perceptual and emotional impact of charts. However, it also raises concerns, as many applications of LLMs are based on overgeneralized assumptions from a few examples, lacking sufficient validation of their performance and effectiveness. We introduce Chart-to-Experience, a benchmark dataset comprising 36 charts, evaluated by crowdsourced workers for their impact on seven experiential factors. Using the dataset as ground truth, we evaluated capabilities of state-of-the-art MLLMs on two tasks: direct prediction and pairwise comparison of charts. Our findings imply that MLLMs are not as sensitive as human evaluators when assessing individual charts, but are accurate and reliable in pairwise comparisons.
        ]]></description>
    </item>
    <item>
        <title>Controlled Agentic Planning & Reasoning for Mechanism Synthesis</title>
        <link>https://arxiv.org/abs/2505.17607</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17607v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jo\~ao Pedro Gandarela, Thiago Rios, Stefan Menzel, Andr\'e Freitas</dc:creator>
        <description><![CDATA[
            背景：需有效方法进行机构综合推理。方法：提出基于双智能体大语言模型的推理方法，能在语言和符号层面推理以生成几何和动态结果，通过自然语言规范、参考抽象属性、生成模拟代码等形成细化循环。效果：在平面机构中有效且收敛，还引入新基准MSynth分析模型组件影响，表明符号回归提示在足够大架构下可解锁机械洞察。
            arXiv:2505.17607v1 Announce Type: cross 
Abstract: This work presents a dual-agent Large Language Model (LLM)-based reasoning method for mechanism synthesis, capable of reasoning at both linguistic and symbolic levels to generate geometrical and dynamic outcomes. The model consists of a composition of well-defined functions that, starting from a natural language specification, references abstract properties through supporting equations, generates and parametrizes simulation code, and elicits feedback anchor points using symbolic regression and distance functions. This process closes an actionable refinement loop at the linguistic and symbolic layers. The approach is shown to be both effective and convergent in the context of planar mechanisms. Additionally, we introduce MSynth, a novel benchmark for planar mechanism synthesis, and perform a comprehensive analysis of the impact of the model components. We further demonstrate that symbolic regression prompts unlock mechanistic insights only when applied to sufficiently large architectures.
        ]]></description>
    </item>
    <item>
        <title>ComfyMind: Toward General-Purpose Generation via Tree-Based Planning and Reactive Feedback</title>
        <link>https://arxiv.org/abs/2505.17908</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17908v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Litao Guo (HKUST), Xinli Xu (HKUST), Luozhou Wang (HKUST), Jiantao Lin (HKUST), Jinsong Zhou (HKUST), Zixin Zhang (HKUST), Bolan Su (Bytedance), Ying-Cong Chen (HKUST, HKUST)</dc:creator>
        <description><![CDATA[
            背景：生成模型发展迅速，但现有开源框架因缺乏结构化工作流规划和执行层面反馈，难以支持复杂应用。方法：提出ComfyMind系统，有两大创新，一是语义工作流接口，将底层节点图抽象为自然语言描述的可调用功能模块；二是带局部反馈执行的搜索树规划机制，将生成建模为分层决策过程。效果：在三个公开基准测试中，ComfyMind性能超现有开源基线，与GPT - Image - 1相当，提升了复杂生成工作流的稳定性和灵活性。
            arXiv:2505.17908v1 Announce Type: cross 
Abstract: With the rapid advancement of generative models, general-purpose generation has gained increasing attention as a promising approach to unify diverse tasks across modalities within a single system. Despite this progress, existing open-source frameworks often remain fragile and struggle to support complex real-world applications due to the lack of structured workflow planning and execution-level feedback. To address these limitations, we present ComfyMind, a collaborative AI system designed to enable robust and scalable general-purpose generation, built on the ComfyUI platform. ComfyMind introduces two core innovations: Semantic Workflow Interface (SWI) that abstracts low-level node graphs into callable functional modules described in natural language, enabling high-level composition and reducing structural errors; Search Tree Planning mechanism with localized feedback execution, which models generation as a hierarchical decision process and allows adaptive correction at each stage. Together, these components improve the stability and flexibility of complex generative workflows. We evaluate ComfyMind on three public benchmarks: ComfyBench, GenEval, and Reason-Edit, which span generation, editing, and reasoning tasks. Results show that ComfyMind consistently outperforms existing open-source baselines and achieves performance comparable to GPT-Image-1. ComfyMind paves a promising path for the development of open-source general-purpose generative AI systems. Project page: https://github.com/LitaoGuo/ComfyMind
        ]]></description>
    </item>
    <item>
        <title>Structured Thinking Matters: Improving LLMs Generalization in Causal Inference Tasks</title>
        <link>https://arxiv.org/abs/2505.18034</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.18034v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wentao Sun, Joao Paulo Nogueira, Alonso Silva</dc:creator>
        <description><![CDATA[
            背景：大语言模型（LLMs）在区分因果和相关关系上表现不佳，现有模型泛化能力有限，如GPT - 4在Corr2Cause数据集上F1分数仅29.08。方法：提出结构化方法，引导模型构建结构化知识图，系统编码相关前提，以结构化思维回答因果查询。效果：在Corr2Cause数据集测试子集上，Qwen3 - 32B模型使用该方法后F1分数从32.71提升到48.26，相对提升超47.5%，精确率和召回率也显著改善。
            arXiv:2505.18034v1 Announce Type: cross 
Abstract: Despite remarkable advances in the field, LLMs remain unreliable in distinguishing causation from correlation. Recent results from the Corr2Cause dataset benchmark reveal that state-of-the-art LLMs -- such as GPT-4 (F1 score: 29.08) -- only marginally outperform random baselines (Random Uniform, F1 score: 20.38), indicating limited capacity of generalization. To tackle this limitation, we propose a novel structured approach: rather than directly answering causal queries, we provide the model with the capability to structure its thinking by guiding the model to build a structured knowledge graph, systematically encoding the provided correlational premises, to answer the causal queries. This intermediate representation significantly enhances the model's causal capabilities. Experiments on the test subset of the Corr2Cause dataset benchmark with Qwen3-32B model (reasoning model) show substantial gains over standard direct prompting methods, improving F1 scores from 32.71 to 48.26 (over 47.5% relative increase), along with notable improvements in precision and recall. These results underscore the effectiveness of providing the model with the capability to structure its thinking and highlight its promising potential for broader generalization across diverse causal inference tasks.
        ]]></description>
    </item>
    <item>
        <title>Ground Every Sentence: Improving Retrieval-Augmented LLMs with Interleaved Reference-Claim Generation</title>
        <link>https://arxiv.org/abs/2407.01796</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2407.01796v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sirui Xia, Xintao Wang, Jiaqing Liang, Yifei Zhang, Weikang Zhou, Jiaji Deng, Fei Yu, Yanghua Xiao</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）广泛用于提升大语言模型在知识密集型任务中的表现，现有归因文本生成（ATG）方法多为粗粒度归因，可验证性不足。方法：提出细粒度ATG方法ReClaim，在长文本问答任务中逐步交替生成参考文献和答案，提供句子级引用。效果：大量实验验证了ReClaim在多种场景下的有效性，引用准确率达90%。
            arXiv:2407.01796v2 Announce Type: replace 
Abstract: Retrieval-Augmented Generation (RAG) has been widely adopted to enhance Large Language Models (LLMs) in knowledge-intensive tasks. To enhance credibility and verifiability in RAG systems, Attributed Text Generation (ATG) is proposed, which provides citations to retrieval knowledge in LLM-generated responses. Prior methods mainly adopt coarse-grained attributions, with passage-level or paragraph-level references or citations, which fall short in verifiability. This paper proposes ReClaim (Refer & Claim), a fine-grained ATG method that alternates the generation of references and answers step by step. Different from previous coarse-grained attribution, ReClaim provides sentence-level citations in long-form question-answering tasks. With extensive experiments, we verify the effectiveness of ReClaim in extensive settings, achieving a citation accuracy rate of 90%.
        ]]></description>
    </item>
    <item>
        <title>Enhancing Unsupervised Sentence Embeddings via Knowledge-Driven Data Augmentation and Gaussian-Decayed Contrastive Learning</title>
        <link>https://arxiv.org/abs/2409.12887</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2409.12887v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Peichao Lai, Zhengfeng Zhang, Wentao Zhang, Fangcheng Fu, Bin Cui</dc:creator>
        <description><![CDATA[
            背景：用大语言模型进行数据增强提升无监督句子嵌入模型时，存在数据多样性有限和噪声高的问题。方法：提出基于大语言模型的管道式数据增强方法，利用知识图谱提取实体和数量以生成更多样样本；引入高斯衰减梯度辅助的对比句子嵌入（GCSE）模型，用高斯衰减函数限制错误难负样本影响。效果：在语义文本相似度任务中达到了最先进水平，使用更少数据样本和更小的大语言模型，展现出效率和鲁棒性。
            arXiv:2409.12887v3 Announce Type: replace 
Abstract: Recently, using large language models (LLMs) for data augmentation has led to considerable improvements in unsupervised sentence embedding models. However, existing methods encounter two primary challenges: limited data diversity and high data noise. Current approaches often neglect fine-grained knowledge, such as entities and quantities, leading to insufficient diversity. Besides, unsupervised data frequently lacks discriminative information, and the generated synthetic samples may introduce noise. In this paper, we propose a pipeline-based data augmentation method via LLMs and introduce the Gaussian-decayed gradient-assisted Contrastive Sentence Embedding (GCSE) model to enhance unsupervised sentence embeddings. To tackle the issue of low data diversity, our pipeline utilizes knowledge graphs (KGs) to extract entities and quantities, enabling LLMs to generate more diverse samples. To address high data noise, the GCSE model uses a Gaussian-decayed function to limit the impact of false hard negative samples, enhancing the model's discriminative capability. Experimental results show that our approach achieves state-of-the-art performance in semantic textual similarity (STS) tasks, using fewer data samples and smaller LLMs, demonstrating its efficiency and robustness across various models.
        ]]></description>
    </item>
    <item>
        <title>MotifDisco: Motif Causal Discovery For Time Series Motifs</title>
        <link>https://arxiv.org/abs/2409.15219</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2409.15219v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Josephine Lamp, Mark Derdzinski, Christopher Hannemann, Sam Hatfield, Joost van der Linden</dc:creator>
        <description><![CDATA[
            背景：时间序列中的主题因果关系识别有助于理解和表征模式，提升深度学习和生成模型性能，但此前缺乏相关因果发现方法。方法：提出MotifDisco框架，受格兰杰因果和转移熵启发定义主题因果概念，构建基于图神经网络的框架，通过解决无监督链接预测问题学习主题间因果关系，并将其集成到预测、异常检测和聚类任务中。效果：在不同健康数据流上评估，发现主题因果在各任务中显著提升性能。
            arXiv:2409.15219v2 Announce Type: replace 
Abstract: Many time series, particularly health data streams, can be best understood as a sequence of phenomenon or events, which we call \textit{motifs}. A time series motif is a short trace segment which may implicitly capture an underlying phenomenon within the time series. Specifically, we focus on glucose traces collected from continuous glucose monitors (CGMs), which inherently contain motifs representing underlying human behaviors such as eating and exercise. The ability to identify and quantify \textit{causal} relationships amongst motifs can provide a mechanism to better understand and represent these patterns, useful for improving deep learning and generative models and for advanced technology development (e.g., personalized coaching and artificial insulin delivery systems). However, no previous work has developed causal discovery methods for time series motifs. Therefore, in this paper we develop MotifDisco (\textbf{motif} \textbf{disco}very of causality), a novel causal discovery framework to learn causal relations amongst motifs from time series traces. We formalize a notion of \textit{Motif Causality (MC)}, inspired from Granger Causality and Transfer Entropy, and develop a Graph Neural Network-based framework that learns causality between motifs by solving an unsupervised link prediction problem. We integrate MC with three model use cases of forecasting, anomaly detection and clustering, to showcase the use of MC as a building block for downstream tasks. Finally, we evaluate our framework on different health data streams and find that Motif Causality provides a significant performance improvement in all use cases.
        ]]></description>
    </item>
    <item>
        <title>Structural Reasoning Improves Molecular Understanding of LLM</title>
        <link>https://arxiv.org/abs/2410.05610</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.05610v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yunhui Jang, Jaehyung Kim, Sungsoo Ahn</dc:creator>
        <description><![CDATA[
            背景：大语言模型虽有进展，但在利用分子结构信息推理上存在不足，而许多分子特性依赖结构细节。方法：提出通过绘制分子结构进行推理的方法，引入分子结构推理（MSR）框架，明确融入关键结构特征，针对目标分子已知和未知两种场景给出框架。效果：经大量实验验证，MSR提升了大语言模型对分子的理解能力。
            arXiv:2410.05610v2 Announce Type: replace 
Abstract: Recently, large language models (LLMs) have shown significant progress, approaching human perception levels. In this work, we demonstrate that despite these advances, LLMs still struggle to reason using molecular structural information. This gap is critical because many molecular properties, including functional groups, depend heavily on such structural details. To address this limitation, we propose an approach that sketches molecular structures for reasoning. Specifically, we introduce Molecular Structural Reasoning (MSR) framework to enhance the understanding of LLMs by explicitly incorporating the key structural features. We present two frameworks for scenarios where the target molecule is known or unknown. We verify that our MSR improves molecular understanding through extensive experiments.
        ]]></description>
    </item>
    <item>
        <title>Long Sequence Modeling with Attention Tensorization: From Sequence to Tensor Learning</title>
        <link>https://arxiv.org/abs/2410.20926</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.20926v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Aosong Feng, Rex Ying, Leandros Tassiulas</dc:creator>
        <description><![CDATA[
            背景：处理长文本数据时，基于注意力机制的模型存在全注意力建模能力范围有限与输入序列长距离依赖的不匹配问题。方法：将长输入序列张量化为紧凑的张量表示，在每个变换维度上进行注意力计算，以扩大注意力感受野，提出的张量化注意力可作为高效的Transformer骨干。效果：该方法将令牌依赖编码为多跳注意力过程，等同于全注意力的Kronecker分解。实验表明，其能高效适配预训练大模型，如Llama - 8B在32768上下文长度下训练，推理时能稳定外推到128k长度，速度比使用FlashAttention - 2的全注意力快11倍。
            arXiv:2410.20926v2 Announce Type: replace 
Abstract: As the demand for processing extended textual data grows, the ability to handle long-range dependencies and maintain computational efficiency is more critical than ever. One of the key issues for long-sequence modeling using attention-based model is the mismatch between the limited-range modeling power of full attention and the long-range token dependency in the input sequence. In this work, we propose to scale up the attention receptive field by tensorizing long input sequences into compact tensor representations followed by attention on each transformed dimension. The resulting Tensorized Attention can be adopted as efficient transformer backbones to extend input context length with improved memory and time efficiency. We show that the proposed attention tensorization encodes token dependencies as a multi-hop attention process, and is equivalent to Kronecker decomposition of full attention. Extensive experiments show that tensorized attention can be used to adapt pretrained LLMs with improved efficiency. Notably, Llama-8B with tensorization is trained under 32,768 context length and can steadily extrapolate to 128k length during inference with $11\times$ speedup, compared to full attention with FlashAttention-2.
        ]]></description>
    </item>
    <item>
        <title>OneProt: Towards Multi-Modal Protein Foundation Models</title>
        <link>https://arxiv.org/abs/2411.04863</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2411.04863v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Klemens Fl\"oge, Srisruthi Udayakumar, Johanna Sommer, Marie Piraud, Stefan Kesselheim, Vincent Fortuin, Stephan G\"unneman, Karel J van der Weg, Holger Gohlke, Erinc Merdivan, Alina Bazarova</dc:creator>
        <description><![CDATA[
            背景：人工智能发展使多模态系统可处理多样信息空间。方法：提出多模态蛋白质模型OneProt，整合结构、序列、文本和结合位点数据，用ImageBind框架以轻量级微调方案对齐蛋白质模态编码器潜在空间，结合图神经网络和Transformer架构。效果：在检索任务中表现出色，在酶功能预测等下游任务中有良好表现；能将专业编码器信息转移到序列编码器，增强区分序列能力；发现结合位点编码器对预测性能贡献大，为相关领域应用奠基。
            arXiv:2411.04863v2 Announce Type: replace 
Abstract: Recent advances in Artificial Intelligence have enabled multi-modal systems to model and translate diverse information spaces. Extending beyond text and vision, we introduce OneProt, a multi-modal AI for proteins that integrates structural, sequence, text, and binding site data. Using the ImageBind framework, OneProt aligns the latent spaces of protein modality encoders in a lightweight fine-tuning scheme that focuses on pairwise alignment with sequence data rather than requiring full matches. This novel approach comprises a mix of Graph Neural Networks and transformer architectures. It demonstrates strong performance in retrieval tasks and showcases the efficacy of multi-modal systems in Protein Machine Learning through a broad spectrum of downstream baselines, including enzyme function prediction and binding site analysis. Furthermore, OneProt enables the transfer of representational information from specialized encoders to the sequence encoder, enhancing capabilities for distinguishing evolutionarily related and unrelated sequences and exhibiting representational properties where evolutionarily related proteins align in similar directions within the latent space. In addition, we extensively investigate modality ablations to identify the encoders that contribute most to predictive performance, highlighting the significance of the binding site encoder, which has not been used in similar models previously. This work expands the horizons of multi-modal protein models, paving the way for transformative applications in drug discovery, biocatalytic reaction planning, and protein engineering.
        ]]></description>
    </item>
    <item>
        <title>Multi-modal Retrieval Augmented Multi-modal Generation: Datasets, Evaluation Metrics and Strong Baselines</title>
        <link>https://arxiv.org/abs/2411.16365</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2411.16365v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zi-Ao Ma, Tian Lan, Rong-Cheng Tu, Yong Hu, Yu-Shi Zhu, Tong Zhang, Heyan Huang, Zhijing Wu, Xian-Ling Mao</dc:creator>
        <description><![CDATA[
            背景：多模态检索增强多模态生成（M²RAG）任务有潜力但研究不足，缺乏全面分析和高质量数据资源。方法：通过严格的数据整理流程建立综合基准，采用基于基础模型的文本和多模态指标评估，提出基础模型有效处理M²RAG任务的策略，用设计指标筛选高质量样本构建训练集。效果：实验表明所提指标可靠，微调后的7B - 8B模型优于GPT - 4o，接近OpenAI o3 - mini。
            arXiv:2411.16365v4 Announce Type: replace 
Abstract: We present a systematic investigation of Multi-modal Retrieval Augmented Multi-modal Generation (M$^2$RAG), a novel task that enables foundation models to process multi-modal web content and generate multi-modal responses, which exhibits better information density and readability. Despite its potential impact, M$^2$RAG remains understudied, lacking comprehensive analysis and high-quality data resources. To address this gap, we establish a comprehensive benchmark through a rigorous data curation pipeline, and employ text-modal metrics and multi-modal metrics based on foundation models for evaluation. We further propose several strategies for foundation models to process M$^2$RAG task effectively and construct a training set by filtering high-quality samples using our designed metrics. Our extensive experiments demonstrate the reliability of our proposed metrics, a landscape of model performance within our designed strategies, and show that our fine-tuned 7B-8B models outperform the GPT-4o model and approach the state-of-the-art OpenAI o3-mini. Additionally, we perform fine-grained analyses across diverse domains and validate the effectiveness of our designs in data curation pipeline. All resources, including codes, datasets, and model weights, will be publicly released.
        ]]></description>
    </item>
    <item>
        <title>URSA: Understanding and Verifying Chain-of-thought Reasoning in Multimodal Mathematics</title>
        <link>https://arxiv.org/abs/2501.04686</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2501.04686v5</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ruilin Luo, Zhuofan Zheng, Yifan Wang, Xinzhe Ni, Zicheng Lin, Songtao Jiang, Yiyao Yu, Chufan Shi, Ruihang Chu, Jin Zeng, Yujiu Yang</dc:creator>
        <description><![CDATA[
            背景：过程奖励模型（PRMs）在提升大语言模型数学推理能力上有潜力，但在多模态推理中的应用待探索，且存在高质量推理数据稀缺等问题。方法：提出URSA三阶段训练框架，构建高质量多模态思维链推理数据集MMathCoT - 1M，合成过程监督数据，提出PS - GRPO多模态PRM辅助在线强化学习方法。效果：URSA - 8B - PS - GRPO在6个基准测试中平均比Gemma3 - 12B和GPT - 4o分别高8.4%和2.7%。
            arXiv:2501.04686v5 Announce Type: replace 
Abstract: Process Reward Models (PRMs) have shown promise in enhancing the mathematical reasoning capabilities of Large Language Models (LLMs) through Test-Time Scaling (TTS). However, their integration into multimodal reasoning remains largely unexplored. In this work, we take the first step toward unlocking the potential of PRMs in multimodal mathematical reasoning. We identify three key challenges: (1) the scarcity of high-quality reasoning data constrains the capabilities of foundation Multimodal Large Language Models (MLLMs), which imposes further limitations on the upper bounds of TTS and reinforcement learning (RL); (2) a lack of automated methods for process labeling within multimodal contexts persists; (3) the employment of process rewards in unimodal RL faces issues like reward hacking, which may extend to multimodal scenarios. To address these issues, we introduce URSA, a three-stage Unfolding multimodal Process-Supervision Aided training framework. We first construct MMathCoT-1M, a high-quality large-scale multimodal Chain-of-Thought (CoT) reasoning dataset, to build a stronger math reasoning foundation MLLM, URSA-8B. Subsequently, we go through an automatic process to synthesize process supervision data, which emphasizes both logical correctness and perceptual consistency. We introduce DualMath-1.1M to facilitate the training of URSA-8B-RM. Finally, we propose Process-Supervised Group-Relative-Policy-Optimization (PS-GRPO), pioneering a multimodal PRM-aided online RL method that outperforms vanilla GRPO. With PS-GRPO application, URSA-8B-PS-GRPO outperforms Gemma3-12B and GPT-4o by 8.4% and 2.7% on average across 6 benchmarks. Code, data and checkpoint can be found at https://github.com/URSA-MATH.
        ]]></description>
    </item>
    <item>
        <title>Vendi-RAG: Adaptively Trading-Off Diversity And Quality Significantly Improves Retrieval Augmented Generation With LLMs</title>
        <link>https://arxiv.org/abs/2502.11228</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.11228v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mohammad Reza Rezaei, Adji Bousso Dieng</dc:creator>
        <description><![CDATA[
            背景：传统检索增强生成（RAG）系统用于特定领域问答任务时，主要基于相关性检索，处理多源信息推理时易冗余。方法：提出Vendi - RAG框架，通过迭代过程联合优化检索多样性和答案质量，利用Vendi Score促进文档检索的语义多样性，用大语言模型评估候选答案以平衡相关性和多样性。效果：在三个数据集上实验表明，相比传统RAG方法显著提升多跳推理任务准确率，如在HotpotQA上最高提升4.2%，且对不同大模型骨干均有效。
            arXiv:2502.11228v2 Announce Type: replace 
Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs) for domain-specific question-answering (QA) tasks by leveraging external knowledge sources. However, traditional RAG systems primarily focus on relevance-based retrieval and often struggle with redundancy, especially when reasoning requires connecting information from multiple sources. This paper introduces Vendi-RAG, a framework based on an iterative process that jointly optimizes retrieval diversity and answer quality. This joint optimization leads to significantly higher accuracy for multi-hop QA tasks. Vendi-RAG leverages the Vendi Score (VS), a flexible similarity-based diversity metric, to promote semantic diversity in document retrieval. It then uses an LLM judge that evaluates candidate answers, generated after a reasoning step, and outputs a score that the retriever uses to balance relevance and diversity among the retrieved documents during each iteration. Experiments on three challenging datasets -- HotpotQA, MuSiQue, and 2WikiMultiHopQA -- demonstrate Vendi-RAG's effectiveness in multi-hop reasoning tasks. The framework achieves significant accuracy improvements over traditional single-step and multi-step RAG approaches, with accuracy increases reaching up to +4.2% on HotpotQA, +4.1% on 2WikiMultiHopQA, and +1.3% on MuSiQue compared to Adaptive-RAG, the current best baseline. The benefits of Vendi-RAG are even more pronounced as the number of retrieved documents increases. Finally, we evaluated Vendi-RAG across different LLM backbones, including GPT-3.5, GPT-4, and GPT-4o-mini, and observed consistent improvements, demonstrating that the framework's advantages are model-agnostic.
        ]]></description>
    </item>
    <item>
        <title>ICA-RAG: Information Completeness Guided Adaptive Retrieval-Augmented Generation for Disease Diagnosis</title>
        <link>https://arxiv.org/abs/2502.14614</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.14614v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mingyi Jia, Zhihao Jia, Junwen Duan, Yan Song, Jianxin Wang</dc:creator>
        <description><![CDATA[
            背景：检索增强大语言模型在医学领域表现出色，但现有RAG方法难根据诊断难度和输入样本信息量调整检索策略，导致效率低、准确率下降。方法：提出ICA - RAG框架，利用自适应控制模块根据输入信息完整性评估检索必要性，优化检索并进行知识过滤。效果：在三个中文电子病历数据集实验显示，ICA - RAG显著优于基线方法，在临床诊断中效果良好。
            arXiv:2502.14614v4 Announce Type: replace 
Abstract: Retrieval-Augmented Large Language Models~(LLMs), which integrate external knowledge, have shown remarkable performance in medical domains, including clinical diagnosis. However, existing RAG methods often struggle to tailor retrieval strategies to diagnostic difficulty and input sample informativeness. This limitation leads to excessive and often unnecessary retrieval, impairing computational efficiency and increasing the risk of introducing noise that can degrade diagnostic accuracy. To address this, we propose ICA-RAG (\textbf{I}nformation \textbf{C}ompleteness Guided \textbf{A}daptive \textbf{R}etrieval-\textbf{A}ugmented \textbf{G}eneration), a novel framework for enhancing RAG reliability in disease diagnosis. ICA-RAG utilizes an adaptive control module to assess the necessity of retrieval based on the input's information completeness. By optimizing retrieval and incorporating knowledge filtering, ICA-RAG better aligns retrieval operations with clinical requirements. Experiments on three Chinese electronic medical record datasets demonstrate that ICA-RAG significantly outperforms baseline methods, highlighting its effectiveness in clinical diagnosis.
        ]]></description>
    </item>
    <item>
        <title>Retrieval-Augmented Fine-Tuning With Preference Optimization For Visual Program Generation</title>
        <link>https://arxiv.org/abs/2502.16529</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.16529v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Deokhyung Kang, Jeonghun Cho, Yejin Jeon, Sunbin Jang, Minsub Lee, Jawoon Cho, Gary Geunbae Lee</dc:creator>
        <description><![CDATA[
            背景：可视化编程语言（VPLs）应用广泛，现有基于提示的大语言模型生成VPL代码方法对工业VPL（如梯形图LD）效果不佳。方法：提出两阶段训练策略，先进行检索增强微调利用工业VPL子程序复用性，再通过图编辑操作生成偏好对进行直接偏好优化（DPO）引导模型输出。效果：在真实LD数据实验中，该方法较监督微调使程序级准确率提升超10%，有助于推动工业自动化。
            arXiv:2502.16529v2 Announce Type: replace 
Abstract: Visual programming languages (VPLs) allow users to create programs through graphical interfaces, which results in easier accessibility and their widespread usage in various domains. To further enhance this accessibility, recent research has focused on generating VPL code from user instructions using large language models (LLMs). Specifically, by employing prompting-based methods, these studies have shown promising results. Nevertheless, such approaches can be less effective for industrial VPLs such as Ladder Diagram (LD). LD is a pivotal language used in industrial automation processes and involves extensive domain-specific configurations, which are difficult to capture in a single prompt. In this work, we demonstrate that training-based methods outperform prompting-based methods for LD generation accuracy, even with smaller backbone models. Building on these findings, we propose a two-stage training strategy to further enhance VPL generation. First, we employ retrieval-augmented fine-tuning to leverage the repetitive use of subroutines commonly seen in industrial VPLs. Second, we apply direct preference optimization (DPO) to further guide the model toward accurate outputs, using systematically generated preference pairs through graph editing operations. Extensive experiments on real-world LD data demonstrate that our approach improves program-level accuracy by over 10% compared to supervised fine-tuning, which highlights its potential to advance industrial automation.
        ]]></description>
    </item>
    <item>
        <title>Do Retrieval-Augmented Language Models Adapt to Varying User Needs?</title>
        <link>https://arxiv.org/abs/2502.19779</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.19779v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Peilin Wu, Xinlu Zhang, Wenhao Yu, Xingyu Liu, Xinya Du, Zhiyu Zoey Chen</dc:creator>
        <description><![CDATA[
            背景：检索增强语言模型（RALMs）在知识密集型任务中有效，但现有评估基准未考虑用户需求差异。方法：本文提出新评估框架，在三种用户需求场景和三种上下文设置下系统评估RALMs，通过改变用户指令和检索信息性质，模拟现实应用的复杂性。效果：在多个问答数据集实验发现，限制内存使用在对抗性检索条件下提高鲁棒性，但在理想检索结果下降低峰值性能，模型家族主导行为差异。
            arXiv:2502.19779v2 Announce Type: replace 
Abstract: Recent advancements in Retrieval-Augmented Language Models (RALMs) have demonstrated their efficacy in knowledge-intensive tasks. However, existing evaluation benchmarks often assume a single optimal approach to leveraging retrieved information, failing to account for varying user needs. This paper introduces a novel evaluation framework that systematically assesses RALMs under three user need cases-Context-Exclusive, Context-First, and Memory-First-across three distinct context settings: Context Matching, Knowledge Conflict, and Information Irrelevant. By varying both user instructions and the nature of retrieved information, our approach captures the complexities of real-world applications where models must adapt to diverse user requirements. Through extensive experiments on multiple QA datasets, including HotpotQA, DisentQA, and our newly constructed synthetic URAQ dataset, we find that restricting memory usage improves robustness in adversarial retrieval conditions but decreases peak performance with ideal retrieval results and model family dominates behavioral differences. Our findings highlight the necessity of user-centric evaluations in the development of retrieval-augmented systems and provide insights into optimizing model performance across varied retrieval contexts. We will release our code and URAQ dataset upon acceptance of the paper.
        ]]></description>
    </item>
    <item>
        <title>HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs</title>
        <link>https://arxiv.org/abs/2503.02003</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.02003v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tin Nguyen, Logan Bolton, Mohammad Reza Taesiri, Anh Totti Nguyen</dc:creator>
        <description><![CDATA[
            大语言模型易产生非事实陈述，混合真假信息的回复给人类验证和决策带来挑战。为此，研究提出高亮思维链提示（HoT）技术，让模型用XML标签生成回复，将事实与查询内容关联。先给问题添加XML标签突出关键事实，再生成含高亮引用事实的回复。在小样本场景下，HoT在17种任务中表现优于普通思维链提示。它能助人类限时验证回复，但模型答错时，会让用户误信答案正确。
            arXiv:2503.02003v3 Announce Type: replace 
Abstract: An Achilles heel of Large Language Models (LLMs) is their tendency to hallucinate non-factual statements. A response mixed of factual and non-factual statements poses a challenge for humans to verify and accurately base their decisions on. To combat this problem, we propose Highlighted Chain-of-Thought Prompting (HoT), a technique for prompting LLMs to generate responses with XML tags that ground facts to those provided in the query. That is, given an input question, LLMs would first re-format the question to add XML tags highlighting key facts, and then, generate a response with highlights over the facts referenced from the input. Interestingly, in few-shot settings, HoT outperforms vanilla chain of thought prompting (CoT) on a wide range of 17 tasks from arithmetic, reading comprehension to logical reasoning. When asking humans to verify LLM responses, highlights help time-limited participants to more accurately and efficiently recognize when LLMs are correct. Yet, surprisingly, when LLMs are wrong, HoTs tend to make users believe that an answer is correct.
        ]]></description>
    </item>
    <item>
        <title>Compositional Causal Reasoning Evaluation in Language Models</title>
        <link>https://arxiv.org/abs/2503.04556</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.04556v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jacqueline R. M. A. Maasch, Alihan H\"uy\"uk, Xinnuo Xu, Aditya V. Nori, Javier Gonzalez</dc:creator>
        <description><![CDATA[
            背景：因果推理和组合推理是AI核心目标，需有效评估方法。方法：提出组合因果推理（CCR）统一视角，即推断因果度量如何组合及因果量如何通过图传播的能力，构建系统评估CCR的框架，以平均处理效果和必要性与充分性概率为例，对LLama、Phi和GPT系列语言模型进行评估。效果：在数学应用题上，框架揭示多种不同错误模式，除o1外，所有模型CCR错误随因果路径复杂度增加而上升。
            arXiv:2503.04556v3 Announce Type: replace 
Abstract: Causal reasoning and compositional reasoning are two core aspirations in AI. Measuring the extent of these behaviors requires principled evaluation methods. We explore a unified perspective that considers both behaviors simultaneously, termed compositional causal reasoning (CCR): the ability to infer how causal measures compose and, equivalently, how causal quantities propagate through graphs. We instantiate a framework for the systematic evaluation of CCR for the average treatment effect and the probability of necessity and sufficiency. As proof of concept, we demonstrate CCR evaluation for language models in the LLama, Phi, and GPT families. On a math word problem, our framework revealed a range of taxonomically distinct error patterns. CCR errors increased with the complexity of causal paths for all models except o1.
        ]]></description>
    </item>
    <item>
        <title>MedPlan:A Two-Stage RAG-Based System for Personalized Medical Plan Generation</title>
        <link>https://arxiv.org/abs/2503.17900</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.17900v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hsin-Ling Hsu, Cong-Tinh Dao, Luning Wang, Zitao Shuai, Thao Nguyen Minh Phan, Jun-En Ding, Chun-Chieh Liao, Pengfei Hu, Xiaoxue Han, Chih-Ho Hsu, Dongsheng Luo, Wen-Chih Peng, Feng Liu, Fang-Ming Hung, Chenwei Wu</dc:creator>
        <description><![CDATA[
            背景：当前大语言模型应用于电子病历多聚焦评估而非治疗规划，且存在生成无顺序推理、少结合患者历史信息、难区分主客观信息等问题。方法：受SOAP方法启发，提出MedPlan框架，采用两阶段架构，先基于患者症状和客观数据生成临床评估，再通过检索增强生成制定含患者特定信息的结构化治疗方案。效果：综合评估显示，该方法在评估准确性和治疗方案质量上显著优于基线方法。
            arXiv:2503.17900v2 Announce Type: replace 
Abstract: Despite recent success in applying large language models (LLMs) to electronic health records (EHR), most systems focus primarily on assessment rather than treatment planning. We identify three critical limitations in current approaches: they generate treatment plans in a single pass rather than following the sequential reasoning process used by clinicians; they rarely incorporate patient-specific historical context; and they fail to effectively distinguish between subjective and objective clinical information. Motivated by the SOAP methodology (Subjective, Objective, Assessment, Plan), we introduce \ours{}, a novel framework that structures LLM reasoning to align with real-life clinician workflows. Our approach employs a two-stage architecture that first generates a clinical assessment based on patient symptoms and objective data, then formulates a structured treatment plan informed by this assessment and enriched with patient-specific information through retrieval-augmented generation. Comprehensive evaluation demonstrates that our method significantly outperforms baseline approaches in both assessment accuracy and treatment plan quality.
        ]]></description>
    </item>
    <item>
        <title>STI-Bench: Are MLLMs Ready for Precise Spatial-Temporal World Understanding?</title>
        <link>https://arxiv.org/abs/2503.23765</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.23765v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yun Li, Yiming Zhang, Tao Lin, XiangRui Liu, Wenxiao Cai, Zheng Liu, Bo Zhao</dc:creator>
        <description><![CDATA[
            背景：多模态大模型在具身AI和自动驾驶中应用成趋势，但在现实应用中精确时空理解能力待考察。方法：提出STI - Bench基准，通过估计和预测物体外观、姿态、位移和运动等挑战性任务评估多模态大模型的时空理解能力，涵盖多种场景下的机器人和车辆操作。效果：实验表明，现有先进多模态大模型在现实时空理解上仍面临困难，尤其在精确距离估计和运动分析任务中表现不佳。
            arXiv:2503.23765v4 Announce Type: replace 
Abstract: The use of Multimodal Large Language Models (MLLMs) as an end-to-end solution for Embodied AI and Autonomous Driving has become a prevailing trend. While MLLMs have been extensively studied for visual semantic understanding tasks, their ability to perform precise and quantitative spatial-temporal understanding in real-world applications remains largely unexamined, leading to uncertain prospects. To evaluate models' Spatial-Temporal Intelligence, we introduce STI-Bench, a benchmark designed to evaluate MLLMs' spatial-temporal understanding through challenging tasks such as estimating and predicting the appearance, pose, displacement, and motion of objects. Our benchmark encompasses a wide range of robot and vehicle operations across desktop, indoor, and outdoor scenarios. The extensive experiments reveals that the state-of-the-art MLLMs still struggle in real-world spatial-temporal understanding, especially in tasks requiring precise distance estimation and motion analysis.
        ]]></description>
    </item>
    <item>
        <title>TimeCapsule: Solving the Jigsaw Puzzle of Long-Term Time Series Forecasting with Compressed Predictive Representations</title>
        <link>https://arxiv.org/abs/2504.12721</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.12721v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yihang Lu, Yangyang Xu, Qitao Qing, Xianwei Meng</dc:creator>
        <description><![CDATA[
            背景：当前深度学习长时序预测模型设计复杂，而线性模型等简单架构表现更优。方法：论文梳理先进长时序预测模型常用技术核心思想，提出基于高维信息压缩原理的TimeCapsule模型，将时间序列建模为3D张量，利用模式积捕捉多模式依赖并降维，在压缩表示域内进行内部预测，用联合嵌入预测架构监测预测表示学习。效果：在多个基准测试中，该模型展现出通用性，达到了当前最优性能。
            arXiv:2504.12721v3 Announce Type: replace 
Abstract: Recent deep learning models for Long-term Time Series Forecasting (LTSF) often emphasize complex, handcrafted designs, while simpler architectures like linear models or MLPs have often outperformed these intricate solutions. In this paper, we revisit and organize the core ideas behind several key techniques, such as redundancy reduction and multi-scale modeling, which are frequently employed in advanced LTSF models. Our goal is to streamline these ideas for more efficient deep learning utilization. To this end, we introduce TimeCapsule, a model built around the principle of high-dimensional information compression that unifies these techniques in a generalized yet simplified framework. Specifically, we model time series as a 3D tensor, incorporating temporal, variate, and level dimensions, and leverage mode production to capture multi-mode dependencies while achieving dimensionality compression. We propose an internal forecast within the compressed representation domain, supported by the Joint-Embedding Predictive Architecture (JEPA), to monitor the learning of predictive representations. Extensive experiments on challenging benchmarks demonstrate the versatility of our method, showing that TimeCapsule can achieve state-of-the-art performance.
        ]]></description>
    </item>
    <item>
        <title>UniEdit: A Unified Knowledge Editing Benchmark for Large Language Models</title>
        <link>https://arxiv.org/abs/2505.12345</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12345v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qizhou Chen, Dakan Wang, Taolin Zhang, Zaoming Yan, Chengsong You, Chengyu Wang, Xiaofeng He</dc:creator>
        <description><![CDATA[
            背景：当前多数大语言模型编辑数据集局限于狭窄知识领域，编辑评估范围有限。方法：提出统一基准UniEdit，从25个常见领域选实体构建编辑样本，用开放知识图谱三元组知识确保覆盖度；设计NMCS算法采样子图以评估编辑影响；用专有大模型将子图转为自然语言文本。效果：统计分析证实了基准的规模、全面性和多样性，多模型和编辑器实验分析了其在开放知识领域和不同评估标准下的优缺点，为后续研究提供参考。
            arXiv:2505.12345v2 Announce Type: replace 
Abstract: Model editing aims to enhance the accuracy and reliability of large language models (LLMs) by efficiently adjusting their internal parameters. Currently, most LLM editing datasets are confined to narrow knowledge domains and cover a limited range of editing evaluation. They often overlook the broad scope of editing demands and the diversity of ripple effects resulting from edits. In this context, we introduce UniEdit, a unified benchmark for LLM editing grounded in open-domain knowledge. First, we construct editing samples by selecting entities from 25 common domains across five major categories, utilizing the extensive triple knowledge available in open-domain knowledge graphs to ensure comprehensive coverage of the knowledge domains. To address the issues of generality and locality in editing, we design an Neighborhood Multi-hop Chain Sampling (NMCS) algorithm to sample subgraphs based on a given knowledge piece to entail comprehensive ripple effects to evaluate. Finally, we employ proprietary LLMs to convert the sampled knowledge subgraphs into natural language text, guaranteeing grammatical accuracy and syntactical diversity. Extensive statistical analysis confirms the scale, comprehensiveness, and diversity of our UniEdit benchmark. We conduct comprehensive experiments across multiple LLMs and editors, analyzing their performance to highlight strengths and weaknesses in editing across open knowledge domains and various evaluation criteria, thereby offering valuable insights for future research endeavors.
        ]]></description>
    </item>
    <item>
        <title>Enhancing Channel-Independent Time Series Forecasting via Cross-Variate Patch Embedding</title>
        <link>https://arxiv.org/abs/2505.12761</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12761v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Donghwa Shin, Edwin Zhang</dc:creator>
        <description><![CDATA[
            背景：Transformers用于时间序列预测时，现有模型多只关注时间依赖，忽略变量间复杂关系，且部分模型全层依赖通道，易过拟合。方法：提出轻量级通道依赖模块Cross - Variate Patch Embeddings（CVPE），通过修改补丁嵌入过程，向通道独立模型注入跨变量上下文，还将其集成到多模态通道独立预测模型Time - LLM中。效果：在七个真实数据集上实验表明，仅集成CVPE模块，增强后的Time - LLM性能就优于原基线模型。
            arXiv:2505.12761v3 Announce Type: replace 
Abstract: Transformers have recently gained popularity in time series forecasting due to their ability to capture long-term dependencies. However, many existing models focus only on capturing temporal dependencies while omitting intricate relationships between variables. Recent models have tried tackling this by explicitly modeling both cross-time and cross-variate dependencies through a sequential or unified attention mechanism, but they are entirely channel dependent (CD) across all layers, making them potentially susceptible to overfitting. To address this, we propose Cross-Variate Patch Embeddings (CVPE), a lightweight CD module that injects cross-variate context into channel-independent (CI) models by simply modifying the patch embedding process. We achieve this by adding a learnable positional encoding and a lightweight router-attention block to the vanilla patch embedding layer. We then integrate CVPE into Time-LLM, a multimodal CI forecasting model, to demonstrate its effectiveness in capturing cross-variate dependencies and enhance the CI model's performance. Extensive experimental results on seven real-world datasets show that our enhanced Time-LLM outperforms the original baseline model simply by incorporating the CVPE module, with no other changes.
        ]]></description>
    </item>
    <item>
        <title>Rank, Chunk and Expand: Lineage-Oriented Reasoning for Taxonomy Expansion</title>
        <link>https://arxiv.org/abs/2505.13282</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13282v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sahil Mishra, Kumar Arjun, Tanmoy Chakraborty</dc:creator>
        <description><![CDATA[
            背景：分类法作为层次化知识图谱，在数据增长背景下进行扩展很重要，但现有判别和生成方法存在局限性。方法：提出LORex框架，结合判别排序和生成推理进行分类法扩展，对候选术语排序分块，过滤噪声，通过推理候选者层次结构迭代优化选择。效果：在四个基准和十二个基线模型上实验，相比现有最优方法，准确率提高12%，Wu & Palmer相似度提高5%。
            arXiv:2505.13282v3 Announce Type: replace 
Abstract: Taxonomies are hierarchical knowledge graphs crucial for recommendation systems, and web applications. As data grows, expanding taxonomies is essential, but existing methods face key challenges: (1) discriminative models struggle with representation limits and generalization, while (2) generative methods either process all candidates at once, introducing noise and exceeding context limits, or discard relevant entities by selecting noisy candidates. We propose LORex ($\textbf{L}$ineage-$\textbf{O}$riented $\textbf{Re}$asoning for Taxonomy E$\textbf{x}$pansion), a plug-and-play framework that combines discriminative ranking and generative reasoning for efficient taxonomy expansion. Unlike prior methods, LORex ranks and chunks candidate terms into batches, filtering noise and iteratively refining selections by reasoning candidates' hierarchy to ensure contextual efficiency. Extensive experiments across four benchmarks and twelve baselines show that LORex improves accuracy by 12% and Wu & Palmer similarity by 5% over state-of-the-art methods.
        ]]></description>
    </item>
    <item>
        <title>ThinkLess: A Training-Free Inference-Efficient Method for Reducing Reasoning Redundancy</title>
        <link>https://arxiv.org/abs/2505.15684</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.15684v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Gengyang Li, Yifeng Gao, Yuming Li, Yunfang Wu</dc:creator>
        <description><![CDATA[
            背景：思维链提示虽提升大语言模型推理能力，但推理令牌过长会增加延迟和缓存内存使用，甚至截断最终答案。方法：提出ThinkLess框架，通过注意力分析发现答案令牌主要关注推理终止符，在早期位置插入终止符跳过冗余推理，并用轻量级后调节机制防止格式混乱。效果：无需微调或辅助数据，在大幅减少解码时间和内存消耗的同时，达到与全长度思维链解码相当的准确率。
            arXiv:2505.15684v2 Announce Type: replace 
Abstract: While Chain-of-Thought (CoT) prompting improves reasoning in large language models (LLMs), the excessive length of reasoning tokens increases latency and KV cache memory usage, and may even truncate final answers under context limits. We propose ThinkLess, an inference-efficient framework that terminates reasoning generation early and maintains output quality without modifying the model. Atttention analysis reveals that answer tokens focus minimally on earlier reasoning steps and primarily attend to the reasoning terminator token, due to information migration under causal masking. Building on this insight, ThinkLess inserts the terminator token at earlier positions to skip redundant reasoning while preserving the underlying knowledge transfer. To prevent format discruption casued by early termination, ThinkLess employs a lightweight post-regulation mechanism, relying on the model's natural instruction-following ability to produce well-structured answers. Without fine-tuning or auxiliary data, ThinkLess achieves comparable accuracy to full-length CoT decoding while greatly reducing decoding time and memory consumption.
        ]]></description>
    </item>
    <item>
        <title>Panoptic Captioning: Seeking An Equivalency Bridge for Image and Text</title>
        <link>https://arxiv.org/abs/2505.16334</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.16334v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kun-Yu Lin, Hongjun Wang, Weining Ren, Kai Han</dc:creator>
        <description><![CDATA[
            背景：现有多模态大模型在解决全景字幕任务（为图像生成全面文本描述）时性能有限。方法：提出数据引擎PancapEngine生成高质量数据，用精心设计的检测套件检测图像实体并使用实体感知提示生成字幕；提出PancapChain方法，将任务拆分为多阶段逐步生成字幕；还贡献了评估指标PancapScore和人工标注测试集。效果：PancapChain - 13B模型超越InternVL - 2.5 - 78B等开源模型及GPT - 4o、Gemini - 2.0 - Pro等专有模型。
            arXiv:2505.16334v2 Announce Type: replace 
Abstract: This work introduces panoptic captioning, a novel task striving to seek the minimum text equivalence of images. We take the first step towards panoptic captioning by formulating it as a task of generating a comprehensive textual description for an image, which encapsulates all entities, their respective locations and attributes, relationships among entities, as well as global image state. Through an extensive evaluation, our work reveals that state-of-the-art Multi-modal Large Language Models (MLLMs) have limited performance in solving panoptic captioning. To address this, we propose an effective data engine named PancapEngine to produce high-quality data and a novel method named PancapChain to improve panoptic captioning. Specifically, our PancapEngine first detects diverse categories of entities in images by an elaborate detection suite, and then generates required panoptic captions using entity-aware prompts. Additionally, our PancapChain explicitly decouples the challenging panoptic captioning task into multiple stages and generates panoptic captions step by step. More importantly, we contribute a comprehensive metric named PancapScore and a human-curated test set for reliable model evaluation. Experiments show that our PancapChain-13B model can beat state-of-the-art open-source MLLMs like InternVL-2.5-78B and even surpass proprietary models like GPT-4o and Gemini-2.0-Pro, demonstrating the effectiveness of our data engine and method. Project page: https://visual-ai.github.io/pancap/
        ]]></description>
    </item>
    <item>
        <title>Think Silently, Think Fast: Dynamic Latent Compression of LLM Reasoning Chains</title>
        <link>https://arxiv.org/abs/2505.16552</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.16552v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wenhui Tan, Jiaze Li, Jianzhong Ju, Zhenbo Luo, Jian Luan, Ruihua Song</dc:creator>
        <description><![CDATA[
            大语言模型通过思维链推理取得良好效果，但标记级推理链计算成本高、效率低。本文提出压缩潜在推理（CoLaR）框架，采用两阶段训练方法在潜在空间动态压缩推理过程。一是在监督微调时加入辅助的下一个压缩嵌入预测目标；二是通过强化学习探索更多推理路径。实验表明，在四个数学推理数据集上，CoLaR在相近压缩率下比潜在基线方法准确率高14.1%，相比显式思维链方法推理链长度减少53.3%，性能仅下降4.8%；在更具挑战性任务中性能提升达5.4%，潜在推理链长度减少82.8%。
            arXiv:2505.16552v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) achieve superior performance through Chain-of-Thought (CoT) reasoning, but these token-level reasoning chains are computationally expensive and inefficient. In this paper, we introduce Compressed Latent Reasoning (CoLaR), a novel framework that dynamically compresses reasoning processes in latent space through a two-stage training approach. First, during supervised fine-tuning, CoLaR extends beyond next-token prediction by incorporating an auxiliary next compressed embedding prediction objective. This process merges embeddings of consecutive tokens using a compression factor randomly sampled from a predefined range, and trains a specialized latent head to predict distributions of subsequent compressed embeddings. Second, we enhance CoLaR through reinforcement learning (RL) that leverages the latent head's non-deterministic nature to explore diverse reasoning paths and exploit more compact ones. This approach enables CoLaR to: i) perform reasoning at a dense latent level (i.e., silently), substantially reducing reasoning chain length, and ii) dynamically adjust reasoning speed at inference time by simply prompting the desired compression factor. Extensive experiments across four mathematical reasoning datasets demonstrate that CoLaR achieves 14.1% higher accuracy than latent-based baseline methods at comparable compression ratios, and reduces reasoning chain length by 53.3% with only 4.8% performance degradation compared to explicit CoT method. Moreover, when applied to more challenging mathematical reasoning tasks, our RL-enhanced CoLaR demonstrates performance gains of up to 5.4% while dramatically reducing latent reasoning chain length by 82.8%. The code and models will be released upon acceptance.
        ]]></description>
    </item>
    <item>
        <title>RBench-V: A Primary Assessment for Visual Reasoning Models with Multi-modal Outputs</title>
        <link>https://arxiv.org/abs/2505.16770</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.16770v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Meng-Hao Guo, Xuanyu Chu, Qianrui Yang, Zhe-Han Mo, Yiqing Shen, Pei-lin Li, Xinjie Lin, Jinnian Zhang, Xin-Sheng Chen, Yi Zhang, Kiyohiro Nakayama, Zhengyang Geng, Houwen Peng, Han Hu, Shi-Min Hu</dc:creator>
        <description><![CDATA[
            背景：原生多模态模型和全模态模型发展迅速，但现有多模态模型评估基准主要关注多模态输入和纯文本推理，忽视多模态输出推理。方法：提出RBench - V基准，精心挑选803个涵盖数学、物理等领域的问题，聚焦多模态输出，需图像操作辅助推理。效果：对多个开源和闭源模型评估，表现最佳的o3模型在RBench - V上准确率仅25.8%，远低于人类的82.3%，表明当前模型多模态推理能力不足。
            arXiv:2505.16770v2 Announce Type: replace 
Abstract: The rapid advancement of native multi-modal models and omni-models, exemplified by GPT-4o, Gemini, and o3, with their capability to process and generate content across modalities such as text and images, marks a significant milestone in the evolution of intelligence. Systematic evaluation of their multi-modal output capabilities in visual thinking processes (also known as multi-modal chain of thought, M-CoT) becomes critically important. However, existing benchmarks for evaluating multi-modal models primarily focus on assessing multi-modal inputs and text-only reasoning while neglecting the importance of reasoning through multi-modal outputs. In this paper, we present a benchmark, dubbed RBench-V, designed to assess models' vision-indispensable reasoning abilities. To construct RBench-V, we carefully hand-pick 803 questions covering math, physics, counting, and games. Unlike previous benchmarks that typically specify certain input modalities, RBench-V presents problems centered on multi-modal outputs, which require image manipulation such as generating novel images and constructing auxiliary lines to support the reasoning process. We evaluate numerous open- and closed-source models on RBench-V, including o3, Gemini 2.5 Pro, Qwen2.5-VL, etc. Even the best-performing model, o3, achieves only 25.8% accuracy on RBench-V, far below the human score of 82.3%, highlighting that current models struggle to leverage multi-modal reasoning. Data and code are available at https://evalmodels.github.io/rbenchv
        ]]></description>
    </item>
    <item>
        <title>FoMoH: A clinically meaningful foundation model evaluation for structured electronic health records</title>
        <link>https://arxiv.org/abs/2505.16941</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.16941v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chao Pang, Vincent Jeanselme, Young Sang Choi, Xinzhuo Jiang, Zilin Jing, Aparajita Kashyap, Yuta Kobayashi, Yanwei Li, Florent Pollet, Karthik Natarajan, Shalmali Joshi</dc:creator>
        <description><![CDATA[
            背景：基础模型在医疗保健领域潜力大，基于结构化电子健康记录（EHR）数据训练有出色表现，但因缺乏综合有意义任务和多样评估，其临床实用性存争议。方法：提出一套涵盖患者预后、急慢性疾病早期预测等临床有意义的任务及评估指标，在包含500万患者的EHR数据上对先进基础模型进行14项临床相关任务评估。效果：通过测量整体准确性、校准度和亚群体表现，揭示预训练、分词和数据表示策略选择的权衡，推动结构化EHR基础模型评估并指导未来医疗基础模型发展。
            arXiv:2505.16941v2 Announce Type: replace 
Abstract: Foundation models hold significant promise in healthcare, given their capacity to extract meaningful representations independent of downstream tasks. This property has enabled state-of-the-art performance across several clinical applications trained on structured electronic health record (EHR) data, even in settings with limited labeled data, a prevalent challenge in healthcare. However, there is little consensus on these models' potential for clinical utility due to the lack of desiderata of comprehensive and meaningful tasks and sufficiently diverse evaluations to characterize the benefit over conventional supervised learning. To address this gap, we propose a suite of clinically meaningful tasks spanning patient outcomes, early prediction of acute and chronic conditions, including desiderata for robust evaluations. We evaluate state-of-the-art foundation models on EHR data consisting of 5 million patients from Columbia University Irving Medical Center (CUMC), a large urban academic medical center in New York City, across 14 clinically relevant tasks. We measure overall accuracy, calibration, and subpopulation performance to surface tradeoffs based on the choice of pre-training, tokenization, and data representation strategies. Our study aims to advance the empirical evaluation of structured EHR foundation models and guide the development of future healthcare foundation models.
        ]]></description>
    </item>
    <item>
        <title>Towards Copyright Protection for Knowledge Bases of Retrieval-augmented Language Models via Reasoning</title>
        <link>https://arxiv.org/abs/2502.10440</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.10440v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Junfeng Guo, Yiming Li, Ruibo Chen, Yihan Wu, Chenxi Liu, Yanshuo Chen, Heng Huang</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）机制让大语言模型结合特定领域知识，但知识库有被非法使用风险，现有水印保护方法易被检测且有新安全风险。方法：提出一种‘无害’版权保护方法，在思维链（CoT）推理空间植入良性验证行为，分生成CoTs、优化水印短语和目标CoTs、所有权验证三阶段。效果：实验表明该方法能有效保护知识库，且能抵抗自适应攻击。
            arXiv:2502.10440v2 Announce Type: replace-cross 
Abstract: Large language models (LLMs) are increasingly integrated into real-world personalized applications through retrieval-augmented generation (RAG) mechanisms to supplement their responses with domain-specific knowledge. However, the valuable and often proprietary nature of the knowledge bases used in RAG introduces the risk of unauthorized usage by adversaries. Existing methods that can be generalized as watermarking techniques to protect these knowledge bases typically involve poisoning or backdoor attacks. However, these methods require altering the LLM's results of verification samples, inevitably making these watermarks susceptible to anomaly detection and even introducing new security risks. To address these challenges, we propose \name{} for `harmless' copyright protection of knowledge bases. Instead of manipulating LLM's final output, \name{} implants distinct yet benign verification behaviors in the space of chain-of-thought (CoT) reasoning, maintaining the correctness of the final answer. Our method has three main stages: (1) Generating CoTs: For each verification question, we generate two `innocent' CoTs, including a target CoT for building watermark behaviors; (2) Optimizing Watermark Phrases and Target CoTs: Inspired by our theoretical analysis, we optimize them to minimize retrieval errors under the \emph{black-box} and \emph{text-only} setting of suspicious LLM, ensuring that only watermarked verification queries can retrieve their correspondingly target CoTs contained in the knowledge base; (3) Ownership Verification: We exploit a pairwise Wilcoxon test to verify whether a suspicious LLM is augmented with the protected knowledge base by comparing its responses to watermarked and benign verification queries. Our experiments on diverse benchmarks demonstrate that \name{} effectively protects knowledge bases and its resistance to adaptive attacks.
        ]]></description>
    </item>
    <item>
        <title>Table-Critic: A Multi-Agent Framework for Collaborative Criticism and Refinement in Table Reasoning</title>
        <link>https://arxiv.org/abs/2502.11799</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.11799v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Peiying Yu, Guoxin Chen, Jingjing Wang</dc:creator>
        <description><![CDATA[
            背景：大语言模型在表格推理任务中存在不足，尤其难在多步推理中保持一致性，现有方法缺乏识别和纠正中间推理步骤错误的有效机制。方法：提出Table - Critic多智能体框架，含判断、批评、改进、提炼四种智能体，还引入自我进化模板树积累批评知识。效果：大量实验表明，该框架较现有方法有显著提升，准确率和纠错率更高，计算效率高且解退化率更低。
            arXiv:2502.11799v3 Announce Type: replace-cross 
Abstract: Despite the remarkable capabilities of large language models (LLMs) in various reasoning tasks, they still struggle with table reasoning tasks, particularly in maintaining consistency throughout multi-step reasoning processes. While existing approaches have explored various decomposition strategies, they often lack effective mechanisms to identify and correct errors in intermediate reasoning steps, leading to cascading error propagation. To address these issues, we propose Table-Critic, a novel multi-agent framework that facilitates collaborative criticism and iterative refinement of the reasoning process until convergence to correct solutions. Our framework consists of four specialized agents: a Judge for error identification, a Critic for comprehensive critiques, a Refiner for process improvement, and a Curator for pattern distillation. To effectively deal with diverse and unpredictable error types, we introduce a self-evolving template tree that systematically accumulates critique knowledge through experience-driven learning and guides future reflections. Extensive experiments have demonstrated that Table-Critic achieves substantial improvements over existing methods, achieving superior accuracy and error correction rates while maintaining computational efficiency and lower solution degradation rate.
        ]]></description>
    </item>
    <item>
        <title>Unearthing Gems from Stones: Policy Optimization with Negative Sample Augmentation for LLM Reasoning</title>
        <link>https://arxiv.org/abs/2505.14403</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14403v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhaohui Yang, Shilei Jiang, Chen Hu, Linjing Li, Shihong Deng, Daxin Jiang</dc:creator>
        <description><![CDATA[
            背景：推理语言模型从短思维链转向长思维链，长思维链模型推演计算成本高，需最大化固定训练数据集效用，而现有方法未充分利用负样本学习信号。方法：提出带负样本增强的行为约束策略梯度（BCPG - NSA）细粒度离线强化学习框架，包括样本分割、结合大语言模型和PRM评判器的步骤正确性评估、用负样本增强进行策略优化。效果：在多个数学/编码推理基准测试中，BCPG - NSA优于基线，提高样本效率，多轮迭代时具鲁棒性和可扩展性。
            arXiv:2505.14403v2 Announce Type: replace-cross 
Abstract: Recent advances in reasoning language models have witnessed a paradigm shift from short to long CoT pattern. Given the substantial computational cost of rollouts in long CoT models, maximizing the utility of fixed training datasets becomes crucial. Our analysis reveals that negative responses contain valuable components such as self-reflection and error-correction steps, yet primary existing methods either completely discard negative samples (RFT) or apply equal penalization across all tokens (RL), failing to leverage these potential learning signals. In light of this, we propose Behavior Constrained Policy Gradient with Negative Sample Augmentation (BCPG-NSA), a fine-grained offline RL framework that encompasses three stages: 1) sample segmentation, 2) consensus-based step correctness assessment combining LLM and PRM judgers, and 3) policy optimization with NSA designed to effectively mine positive steps within negative samples. Experimental results show that BCPG-NSA outperforms baselines on several challenging math/coding reasoning benchmarks using the same training dataset, achieving improved sample efficiency and demonstrating robustness and scalability when extended to multiple iterations.
        ]]></description>
    </item>
    <item>
        <title>When to Continue Thinking: Adaptive Thinking Mode Switching for Efficient Reasoning</title>
        <link>https://arxiv.org/abs/2505.15400</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.15400v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiaoyun Zhang, Jingqing Ruan, Xing Ma, Yawen Zhu, Haodong Zhao, Hao Li, Jiansong Chen, Ke Zeng, Xunliang Cai</dc:creator>
        <description><![CDATA[
            背景：大型推理模型通过长推理链取得出色性能，但在简单任务上因冗余推理产生过多计算开销。方法：系统量化长思考和无思考模式下模型上限，发现“内部自我恢复机制”，提出自适应自我恢复推理（ASRR）框架，引入准确率感知的长度奖励调节，根据问题难度自适应分配推理精力。效果：实验显示，与GRPO相比，ASRR在1.5B和7B模型上最多分别减少32.5%和25.7%的推理预算，准确率损失极小（1.2%和0.6% pass@1），还显著提高安全基准的无害率。
            arXiv:2505.15400v2 Announce Type: replace-cross 
Abstract: Large reasoning models (LRMs) achieve remarkable performance via long reasoning chains, but often incur excessive computational overhead due to redundant reasoning, especially on simple tasks. In this work, we systematically quantify the upper bounds of LRMs under both Long-Thinking and No-Thinking modes, and uncover the phenomenon of "Internal Self-Recovery Mechanism" where models implicitly supplement reasoning during answer generation. Building on this insight, we propose Adaptive Self-Recovery Reasoning (ASRR), a framework that suppresses unnecessary reasoning and enables implicit recovery. By introducing accuracy-aware length reward regulation, ASRR adaptively allocates reasoning effort according to problem difficulty, achieving high efficiency with negligible performance sacrifice. Experiments across multiple benchmarks and models show that, compared with GRPO, ASRR reduces reasoning budget by up to 32.5% (1.5B) and 25.7% (7B) with minimal accuracy loss (1.2% and 0.6% pass@1), and significantly boosts harmless rates on safety benchmarks (up to +21.7%). Our results highlight the potential of ASRR for enabling efficient, adaptive, and safer reasoning in LRMs.
        ]]></description>
    </item>
    <item>
        <title>InfoDeepSeek: Benchmarking Agentic Information Seeking for Retrieval-Augmented Generation</title>
        <link>https://arxiv.org/abs/2505.15872</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.15872v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yunjia Xi, Jianghao Lin, Menghui Zhu, Yongzhao Xiao, Zhuoying Ou, Jiaqi Liu, Tong Wan, Bo Chen, Weiwen Liu, Yasheng Wang, Ruiming Tang, Weinan Zhang, Yong Yu</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）能借助检索信息提升大语言模型，但现有基准在评估相关系统时存在局限，无法适应真实动态网络环境。方法：提出InfoDeepSeek基准，设计挑战性问题，构建满足确定性、难度和多样性标准的查询，开发适用于动态信息检索的评估框架及细粒度指标。效果：通过对大语言模型、搜索引擎和问题类型的大量实验，揭示了细微的智能体行为，为未来研究提供了可行见解。
            arXiv:2505.15872v2 Announce Type: replace-cross 
Abstract: Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by grounding responses with retrieved information. As an emerging paradigm, Agentic RAG further enhances this process by introducing autonomous LLM agents into the information seeking process. However, existing benchmarks fall short in evaluating such systems, as they are confined to a static retrieval environment with a fixed, limited corpus} and simple queries that fail to elicit agentic behavior. Moreover, their evaluation protocols assess information seeking effectiveness by pre-defined gold sets of documents, making them unsuitable for the open-ended and dynamic nature of real-world web environments. To bridge this gap, we present InfoDeepSeek, a new benchmark with challenging questions designed for assessing agentic information seeking in real-world, dynamic web environments. We propose a systematic methodology for constructing challenging queries satisfying the criteria of determinacy, difficulty, and diversity. Based on this, we develop the first evaluation framework tailored to dynamic agentic information seeking, including fine-grained metrics about the accuracy, utility, and compactness of information seeking outcomes. Through extensive experiments across LLMs, search engines, and question types, InfoDeepSeek reveals nuanced agent behaviors and offers actionable insights for future research.
        ]]></description>
    </item>
    <item>
        <title>ReMi: A Random Recurrent Neural Network Approach to Music Production</title>
        <link>https://arxiv.org/abs/2505.17023</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17023v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hugo Chateau-Laurent, Tara Vanhatalo</dc:creator>
        <description><![CDATA[
            背景：生成式人工智能在音乐创作中存在能耗、版权及创造力萎缩等问题。方法：提出ReMi，采用随机初始化的循环神经网络生成琶音和低频振荡，与旨在取代音乐家的端到端音乐生成不同，该方法无需数据且计算量小，可拓展音乐家创造力。效果：能产生丰富且可配置的琶音和低频振荡。更多信息见https://allendia.com/ 。
            arXiv:2505.17023v1 Announce Type: new 
Abstract: Generative artificial intelligence raises concerns related to energy consumption, copyright infringement and creative atrophy. We show that randomly initialized recurrent neural networks can produce arpeggios and low-frequency oscillations that are rich and configurable. In contrast to end-to-end music generation that aims to replace musicians, our approach expands their creativity while requiring no data and much less computational power. More information can be found at: https://allendia.com/
        ]]></description>
    </item>
    <item>
        <title>Voicing Personas: Rewriting Persona Descriptions into Style Prompts for Controllable Text-to-Speech</title>
        <link>https://arxiv.org/abs/2505.17093</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17093v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yejin Lee, Jaehoon Kang, Kyuhong Shim</dc:creator>
        <description><![CDATA[
            背景：在基于提示的可控文本转语音系统中需控制语音风格。方法：提出利用文本人物形象作为语音风格提示的框架，给出两种将通用人物描述转化为面向语音提示的策略，实现对音高、情感和语速等韵律属性的细粒度控制。效果：实验表明，该方法提升了合成语音的自然度、清晰度和一致性。此外，还分析了基于大语言模型改写引入的社会偏见，强调语音风格对人物驱动的人工智能对话系统至关重要。
            arXiv:2505.17093v1 Announce Type: new 
Abstract: In this paper, we propose a novel framework to control voice style in prompt-based, controllable text-to-speech systems by leveraging textual personas as voice style prompts. We present two persona rewriting strategies to transform generic persona descriptions into speech-oriented prompts, enabling fine-grained manipulation of prosodic attributes such as pitch, emotion, and speaking rate. Experimental results demonstrate that our methods enhance the naturalness, clarity, and consistency of synthesized speech. Finally, we analyze implicit social biases introduced by LLM-based rewriting, with a focus on gender. We underscore voice style as a crucial factor for persona-driven AI dialogue systems.
        ]]></description>
    </item>
    <item>
        <title>UniTTS: An end-to-end TTS system without decoupling of acoustic and semantic information</title>
        <link>https://arxiv.org/abs/2505.17426</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17426v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Rui Wang, Qianguo Sun, Tianrong Chen, Zhiyun Zeng, Junlong Wu, Jiaxing Zhang</dc:creator>
        <description><![CDATA[
            背景：基于大语言模型（LLM）的文本转语音（TTS）系统受多码本中性音频编解码器推动，但语义和声学信息无法完全对齐，限制了大模型获取完整音频信息。方法：提出DistilCodec和UniTTS，将多码本音频编解码器提炼为单码本，训练时可融入大量无标注音频，在UniTTS预训练框架中集成三项关键任务，采用三阶段训练。效果：单码本有32768个码且利用率近100%，UniTTS能接受交错文本和语音提示，保留LLM文本能力。
            arXiv:2505.17426v1 Announce Type: new 
Abstract: The emergence of multi-codebook neutral audio codecs such as Residual Vector Quantization (RVQ) and Group Vector Quantization (GVQ) has significantly advanced Large-Language-Model (LLM) based Text-to-Speech (TTS) systems. These codecs are crucial in separating semantic and acoustic information while efficiently harnessing semantic priors. However, since semantic and acoustic information cannot be fully aligned, a significant drawback of these methods when applied to LLM-based TTS is that large language models may have limited access to comprehensive audio information. To address this limitation, we propose DistilCodec and UniTTS, which collectively offer the following advantages: 1) This method can distill a multi-codebook audio codec into a single-codebook audio codec with 32,768 codes while achieving a near 100\% utilization. 2) As DistilCodec does not employ a semantic alignment scheme, a large amount of high-quality unlabeled audio (such as audiobooks with sound effects, songs, etc.) can be incorporated during training, further expanding data diversity and broadening its applicability. 3) Leveraging the comprehensive audio information modeling of DistilCodec, we integrated three key tasks into UniTTS's pre-training framework: audio modality autoregression, text modality autoregression, and speech-text cross-modal autoregression. This allows UniTTS to accept interleaved text and speech/audio prompts while substantially preserving LLM's text capabilities. 4) UniTTS employs a three-stage training process: Pre-Training, Supervised Fine-Tuning (SFT), and Alignment. Source code and model checkpoints are publicly available at https://github.com/IDEA-Emdoor-Lab/UniTTS and https://github.com/IDEA-Emdoor-Lab/DistilCodec.
        ]]></description>
    </item>
    <item>
        <title>CosyVoice 3: Towards In-the-wild Speech Generation via Scaling-up and Post-training</title>
        <link>https://arxiv.org/abs/2505.17589</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17589v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhihao Du, Changfeng Gao, Yuxuan Wang, Fan Yu, Tianyu Zhao, Hao Wang, Xiang Lv, Hui Wang, Xian Shi, Keyu An, Guanrou Yang, Yabin Li, Yanni Chen, Zhifu Gao, Qian Chen, Yue Gu, Mengzhe Chen, Yafeng Chen, Shiliang Zhang, Wen Wang, Jieping Ye</dc:creator>
        <description><![CDATA[
            背景：先前的CosyVoice 2在语言覆盖、领域多样性等方面存在局限。方法：提出CosyVoice 3用于野外零样本多语言语音合成，采用新的语音分词器提升韵律自然度，设计可微奖励模型用于后训练，将训练数据从一万小时扩展到一百万小时，涵盖9种语言和18种汉语方言，模型参数从5亿增加到15亿。效果：在内容一致性、说话人相似度和韵律自然度上超越前代，在多语言基准测试中表现更优。
            arXiv:2505.17589v1 Announce Type: new 
Abstract: In our prior works, we introduced a scalable streaming speech synthesis model, CosyVoice 2, which integrates a large language model (LLM) and a chunk-aware flow matching (FM) model, and achieves low-latency bi-streaming speech synthesis and human-parity quality. Despite these advancements, CosyVoice 2 exhibits limitations in language coverage, domain diversity, data volume, text formats, and post-training techniques. In this paper, we present CosyVoice 3, an improved model designed for zero-shot multilingual speech synthesis in the wild, surpassing its predecessor in content consistency, speaker similarity, and prosody naturalness. Key features of CosyVoice 3 include: 1) A novel speech tokenizer to improve prosody naturalness, developed via supervised multi-task training, including automatic speech recognition, speech emotion recognition, language identification, audio event detection, and speaker analysis. 2) A new differentiable reward model for post-training applicable not only to CosyVoice 3 but also to other LLM-based speech synthesis models. 3) Dataset Size Scaling: Training data is expanded from ten thousand hours to one million hours, encompassing 9 languages and 18 Chinese dialects across various domains and text formats. 4) Model Size Scaling: Model parameters are increased from 0.5 billion to 1.5 billion, resulting in enhanced performance on our multilingual benchmark due to the larger model capacity. These advancements contribute significantly to the progress of speech synthesis in the wild. We encourage readers to listen to the demo at https://funaudiollm.github.io/cosyvoice3.
        ]]></description>
    </item>
    <item>
        <title>Audio-to-Audio Emotion Conversion With Pitch And Duration Style Transfer</title>
        <link>https://arxiv.org/abs/2505.17655</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17655v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Soumya Dutta, Avni Jain, Sriram Ganapathy</dc:creator>
        <description><![CDATA[
            背景：音频到音频风格迁移旨在生成模仿参考音频风格特征，同时保留源音频内容和说话人属性的语音。方法：提出A2A零样本情感风格迁移（A2A - ZEST）框架，分析模块将语音分解为语义标记、说话人表征和情感嵌入，学习音高轮廓估计器和时长预测器，合成模块根据输入表征和派生因素生成语音，以自监督方式训练。效果：实验表明，A2A - ZEST在内容/说话人保留和情感风格迁移有效性评估上优于先前工作，可在无平行训练数据下实现风格迁移，还能用于情感识别任务的数据增强。
            arXiv:2505.17655v1 Announce Type: new 
Abstract: Given a pair of source and reference speech recordings, audio-to-audio (A2A) style transfer involves the generation of an output speech that mimics the style characteristics of the reference while preserving the content and speaker attributes of the source. In this paper, we propose a novel framework, termed as A2A Zero-shot Emotion Style Transfer (A2A-ZEST), that enables the transfer of reference emotional attributes to the source while retaining its speaker and speech contents. The A2A-ZEST framework consists of an analysis-synthesis pipeline, where the analysis module decomposes speech into semantic tokens, speaker representations, and emotion embeddings. Using these representations, a pitch contour estimator and a duration predictor are learned. Further, a synthesis module is designed to generate speech based on the input representations and the derived factors. This entire paradigm of analysis-synthesis is trained purely in a self-supervised manner with an auto-encoding loss. For A2A emotion style transfer, the emotion embedding extracted from the reference speech along with the rest of the representations from the source speech are used in the synthesis module to generate the style translated speech. In our experiments, we evaluate the converted speech on content/speaker preservation (w.r.t. source) as well as on the effectiveness of the emotion style transfer (w.r.t. reference). The proposal, A2A-ZEST, is shown to improve over other prior works on these evaluations, thereby enabling style transfer without any parallel training data. We also illustrate the application of the proposed work for data augmentation in emotion recognition tasks.
        ]]></description>
    </item>
    <item>
        <title>Impact of Frame Rates on Speech Tokenizer: A Case Study on Mandarin and English</title>
        <link>https://arxiv.org/abs/2505.17076</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17076v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Haoyang Zhang, Hexin Liu, Xiangyu Zhang, Qiquan Zhang, Yuchen Hu, Junqi Zhao, Fei Tian, Xuerui Yang, Eng Siong Chng</dc:creator>
        <description><![CDATA[
            背景：语音分词器在语音任务中至关重要，低帧率编解码器常用作语音分词器，但帧率对语音标记的影响研究不足。方法：研究通过考察普通话和英语这两种类型不同的语言，以不同帧率对语音编码，并在语音识别任务中评估语义标记。效果：发现帧率变化对不同语言的语音标记影响不同，凸显了帧率、语音密度和特定语言声学特征之间的相互作用，为优化语音分词器帧率选择提供了见解。
            arXiv:2505.17076v1 Announce Type: cross 
Abstract: The speech tokenizer plays a crucial role in recent speech tasks, generally serving as a bridge between speech signals and language models. While low-frame-rate codecs are widely employed as speech tokenizers, the impact of frame rates on speech tokens remains underexplored. In this study, we investigate how varying frame rates affect speech tokenization by examining Mandarin and English, two typologically distinct languages. We encode speech at different frame rates and evaluate the resulting semantic tokens in the speech recognition task. Our findings reveal that frame rate variations influence speech tokenization differently for each language, highlighting the interplay between frame rates, phonetic density, and language-specific acoustic features. The results provide insights into optimizing frame rate selection for speech tokenizers, with implications for automatic speech recognition, text-to-speech, and other speech-related applications.
        ]]></description>
    </item>
    <item>
        <title>Large Language Models Implicitly Learn to See and Hear Just By Reading</title>
        <link>https://arxiv.org/abs/2505.17091</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17091v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Prateek Verma, Mert Pilanci</dc:creator>
        <description><![CDATA[
            背景：以往视听大语言模型需微调文本大语言模型以基于图像和音频嵌入输出文本。方法：该论文提出在文本标记上训练自回归大语言模型，模型可内在地发展出理解图像和音频的能力，其架构以图像块、音频波形或标记为输入，给出分类管道的嵌入或类别标签。效果：展示了文本权重对FSD - 50K和GTZAN数据集音频分类的作用，也验证了在CIFAR - 10等图像分类上的效果，避免每次从头训练模型。 
            arXiv:2505.17091v1 Announce Type: cross 
Abstract: This paper presents a fascinating find: By training an auto-regressive LLM model on text tokens, the text model inherently develops internally an ability to understand images and audio, thereby developing the ability to see and hear just by reading. Popular audio and visual LLM models fine-tune text LLM models to give text output conditioned on images and audio embeddings. On the other hand, our architecture takes in patches of images, audio waveforms or tokens as input. It gives us the embeddings or category labels typical of a classification pipeline. We show the generality of text weights in aiding audio classification for datasets FSD-50K and GTZAN. Further, we show this working for image classification on CIFAR-10 and Fashion-MNIST, as well on image patches. This pushes the notion of text-LLMs learning powerful internal circuits that can be utilized by activating necessary connections for various applications rather than training models from scratch every single time.
        ]]></description>
    </item>
    <item>
        <title>Semantic-Aware Interpretable Multimodal Music Auto-Tagging</title>
        <link>https://arxiv.org/abs/2505.17233</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17233v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Andreas Patakis, Vassilis Lyberatos, Spyridon Kantarelis, Edmund Dervakos, Giorgos Stamou</dc:creator>
        <description><![CDATA[
            背景：音乐自动标注对数字音乐库的整理和检索至关重要，但基础模型输出缺乏可解释性，限制了其应用。方法：提出可解释音乐自动标注框架，利用从信号处理、深度学习等领域获取的多模态特征，对特征进行语义聚类，采用期望最大化算法，根据特征组对标注过程的贡献分配权重。效果：该方法在标注性能上具有竞争力，且能让用户更深入理解决策过程，为构建更透明、以用户为中心的音乐标注系统奠定基础。
            arXiv:2505.17233v1 Announce Type: cross 
Abstract: Music auto-tagging is essential for organizing and discovering music in extensive digital libraries. While foundation models achieve exceptional performance in this domain, their outputs often lack interpretability, limiting trust and usability for researchers and end-users alike. In this work, we present an interpretable framework for music auto-tagging that leverages groups of musically meaningful multimodal features, derived from signal processing, deep learning, ontology engineering, and natural language processing. To enhance interpretability, we cluster features semantically and employ an expectation maximization algorithm, assigning distinct weights to each group based on its contribution to the tagging process. Our method achieves competitive tagging performance while offering a deeper understanding of the decision-making process, paving the way for more transparent and user-centric music tagging systems.
        ]]></description>
    </item>
    <item>
        <title>Benchmarking Expressive Japanese Character Text-to-Speech with VITS and Style-BERT-VITS2</title>
        <link>https://arxiv.org/abs/2505.17320</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17320v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zackary Rackauckas, Julia Hirschberg</dc:creator>
        <description><![CDATA[
            背景：因对音调重音敏感和风格多变，合成富有表现力的日语角色语音存在挑战。方法：本文在特定领域、角色驱动的日语语音上对VITS和Style - BERT - VITS2 JP Extra（SBV2JE）两个开源文本转语音模型进行基准测试，利用三个角色特定数据集，从自然度、可懂度和说话人一致性方面评估。效果：SBV2JE在自然度上与真人接近（MOS 4.37对比4.38），字错误率更低，比较平均意见得分稍优，虽计算需求高，但在语言学习和角色对话生成等应用中有效。
            arXiv:2505.17320v1 Announce Type: cross 
Abstract: Synthesizing expressive Japanese character speech poses unique challenges due to pitch-accent sensitivity and stylistic variability. This paper benchmarks two open-source text-to-speech models--VITS and Style-BERT-VITS2 JP Extra (SBV2JE)--on in-domain, character-driven Japanese speech. Using three character-specific datasets, we evaluate models across naturalness (mean opinion and comparative mean opinion score), intelligibility (word error rate), and speaker consistency. SBV2JE matches human ground truth in naturalness (MOS 4.37 vs. 4.38), achieves lower WER, and shows slight preference in CMOS. Enhanced by pitch-accent controls and a WavLM-based discriminator, SBV2JE proves effective for applications like language learning and character dialogue generation, despite higher computational demands.
        ]]></description>
    </item>
    <item>
        <title>Exploring the Effect of Segmentation and Vocabulary Size on Speech Tokenization for Speech Language Models</title>
        <link>https://arxiv.org/abs/2505.17446</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17446v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Shunsuke Kando, Yusuke Miyao, Shinnosuke Takamichi</dc:creator>
        <description><![CDATA[
            背景：语音标记化是语音语言模型（SLMs）的基础，但不同标记化方式对SLMs性能的影响尚不明确。方法：研究语音标记化的分割宽度和离散单元聚类大小两个关键方面，将语音信号分割为固定/可变宽度及池化表示，训练不同聚类大小的K-means模型。效果：在零样本口语理解基准测试中，适度粗分割和较大聚类大小有积极效果。最佳模型中最有效的一个使训练数据减少50%，训练时间减少70%，分析强调组合多标记对增强细粒度口语理解很重要。
            arXiv:2505.17446v1 Announce Type: cross 
Abstract: The purpose of speech tokenization is to transform a speech signal into a sequence of discrete representations, serving as the foundation for speech language models (SLMs). While speech tokenization has many options, their effect on the performance of SLMs remains unclear. This paper investigates two key aspects of speech tokenization: the segmentation width and the cluster size of discrete units. First, we segment speech signals into fixed/variable widths and pooled representations. We then train K-means models in multiple cluster sizes. Through the evaluation on zero-shot spoken language understanding benchmarks, we find the positive effect of moderately coarse segmentation and bigger cluster size. Notably, among the best-performing models, the most efficient one achieves a 50% reduction in training data and a 70% decrease in training runtime. Our analysis highlights the importance of combining multiple tokens to enhance fine-grained spoken language understanding.
        ]]></description>
    </item>
    <item>
        <title>What You Read Isn't What You Hear: Linguistic Sensitivity in Deepfake Speech Detection</title>
        <link>https://arxiv.org/abs/2505.17513</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17513v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Binh Nguyen, Shuji Shi, Ryan Ofman, Thai Le</dc:creator>
        <description><![CDATA[
            背景：文本转语音技术进步使音频深度伪造攻击增多，现有音频反欺骗系统多关注声学层面，未充分探索语言变化影响。方法：引入转录级对抗攻击，研究开源和商用反欺骗检测器的语言敏感性，进行特征归因分析。效果：小的语言扰动会显著降低检测准确率，多个开源检测器 - 语音对攻击成功率超 60%，一个商用检测器对合成音频检测准确率从 100% 降至 32%，案例研究中转录对抗攻击可绕过商用检测器。
            arXiv:2505.17513v1 Announce Type: cross 
Abstract: Recent advances in text-to-speech technologies have enabled realistic voice generation, fueling audio-based deepfake attacks such as fraud and impersonation. While audio anti-spoofing systems are critical for detecting such threats, prior work has predominantly focused on acoustic-level perturbations, leaving the impact of linguistic variation largely unexplored. In this paper, we investigate the linguistic sensitivity of both open-source and commercial anti-spoofing detectors by introducing transcript-level adversarial attacks. Our extensive evaluation reveals that even minor linguistic perturbations can significantly degrade detection accuracy: attack success rates surpass 60% on several open-source detector-voice pairs, and notably one commercial detection accuracy drops from 100% on synthetic audio to just 32%. Through a comprehensive feature attribution analysis, we identify that both linguistic complexity and model-level audio embedding similarity contribute strongly to detector vulnerability. We further demonstrate the real-world risk via a case study replicating the Brad Pitt audio deepfake scam, using transcript adversarial attacks to completely bypass commercial detectors. These results highlight the need to move beyond purely acoustic defenses and account for linguistic variation in the design of robust anti-spoofing systems. All source code will be publicly available.
        ]]></description>
    </item>
    <item>
        <title>JALMBench: Benchmarking Jailbreak Vulnerabilities in Audio Language Models</title>
        <link>https://arxiv.org/abs/2505.17568</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17568v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zifan Peng, Yule Liu, Zhen Sun, Mingchen Li, Zeren Luo, Jingyi Zheng, Wenhan Dong, Xinlei He, Xuechao Wang, Yingjie Xue, Shengmin Xu, Xinyi Huang</dc:creator>
        <description><![CDATA[
            背景：音频语言模型（ALMs）发展迅速，但针对其越狱攻击的安全性研究较少，且缺乏评估框架和数据集。方法：提出首个评估ALMs抗越狱攻击安全性的综合基准JALMBench，包含2200个文本样本和超268小时的51381个音频样本，支持12种主流ALMs、8种攻击方法和5种防御方法。效果：利用该基准深入分析攻击效率等，还探索了提示和响应层面的攻击缓解策略。
            arXiv:2505.17568v1 Announce Type: cross 
Abstract: Audio Language Models (ALMs) have made significant progress recently. These models integrate the audio modality directly into the model, rather than converting speech into text and inputting text to Large Language Models (LLMs). While jailbreak attacks on LLMs have been extensively studied, the security of ALMs with audio modalities remains largely unexplored. Currently, there is a lack of an adversarial audio dataset and a unified framework specifically designed to evaluate and compare attacks and ALMs. In this paper, we present JALMBench, the \textit{first} comprehensive benchmark to assess the safety of ALMs against jailbreak attacks. JALMBench includes a dataset containing 2,200 text samples and 51,381 audio samples with over 268 hours. It supports 12 mainstream ALMs, 4 text-transferred and 4 audio-originated attack methods, and 5 defense methods. Using JALMBench, we provide an in-depth analysis of attack efficiency, topic sensitivity, voice diversity, and attack representations. Additionally, we explore mitigation strategies for the attacks at both the prompt level and the response level.
        ]]></description>
    </item>
    <item>
        <title>SAKURA: On the Multi-hop Reasoning of Large Audio-Language Models Based on Speech and Audio Information</title>
        <link>https://arxiv.org/abs/2505.13237</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13237v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chih-Kai Yang, Neo Ho, Yen-Ting Piao, Hung-yi Lee</dc:creator>
        <description><![CDATA[
            背景：大型音频语言模型（LALMs）在语音和音频处理任务上表现受广泛研究，但推理能力，尤其是多跳推理能力缺乏系统评估，现有基准忽视此方面。方法：引入基准SAKURA，用于评估LALMs基于语音和音频信息的多跳推理能力。效果：结果显示，即便LALMs能正确提取相关信息，也难以整合语音/音频表征进行多跳推理，暴露出LALMs在多模态推理中的根本挑战。
            arXiv:2505.13237v2 Announce Type: replace 
Abstract: Large audio-language models (LALMs) extend the large language models with multimodal understanding in speech, audio, etc. While their performances on speech and audio-processing tasks are extensively studied, their reasoning abilities remain underexplored. Particularly, their multi-hop reasoning, the ability to recall and integrate multiple facts, lacks systematic evaluation. Existing benchmarks focus on general speech and audio-processing tasks, conversational abilities, and fairness but overlook this aspect. To bridge this gap, we introduce SAKURA, a benchmark assessing LALMs' multi-hop reasoning based on speech and audio information. Results show that LALMs struggle to integrate speech/audio representations for multi-hop reasoning, even when they extract the relevant information correctly, highlighting a fundamental challenge in multimodal reasoning. Our findings expose a critical limitation in LALMs, offering insights and resources for future research.
        ]]></description>
    </item>
    <item>
        <title>U-SAM: An audio language Model for Unified Speech, Audio, and Music Understanding</title>
        <link>https://arxiv.org/abs/2505.13880</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13880v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ziqian Wang, Xianjun Xia, Xinfa Zhu, Lei Xie</dc:creator>
        <description><![CDATA[
            背景：现有音频模型在跨语音、音频事件和音乐等多种音频类型理解上有挑战，且依赖交叉熵损失进行对齐效果不佳。方法：提出U - SAM，将语音、音频和音乐的专用编码器与预训练大语言模型（LLM）集成，采用专家混合（MoE）投影器进行任务感知特征融合，还引入语义感知对比损失模块提升跨模态对齐。效果：在多个基准测试中始终优于专业模型和现有音频语言模型，在未见任务上也展现出泛化能力。
            arXiv:2505.13880v2 Announce Type: replace 
Abstract: The text generation paradigm for audio tasks has opened new possibilities for unified audio understanding. However, existing models face significant challenges in achieving a comprehensive understanding across diverse audio types, such as speech, general audio events, and music. Furthermore, their exclusive reliance on cross-entropy loss for alignment often falls short, as it treats all tokens equally and fails to account for redundant audio features, leading to weaker cross-modal alignment. To deal with the above challenges, this paper introduces U-SAM, an advanced audio language model that integrates specialized encoders for speech, audio, and music with a pre-trained large language model (LLM). U-SAM employs a Mixture of Experts (MoE) projector for task-aware feature fusion, dynamically routing and integrating the domain-specific encoder outputs. Additionally, U-SAM incorporates a Semantic-Aware Contrastive Loss Module, which explicitly identifies redundant audio features under language supervision and rectifies their semantic and spectral representations to enhance cross-modal alignment. Extensive experiments demonstrate that U-SAM consistently outperforms both specialized models and existing audio language models across multiple benchmarks. Moreover, it exhibits emergent capabilities on unseen tasks, showcasing its generalization potential. Code is available (https://github.com/Honee-W/U-SAM/).
        ]]></description>
    </item>
    <item>
        <title>Towards Holistic Evaluation of Large Audio-Language Models: A Comprehensive Survey</title>
        <link>https://arxiv.org/abs/2505.15957</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.15957v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chih-Kai Yang, Neo S. Ho, Hung-yi Lee</dc:creator>
        <description><![CDATA[
            背景：大音频语言模型（LALMs）发展迅速，但评估基准零散且缺乏结构化分类。方法：本文开展全面调研，提出系统的LALM评估分类法，从通用听觉感知与处理、知识与推理、对话能力、公平安全与可信度四个维度分类。结果：详细概述各维度情况，指出领域挑战并给出未来方向。这是首个聚焦LALM评估的调研，将发布调研论文集并维护，为领域发展提供指引。
            arXiv:2505.15957v2 Announce Type: replace 
Abstract: With advancements in large audio-language models (LALMs), which enhance large language models (LLMs) with auditory capabilities, these models are expected to demonstrate universal proficiency across various auditory tasks. While numerous benchmarks have emerged to assess LALMs' performance, they remain fragmented and lack a structured taxonomy. To bridge this gap, we conduct a comprehensive survey and propose a systematic taxonomy for LALM evaluations, categorizing them into four dimensions based on their objectives: (1) General Auditory Awareness and Processing, (2) Knowledge and Reasoning, (3) Dialogue-oriented Ability, and (4) Fairness, Safety, and Trustworthiness. We provide detailed overviews within each category and highlight challenges in this field, offering insights into promising future directions. To the best of our knowledge, this is the first survey specifically focused on the evaluations of LALMs, providing clear guidelines for the community. We will release the collection of the surveyed papers and actively maintain it to support ongoing advancements in the field.
        ]]></description>
    </item>
    <item>
        <title>EZ-VC: Easy Zero-shot Any-to-Any Voice Conversion</title>
        <link>https://arxiv.org/abs/2505.16691</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.16691v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Advait Joglekar, Divyanshu Singh, Rooshil Rohit Bhatia, S. Umesh</dc:creator>
        <description><![CDATA[
            背景：当前语音转换研究注重提升零样本能力，但现有架构在零样本跨语言场景表现不佳，难以泛化到未见语言和口音。方法：结合自监督模型的离散语音表征与基于非自回归Diffusion - Transformer的条件流匹配语音解码器，以纯无文本、自监督方式训练语音转换模型，无需多个编码器分离语音特征。效果：模型在零样本跨语言场景表现出色，对未见语言也有良好效果。
            arXiv:2505.16691v2 Announce Type: replace 
Abstract: Voice Conversion research in recent times has increasingly focused on improving the zero-shot capabilities of existing methods. Despite remarkable advancements, current architectures still tend to struggle in zero-shot cross-lingual settings. They are also often unable to generalize for speakers of unseen languages and accents. In this paper, we adopt a simple yet effective approach that combines discrete speech representations from self-supervised models with a non-autoregressive Diffusion-Transformer based conditional flow matching speech decoder. We show that this architecture allows us to train a voice-conversion model in a purely textless, self-supervised fashion. Our technique works without requiring multiple encoders to disentangle speech features. Our model also manages to excel in zero-shot cross-lingual settings even for unseen languages. For Demo: https://ez-vc.github.io/EZ-VC-Demo/
        ]]></description>
    </item>
    <item>
        <title>Adversarial Deep Metric Learning for Cross-Modal Audio-Text Alignment in Open-Vocabulary Keyword Spotting</title>
        <link>https://arxiv.org/abs/2505.16735</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.16735v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Youngmoon Jung, Yong-Hyeok Lee, Myunghun Jung, Jaeyoung Roh, Chang Woo Han, Hoon-Young Cho</dc:creator>
        <description><![CDATA[
            背景：在基于文本注册的开放词汇关键词检测中，声学和文本嵌入的比较面临音频与文本模态异质性挑战。方法：提出模态对抗学习（MAL），通过对抗训练模态分类器，促使编码器生成模态不变嵌入，减少异质模态表示的领域差距；还应用深度度量学习（DML）实现音频和文本的音素级对齐，并对不同DML目标进行广泛比较。效果：在华尔街日报和LibriPhrase数据集上的实验证明了该方法的有效性。
            arXiv:2505.16735v2 Announce Type: replace 
Abstract: For text enrollment-based open-vocabulary keyword spotting (KWS), acoustic and text embeddings are typically compared at either the phoneme or utterance level. To facilitate this, we optimize acoustic and text encoders using deep metric learning (DML), enabling direct comparison of multi-modal embeddings in a shared embedding space. However, the inherent heterogeneity between audio and text modalities presents a significant challenge. To address this, we propose Modality Adversarial Learning (MAL), which reduces the domain gap in heterogeneous modality representations. Specifically, we train a modality classifier adversarially to encourage both encoders to generate modality-invariant embeddings. Additionally, we apply DML to achieve phoneme-level alignment between audio and text, and conduct extensive comparisons across various DML objectives. Experiments on the Wall Street Journal (WSJ) and LibriPhrase datasets demonstrate the effectiveness of the proposed approach.
        ]]></description>
    </item>
    <item>
        <title>Enhancing Low-Resource Language and Instruction Following Capabilities of Audio Language Models</title>
        <link>https://arxiv.org/abs/2409.10999</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2409.10999v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Potsawee Manakul, Guangzhi Sun, Warit Sirichotedumrong, Kasima Tharnpipitchai, Kunat Pipatanakul</dc:creator>
        <description><![CDATA[
            背景：音频语言模型多基于英文训练，在低资源语言上可用性受限。方法：评估音频语言模型在泰语上的表现，发现其缺乏跨语言能力，进而探索数据混合方式，将音频理解和语音指令遵循整合到统一模型，平衡特定语言和多语言训练数据。效果：提出的Typhoon - Audio模型显著优于现有开源模型，在英语和泰语上的表现与最先进的Gemini - 1.5 - Pro相当。
            arXiv:2409.10999v2 Announce Type: replace-cross 
Abstract: Audio language models process audio inputs using textual prompts for tasks like speech recognition and audio captioning. Although built on multilingual pre-trained components, most are trained primarily on English, limiting their usability for other languages. This paper evaluates audio language models on Thai, a low-resource language, and finds that they lack emergent cross-lingual abilities despite their multilingual foundations. To address this, we explore data mixtures that optimize audio language models for both a target language and English while integrating audio comprehension and speech instruction-following into a unified model. Our experiments provide insights into improving instruction-following in low-resource languages by balancing language-specific and multilingual training data. The proposed model, Typhoon-Audio, significantly outperforms existing open-source models and achieves performance comparable to state-of-the-art Gemini-1.5-Pro in both English and Thai.
        ]]></description>
    </item>
</channel>
</rss>