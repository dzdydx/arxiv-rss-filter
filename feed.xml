<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
<channel>
    <title>arXiv Paper Filter</title>
    <link>https://github.com/None/arxiv_filter</link>
    <description>根据研究兴趣筛选的arXiv论文</description>
    <atom:link href="https://raw.githubusercontent.com/None/arxiv_filter/main/feed.xml" rel="self" type="application/rss+xml" />
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>zh-CN</language>
    <lastBuildDate>Tue, 15 Apr 2025 12:11:31 +0800</lastBuildDate>
    <managingEditor>None@github.com</managingEditor>
    <pubDate>Tue, 15 Apr 2025 12:11:31 +0800</pubDate>
    <skipDays>
        <day>Saturday</day>
        <day>Sunday</day>
    </skipDays>

    <item>
        <title>From Tokens to Lattices: Emergent Lattice Structures in Language Models</title>
        <link>https://arxiv.org/abs/2504.08778</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.08778v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Bo Xiong, Steffen Staab</dc:creator>
        <description><![CDATA[
            背景：预训练掩码语言模型（MLMs）展现出理解和编码概念知识的能力，揭示了概念间的格结构，但这种概念化如何从MLM预训练中出现尚待探究。方法：从形式概念分析（FCA）角度出发，表明MLM目标隐式学习了描述对象、属性及其依赖关系的形式上下文，提出从预训练MLMs构建概念格的新框架，研究MLMs在格结构学习中归纳偏置的来源。效果：创建三个数据集评估，实证结果验证了假设。
            arXiv:2504.08778v1 Announce Type: new 
Abstract: Pretrained masked language models (MLMs) have demonstrated an impressive capability to comprehend and encode conceptual knowledge, revealing a lattice structure among concepts. This raises a critical question: how does this conceptualization emerge from MLM pretraining? In this paper, we explore this problem from the perspective of Formal Concept Analysis (FCA), a mathematical framework that derives concept lattices from the observations of object-attribute relationships. We show that the MLM's objective implicitly learns a \emph{formal context} that describes objects, attributes, and their dependencies, which enables the reconstruction of a concept lattice through FCA. We propose a novel framework for concept lattice construction from pretrained MLMs and investigate the origin of the inductive biases of MLMs in lattice structure learning. Our framework differs from previous work because it does not rely on human-defined concepts and allows for discovering "latent" concepts that extend beyond human definitions. We create three datasets for evaluation, and the empirical results verify our hypothesis.
        ]]></description>
    </item>
    <item>
        <title>InfoGain Wavelets: Furthering the Design of Diffusion Wavelets for Graph-Structured Data</title>
        <link>https://arxiv.org/abs/2504.08802</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.08802v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>David R. Johnson, Smita Krishnaswamy, Michael Perlmutter</dc:creator>
        <description><![CDATA[
            背景：传统扩散小波在处理图结构数据时，扩散尺度通常选择二进整数。方法：本文基于信息论思想，提出一种无监督的扩散尺度选择方法，并将其融入基于小波的图神经网络。效果：通过图分类实验表明，该方法能有效应用于相关模型，有助于从图信号中以不同分辨率尺度提取信息，在图结构数据处理方面具有一定优势。
            arXiv:2504.08802v1 Announce Type: new 
Abstract: Diffusion wavelets extract information from graph signals at different scales of resolution by utilizing graph diffusion operators raised to various powers, known as diffusion scales. Traditionally, the diffusion scales are chosen to be dyadic integers, $\mathbf{2^j}$. Here, we propose a novel, unsupervised method for selecting the diffusion scales based on ideas from information theory. We then show that our method can be incorporated into wavelet-based GNNs via graph classification experiments.
        ]]></description>
    </item>
    <item>
        <title>Exploring the Effectiveness and Interpretability of Texts in LLM-based Time Series Models</title>
        <link>https://arxiv.org/abs/2504.08808</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.08808v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhengke Sun, Hangwei Qian, Ivor Tsang</dc:creator>
        <description><![CDATA[
            背景：大语言模型用于时间序列预测任务，借助预训练语言模型并引入文本数据提升其能力，但文本对可解释性的作用未知。方法：对文本提示和原型进行实验，还提出语义匹配指数（SMI）评估时间序列与文本匹配度。效果：发现两模态存在不对齐情况，很多时候文本信息未显著提升预测性能，现有框架学习的文本表征应用于时间序列数据时缺乏可解释性。代码见https://github.com/zachysun/TS-Lang-Exp 。
            arXiv:2504.08808v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have been applied to time series forecasting tasks, leveraging pre-trained language models as the backbone and incorporating textual data to purportedly enhance the comprehensive capabilities of LLMs for time series. However, are these texts really helpful for interpretation? This study seeks to investigate the actual efficacy and interpretability of such textual incorporations. Through a series of empirical experiments on textual prompts and textual prototypes, our findings reveal that the misalignment between two modalities exists, and the textual information does not significantly improve time series forecasting performance in many cases. Furthermore, visualization analysis indicates that the textual representations learned by existing frameworks lack sufficient interpretability when applied to time series data. We further propose a novel metric named Semantic Matching Index (SMI) to better evaluate the matching degree between time series and texts during our post hoc interpretability investigation. Our analysis reveals the misalignment and limited interpretability of texts in current time-series LLMs, and we hope this study can raise awareness of the interpretability of texts for time series. The code is available at https://github.com/zachysun/TS-Lang-Exp.
        ]]></description>
    </item>
    <item>
        <title>SafeMLRM: Demystifying Safety in Multi-modal Large Reasoning Models</title>
        <link>https://arxiv.org/abs/2504.08813</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.08813v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Junfeng Fang, Yukai Wang, Ruipeng Wang, Zijun Yao, Kun Wang, An Zhang, Xiang Wang, Tat-Seng Chua</dc:creator>
        <description><![CDATA[
            多模态大型推理模型（MLRMs）发展迅速，但安全问题未被充分研究。该研究首次对MLRMs进行系统安全分析，通过大规模实验对比MLRMs和基础多模态语言模型（MLLMs）。结果显示：一是推理能力会使安全对齐性大幅下降，MLRMs越狱成功率比MLLMs高37.44%；二是存在安全盲点，特定场景攻击率比平均高出25倍；三是MLRMs有初步自我纠正能力，16.9%的越狱推理步骤被安全答案覆盖。研究还开源了评估工具包。
            arXiv:2504.08813v1 Announce Type: new 
Abstract: The rapid advancement of multi-modal large reasoning models (MLRMs) -- enhanced versions of multimodal language models (MLLMs) equipped with reasoning capabilities -- has revolutionized diverse applications. However, their safety implications remain underexplored. While prior work has exposed critical vulnerabilities in unimodal reasoning models, MLRMs introduce distinct risks from cross-modal reasoning pathways. This work presents the first systematic safety analysis of MLRMs through large-scale empirical studies comparing MLRMs with their base MLLMs. Our experiments reveal three critical findings: (1) The Reasoning Tax: Acquiring reasoning capabilities catastrophically degrades inherited safety alignment. MLRMs exhibit 37.44% higher jailbreaking success rates than base MLLMs under adversarial attacks. (2) Safety Blind Spots: While safety degradation is pervasive, certain scenarios (e.g., Illegal Activity) suffer 25 times higher attack rates -- far exceeding the average 3.4 times increase, revealing scenario-specific vulnerabilities with alarming cross-model and datasets consistency. (3) Emergent Self-Correction: Despite tight reasoning-answer safety coupling, MLRMs demonstrate nascent self-correction -- 16.9% of jailbroken reasoning steps are overridden by safe answers, hinting at intrinsic safeguards. These findings underscore the urgency of scenario-aware safety auditing and mechanisms to amplify MLRMs' self-correction potential. To catalyze research, we open-source OpenSafeMLRM, the first toolkit for MLRM safety evaluation, providing unified interface for mainstream models, datasets, and jailbreaking methods. Our work calls for immediate efforts to harden reasoning-augmented AI, ensuring its transformative potential aligns with ethical safeguards.
        ]]></description>
    </item>
    <item>
        <title>From Text to Time? Rethinking the Effectiveness of the Large Language Model for Time Series Forecasting</title>
        <link>https://arxiv.org/abs/2504.08818</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.08818v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xinyu Zhang, Shanshan Feng, Xutao Li</dc:creator>
        <description><![CDATA[
            背景：用预训练大语言模型（LLMs）进行时间序列预测受关注，但LLM骨干在该领域的有效性存争议。方法：通过实证分析发现小数据集训练测试会使编解码器过度适配，为此引入三种架构相同、预训练策略不同的预训练模型，进行大规模预训练以创建适合LLM骨干的无偏编解码器，并通过对照实验评估其零样本和少样本预测性能。效果：实验表明LLM骨干有一定潜力，但预测性能有限。
            arXiv:2504.08818v1 Announce Type: new 
Abstract: Using pre-trained large language models (LLMs) as the backbone for time series prediction has recently gained significant research interest. However, the effectiveness of LLM backbones in this domain remains a topic of debate. Based on thorough empirical analyses, we observe that training and testing LLM-based models on small datasets often leads to the Encoder and Decoder becoming overly adapted to the dataset, thereby obscuring the true predictive capabilities of the LLM backbone. To investigate the genuine potential of LLMs in time series prediction, we introduce three pre-training models with identical architectures but different pre-training strategies. Thereby, large-scale pre-training allows us to create unbiased Encoder and Decoder components tailored to the LLM backbone. Through controlled experiments, we evaluate the zero-shot and few-shot prediction performance of the LLM, offering insights into its capabilities. Extensive experiments reveal that although the LLM backbone demonstrates some promise, its forecasting performance is limited. Our source code is publicly available in the anonymous repository: https://anonymous.4open.science/r/LLM4TS-0B5C.
        ]]></description>
    </item>
    <item>
        <title>Mimic In-Context Learning for Multimodal Tasks</title>
        <link>https://arxiv.org/abs/2504.08851</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.08851v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuchu Jiang, Jiale Fu, Chenduo Hao, Xinting Hu, Yingzhe Peng, Xin Geng, Xu Yang</dc:creator>
        <description><![CDATA[
            背景：上下文学习（ICL）成为多模态大模型重要推理范式，但多模态数据协同效应使ICL性能对上下文示例（ICDs）配置敏感，需更稳定通用的映射函数。方法：提出模仿上下文学习（MimIC），通过在大模型中集成轻量级可学习模块，严格近似ICDs的偏移效果，有插入偏移向量、为每个注意力头分配偏移向量等四项关键改进。效果：在两个大模型和三个多模态任务上实验表明，MimIC优于现有基于偏移向量的方法。
            arXiv:2504.08851v1 Announce Type: new 
Abstract: Recently, In-context Learning (ICL) has become a significant inference paradigm in Large Multimodal Models (LMMs), utilizing a few in-context demonstrations (ICDs) to prompt LMMs for new tasks. However, the synergistic effects in multimodal data increase the sensitivity of ICL performance to the configurations of ICDs, stimulating the need for a more stable and general mapping function. Mathematically, in Transformer-based models, ICDs act as ``shift vectors'' added to the hidden states of query tokens. Inspired by this, we introduce Mimic In-Context Learning (MimIC) to learn stable and generalizable shift effects from ICDs. Specifically, compared with some previous shift vector-based methods, MimIC more strictly approximates the shift effects by integrating lightweight learnable modules into LMMs with four key enhancements: 1) inserting shift vectors after attention layers, 2) assigning a shift vector to each attention head, 3) making shift magnitude query-dependent, and 4) employing a layer-wise alignment loss. Extensive experiments on two LMMs (Idefics-9b and Idefics2-8b-base) across three multimodal tasks (VQAv2, OK-VQA, Captioning) demonstrate that MimIC outperforms existing shift vector-based methods. The code is available at https://github.com/Kamichanw/MimIC.
        ]]></description>
    </item>
    <item>
        <title>Knowledge Graph-extended Retrieval Augmented Generation for Question Answering</title>
        <link>https://arxiv.org/abs/2504.08893</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.08893v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jasper Linders, Jakub M. Tomczak</dc:creator>
        <description><![CDATA[
            背景：大语言模型处理自然语言能力强，但存在知识缺口和幻觉问题；知识图谱提供结构化知识，却缺乏自然语言交互。方法：提出无需训练的KG - RAG系统，集成大语言模型和知识图谱，含问题分解模块，用上下文学习和思维链提示生成推理链。效果：在MetaQA基准测试中，多跳问题准确性提升，单跳性能较含知识图谱的大语言模型基线略有下降，能增强问答透明度，实现非结构化语言理解与结构化知识检索的结合。
            arXiv:2504.08893v1 Announce Type: new 
Abstract: Large Language Models (LLMs) and Knowledge Graphs (KGs) offer a promising approach to robust and explainable Question Answering (QA). While LLMs excel at natural language understanding, they suffer from knowledge gaps and hallucinations. KGs provide structured knowledge but lack natural language interaction. Ideally, an AI system should be both robust to missing facts as well as easy to communicate with. This paper proposes such a system that integrates LLMs and KGs without requiring training, ensuring adaptability across different KGs with minimal human effort. The resulting approach can be classified as a specific form of a Retrieval Augmented Generation (RAG) with a KG, thus, it is dubbed Knowledge Graph-extended Retrieval Augmented Generation (KG-RAG). It includes a question decomposition module to enhance multi-hop information retrieval and answer explainability. Using In-Context Learning (ICL) and Chain-of-Thought (CoT) prompting, it generates explicit reasoning chains processed separately to improve truthfulness. Experiments on the MetaQA benchmark show increased accuracy for multi-hop questions, though with a slight trade-off in single-hop performance compared to LLM with KG baselines. These findings demonstrate KG-RAG's potential to improve transparency in QA by bridging unstructured language understanding with structured knowledge retrieval.
        ]]></description>
    </item>
    <item>
        <title>Position: Beyond Euclidean -- Foundation Models Should Embrace Non-Euclidean Geometries</title>
        <link>https://arxiv.org/abs/2504.08896</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.08896v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Neil He, Jiahong Liu, Buze Zhang, Ngoc Bui, Ali Maatouk, Menglin Yang, Irwin King, Melanie Weber, Rex Ying</dc:creator>
        <description><![CDATA[
            背景：在基础模型和大语言模型时代，机器学习架构多采用欧几里得空间，但现实数据常具非欧几里得结构，欧氏空间难以有效捕捉。方法：提出超越欧氏几何是下一代基础模型维持扩展定律的必要之举，采用非欧几何可利用数据结构，结合任务感知适应性动态调整嵌入。通过理论和实证研究支撑该观点，并给出整合非欧几何的路线图。效果：有望提升模型效率和表达能力。
            arXiv:2504.08896v1 Announce Type: new 
Abstract: In the era of foundation models and Large Language Models (LLMs), Euclidean space has been the de facto geometric setting for machine learning architectures. However, recent literature has demonstrated that this choice comes with fundamental limitations. At a large scale, real-world data often exhibit inherently non-Euclidean structures, such as multi-way relationships, hierarchies, symmetries, and non-isotropic scaling, in a variety of domains, such as languages, vision, and the natural sciences. It is challenging to effectively capture these structures within the constraints of Euclidean spaces. This position paper argues that moving beyond Euclidean geometry is not merely an optional enhancement but a necessity to maintain the scaling law for the next-generation of foundation models. By adopting these geometries, foundation models could more efficiently leverage the aforementioned structures. Task-aware adaptability that dynamically reconfigures embeddings to match the geometry of downstream applications could further enhance efficiency and expressivity. Our position is supported by a series of theoretical and empirical investigations of prevalent foundation models.Finally, we outline a roadmap for integrating non-Euclidean geometries into foundation models, including strategies for building geometric foundation models via fine-tuning, training from scratch, and hybrid approaches.
        ]]></description>
    </item>
    <item>
        <title>HyperCore: The Core Framework for Building Hyperbolic Foundation Models with Comprehensive Modules</title>
        <link>https://arxiv.org/abs/2504.08912</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.08912v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Neil He, Menglin Yang, Rex Ying</dc:creator>
        <description><![CDATA[
            背景：双曲神经网络是建模多模态分层数据的有力工具，且基础模型的token分布有幂律特性，表明双曲空间更适合许多预训练和下游任务，但现有工具缺乏构建双曲基础模型的必要组件。方法：提出HyperCore，一个提供多模态双曲基础模型核心模块的开源框架。效果：构建并测试了全双曲视觉Transformer、全双曲多模态CLIP模型和带双曲图编码器的混合图RAG，LViT性能优于欧氏模型，还通过实验凸显了HyperCore的优势。
            arXiv:2504.08912v1 Announce Type: new 
Abstract: Hyperbolic neural networks have emerged as a powerful tool for modeling hierarchical data across diverse modalities. Recent studies show that token distributions in foundation models exhibit scale-free properties, suggesting that hyperbolic space is a more suitable ambient space than Euclidean space for many pre-training and downstream tasks. However, existing tools lack essential components for building hyperbolic foundation models, making it difficult to leverage recent advancements. We introduce HyperCore, a comprehensive open-source framework that provides core modules for constructing hyperbolic foundation models across multiple modalities. HyperCore's modules can be effortlessly combined to develop novel hyperbolic foundation models, eliminating the need to extensively modify Euclidean modules from scratch and possible redundant research efforts. To demonstrate its versatility, we build and test the first fully hyperbolic vision transformers (LViT) with a fine-tuning pipeline, the first fully hyperbolic multimodal CLIP model (L-CLIP), and a hybrid Graph RAG with a hyperbolic graph encoder. Our experiments demonstrate that LViT outperforms its Euclidean counterpart. Additionally, we benchmark and reproduce experiments across hyperbolic GNNs, CNNs, Transformers, and vision Transformers to highlight HyperCore's advantages.
        ]]></description>
    </item>
    <item>
        <title>An Adaptive Vector Index Partitioning Scheme for Low-Latency RAG Pipeline</title>
        <link>https://arxiv.org/abs/2504.08930</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.08930v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Junkyum Kim, Divya Mahajan</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）系统将大语言模型与向量数据库结合以提升回答质量，但现有向量搜索和大语言模型服务的优化孤立进行，导致端到端性能不佳。方法：提出VectorLiteRAG，利用向量数据库集群访问的偏斜特性，通过优化内存分配策略，将对应频繁访问集群的最少向量索引动态分配到GPU HBM，并借助统计模型指导内存和工作负载分配。效果：使向量搜索响应速度提升2倍，显著降低RAG系统的端到端首词响应时间。
            arXiv:2504.08930v1 Announce Type: new 
Abstract: Retrieval Augmented Generation (RAG) systems enhance response quality by integrating Large Language Models (LLMs) with vector databases, enabling external knowledge retrieval to support language model reasoning. While RAG enables efficient question answering with smaller LLMs, existing optimizations for vector search and LLM serving have largely been developed in isolation. As a result, their integration often leads to suboptimal end-to-end performance. ... This paper introduces VectorLiteRAG, an optimized vector index partitioning mechanism designed for RAG systems that enhances the responsiveness of the system by jointly optimizing vector search and LLM serving across CPU and GPU system. A key challenge is to determine which indices and how much of the vector index should reside on the GPU and adjusting LLM batch sizes to balance the pipeline for lower Time-To-First-Token (TTFT) and meeting user-defined Service-Level Objectives (SLOs). To address this, we leverage the insight that cluster access in vector databases exhibits access skew, where a subset of clusters are queried significantly more frequently than others. VectorLiteRAG exploits this property through an optimized memory distribution strategy, dynamically allocating the minimum number of vector indices corresponding to frequently accessed clusters onto the GPU HBM to ensure a balanced pipeline with the LLM for high responsiveness. This adaptive partitioning scheme is guided by a statistical model that informs memory allocation and workload distribution. Our evaluation demonstrates that VectorLiteRAG improves vector search responsiveness by 2x, significantly reduces end-to-end TTFT in RAG systems by intelligently balancing memory resources between vector search and LLM execution.
        ]]></description>
    </item>
    <item>
        <title>Bidirectional Linear Recurrent Models for Sequence-Level Multisource Fusion</title>
        <link>https://arxiv.org/abs/2504.08964</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.08964v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qisai Liu, Zhanhong Jiang, Joshua R. Waite, Chao Liu, Aditya Balu, Soumik Sarkar</dc:creator>
        <description><![CDATA[
            序列建模在多领域应用广泛但具挑战。Transformer虽训练高效，但处理长序列时时间复杂度高。循环神经网络（RNN）有线性时间复杂度。本文提出BLUR，用前后向线性循环单元（LRU）高效捕捉前后依赖关系，保持传统RNN线性复杂度，通过LRU实现快速并行训练，训练稳定且近似能力强。在序列图像和时间序列数据集实验显示，BLUR准确率超Transformer和传统RNN，还大幅降低计算成本，适合实际预测任务。
            arXiv:2504.08964v1 Announce Type: new 
Abstract: Sequence modeling is a critical yet challenging task with wide-ranging applications, especially in time series forecasting for domains like weather prediction, temperature monitoring, and energy load forecasting. Transformers, with their attention mechanism, have emerged as state-of-the-art due to their efficient parallel training, but they suffer from quadratic time complexity, limiting their scalability for long sequences. In contrast, recurrent neural networks (RNNs) offer linear time complexity, spurring renewed interest in linear RNNs for more computationally efficient sequence modeling. In this work, we introduce BLUR (Bidirectional Linear Unit for Recurrent network), which uses forward and backward linear recurrent units (LRUs) to capture both past and future dependencies with high computational efficiency. BLUR maintains the linear time complexity of traditional RNNs, while enabling fast parallel training through LRUs. Furthermore, it offers provably stable training and strong approximation capabilities, making it highly effective for modeling long-term dependencies. Extensive experiments on sequential image and time series datasets reveal that BLUR not only surpasses transformers and traditional RNNs in accuracy but also significantly reduces computational costs, making it particularly suitable for real-world forecasting tasks. Our code is available here.
        ]]></description>
    </item>
    <item>
        <title>On Large-scale Evaluation of Embedding Models for Knowledge Graph Completion</title>
        <link>https://arxiv.org/abs/2504.08970</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.08970v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Nasim Shirvani-Mahdavi, Farahnaz Akrami, Chengkai Li</dc:creator>
        <description><![CDATA[
            背景：知识图谱嵌入（KGE）模型在知识图谱补全中广泛研究，但评估受不现实基准限制，常用数据集有缺陷，评估指标存在诸多问题。方法：对四个代表性KGE模型在大规模数据集FB - CVT - REV和FB+CVT - REV上进行全面评估。效果：分析发现大小数据集上模型性能有显著差异，二元化n元关系会高估模型能力，当前评估协议和指标存在根本局限。
            arXiv:2504.08970v1 Announce Type: new 
Abstract: Knowledge graph embedding (KGE) models are extensively studied for knowledge graph completion, yet their evaluation remains constrained by unrealistic benchmarks. Commonly used datasets are either faulty or too small to reflect real-world data. Few studies examine the role of mediator nodes, which are essential for modeling n-ary relationships, or investigate model performance variation across domains. Standard evaluation metrics rely on the closed-world assumption, which penalizes models for correctly predicting missing triples, contradicting the fundamental goals of link prediction. These metrics often compress accuracy assessment into a single value, obscuring models' specific strengths and weaknesses. The prevailing evaluation protocol operates under the unrealistic assumption that an entity's properties, for which values are to be predicted, are known in advance. While alternative protocols such as property prediction, entity-pair ranking and triple classification address some of these limitations, they remain underutilized. This paper conducts a comprehensive evaluation of four representative KGE models on large-scale datasets FB-CVT-REV and FB+CVT-REV. Our analysis reveals critical insights, including substantial performance variations between small and large datasets, both in relative rankings and absolute metrics, systematic overestimation of model capabilities when n-ary relations are binarized, and fundamental limitations in current evaluation protocols and metrics.
        ]]></description>
    </item>
    <item>
        <title>Repetitive Contrastive Learning Enhances Mamba's Selectivity in Time Series Prediction</title>
        <link>https://arxiv.org/abs/2504.09185</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09185v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wenbo Yan, Hanzhong Cao, Ying Tan</dc:creator>
        <description><![CDATA[
            长序列预测是时间序列预测的关键挑战，基于Mamba的模型虽有序列选择能力，但因选择能力有限，存在对关键时间步关注不足和噪声抑制不完全的问题。为此，研究提出重复对比学习（RCL）这一标记级对比预训练框架，增强Mamba的选择能力。该方法先预训练单个Mamba块，再将参数迁移到骨干模型中。它通过序列增强和对比学习，让Mamba模块关注关键信息、忽略噪声。实验表明，RCL提升了骨干模型性能，超现有方法，还提出指标量化Mamba选择能力。
            arXiv:2504.09185v1 Announce Type: new 
Abstract: Long sequence prediction is a key challenge in time series forecasting. While Mamba-based models have shown strong performance due to their sequence selection capabilities, they still struggle with insufficient focus on critical time steps and incomplete noise suppression, caused by limited selective abilities. To address this, we introduce Repetitive Contrastive Learning (RCL), a token-level contrastive pretraining framework aimed at enhancing Mamba's selective capabilities. RCL pretrains a single Mamba block to strengthen its selective abilities and then transfers these pretrained parameters to initialize Mamba blocks in various backbone models, improving their temporal prediction performance. RCL uses sequence augmentation with Gaussian noise and applies inter-sequence and intra-sequence contrastive learning to help the Mamba module prioritize information-rich time steps while ignoring noisy ones. Extensive experiments show that RCL consistently boosts the performance of backbone models, surpassing existing methods and achieving state-of-the-art results. Additionally, we propose two metrics to quantify Mamba's selective capabilities, providing theoretical, qualitative, and quantitative evidence for the improvements brought by RCL.
        ]]></description>
    </item>
    <item>
        <title>Question Tokens Deserve More Attention: Enhancing Large Language Models without Training through Step-by-Step Reading and Question Attention Recalibration</title>
        <link>https://arxiv.org/abs/2504.09402</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09402v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Feijiang Han, Licheng Guo, Hengtao Cui, Zhiyuan Lyu</dc:creator>
        <description><![CDATA[
            背景：大语言模型在理解复杂问题、处理长距离依赖和多步推理任务时存在困难。方法：基于对模型在问题理解方面局限的研究，提出基于提示的策略SSR、SSR+和SSR++，引导模型逐步处理问题标记并使推理与输入结构对齐；还引入免训练的注意力重新校准机制，在推理时动态调整注意力分布。效果：SSR++在多个基准测试中取得最优成绩，如GSM8K达到96.66%等；注意力重新校准机制使LLaMA 3.1 - 8B在AQuA上准确率提升5.17%。
            arXiv:2504.09402v1 Announce Type: new 
Abstract: Large Language Models (LLMs) often struggle with tasks that require a deep understanding of complex questions, especially when faced with long-range dependencies or multi-step reasoning. This work investigates the limitations of current LLMs in question comprehension and identifies three insights: (1) repeating question tokens improves comprehension by increasing attention to question regions, (2) increased backward dependencies negatively affect performance due to unidirectional attentional constraints, and (3) recalibrating attentional mechanisms to prioritize question-relevant regions improves performance.
  Based on these findings, we first propose a family of prompt-based strategies - Step-by-Step Reading (SSR), SSR+, and SSR++ - that guide LLMs to incrementally process question tokens and align their reasoning with the input structure. These methods significantly improve performance, with SSR++ achieving state-of-the-art results on several benchmarks: 96.66% on GSM8K, 94.61% on ASDiv, and 76.28% on AQuA. Second, we introduce a training-free attention recalibration mechanism that dynamically adjusts attention distributions during inference to emphasize question-relevant regions. This method improves the accuracy of LLaMA 3.1-8B on AQuA by 5.17% without changing model parameters or input prompts.
  Taken together, our results highlight the importance of structured prompt design and attention optimization in improving LLM comprehension, providing lightweight yet effective tools for improving performance in various NLP tasks.
        ]]></description>
    </item>
    <item>
        <title>FROG: Effective Friend Recommendation in Online Games via Modality-aware User Preferences</title>
        <link>https://arxiv.org/abs/2504.09428</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09428v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qiwei Wang, Dandan Lin, Wenqing Lin, Ziming Wu</dc:creator>
        <description><![CDATA[
            背景：因移动设备便利，在线游戏成重要娱乐方式，催生游戏好友推荐需求，但现有方法难以有效结合多模态用户特征与友谊图结构信息。方法：提出端到端模型FROG，解决现有方法忽视用户高阶结构接近性、特定模态下用户相关性学习不足、无法捕捉不同模态本地和全局用户偏好等问题，更好地建模用户对潜在好友的偏好。效果：在腾讯的离线评估和在线部署实验中，FROG优于现有方法。
            arXiv:2504.09428v1 Announce Type: new 
Abstract: Due to the convenience of mobile devices, the online games have become an important part for user entertainments in reality, creating a demand for friend recommendation in online games. However, none of existing approaches can effectively incorporate the multi-modal user features (\emph{e.g.}, images and texts) with the structural information in the friendship graph, due to the following limitations: (1) some of them ignore the high-order structural proximity between users, (2) some fail to learn the pairwise relevance between users at modality-specific level, and (3) some cannot capture both the local and global user preferences on different modalities. By addressing these issues, in this paper, we propose an end-to-end model \textsc{FROG} that better models the user preferences on potential friends. Comprehensive experiments on both offline evaluation and online deployment at \kw{Tencent} have demonstrated the superiority of \textsc{FROG} over existing approaches.
        ]]></description>
    </item>
    <item>
        <title>GenEDA: Unleashing Generative Reasoning on Netlist via Multimodal Encoder-Decoder Aligned Foundation Model</title>
        <link>https://arxiv.org/abs/2504.09485</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09485v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wenji Fang, Jing Wang, Yao Lu, Shang Liu, Zhiyao Xie</dc:creator>
        <description><![CDATA[
            背景：现有预训练电路模型的编码器和解码器独立开发，工作于不同电路模态和潜在空间，限制了其在高级应用中的互补能力。方法：提出GenEDA框架，在共享潜在空间中对齐电路编码器和解码器，弥合基于图的电路表示与基于文本的大语言模型的差距，还提出两种范式支持不同类型大语言模型。效果：能实现网表的三种生成推理任务，将传统门类型预测扩展到全电路功能生成，显著提升GPT - 4o和DeepSeek - V3等大模型在各任务中的表现。
            arXiv:2504.09485v1 Announce Type: new 
Abstract: The success of foundation AI has motivated the research of circuit foundation models, which are customized to assist the integrated circuit (IC) design process. However, existing pre-trained circuit models are typically limited to standalone encoders for predictive tasks or decoders for generative tasks. These two model types are developed independently, operate on different circuit modalities, and reside in separate latent spaces, which restricts their ability to complement each other for more advanced applications. In this work, we present GenEDA, the first framework that aligns circuit encoders with decoders within a shared latent space. GenEDA bridges the gap between graph-based circuit representations and text-based large language models (LLMs), enabling communication between their respective latent spaces. To achieve the alignment, we propose two paradigms that support both open-source trainable LLMs and commercial frozen LLMs. Built on this aligned architecture, GenEDA enables three unprecedented generative reasoning tasks over netlists, where the model reversely generates the high-level functionality from low-level netlists in different granularities. These tasks extend traditional gate-type prediction to direct generation of full-circuit functionality. Experiments demonstrate that GenEDA significantly boosts advanced LLMs' (e.g., GPT-4o and DeepSeek-V3) performance in all tasks.
        ]]></description>
    </item>
    <item>
        <title>MADLLM: Multivariate Anomaly Detection via Pre-trained LLMs</title>
        <link>https://arxiv.org/abs/2504.09504</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09504v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wei Tao, Xiaoyang Qu, Kai Lu, Jiguang Wan, Guokuan Li, Jianzong Wang</dc:creator>
        <description><![CDATA[
            背景：将预训练大语言模型用于异常检测任务时，多元时间序列（MTS）模态与大语言模型的文本模态不匹配，现有方法将MTS数据转化为多个单变量时间序列序列存在诸多问题。方法：提出MADLLM方法，设计新的三重编码技术，将传统补丁嵌入方法与跳跃嵌入、特征嵌入两种新嵌入方法结合，使MTS模态与文本模态对齐。效果：在多个公开异常检测数据集上，该方法优于现有先进方法。
            arXiv:2504.09504v1 Announce Type: new 
Abstract: When applying pre-trained large language models (LLMs) to address anomaly detection tasks, the multivariate time series (MTS) modality of anomaly detection does not align with the text modality of LLMs. Existing methods simply transform the MTS data into multiple univariate time series sequences, which can cause many problems. This paper introduces MADLLM, a novel multivariate anomaly detection method via pre-trained LLMs. We design a new triple encoding technique to align the MTS modality with the text modality of LLMs. Specifically, this technique integrates the traditional patch embedding method with two novel embedding approaches: Skip Embedding, which alters the order of patch processing in traditional methods to help LLMs retain knowledge of previous features, and Feature Embedding, which leverages contrastive learning to allow the model to better understand the correlations between different features. Experimental results demonstrate that our method outperforms state-of-the-art methods in various public anomaly detection datasets.
        ]]></description>
    </item>
    <item>
        <title>Syzygy of Thoughts: Improving LLM CoT with the Minimal Free Resolution</title>
        <link>https://arxiv.org/abs/2504.09566</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09566v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chenghao Li, Chaoning Zhang, Yi Lu, Jiaquan Zhang, Qigan Sun, Xudong Wang, Jiwei Wei, Guoqing Wang, Yang Yang, Heng Tao Shen</dc:creator>
        <description><![CDATA[
            背景：思维链（CoT）提示可增强大语言模型推理能力，但复杂任务常超出单条推理链能力。方法：受交换代数和代数几何中最小自由分解（MFR）启发，提出思维合冲（SoT）框架，引入辅助、相互关联的推理路径拓展CoT，将原复杂问题系统分解为逻辑完整的最小子问题。效果：在多个数据集和模型上测试，推理准确率达到或超过主流CoT标准，还提升了大语言模型推理时间的可扩展性。
            arXiv:2504.09566v1 Announce Type: new 
Abstract: Chain-of-Thought (CoT) prompting enhances the reasoning of large language models (LLMs) by decomposing problems into sequential steps, mimicking human logic and reducing errors. However, complex tasks with vast solution spaces and vague constraints often exceed the capacity of a single reasoning chain. Inspired by Minimal Free Resolution (MFR) in commutative algebra and algebraic geometry, we propose Syzygy of Thoughts (SoT)-a novel framework that extends CoT by introducing auxiliary, interrelated reasoning paths. SoT captures deeper logical dependencies, enabling more robust and structured problem-solving. MFR decomposes a module into a sequence of free modules with minimal rank, providing a structured analytical approach to complex systems. This method introduces the concepts of "Module", "Betti numbers","Freeness", "Mapping", "Exactness" and "Minimality", enabling the systematic decomposition of the original complex problem into logically complete minimal subproblems while preserving key problem features and reducing reasoning length. We tested SoT across diverse datasets (e.g., GSM8K, MATH) and models (e.g., GPT-4o-mini, Qwen2.5), achieving inference accuracy that matches or surpasses mainstream CoTs standards. Additionally, by aligning the sampling process with algebraic constraints, our approach enhances the scalability of inference time in LLMs, ensuring both transparent reasoning and high performance. Our code will be publicly available at https://github.com/dlMARiA/Syzygy-of-thoughts.
        ]]></description>
    </item>
    <item>
        <title>Short-Path Prompting in LLMs: Analyzing Reasoning Instability and Solutions for Robust Performance</title>
        <link>https://arxiv.org/abs/2504.09586</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09586v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zuoli Tang, Junjie Ou, Kaiqin Hu, Chunwei Wu, Zhaoxin Huan, Chilin Fu, Xiaolu Zhang, Jun Zhou, Chenliang Li</dc:creator>
        <description><![CDATA[
            背景：大语言模型推理近年因思维链（CoT）方法取得进展，但人类倾向短提示与CoT推理冲突。方法：研究用户短路径提示下大语言模型推理性能变化，针对推理能力下降且不稳定问题，提出指令引导和微调两种方法解决冲突。效果：实验表明两种方法均有较高准确率，为当前模型指令遵循与推理准确性的权衡提供了见解。
            arXiv:2504.09586v1 Announce Type: new 
Abstract: Recent years have witnessed significant progress in large language models' (LLMs) reasoning, which is largely due to the chain-of-thought (CoT) approaches, allowing models to generate intermediate reasoning steps before reaching the final answer. Building on these advances, state-of-the-art LLMs are instruction-tuned to provide long and detailed CoT pathways when responding to reasoning-related questions. However, human beings are naturally cognitive misers and will prompt language models to give rather short responses, thus raising a significant conflict with CoT reasoning. In this paper, we delve into how LLMs' reasoning performance changes when users provide short-path prompts. The results and analysis reveal that language models can reason effectively and robustly without explicit CoT prompts, while under short-path prompting, LLMs' reasoning ability drops significantly and becomes unstable, even on grade-school problems. To address this issue, we propose two approaches: an instruction-guided approach and a fine-tuning approach, both designed to effectively manage the conflict. Experimental results show that both methods achieve high accuracy, providing insights into the trade-off between instruction adherence and reasoning accuracy in current models.
        ]]></description>
    </item>
    <item>
        <title>Leveraging Reasoning Model Answers to Enhance Non-Reasoning Model Capability</title>
        <link>https://arxiv.org/abs/2504.09639</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09639v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Haotian Wang, Han Zhao, Shuaiting Chen, Xiaoyu Tian, Sitong Zhao, Yunjie Ji, Yiping Peng, Xiangang Li</dc:creator>
        <description><![CDATA[
            背景：大型语言模型在测试时扩展表现出显著效果，推理密集型模型利用“思考”步骤提升答案质量。方法：本文提出利用推理密集型模型的高质量输出来改进计算需求较低的非推理模型，并探索比较利用推理模型答案训练非推理模型的方法。效果：通过在既定基准上进行简单的监督微调实验，在多个基准测试中均取得了持续改进，凸显了该方法提升模型直接回答问题能力的潜力。
            arXiv:2504.09639v1 Announce Type: new 
Abstract: Recent advancements in large language models (LLMs), such as DeepSeek-R1 and OpenAI-o1, have demonstrated the significant effectiveness of test-time scaling, achieving substantial performance gains across various benchmarks. These advanced models utilize deliberate "thinking" steps to systematically enhance answer quality. In this paper, we propose leveraging these high-quality outputs generated by reasoning-intensive models to improve less computationally demanding, non-reasoning models. We explore and compare methodologies for utilizing the answers produced by reasoning models to train and improve non-reasoning models. Through straightforward Supervised Fine-Tuning (SFT) experiments on established benchmarks, we demonstrate consistent improvements across various benchmarks, underscoring the potential of this approach for advancing the ability of models to answer questions directly.
        ]]></description>
    </item>
    <item>
        <title>TinyLLaVA-Video-R1: Towards Smaller LMMs for Video Reasoning</title>
        <link>https://arxiv.org/abs/2504.09641</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09641v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xingjian Zhang, Siwei Wen, Wenjun Wu, Lei Huang</dc:creator>
        <description><![CDATA[
            背景：提升大模型推理能力研究进展大，但多基于高推理强度数据集且采用大规模模型，探索小模型推理能力对计算资源有限者有价值。方法：提出小规模视频推理模型TinyLLaVA - Video - R1，基于参数不超4B的TinyLLaVA - Video，在通用视频问答数据集上用强化学习训练。效果：显著提升推理和思维能力，展现“顿悟时刻”特征，研究成果开源，为小模型视频推理能力探索提供见解。
            arXiv:2504.09641v1 Announce Type: new 
Abstract: Recently, improving the reasoning ability of large multimodal models (LMMs) through reinforcement learning has made great progress. However, most existing works are based on highly reasoning-intensive datasets such as mathematics and code, and researchers generally choose large-scale models as the foundation. We argue that exploring small-scale models' reasoning capabilities remains valuable for researchers with limited computational resources. Moreover, enabling models to explain their reasoning processes on general question-answering datasets is equally meaningful. Therefore, we present the small-scale video reasoning model TinyLLaVA-Video-R1. Based on TinyLLaVA-Video, a traceably trained video understanding model with no more than 4B parameters, it not only demonstrates significantly improved reasoning and thinking capabilities after using reinforcement learning on general Video-QA datasets, but also exhibits the emergent characteristic of "aha moments". Furthermore, we share a series of experimental findings, aiming to provide practical insights for future exploration of video reasoning (thinking) abilities in small-scale models. It is available at https://github.com/ZhangXJ199/TinyLLaVA-Video-R1.
        ]]></description>
    </item>
    <item>
        <title>CLEAR-KGQA: Clarification-Enhanced Ambiguity Resolution for Knowledge Graph Question Answering</title>
        <link>https://arxiv.org/abs/2504.09665</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09665v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Liqiang Wen, Guanming Xiong, Tong Mo, Bing Li, Weiping Li, Wen Zhao</dc:creator>
        <description><![CDATA[
            背景：现有知识图谱问答（KGQA）系统虽结合大语言模型取得进展，但多假设用户查询无歧义，与实际不符。方法：提出新框架，通过交互式澄清动态处理实体和意图歧义，采用贝叶斯推理机制量化查询歧义，引导大语言模型在多轮对话中向用户请求澄清，还开发双智能体交互框架，利用用户模拟器完善逻辑形式。效果：在WebQSP和CWQ数据集上有效解决语义歧义，显著提升性能，还提供精炼的消歧查询数据集。
            arXiv:2504.09665v1 Announce Type: new 
Abstract: This study addresses the challenge of ambiguity in knowledge graph question answering (KGQA). While recent KGQA systems have made significant progress, particularly with the integration of large language models (LLMs), they typically assume user queries are unambiguous, which is an assumption that rarely holds in real-world applications. To address these limitations, we propose a novel framework that dynamically handles both entity ambiguity (e.g., distinguishing between entities with similar names) and intent ambiguity (e.g., clarifying different interpretations of user queries) through interactive clarification. Our approach employs a Bayesian inference mechanism to quantify query ambiguity and guide LLMs in determining when and how to request clarification from users within a multi-turn dialogue framework. We further develop a two-agent interaction framework where an LLM-based user simulator enables iterative refinement of logical forms through simulated user feedback. Experimental results on the WebQSP and CWQ dataset demonstrate that our method significantly improves performance by effectively resolving semantic ambiguities. Additionally, we contribute a refined dataset of disambiguated queries, derived from interaction histories, to facilitate future research in this direction.
        ]]></description>
    </item>
    <item>
        <title>Socratic Chart: Cooperating Multiple Agents for Robust SVG Chart Understanding</title>
        <link>https://arxiv.org/abs/2504.09764</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09764v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuyang Ji, Haohan Wang</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型在图表推理任务中难以实现真正的视觉理解，现有基准测试显示模型多依赖文本捷径和概率模式匹配。方法：在ChartQA数据集上移除文本标签并引入图表扰动构建更具挑战性的测试场景，提出Socratic Chart框架，将图表图像转换为SVG表示，采用多智能体管道，用专门的生成智能体提取图表属性、评估智能体验证结果。效果：GPT - 4o和Gemini - 2.0 Pro在新场景下性能最多下降30%，该框架在捕捉图表原语和提升推理性能上超越了现有模型。
            arXiv:2504.09764v1 Announce Type: new 
Abstract: Multimodal Large Language Models (MLLMs) have shown remarkable versatility but face challenges in demonstrating true visual understanding, particularly in chart reasoning tasks. Existing benchmarks like ChartQA reveal significant reliance on text-based shortcuts and probabilistic pattern-matching rather than genuine visual reasoning. To rigorously evaluate visual reasoning, we introduce a more challenging test scenario by removing textual labels and introducing chart perturbations in the ChartQA dataset. Under these conditions, models like GPT-4o and Gemini-2.0 Pro experience up to a 30% performance drop, underscoring their limitations. To address these challenges, we propose Socratic Chart, a new framework that transforms chart images into Scalable Vector Graphics (SVG) representations, enabling MLLMs to integrate textual and visual modalities for enhanced chart understanding. Socratic Chart employs a multi-agent pipeline with specialized agent-generators to extract primitive chart attributes (e.g., bar heights, line coordinates) and an agent-critic to validate results, ensuring high-fidelity symbolic representations. Our framework surpasses state-of-the-art models in accurately capturing chart primitives and improving reasoning performance, establishing a robust pathway for advancing MLLM visual understanding.
        ]]></description>
    </item>
    <item>
        <title>VDocRAG: Retrieval-Augmented Generation over Visually-Rich Documents</title>
        <link>https://arxiv.org/abs/2504.09795</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09795v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ryota Tanaka, Taichi Iki, Taku Hasegawa, Kyosuke Nishida, Kuniko Saito, Jun Suzuki</dc:creator>
        <description><![CDATA[
            背景：需开发能处理多模态、多格式富视觉文档的检索增强生成（RAG）框架。方法：提出VDocRAG框架，将文档统一为图像格式以避免信息丢失；设计自监督预训练任务，压缩视觉信息为密集令牌表示并与文本内容对齐；构建首个开放域文档视觉问答数据集OpenDocVQA。效果：实验显示，VDocRAG显著优于传统基于文本的RAG，有强泛化能力。 
            arXiv:2504.09795v1 Announce Type: new 
Abstract: We aim to develop a retrieval-augmented generation (RAG) framework that answers questions over a corpus of visually-rich documents presented in mixed modalities (e.g., charts, tables) and diverse formats (e.g., PDF, PPTX). In this paper, we introduce a new RAG framework, VDocRAG, which can directly understand varied documents and modalities in a unified image format to prevent missing information that occurs by parsing documents to obtain text. To improve the performance, we propose novel self-supervised pre-training tasks that adapt large vision-language models for retrieval by compressing visual information into dense token representations while aligning them with textual content in documents. Furthermore, we introduce OpenDocVQA, the first unified collection of open-domain document visual question answering datasets, encompassing diverse document types and formats. OpenDocVQA provides a comprehensive resource for training and evaluating retrieval and question answering models on visually-rich documents in an open-domain setting. Experiments show that VDocRAG substantially outperforms conventional text-based RAG and has strong generalization capability, highlighting the potential of an effective RAG paradigm for real-world documents.
        ]]></description>
    </item>
    <item>
        <title>Training Small Reasoning LLMs with Cognitive Preference Alignment</title>
        <link>https://arxiv.org/abs/2504.09802</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09802v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wenrui Cai, Chengyu Wang, Junbing Yan, Jun Huang, Xiangzhong Fang</dc:creator>
        <description><![CDATA[
            背景：大语言模型推理能力虽有提升，但资源需求大，小模型与大模型能力和认知轨迹不同，直接蒸馏思维链效果不佳且需大量标注数据。方法：提出Critique - Rethink - Verify（CRV）框架，由多个专长不同的LLM代理组成，还提出认知偏好优化（CogPO）算法，使小模型思维与认知能力对齐。效果：在挑战性推理基准测试中，CRV和CogPO大幅优于其他训练方法。
            arXiv:2504.09802v1 Announce Type: new 
Abstract: The reasoning capabilities of large language models (LLMs), such as OpenAI's o1 and DeepSeek-R1, have seen substantial advancements through deep thinking. However, these enhancements come with significant resource demands, underscoring the need to explore strategies to train effective reasoning LLMs with far fewer parameters. A critical challenge is that smaller models have different capacities and cognitive trajectories than their larger counterparts. Hence, direct distillation of chain-of-thought (CoT) results from large LLMs to smaller ones can be sometimes ineffective and requires a huge amount of annotated data. In this paper, we introduce a novel framework called Critique-Rethink-Verify (CRV), designed for training smaller yet powerful reasoning LLMs. Our CRV framework consists of multiple LLM agents, each specializing in unique abilities: (i) critiquing the CoTs according to the cognitive capabilities of smaller models, (ii) rethinking and refining these CoTs based on the critiques, and (iii) verifying the correctness of the refined results. We further propose the cognitive preference optimization (CogPO) algorithm to enhance the reasoning abilities of smaller models by aligning thoughts of these models with their cognitive capacities. Comprehensive evaluations on challenging reasoning benchmarks demonstrate the efficacy of CRV and CogPO, which outperforms other training methods by a large margin.
        ]]></description>
    </item>
    <item>
        <title>RadarLLM: Empowering Large Language Models to Understand Human Motion from Millimeter-wave Point Cloud Sequence</title>
        <link>https://arxiv.org/abs/2504.09862</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09862v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zengyuan Lai, Jiarui Yang, Songpengcheng Xia, Lizhou Lin, Lan Sun, Renwen Wang, Jianran Liu, Qi Wu, Ling Pei</dc:creator>
        <description><![CDATA[
            背景：毫米波雷达用于人体运动分析时，其稀疏点云给语义理解带来挑战。方法：提出Radar - LLM框架，一是基于Aggregate VQ - VAE架构的运动引导雷达分词器，将时空点云编码为紧凑语义标记；二是雷达感知语言模型，在共享嵌入空间建立雷达与文本的跨模态对齐，还引入物理感知合成管道生成雷达 - 文本对。效果：在合成和真实基准测试中均达最优性能，能将毫米波信号准确转化为自然语言描述，助力隐私敏感场景的运动理解。
            arXiv:2504.09862v1 Announce Type: new 
Abstract: Millimeter-wave radar provides a privacy-preserving solution for human motion analysis, yet its sparse point clouds pose significant challenges for semantic understanding. We present Radar-LLM, the first framework that leverages large language models (LLMs) for human motion understanding using millimeter-wave radar as the sensing modality. Our approach introduces two key innovations: (1) a motion-guided radar tokenizer based on our Aggregate VQ-VAE architecture that incorporates deformable body templates and masked trajectory modeling to encode spatiotemporal point clouds into compact semantic tokens, and (2) a radar-aware language model that establishes cross-modal alignment between radar and text in a shared embedding space. To address data scarcity, we introduce a physics-aware synthesis pipeline that generates realistic radar-text pairs from motion-text datasets. Extensive experiments demonstrate that Radar-LLM achieves state-of-the-art performance across both synthetic and real-world benchmarks, enabling accurate translation of millimeter-wave signals to natural language descriptions. This breakthrough facilitates comprehensive motion understanding in privacy-sensitive applications like healthcare and smart homes. We will release the full implementation to support further research on https://inowlzy.github.io/RadarLLM/.
        ]]></description>
    </item>
    <item>
        <title>TAMP: Token-Adaptive Layerwise Pruning in Multimodal Large Language Models</title>
        <link>https://arxiv.org/abs/2504.09897</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09897v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jaewoo Lee (May), Keyang Xuan (May), Chanakya Ekbote (May), Sandeep Polisetty (May), Yi R. (May),  Fung, Paul Pu Liang</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型（MLLMs）功能强大但模型规模大，现有后训练剪枝方法在MLLMs上效果有限，因其未考虑MLLMs各层和模态的独特token属性。方法：提出TAMP剪枝框架，含多样性感知稀疏性（根据多模态输出token多样性调整每层稀疏率）和自适应多模态输入激活（用注意力分数识别代表性输入token以指导非结构化权重剪枝）。效果：在LLaVA - NeXT和VideoLLaMA2上验证，各组件在多模态评估基准上显著优于现有剪枝技术。
            arXiv:2504.09897v1 Announce Type: new 
Abstract: Multimodal Large Language Models (MLLMs) have shown remarkable versatility in understanding diverse multimodal data and tasks. However, these capabilities come with an increased model scale. While post-training pruning reduces model size in unimodal models, its application to MLLMs often yields limited success. Our analysis discovers that conventional methods fail to account for the unique token attributes across layers and modalities inherent to MLLMs. Inspired by this observation, we propose TAMP, a simple yet effective pruning framework tailored for MLLMs, featuring two key components: (1) Diversity-Aware Sparsity, which adjusts sparsity ratio per layer based on diversities among multimodal output tokens, preserving more parameters in high-diversity layers; and (2) Adaptive Multimodal Input Activation, which identifies representative multimodal input tokens using attention scores to guide unstructured weight pruning. We validate our method on two state-of-the-art MLLMs: LLaVA-NeXT, designed for vision-language tasks, and VideoLLaMA2, capable of processing audio, visual, and language modalities. Empirical experiments across various multimodal evaluation benchmarks demonstrate that each component of our approach substantially outperforms existing pruning techniques.
        ]]></description>
    </item>
    <item>
        <title>Learning to Erase Private Knowledge from Multi-Documents for Retrieval-Augmented Large Language Models</title>
        <link>https://arxiv.org/abs/2504.09910</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09910v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yujing Wang, Hainan Zhang, Liang Pang, Yongxin Tong, Binghui Guo, Hongwei Zheng, Zhiming Zheng</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）应用于专有领域时，检索文档含敏感知识，易致隐私泄露。方法：本文提出RAG的隐私擦除任务及Eraser4RAG，先构建全局知识图识别文档潜在知识，抵御反匿名攻击；再将其随机分为私有和公共子图，微调Flan - T5重写文档以排除私有三元组；最后用PPO算法优化重写模型。效果：在四个问答数据集上实验表明，Eraser4RAG擦除性能优于GPT - 4o。
            arXiv:2504.09910v1 Announce Type: new 
Abstract: Retrieval-Augmented Generation (RAG) is a promising technique for applying LLMs to proprietary domains. However, retrieved documents may contain sensitive knowledge, posing risks of privacy leakage in generative results. Thus, effectively erasing private information from retrieved documents is a key challenge for RAG. Unlike traditional text anonymization, RAG should consider: (1) the inherent multi-document reasoning may face de-anonymization attacks; (2) private knowledge varies by scenarios, so users should be allowed to customize which information to erase; (3) preserving sufficient publicly available knowledge for generation tasks. This paper introduces the privacy erasure task for RAG and proposes Eraser4RAG, a private knowledge eraser which effectively removes user-defined private knowledge from documents while preserving sufficient public knowledge for generation. Specifically, we first construct a global knowledge graph to identify potential knowledge across documents, aiming to defend against de-anonymization attacks. Then we randomly split it into private and public sub-graphs, and fine-tune Flan-T5 to rewrite the retrieved documents excluding private triples. Finally, PPO algorithm optimizes the rewriting model to minimize private triples and maximize public triples retention. Experiments on four QA datasets demonstrate that Eraser4RAG achieves superior erase performance than GPT-4o.
        ]]></description>
    </item>
    <item>
        <title>Guiding Reasoning in Small Language Models with LLM Assistance</title>
        <link>https://arxiv.org/abs/2504.09923</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09923v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yujin Kim, Euiin Yi, Minu Kim, Se-Young Yun, Taehyeon Kim</dc:creator>
        <description><![CDATA[
            背景：小语言模型推理能力有限，难以胜任深度多步逻辑推理任务。方法：提出Small Reasons, Large Hints（SMART）框架，受认知支架概念启发，采用基于分数的评估识别不确定推理步骤，必要时注入大语言模型生成的校正推理，将结构化推理构建为最优策略搜索。效果：在数学推理数据集实验表明，有针对性的外部支架显著提升了小语言模型性能，为大小语言模型协作解决复杂推理任务奠定基础。
            arXiv:2504.09923v1 Announce Type: new 
Abstract: The limited reasoning capabilities of small language models (SLMs) cast doubt on their suitability for tasks demanding deep, multi-step logical deduction. This paper introduces a framework called Small Reasons, Large Hints (SMART), which selectively augments SLM reasoning with targeted guidance from large language models (LLMs). Inspired by the concept of cognitive scaffolding, SMART employs a score-based evaluation to identify uncertain reasoning steps and injects corrective LLM-generated reasoning only when necessary. By framing structured reasoning as an optimal policy search, our approach steers the reasoning trajectory toward correct solutions without exhaustive sampling. Our experiments on mathematical reasoning datasets demonstrate that targeted external scaffolding significantly improves performance, paving the way for collaborative use of both SLM and LLM to tackle complex reasoning tasks that are currently unsolvable by SLMs alone.
        ]]></description>
    </item>
    <item>
        <title>AimTS: Augmented Series and Image Contrastive Learning for Time Series Classification</title>
        <link>https://arxiv.org/abs/2504.09993</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09993v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuxuan Chen, Shanshan Huang, Yunyao Cheng, Peng Chen, Zhongwen Rao, Yang Shu, Bin Yang, Lujia Pan, Chenjuan Guo</dc:creator>
        <description><![CDATA[
            时间序列分类（TSC）中现有方法在单领域训练，训练样本不足时精度下降，且多源数据预训练及模型泛化能力面临挑战。为此提出AimTS预训练框架，采用基于两级原型的对比学习方法，有效利用多源预训练中的各种增强方式；引入图像模态补充结构信息，建立序列 - 图像对比学习。大量实验表明，经多源预训练后，AimTS泛化性能良好，能在下游TSC数据集上实现高效学习甚至少样本学习。
            arXiv:2504.09993v1 Announce Type: new 
Abstract: Time series classification (TSC) is an important task in time series analysis. Existing TSC methods mainly train on each single domain separately, suffering from a degradation in accuracy when the samples for training are insufficient in certain domains. The pre-training and fine-tuning paradigm provides a promising direction for solving this problem. However, time series from different domains are substantially divergent, which challenges the effective pre-training on multi-source data and the generalization ability of pre-trained models. To handle this issue, we introduce Augmented Series and Image Contrastive Learning for Time Series Classification (AimTS), a pre-training framework that learns generalizable representations from multi-source time series data. We propose a two-level prototype-based contrastive learning method to effectively utilize various augmentations in multi-source pre-training, which learns representations for TSC that can be generalized to different domains. In addition, considering augmentations within the single time series modality are insufficient to fully address classification problems with distribution shift, we introduce the image modality to supplement structural information and establish a series-image contrastive learning to improve the generalization of the learned representations for TSC tasks. Extensive experiments show that after multi-source pre-training, AimTS achieves good generalization performance, enabling efficient learning and even few-shot learning on various downstream TSC datasets.
        ]]></description>
    </item>
    <item>
        <title>DataMosaic: Explainable and Verifiable Multi-Modal Data Analytics through Extract-Reason-Verify</title>
        <link>https://arxiv.org/abs/2504.10036</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.10036v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhengxuan Zhang, Zhuowen Liang, Yin Wu, Teng Lin, Yuyu Luo, Nan Tang</dc:creator>
        <description><![CDATA[
            背景：大语言模型虽变革数据分析，但存在不可解释和不可验证的局限，检索增强生成也无法解决多模态数据可信分析的核心挑战。方法：提出DataMosaic框架，从原始数据中动态提取特定任务结构，提供透明的逐步推理过程并验证中间结果，基于多智能体框架协调自适应智能体以契合下游任务需求。效果：该框架解决了现有大语言模型数据分析系统的局限，为多模态数据分析新范式奠定基础。
            arXiv:2504.10036v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are transforming data analytics, but their widespread adoption is hindered by two critical limitations: they are not explainable (opaque reasoning processes) and not verifiable (prone to hallucinations and unchecked errors). While retrieval-augmented generation (RAG) improves accuracy by grounding LLMs in external data, it fails to address the core challenges of trustworthy analytics - especially when processing noisy, inconsistent, or multi-modal data (for example, text, tables, images). We propose DataMosaic, a framework designed to make LLM-powered analytics both explainable and verifiable. By dynamically extracting task-specific structures (for example, tables, graphs, trees) from raw data, DataMosaic provides transparent, step-by-step reasoning traces and enables validation of intermediate results. Built on a multi-agent framework, DataMosaic orchestrates self-adaptive agents that align with downstream task requirements, enhancing consistency, completeness, and privacy. Through this approach, DataMosaic not only tackles the limitations of current LLM-powered analytics systems but also lays the groundwork for a new paradigm of grounded, accurate, and explainable multi-modal data analytics.
        ]]></description>
    </item>
    <item>
        <title>Summarization of Multimodal Presentations with Vision-Language Models: Study of the Effect of Modalities and Structure</title>
        <link>https://arxiv.org/abs/2504.10049</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.10049v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Th\'eo Gigant, Camille Guinaudeau, Fr\'ed\'eric Dufaux</dc:creator>
        <description><![CDATA[
            背景：视觉语言模型（VLMs）可处理多格式的视觉和文本信息。方法：对使用不同表示作为输入的VLMs进行多模态演示自动摘要的细粒度定量和定性分析，提出在不同输入长度预算下从多文本多模态文档生成摘要的经济有效策略。效果：视频流中提取的幻灯片作为输入比原始视频更优，交错幻灯片和文字记录的结构化表示效果最佳，还为提升VLMs理解此类文档能力给出建议。
            arXiv:2504.10049v1 Announce Type: new 
Abstract: Vision-Language Models (VLMs) can process visual and textual information in multiple formats: texts, images, interleaved texts and images, or even hour-long videos. In this work, we conduct fine-grained quantitative and qualitative analyses of automatic summarization of multimodal presentations using VLMs with various representations as input. From these experiments, we suggest cost-effective strategies for generating summaries from text-heavy multimodal documents under different input-length budgets using VLMs. We show that slides extracted from the video stream can be beneficially used as input against the raw video, and that a structured representation from interleaved slides and transcript provides the best performance. Finally, we reflect and comment on the nature of cross-modal interactions in multimodal presentations and share suggestions to improve the capabilities of VLMs to understand documents of this nature.
        ]]></description>
    </item>
    <item>
        <title>Hallucination Detection in LLMs via Topological Divergence on Attention Graphs</title>
        <link>https://arxiv.org/abs/2504.10063</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.10063v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Alexandra Bazarova, Aleksandr Yugay, Andrey Shulga, Alina Ermilova, Andrei Volodichev, Konstantin Polev, Julia Belikova, Rauf Parchiev, Dmitry Simakov, Maxim Savchenko, Andrey Savchenko, Serguei Barannikov, Alexey Zaytsev</dc:creator>
        <description><![CDATA[
            大语言模型存在生成事实错误内容（幻觉）的问题。为此提出TOHA，一种基于拓扑结构的幻觉检测器，利用拓扑差异指标量化注意力矩阵诱导图的结构特性。通过检查提示和响应子图间的拓扑差异，发现特定注意力头较高的差异值与幻觉输出相关。在问答和数据转文本任务等实验中，该方法在多个基准上达到了最优或有竞争力的结果，且具有跨多个开源大模型的领域迁移能力，表明分析注意力矩阵拓扑结构可有效指示大模型事实可靠性。
            arXiv:2504.10063v1 Announce Type: new 
Abstract: Hallucination, i.e., generating factually incorrect content, remains a critical challenge for large language models (LLMs). We introduce TOHA, a TOpology-based HAllucination detector in the RAG setting, which leverages a topological divergence metric to quantify the structural properties of graphs induced by attention matrices. Examining the topological divergence between prompt and response subgraphs reveals consistent patterns: higher divergence values in specific attention heads correlate with hallucinated outputs, independent of the dataset. Extensive experiments, including evaluation on question answering and data-to-text tasks, show that our approach achieves state-of-the-art or competitive results on several benchmarks, two of which were annotated by us and are being publicly released to facilitate further research. Beyond its strong in-domain performance, TOHA maintains remarkable domain transferability across multiple open-source LLMs. Our findings suggest that analyzing the topological structure of attention matrices can serve as an efficient and robust indicator of factual reliability in LLMs.
        ]]></description>
    </item>
    <item>
        <title>A Computational Cognitive Model for Processing Repetitions of Hierarchical Relations</title>
        <link>https://arxiv.org/abs/2504.10065</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.10065v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zeng Ren, Xinyi Guan, Martin Rohrmeier</dc:creator>
        <description><![CDATA[
            背景：模式对人类认知至关重要，可助于识别不同领域的结构和规律。方法：聚焦序列数据中层次关系重复产生的结构重复模式，基于加权演绎系统，以模板程序形式推断给定序列的最小生成过程，该形式主义用重复组合器丰富上下文无关语法，递归编码子计算的重复。效果：在音乐和行动规划的短序列上证明了模型的表达能力，为人类模式识别的心理表征和认知机制提供了更广泛见解。
            arXiv:2504.10065v1 Announce Type: new 
Abstract: Patterns are fundamental to human cognition, enabling the recognition of structure and regularity across diverse domains. In this work, we focus on structural repeats, patterns that arise from the repetition of hierarchical relations within sequential data, and develop a candidate computational model of how humans detect and understand such structural repeats. Based on a weighted deduction system, our model infers the minimal generative process of a given sequence in the form of a Template program, a formalism that enriches the context-free grammar with repetition combinators. Such representation efficiently encodes the repetition of sub-computations in a recursive manner. As a proof of concept, we demonstrate the expressiveness of our model on short sequences from music and action planning. The proposed model offers broader insights into the mental representations and cognitive mechanisms underlying human pattern recognition.
        ]]></description>
    </item>
    <item>
        <title>Towards Quantifying Commonsense Reasoning with Mechanistic Insights</title>
        <link>https://arxiv.org/abs/2504.10077</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.10077v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Abhinav Joshi, Areeb Ahmad, Divyaksh Shukla, Ashutosh Modi</dc:creator>
        <description><![CDATA[
            背景：常识推理处理人类通过与世界互动获得的隐性知识，目前多通过基于文本的任务评估大语言模型（LLMs）的常识推理能力。方法：将这种理解以图形结构形式保存，为37种日常人类活动创建标注方案，还提出设计机制。效果：所创建资源可构建约10¹⁷个常识查询，便于严格评估LLMs的常识推理能力，研究发现推理组件在LLMs中是局部化的，在处理常识查询决策中起重要作用。
            arXiv:2504.10077v1 Announce Type: new 
Abstract: Commonsense reasoning deals with the implicit knowledge that is well understood by humans and typically acquired via interactions with the world. In recent times, commonsense reasoning and understanding of various LLMs have been evaluated using text-based tasks. In this work, we argue that a proxy of this understanding can be maintained as a graphical structure that can further help to perform a rigorous evaluation of commonsense reasoning abilities about various real-world activities. We create an annotation scheme for capturing this implicit knowledge in the form of a graphical structure for 37 daily human activities. We find that the created resource can be used to frame an enormous number of commonsense queries (~ 10^{17}), facilitating rigorous evaluation of commonsense reasoning in LLMs. Moreover, recently, the remarkable performance of LLMs has raised questions about whether these models are truly capable of reasoning in the wild and, in general, how reasoning occurs inside these models. In this resource paper, we bridge this gap by proposing design mechanisms that facilitate research in a similar direction. Our findings suggest that the reasoning components are localized in LLMs that play a prominent role in decision-making when prompted with a commonsense query.
        ]]></description>
    </item>
    <item>
        <title>STaRFormer: Semi-Supervised Task-Informed Representation Learning via Dynamic Attention-Based Regional Masking for Sequential Data</title>
        <link>https://arxiv.org/abs/2504.10097</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.10097v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Maxmilian Forstenh\"ausler, Daniel K\"ulzer, Christos Anagnostopoulos, Shameem Puthiya Parambath, Natascha Weber</dc:creator>
        <description><![CDATA[
            背景：用序列时空数据进行准确预测对多种应用至关重要，但现实中环境因素和传感器限制导致数据非平稳、采样不规则，带来挑战。方法：提出基于Transformer的STaRFormer，作为序列建模通用框架，采用基于动态注意力的区域掩码方案结合半监督对比学习，增强特定任务的潜在表征。效果：在15个不同类型、领域、序列长度等的数据集上实验，相比现有方法有显著提升。
            arXiv:2504.10097v1 Announce Type: new 
Abstract: Accurate predictions using sequential spatiotemporal data are crucial for various applications. Utilizing real-world data, we aim to learn the intent of a smart device user within confined areas of a vehicle's surroundings. However, in real-world scenarios, environmental factors and sensor limitations result in non-stationary and irregularly sampled data, posing significant challenges. To address these issues, we developed a Transformer-based approach, STaRFormer, which serves as a universal framework for sequential modeling. STaRFormer employs a novel, dynamic attention-based regional masking scheme combined with semi-supervised contrastive learning to enhance task-specific latent representations. Comprehensive experiments on 15 datasets varying in types (including non-stationary and irregularly sampled), domains, sequence lengths, training samples, and applications, demonstrate the efficacy and practicality of STaRFormer. We achieve notable improvements over state-of-the-art approaches. Code and data will be made available.
        ]]></description>
    </item>
    <item>
        <title>Negate or Embrace: On How Misalignment Shapes Multimodal Representation Learning</title>
        <link>https://arxiv.org/abs/2504.10143</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.10143v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yichao Cai, Yuhang Liu, Erdun Gao, Tianjiao Jiang, Zhen Zhang, Anton van den Hengel, Javen Qinfeng Shi</dc:creator>
        <description><![CDATA[
            背景：多模态表征学习通过跨模态对齐线索来学习强大表征，但现实数据集常存在模态不对齐问题。方法：用潜变量模型形式化不对齐，引入选择偏差和扰动偏差两种机制，理论分析表明多模态对比学习学到的表征能捕捉对偏差不变的语义变量子集信息，还为现实机器学习系统设计提供见解。效果：在合成数据和真实图像 - 文本数据集上的实证研究验证了理论发现，揭示了不对齐对多模态表征学习的细微影响。
            arXiv:2504.10143v1 Announce Type: new 
Abstract: Multimodal representation learning, exemplified by multimodal contrastive learning (MMCL) using image-text pairs, aims to learn powerful representations by aligning cues across modalities. This approach relies on the core assumption that the exemplar image-text pairs constitute two representations of an identical concept. However, recent research has revealed that real-world datasets often exhibit misalignment. There are two distinct viewpoints on how to address this issue: one suggests mitigating the misalignment, and the other leveraging it. We seek here to reconcile these seemingly opposing perspectives, and to provide a practical guide for practitioners. Using latent variable models we thus formalize misalignment by introducing two specific mechanisms: selection bias, where some semantic variables are missing, and perturbation bias, where semantic variables are distorted -- both affecting latent variables shared across modalities. Our theoretical analysis demonstrates that, under mild assumptions, the representations learned by MMCL capture exactly the information related to the subset of the semantic variables invariant to selection and perturbation biases. This provides a unified perspective for understanding misalignment. Based on this, we further offer actionable insights into how misalignment should inform the design of real-world ML systems. We validate our theoretical findings through extensive empirical studies on both synthetic data and real image-text datasets, shedding light on the nuanced impact of misalignment on multimodal representation learning.
        ]]></description>
    </item>
    <item>
        <title>DioR: Adaptive Cognitive Detection and Contextual Retrieval Optimization for Dynamic Retrieval-Augmented Generation</title>
        <link>https://arxiv.org/abs/2504.10198</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.10198v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hanghui Guo, Jia Zhu, Shimin Di, Weijie Shi, Zhangze Chen, Jiajie Xu</dc:creator>
        <description><![CDATA[
            背景：动态检索增强生成（RAG）可缓解大语言模型生成时的幻觉问题，但现有方法在控制检索触发机制和审查检索内容方面存在局限。方法：提出创新动态RAG方法DioR，包含自适应认知检测和上下文检索优化两部分，用于确定大模型何时需要检索及检索什么内容。效果：实验表明，DioR在所有任务上表现出色，证明了该方法的有效性。
            arXiv:2504.10198v1 Announce Type: new 
Abstract: Dynamic Retrieval-augmented Generation (RAG) has shown great success in mitigating hallucinations in large language models (LLMs) during generation. However, existing dynamic RAG methods face significant limitations in two key aspects: 1) Lack of an effective mechanism to control retrieval triggers, and 2) Lack of effective scrutiny of retrieval content. To address these limitations, we propose an innovative dynamic RAG method, DioR (Adaptive Cognitive Detection and Contextual Retrieval Optimization), which consists of two main components: adaptive cognitive detection and contextual retrieval optimization, specifically designed to determine when retrieval is needed and what to retrieve for LLMs is useful. Experimental results demonstrate that DioR achieves superior performance on all tasks, demonstrating the effectiveness of our work.
        ]]></description>
    </item>
    <item>
        <title>PRM-BAS: Enhancing Multimodal Reasoning through PRM-guided Beam Annealing Search</title>
        <link>https://arxiv.org/abs/2504.10222</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.10222v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Pengfei Hu, Zhenrong Zhang, Qikai Chang, Shuhang Liu, Jiefeng Ma, Jun Du, Jianshu Zhang, Quan Liu, Jianqing Gao, Feng Ma, Qingfeng Liu</dc:creator>
        <description><![CDATA[
            背景：提升多模态大语言模型推理能力是当前研究热点，过程奖励模型（PRMs）能提供分步监督，但如何有效融入搜索策略尚待解决。方法：提出PRM - BAS方法，动态调整束宽以平衡性能与效率，还提出数据构建和PRM训练统一框架，构建PRM - BAS - 300k数据集，用价值损失和排序损失训练PRM。效果：在多模态推理基准测试中显著提升推理性能，计算成本低，跨模型规模和架构泛化性好，有强鲁棒性和即插即用能力。
            arXiv:2504.10222v1 Announce Type: new 
Abstract: Recent work increasingly focuses on improving the reasoning capabilities of Multimodal Large Language Models (MLLMs). Among existing methods, Process Reward Models (PRMs) stand out for offering dense, step-wise supervision to guide intermediate reasoning. However, how to effectively integrate PRMs into search strategies remains an open question. In this paper, we introduce PRM-BAS (PRM-Guided Beam Annealing Search), a lightweight approach for PRM-guided reasoning that dynamically adjusts beam size -- starting with a broader search space and gradually narrowing it as contextual information accumulates, thereby balancing performance and efficiency. We further propose a unified framework for data construction and PRM training. Specifically, we construct the PRM-BAS-300k dataset by selecting 300k questions from existing datasets and performing rollouts at each step to estimate the probability of reaching a correct final answer. The PRM is then trained using a combination of value loss for absolute action quality and rank loss for relative action quality. Extensive experiments on challenging multimodal reasoning benchmarks demonstrate that PRM-BAS significantly improves reasoning performance while maintaining low computational cost. Moreover, it generalizes well across different model scales and architectures, showcasing strong robustness and plug-and-play capability.
        ]]></description>
    </item>
    <item>
        <title>Forecasting from Clinical Textual Time Series: Adaptations of the Encoder and Decoder Language Model Families</title>
        <link>https://arxiv.org/abs/2504.10340</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.10340v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Shahriar Noroozizadeh, Sayantan Kumar, Jeremy C. Weiss</dc:creator>
        <description><![CDATA[
            背景：传统机器学习依赖结构化数据，对临床文本时间序列中丰富的患者轨迹信息利用不足。方法：提出基于文本时间序列的预测问题，以大语言模型辅助标注流程提取的带时间戳临床发现为输入，系统评估多种模型，包括微调的基于解码器的大语言模型和基于编码器的Transformer。效果：编码器模型在长短时事件预测上F1分数更高、时间一致性更好，微调掩码方法提升排序性能；指令微调解码器模型在生存分析中，尤其早期预后有优势。
            arXiv:2504.10340v1 Announce Type: new 
Abstract: Clinical case reports encode rich, temporal patient trajectories that are often underexploited by traditional machine learning methods relying on structured data. In this work, we introduce the forecasting problem from textual time series, where timestamped clinical findings--extracted via an LLM-assisted annotation pipeline--serve as the primary input for prediction. We systematically evaluate a diverse suite of models, including fine-tuned decoder-based large language models and encoder-based transformers, on tasks of event occurrence prediction, temporal ordering, and survival analysis. Our experiments reveal that encoder-based models consistently achieve higher F1 scores and superior temporal concordance for short- and long-horizon event forecasting, while fine-tuned masking approaches enhance ranking performance. In contrast, instruction-tuned decoder models demonstrate a relative advantage in survival analysis, especially in early prognosis settings. Our sensitivity analyses further demonstrate the importance of time ordering, which requires clinical time series construction, as compared to text ordering, the format of the text inputs that LLMs are classically trained on. This highlights the additional benefit that can be ascertained from time-ordered corpora, with implications for temporal tasks in the era of widespread LLM use.
        ]]></description>
    </item>
    <item>
        <title>Multimodal Long Video Modeling Based on Temporal Dynamic Context</title>
        <link>https://arxiv.org/abs/2504.10443</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.10443v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Haoran Hao, Jiaming Han, Yiyuan Zhang, Xiangyu Yue</dc:creator>
        <description><![CDATA[
            背景：大语言模型在视频理解取得进展，但现有模型受上下文长度和视频信息量大的限制，处理长视频能力不足。方法：提出基于帧间时间关系的动态长视频编码方法TDC，先将视频按帧相似度分割成场景并编码，再用时间上下文压缩器减少片段内的标记数，最后将静态帧标记和时间上下文标记输入大模型；还提出免训练的思维链策略处理超长视频。效果：在视频理解和视听理解基准测试中表现出色。
            arXiv:2504.10443v1 Announce Type: new 
Abstract: Recent advances in Large Language Models (LLMs) have led to significant breakthroughs in video understanding. However, existing models still struggle with long video processing due to the context length constraint of LLMs and the vast amount of information within the video. Although some recent methods are designed for long video understanding, they often lose crucial information during token compression and struggle with additional modality like audio. In this work, we propose a dynamic long video encoding method utilizing the temporal relationship between frames, named Temporal Dynamic Context (TDC). Firstly, we segment the video into semantically consistent scenes based on inter-frame similarities, then encode each frame into tokens using visual-audio encoders. Secondly, we propose a novel temporal context compressor to reduce the number of tokens within each segment. Specifically, we employ a query-based Transformer to aggregate video, audio, and instruction text tokens into a limited set of temporal context tokens. Finally, we feed the static frame tokens and the temporal context tokens into the LLM for video understanding. Furthermore, to handle extremely long videos, we propose a training-free chain-of-thought strategy that progressively extracts answers from multiple video segments. These intermediate answers serve as part of the reasoning process and contribute to the final answer. We conduct extensive experiments on general video understanding and audio-video understanding benchmarks, where our method demonstrates strong performance. The code and models are available at https://github.com/Hoar012/TDC-Video.
        ]]></description>
    </item>
    <item>
        <title>M1: Towards Scalable Test-Time Compute with Mamba Reasoning Models</title>
        <link>https://arxiv.org/abs/2504.10449</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.10449v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Junxiong Wang, Wen-Ding Li, Daniele Paliotta, Daniel Ritter, Alexander M. Rush, Tri Dao</dc:creator>
        <description><![CDATA[
            背景：有效推理对解决复杂数学问题至关重要，基于Transformer的模型因计算复杂度和内存需求限制了上下文长度扩展。方法：提出基于Mamba架构的混合线性RNN推理模型M1，利用现有推理模型的蒸馏过程，并通过强化学习训练增强。效果：在AIME和MATH基准测试中，M1优于以往线性RNN模型，与同规模的先进模型性能相当；生成速度比同规模Transformer快3倍多，在固定生成时间内，通过自一致性投票比DeepSeek R1蒸馏Transformer推理模型准确率更高。
            arXiv:2504.10449v1 Announce Type: new 
Abstract: Effective reasoning is crucial to solving complex mathematical problems. Recent large language models (LLMs) have boosted performance by scaling test-time computation through long chain-of-thought reasoning. However, transformer-based models are inherently limited in extending context length due to their quadratic computational complexity and linear memory requirements. In this paper, we introduce a novel hybrid linear RNN reasoning model, M1, built on the Mamba architecture, which allows memory-efficient inference. Our approach leverages a distillation process from existing reasoning models and is further enhanced through RL training. Experimental results on the AIME and MATH benchmarks show that M1 not only outperforms previous linear RNN models but also matches the performance of state-of-the-art Deepseek R1 distilled reasoning models at a similar scale. We also compare our generation speed with a highly performant general purpose inference engine, vLLM, and observe more than a 3x speedup compared to a same size transformer. With throughput speedup, we are able to achieve higher accuracy compared to DeepSeek R1 distilled transformer reasoning models under a fixed generation time budget using self-consistency voting. Overall, we introduce a hybrid Mamba reasoning model and provide a more effective approach to scaling test-time generation using self-consistency or long chain of thought reasoning.
        ]]></description>
    </item>
    <item>
        <title>The Scalability of Simplicity: Empirical Analysis of Vision-Language Learning with a Single Transformer</title>
        <link>https://arxiv.org/abs/2504.10462</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.10462v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Weixian Lei, Jiacong Wang, Haochen Wang, Xiangtai Li, Jun Hao Liew, Jiashi Feng, Zilong Huang</dc:creator>
        <description><![CDATA[
            背景：现有模块化多模态大语言模型依赖预训练视觉变压器，架构不够简洁。方法：提出单变压器统一多模态大语言模型SAIL，整合原始像素编码和语言解码，采用混合注意力机制和多模态位置编码，消除单独的视觉编码器。效果：通过扩展训练数据和模型大小，SAIL性能与模块化模型相当。去除预训练组件提升了可扩展性，改变了跨模态信息流模式，在语义分割等视觉任务中表现与ViT - 22B相当。
            arXiv:2504.10462v1 Announce Type: new 
Abstract: This paper introduces SAIL, a single transformer unified multimodal large language model (MLLM) that integrates raw pixel encoding and language decoding within a singular architecture. Unlike existing modular MLLMs, which rely on a pre-trained vision transformer (ViT), SAIL eliminates the need for a separate vision encoder, presenting a more minimalist architecture design. Instead of introducing novel architectural components, SAIL adapts mix-attention mechanisms and multimodal positional encodings to better align with the distinct characteristics of visual and textual modalities. We systematically compare SAIL's properties-including scalability, cross-modal information flow patterns, and visual representation capabilities-with those of modular MLLMs. By scaling both training data and model size, SAIL achieves performance comparable to modular MLLMs. Notably, the removal of pretrained ViT components enhances SAIL's scalability and results in significantly different cross-modal information flow patterns. Moreover, SAIL demonstrates strong visual representation capabilities, achieving results on par with ViT-22B in vision tasks such as semantic segmentation. Code and models are available at https://github.com/bytedance/SAIL.
        ]]></description>
    </item>
    <item>
        <title>Recommendation System in Advertising and Streaming Media: Unsupervised Data Enhancement Sequence Suggestions</title>
        <link>https://arxiv.org/abs/2504.08740</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.08740v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kowei Shih, Yi Han, Li Tan</dc:creator>
        <description><![CDATA[
            背景：序列推荐旨在基于用户过往交互预测其下一选择，但存在监督信号有限、数据有噪声等问题，现有方法还忽略多序列间物品关联。方法：提出Global Unsupervised Data-Augmentation（UDA4SR）框架，先利用生成对抗网络进行数据增强，构建全局物品关系图，再用图对比学习增强物品嵌入，还引入目标注意力机制改进CapsNet模块。效果：大量实验表明，UDA4SR显著优于现有方法。
            arXiv:2504.08740v1 Announce Type: cross 
Abstract: Sequential recommendation is an extensively explored approach to capturing users' evolving preferences based on past interactions, aimed at predicting their next likely choice. Despite significant advancements in this domain, including methods based on RNNs and self-attention, challenges like limited supervised signals and noisy data caused by unintentional clicks persist. To address these challenges, some studies have incorporated unsupervised learning by leveraging local item contexts within individual sequences. However, these methods often overlook the intricate associations between items across multiple sequences and are susceptible to noise in item co-occurrence patterns. In this context, we introduce a novel framework, Global Unsupervised Data-Augmentation (UDA4SR), which adopts a graph contrastive learning perspective to generate more robust item embeddings for sequential recommendation. Our approach begins by integrating Generative Adversarial Networks (GANs) for data augmentation, which serves as the first step to enhance the diversity and richness of the training data. Then, we build a Global Item Relationship Graph (GIG) based on all user interaction sequences. Subsequently, we employ graph contrastive learning on the refined graph to enhance item embeddings by capturing complex global associations. To model users' dynamic and diverse interests more effectively, we enhance the CapsNet module with a novel target-attention mechanism. Extensive experiments show that UDA4SR significantly outperforms state-of-the-art approaches.
        ]]></description>
    </item>
    <item>
        <title>A Survey of Multimodal Retrieval-Augmented Generation</title>
        <link>https://arxiv.org/abs/2504.08748</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.08748v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Lang Mei, Siyu Mo, Zhihan Yang, Chong Chen</dc:creator>
        <description><![CDATA[
            背景：文本RAG有局限，多模态RAG（MRAG）将多模态数据融入检索和生成过程，可克服其不足。方法：MRAG扩展了RAG框架，纳入多模态检索和生成，利用不同数据类型的上下文信息。效果：能减少幻觉，基于多模态知识增强问答系统，近期研究显示其性能优于传统RAG，尤其在需图文理解的场景。该综述回顾了MRAG的关键组件等，指出挑战和方向，有望推动该领域发展。
            arXiv:2504.08748v1 Announce Type: cross 
Abstract: Multimodal Retrieval-Augmented Generation (MRAG) enhances large language models (LLMs) by integrating multimodal data (text, images, videos) into retrieval and generation processes, overcoming the limitations of text-only Retrieval-Augmented Generation (RAG). While RAG improves response accuracy by incorporating external textual knowledge, MRAG extends this framework to include multimodal retrieval and generation, leveraging contextual information from diverse data types. This approach reduces hallucinations and enhances question-answering systems by grounding responses in factual, multimodal knowledge. Recent studies show MRAG outperforms traditional RAG, especially in scenarios requiring both visual and textual understanding. This survey reviews MRAG's essential components, datasets, evaluation methods, and limitations, providing insights into its construction and improvement. It also identifies challenges and future research directions, highlighting MRAG's potential to revolutionize multimodal information retrieval and generation. By offering a comprehensive perspective, this work encourages further exploration into this promising paradigm.
        ]]></description>
    </item>
    <item>
        <title>A Survey of Frontiers in LLM Reasoning: Inference Scaling, Learning to Reason, and Agentic Systems</title>
        <link>https://arxiv.org/abs/2504.09037</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09037v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zixuan Ke, Fangkai Jiao, Yifei Ming, Xuan-Phi Nguyen, Austin Xu, Do Xuan Long, Minzhi Li, Chengwei Qin, Peifeng Wang, Silvio Savarese, Caiming Xiong, Shafiq Joty</dc:creator>
        <description><![CDATA[
            背景：推理是关键认知能力，大语言模型发展使推理成为区分先进AI与传统模型的关键。方法：从推理实现阶段（推理时或专门训练）和架构（独立LLM、含外部工具的复合系统等）两维度对现有方法分类，从输入（构建高质量提示）和输出（优化候选以提升推理质量）两视角分析。效果：该分类系统展现LLM推理发展态势，如从推理扩展到学习推理、向智能工作流转变等，还涵盖多种学习算法和工作流设计。
            arXiv:2504.09037v1 Announce Type: cross 
Abstract: Reasoning is a fundamental cognitive process that enables logical inference, problem-solving, and decision-making. With the rapid advancement of large language models (LLMs), reasoning has emerged as a key capability that distinguishes advanced AI systems from conventional models that empower chatbots. In this survey, we categorize existing methods along two orthogonal dimensions: (1) Regimes, which define the stage at which reasoning is achieved (either at inference time or through dedicated training); and (2) Architectures, which determine the components involved in the reasoning process, distinguishing between standalone LLMs and agentic compound systems that incorporate external tools, and multi-agent collaborations. Within each dimension, we analyze two key perspectives: (1) Input level, which focuses on techniques that construct high-quality prompts that the LLM condition on; and (2) Output level, which methods that refine multiple sampled candidates to enhance reasoning quality. This categorization provides a systematic understanding of the evolving landscape of LLM reasoning, highlighting emerging trends such as the shift from inference-scaling to learning-to-reason (e.g., DeepSeek-R1), and the transition to agentic workflows (e.g., OpenAI Deep Research, Manus Agent). Additionally, we cover a broad spectrum of learning algorithms, from supervised fine-tuning to reinforcement learning such as PPO and GRPO, and the training of reasoners and verifiers. We also examine key designs of agentic workflows, from established patterns like generator-evaluator and LLM debate to recent innovations. ...
        ]]></description>
    </item>
    <item>
        <title>Towards Stepwise Domain Knowledge-Driven Reasoning Optimization and Reflection Improvement</title>
        <link>https://arxiv.org/abs/2504.09058</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09058v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chengyuan Liu, Shihang Wang, Lizhi Qing, Kaisong Song, Junjie Cao, Jun Lin, Ji Zhang, Ang Li, Kun Kuang, Fei Wu</dc:creator>
        <description><![CDATA[
            背景：目前基于蒙特卡罗树搜索（MCTS）的思维链（CoTs）逐步监督在编码和数学等逻辑推理任务中有提升，但在需要特定领域专业知识的任务中的作用未知。方法：提出逐步领域知识驱动推理优化框架，用MCTS算法为需理解、推理和专业知识的问题进行步骤级监督，还引入反思路径偏好优化以从更好视角迭代学习推理反思。效果：实验表明该方法在各类法律领域问题上有效。 
            arXiv:2504.09058v1 Announce Type: cross 
Abstract: Recently, stepwise supervision on Chain of Thoughts (CoTs) presents an enhancement on the logical reasoning tasks such as coding and math, with the help of Monte Carlo Tree Search (MCTS). However, its contribution to tasks requiring domain-specific expertise and knowledge remains unexplored. Motivated by the interest, we identify several potential challenges of vanilla MCTS within this context, and propose the framework of Stepwise Domain Knowledge-Driven Reasoning Optimization, employing the MCTS algorithm to develop step-level supervision for problems that require essential comprehension, reasoning, and specialized knowledge. Additionally, we also introduce the Preference Optimization towards Reflection Paths, which iteratively learns self-reflection on the reasoning thoughts from better perspectives. We have conducted extensive experiments to evaluate the advantage of the methodologies. Empirical results demonstrate the effectiveness on various legal-domain problems. We also report a diverse set of valuable findings, hoping to encourage the enthusiasm to the research of domain-specific LLMs and MCTS.
        ]]></description>
    </item>
    <item>
        <title>NetTAG: A Multimodal RTL-and-Layout-Aligned Netlist Foundation Model via Text-Attributed Graph</title>
        <link>https://arxiv.org/abs/2504.09260</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09260v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wenji Fang, Wenkai Li, Shang Liu, Yao Lu, Hongce Zhang, Zhiyao Xie</dc:creator>
        <description><![CDATA[
            背景：现有电路表示学习预训练方案仅处理简单与非门图，大语言模型缺乏对扁平化网表的结构感知。方法：提出NetTAG网表基础模型，将网表表示为文本属性图，结合基于大语言模型的文本编码器和图变换器，通过自监督目标进行预训练并与RTL和布局阶段对齐。效果：在四个不同的功能和物理任务中始终优于各特定任务方法，超越了现有先进的AIG编码器，展现出多功能性。
            arXiv:2504.09260v1 Announce Type: cross 
Abstract: Circuit representation learning has shown promise in advancing Electronic Design Automation (EDA) by capturing structural and functional circuit properties for various tasks. Existing pre-trained solutions rely on graph learning with complex functional supervision, such as truth table simulation. However, they only handle simple and-inverter graphs (AIGs), struggling to fully encode other complex gate functionalities. While large language models (LLMs) excel at functional understanding, they lack the structural awareness for flattened netlists. To advance netlist representation learning, we present NetTAG, a netlist foundation model that fuses gate semantics with graph structure, handling diverse gate types and supporting a variety of functional and physical tasks. Moving beyond existing graph-only methods, NetTAG formulates netlists as text-attributed graphs, with gates annotated by symbolic logic expressions and physical characteristics as text attributes. Its multimodal architecture combines an LLM-based text encoder for gate semantics and a graph transformer for global structure. Pre-trained with gate and graph self-supervised objectives and aligned with RTL and layout stages, NetTAG captures comprehensive circuit intrinsics. Experimental results show that NetTAG consistently outperforms each task-specific method on four largely different functional and physical tasks and surpasses state-of-the-art AIG encoders, demonstrating its versatility.
        ]]></description>
    </item>
    <item>
        <title>Draw with Thought: Unleashing Multimodal Reasoning for Scientific Diagram Generation</title>
        <link>https://arxiv.org/abs/2504.09479</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09479v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhiqing Cui, Jiahao Yuan, Hanqing Wang, Yanshu Li, Chenxu Du, Zhenglong Ding</dc:creator>
        <description><![CDATA[
            背景：科学图表是跨学科交流结构化知识的重要工具，但常以静态图像形式发布，现有多模态大模型在处理复杂图表时缺乏语义控制和结构可解释性。方法：提出无需训练的框架Draw with Thought (DwT)，通过思维链推理引导多模态大模型将图表重构为可编辑的mxGraph XML代码，分粗到细规划和结构感知代码生成两阶段。效果：在八个多模态大模型上实验，实现高保真、语义对齐和结构有效的重构，人工评估显示在准确性和视觉美感上高度一致。
            arXiv:2504.09479v1 Announce Type: cross 
Abstract: Scientific diagrams are vital tools for communicating structured knowledge across disciplines. However, they are often published as static raster images, losing symbolic semantics and limiting reuse. While Multimodal Large Language Models (MLLMs) offer a pathway to bridging vision and structure, existing methods lack semantic control and structural interpretability, especially on complex diagrams. We propose Draw with Thought (DwT), a training-free framework that guides MLLMs to reconstruct diagrams into editable mxGraph XML code through cognitively-grounded Chain-of-Thought reasoning. DwT enables interpretable and controllable outputs without model fine-tuning by dividing the task into two stages: Coarse-to-Fine Planning, which handles perceptual structuring and semantic specification, and Structure-Aware Code Generation, enhanced by format-guided refinement. To support evaluation, we release Plot2XML, a benchmark of 247 real-world scientific diagrams with gold-standard XML annotations. Extensive experiments across eight MLLMs show that our approach yields high-fidelity, semantically aligned, and structurally valid reconstructions, with human evaluations confirming strong alignment in both accuracy and visual aesthetics, offering a scalable solution for converting static visuals into executable representations and advancing machine understanding of scientific graphics.
        ]]></description>
    </item>
    <item>
        <title>InfoMAE: Pair-Efficient Cross-Modal Alignment for Multimodal Time-Series Sensing Signals</title>
        <link>https://arxiv.org/abs/2504.09707</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09707v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tomoyoshi Kimura, Xinlin Li, Osama Hanna, Yatong Chen, Yizhuo Chen, Denizhan Kara, Tianshi Wang, Jinyang Li, Xiaomin Ouyang, Shengzhong Liu, Mani Srivastava, Suhas Diggavi, Tarek Abdelzaher</dc:creator>
        <description><![CDATA[
            背景：标准多模态自监督学习算法对多模态样本规模和质量要求高，而时间序列信号的异质性和不可解释性导致单模态数据多、高质量多模态对稀缺，限制了物联网传感智能性能。方法：提出InfoMAE框架，通过促进预训练单模态表示的高效跨模态对齐，解决自监督学习下多模态对效率问题，采用新的信息理论公式同时处理分布级和实例级对齐。效果：在两个物联网应用中，提升下游多模态任务超60%，多模态配对效率显著提高，单模态任务准确率平均提升22%。
            arXiv:2504.09707v1 Announce Type: cross 
Abstract: Standard multimodal self-supervised learning (SSL) algorithms regard cross-modal synchronization as implicit supervisory labels during pretraining, thus posing high requirements on the scale and quality of multimodal samples. These constraints significantly limit the performance of sensing intelligence in IoT applications, as the heterogeneity and the non-interpretability of time-series signals result in abundant unimodal data but scarce high-quality multimodal pairs. This paper proposes InfoMAE, a cross-modal alignment framework that tackles the challenge of multimodal pair efficiency under the SSL setting by facilitating efficient cross-modal alignment of pretrained unimodal representations. InfoMAE achieves \textit{efficient cross-modal alignment} with \textit{limited data pairs} through a novel information theory-inspired formulation that simultaneously addresses distribution-level and instance-level alignment. Extensive experiments on two real-world IoT applications are performed to evaluate InfoMAE's pairing efficiency to bridge pretrained unimodal models into a cohesive joint multimodal model. InfoMAE enhances downstream multimodal tasks by over 60% with significantly improved multimodal pairing efficiency. It also improves unimodal task accuracy by an average of 22%.
        ]]></description>
    </item>
    <item>
        <title>Integrating Large Language Models for Automated Structural Analysis</title>
        <link>https://arxiv.org/abs/2504.09754</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09754v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Haoran Liang, Mohammad Talebi Kalaleh, Qipei Mei</dc:creator>
        <description><![CDATA[
            背景：当前缺乏利用大语言模型（LLMs）进行自动结构分析的系统框架。方法：提出将LLMs与结构分析软件集成的框架，以LLMs为核心，将文本结构描述转化为Python脚本，结合代码型有限元工具，采用特定领域提示设计和上下文学习策略。效果：在20个结构分析文字问题的基准测试中，基于GPT - 4o的框架准确率达100%，超GPT - 4等模型，特定领域指令使非对称结构问题性能提升30%，大幅提高自动化程度。
            arXiv:2504.09754v1 Announce Type: cross 
Abstract: Automated analysis for engineering structures offers considerable potential for boosting efficiency by minimizing repetitive tasks. Although AI-driven methods are increasingly common, no systematic framework yet leverages Large Language Models (LLMs) for automatic structural analysis. To address this gap, we propose a novel framework that integrates LLMs with structural analysis software. LLMs serve as the core engine: they parse structural descriptions from text and translate them into executable Python scripts. Moreover, the framework integrates the generative capabilities of LLMs with code-based finite element (FE) tools like OpenSeesPy. It employs domain-specific prompt design and in-context learning strategies to enhance the LLM's problem-solving capabilities and generative stability, enabling fully automated structural analysis from descriptive text to model outputs. In our experiments, we introduce a well-curated small-scale benchmark dataset of 20 structural analysis word problems (SAWPs) with ground-truth solutions and evaluate the performance of different LLMs within our framework in solving these SAWPs. The role of system instructions, crafted by structural engineers, is also investigated to understand their impact on LLM-driven structural analysis. Additionally, the generative stability of our framework is examined. Through multiple validation experiments on the benchmark, our results demonstrate that the proposed framework can substantially increase the level of automation in solving SAWPs compared to traditional methods. Quantitatively, the framework, built on GPT-4o, achieved 100% accuracy, surpassing GPT-4 (85%), Gemini 1.5 Pro (80%), and Llama-3.3 (30%) on the test examples. Furthermore, integrating domain-specific instructions enhanced performance by 30% on problems with asymmetrical structural configurations.
        ]]></description>
    </item>
    <item>
        <title>Understanding and Optimizing Multi-Stage AI Inference Pipelines</title>
        <link>https://arxiv.org/abs/2504.09775</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09775v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Abhimanyu Rajeshkumar Bambhaniya, Hanjiang Wu, Suvinay Subramanian, Sudarshan Srinivasan, Souvik Kundu, Amir Yazdanbakhsh, Midhilesh Elavazhagan, Madhu Kumar, Tushar Krishna</dc:creator>
        <description><![CDATA[
            背景：大语言模型发展促使推理流程和硬件平台不断升级，现有模拟器难以模拟多阶段异构工作流。方法：提出HERMES模拟器，可模拟RAG、推理等多种请求阶段，支持异构客户端并发执行多模型，集成硬件跟踪与分析建模。效果：通过案例研究，探究推理阶段对端到端延迟的影响等，能为系统设计者提供优化软硬件协同设计的可行见解，助力应对大模型推理的复杂局面。
            arXiv:2504.09775v1 Announce Type: cross 
Abstract: The rapid evolution of Large Language Models (LLMs) has driven the need for increasingly sophisticated inference pipelines and hardware platforms. Modern LLM serving extends beyond traditional prefill-decode workflows, incorporating multi-stage processes such as Retrieval Augmented Generation (RAG), key-value (KV) cache retrieval, dynamic model routing, and multi step reasoning. These stages exhibit diverse computational demands, requiring distributed systems that integrate GPUs, ASICs, CPUs, and memory-centric architectures. However, existing simulators lack the fidelity to model these heterogeneous, multi-engine workflows, limiting their ability to inform architectural decisions.
  To address this gap, we introduce HERMES, a Heterogeneous Multi-stage LLM inference Execution Simulator. HERMES models diverse request stages; including RAG, KV retrieval, reasoning, prefill, and decode across complex hardware hierarchies. HERMES supports heterogeneous clients executing multiple models concurrently unlike prior frameworks while incorporating advanced batching strategies and multi-level memory hierarchies. By integrating real hardware traces with analytical modeling, HERMES captures critical trade-offs such as memory bandwidth contention, inter-cluster communication latency, and batching efficiency in hybrid CPU-accelerator deployments. Through case studies, we explore the impact of reasoning stages on end-to-end latency, optimal batching strategies for hybrid pipelines, and the architectural implications of remote KV cache retrieval. HERMES empowers system designers to navigate the evolving landscape of LLM inference, providing actionable insights into optimizing hardware-software co-design for next-generation AI workloads.
        ]]></description>
    </item>
    <item>
        <title>StePO-Rec: Towards Personalized Outfit Styling Assistant via Knowledge-Guided Multi-Step Reasoning</title>
        <link>https://arxiv.org/abs/2504.09915</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09915v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuxi Bi, Yunfan Gao, Haofen Wang</dc:creator>
        <description><![CDATA[
            背景：传统时尚推荐系统缺乏透明度且难融入专业知识，个性化时尚造型潜力未充分挖掘。方法：提出多粒度知识库PAFA，将专业造型知识组织为元数据、领域原则和语义关系三个层次；基于此开发知识引导的多步穿搭推荐方法StePO-Rec，用场景 - 维度 - 属性框架提供结构化建议，采用递归树构建使推荐符合专业原则和个人偏好，还有偏好 - 趋势重排系统。效果：在IQON数据集上，Recall@1提升28%，MAP提升32.8%，案例显示可解释性等增强。
            arXiv:2504.09915v1 Announce Type: cross 
Abstract: Advancements in Generative AI offers new opportunities for FashionAI, surpassing traditional recommendation systems that often lack transparency and struggle to integrate expert knowledge, leaving the potential for personalized fashion styling remain untapped. To address these challenges, we present PAFA (Principle-Aware Fashion), a multi-granular knowledge base that organizes professional styling expertise into three levels of metadata, domain principles, and semantic relationships. Using PAFA, we develop StePO-Rec, a knowledge-guided method for multi-step outfit recommendation. StePO-Rec provides structured suggestions using a scenario-dimension-attribute framework, employing recursive tree construction to align recommendations with both professional principles and individual preferences. A preference-trend re-ranking system further adapts to fashion trends while maintaining the consistency of the user's original style. Experiments on the widely used personalized outfit dataset IQON show a 28% increase in Recall@1 and 32.8% in MAP. Furthermore, case studies highlight improved explainability, traceability, result reliability, and the seamless integration of expertise and personalization.
        ]]></description>
    </item>
    <item>
        <title>OctGPT: Octree-based Multiscale Autoregressive Models for 3D Shape Generation</title>
        <link>https://arxiv.org/abs/2504.09975</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09975v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Si-Tong Wei, Rui-Huan Wang, Chuan-Zhi Zhou, Baoquan Chen, Peng-Shuai Wang</dc:creator>
        <description><![CDATA[
            背景：自回归模型在3D形状生成方面表现落后于扩散模型。方法：提出OctGPT，采用序列化八叉树表示捕捉3D形状的层次和空间结构，用VQVAE生成二进制令牌表示细节，将3D形状转换为多尺度二进制序列；引入基于八叉树的变压器，结合3D旋转位置编码等。效果：训练时间减少13倍，生成时间减少69倍，能在4块NVIDIA 4090 GPU上数天内完成高分辨率3D形状训练，加速收敛，提升生成质量。
            arXiv:2504.09975v1 Announce Type: cross 
Abstract: Autoregressive models have achieved remarkable success across various domains, yet their performance in 3D shape generation lags significantly behind that of diffusion models. In this paper, we introduce OctGPT, a novel multiscale autoregressive model for 3D shape generation that dramatically improves the efficiency and performance of prior 3D autoregressive approaches, while rivaling or surpassing state-of-the-art diffusion models. Our method employs a serialized octree representation to efficiently capture the hierarchical and spatial structures of 3D shapes. Coarse geometry is encoded via octree structures, while fine-grained details are represented by binary tokens generated using a vector quantized variational autoencoder (VQVAE), transforming 3D shapes into compact \emph{multiscale binary sequences} suitable for autoregressive prediction. To address the computational challenges of handling long sequences, we incorporate octree-based transformers enhanced with 3D rotary positional encodings, scale-specific embeddings, and token-parallel generation schemes. These innovations reduce training time by 13 folds and generation time by 69 folds, enabling the efficient training of high-resolution 3D shapes, e.g.,$1024^3$, on just four NVIDIA 4090 GPUs only within days. OctGPT showcases exceptional versatility across various tasks, including text-, sketch-, and image-conditioned generation, as well as scene-level synthesis involving multiple objects. Extensive experiments demonstrate that OctGPT accelerates convergence and improves generation quality over prior autoregressive methods, offering a new paradigm for high-quality, scalable 3D content creation.
        ]]></description>
    </item>
    <item>
        <title>HistLLM: A Unified Framework for LLM-Based Multimodal Recommendation with User History Encoding and Compression</title>
        <link>https://arxiv.org/abs/2504.10150</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.10150v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chen Zhang, Bo Hu, Weidong Chen, Zhendong Mao</dc:creator>
        <description><![CDATA[
            背景：大语言模型用于多模态推荐任务尚待深入研究，现有方法用长提示表示用户历史交互影响效率，还难以准确捕捉偏好，降低推荐性能。方法：提出HistLLM框架，通过用户历史编码模块整合文本和视觉特征，将多模态用户历史交互压缩成单个令牌表示，便于大模型处理用户偏好。效果：大量实验证明了该机制的有效性和高效性。
            arXiv:2504.10150v1 Announce Type: cross 
Abstract: While large language models (LLMs) have proven effective in leveraging textual data for recommendations, their application to multimodal recommendation tasks remains relatively underexplored. Although LLMs can process multimodal information through projection functions that map visual features into their semantic space, recommendation tasks often require representing users' history interactions through lengthy prompts combining text and visual elements, which not only hampers training and inference efficiency but also makes it difficult for the model to accurately capture user preferences from complex and extended prompts, leading to reduced recommendation performance. To address this challenge, we introduce HistLLM, an innovative multimodal recommendation framework that integrates textual and visual features through a User History Encoding Module (UHEM), compressing multimodal user history interactions into a single token representation, effectively facilitating LLMs in processing user preferences. Extensive experiments demonstrate the effectiveness and efficiency of our proposed mechanism.
        ]]></description>
    </item>
    <item>
        <title>The Future of MLLM Prompting is Adaptive: A Comprehensive Experimental Evaluation of Prompt Engineering Methods for Robust Multimodal Performance</title>
        <link>https://arxiv.org/abs/2504.10179</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.10179v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Anwesha Mohanty, Venkatesh Balavadhani Parthasarathy, Arsalan Shahid</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型（MLLMs）需通过最优提示工程发挥能力。方法：对13个开源MLLMs的7种提示工程方法进行全面实验评估，按参数数量将模型分类，对比多种提示技术。效果：大模型在代码生成等结构化任务中表现出色，少样本提示下准确率达96.88%，但所有模型在复杂推理和抽象理解上表现不佳，准确率常低于60%且幻觉率高。简单提示方法输出更简洁高效，自适应策略对提升性能至关重要。
            arXiv:2504.10179v1 Announce Type: cross 
Abstract: Multimodal Large Language Models (MLLMs) are set to transform how machines process and generate human-like responses by integrating diverse modalities such as text, images, and code. Yet, effectively harnessing their capabilities hinges on optimal prompt engineering. We present a comprehensive experimental evaluation of seven prompt engineering methods applied to 13 open-source MLLMs over 24 tasks spanning Reasoning and Compositionality, Multimodal Understanding and Alignment, Complex Code Generation and Execution, and Knowledge Retrieval and Integration. Our approach stratifies models by parameter count into Small (<4B), Medium (4B-10B), and Large (>10B) categories and compares prompting techniques including Zero-Shot, One-Shot, Few-Shot, Chain-of-Thought, Analogical, Generated Knowledge, and Tree-of-Thought. While Large MLLMs excel in structured tasks such as code generation, achieving accuracies up to 96.88% under Few-Shot prompting, all models struggle with complex reasoning and abstract understanding, often yielding accuracies below 60% and high hallucination rates. Structured reasoning prompts frequently increased hallucination up to 75% in small models and led to longer response times (over 20 seconds in Large MLLMs), while simpler prompting methods provided more concise and efficient outputs. No single prompting method uniformly optimises all task types. Instead, adaptive strategies combining example-based guidance with selective structured reasoning are essential to enhance robustness, efficiency, and factual accuracy. Our findings offer practical recommendations for prompt engineering and support more reliable deployment of MLLMs across applications including AI-assisted coding, knowledge retrieval, and multimodal content understanding.
        ]]></description>
    </item>
    <item>
        <title>GNN-ACLP: Graph Neural Networks based Analog Circuit Link Prediction</title>
        <link>https://arxiv.org/abs/2504.10240</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.10240v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Guanyuan Pan, Tiansheng Zhou, Bingtao Ma, Yaqi Wang, Jianxiang Zhao, Shuai Wang</dc:creator>
        <description><![CDATA[
            背景：模拟电路设计自动化中，从非完整网表识别缺失组件连接的电路链路预测很关键，但现有方法存在拓扑模式利用不足、数据稀缺、网表格式适应性有限等问题。方法：提出基于图神经网络的GNN - ACLP框架，引入SEAL框架实现端口级精度预测，用大语言模型检索增强生成（RAG）开发网表格式转换工具，构建含775个标注电路的SpiceNetlist数据集。效果：在SpiceNetlist和Image2Net数据集上较现有方法分别提升15.05%和12.01%。
            arXiv:2504.10240v1 Announce Type: cross 
Abstract: Circuit link prediction identifying missing component connections from incomplete netlists is crucial in automating analog circuit design. However, existing methods face three main challenges: 1) Insufficient use of topological patterns in circuit graphs reduces prediction accuracy; 2) Data scarcity due to the complexity of annotations hinders model generalization; 3) Limited adaptability to various netlist formats. We propose GNN-ACLP, a Graph Neural Networks (GNNs) based framework featuring three innovations to tackle these challenges. First, we introduce the SEAL (Subgraphs, Embeddings, and Attributes for Link Prediction) framework and achieve port-level accuracy in circuit link prediction. Second, we propose Netlist Babel Fish, a netlist format conversion tool leveraging retrieval-augmented generation (RAG) with large language model (LLM) to enhance the compatibility of netlist formats. Finally, we construct SpiceNetlist, a comprehensive dataset that contains 775 annotated circuits across 10 different classes of components. The experimental results demonstrate an improvement of 15.05% on the SpiceNetlist dataset and 12.01% on the Image2Net dataset over the existing approach.
        ]]></description>
    </item>
    <item>
        <title>Can LLMs Assist Expert Elicitation for Probabilistic Causal Modeling?</title>
        <link>https://arxiv.org/abs/2504.10397</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.10397v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Olha Shaposhnyk, Daria Zahorska, Svetlana Yanushkevich</dc:creator>
        <description><![CDATA[
            背景：研究探索大语言模型（LLMs）在生物识别和医疗应用中替代人类专家提取结构化因果知识、促进因果建模的潜力。方法：用医疗数据集将LLM生成的贝叶斯网络（BNs）与传统统计方法对比，通过结构方程建模验证关系，用熵、预测准确性等指标比较网络结构。效果：LLM生成的BNs熵低于专家引出和统计生成的BNs，预测更有信心和精度，但存在上下文约束等局限。
            arXiv:2504.10397v1 Announce Type: cross 
Abstract: Objective: This study investigates the potential of Large Language Models (LLMs) as an alternative to human expert elicitation for extracting structured causal knowledge and facilitating causal modeling in biometric and healthcare applications.
  Material and Methods: LLM-generated causal structures, specifically Bayesian networks (BNs), were benchmarked against traditional statistical methods (e.g., Bayesian Information Criterion) using healthcare datasets. Validation techniques included structural equation modeling (SEM) to verifying relationships, and measures such as entropy, predictive accuracy, and robustness to compare network structures.
  Results and Discussion: LLM-generated BNs demonstrated lower entropy than expert-elicited and statistically generated BNs, suggesting higher confidence and precision in predictions. However, limitations such as contextual constraints, hallucinated dependencies, and potential biases inherited from training data require further investigation.
  Conclusion: LLMs represent a novel frontier in expert elicitation for probabilistic causal modeling, promising to improve transparency and reduce uncertainty in the decision-making using such models.
        ]]></description>
    </item>
    <item>
        <title>Fine-tuning Multi-hop Question Answering with Hierarchical Graph Network</title>
        <link>https://arxiv.org/abs/2004.13821</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2004.13821v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Guanming Xiong</dc:creator>
        <description><![CDATA[
            背景：多跳问答需要模型具备复杂推理能力。方法：提出两阶段模型，第一阶段用分层图网络处理多跳问题，利用文档自然结构捕捉不同粒度信息，将推理转为节点分类任务；第二阶段进行语言模型微调。先由图神经网络选择并拼接支持句成段落，再在微调范式下找出答案区间。效果：论文未提及具体定量效果指标，但该方法结合图网络与语言模型微调，有望提升多跳问答性能。 
            arXiv:2004.13821v4 Announce Type: replace 
Abstract: In this paper, we present a two stage model for multi-hop question answering. The first stage is a hierarchical graph network, which is used to reason over multi-hop question and is capable to capture different levels of granularity using the nature structure(i.e., paragraphs, questions, sentences and entities) of documents. The reasoning process is convert to node classify task(i.e., paragraph nodes and sentences nodes). The second stage is a language model fine-tuning task. In a word, stage one use graph neural network to select and concatenate support sentences as one paragraph, and stage two find the answer span in language model fine-tuning paradigm.
        ]]></description>
    </item>
    <item>
        <title>PhD: A ChatGPT-Prompted Visual hallucination Evaluation Dataset</title>
        <link>https://arxiv.org/abs/2403.11116</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2403.11116v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiazhen Liu, Yuhan Fu, Ruobing Xie, Runquan Xie, Xingwu Sun, Fengzong Lian, Zhanhui Kang, Xirong Li</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型存在幻觉问题，视觉幻觉评估成为新兴话题。方法：本文构建了ChatGPT驱动的视觉幻觉评估数据集PhD，从任务和模式两个维度进行结构化设计，涵盖5种视觉识别任务，有多种提问模式，通过ChatGPT辅助的半自动化流程构建。效果：数据集包含超1.4万张日常图像、750张反常识图像和10.2万个VQA三元组，揭示了模型在不同模式和任务下的表现差异，可用于视觉幻觉评估和模型改进。
            arXiv:2403.11116v4 Announce Type: replace 
Abstract: Multimodal Large Language Models (MLLMs) hallucinate, resulting in an emerging topic of visual hallucination evaluation (VHE). This paper contributes a ChatGPT-Prompted visual hallucination evaluation Dataset (PhD) for objective VHE at a large scale. The essence of VHE is to ask an MLLM questions about specific images to assess its susceptibility to hallucination. Depending on what to ask (objects, attributes, sentiment, etc.) and how the questions are asked, we structure PhD along two dimensions, i.e. task and mode. Five visual recognition tasks, ranging from low-level (object / attribute recognition) to middle-level (sentiment / position recognition and counting), are considered. Besides a normal visual QA mode, which we term PhD-base, PhD also asks questions with specious context (PhD-sec) or with incorrect context ({PhD-icc), or with AI-generated counter common sense images (PhD-ccs). We construct PhD by a ChatGPT-assisted semi-automated pipeline, encompassing four pivotal modules: task-specific hallucinatory item (hitem) selection, hitem-embedded question generation, specious / incorrect context generation, and counter-common-sense (CCS) image generation. With over 14k daily images, 750 CCS images and 102k VQA triplets in total, PhD reveals considerable variability in MLLMs' performance across various modes and tasks, offering valuable insights into the nature of hallucination. As such, PhD stands as a potent tool not only for VHE but may also play a significant role in the refinement of MLLMs.
        ]]></description>
    </item>
    <item>
        <title>Bundle Neural Networks for message diffusion on graphs</title>
        <link>https://arxiv.org/abs/2405.15540</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2405.15540v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jacob Bamberger, Federico Barbero, Xiaowen Dong, Michael M. Bronstein</dc:creator>
        <description><![CDATA[
            背景：图结构数据学习主流是消息传递，但存在过平滑、过压缩和节点级表达能力有限等问题。方法：提出束神经网络（BuNN），通过在平坦向量束上进行消息扩散操作，其层根据扩散型偏微分方程更新特征，离散化时是Sheaf神经网络特例。结果：连续消息扩散使BuNN能处理图的更大尺度，缓解过压缩；理论上有通用节点级表达能力；合成实验和实际任务验证其性能，在多个标准基准测试中达最优。
            arXiv:2405.15540v2 Announce Type: replace 
Abstract: The dominant paradigm for learning on graph-structured data is message passing. Despite being a strong inductive bias, the local message passing mechanism suffers from pathological issues such as over-smoothing, over-squashing, and limited node-level expressivity. To address these limitations we propose Bundle Neural Networks (BuNN), a new type of GNN that operates via message diffusion over flat vector bundles - structures analogous to connections on Riemannian manifolds that augment the graph by assigning to each node a vector space and an orthogonal map. A BuNN layer evolves the features according to a diffusion-type partial differential equation. When discretized, BuNNs are a special case of Sheaf Neural Networks (SNNs), a recently proposed MPNN capable of mitigating over-smoothing. The continuous nature of message diffusion enables BuNNs to operate on larger scales of the graph and, therefore, to mitigate over-squashing. Finally, we prove that BuNN can approximate any feature transformation over nodes on any (potentially infinite) family of graphs given injective positional encodings, resulting in universal node-level expressivity. We support our theory via synthetic experiments and showcase the strong empirical performance of BuNNs over a range of real-world tasks, achieving state-of-the-art results on several standard benchmarks in transductive and inductive settings.
        ]]></description>
    </item>
    <item>
        <title>Ctrl-GenAug: Controllable Generative Augmentation for Medical Sequence Classification</title>
        <link>https://arxiv.org/abs/2409.17091</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2409.17091v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xinrui Zhou, Yuhao Huang, Haoran Dou, Shijing Chen, Ao Chang, Jia Liu, Weiran Long, Jian Zheng, Erjiao Xu, Jie Ren, Ruobing Huang, Jun Cheng, Wufeng Xue, Dong Ni</dc:creator>
        <description><![CDATA[
            背景：医学领域中，大规模数据集有限和标注过程繁琐阻碍了深度模型性能，现有扩散生成增强方法缺乏语义和序列可控性且忽视合成样本质量。方法：提出Ctrl - GenAug框架，设计多模态条件引导的序列生成器合成诊断促进样本，集成序列增强模块提升生成样本连贯性，提出噪声合成数据过滤器抑制不可靠样本。效果：在3个医学数据集上用11个网络经3种范式训练，证明该框架有效且通用，尤其在高危人群和域外条件下表现良好。
            arXiv:2409.17091v2 Announce Type: replace 
Abstract: In the medical field, the limited availability of large-scale datasets and labor-intensive annotation processes hinder the performance of deep models. Diffusion-based generative augmentation approaches present a promising solution to this issue, having been proven effective in advancing downstream medical recognition tasks. Nevertheless, existing works lack sufficient semantic and sequential steerability for challenging video/3D sequence generation, and neglect quality control of noisy synthesized samples, resulting in unreliable synthetic databases and severely limiting the performance of downstream tasks. In this work, we present Ctrl-GenAug, a novel and general generative augmentation framework that enables highly semantic- and sequential-customized sequence synthesis and suppresses incorrectly synthesized samples, to aid medical sequence classification. Specifically, we first design a multimodal conditions-guided sequence generator for controllably synthesizing diagnosis-promotive samples. A sequential augmentation module is integrated to enhance the temporal/stereoscopic coherence of generated samples. Then, we propose a noisy synthetic data filter to suppress unreliable cases at semantic and sequential levels. Extensive experiments on 3 medical datasets, using 11 networks trained on 3 paradigms, comprehensively analyze the effectiveness and generality of Ctrl-GenAug, particularly in underrepresented high-risk populations and out-domain conditions.
        ]]></description>
    </item>
    <item>
        <title>ResiDual Transformer Alignment with Spectral Decomposition</title>
        <link>https://arxiv.org/abs/2411.00246</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2411.00246v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Lorenzo Basile, Valentino Maiorca, Luca Bortolussi, Emanuele Rodol\`a, Francesco Locatello</dc:creator>
        <description><![CDATA[
            背景：Transformer网络残差流中存在特定任务或输入属性的专门化现象，影响视觉 - 语言模型模态对齐。方法：分析视觉Transformer残差的频谱几何，研究视觉头表示的低维结构，探讨文本与专门头的对齐对零样本分类性能的影响，并提出ResiDual技术实现残差流频谱对齐。效果：在70个预训练网络 - 数据集组合上验证，该方法能在不同数据分布上达到微调水平的性能，且具有高可解释性和参数效率。
            arXiv:2411.00246v2 Announce Type: replace 
Abstract: When examined through the lens of their residual streams, a puzzling property emerges in transformer networks: residual contributions (e.g., attention heads) sometimes specialize in specific tasks or input attributes. In this paper, we analyze this phenomenon in vision transformers, focusing on the spectral geometry of residuals, and explore its implications for modality alignment in vision-language models. First, we link it to the intrinsically low-dimensional structure of visual head representations, zooming into their principal components and showing that they encode specialized roles across a wide variety of input data distributions. Then, we analyze the effect of head specialization in multimodal models, focusing on how improved alignment between text and specialized heads impacts zero-shot classification performance. This specialization-performance link consistently holds across diverse pre-training data, network sizes, and objectives, demonstrating a powerful new mechanism for boosting zero-shot classification through targeted alignment. Ultimately, we translate these insights into actionable terms by introducing ResiDual, a technique for spectral alignment of the residual stream. Much like panning for gold, it lets the noise from irrelevant unit principal components (i.e., attributes) wash away to amplify task-relevant ones. Remarkably, this dual perspective on modality alignment yields fine-tuning level performance on different data distributions while modelling an extremely interpretable and parameter-efficient transformation, as we extensively show on 70 pre-trained network-dataset combinations (7 models, 10 datasets).
        ]]></description>
    </item>
    <item>
        <title>Expressivity of Representation Learning on Continuous-Time Dynamic Graphs: An Information-Flow Centric Review</title>
        <link>https://arxiv.org/abs/2412.03783</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2412.03783v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sofiane Ennadir, Gabriela Zarzar Gandler, Filip Cornell, Lele Cao, Oleg Smirnov, Tianze Wang, Levente Z\'olyomi, Bj\"orn Brinne, Sahar Asadi</dc:creator>
        <description><![CDATA[
            现实中许多场景涉及动态图，促使连续时间动态图（CTDG）模型的发展。该论文聚焦自监督表示学习，对CTDG的图表示学习进行全面综述。引入新理论框架，从信息流角度分析CTDG模型表达能力，量化其传播和编码时间与结构信息的能力，并据此对现有方法分类。还研究了针对CTDG的自监督学习方法设计。在合成和真实数据集上的实验验证了理论，展示了不同方法在不同类型图上的优劣，为CTDG模型选择和开发提供理论与实践指导。
            arXiv:2412.03783v2 Announce Type: replace 
Abstract: Graphs are ubiquitous in real-world applications, ranging from social networks to biological systems, and have inspired the development of Graph Neural Networks (GNNs) for learning expressive representations. While most research has centered on static graphs, many real-world scenarios involve dynamic, temporally evolving graphs, motivating the need for Continuous-Time Dynamic Graph (CTDG) models. This paper provides a comprehensive review of Graph Representation Learning (GRL) on CTDGs with a focus on Self-Supervised Representation Learning (SSRL). We introduce a novel theoretical framework that analyzes the expressivity of CTDG models through an Information-Flow (IF) lens, quantifying their ability to propagate and encode temporal and structural information. Leveraging this framework, we categorize existing CTDG methods based on their suitability for different graph types and application scenarios. Within the same scope, we examine the design of SSRL methods tailored to CTDGs, such as predictive and contrastive approaches, highlighting their potential to mitigate the reliance on labeled data. Empirical evaluations on synthetic and real-world datasets validate our theoretical insights, demonstrating the strengths and limitations of various methods across long-range, bi-partite and community-based graphs. This work offers both a theoretical foundation and practical guidance for selecting and developing CTDG models, advancing the understanding of GRL in dynamic settings.
        ]]></description>
    </item>
    <item>
        <title>Learning Free Token Reduction for Multi-Modal Large Language Models</title>
        <link>https://arxiv.org/abs/2501.17391</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2501.17391v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zihui Zhao, Yingxin Li, Yang Li</dc:creator>
        <description><![CDATA[
            背景：视觉语言模型在多模态任务中表现出色，但高计算成本和长推理时间限制其实际应用，现有视觉提示压缩方法未充分考虑视觉数据特性。方法：提出在空间和时间维度上的无学习标记压缩范式，有可即插即用的压缩管道，能无缝集成到多数多模态大语言模型框架。效果：在Video - QA任务实验中，该方法提升了模型推理能力，降低计算成本，在不牺牲性能前提下显著提高效率。
            arXiv:2501.17391v2 Announce Type: replace 
Abstract: Vision-Language Models (VLMs) have achieved remarkable success across a range of multimodal tasks; however, their practical deployment is often constrained by high computational costs and prolonged inference times. Since the vision modality typically carries more information than the text modality, compressing visual prompts offers a promising solution to alleviate these challenges. Existing approaches predominantly focus on refining model architectures or directly reducing the number of visual tokens. However, these methods often compromise inference performance due to a lack of consideration for the unique spatial and temporal characteristics of visual data. In this work, we propose a token compression paradigm that operates on both spatial and temporal dimensions. Our approach includes a learning-free, plug-and-play compression pipeline that can be seamlessly integrated into most Multimodal Large Language Model (MLLM) frameworks. By leveraging this method, we enhance the model inference capability while simultaneously reducing its computational cost. Experimental results on the Video-QA task demonstrate the effectiveness of the proposed approach, showcasing significant improvements in efficiency without sacrificing performance.
        ]]></description>
    </item>
    <item>
        <title>ReFoRCE: A Text-to-SQL Agent with Self-Refinement, Format Restriction, and Column Exploration</title>
        <link>https://arxiv.org/abs/2502.00675</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.00675v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Minghang Deng, Ashwin Ramachandran, Canwen Xu, Lanxiang Hu, Zhewei Yao, Anupam Datta, Hao Zhang</dc:creator>
        <description><![CDATA[
            背景：文本到SQL系统虽让自然语言查询结构化数据库更便捷，但在企业环境部署面临大而复杂的模式、多样SQL方言等挑战，在Spider 2.0数据集上现有最佳性能仅20%。方法：提出ReFoRCE，引入表压缩、格式限制和迭代列探索，还采用含投票机制的并行工作流和基于公共表表达式的细化方法的自细化管道。效果：在Spider 2.0 - Snow任务中得分31.26，在Spider 2.0 - Lite任务中得分30.35，达当前最优。
            arXiv:2502.00675v3 Announce Type: replace 
Abstract: Text-to-SQL systems have unlocked easier access to critical data insights by enabling natural language queries over structured databases. However, deploying such systems in enterprise environments remains challenging due to factors such as large, complex schemas (> 3000 columns), diverse SQL dialects (e.g., BigQuery, Snowflake) and sophisticated query requirements (e.g., transformation, analytics). Current state-of-the-art performance on the Spider 2.0 dataset -- a benchmark built to mimic such complex environments -- remains limited at 20%. Key limitations include inadequate instruction-following, poor long-context comprehension, weak self-refinement, and insufficient dialect-specific knowledge. To address these gaps, we propose ReFoRCE (Self-Refinement Agent with Format Restriction and Column Exploration) which introduces (1) table compression to mitigate long-context limitations (2) format restriction to ensure accurate answer format, and (3) iterative column exploration for enhanced schema understanding. Additionally, it employs self-refinement pipeline consisting of (1) parallelized workflows with voting mechanisms and (2) a Common Table Expression (CTE) based refinement approach to handle unresolved cases. ReFoRCE achieves state-of-the-art results scoring 31.26 on the Spider 2.0-Snow and scoring 30.35 on the Spider 2.0-Lite tasks. Our code is available at https://github.com/hao-ai-lab/ReFoRCE.
        ]]></description>
    </item>
    <item>
        <title>SAMGPT: Text-free Graph Foundation Model for Multi-domain Pre-training and Cross-domain Adaptation</title>
        <link>https://arxiv.org/abs/2502.05424</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.05424v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xingtong Yu, Zechuan Gong, Chang Zhou, Yuan Fang, Hui Zhang</dc:creator>
        <description><![CDATA[
            背景：图能建模在线服务中的互联实体，但不同领域的图特征差异大，现有研究在处理无文本图时多忽视结构差异。方法：提出SAMGPT框架，预训练阶段引入结构令牌协调源域结构聚合；跨域适配时设计整体和特定双提示，分别适配统一多域结构知识和细粒度特定领域信息。效果：在七个公开数据集上实验，评估了SAMGPT的有效性。 
            arXiv:2502.05424v2 Announce Type: replace 
Abstract: Graphs are able to model interconnected entities in many online services, supporting a wide range of applications on the Web. This raises an important question: How can we train a graph foundational model on multiple source domains and adapt to an unseen target domain? A major obstacle is that graphs from different domains often exhibit divergent characteristics. Some studies leverage large language models to align multiple domains based on textual descriptions associated with the graphs, limiting their applicability to text-attributed graphs. For text-free graphs, a few recent works attempt to align different feature distributions across domains, while generally neglecting structural differences. In this work, we propose a novel Structure Alignment framework for text-free Multi-domain Graph Pre-Training and cross-domain adaptation (SAMGPT). It is designed to learn multi-domain knowledge from graphs originating in multiple source domains, which can then be adapted to address applications in an unseen target domain. Specifically, we introduce a set of structure tokens to harmonize structure-based aggregation across source domains during the pre-training phase. Next, for cross-domain adaptation, we design dual prompts, namely, holistic prompts and specific prompts, which adapt unified multi-domain structural knowledge and fine-grained, domain-specific information, respectively, to a target domain. Finally, we conduct comprehensive experiments on seven public datasets to evaluate and analyze the effectiveness of SAMGPT.
        ]]></description>
    </item>
    <item>
        <title>Text-Promptable Propagation for Referring Medical Image Sequence Segmentation</title>
        <link>https://arxiv.org/abs/2502.11093</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.11093v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Runtian Yuan, Mohan Chen, Jilan Xu, Ling Zhou, Qingqiu Li, Yuejie Zhang, Rui Feng, Tao Zhang, Shang Gao</dc:creator>
        <description><![CDATA[
            背景：基于自然语言描述对医学图像序列中解剖结构进行分割的Ref - MISS任务有重要临床价值，但现有2D和3D分割模型难以跨序列追踪目标且缺乏文本驱动引导。方法：提出Text - Promptable Propagation（TPP）模型，通过跨模态交互识别目标，用基于Transformer的三重传播结合文本嵌入追踪目标，还构建了大规模基准Ref - MISS - Bench。效果：在该基准上，TPP在医学分割和指称视频目标分割中均优于现有方法。
            arXiv:2502.11093v2 Announce Type: replace 
Abstract: Referring Medical Image Sequence Segmentation (Ref-MISS) is a novel and challenging task that aims to segment anatomical structures in medical image sequences (\emph{e.g.} endoscopy, ultrasound, CT, and MRI) based on natural language descriptions. This task holds significant clinical potential and offers a user-friendly advancement in medical imaging interpretation. Existing 2D and 3D segmentation models struggle to explicitly track objects of interest across medical image sequences, and lack support for nteractive, text-driven guidance. To address these limitations, we propose Text-Promptable Propagation (TPP), a model designed for referring medical image sequence segmentation. TPP captures the intrinsic relationships among sequential images along with their associated textual descriptions. Specifically, it enables the recognition of referred objects through cross-modal referring interaction, and maintains continuous tracking across the sequence via Transformer-based triple propagation, using text embeddings as queries. To support this task, we curate a large-scale benchmark, Ref-MISS-Bench, which covers 4 imaging modalities and 20 different organs and lesions. Experimental results on this benchmark demonstrate that TPP consistently outperforms state-of-the-art methods in both medical segmentation and referring video object segmentation.
        ]]></description>
    </item>
    <item>
        <title>A-MEM: Agentic Memory for LLM Agents</title>
        <link>https://arxiv.org/abs/2502.12110</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.12110v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wujiang Xu, Zujie Liang, Kai Mei, Hang Gao, Juntao Tan, Yongfeng Zhang</dc:creator>
        <description><![CDATA[
            背景：大语言模型（LLM）智能体需记忆系统利用历史经验，但现有系统缺乏复杂记忆组织，操作和结构固定，适应性有限。方法：提出一种新的LLM智能体记忆系统，遵循Zettelkasten方法原则，通过动态索引和链接创建知识网络，添加新记忆时生成含多种结构化属性的笔记，分析历史记忆建立关联，实现记忆进化。效果：在六个基础模型上的实验显示，较现有SOTA基线有显著提升。
            arXiv:2502.12110v4 Announce Type: replace 
Abstract: While large language model (LLM) agents can effectively use external tools for complex real-world tasks, they require memory systems to leverage historical experiences. Current memory systems enable basic storage and retrieval but lack sophisticated memory organization, despite recent attempts to incorporate graph databases. Moreover, these systems' fixed operations and structures limit their adaptability across diverse tasks. To address this limitation, this paper proposes a novel agentic memory system for LLM agents that can dynamically organize memories in an agentic way. Following the basic principles of the Zettelkasten method, we designed our memory system to create interconnected knowledge networks through dynamic indexing and linking. When a new memory is added, we generate a comprehensive note containing multiple structured attributes, including contextual descriptions, keywords, and tags. The system then analyzes historical memories to identify relevant connections, establishing links where meaningful similarities exist. Additionally, this process enables memory evolution - as new memories are integrated, they can trigger updates to the contextual representations and attributes of existing historical memories, allowing the memory network to continuously refine its understanding. Our approach combines the structured organization principles of Zettelkasten with the flexibility of agent-driven decision making, allowing for more adaptive and context-aware memory management. Empirical experiments on six foundation models show superior improvement against existing SOTA baselines. The source code for evaluating performance is available at https://github.com/WujiangXu/AgenticMemory, while the source code of agentic memory system is available at https://github.com/agiresearch/A-mem.
        ]]></description>
    </item>
    <item>
        <title>Stepwise Informativeness Search for Efficient and Effective LLM Reasoning</title>
        <link>https://arxiv.org/abs/2502.15335</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.15335v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Siyuan Wang, Enda Zhao, Zhongyu Wei, Xiang Ren</dc:creator>
        <description><![CDATA[
            背景：大语言模型虽能通过生成自由文本理由提升多步推理能力，但在长上下文推理时易失焦，产生不可靠和冗余理由。方法：提出逐步信息搜索方法，包含两种选择启发式，即基于基础引导和新颖性引导的选择，同时采用自我基础策略让模型明确引用相关先前步骤。效果：在四个推理数据集上实验表明，该方法能生成高质量理由，减少错误和冗余，提高推理准确率。
            arXiv:2502.15335v2 Announce Type: replace 
Abstract: Advances in Large Language Models (LLMs) have significantly improved multi-step reasoning through generating free-text rationales. However, recent studies show that LLMs tend to lose focus over the middle of long contexts. This raises concerns that as reasoning progresses, LLMs may overlook information in earlier steps when decoding subsequent steps, leading to generate unreliable and redundant rationales. To address this, we propose guiding LLMs to generate more accurate and concise step-by-step rationales by (1) proactively referencing information from underutilized prior steps, and (2) minimizing redundant information between new and existing steps. We introduce stepwise informativeness search, an inference-time tree search framework incorporating two selection heuristics: grounding-guided selection which prioritizes steps paying higher attention over underutilized steps; and novelty-guided selection which encourages steps with novel conclusions. During rationale generation, we use a self-grounding strategy that prompts LLMs to explicitly reference relevant prior steps to provide premises before deduction at each step. Experimental results on four reasoning datasets demonstrate that our approach improves reasoning accuracy by generating higher-quality rationales with reduced errors and redundancy.
        ]]></description>
    </item>
    <item>
        <title>IGDA: Interactive Graph Discovery through Large Language Model Agents</title>
        <link>https://arxiv.org/abs/2502.17189</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.17189v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Alex Havrilla, David Alvarez-Melis, Nicolo Fusi</dc:creator>
        <description><![CDATA[
            背景：大语言模型在发现任务中展现强大能力，可利用语义元数据预测变量关系，还能作为黑箱优化器。方法：提出IGDA，这一基于大语言模型的流程包含边缘实验选择的不确定性驱动方法和利用实验二元反馈更新局部图的策略。效果：在八个真实世界图上的实验表明，该方法常优于所有基线方法，包括最先进的数值方法。在蛋白质转录因子因果图上也表现出色，证明是一种强大的图发现方法。 
            arXiv:2502.17189v2 Announce Type: replace 
Abstract: Large language models ($\textbf{LLMs}$) have emerged as a powerful method for discovery. Instead of utilizing numerical data, LLMs utilize associated variable $\textit{semantic metadata}$ to predict variable relationships. Simultaneously, LLMs demonstrate impressive abilities to act as black-box optimizers when given an objective $f$ and sequence of trials. We study LLMs at the intersection of these two capabilities by applying LLMs to the task of $\textit{interactive graph discovery}$: given a ground truth graph $G^*$ capturing variable relationships and a budget of $I$ edge experiments over $R$ rounds, minimize the distance between the predicted graph $\hat{G}_R$ and $G^*$ at the end of the $R$-th round. To solve this task we propose $\textbf{IGDA}$, a LLM-based pipeline incorporating two key components: 1) an LLM uncertainty-driven method for edge experiment selection 2) a local graph update strategy utilizing binary feedback from experiments to improve predictions for unselected neighboring edges. Experiments on eight different real-world graphs show our approach often outperforms all baselines including a state-of-the-art numerical method for interactive graph discovery. Further, we conduct a rigorous series of ablations dissecting the impact of each pipeline component. Finally, to assess the impact of memorization, we apply our interactive graph discovery strategy to a complex, new (as of July 2024) causal graph on protein transcription factors, finding strong performance in a setting where memorization is impossible. Overall, our results show IGDA to be a powerful method for graph discovery complementary to existing numerically driven approaches.
        ]]></description>
    </item>
    <item>
        <title>Generative Modeling of Class Probability for Multi-Modal Representation Learning</title>
        <link>https://arxiv.org/abs/2503.17417</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.17417v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jungkyoo Shin, Bumsoo Kim, Eunwoo Kim</dc:creator>
        <description><![CDATA[
            背景：多模态理解在人工智能中至关重要，但传统方法如对比学习常面临模态差异问题，易导致对齐错误。方法：提出类锚点对齐方法CALM，将类锚点编码为提示，为各模态生成并对齐类概率分布；引入跨模态概率变分自编码器，对对齐中的不确定性建模。效果：在四个基准数据集上的实验表明，该方法显著优于现有方法，尤其在域外评估中表现出色，展现出多模态表征学习中更强的泛化能力。
            arXiv:2503.17417v2 Announce Type: replace 
Abstract: Multi-modal understanding plays a crucial role in artificial intelligence by enabling models to jointly interpret inputs from different modalities. However, conventional approaches such as contrastive learning often struggle with modality discrepancies, leading to potential misalignments. In this paper, we propose a novel class anchor alignment approach that leverages class probability distributions for multi-modal representation learning. Our method, Class-anchor-ALigned generative Modeling (CALM), encodes class anchors as prompts to generate and align class probability distributions for each modality, enabling more effective alignment. Furthermore, we introduce a cross-modal probabilistic variational autoencoder to model uncertainty in the alignment, enhancing the ability to capture deeper relationships between modalities and data variations. Extensive experiments on four benchmark datasets demonstrate that our approach significantly outperforms state-of-the-art methods, especially in out-of-domain evaluations. This highlights its superior generalization capabilities in multi-modal representation learning.
        ]]></description>
    </item>
    <item>
        <title>Graph ODEs and Beyond: A Comprehensive Survey on Integrating Differential Equations with Graph Neural Networks</title>
        <link>https://arxiv.org/abs/2503.23167</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.23167v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zewen Liu, Xiaoda Wang, Bohan Wang, Zijie Huang, Carl Yang, Wei Jin</dc:creator>
        <description><![CDATA[
            背景：图神经网络（GNNs）和微分方程（DEs）是近年来发展迅速且结合良好的研究领域，GNNs用于图结构数据学习，DEs用于建模时空连续动态。方法：该综述对GNNs与DEs交叉领域的研究进行全面概述，对现有方法分类，探讨其原理，强调在多领域的应用。效果：指出该交叉领域的开放挑战和未来研究方向，还提供了论文列表，为相关研究者和从业者提供资源。 
            arXiv:2503.23167v2 Announce Type: replace 
Abstract: Graph Neural Networks (GNNs) and differential equations (DEs) are two rapidly advancing areas of research that have shown remarkable synergy in recent years. GNNs have emerged as powerful tools for learning on graph-structured data, while differential equations provide a principled framework for modeling continuous dynamics across time and space. The intersection of these fields has led to innovative approaches that leverage the strengths of both, enabling applications in physics-informed learning, spatiotemporal modeling, and scientific computing. This survey aims to provide a comprehensive overview of the burgeoning research at the intersection of GNNs and DEs. We will categorize existing methods, discuss their underlying principles, and highlight their applications across domains such as molecular modeling, traffic prediction, and epidemic spreading. Furthermore, we identify open challenges and outline future research directions to advance this interdisciplinary field. A comprehensive paper list is provided at https://github.com/Emory-Melody/Awesome-Graph-NDEs. This survey serves as a resource for researchers and practitioners seeking to understand and contribute to the fusion of GNNs and DEs
        ]]></description>
    </item>
    <item>
        <title>Dual Boost-Driven Graph-Level Clustering Network</title>
        <link>https://arxiv.org/abs/2504.05670</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.05670v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>John Smith, Wenxuan Tu, Junlong Wu, Wenxin Zhang, Jingxin Liu, Haotian Wang, Jieren Cheng, Huajie Lei, Guangzhen Yao, Lingren Wang, Mengfei Li, Renda Han, Yu Li</dc:creator>
        <description><![CDATA[
            图级聚类是图学习中的关键难题，现有深度学习与表示学习结合的方法存在原始图结构有噪声、特征传播和池化时噪声聚合到图级嵌入等问题，影响聚类性能。为此提出双增强驱动的图级聚类网络（DBGCN），在池化步骤评估全局特征贡献并优化，还通过评估图级表示相似度识别并抑制有害信息。大量实验表明，DBGCN在六个基准数据集上优于现有图级聚类方法。
            arXiv:2504.05670v2 Announce Type: replace 
Abstract: Graph-level clustering remains a pivotal yet formidable challenge in graph learning. Recently, the integration of deep learning with representation learning has demonstrated notable advancements, yielding performance enhancements to a certain degree. However, existing methods suffer from at least one of the following issues: 1. the original graph structure has noise, and 2. during feature propagation and pooling processes, noise is gradually aggregated into the graph-level embeddings through information propagation. Consequently, these two limitations mask clustering-friendly information, leading to suboptimal graph-level clustering performance. To this end, we propose a novel Dual Boost-Driven Graph-Level Clustering Network (DBGCN) to alternately promote graph-level clustering and filtering out interference information in a unified framework. Specifically, in the pooling step, we evaluate the contribution of features at the global and optimize them using a learnable transformation matrix to obtain high-quality graph-level representation, such that the model's reasoning capability can be improved. Moreover, to enable reliable graph-level clustering, we first identify and suppress information detrimental to clustering by evaluating similarities between graph-level representations, providing more accurate guidance for multi-view fusion. Extensive experiments demonstrated that DBGCN outperforms the state-of-the-art graph-level clustering methods on six benchmark datasets.
        ]]></description>
    </item>
    <item>
        <title>Embedding Ontologies via Incorporating Extensional and Intensional Knowledge</title>
        <link>https://arxiv.org/abs/2402.01677</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2402.01677v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Keyu Wang, Guilin Qi, Jiaoyan Chen, Yi Huang, Tianxing Wu</dc:creator>
        <description><![CDATA[
            背景：本体包含丰富知识，分为外延和内涵知识，但现有本体嵌入方法未能同时兼顾二者。方法：提出名为EIKE的本体嵌入方法，在两个空间（外延和内涵空间）表示本体，用基于几何的方法建模外延知识，用预训练语言模型建模内涵知识，统一嵌入实例、概念及其关系。效果：在三个数据集的三元组分类和链接预测任务中，EIKE显著优于现有方法，能提供更全面且有代表性的领域视角。
            arXiv:2402.01677v4 Announce Type: replace-cross 
Abstract: Ontologies contain rich knowledge within domain, which can be divided into two categories, namely extensional knowledge and intensional knowledge. Extensional knowledge provides information about the concrete instances that belong to specific concepts in the ontology, while intensional knowledge details inherent properties, characteristics, and semantic associations among concepts. However, existing ontology embedding approaches fail to take both extensional knowledge and intensional knowledge into fine consideration simultaneously. In this paper, we propose a novel ontology embedding approach named EIKE (Extensional and Intensional Knowledge Embedding) by representing ontologies in two spaces, called extensional space and intensional space. EIKE presents a unified framework for embedding instances, concepts and their relations in an ontology, applying a geometry-based method to model extensional knowledge and a pretrained language model to model intensional knowledge, which can capture both structure information and textual information. Experimental results show that EIKE significantly outperforms state-of-the-art methods in three datasets for both triple classification and link prediction, indicating that EIKE provides a more comprehensive and representative perspective of the domain.
        ]]></description>
    </item>
    <item>
        <title>TurtleBench: A Visual Programming Benchmark in Turtle Geometry</title>
        <link>https://arxiv.org/abs/2411.00264</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2411.00264v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sina Rismanchian, Yasaman Razeghi, Sameer Singh, Shayan Doroudi</dc:creator>
        <description><![CDATA[
            背景：人类从小就具备对图像和场景中几何图案的推理能力，但开发具备类似能力的多模态大模型仍是挑战，缺乏有效评估方法。方法：提出TurtleBench基准，受用于教儿童编程和几何概念的海龟几何启发，包含有算法逻辑的图案形状任务，评估模型结合视觉示例、文本指令生成代码的能力。效果：领先的多模态大模型完成任务能力差，GPT - 4o在最简单任务上准确率仅19%，少样本提示提升不足2%。
            arXiv:2411.00264v2 Announce Type: replace-cross 
Abstract: Humans have the ability to reason about geometric patterns in images and scenes from a young age. However, developing large multimodal models (LMMs) capable of similar reasoning remains a challenge, highlighting the need for robust evaluation methods to assess these capabilities. We introduce \Turtle, a benchmark designed to evaluate LMMs' capacity to interpret geometric patterns -- given visual examples, textual instructions, or both -- and generate precise code outputs. Inspired by turtle geometry, a notion used to teach children foundational coding and geometric concepts, TurtleBench features tasks with patterned shapes that have underlying algorithmic logic. Our evaluation reveals that leading LMMs struggle significantly with these tasks, with GPT-4o achieving only 19\% accuracy on the simplest tasks and few-shot prompting only marginally improves their performance ($<2\%$). \Turtle highlights the gap between human and AI performance in intuitive and visual geometrical understanding, setting the stage for future research in this area. \Turtle stands as one of the few benchmarks to evaluate the integration of visual understanding and code generation capabilities in LMMs, setting the stage for future research. Code and Dataset for this paper is provided here: \href{https://github.com/sinaris76/TurtleBench}{https://github.com/sinaris76/TurtleBench}
        ]]></description>
    </item>
    <item>
        <title>Table Integration in Data Lakes Unleashed: Pairwise Integrability Judgment, Integrable Set Discovery, and Multi-Tuple Conflict Resolution</title>
        <link>https://arxiv.org/abs/2412.00324</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2412.00324v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Daomin Ji, Hui Luo, Zhifeng Bao, Shane Culpepper</dc:creator>
        <description><![CDATA[
            背景：表集成旨在整合相关信息元组形成综合表，本文聚焦数据湖中多表集成的三个核心任务。方法：训练二元分类器进行成对可集成性判断，提出自监督对抗对比学习算法解决标注数据稀缺问题；利用社区检测算法进行可集成集发现；引入上下文学习方法，借助大语言模型知识解决多元组冲突。效果：该方法减少了对标注数据的需求，适用于标注数据集稀缺的场景。
            arXiv:2412.00324v2 Announce Type: replace-cross 
Abstract: Table integration aims to create a comprehensive table by consolidating tuples containing relevant information. In this work, we investigate the challenge of integrating multiple tables from a data lake, focusing on three core tasks: 1) pairwise integrability judgment, which determines whether a tuple pair is integrable, accounting for any occurrences of semantic equivalence or typographical errors; 2) integrable set discovery, which identifies all integrable sets in a table based on pairwise integrability judgments established in the first task; 3) multi-tuple conflict resolution, which resolves conflicts between multiple tuples during integration. To this end, we train a binary classifier to address the task of pairwise integrability judgment. Given the scarcity of labeled data in data lakes, we propose a self-supervised adversarial contrastive learning algorithm to perform classification, which incorporates data augmentation methods and adversarial examples to autonomously generate new training data. Upon the output of pairwise integrability judgment, each integrable set can be considered as a community, a densely connected sub-graph where nodes and edges correspond to tuples in the table and their pairwise integrability respectively, we proceed to investigate various community detection algorithms to address the integrable set discovery objective. Moving forward to tackle multi-tuple conflict resolution, we introduce an innovative in-context learning methodology. This approach capitalizes on the knowledge embedded within large language models (LLMs) to effectively resolve conflicts that arise when integrating multiple tuples. Notably, our method minimizes the need for annotated data, making it particularly suited for scenarios where labeled datasets are scarce.
        ]]></description>
    </item>
    <item>
        <title>Task Memory Engine (TME): A Structured Memory Framework with Graph-Aware Extensions for Multi-Step LLM Agent Tasks</title>
        <link>https://arxiv.org/abs/2504.08525</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.08525v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ye Ye</dc:creator>
        <description><![CDATA[
            背景：大语言模型用于多步任务时，现有框架难对任务状态进行结构化理解，导致性能不稳定、易产生幻觉和长距离连贯性差等问题。方法：提出任务记忆引擎（TME），用分层任务记忆树（TMT）跟踪任务执行，每个节点存储任务步骤相关信息；引入基于活动节点路径动态生成提示的方法。效果：通过多步代理任务案例研究和对比实验，TME提升了任务完成准确率，行为更具可解释性，且实现开销小。
            arXiv:2504.08525v2 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) are increasingly used as autonomous agents for multi-step tasks. However, most existing frameworks fail to maintain a structured understanding of the task state, often relying on linear prompt concatenation or shallow memory buffers. This leads to brittle performance, frequent hallucinations, and poor long-range coherence. In this work, we propose the Task Memory Engine (TME), a lightweight and structured memory module that tracks task execution using a hierarchical Task Memory Tree (TMT). Each node in the tree corresponds to a task step, storing relevant input, output, status, and sub-task relationships. We introduce a prompt synthesis method that dynamically generates LLM prompts based on the active node path, significantly improving execution consistency and contextual grounding. Through case studies and comparative experiments on multi-step agent tasks, we demonstrate that TME leads to better task completion accuracy and more interpretable behavior with minimal implementation overhead. A reference implementation of the core TME components is available at https://github.com/biubiutomato/TME-Agent, including basic examples and structured memory integration. While the current implementation uses a tree-based structure, TME is designed to be graph-aware, supporting reusable substeps, converging task paths, and shared dependencies. This lays the groundwork for future DAG-based memory architectures.
        ]]></description>
    </item>
    <item>
        <title>Spatial Audio Processing with Large Language Model on Wearable Devices</title>
        <link>https://arxiv.org/abs/2504.08907</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.08907v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ayushi Mishra, Yang Bai, Priyadarshan Narayanasamy, Nakul Garg, Nirupam Roy</dc:creator>
        <description><![CDATA[
            将空间上下文融入大语言模型（LLM）有望革新人机交互。本文提出将空间语音理解融入LLM的系统架构，利用单声道麦克风基于微观结构的空间传感提取精确到达方向（DoA）信息，合成数据集OmniTalk。将空间信息与Whisper模型的语言嵌入融合，与LLaMA - 3.2 3B模型输入空间对齐并微调。该系统支持空间感知自动语音识别，平均误差25.72°，优于现有工作的88.52°，字错率5.3；支持声景分析，最多处理5人，DoA中值误差16°，性能优越。
            arXiv:2504.08907v1 Announce Type: new 
Abstract: Integrating spatial context into large language models (LLMs) has the potential to revolutionize human-computer interaction, particularly in wearable devices. In this work, we present a novel system architecture that incorporates spatial speech understanding into LLMs, enabling contextually aware and adaptive applications for wearable technologies. Our approach leverages microstructure-based spatial sensing to extract precise Direction of Arrival (DoA) information using a monaural microphone. To address the lack of existing dataset for microstructure-assisted speech recordings, we synthetically create a dataset called OmniTalk by using the LibriSpeech dataset. This spatial information is fused with linguistic embeddings from OpenAI's Whisper model, allowing each modality to learn complementary contextual representations. The fused embeddings are aligned with the input space of LLaMA-3.2 3B model and fine-tuned with lightweight adaptation technique LoRA to optimize for on-device processing. SING supports spatially-aware automatic speech recognition (ASR), achieving a mean error of $25.72^\circ$-a substantial improvement compared to the 88.52$^\circ$ median error in existing work-with a word error rate (WER) of 5.3. SING also supports soundscaping, for example, inference how many people were talking and their directions, with up to 5 people and a median DoA error of 16$^\circ$. Our system demonstrates superior performance in spatial speech understanding while addressing the challenges of power efficiency, privacy, and hardware constraints, paving the way for advanced applications in augmented reality, accessibility, and immersive experiences.
        ]]></description>
    </item>
    <item>
        <title>SIFT-50M: A Large-Scale Multilingual Dataset for Speech Instruction Fine-Tuning</title>
        <link>https://arxiv.org/abs/2504.09081</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09081v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Prabhat Pandey, Rupak Vignesh Swaminathan, K V Vijay Girish, Arunasish Sen, Jian Xie, Grant P. Strimel, Andreas Schwarz</dc:creator>
        <description><![CDATA[
            背景：缺乏大规模用于语音指令微调的数据集。方法：提出SIFT-50M数据集，基于公开语音语料构建，含14K小时语音，利用大语言模型和现成专家模型，覆盖五种语言及多样语音理解与可控语音生成指令；用其训练SIFT-LLM，并推出评估基准EvalSIFT。效果：SIFT-LLM在指令遵循基准上超越现有语音文本大语言模型，在基础语音任务上表现有竞争力。
            arXiv:2504.09081v1 Announce Type: new 
Abstract: We introduce SIFT (Speech Instruction Fine-Tuning), a 50M-example dataset designed for instruction fine-tuning and pre-training of speech-text large language models (LLMs). SIFT-50M is built from publicly available speech corpora, which collectively contain 14K hours of speech, and leverages LLMs along with off-the-shelf expert models. The dataset spans five languages, encompassing a diverse range of speech understanding as well as controllable speech generation instructions. Using SIFT-50M, we train SIFT-LLM, which outperforms existing speech-text LLMs on instruction-following benchmarks while achieving competitive performance on foundational speech tasks. To support further research, we also introduce EvalSIFT, a benchmark dataset specifically designed to evaluate the instruction-following capabilities of speech-text LLMs.
        ]]></description>
    </item>
    <item>
        <title>Generation of Musical Timbres using a Text-Guided Diffusion Model</title>
        <link>https://arxiv.org/abs/2504.09219</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09219v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Weixuan Yuan, Qadeer Khan, Vladimir Golkov</dc:creator>
        <description><![CDATA[
            背景：近年文本到音频系统虽取得成功，但在音乐创作中对人类创造力和表达的支持有限。方法：提出结合潜在扩散模型和多模态对比学习的系统，通过文本提示指定音频音色特征，联合生成频谱图的幅度和相位，无需后续运行相位检索算法。效果：能让创作者为音乐创作生成单个音符音频这一基础单元，用户可根据文本描述生成所需的音乐音色。
            arXiv:2504.09219v1 Announce Type: new 
Abstract: In recent years, text-to-audio systems have achieved remarkable success, enabling the generation of complete audio segments directly from text descriptions. While these systems also facilitate music creation, the element of human creativity and deliberate expression is often limited. In contrast, the present work allows composers, arrangers, and performers to create the basic building blocks for music creation: audio of individual musical notes for use in electronic instruments and DAWs. Through text prompts, the user can specify the timbre characteristics of the audio. We introduce a system that combines a latent diffusion model and multi-modal contrastive learning to generate musical timbres conditioned on text descriptions. By jointly generating the magnitude and phase of the spectrogram, our method eliminates the need for subsequently running a phase retrieval algorithm, as related methods do.
  Audio examples, source code, and a web app are available at https://wxuanyuan.github.io/Musical-Note-Generation/
        ]]></description>
    </item>
    <item>
        <title>DiTSE: High-Fidelity Generative Speech Enhancement via Latent Diffusion Transformers</title>
        <link>https://arxiv.org/abs/2504.09381</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09381v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Heitor R. Guimar\~aes, Jiaqi Su, Rithesh Kumar, Tiago H. Falk, Zeyu Jin</dc:creator>
        <description><![CDATA[
            现实中语音录音常受背景噪声和混响干扰，语音增强旨在生成干净高保真信号解决这些问题。现有生成式方法存在内容幻觉和一致性不足问题。本文提出DiTSE，采用潜在扩散Transformer模型和鲁棒调节特征，在全带宽处理语音质量问题，计算效率高。主客观实验表明，DiTSE达到了与DAPS数据集里真实录音室音质相匹配的先进水平，还显著提升了说话人身份和内容保真度，减少了跨数据集的幻觉。
            arXiv:2504.09381v1 Announce Type: new 
Abstract: Real-world speech recordings suffer from degradations such as background noise and reverberation. Speech enhancement aims to mitigate these issues by generating clean high-fidelity signals. While recent generative approaches for speech enhancement have shown promising results, they still face two major challenges: (1) content hallucination, where plausible phonemes generated differ from the original utterance; and (2) inconsistency, failing to preserve speaker's identity and paralinguistic features from the input speech. In this work, we introduce DiTSE (Diffusion Transformer for Speech Enhancement), which addresses quality issues of degraded speech in full bandwidth. Our approach employs a latent diffusion transformer model together with robust conditioning features, effectively addressing these challenges while remaining computationally efficient. Experimental results from both subjective and objective evaluations demonstrate that DiTSE achieves state-of-the-art audio quality that, for the first time, matches real studio-quality audio from the DAPS dataset. Furthermore, DiTSE significantly improves the preservation of speaker identity and content fidelity, reducing hallucinations across datasets compared to state-of-the-art enhancers. Audio samples are available at: http://hguimaraes.me/DiTSE
        ]]></description>
    </item>
    <item>
        <title>FSSUAVL: A Discriminative Framework using Vision Models for Federated Self-Supervised Audio and Image Understanding</title>
        <link>https://arxiv.org/abs/2504.09516</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09516v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yasar Abbas Ur Rehman, Kin Wai Lau, Yuyang Xie, Ma Lan, JiaJun Shen</dc:creator>
        <description><![CDATA[
            背景：现有研究虽表明视觉模型能学习配对的多模态音频 - 图像表征，但让深度模型从非配对模态学习表征仍是挑战，尤其在联邦学习场景。方法：提出FSSUAVL，这是一个在联邦学习中用自监督对比学习预训练的深度模型，不进行模态对齐，而是通过对比学习将音频和图像投影到公共嵌入空间进行联合判别。效果：实验显示，相比各模态用单独模型，FSSUAVL显著提升了多种基于图像和音频的下游任务性能，还可整合辅助信息提高识别准确率。
            arXiv:2504.09516v1 Announce Type: new 
Abstract: Recent studies have demonstrated that vision models can effectively learn multimodal audio-image representations when paired. However, the challenge of enabling deep models to learn representations from unpaired modalities remains unresolved. This issue is especially pertinent in scenarios like Federated Learning (FL), where data is often decentralized, heterogeneous, and lacks a reliable guarantee of paired data. Previous attempts tackled this issue through the use of auxiliary pretrained encoders or generative models on local clients, which invariably raise computational cost with increasing number modalities. Unlike these approaches, in this paper, we aim to address the task of unpaired audio and image recognition using \texttt{FSSUAVL}, a single deep model pretrained in FL with self-supervised contrastive learning (SSL). Instead of aligning the audio and image modalities, \texttt{FSSUAVL} jointly discriminates them by projecting them into a common embedding space using contrastive SSL. This extends the utility of \texttt{FSSUAVL} to paired and unpaired audio and image recognition tasks. Our experiments with CNN and ViT demonstrate that \texttt{FSSUAVL} significantly improves performance across various image- and audio-based downstream tasks compared to using separate deep models for each modality. Additionally, \texttt{FSSUAVL}'s capacity to learn multimodal feature representations allows for integrating auxiliary information, if available, to enhance recognition accuracy.
        ]]></description>
    </item>
    <item>
        <title>Separate to Collaborate: Dual-Stream Diffusion Model for Coordinated Piano Hand Motion Synthesis</title>
        <link>https://arxiv.org/abs/2504.09885</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09885v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zihao Liu, Mingwen Ou, Zunnan Xu, Jiaqi Huang, Haonan Han, Ronghui Li, Xiu Li</dc:creator>
        <description><![CDATA[
            自动合成协调的双手钢琴演奏面临挑战，需兼顾双手独立性与协调性。本文提出双流神经框架，从音频输入生成同步钢琴演奏手势。创新点有：一是基于解耦扩散的生成框架，通过双噪声初始化独立建模双手动作；二是引入双手协调非对称注意力机制，抑制对称噪声、突出非对称特征并增强双手协调性。系统先从音频特征预测三维手部位置，再通过位置感知扩散模型生成关节角度。综合评估显示，该框架在多个指标上优于现有最优方法。
            arXiv:2504.09885v1 Announce Type: new 
Abstract: Automating the synthesis of coordinated bimanual piano performances poses significant challenges, particularly in capturing the intricate choreography between the hands while preserving their distinct kinematic signatures. In this paper, we propose a dual-stream neural framework designed to generate synchronized hand gestures for piano playing from audio input, addressing the critical challenge of modeling both hand independence and coordination. Our framework introduces two key innovations: (i) a decoupled diffusion-based generation framework that independently models each hand's motion via dual-noise initialization, sampling distinct latent noise for each while leveraging a shared positional condition, and (ii) a Hand-Coordinated Asymmetric Attention (HCAA) mechanism suppresses symmetric (common-mode) noise to highlight asymmetric hand-specific features, while adaptively enhancing inter-hand coordination during denoising. The system operates hierarchically: it first predicts 3D hand positions from audio features and then generates joint angles through position-aware diffusion models, where parallel denoising streams interact via HCAA. Comprehensive evaluations demonstrate that our framework outperforms existing state-of-the-art methods across multiple metrics.
        ]]></description>
    </item>
    <item>
        <title>AutoStyle-TTS: Retrieval-Augmented Generation based Automatic Style Matching Text-to-Speech Synthesis</title>
        <link>https://arxiv.org/abs/2504.10309</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.10309v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Dan Luo, Chengyuan Ma, Weiqin Li, Jun Wang, Wei Chen, Zhiyong Wu</dc:creator>
        <description><![CDATA[
            背景：随着语音合成技术发展，用户对合成语音自然度和表现力期望提高，以往研究忽视提示选择重要性。方法：提出基于检索增强生成（RAG）技术的文本到语音（TTS）框架，构建含多种语境高质量语音样本的语音风格知识库，开发风格匹配方案，用Llama等提取的嵌入与知识库样本匹配，选最合适风格合成。效果：实证研究验证了方法有效性，可查看演示：https://thuhcsi.github.io/icme2025-AutoStyle-TTS 。
            arXiv:2504.10309v1 Announce Type: new 
Abstract: With the advancement of speech synthesis technology, users have higher expectations for the naturalness and expressiveness of synthesized speech. But previous research ignores the importance of prompt selection. This study proposes a text-to-speech (TTS) framework based on Retrieval-Augmented Generation (RAG) technology, which can dynamically adjust the speech style according to the text content to achieve more natural and vivid communication effects. We have constructed a speech style knowledge database containing high-quality speech samples in various contexts and developed a style matching scheme. This scheme uses embeddings, extracted by Llama, PER-LLM-Embedder,and Moka, to match with samples in the knowledge database, selecting the most appropriate speech style for synthesis. Furthermore, our empirical research validates the effectiveness of the proposed method. Our demo can be viewed at: https://thuhcsi.github.io/icme2025-AutoStyle-TTS
        ]]></description>
    </item>
    <item>
        <title>ALMTokenizer: A Low-bitrate and Semantic-rich Audio Codec Tokenizer for Audio Language Modeling</title>
        <link>https://arxiv.org/abs/2504.10344</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.10344v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Dongchao Yang, Songxiang Liu, Haohan Guo, Jiankun Zhao, Yuanyuan Wang, Helin Wang, Zeqian Ju, Xubo Liu, Xueyuan Chen, Xu Tan, Xixin Wu, Helen Meng</dc:creator>
        <description><![CDATA[
            背景：音频语言模型发展中，音频tokenization至关重要。现有方法如Encodec编码时不考虑帧间上下文信息。方法：提出ALMTokenizer，采用基于查询的压缩策略，通过可学习的查询token捕获帧间上下文信息；引入MAE损失、基于语义先验的向量量化和AR预测损失增强语义信息。效果：在低比特率下实现了与现有方法相当的重建性能，在同一音频语言模型框架中，在音频理解和生成任务上优于以往tokenizer。
            arXiv:2504.10344v1 Announce Type: new 
Abstract: Recent advancements in audio language models have underscored the pivotal role of audio tokenization, which converts audio signals into discrete tokens, thereby facilitating the application of language model architectures to the audio domain. In this study, we introduce ALMTokenizer, a novel low-bitrate and semantically rich audio codec tokenizer for audio language models. Prior methods, such as Encodec, typically encode individual audio frames into discrete tokens without considering the use of context information across frames. Unlike these methods, we introduce a novel query-based compression strategy to capture holistic information with a set of learnable query tokens by explicitly modeling the context information across frames. This design not only enables the codec model to capture more semantic information but also encodes the audio signal with fewer token sequences. Additionally, to enhance the semantic information in audio codec models, we introduce the following: (1) A masked autoencoder (MAE) loss, (2) Vector quantization based on semantic priors, and (3) An autoregressive (AR) prediction loss. As a result, ALMTokenizer achieves competitive reconstruction performance relative to state-of-the-art approaches while operating at a lower bitrate. Within the same audio language model framework, ALMTokenizer outperforms previous tokenizers in audio understanding and generation tasks.
        ]]></description>
    </item>
    <item>
        <title>Pseudo-Autoregressive Neural Codec Language Models for Efficient Zero-Shot Text-to-Speech Synthesis</title>
        <link>https://arxiv.org/abs/2504.10352</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.10352v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yifan Yang, Shujie Liu, Jinyu Li, Yuxuan Hu, Haibin Wu, Hui Wang, Jianwei Yu, Lingwei Meng, Haiyang Sun, Yanqing Liu, Yan Lu, Kai Yu, Xie Chen</dc:creator>
        <description><![CDATA[
            背景：现有零样本文本转语音（TTS）系统中，自回归（AR）模型生成慢且缺乏时长可控性，非自回归（NAR）模型缺乏时序建模且设计复杂。方法：提出伪自回归（PAR）编解码语言建模方法统一AR和NAR，在此基础上构建两阶段TTS系统PALLE，先由PAR生成初始语音，再用NAR细化。效果：在LibriSpeech测试集上，PALLE语音质量、说话人相似度和可懂度超现有系统，推理速度快达10倍。
            arXiv:2504.10352v1 Announce Type: new 
Abstract: Recent zero-shot text-to-speech (TTS) systems face a common dilemma: autoregressive (AR) models suffer from slow generation and lack duration controllability, while non-autoregressive (NAR) models lack temporal modeling and typically require complex designs. In this paper, we introduce a novel pseudo-autoregressive (PAR) codec language modeling approach that unifies AR and NAR modeling. Combining explicit temporal modeling from AR with parallel generation from NAR, PAR generates dynamic-length spans at fixed time steps. Building on PAR, we propose PALLE, a two-stage TTS system that leverages PAR for initial generation followed by NAR refinement. In the first stage, PAR progressively generates speech tokens along the time dimension, with each step predicting all positions in parallel but only retaining the left-most span. In the second stage, low-confidence tokens are iteratively refined in parallel, leveraging the global contextual information. Experiments demonstrate that PALLE, trained on LibriTTS, outperforms state-of-the-art systems trained on large-scale data, including F5-TTS, E2-TTS, and MaskGCT, on the LibriSpeech test-clean set in terms of speech quality, speaker similarity, and intelligibility, while achieving up to ten times faster inference speed. Audio samples are available at https://anonymous-palle.github.io.
        ]]></description>
    </item>
    <item>
        <title>DASS: Distilled Audio State Space Models Are Stronger and More Duration-Scalable Learners</title>
        <link>https://arxiv.org/abs/2407.04082</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2407.04082v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Saurabhchand Bhati, Yuan Gong, Leonid Karlinsky, Hilde Kuehne, Rogerio Feris, James Glass</dc:creator>
        <description><![CDATA[
            背景：状态空间模型（SSMs）用于音频建模有计算效率高的优势，但在10秒短音频标注任务中表现不如基于Transformer的模型，且长音频性能未充分评估。方法：本文在音频空间模型训练中应用知识蒸馏，得到知识蒸馏音频SSM（DASS），还设计了新测试Audio NIAH。效果：DASS在AudioSet上表现超越Transformers，mAP达48.9；仅用10秒音频片段训练的DASS能检索长达2.5小时录音中的声音事件，而AST输入50秒就失败，证明SSMs更具时长扩展性。
            arXiv:2407.04082v2 Announce Type: replace 
Abstract: State-space models (SSMs) have emerged as an alternative to Transformers for audio modeling due to their high computational efficiency with long inputs. While recent efforts on Audio SSMs have reported encouraging results, two main limitations remain: First, in 10-second short audio tagging tasks, Audio SSMs still underperform compared to Transformer-based models such as Audio Spectrogram Transformer (AST). Second, although Audio SSMs theoretically support long audio inputs, their actual performance with long audio has not been thoroughly evaluated. To address these limitations, in this paper, 1) We applied knowledge distillation in audio space model training, resulting in a model called Knowledge Distilled Audio SSM (DASS). To the best of our knowledge, it is the first SSM that outperforms the Transformers on AudioSet and achieves an mAP of 48.9; and 2) We designed a new test called Audio Needle In A Haystack (Audio NIAH). We find that DASS, trained with only 10-second audio clips, can retrieve sound events in audio recordings up to 2.5 hours long, while the AST model fails when the input is just 50 seconds, demonstrating SSMs are indeed more duration scalable. Code: https://github.com/Saurabhbhati/DASS, https://huggingface.co/saurabhati/DASS_small_AudioSet_48.9
        ]]></description>
    </item>
    <item>
        <title>FLAMO: An Open-Source Library for Frequency-Domain Differentiable Audio Processing</title>
        <link>https://arxiv.org/abs/2409.08723</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2409.08723v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Gloria Dal Santo, Gian Marco De Bortoli, Karolina Prawda, Sebastian J. Schlecht, Vesa V\"alim\"aki</dc:creator>
        <description><![CDATA[
            背景：为实现和优化可微线性时不变音频系统。方法：提出开源的频率采样音频模块优化库FLAMO，基于频率采样滤波器设计方法，可创建独立或用于神经网络计算图的可微模块，还包含预定义滤波模块及辅助类，通过直观界面访问。效果：通过人工混响器和有源声学系统优化两个案例，展示了模块在改善响应色彩方面的实际应用。
            arXiv:2409.08723v2 Announce Type: replace 
Abstract: We present FLAMO, a Frequency-sampling Library for Audio-Module Optimization designed to implement and optimize differentiable linear time-invariant audio systems. The library is open-source and built on the frequency-sampling filter design method, allowing for the creation of differentiable modules that can be used stand-alone or within the computation graph of neural networks, simplifying the development of differentiable audio systems. It includes predefined filtering modules and auxiliary classes for constructing, training, and logging the optimized systems, all accessible through an intuitive interface. Practical application of these modules is demonstrated through two case studies: the optimization of an artificial reverberator and an active acoustics system for improved response coloration.
        ]]></description>
    </item>
    <item>
        <title>Language-based Audio Moment Retrieval</title>
        <link>https://arxiv.org/abs/2409.15672</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2409.15672v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hokuto Munakata, Taichi Nishimura, Shota Nakada, Tatsuya Komatsu</dc:creator>
        <description><![CDATA[
            背景：现有基于语言的音频检索任务多搜索短音频片段，音频时刻检索（AMR）相关工作缺乏。方法：构建含时刻标注的数据集Clotho - Moment，提出基于DETR的模型Audio Moment DETR（AM - DETR）用于AMR任务，该模型受视频时刻检索启发，能捕捉音频特征的时间依赖。效果：使用手动标注数据集测试，AM - DETR在各指标上均优于采用滑动窗口的剪辑级音频检索基线模型，Recall1@0.7提高9.00个百分点。
            arXiv:2409.15672v2 Announce Type: replace 
Abstract: In this paper, we propose and design a new task called audio moment retrieval (AMR). Unlike conventional language-based audio retrieval tasks that search for short audio clips from an audio database, AMR aims to predict relevant moments in untrimmed long audio based on a text query. Given the lack of prior work in AMR, we first build a dedicated dataset, Clotho-Moment, consisting of large-scale simulated audio recordings with moment annotations. We then propose a DETR-based model, named Audio Moment DETR (AM-DETR), as a fundamental framework for AMR tasks. This model captures temporal dependencies within audio features, inspired by similar video moment retrieval tasks, thus surpassing conventional clip-level audio retrieval methods. Additionally, we provide manually annotated datasets to properly measure the effectiveness and robustness of our methods on real data. Experimental results show that AM-DETR, trained with Clotho-Moment, outperforms a baseline model that applies a clip-level audio retrieval method with a sliding window on all metrics, particularly improving Recall1@0.7 by 9.00 points. Our datasets and code are publicly available in https://h-munakata.github.io/Language-based-Audio-Moment-Retrieval.
        ]]></description>
    </item>
    <item>
        <title>Sketch2Sound: Controllable Audio Generation via Time-Varying Signals and Sonic Imitations</title>
        <link>https://arxiv.org/abs/2412.08550</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2412.08550v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hugo Flores Garc\'ia, Oriol Nieto, Justin Salamon, Bryan Pardo, Prem Seetharaman</dc:creator>
        <description><![CDATA[
            背景：当前缺乏能依据可解释时变控制信号及文本提示生成高质量声音的音频生成模型。方法：提出Sketch2Sound，可基于响度、亮度、音高和文本提示生成声音，能从声音模仿合成任意声音，可在任意文本到音频潜在扩散变换器上实现，训练时对控制信号应用随机中值滤波器。效果：相比仅用文本的基线方法，能合成遵循输入控制要点、符合文本提示且保证音频质量的声音，更轻量级。
            arXiv:2412.08550v2 Announce Type: replace 
Abstract: We present Sketch2Sound, a generative audio model capable of creating high-quality sounds from a set of interpretable time-varying control signals: loudness, brightness, and pitch, as well as text prompts. Sketch2Sound can synthesize arbitrary sounds from sonic imitations (i.e.,~a vocal imitation or a reference sound-shape). Sketch2Sound can be implemented on top of any text-to-audio latent diffusion transformer (DiT), and requires only 40k steps of fine-tuning and a single linear layer per control, making it more lightweight than existing methods like ControlNet. To synthesize from sketchlike sonic imitations, we propose applying random median filters to the control signals during training, allowing Sketch2Sound to be prompted using controls with flexible levels of temporal specificity. We show that Sketch2Sound can synthesize sounds that follow the gist of input controls from a vocal imitation while retaining the adherence to an input text prompt and audio quality compared to a text-only baseline. Sketch2Sound allows sound artists to create sounds with the semantic flexibility of text prompts and the expressivity and precision of a sonic gesture or vocal imitation. Sound examples are available at https://hugofloresgarcia.art/sketch2sound/.
        ]]></description>
    </item>
    <item>
        <title>Designing Neural Synthesizers for Low-Latency Interaction</title>
        <link>https://arxiv.org/abs/2503.11562</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.11562v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Franco Caspe, Jordie Shier, Mark Sandler, Charalampos Saitis, Andrew McPherson</dc:creator>
        <description><![CDATA[
            背景：神经音频合成（NAS）模型虽能实时运行，但高延迟使其不适用于音乐交互，且深度学习模型架构选择对音频延迟的影响研究较少。方法：研究交互式NAS模型延迟和抖动来源，将分析应用于RAVE音色转换任务，提出优化延迟的迭代设计方法，得到低延迟模型BRAVE，并在专用推理框架中实现。效果：BRAVE能更好复制音高和响度，音色修改能力与RAVE相当，还开发了兼容乐器音频信号的概念验证音频插件。
            arXiv:2503.11562v2 Announce Type: replace 
Abstract: Neural Audio Synthesis (NAS) models offer interactive musical control over high-quality, expressive audio generators. While these models can operate in real-time, they often suffer from high latency, making them unsuitable for intimate musical interaction. The impact of architectural choices in deep learning models on audio latency remains largely unexplored in the NAS literature. In this work, we investigate the sources of latency and jitter typically found in interactive NAS models. We then apply this analysis to the task of timbre transfer using RAVE, a convolutional variational autoencoder for audio waveforms introduced by Caillon et al. in 2021. Finally, we present an iterative design approach for optimizing latency. This culminates with a model we call BRAVE (Bravely Realtime Audio Variational autoEncoder), which is low-latency and exhibits better pitch and loudness replication while showing timbre modification capabilities similar to RAVE. We implement it in a specialized inference framework for low-latency, real-time inference and present a proof-of-concept audio plugin compatible with audio signals from musical instruments. We expect the challenges and guidelines described in this document to support NAS researchers in designing models for low-latency inference from the ground up, enriching the landscape of possibilities for musicians.
        ]]></description>
    </item>
    <item>
        <title>UniForm: A Unified Multi-Task Diffusion Transformer for Audio-Video Generation</title>
        <link>https://arxiv.org/abs/2502.03897</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.03897v3</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 15 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Lei Zhao, Linfeng Feng, Dongxu Ge, Rujin Chen, Fangqiu Yi, Chi Zhang, Xiao-Lei Zhang, Xuelong Li</dc:creator>
        <description><![CDATA[
            背景：扩散模型兴起使音视频生成变革，但现有方法多依赖独立模块，统一架构探索有限且多局限单任务和小数据集。方法：提出UniForm，在共享潜在空间联合生成音视频，单个扩散过程对两者建模；引入特定任务噪声方案和任务令牌，支持多任务；借助大语言模型和大规模数据集。效果：比以往方法有更高生成多样性，在音视频生成任务中达最优性能，生成内容与现实数据分布接近且对齐良好。
            arXiv:2502.03897v3 Announce Type: replace-cross 
Abstract: With the rise of diffusion models, audio-video generation has been revolutionized. However, most existing methods rely on separate modules for each modality, with limited exploration of unified generative architectures. In addition, many are confined to a single task and small-scale datasets. To address these limitations, we first propose UniForm, a unified multi-task diffusion transformer that jointly generates audio and visual modalities in a shared latent space. A single diffusion process models both audio and video, capturing the inherent correlations between sound and vision. Second, we introduce task-specific noise schemes and task tokens, enabling a single model to support multiple tasks, including text-to-audio-video, audio-to-video, and video-to-audio generation. Furthermore, by leveraging large language models and a large-scale text-audio-video combined dataset, UniForm achieves greater generative diversity than prior approaches. Extensive experiments show that UniForm achieves the state-of-the-art performance across audio-video generation tasks, producing content that is both well-aligned and close to real-world data distributions. Our demos are available at https://uniform-t2av.github.io/.
        ]]></description>
    </item>
</channel>
</rss>