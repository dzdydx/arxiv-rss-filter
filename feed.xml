<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
<channel>
    <title>arXiv Paper Filter</title>
    <link>https://github.com/None/arxiv_filter</link>
    <description>根据研究兴趣筛选的arXiv论文</description>
    <atom:link href="https://raw.githubusercontent.com/None/arxiv_filter/main/feed.xml" rel="self" type="application/rss+xml" />
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>zh-CN</language>
    <lastBuildDate>Wed, 04 Jun 2025 16:58:26 +0800</lastBuildDate>
    <managingEditor>None@github.com</managingEditor>
    <pubDate>Wed, 04 Jun 2025 16:58:26 +0800</pubDate>
    <skipDays>
        <day>Saturday</day>
        <day>Sunday</day>
    </skipDays>

    <item>
        <title>Matrix Is All You Need</title>
        <link>https://arxiv.org/abs/2506.01966</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.01966v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuzhou Zhu</dc:creator>
        <description><![CDATA[
            背景：深度神经网络在视觉、序列和语言任务中架构繁多，掩盖了其潜在共性。方法：引入统一的矩阵阶框架，将卷积、循环和自注意力操作视为稀疏矩阵乘法，卷积通过上三角权重矩阵实现一阶变换，循环由下三角矩阵编码逐步更新，注意力自然地作为三阶张量分解。效果：在图像分类、时间序列预测和语言建模/分类等任务上，稀疏矩阵公式的性能与原生模型相当或更优，且收敛所需轮数相当或更少，为不同神经架构奠定数学基础。
            arXiv:2506.01966v1 Announce Type: new 
Abstract: Deep neural networks employ specialized architectures for vision, sequential and language tasks, yet this proliferation obscures their underlying commonalities. We introduce a unified matrix-order framework that casts convolutional, recurrent and self-attention operations as sparse matrix multiplications. Convolution is realized via an upper-triangular weight matrix performing first-order transformations; recurrence emerges from a lower-triangular matrix encoding stepwise updates; attention arises naturally as a third-order tensor factorization. We prove algebraic isomorphism with standard CNN, RNN and Transformer layers under mild assumptions. Empirical evaluations on image classification (MNIST, CIFAR-10/100, Tiny ImageNet), time-series forecasting (ETTh1, Electricity Load Diagrams) and language modeling/classification (AG News, WikiText-2, Penn Treebank) confirm that sparse-matrix formulations match or exceed native model performance while converging in comparable or fewer epochs. By reducing architecture design to sparse pattern selection, our matrix perspective aligns with GPU parallelism and leverages mature algebraic optimization tools. This work establishes a mathematically rigorous substrate for diverse neural architectures and opens avenues for principled, hardware-aware network design.
        ]]></description>
    </item>
    <item>
        <title>Johnny: Structuring Representation Space to Enhance Machine Abstract Reasoning Ability</title>
        <link>https://arxiv.org/abs/2506.01970</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.01970v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ruizhuo Song, Beiming Yuan</dc:creator>
        <description><![CDATA[
            该论文聚焦于提升AI抽象推理能力的挑战，以涉及复杂类人概念的瑞文推理测验（RPM）任务为背景。指出传统端到端RPM求解模型过度依赖选项池配置，限制了推理能力。为此提出Johnny架构，通过其表征提取模块和推理模块协同运作，用学习的表征空间补充原始负选项配置，提升推理性能。还引入Spin - Transformer网络架构及轻量级变体，减少计算开销。实验表明，两者在RPM任务上表现出色，为提升AI抽象推理能力提供新方法。
            arXiv:2506.01970v1 Announce Type: new 
Abstract: This paper thoroughly investigates the challenges of enhancing AI's abstract reasoning capabilities, with a particular focus on Raven's Progressive Matrices (RPM) tasks involving complex human-like concepts. Firstly, it dissects the empirical reality that traditional end-to-end RPM-solving models heavily rely on option pool configurations, highlighting that this dependency constrains the model's reasoning capabilities. To address this limitation, the paper proposes the Johnny architecture - a novel representation space-based framework for RPM-solving. Through the synergistic operation of its Representation Extraction Module and Reasoning Module, Johnny significantly enhances reasoning performance by supplementing primitive negative option configurations with a learned representation space. Furthermore, to strengthen the model's capacity for capturing positional relationships among local features, the paper introduces the Spin-Transformer network architecture, accompanied by a lightweight Straw Spin-Transformer variant that reduces computational overhead through parameter sharing and attention mechanism optimization. Experimental evaluations demonstrate that both Johnny and Spin-Transformer achieve superior performance on RPM tasks, offering innovative methodologies for advancing AI's abstract reasoning capabilities.
        ]]></description>
    </item>
    <item>
        <title>NovelHopQA: Diagnosing Multi-Hop Reasoning Failures in Long Narrative Contexts</title>
        <link>https://arxiv.org/abs/2506.02000</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02000v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Abhay Gupta, Michael Lu, Kevin Zhu, Sean O'Brien, Vasu Sharma</dc:creator>
        <description><![CDATA[
            背景：当前大语言模型在回答涉及多跳推理的长文本问题时存在困难，且现有基准未在自然叙事场景中同时改变上下文长度和推理深度。方法：引入 NovelHopQA 基准，对 83 部小说的 64k - 128k 词节选进行 1 - 4 跳问答评估，用关键词引导的管道构建基于连贯故事情节的跳链，评估 6 个最先进模型并应用 oracle - 上下文过滤。效果：发现随着跳数和上下文长度增加，准确率下降，揭示单纯规模不能保证强大推理能力。
            arXiv:2506.02000v1 Announce Type: new 
Abstract: Current large language models (LLMs) struggle to answer questions that span tens of thousands of tokens, especially when multi-hop reasoning is involved. While prior benchmarks explore long-context comprehension or multi-hop reasoning in isolation, none jointly vary context length and reasoning depth in natural narrative settings. We introduce NovelHopQA, the first benchmark to evaluate k1-4 hop QA over 64k-128k-token excerpts from 83 full-length public-domain novels. A keyword-guided pipeline builds hop-separated chains grounded in coherent storylines. We evaluate six state-of-the-art (SOTA) models and apply oracle-context filtering to ensure all questions are genuinely answerable. Human annotators validate both alignment and hop depth. We noticed consistent accuracy drops with increased hops and context length, even in frontier models-revealing that sheer scale does not guarantee robust reasoning. Our failure mode analysis highlights common breakdowns, such as missed final-hop integration and long-range drift. NovelHopQA offers a controlled diagnostic setting to stress-test multi-hop reasoning at scale.
        ]]></description>
    </item>
    <item>
        <title>ChatCFD: an End-to-End CFD Agent with Domain-specific Structured Thinking</title>
        <link>https://arxiv.org/abs/2506.02019</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02019v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>E Fan, Weizong Wang, Tianhan Zhang</dc:creator>
        <description><![CDATA[
            背景：计算流体动力学（CFD）对科学和工程进步至关重要，但受操作复杂性和专业知识需求限制。方法：本文提出由大语言模型驱动的ChatCFD，在OpenFOAM框架下自动化CFD工作流，通过结构化方法构建数据库、验证配置和进行错误反思，将CFD和OpenFOAM知识与通用语言模型集成。效果：验证表明ChatCFD能自主重现已发表的CFD结果，可处理复杂、未见的配置，这是通用语言模型难以完成的。
            arXiv:2506.02019v1 Announce Type: new 
Abstract: Computational Fluid Dynamics (CFD) is essential for scientific and engineering advancements but is limited by operational complexity and the need for extensive expertise. This paper presents ChatCFD, a large language model-driven pipeline that automates CFD workflows within the OpenFOAM framework. It enables users to configure and execute complex simulations from natural language prompts or published literature with minimal expertise. The innovation is its structured approach to database construction, configuration validation, and error reflection, integrating CFD and OpenFOAM knowledge with general language models to improve accuracy and adaptability. Validation shows ChatCFD can autonomously reproduce published CFD results, handling complex, unseen configurations beyond basic examples, a task challenging for general language models.
        ]]></description>
    </item>
    <item>
        <title>FinS-Pilot: A Benchmark for Online Financial System</title>
        <link>https://arxiv.org/abs/2506.02037</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02037v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Feng Wang, Yiding Sun, Jiaxin Mao, Wei Xue, Danqing Xu</dc:creator>
        <description><![CDATA[
            背景：大语言模型在各专业领域表现出色，但金融RAG基准的发展受数据保密和缺乏动态数据整合的限制。方法：提出FinS-Pilot这一用于评估在线金融应用中RAG系统的新基准，它基于真实金融助手交互构建，整合实时API数据和结构化文本源，并通过意图分类框架组织。效果：能全面评估金融助手处理静态知识和时效性市场信息的能力，通过对多个中文领先大模型的实验，证明其能识别适合金融应用的模型，填补金融领域专业评估工具的空白。
            arXiv:2506.02037v1 Announce Type: new 
Abstract: Large language models (LLMs) have demonstrated remarkable capabilities across various professional domains, with their performance typically evaluated through standardized benchmarks. However, the development of financial RAG benchmarks has been constrained by data confidentiality issues and the lack of dynamic data integration. To address this issue, we introduces FinS-Pilot, a novel benchmark for evaluating RAG systems in online financial applications. Constructed from real-world financial assistant interactions, our benchmark incorporates both real-time API data and structured text sources, organized through an intent classification framework covering critical financial domains such as equity analysis and macroeconomic forecasting. The benchmark enables comprehensive evaluation of financial assistants' capabilities in handling both static knowledge and time-sensitive market information. Through systematic experiments with multiple Chinese leading LLMs, we demonstrate FinS-Pilot's effectiveness in identifying models suitable for financial applications while addressing the current gap in specialized evaluation tools for the financial domain. Our work contributes both a practical evaluation framework and a curated dataset to advance research in financial NLP systems. The code and dataset are accessible on GitHub\footnote{https://github.com/PhealenWang/financial\_rag\_benchmark}.
        ]]></description>
    </item>
    <item>
        <title>RATFM: Retrieval-augmented Time Series Foundation Model for Anomaly Detection</title>
        <link>https://arxiv.org/abs/2506.02081</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02081v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chihiro Maru, Shoetsu Sato</dc:creator>
        <description><![CDATA[
            背景：受大语言模型在自然语言处理中成功的启发，时间序列基础模型被应用于多项任务，但不同领域和任务表现不同，且时间序列基础模型缺乏解释或利用示例及指令的能力。方法：提出检索增强时间序列基础模型（RATFM），使预训练时间序列基础模型能融入测试时自适应的示例。效果：RATFM性能与领域内微调相当且避免了依赖领域的微调，在包含九个领域的UCR异常档案数据集上实验证实了该方法的有效性。
            arXiv:2506.02081v1 Announce Type: new 
Abstract: Inspired by the success of large language models (LLMs) in natural language processing, recent research has explored the building of time series foundation models and applied them to tasks such as forecasting, classification, and anomaly detection. However, their performances vary between different domains and tasks. In LLM-based approaches, test-time adaptation using example-based prompting has become common, owing to the high cost of retraining. In the context of anomaly detection, which is the focus of this study, providing normal examples from the target domain can also be effective. However, time series foundation models do not naturally acquire the ability to interpret or utilize examples or instructions, because the nature of time series data used during training does not encourage such capabilities. To address this limitation, we propose a retrieval augmented time series foundation model (RATFM), which enables pretrained time series foundation models to incorporate examples of test-time adaptation. We show that RATFM achieves a performance comparable to that of in-domain fine-tuning while avoiding domain-dependent fine-tuning. Experiments on the UCR Anomaly Archive, a multi-domain dataset including nine domains, confirms the effectiveness of the proposed approach.
        ]]></description>
    </item>
    <item>
        <title>SynthRL: Scaling Visual Reasoning with Verifiable Data Synthesis</title>
        <link>https://arxiv.org/abs/2506.02096</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02096v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zijian Wu, Jinjie Ni, Xiangyan Liu, Zichen Liu, Hang Yan, Michael Qizhe Shieh</dc:creator>
        <description><![CDATA[
            背景：通过可验证奖励强化学习（RLVR）训练的视觉语言模型在有效扩展测试时计算方面取得显著进展，需研究合成的RL数据能否进一步改进RLVR。方法：提出SynthRL，包含选择合适分布的种子问题、将其扩充为更具挑战性的变体并保留原答案、保证正确性和难度提升的验证阶段。效果：在MMK12数据集上合成超3.3K个额外可验证且有挑战性的问题，在五个跨领域视觉数学推理基准测试中，用合成数据训练的模型有一致提升，对最难样本提升更明显。
            arXiv:2506.02096v1 Announce Type: new 
Abstract: Vision-language models (VLMs) trained via reinforcement learning with verifiable reward (RLVR) have shown notable progress in scaling test-time compute effectively. In this work, we investigate how synthesized RL data can further improve RLVR. To this end, we propose \textbf{SynthRL}-a scalable and guaranteed pipeline for automatic data scaling in reasoning-oriented RL training. SynthRL comprises three key stages: (1) selecting seed questions with appropriate distribution, (2) augmenting them into more challenging variants while preserving the original answers, and (3) a guaranteed verification stage that ensures near-perfect correctness and difficulty enhancement. Our empirical experiments demonstrate SynthRL's scalability and effectiveness. When applied to the MMK12 dataset, SynthRL synthesizes over 3.3K additional verifiable, challenging questions from approximately 8K seed samples. Models trained with our synthesized data achieve consistent gains across five out-of-domain visual math reasoning benchmarks, with a significant improvement over baseline models trained on seed data alone. Notably, detailed analysis reveals that the gains are more pronounced on the most challenging evaluation samples, highlighting SynthRL's effectiveness in eliciting deeper and more complex reasoning patterns.
        ]]></description>
    </item>
    <item>
        <title>Revisiting LRP: Positional Attribution as the Missing Ingredient for Transformer Explainability</title>
        <link>https://arxiv.org/abs/2506.02138</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02138v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yarden Bakish, Itamar Zimerman, Hila Chefer, Lior Wolf</dc:creator>
        <description><![CDATA[
            背景：开发有效的Transformer可解释性工具是深度学习研究的关键，现有基于LRP的方法忽略了Transformer架构的位置编码，导致违反守恒性及相关信息丢失。方法：将Transformer可解释性的输入空间重新定义为位置 - 令牌对，提出专门的LRP规则以在不同位置编码方法中传播归因。效果：在微调分类器和零样本基础模型（如LLaMA 3）的实验中，该方法在视觉和NLP可解释性任务上显著优于现有技术。
            arXiv:2506.02138v1 Announce Type: new 
Abstract: The development of effective explainability tools for Transformers is a crucial pursuit in deep learning research. One of the most promising approaches in this domain is Layer-wise Relevance Propagation (LRP), which propagates relevance scores backward through the network to the input space by redistributing activation values based on predefined rules. However, existing LRP-based methods for Transformer explainability entirely overlook a critical component of the Transformer architecture: its positional encoding (PE), resulting in violation of the conservation property, and the loss of an important and unique type of relevance, which is also associated with structural and positional features. To address this limitation, we reformulate the input space for Transformer explainability as a set of position-token pairs. This allows us to propose specialized theoretically-grounded LRP rules designed to propagate attributions across various positional encoding methods, including Rotary, Learnable, and Absolute PE. Extensive experiments with both fine-tuned classifiers and zero-shot foundation models, such as LLaMA 3, demonstrate that our method significantly outperforms the state-of-the-art in both vision and NLP explainability tasks. Our code is publicly available.
        ]]></description>
    </item>
    <item>
        <title>KDRL: Post-Training Reasoning LLMs via Unified Knowledge Distillation and Reinforcement Learning</title>
        <link>https://arxiv.org/abs/2506.02208</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02208v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hongling Xu, Qi Zhu, Heyuan Deng, Jinpeng Li, Lu Hou, Yasheng Wang, Lifeng Shang, Ruifeng Xu, Fei Mi</dc:creator>
        <description><![CDATA[
            背景：大语言模型后训练提升推理能力的强化学习（RL）样本效率低，知识蒸馏（KD）泛化性差。方法：提出统一后训练框架KDRL，通过教师监督（KD）和自我探索（RL）联合优化推理模型，利用策略梯度优化，同时最小化学生与教师分布的反向KL散度、最大化基于规则的预期奖励，并系统探索不同因素对后训练的影响。效果：在多个推理基准测试中，KDRL优于GRPO和多种KD基线，平衡了性能和推理令牌效率。
            arXiv:2506.02208v1 Announce Type: new 
Abstract: Recent advances in large language model (LLM) post-training have leveraged two distinct paradigms to enhance reasoning capabilities: reinforcement learning (RL) and knowledge distillation (KD). While RL enables the emergence of complex reasoning behaviors, it often suffers from low sample efficiency when the initial policy struggles to explore high-reward trajectories. Conversely, KD improves learning efficiency via mimicking the teacher model but tends to generalize poorly to out-of-domain scenarios. In this work, we present \textbf{KDRL}, a \textit{unified post-training framework} that jointly optimizes a reasoning model through teacher supervision (KD) and self-exploration (RL). Specifically, KDRL leverages policy gradient optimization to simultaneously minimize the reverse Kullback-Leibler divergence (RKL) between the student and teacher distributions while maximizing the expected rule-based rewards. We first formulate a unified objective that integrates GRPO and KD, and systematically explore how different KL approximations, KL coefficients, and reward-guided KD strategies affect the overall post-training dynamics and performance. Empirical results on multiple reasoning benchmarks demonstrate that KDRL outperforms GRPO and various KD baselines while achieving a favorable balance between performance and reasoning token efficiency. These findings indicate that integrating KD and RL serves as an effective and efficient strategy to train reasoning LLMs.
        ]]></description>
    </item>
    <item>
        <title>Leveraging Natural Language Processing to Unravel the Mystery of Life: A Review of NLP Approaches in Genomics, Transcriptomics, and Proteomics</title>
        <link>https://arxiv.org/abs/2506.02212</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02212v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ella Rannon, David Burstein</dc:creator>
        <description><![CDATA[
            背景：自然语言处理（NLP）技术可用于分析生物序列数据。方法：该综述聚焦基因组学、转录组学和蛋白质组学，探讨从经典的word2vec到采用transformers和hyena算子的先进模型等NLP方法如何应用于分析DNA、RNA、蛋白质序列及整个基因组，还研究了分词策略和模型架构。效果：评估了各方法的优缺点及适用性，介绍了NLP在生物数据应用中的进展，其有望助力从大规模基因组数据中提取有价值信息，推动对生物过程的理解。
            arXiv:2506.02212v1 Announce Type: new 
Abstract: Natural Language Processing (NLP) has transformed various fields beyond linguistics by applying techniques originally developed for human language to the analysis of biological sequences. This review explores the application of NLP methods to biological sequence data, focusing on genomics, transcriptomics, and proteomics. We examine how various NLP methods, from classic approaches like word2vec to advanced models employing transformers and hyena operators, are being adapted to analyze DNA, RNA, protein sequences, and entire genomes. The review also examines tokenization strategies and model architectures, evaluating their strengths, limitations, and suitability for different biological tasks. We further cover recent advances in NLP applications for biological data, such as structure prediction, gene expression, and evolutionary analysis, highlighting the potential of these methods for extracting meaningful insights from large-scale genomic data. As language models continue to advance, their integration into bioinformatics holds immense promise for advancing our understanding of biological processes in all domains of life.
        ]]></description>
    </item>
    <item>
        <title>From Street Views to Urban Science: Discovering Road Safety Factors with Multimodal Large Language Models</title>
        <link>https://arxiv.org/abs/2506.02242</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02242v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yihong Tang, Ao Qu, Xujing Yu, Weipeng Deng, Jun Ma, Jinhua Zhao, Lijun Sun</dc:creator>
        <description><![CDATA[
            城市与交通研究长期致力于挖掘关键变量与道路安全等社会结果间的关系，但传统方法存在依赖专家、可解释性有限、未充分利用非结构化数据等问题。为此，研究提出基于多模态大模型的可解释假设推理方法，利用多模态大模型提出安全相关问题，提取可解释嵌入并用于回归模型。实验表明，该方法在曼哈顿街道段的评估中优于预训练深度学习模型，且具有完全可解释性，还能作为通用框架用于城市科学发现。
            arXiv:2506.02242v1 Announce Type: new 
Abstract: Urban and transportation research has long sought to uncover statistically meaningful relationships between key variables and societal outcomes such as road safety, to generate actionable insights that guide the planning, development, and renewal of urban and transportation systems. However, traditional workflows face several key challenges: (1) reliance on human experts to propose hypotheses, which is time-consuming and prone to confirmation bias; (2) limited interpretability, particularly in deep learning approaches; and (3) underutilization of unstructured data that can encode critical urban context. Given these limitations, we propose a Multimodal Large Language Model (MLLM)-based approach for interpretable hypothesis inference, enabling the automated generation, evaluation, and refinement of hypotheses concerning urban context and road safety outcomes. Our method leverages MLLMs to craft safety-relevant questions for street view images (SVIs), extract interpretable embeddings from their responses, and apply them in regression-based statistical models. UrbanX supports iterative hypothesis testing and refinement, guided by statistical evidence such as coefficient significance, thereby enabling rigorous scientific discovery of previously overlooked correlations between urban design and safety. Experimental evaluations on Manhattan street segments demonstrate that our approach outperforms pretrained deep learning models while offering full interpretability. Beyond road safety, UrbanX can serve as a general-purpose framework for urban scientific discovery, extracting structured insights from unstructured urban data across diverse socioeconomic and environmental outcomes. This approach enhances model trustworthiness for policy applications and establishes a scalable, statistically grounded pathway for interpretable knowledge discovery in urban and transportation studies.
        ]]></description>
    </item>
    <item>
        <title>CoDial: Interpretable Task-Oriented Dialogue Systems Through Dialogue Flow Alignment</title>
        <link>https://arxiv.org/abs/2506.02264</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02264v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Radin Shayanfar, Chu Fei Luo, Rohan Bhambhoria, Samuel Dahan, Xiaodan Zhu</dc:creator>
        <description><![CDATA[
            背景：由于专家知识、训练数据成本高和技术难度大，教对话系统执行专业、未知任务颇具挑战，构建让非技术专家轻松定义系统行为的框架很有必要。方法：提出CoDial框架，将以新型结构化异构图表示的专家知识转化为可执行对话逻辑，能在现有防护语言中实现。效果：在STAR数据集上达推理模型的最优性能，在MultiWOZ数据集上与类似基线有竞争力，还可通过反馈迭代改进，是高风险领域大模型专家引导对齐的实用工具。
            arXiv:2506.02264v1 Announce Type: new 
Abstract: It is often challenging to teach specialized, unseen tasks to dialogue systems due to the high cost of expert knowledge, training data, and high technical difficulty. To support domain-specific applications - such as law, medicine, or finance - it is essential to build frameworks that enable non-technical experts to define, test, and refine system behaviour with minimal effort. Achieving this requires cross-disciplinary collaboration between developers and domain specialists. In this work, we introduce a novel framework, CoDial (Code for Dialogue), that converts expert knowledge, represented as a novel structured heterogeneous graph, into executable conversation logic. CoDial can be easily implemented in existing guardrailing languages, such as Colang, to enable interpretable, modifiable, and true zero-shot specification of task-oriented dialogue systems. Empirically, CoDial achieves state-of-the-art performance on the STAR dataset for inference-based models and is competitive with similar baselines on the well-known MultiWOZ dataset. We also demonstrate CoDial's iterative improvement via manual and LLM-aided feedback, making it a practical tool for expert-guided alignment of LLMs in high-stakes domains.
        ]]></description>
    </item>
    <item>
        <title>ImpRAG: Retrieval-Augmented Generation with Implicit Queries</title>
        <link>https://arxiv.org/abs/2506.02279</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02279v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wenzheng Zhang, Xi Victoria Lin, Karl Stratos, Wen-tau Yih, Mingda Chen</dc:creator>
        <description><![CDATA[
            背景：传统检索增强生成（RAG）系统将检索和生成视为独立过程，需显式文本查询，限制了模型跨任务泛化能力。方法：提出无查询的RAG系统ImpRAG，将检索和生成集成到统一模型，通过划分预训练仅解码器语言模型的层组优化任务，采用两阶段推理过程。效果：在8个知识密集型任务实验中，ImpRAG在不同格式的未见任务上精确匹配分数提升3.6 - 11.5，证明其有效性。
            arXiv:2506.02279v1 Announce Type: new 
Abstract: Retrieval-Augmented Generation (RAG) systems traditionally treat retrieval and generation as separate processes, requiring explicit textual queries to connect them. This separation can limit the ability of models to generalize across diverse tasks. In this work, we propose a query-free RAG system, named ImpRAG, which integrates retrieval and generation into a unified model. ImpRAG allows models to implicitly express their information needs, eliminating the need for human-specified queries. By dividing pretrained decoder-only language models into specialized layer groups, ImpRAG optimizes retrieval and generation tasks simultaneously. Our approach employs a two-stage inference process, using the same model parameters and forward pass for both retrieval and generation, thereby minimizing the disparity between retrievers and language models. Experiments on 8 knowledge-intensive tasks demonstrate that ImpRAG achieves 3.6-11.5 improvements in exact match scores on unseen tasks with diverse formats, highlighting its effectiveness in enabling models to articulate their own information needs and generalize across tasks. Our analysis underscores the importance of balancing retrieval and generation parameters and leveraging generation perplexities as retrieval training objectives for enhanced performance.
        ]]></description>
    </item>
    <item>
        <title>CACTI: Leveraging Copy Masking and Contextual Information to Improve Tabular Data Imputation</title>
        <link>https://arxiv.org/abs/2506.02306</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02306v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Aditya Gorla, Ryan Wang, Zhengtong Liu, Ulzee An, Sriram Sankararaman</dc:creator>
        <description><![CDATA[
            背景：在表格数据插补任务中，需利用缺失模式结构和上下文信息。方法：提出CACTI，采用新型中位数截断复制掩码训练策略，促使模型从缺失的经验模式中学习，同时结合特征间语义关系。效果：在多种数据集和缺失条件下，CACTI表现优于现有方法，相比次优方法平均 $R^2$ 提升7.8%，在非随机缺失、随机缺失和完全随机缺失情况下分别提升13.4%、6.1%和5.3%。
            arXiv:2506.02306v1 Announce Type: new 
Abstract: We present CACTI, a masked autoencoding approach for imputing tabular data that leverages the structure in missingness patterns and contextual information. Our approach employs a novel median truncated copy masking training strategy that encourages the model to learn from empirical patterns of missingness while incorporating semantic relationships between features - captured by column names and text descriptions - to better represent feature dependence. These dual sources of inductive bias enable CACTI to outperform state-of-the-art methods - an average $R^2$ gain of 7.8% over the next best method (13.4%, 6.1%, and 5.3% under missing not at random, at random and completely at random, respectively) - across a diverse range of datasets and missingness conditions. Our results highlight the value of leveraging dataset-specific contextual information and missingness patterns to enhance imputation performance.
        ]]></description>
    </item>
    <item>
        <title>One Missing Piece for Open-Source Reasoning Models: A Dataset to Mitigate Cold-Starting Short CoT LLMs in RL</title>
        <link>https://arxiv.org/abs/2506.02338</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02338v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hyungjoo Chae, Dongjin Kang, Jihyuk Kim, Beong-woo Kwak, Sunghyun Park, Haeju Park, Jinyoung Yeo, Moontae Lee, Kyungjae Lee</dc:creator>
        <description><![CDATA[
            背景：现有研究常基于R1的长思维链推理训练新的大型推理模型（LRM），但依赖现有模型限制了该领域发展。方法：本文探索构建长思维链数据集的可能性，推出含10万个思维链理由的Long CoT Collection数据集，开发将o1推理策略引入短思维链大语言模型的流程，引入对思维预算的可控性。效果：数据集质量与R1相当或略低，基于该数据集训练不仅强化推理能力，还为强化学习奠定基础，初始化模型用RLVR可获2 - 3倍提升。
            arXiv:2506.02338v1 Announce Type: new 
Abstract: With the release of R1, a publicly available large reasoning model (LRM), researchers commonly train new LRMs by training language models on R1's long chain-of-thought (CoT) inferences. While prior works show that LRMs' capabilities can be reproduced through direct distillation, the continued reliance on the existing models (e.g., R1) remains a critical limitation in advancing the field. As a first step toward independent LRM development, this paper explores the possibility of constructing a long CoT dataset with LLMs that are not trained for inference-time scaling. To this end, we present the Long CoT Collection, a dataset of 100K CoT rationales annotated using existing short CoT LLMs. We develop a pipeline that induces o1's novel reasoning strategies into short CoT LLMs, enabling them to think longer and introducing controllability over the thought budget to better manage the overthinking problem. Our extensive analyses validate that our dataset achieves quality comparable to--or slightly below--R1. Furthermore, our experiments demonstrate that training on our dataset not only strengthens general reasoning skills, but also provides a strong foundation for reinforcement learning--models initialized on our data achieve 2-3x larger gains with RLVR.
        ]]></description>
    </item>
    <item>
        <title>DIAMOND: An LLM-Driven Agent for Context-Aware Baseball Highlight Summarization</title>
        <link>https://arxiv.org/abs/2506.02351</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02351v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jeonghun Kang, Soonmok Kwon, Joonseok Lee, Byung-Hak Kim</dc:creator>
        <description><![CDATA[
            传统棒球高光总结方法，如基于WPA的排名或计算机视觉驱动的事件检测，会忽略战略深度等内容，人工整理虽好但耗资源且难扩展。为此提出DIAMOND，它是一个由大语言模型驱动的上下文感知棒球高光总结代理，将结构化体育分析与自然语言推理相结合。利用棒球数据特征量化比赛重要性，通过大语言模型模块基于上下文叙述价值优化选择。在五场比赛上评估，其F1分数从仅用WPA时的42.9%提升到84.8%，超越商业和统计基线，展现了基于代理的框架在事件总结中的潜力。
            arXiv:2506.02351v1 Announce Type: new 
Abstract: Traditional approaches -- such as Win Probability Added (WPA)-based ranking or computer vision-driven event detection -- can identify scoring plays but often miss strategic depth, momentum shifts, and storyline progression. Manual curation remains the gold standard but is resource-intensive and not scalable. We introduce DIAMOND, an LLM-driven agent for context-aware baseball highlight summarization that integrates structured sports analytics with natural language reasoning. DIAMOND leverages sabermetric features -- Win Expectancy, WPA, and Leverage Index -- to quantify play importance, while an LLM module enhances selection based on contextual narrative value. This hybrid approach ensures both quantitative rigor and qualitative richness, surpassing the limitations of purely statistical or vision-based systems. Evaluated on five diverse Korean Baseball Organization League games, DIAMOND improves F1-score from 42.9% (WPA-only) to 84.8%, outperforming both commercial and statistical baselines. Though limited in scale, our results highlight the potential of modular, interpretable agent-based frameworks for event-level summarization in sports and beyond.
        ]]></description>
    </item>
    <item>
        <title>Rewarding the Unlikely: Lifting GRPO Beyond Distribution Sharpening</title>
        <link>https://arxiv.org/abs/2506.02355</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02355v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Andre He, Daniel Fried, Sean Welleck</dc:creator>
        <description><![CDATA[
            背景：强化学习是训练大语言模型处理结构化语言条件任务的有效框架，但广泛使用的GRPO算法存在缺陷，在多样本任务中会偏向强化可能的解，忽视罕见但正确的证明，影响大样本下的性能。方法：引入“罕见性奖励”明确鼓励强化罕见正确解，增加PPO轮数减轻偏差。效果：实验表明，该方法显著提高了大范围N下的pass@$N$，优于标准GRPO，大幅增加样本多样性，在miniF2F - test基准上取得有竞争力的表现。
            arXiv:2506.02355v1 Announce Type: new 
Abstract: Reinforcement learning has emerged as an effective framework for training large language models on structured language-conditioned tasks. We identify a critical flaw of Group Relative Policy Optimization (GRPO), a widely used RL algorithm in this setting. For tasks that require multi-sample performance, such as formal theorem proving, GRPO biasedly reinforces already probable solutions and neglects rare but correct proofs. This implicit bias impairs performance on pass@$N$ metrics at large sample sizes, limiting its practicality for training theorem provers. To address this, we introduce the unlikeliness reward, a straightforward method that explicitly encourages reinforcing rare correct solutions. Additionally, we find that increasing the number of PPO epochs further mitigates this bias. Our experiments confirm that incorporating the unlikeliness reward significantly improves pass@$N$ across a large range of N, outperforming standard GRPO and substantially increasing sample diversity. Applying our revised recipe to Lean, we achieve competitive performance with DeepSeek-Prover-V1.5-RL on the miniF2F-test benchmark. We release our implementation, providing a simple yet effective recipe for training formal theorem provers with RL.
        ]]></description>
    </item>
    <item>
        <title>Multi-level and Multi-modal Action Anticipation</title>
        <link>https://arxiv.org/abs/2506.02382</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02382v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Seulgi Kim, Ghazal Kaviani, Mohit Prabhushankar, Ghassan AlRegib</dc:creator>
        <description><![CDATA[
            动作预测对推进智能系统至关重要，但传统方法多仅关注视觉模态，忽略多源信息融合。为此，研究提出多级别多模态动作预测方法（m&m - Ant），结合视觉和文本线索，显式建模分层语义信息。为解决粗略动作标签不准确问题，提出细粒度标签生成器和专用时间一致性损失函数。在多个常用数据集实验，平均预测准确率比现有方法提高3.08%，为该领域研究树立新标杆。
            arXiv:2506.02382v1 Announce Type: new 
Abstract: Action anticipation, the task of predicting future actions from partially observed videos, is crucial for advancing intelligent systems. Unlike action recognition, which operates on fully observed videos, action anticipation must handle incomplete information. Hence, it requires temporal reasoning, and inherent uncertainty handling. While recent advances have been made, traditional methods often focus solely on visual modalities, neglecting the potential of integrating multiple sources of information. Drawing inspiration from human behavior, we introduce \textit{Multi-level and Multi-modal Action Anticipation (m\&amp;m-Ant)}, a novel multi-modal action anticipation approach that combines both visual and textual cues, while explicitly modeling hierarchical semantic information for more accurate predictions. To address the challenge of inaccurate coarse action labels, we propose a fine-grained label generator paired with a specialized temporal consistency loss function to optimize performance. Extensive experiments on widely used datasets, including Breakfast, 50 Salads, and DARai, demonstrate the effectiveness of our approach, achieving state-of-the-art results with an average anticipation accuracy improvement of 3.08\% over existing methods. This work underscores the potential of multi-modal and hierarchical modeling in advancing action anticipation and establishes a new benchmark for future research in the field. Our code is available at: https://github.com/olivesgatech/mM-ant.
        ]]></description>
    </item>
    <item>
        <title>GraphRAG-Bench: Challenging Domain-Specific Reasoning for Evaluating Graph Retrieval-Augmented Generation</title>
        <link>https://arxiv.org/abs/2506.02404</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02404v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yilin Xiao, Junnan Dong, Chuang Zhou, Su Dong, Qianwen Zhang, Di Yin, Xing Sun, Xiao Huang</dc:creator>
        <description><![CDATA[
            背景：当前对图检索增强生成（GraphRAG）模型的评估，因传统问答数据集问题和指标有限，无法全面评估其推理能力提升。方法：引入大规模特定领域基准GraphRAG - Bench，有挑战性问题设计、多样任务覆盖和整体评估框架三个优势。效果：将九种GraphRAG方法应用于此基准，证明其可量化基于图的结构化对模型推理能力的提升，分析揭示了图架构、检索效果和推理能力的关键见解。
            arXiv:2506.02404v1 Announce Type: new 
Abstract: Graph Retrieval Augmented Generation (GraphRAG) has garnered increasing recognition for its potential to enhance large language models (LLMs) by structurally organizing domain-specific corpora and facilitating complex reasoning. However, current evaluations of GraphRAG models predominantly rely on traditional question-answering datasets. Their limited scope in questions and evaluation metrics fails to comprehensively assess the reasoning capacity improvements enabled by GraphRAG models. To address this gap, we introduce GraphRAG-Bench, a large-scale, domain-specific benchmark designed to rigorously evaluate GraphRAG models. Our benchmark offers three key superiorities: \((i)\) Challenging question design. Featuring college-level, domain-specific questions that demand multi-hop reasoning, the benchmark ensures that simple content retrieval is insufficient for problem-solving. For example, some questions require mathematical reasoning or programming. \((ii)\) Diverse task coverage. The dataset includes a broad spectrum of reasoning tasks, multiple-choice, true/false, multi-select, open-ended, and fill-in-the-blank. It spans 16 disciplines in twenty core textbooks. \((iii)\) Holistic evaluation framework. GraphRAG-Bench provides comprehensive assessment across the entire GraphRAG pipeline, including graph construction, knowledge retrieval, and answer generation. Beyond final-answer correctness, it evaluates the logical coherence of the reasoning process. By applying nine contemporary GraphRAG methods to GraphRAG-Bench, we demonstrate its utility in quantifying how graph-based structuring improves model reasoning capabilities. Our analysis reveals critical insights about graph architectures, retrieval efficacy, and reasoning capabilities, offering actionable guidance for the research community.
        ]]></description>
    </item>
    <item>
        <title>Comparative Analysis of AI Agent Architectures for Entity Relationship Classification</title>
        <link>https://arxiv.org/abs/2506.02426</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02426v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Maryam Berijanian, Kuldeep Singh, Amin Sehati</dc:creator>
        <description><![CDATA[
            实体关系分类在信息提取中是一项具有挑战性的任务，特别是在标注数据有限和关系结构复杂的场景下。该研究对三种使用大语言模型进行关系分类的人工智能代理架构进行了比较分析，包括反思性自我评估、分层任务分解和多智能体动态示例生成机制。其中动态示例生成机制引入了实时合作和对抗性提示。实验表明，多智能体协调始终优于标准少样本提示，接近微调模型的性能，为基于大语言模型的结构化关系提取系统设计提供了实用指导。
            arXiv:2506.02426v1 Announce Type: new 
Abstract: Entity relationship classification remains a challenging task in information extraction, especially in scenarios with limited labeled data and complex relational structures. In this study, we conduct a comparative analysis of three distinct AI agent architectures designed to perform relation classification using large language models (LLMs). The agentic architectures explored include (1) reflective self-evaluation, (2) hierarchical task decomposition, and (3) a novel multi-agent dynamic example generation mechanism, each leveraging different modes of reasoning and prompt adaptation. In particular, our dynamic example generation approach introduces real-time cooperative and adversarial prompting. We systematically compare their performance across multiple domains and model backends. Our experiments demonstrate that multi-agent coordination consistently outperforms standard few-shot prompting and approaches the performance of fine-tuned models. These findings offer practical guidance for the design of modular, generalizable LLM-based systems for structured relation extraction. The source codes and dataset are available at \href{https://github.com/maryambrj/ALIEN.git}{https://github.com/maryambrj/ALIEN.git}.
        ]]></description>
    </item>
    <item>
        <title>Weak Supervision for Real World Graphs</title>
        <link>https://arxiv.org/abs/2506.02451</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02451v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Pratheeksha Nair, Reihaneh Rabbany</dc:creator>
        <description><![CDATA[
            现实世界图中的节点分类常面临标签稀缺和噪声问题。虽直接监督受限，但图中存在可用于学习的弱信号。为此提出WSNET，这是一种弱监督图对比学习框架，通过针对弱标签数据的对比目标，整合图结构、节点特征和多个有噪声的监督源，以引导鲁棒的表征学习。在三个真实数据集和可控噪声的合成基准测试中，WSNET的F1分数比现有对比和噪声标签学习方法最高高出15%，凸显了弱监督下对比学习的有效性。
            arXiv:2506.02451v1 Announce Type: new 
Abstract: Node classification in real world graphs often suffers from label scarcity and noise, especially in high stakes domains like human trafficking detection and misinformation monitoring. While direct supervision is limited, such graphs frequently contain weak signals, noisy or indirect cues, that can still inform learning. We propose WSNET, a novel weakly supervised graph contrastive learning framework that leverages these weak signals to guide robust representation learning. WSNET integrates graph structure, node features, and multiple noisy supervision sources through a contrastive objective tailored for weakly labeled data. Across three real world datasets and synthetic benchmarks with controlled noise, WSNET consistently outperforms state of the art contrastive and noisy label learning methods by up to 15% in F1 score. Our results highlight the effectiveness of contrastive learning under weak supervision and the promise of exploiting imperfect labels in graph based settings.
        ]]></description>
    </item>
    <item>
        <title>ReasoningFlow: Semantic Structure of Complex Reasoning Traces</title>
        <link>https://arxiv.org/abs/2506.02532</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02532v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jinu Lee, Sagnik Mukherjee, Dilek Hakkani-Tur, Julia Hockenmaier</dc:creator>
        <description><![CDATA[
            背景：大型推理模型会生成包含规划、反思、验证和回溯的复杂推理轨迹。方法：本文提出ReasoningFlow，这是一种统一模式，可将推理轨迹解析为有向无环图，把不同推理模式表征为子图结构。效果：这种人类可解释的表征在理解、评估和增强大型推理模型的推理过程方面有很好的应用前景。
            arXiv:2506.02532v1 Announce Type: new 
Abstract: Large reasoning models (LRMs) generate complex reasoning traces with planning, reflection, verification, and backtracking. In this work, we introduce ReasoningFlow, a unified schema for analyzing the semantic structures of these complex traces. ReasoningFlow parses traces into directed acyclic graphs, enabling the characterization of distinct reasoning patterns as subgraph structures. This human-interpretable representation offers promising applications in understanding, evaluating, and enhancing the reasoning processes of LRMs.
        ]]></description>
    </item>
    <item>
        <title>HGOT: Self-supervised Heterogeneous Graph Neural Network with Optimal Transport</title>
        <link>https://arxiv.org/abs/2506.02619</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02619v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yanbei Liu, Chongxu Wang, Zhitao Xiao, Lei Geng, Yanwei Pang, Xiao Wang</dc:creator>
        <description><![CDATA[
            背景：异质图神经网络处理异质信息网络能力强，但自监督学习需精心设计图增强策略及正负样本选择，确定样本对相似度不易。方法：提出HGOT方法，用最优传输机制缓解正负样本采样难题，设计聚合视图整合语义信息，引入最优传输计划确定视图间传输关系。效果：在四个真实数据集上的实验表明，HGOT在各种下游任务中达最优性能，节点分类任务准确率比现有方法平均提高超6%。
            arXiv:2506.02619v1 Announce Type: new 
Abstract: Heterogeneous Graph Neural Networks (HGNNs), have demonstrated excellent capabilities in processing heterogeneous information networks. Self-supervised learning on heterogeneous graphs, especially contrastive self-supervised strategy, shows great potential when there are no labels. However, this approach requires the use of carefully designed graph augmentation strategies and the selection of positive and negative samples. Determining the exact level of similarity between sample pairs is non-trivial.To solve this problem, we propose a novel self-supervised Heterogeneous graph neural network with Optimal Transport (HGOT) method which is designed to facilitate self-supervised learning for heterogeneous graphs without graph augmentation strategies. Different from traditional contrastive self-supervised learning, HGOT employs the optimal transport mechanism to relieve the laborious sampling process of positive and negative samples. Specifically, we design an aggregating view (central view) to integrate the semantic information contained in the views represented by different meta-paths (branch views). Then, we introduce an optimal transport plan to identify the transport relationship between the semantics contained in the branch view and the central view. This allows the optimal transport plan between graphs to align with the representations, forcing the encoder to learn node representations that are more similar to the graph space and of higher quality. Extensive experiments on four real-world datasets demonstrate that our proposed HGOT model can achieve state-of-the-art performance on various downstream tasks. In particular, in the node classification task, HGOT achieves an average of more than 6% improvement in accuracy compared with state-of-the-art methods.
        ]]></description>
    </item>
    <item>
        <title>FreeScene: Mixed Graph Diffusion for 3D Scene Synthesis from Free Prompts</title>
        <link>https://arxiv.org/abs/2506.02781</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02781v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tongyuan Bai, Wangyuanfan Bai, Dong Chen, Tieru Wu, Manyi Li, Rui Ma</dc:creator>
        <description><![CDATA[
            在3D室内场景合成的实际应用中，可控性至关重要。现有方法要么基于语言控制较粗略，要么基于图控制但设计过程繁琐。为此提出FreeScene框架，支持自由形式的用户输入，通过基于VLM的图设计器将输入分析并集成到图表示中。还提出Mixed Graph Diffusion Transformer（MG - DiT）进行图感知去噪以增强场景生成。实验表明，FreeScene统一了基于文本和图的场景合成，在生成质量和可控性上超越了现有方法。
            arXiv:2506.02781v1 Announce Type: new 
Abstract: Controllability plays a crucial role in the practical applications of 3D indoor scene synthesis. Existing works either allow rough language-based control, that is convenient but lacks fine-grained scene customization, or employ graph based control, which offers better controllability but demands considerable knowledge for the cumbersome graph design process. To address these challenges, we present FreeScene, a user-friendly framework that enables both convenient and effective control for indoor scene synthesis.Specifically, FreeScene supports free-form user inputs including text description and/or reference images, allowing users to express versatile design intentions. The user inputs are adequately analyzed and integrated into a graph representation by a VLM-based Graph Designer. We then propose MG-DiT, a Mixed Graph Diffusion Transformer, which performs graph-aware denoising to enhance scene generation. Our MG-DiT not only excels at preserving graph structure but also offers broad applicability to various tasks, including, but not limited to, text-to-scene, graph-to-scene, and rearrangement, all within a single model. Extensive experiments demonstrate that FreeScene provides an efficient and user-friendly solution that unifies text-based and graph based scene synthesis, outperforming state-of-the-art methods in terms of both generation quality and controllability in a range of applications.
        ]]></description>
    </item>
    <item>
        <title>CoT is Not True Reasoning, It Is Just a Tight Constraint to Imitate: A Theory Perspective</title>
        <link>https://arxiv.org/abs/2506.02878</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02878v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jintian Shao, Yiming Cheng</dc:creator>
        <description><![CDATA[
            背景：思维链（CoT）提示显著提升了大语言模型在多步推理任务中的表现，人们普遍认为模型具备了新兴推理能力。方法：本文提出理论反观点，认为CoT并非引发真正的抽象推理，而是作为强大的结构约束，通过强制生成中间步骤，利用模型的序列预测和模式匹配能力。效果：使模型输出类似于连贯思维过程的序列，表明CoT只是引导大语言模型模仿推理形式。
            arXiv:2506.02878v1 Announce Type: new 
Abstract: Chain-of-Thought (CoT) prompting has demonstrably enhanced the performance of Large Language Models on tasks requiring multi-step inference. This success has led to widespread claims of emergent reasoning capabilities in these models. In this paper, we present a theoretical counter-perspective: Chain-of-Thought (CoT) does not elicit genuine, abstract reasoning. Instead, we argue that Chain-of-Thought functions as a powerful structural constraint that guides Large Language Models to imitate the form of reasoning. By forcing the generation of intermediate steps, Chain-of-Thought leverages the model immense capacity for sequence prediction and pattern matching, effectively constraining its output to sequences that resemble coherent thought processes. Chain-of-Thought (CoT) prompting has demonstrably enhanced the performance of Large Language Models on tasks requiring multi-step inference. This success has led to widespread claims of emergent reasoning capabilities in these models. In this paper, we present a theoretical counter-perspective: Chain-of-Thought (CoT) does not elicit genuine, abstract reasoning. Instead, we argue that Chain-of-Thought functions as a powerful structural constraint that guides Large Language Models to imitate the form of reasoning. By forcing the generation of intermediate steps, Chain-of-Thought leverages the model immense capacity for sequence prediction and pattern matching, effectively constraining its output to sequences that resemble coherent thought processes.
        ]]></description>
    </item>
    <item>
        <title>From Flat to Hierarchical: Extracting Sparse Representations with Matching Pursuit</title>
        <link>https://arxiv.org/abs/2506.03093</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.03093v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Val\'erie Costa, Thomas Fel, Ekdeep Singh Lubana, Bahareh Tolooshams, Demba Ba</dc:creator>
        <description><![CDATA[
            背景：稀疏自编码器（SAEs）基于神经网络表征编码抽象、可解释特征的假设，但近期研究发现模型表征存在该假设范围外的现象。方法：采用基于构造的方法，将匹配追踪（MP）算法从稀疏编码重新情境化，设计出MP - SAE，其编码器展开为一系列残差引导步骤，能捕捉分层和非线性可访问特征。效果：在合成和自然数据上对比显示，MP - SAE能捕捉现有SAEs无法忠实捕捉的特征，恢复有意义特征，还能在推理时实现自适应稀疏性。
            arXiv:2506.03093v1 Announce Type: new 
Abstract: Motivated by the hypothesis that neural network representations encode abstract, interpretable features as linearly accessible, approximately orthogonal directions, sparse autoencoders (SAEs) have become a popular tool in interpretability. However, recent work has demonstrated phenomenology of model representations that lies outside the scope of this hypothesis, showing signatures of hierarchical, nonlinear, and multi-dimensional features. This raises the question: do SAEs represent features that possess structure at odds with their motivating hypothesis? If not, does avoiding this mismatch help identify said features and gain further insights into neural network representations? To answer these questions, we take a construction-based approach and re-contextualize the popular matching pursuits (MP) algorithm from sparse coding to design MP-SAE -- an SAE that unrolls its encoder into a sequence of residual-guided steps, allowing it to capture hierarchical and nonlinearly accessible features. Comparing this architecture with existing SAEs on a mixture of synthetic and natural data settings, we show: (i) hierarchical concepts induce conditionally orthogonal features, which existing SAEs are unable to faithfully capture, and (ii) the nonlinear encoding step of MP-SAE recovers highly meaningful features, helping us unravel shared structure in the seemingly dichotomous representation spaces of different modalities in a vision-language model, hence demonstrating the assumption that useful features are solely linearly accessible is insufficient. We also show that the sequential encoder principle of MP-SAE affords an additional benefit of adaptive sparsity at inference time, which may be of independent interest. Overall, we argue our results provide credence to the idea that interpretability should begin with the phenomenology of representations, with methods emerging from assumptions that fit it.
        ]]></description>
    </item>
    <item>
        <title>GUI-Actor: Coordinate-Free Visual Grounding for GUI Agents</title>
        <link>https://arxiv.org/abs/2506.03143</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.03143v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qianhui Wu, Kanzhi Cheng, Rui Yang, Chaoyun Zhang, Jianwei Yang, Huiqiang Jiang, Jian Mu, Baolin Peng, Bo Qiao, Reuben Tan, Si Qin, Lars Liden, Qingwei Lin, Huan Zhang, Tong Zhang, Jianbing Zhang, Dongmei Zhang, Jianfeng Gao</dc:creator>
        <description><![CDATA[
            构建基于视觉语言模型（VLM）的图形用户界面（GUI）代理时，视觉定位是主要挑战之一，现有方法存在空间语义对齐弱等局限。本文提出GUI - Actor这一免坐标的GUI定位方法，引入基于注意力的动作头学习对齐标记，还设计定位验证器筛选动作区域。实验表明，该方法在多个GUI动作定位基准测试中优于现有方法，在ScreenSpot - Pro上得分更高，仅微调动作头就能达到与现有最优模型相当的性能，能赋予VLM有效定位能力。
            arXiv:2506.03143v1 Announce Type: new 
Abstract: One of the principal challenges in building VLM-powered GUI agents is visual grounding, i.e., localizing the appropriate screen region for action execution based on both the visual content and the textual plans. Most existing work formulates this as a text-based coordinate generation task. However, these approaches suffer from several limitations: weak spatial-semantic alignment, inability to handle ambiguous supervision targets, and a mismatch between the dense nature of screen coordinates and the coarse, patch-level granularity of visual features extracted by models like Vision Transformers. In this paper, we propose GUI-Actor, a VLM-based method for coordinate-free GUI grounding. At its core, GUI-Actor introduces an attention-based action head that learns to align a dedicated  token with all relevant visual patch tokens, enabling the model to propose one or more action regions in a single forward pass. In line with this, we further design a grounding verifier to evaluate and select the most plausible action region from the candidates proposed for action execution. Extensive experiments show that GUI-Actor outperforms prior state-of-the-art methods on multiple GUI action grounding benchmarks, with improved generalization to unseen screen resolutions and layouts. Notably, GUI-Actor-7B even surpasses UI-TARS-72B (38.1) on ScreenSpot-Pro, achieving scores of 40.7 with Qwen2-VL and 44.6 with Qwen2.5-VL as backbones. Furthermore, by incorporating the verifier, we find that fine-tuning only the newly introduced action head (~100M parameters for 7B model) while keeping the VLM backbone frozen is sufficient to achieve performance comparable to previous state-of-the-art models, highlighting that GUI-Actor can endow the underlying VLM with effective grounding capabilities without compromising its general-purpose strengths.
        ]]></description>
    </item>
    <item>
        <title>Towards Human-like Preference Profiling in Sequential Recommendation</title>
        <link>https://arxiv.org/abs/2506.02261</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02261v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhongyu Ouyang, Qianlong Wen, Chunhui Zhang, Yanfang Ye, Soroush Vosoughi</dc:creator>
        <description><![CDATA[
            背景：现有基于大语言模型的序列推荐系统难以模仿人类灵活、上下文感知的决策策略，忽略人类行为的结构化、动态和上下文感知机制。方法：提出偏好优化框架RecPO，对结构化反馈和上下文延迟进行建模，利用基于推断偏好层次和时间信号的自适应奖励边界。效果：在五个真实数据集上的实验表明，RecPO不仅比现有基线有性能提升，还能反映人类决策的关键特征。
            arXiv:2506.02261v1 Announce Type: cross 
Abstract: Sequential recommendation systems aspire to profile users by interpreting their interaction histories, echoing how humans make decisions by weighing experience, relative preference strength, and situational relevance. Yet, existing large language model (LLM)-based recommenders often fall short of mimicking the flexible, context-aware decision strategies humans exhibit, neglecting the structured, dynamic, and context-aware mechanisms fundamental to human behaviors. To bridge this gap, we propose RecPO, a preference optimization framework that models structured feedback and contextual delay to emulate human-like prioritization in sequential recommendation RecPO exploits adaptive reward margins based on inferred preference hierarchies and temporal signals, enabling the model to favor immediately relevant items and to distinguish between varying degrees of preference and aversion. Extensive experiments across five real-world datasets demonstrate that RecPO not only yields performance gains over state-of-the-art baselines, but also mirrors key characteristics of human decision-making: favoring timely satisfaction, maintaining coherent preferences, and exercising discernment under shifting contexts.
        ]]></description>
    </item>
    <item>
        <title>Tensor State Space-based Dynamic Multilayer Network Modeling</title>
        <link>https://arxiv.org/abs/2506.02413</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02413v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tian Lan, Jie Guo, Chen Zhang</dc:creator>
        <description><![CDATA[
            背景：理解动态多层网络中的复杂交互对多个科学领域的发展至关重要，现有模型难以捕捉其时间和跨层动态。方法：提出基于潜在空间模型框架的动态多层网络张量状态空间模型（TSSDMN），用对称Tucker分解表示潜在节点特征等，固定潜在特征让交互模式随时间演变，还采用平均场变分推理近似后验分布，开发变分期望最大化算法进行模型推理。效果：数值模拟和案例研究证明该模型有效。
            arXiv:2506.02413v1 Announce Type: cross 
Abstract: Understanding the complex interactions within dynamic multilayer networks is critical for advancements in various scientific domains. Existing models often fail to capture such networks' temporal and cross-layer dynamics. This paper introduces a novel Tensor State Space Model for Dynamic Multilayer Networks (TSSDMN), utilizing a latent space model framework. TSSDMN employs a symmetric Tucker decomposition to represent latent node features, their interaction patterns, and layer transitions. Then by fixing the latent features and allowing the interaction patterns to evolve over time, TSSDMN uniquely captures both the temporal dynamics within layers and across different layers. The model identifiability conditions are discussed. By treating latent features as variables whose posterior distributions are approximated using a mean-field variational inference approach, a variational Expectation Maximization algorithm is developed for efficient model inference. Numerical simulations and case studies demonstrate the efficacy of TSSDMN for understanding dynamic multilayer networks.
        ]]></description>
    </item>
    <item>
        <title>Automated Web Application Testing: End-to-End Test Case Generation with Large Language Models and Screen Transition Graphs</title>
        <link>https://arxiv.org/abs/2506.02529</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02529v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Nguyen-Khang Le, Quan Minh Bui, Minh Ngoc Nguyen, Hiep Nguyen, Trung Vo, Son T. Luu, Shoshin Nomura, Minh Le Nguyen</dc:creator>
        <description><![CDATA[
            背景：Web应用对现代软件生态至关重要，但因界面复杂和动态性，确保其可靠性颇具挑战，大语言模型处理动态导航流和复杂表单交互存在局限。方法：提出自动化系统，导航方面用屏幕过渡图和大语言模型建模导航流、生成测试场景；表单填充方面用状态图处理条件表单并自动生成Selenium脚本。效果：实验表明该系统能提高测试覆盖率和健壮性，推动Web应用测试发展。
            arXiv:2506.02529v1 Announce Type: cross 
Abstract: Web applications are critical to modern software ecosystems, yet ensuring their reliability remains challenging due to the complexity and dynamic nature of web interfaces. Recent advances in large language models (LLMs) have shown promise in automating complex tasks, but limitations persist in handling dynamic navigation flows and complex form interactions. This paper presents an automated system for generating test cases for two key aspects of web application testing: site navigation and form filling. For site navigation, the system employs screen transition graphs and LLMs to model navigation flows and generate test scenarios. For form filling, it uses state graphs to handle conditional forms and automates Selenium script generation. Key contributions include: (1) a novel integration of graph structures and LLMs for site navigation testing, (2) a state graph-based approach for automating form-filling test cases, and (3) a comprehensive dataset for evaluating form-interaction testing. Experimental results demonstrate the system's effectiveness in improving test coverage and robustness, advancing the state of web application testing.
        ]]></description>
    </item>
    <item>
        <title>PartComposer: Learning and Composing Part-Level Concepts from Single-Image Examples</title>
        <link>https://arxiv.org/abs/2506.03004</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.03004v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Junyu Liu, R. Kenny Jones, Daniel Ritchie</dc:creator>
        <description><![CDATA[
            背景：现有方法在有效学习细粒度概念或处理数据输入上存在困难。方法：提出PartComposer框架，构建动态数据合成管道解决单样本数据稀缺问题，通过概念预测器最大化去噪潜在变量与结构化概念代码之间的互信息，实现对概念解缠和重新组合的直接调控。效果：实现了强大的解缠和可控的组合，在混合相同或不同对象类别的概念时，优于主体和部件级别的基线方法。
            arXiv:2506.03004v1 Announce Type: cross 
Abstract: We present PartComposer: a framework for part-level concept learning from single-image examples that enables text-to-image diffusion models to compose novel objects from meaningful components. Existing methods either struggle with effectively learning fine-grained concepts or require a large dataset as input. We propose a dynamic data synthesis pipeline generating diverse part compositions to address one-shot data scarcity. Most importantly, we propose to maximize the mutual information between denoised latents and structured concept codes via a concept predictor, enabling direct regulation on concept disentanglement and re-composition supervision. Our method achieves strong disentanglement and controllable composition, outperforming subject and part-level baselines when mixing concepts from the same, or different, object categories.
        ]]></description>
    </item>
    <item>
        <title>Graph Generative Pre-trained Transformer</title>
        <link>https://arxiv.org/abs/2501.01073</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2501.01073v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiaohui Chen, Yinkai Wang, Jiaxing He, Yuanqi Du, Soha Hassoun, Xiaolin Xu, Li-Ping Liu</dc:creator>
        <description><![CDATA[
            图生成在多领域是关键任务，可对复杂关系和结构化数据建模。多数现代图生成模型用邻接矩阵表示图，本文采用将图表示为节点集和边集序列的方法，因其能高效编码图，还提出新表示法。在此基础上引入图生成预训练Transformer（G2PT），通过预测下一标记学习图结构。探索了两个下游应用的微调策略。实验表明，G2PT在通用图和分子数据集上生成性能优越，在下游任务中适应性和通用性强。
            arXiv:2501.01073v2 Announce Type: replace 
Abstract: Graph generation is a critical task in numerous domains, including molecular design and social network analysis, due to its ability to model complex relationships and structured data. While most modern graph generative models utilize adjacency matrix representations, this work revisits an alternative approach that represents graphs as sequences of node set and edge set. We advocate for this approach due to its efficient encoding of graphs and propose a novel representation. Based on this representation, we introduce the Graph Generative Pre-trained Transformer (G2PT), an auto-regressive model that learns graph structures via next-token prediction. To further exploit G2PT's capabilities as a general-purpose foundation model, we explore fine-tuning strategies for two downstream applications: goal-oriented generation and graph property prediction. We conduct extensive experiments across multiple datasets. Results indicate that G2PT achieves superior generative performance on both generic graph and molecule datasets. Furthermore, G2PT exhibits strong adaptability and versatility in downstream tasks from molecular design to property prediction. Code available at https://github.com/tufts-ml/G2PT,
        ]]></description>
    </item>
    <item>
        <title>Controllable Sequence Editing for Biological and Clinical Trajectories</title>
        <link>https://arxiv.org/abs/2502.03569</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.03569v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Michelle M. Li, Kevin Li, Yasha Ektefaie, Ying Jin, Yepeng Huang, Shvat Messica, Tianxi Cai, Marinka Zitnik</dc:creator>
        <description><![CDATA[
            背景：现有纵向序列条件生成模型在编辑时间和范围控制上存在不足，而科学和临床应用需更精准干预。方法：提出可控序列编辑模型CLEF，学习编码条件改变序列未来演变方式和时间的时间概念，对受影响时间步和变量进行有针对性编辑。效果：在6个数据集上与9个基线模型对比，CLEF使即时序列编辑精度（MAE）最高提升36.01%，延迟序列编辑（MAE）最高提升65.71%，反事实轨迹零样本条件生成（MAE）最高提升63.19% 。
            arXiv:2502.03569v2 Announce Type: replace 
Abstract: Conditional generation models for longitudinal sequences can generate new or modified trajectories given a conditioning input. While effective at generating entire sequences, these models typically lack control over the timing and scope of the edits. Most existing approaches either operate on univariate sequences or assume that the condition affects all variables and time steps. However, many scientific and clinical applications require more precise interventions, where a condition takes effect only after a specific time and influences only a subset of variables. We introduce CLEF, a controllable sequence editing model for conditional generation of immediate and delayed effects in multivariate longitudinal sequences. CLEF learns temporal concepts that encode how and when a condition alters future sequence evolution. These concepts allow CLEF to apply targeted edits to the affected time steps and variables while preserving the rest of the sequence. We evaluate CLEF on 6 datasets spanning cellular reprogramming and patient health trajectories, comparing against 9 state-of-the-art baselines. CLEF improves immediate sequence editing accuracy by up to 36.01% (MAE). Unlike prior models, CLEF enables one-step conditional generation at arbitrary future times, outperforming them in delayed sequence editing by up to 65.71% (MAE). We test CLEF under counterfactual inference assumptions and show up to 63.19% (MAE) improvement on zero-shot conditional generation of counterfactual trajectories. In a case study of patients with type 1 diabetes mellitus, CLEF identifies clinical interventions that generate realistic counterfactual trajectories shifted toward healthier outcomes.
        ]]></description>
    </item>
    <item>
        <title>Social Genome: Grounded Social Reasoning Abilities of Multimodal Models</title>
        <link>https://arxiv.org/abs/2502.15109</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.15109v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Leena Mathur, Marian Qian, Paul Pu Liang, Louis-Philippe Morency</dc:creator>
        <description><![CDATA[
            背景：社交推理能力对AI系统在社交场景中解读和回应多模态人类交流互动至关重要。方法：提出首个多模态模型细粒度、有根据的社交推理能力基准SOCIAL GENOME，包含272个互动视频和1486条人工标注推理轨迹，有5777个推理步骤，还可计算指标评估模型生成推理轨迹的语义和结构质量。效果：通过实验验证其有效性，找出性能差距，为提升多模态模型社交推理能力指明研究方向。
            arXiv:2502.15109v3 Announce Type: replace 
Abstract: Social reasoning abilities are crucial for AI systems to effectively interpret and respond to multimodal human communication and interaction within social contexts. We introduce SOCIAL GENOME, the first benchmark for fine-grained, grounded social reasoning abilities of multimodal models. SOCIAL GENOME contains 272 videos of interactions and 1,486 human-annotated reasoning traces related to inferences about these interactions. These traces contain 5,777 reasoning steps that reference evidence from visual cues, verbal cues, vocal cues, and external knowledge (contextual knowledge external to videos). SOCIAL GENOME is also the first modeling challenge to study external knowledge in social reasoning. SOCIAL GENOME computes metrics to holistically evaluate semantic and structural qualities of model-generated social reasoning traces. We demonstrate the utility of SOCIAL GENOME through experiments with state-of-the-art models, identifying performance gaps and opportunities for future research to improve the grounded social reasoning abilities of multimodal models.
        ]]></description>
    </item>
    <item>
        <title>CoT-UQ: Improving Response-wise Uncertainty Quantification in LLMs with Chain-of-Thought</title>
        <link>https://arxiv.org/abs/2502.17214</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.17214v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Boxuan Zhang, Ruqi Zhang</dc:creator>
        <description><![CDATA[
            大语言模型在生成回复时难以准确量化不确定性，现有方法多为提示级而非回复级，且计算成本高。为此，本文提出CoT - UQ框架，将思维链融入不确定性量化过程，通过提取推理步骤关键词、评估其对最终答案的重要性来捕获关键信息，进而聚合生成最终不确定性估计。在Llama系列模型上的实验表明，CoT - UQ显著优于现有方法，在逻辑和数学推理任务中，与现有方法相比，AUROC平均提升5.9%。
            arXiv:2502.17214v2 Announce Type: replace 
Abstract: Large language models (LLMs) excel in many tasks but struggle to accurately quantify uncertainty in their generated responses. This limitation makes it challenging to detect misinformation and ensure reliable decision-making. Existing uncertainty quantification (UQ) methods for LLMs are primarily prompt-wise rather than response-wise, often requiring multiple response samples, which incurs high computational costs. Moreover, LLMs have been shown to be overconfident, particularly when using reasoning steps to derive their answers. In this work, we propose CoT-UQ, a response-wise UQ framework that integrates LLMs' inherent reasoning capabilities through Chain-of-Thought (CoT) into the UQ process. CoT-UQ captures critical information during inference by extracting keywords from each reasoning step and assessing their importance to the final answer. This key reasoning information is then aggregated to produce a final uncertainty estimate. We conduct extensive experiments based on Llama Family with model sizes varying from 8B to 13B across logical and mathematical reasoning tasks. Experimental results demonstrate that CoT-UQ significantly outperforms existing UQ methods, achieving an average improvement of 5.9% AUROC compared to current UQ methods. The code is available at: https://github.com/ZBox1005/CoT-UQ.
        ]]></description>
    </item>
    <item>
        <title>Finite State Automata Inside Transformers with Chain-of-Thought: A Mechanistic Study on State Tracking</title>
        <link>https://arxiv.org/abs/2502.20129</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.20129v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yifan Zhang, Wenyu Du, Dongming Jin, Jie Fu, Zhi Jin</dc:creator>
        <description><![CDATA[
            背景：思维链（CoT）能提升大语言模型（LLMs）性能，但对Transformer+CoT可学习算法的机制理解有限。方法：评估Transformer+CoT及其变体的状态跟踪能力，确定负责跟踪世界状态的电路，提出压缩和区分两个指标；还探索跳过中间步骤、引入数据噪声和测试长度泛化三种挑战性设置。效果：证实CoT有效，模型中神经元集对每个状态的准确率近100%，表明模型内有隐式有限状态自动机（FSA）；Transformer+CoT能学习到鲁棒算法，在挑战场景中具韧性。
            arXiv:2502.20129v3 Announce Type: replace 
Abstract: Chain-of-thought (CoT) significantly enhances the performance of large language models (LLMs) across a wide range of tasks, and prior research shows that CoT can theoretically increase expressiveness. However, there is limited mechanistic understanding of the algorithms that Transformer+CoT can learn. Our key contributions are: (1) We evaluate the state tracking capabilities of Transformer+CoT and its variants, confirming the effectiveness of CoT. (2) Next, we identify the circuit (a subset of model components, responsible for tracking the world state), indicating that late-layer MLP neurons play a key role. We propose two metrics, compression and distinction, and show that the neuron sets for each state achieve nearly 100% accuracy, providing evidence of an implicit finite state automaton (FSA) embedded within the model. (3) Additionally, we explore three challenging settings: skipping intermediate steps, introducing data noises, and testing length generalization. Our results demonstrate that Transformer+CoT learns robust algorithms (FSAs), highlighting its resilience in challenging scenarios. Our code is available at https://github.com/IvanChangPKU/FSA.
        ]]></description>
    </item>
    <item>
        <title>Unnatural Languages Are Not Bugs but Features for LLMs</title>
        <link>https://arxiv.org/abs/2503.01926</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.01926v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Keyu Duan, Yiran Zhao, Zhili Feng, Jinjie Ni, Tianyu Pang, Qian Liu, Tianle Cai, Longxu Dou, Kenji Kawaguchi, Anirudh Goyal, J. Zico Kolter, Michael Qizhe Shieh</dc:creator>
        <description><![CDATA[
            背景：大语言模型处理非人类可读文本序列常被视为对齐大语言模型的缺陷。方法：对这一观点进行系统研究，揭示非自然语言（对人类难以理解但对大语言模型有语义的字符串）含有模型可用的潜在特征，还在非自然版本的指令数据集上微调模型。效果：非自然语言的潜在特征可在不同模型和任务推理中泛化，微调模型表现与自然语言训练的相当，在不同基础模型的长度控制AlpacaEval 2.0中平均胜率达49.71 。
            arXiv:2503.01926v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have been observed to process non-human-readable text sequences, such as jailbreak prompts, often viewed as a bug for aligned LLMs. In this work, we present a systematic investigation challenging this perception, demonstrating that unnatural languages - strings that appear incomprehensible to humans but maintain semantic meanings for LLMs - contain latent features usable by models. Notably, unnatural languages possess latent features that can be generalized across different models and tasks during inference. Furthermore, models fine-tuned on unnatural versions of instruction datasets perform on-par with those trained on natural language, achieving 49.71 win rates in Length-controlled AlpacaEval 2.0 in average across various base models. In addition, through comprehensive analysis, we demonstrate that LLMs process unnatural languages by filtering noise and inferring contextual meaning from filtered words.
        ]]></description>
    </item>
    <item>
        <title>Generator-Assistant Stepwise Rollback Framework for Large Language Model Agent</title>
        <link>https://arxiv.org/abs/2503.02519</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.02519v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xingzuo Li, Kehai Chen, Yunfei Long, Xuefeng Bai, Yong Xu, Min Zhang</dc:creator>
        <description><![CDATA[
            背景：大语言模型（LLM）智能体的逐步推理框架存在单向性问题，中间思维无论对错都会纳入轨迹，导致不可逆的错误传播。方法：提出生成器 - 助手逐步回滚（GA - Rollback）框架，用生成器与环境交互，助手检查生成器的动作，检测到错误则触发回滚，还引入两种适配策略。效果：在三个常用基准测试中，GA - Rollback 较多个强基线有显著提升，且可作为即插即用模块与其他方法无缝集成。
            arXiv:2503.02519v3 Announce Type: replace 
Abstract: Large language model (LLM) agents typically adopt a step-by-step reasoning framework, in which they interleave the processes of thinking and acting to accomplish the given task. However, this paradigm faces a deep-rooted one-pass issue whereby each generated intermediate thought is plugged into the trajectory regardless of its correctness, which can cause irreversible error propagation. To address the issue, this paper proposes a novel framework called Generator-Assistant Stepwise Rollback (GA-Rollback) to induce better decision-making for LLM agents. Particularly, GA-Rollback utilizes a generator to interact with the environment and an assistant to examine each action produced by the generator, where the assistant triggers a rollback operation upon detection of incorrect actions. Moreover, we introduce two additional strategies tailored for the rollback scenario to further improve its effectiveness. Extensive experiments show that GA-Rollback achieves significant improvements over several strong baselines on three widely used benchmarks. Our analysis further reveals that GA-Rollback can function as a robust plug-and-play module, integrating seamlessly with other methods.
        ]]></description>
    </item>
    <item>
        <title>DAST: Difficulty-Adaptive Slow-Thinking for Large Reasoning Models</title>
        <link>https://arxiv.org/abs/2503.04472</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.04472v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yi Shen, Jian Zhang, Jieyun Huang, Shuming Shi, Wenjing Zhang, Jiangze Yan, Ning Wang, Kai Wang, Zhaoxiang Liu, Shiguo Lian</dc:creator>
        <description><![CDATA[
            背景：现有慢思考推理模型在复杂推理任务表现出色，但存在对简单问题过度思考、浪费计算资源的问题，而现有缓解策略可能影响难题推理效果。方法：提出DAST框架，用Token Length Budget（TLB）指标量化难度，通过预算感知奖励塑造和预算偏好优化实现该框架，对简单任务过长回复进行惩罚，激励复杂问题充分推理。效果：在不同数据集和模型规模实验表明，平均减少超30%的token使用量，且保留复杂问题推理准确性。
            arXiv:2503.04472v2 Announce Type: replace 
Abstract: Recent advancements in slow thinking reasoning models have shown exceptional performance in complex reasoning tasks. However, these models often exhibit overthinking (generating redundant reasoning steps for simple problems), leading to excessive computational resource usage. While current mitigation strategies uniformly reduce reasoning tokens, they risk degrading performance on challenging tasks that require extended reasoning. This paper introduces Difficulty-Adaptive Slow Thinking (DAST), a novel framework that enables models to autonomously adjust the length of Chain-of-Thought (CoT) based on problem difficulty. We first propose a Token Length Budget (TLB) metric to quantify difficulty, then leverage budget-aware reward shaping and budget preference optimization to implement DAST. DAST penalizes overlong responses for simple tasks while incentivizing sufficient reasoning for complex problems. Experiments on diverse datasets and model scales demonstrate that DAST effectively mitigates overthinking (reducing token usage by over 30\% on average) while preserving reasoning accuracy on complex problems. Our codes and models are available at https://github.com/AnonymousUser0520/AnonymousRepo01.
        ]]></description>
    </item>
    <item>
        <title>Recall with Reasoning: Chain-of-Thought Distillation for Mamba's Long-Context Memory and Extrapolation</title>
        <link>https://arxiv.org/abs/2505.03320</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.03320v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Junyu Ma, Tianqing Fang, Zhisong Zhang, Hongming Zhang, Haitao Mi, Dong Yu</dc:creator>
        <description><![CDATA[
            背景：Mamba理论上的无限上下文潜力在序列远超训练长度时受限。方法：采用简单有效的“带推理的回忆”（RwR）方法，从教师模型中提炼思维链（CoT）摘要，在微调时将这些摘要作为CoT提示前置，让Mamba主动回忆和推理长上下文。效果：在LONGMEMEVAL和HELMET上的实验表明，RwR在相似预训练条件下，提升了Mamba在长上下文上的性能，且保留了短上下文能力，还无需架构改变。
            arXiv:2505.03320v2 Announce Type: replace 
Abstract: Mamba's theoretical infinite-context potential is limited in practice when sequences far exceed training lengths. This work explores unlocking Mamba's long-context memory ability by a simple-yet-effective method, Recall with Reasoning (RwR), by distilling chain-of-thought (CoT) summarization from a teacher model. Specifically, RwR prepends these summarization as CoT prompts during fine-tuning, teaching Mamba to actively recall and reason over long contexts. Experiments on LONGMEMEVAL and HELMET show RwR boosts Mamba's long-context performance against comparable Transformer/hybrid baselines under similar pretraining conditions, while preserving short-context capabilities, all without architectural changes.
        ]]></description>
    </item>
    <item>
        <title>Towards Efficient Online Tuning of VLM Agents via Counterfactual Soft Reinforcement Learning</title>
        <link>https://arxiv.org/abs/2505.03792</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.03792v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Lang Feng, Weihao Tan, Zhiyi Lyu, Longtao Zheng, Haiyang Xu, Ming Yan, Fei Huang, Bo An</dc:creator>
        <description><![CDATA[
            背景：在线微调视觉语言模型（VLM）智能体虽有潜力，但开放式文本动作空间和非端到端动作生成给强化学习（RL）的有效在线探索带来挑战。方法：提出反事实软强化学习（CoSo）方法，利用反事实推理动态评估单个标记对后处理动作的因果影响，优先探索关键标记。效果：理论分析证明其收敛性和策略改进保证，实证评估显示在多任务中能提高探索效率，取得一致性能提升。
            arXiv:2505.03792v2 Announce Type: replace 
Abstract: Online fine-tuning vision-language model (VLM) agents with reinforcement learning (RL) has shown promise for equipping agents with multi-step, goal-oriented capabilities in dynamic environments. However, their open-ended textual action space and non-end-to-end nature of action generation present significant challenges to effective online exploration in RL, e.g., explosion of the exploration space. We propose a novel online fine-tuning method, Counterfactual Soft Reinforcement Learning (CoSo), better suited to the textual output space of VLM agents. Compared to prior methods that assign uniform uncertainty to all tokens, CoSo leverages counterfactual reasoning to dynamically assess the causal influence of individual tokens on post-processed actions. By prioritizing the exploration of action-critical tokens while reducing the impact of semantically redundant or low-impact tokens, CoSo enables a more targeted and efficient online rollout process. We provide theoretical analysis proving CoSo's convergence and policy improvement guarantees, and extensive empirical evaluations supporting CoSo's effectiveness. Our results across a diverse set of agent tasks, including Android device control, card gaming, and embodied AI, highlight its remarkable ability to enhance exploration efficiency and deliver consistent performance gains. The code is available at https://github.com/langfengQ/CoSo.
        ]]></description>
    </item>
    <item>
        <title>Learning Soft Sparse Shapes for Efficient Time-Series Classification</title>
        <link>https://arxiv.org/abs/2505.06892</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.06892v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhen Liu, Yicheng Luo, Boyuan Li, Emadeldeen Eldele, Min Wu, Qianli Ma</dc:creator>
        <description><![CDATA[
            背景：在时间序列分类中，现有基于形状特征的方法在选择判别性形状时可能排除有益形状，且忽略形状对分类性能的不同贡献。方法：提出Soft sparse Shapes（SoftShape）模型，引入软形状稀疏化和软形状学习模块，前者基于分类贡献分数转换形状表示，后者通过稀疏化的软形状学习时间模式，还利用可学习路由器和共享专家网络分别学习形状内和形状间模式。效果：该模型优于现有方法，且结果具有可解释性。
            arXiv:2505.06892v2 Announce Type: replace 
Abstract: Shapelets are discriminative subsequences (or shapes) with high interpretability in time series classification. Due to the time-intensive nature of shapelet discovery, existing shapelet-based methods mainly focus on selecting discriminative shapes while discarding others to achieve candidate subsequence sparsification. However, this approach may exclude beneficial shapes and overlook the varying contributions of shapelets to classification performance. To this end, we propose a Soft sparse Shapes (SoftShape) model for efficient time series classification. Our approach mainly introduces soft shape sparsification and soft shape learning blocks. The former transforms shapes into soft representations based on classification contribution scores, merging lower-scored ones into a single shape to retain and differentiate all subsequence information. The latter facilitates intra- and inter-shape temporal pattern learning, improving model efficiency by using sparsified soft shapes as inputs. Specifically, we employ a learnable router to activate a subset of class-specific expert networks for intra-shape pattern learning. Meanwhile, a shared expert network learns inter-shape patterns by converting sparsified shapes into sequences. Extensive experiments show that SoftShape outperforms state-of-the-art methods and produces interpretable results.
        ]]></description>
    </item>
    <item>
        <title>JanusDNA: A Powerful Bi-directional Hybrid DNA Foundation Model</title>
        <link>https://arxiv.org/abs/2505.17257</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17257v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qihao Duan, Bingding Huang, Zhenqiao Song, Irina Lehmann, Lei Gu, Roland Eils, Benjamin Wild</dc:creator>
        <description><![CDATA[
            这是一篇关于多模态大模型处理序列数据的论文。背景是大语言模型应用于基因组学面临诸多挑战，如传统模型难以捕捉长距离依赖、标准训练方法不适合DNA的双向特性。方法是提出首个双向DNA基础模型JanusDNA，采用混合架构结合自回归和掩码建模优势。效果显著，能在单块80GB GPU上处理100万个碱基对，在三个基因组表征基准测试中取得新的最优结果，超越参数多250倍的模型。
            arXiv:2505.17257v2 Announce Type: replace 
Abstract: Large language models (LLMs) have revolutionized natural language processing and are increasingly applied to other sequential data types, including genetic sequences. However, adapting LLMs to genomics presents significant challenges. Capturing complex genomic interactions requires modeling long-range dependencies within DNA sequences, where interactions often span over 10,000 base pairs, even within a single gene, posing substantial computational burdens under conventional model architectures and training paradigms. Moreover, standard LLM training approaches are suboptimal for DNA: autoregressive training, while efficient, supports only unidirectional understanding. However, DNA is inherently bidirectional, e.g., bidirectional promoters regulate transcription in both directions and account for nearly 11% of human gene expression. Masked language models (MLMs) allow bidirectional understanding but are inefficient, as only masked tokens contribute to the loss per step. To address these limitations, we introduce JanusDNA, the first bidirectional DNA foundation model built upon a novel pretraining paradigm that combines the optimization efficiency of autoregressive modeling with the bidirectional comprehension of masked modeling. JanusDNA adopts a hybrid Mamba, Attention and Mixture of Experts (MoE) architecture, combining long-range modeling of Attention with efficient sequential learning of Mamba. MoE layers further scale model capacity via sparse activation while keeping computational cost low. Notably, JanusDNA processes up to 1 million base pairs at single nucleotide resolution on a single 80GB GPU. Extensive experiments and ablations show JanusDNA achieves new SOTA results on three genomic representation benchmarks, outperforming models with 250x more activated parameters. Code: https://github.com/Qihao-Duan/JanusDNA
        ]]></description>
    </item>
    <item>
        <title>G1: Teaching LLMs to Reason on Graphs with Reinforcement Learning</title>
        <link>https://arxiv.org/abs/2505.18499</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.18499v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiaojun Guo, Ang Li, Yifei Wang, Stefanie Jegelka, Yisen Wang</dc:creator>
        <description><![CDATA[
            背景：大语言模型在图相关任务中能力有限，此前方法因缺乏大规模通用图数据而面临挑战。方法：提出G1方法，利用强化学习处理合成图论任务，并创建包含50个不同难度图论任务、10万训练数据和5000测试数据的数据集Erdős。效果：G1显著提升了图推理能力，微调的3B模型超越Qwen2.5 - 72B - Instruct，强化学习训练的模型在零样本泛化方面表现出色，且不影响一般推理能力。
            arXiv:2505.18499v2 Announce Type: replace 
Abstract: Although Large Language Models (LLMs) have demonstrated remarkable progress, their proficiency in graph-related tasks remains notably limited, hindering the development of truly general-purpose models. Previous attempts, including pretraining graph foundation models or employing supervised fine-tuning, often face challenges such as the scarcity of large-scale, universally represented graph data. We introduce G1, a simple yet effective approach demonstrating that Reinforcement Learning (RL) on synthetic graph-theoretic tasks can significantly scale LLMs' graph reasoning abilities. To enable RL training, we curate Erd\~os, the largest graph reasoning dataset to date comprising 50 diverse graph-theoretic tasks of varying difficulty levels, 100k training data and 5k test data, all drived from real-world graphs. With RL on Erd\~os, G1 obtains substantial improvements in graph reasoning, where our finetuned 3B model even outperforms Qwen2.5-72B-Instruct (24x size). RL-trained models also show strong zero-shot generalization to unseen tasks, domains, and graph encoding schemes, including other graph-theoretic benchmarks as well as real-world node classification and link prediction tasks, without compromising general reasoning abilities. Our findings offer an efficient, scalable path for building strong graph reasoners by finetuning LLMs with RL on graph-theoretic tasks, which combines the strengths of pretrained LLM capabilities with abundant, automatically generated synthetic data, suggesting that LLMs possess graph understanding abilities that RL can elicit successfully. Our implementation is open-sourced at https://github.com/PKU-ML/G1, with models and datasets hosted on Hugging Face collections https://huggingface.co/collections/PKU-ML/g1-683d659e992794fc99618cf2 for broader accessibility.
        ]]></description>
    </item>
    <item>
        <title>InfoChartQA: A Benchmark for Multimodal Question Answering on Infographic Charts</title>
        <link>https://arxiv.org/abs/2505.19028</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.19028v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Minzhi Lin, Tianchi Xie, Mengchen Liu, Yilin Ye, Changjian Chen, Shixia Liu</dc:creator>
        <description><![CDATA[
            背景：理解含设计驱动视觉元素的信息图表，对多模态大语言模型（MLLMs）提出挑战，现有视觉问答基准在评估其相关能力上存在不足。方法：引入InfoChartQA基准，含5642对信息图表和普通图表，设计基于视觉元素的问题。效果：评估20个MLLMs发现，其在信息图表上性能大幅下降，尤其是与隐喻相关的视觉元素问题。该基准能进行细粒度错误分析和消融研究，为推进MLLMs在信息图表理解方面提供新机会。
            arXiv:2505.19028v3 Announce Type: replace 
Abstract: Understanding infographic charts with design-driven visual elements (e.g., pictograms, icons) requires both visual recognition and reasoning, posing challenges for multimodal large language models (MLLMs). However, existing visual-question answering benchmarks fall short in evaluating these capabilities of MLLMs due to the lack of paired plain charts and visual-element-based questions. To bridge this gap, we introduce InfoChartQA, a benchmark for evaluating MLLMs on infographic chart understanding. It includes 5,642 pairs of infographic and plain charts, each sharing the same underlying data but differing in visual presentations. We further design visual-element-based questions to capture their unique visual designs and communicative intent. Evaluation of 20 MLLMs reveals a substantial performance decline on infographic charts, particularly for visual-element-based questions related to metaphors. The paired infographic and plain charts enable fine-grained error analysis and ablation studies, which highlight new opportunities for advancing MLLMs in infographic chart understanding. We release InfoChartQA at https://github.com/CoolDawnAnt/InfoChartQA.
        ]]></description>
    </item>
    <item>
        <title>Dynamic-I2V: Exploring Image-to-Video Generation Models via Multimodal LLM</title>
        <link>https://arxiv.org/abs/2505.19901</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.19901v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Peng Liu, Xiaoming Ren, Fengkai Liu, Qingsong Xie, Quanlong Zheng, Yanhao Zhang, Haonan Lu, Yujiu Yang</dc:creator>
        <description><![CDATA[
            背景：现有图像到视频（I2V）生成方法在复杂场景面临挑战，且当前I2V基准存在偏向低动态视频的问题。方法：提出Dynamic - I2V框架，集成多模态大语言模型（MLLMs）联合编码视觉和文本条件；还提出DIVE评估基准。效果：该模型显著提升合成视频的运动可控性和时间连贯性，支持多样条件输入。定量实验显示，相比现有方法，其动态范围、可控性和质量分别提升42.5%、7.9%和11.8%。
            arXiv:2505.19901v3 Announce Type: replace 
Abstract: Recent advancements in image-to-video (I2V) generation have shown promising performance in conventional scenarios. However, these methods still encounter significant challenges when dealing with complex scenes that require a deep understanding of nuanced motion and intricate object-action relationships. To address these challenges, we present Dynamic-I2V, an innovative framework that integrates Multimodal Large Language Models (MLLMs) to jointly encode visual and textual conditions for a diffusion transformer (DiT) architecture. By leveraging the advanced multimodal understanding capabilities of MLLMs, our model significantly improves motion controllability and temporal coherence in synthesized videos. The inherent multimodality of Dynamic-I2V further enables flexible support for diverse conditional inputs, extending its applicability to various downstream generation tasks. Through systematic analysis, we identify a critical limitation in current I2V benchmarks: a significant bias towards favoring low-dynamic videos, stemming from an inadequate balance between motion complexity and visual quality metrics. To resolve this evaluation gap, we propose DIVE - a novel assessment benchmark specifically designed for comprehensive dynamic quality measurement in I2V generation. In conclusion, extensive quantitative and qualitative experiments confirm that Dynamic-I2V attains state-of-the-art performance in image-to-video generation, particularly revealing significant improvements of 42.5%, 7.9%, and 11.8% in dynamic range, controllability, and quality, respectively, as assessed by the DIVE metric in comparison to existing methods.
        ]]></description>
    </item>
    <item>
        <title>Generating Hypotheses of Dynamic Causal Graphs in Neuroscience: Leveraging Generative Factor Models of Observed Time Series</title>
        <link>https://arxiv.org/abs/2505.20697</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.20697v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zachary C. Brown, David Carlson</dc:creator>
        <description><![CDATA[
            背景：现有机器学习方法在生成科学假设时多假定因果关系随时间不变，限制了其在大脑等动态系统中的应用，且部分技术存在线性限制等问题。方法：提出一种将动态图建模为静态图条件加权叠加的新方法，每个静态图可捕捉非线性关系。效果：在部分实验中，相比基线平均提高预测动态因果模式的f1分数约22 - 28%，部分改进超60%，对真实大脑数据的案例研究展示了其揭示与特定行为状态相关关系的能力。
            arXiv:2505.20697v2 Announce Type: replace 
Abstract: The field of hypothesis generation promises to reduce costs in neuroscience by narrowing the range of interventional studies needed to study various phenomena. Existing machine learning methods can generate scientific hypotheses from complex datasets, but many approaches assume causal relationships are static over time, limiting their applicability to systems with dynamic, state-dependent behavior, such as the brain. While some techniques attempt dynamic causal discovery through factor models, they often restrict relationships to linear patterns or impose other simplifying assumptions. We propose a novel method that models dynamic graphs as a conditionally weighted superposition of static graphs, where each static graph can capture nonlinear relationships. This approach enables the detection of complex, time-varying interactions between variables beyond linear limitations. Our method improves f1-scores of predicted dynamic causal patterns by roughly 22-28% on average over baselines in some of our experiments, with some improvements reaching well over 60%. A case study on real brain data demonstrates our method's ability to uncover relationships linked to specific behavioral states, offering valuable insights into neural dynamics.
        ]]></description>
    </item>
    <item>
        <title>Threading the Needle: Reweaving Chain-of-Thought Reasoning to Explain Human Label Variation</title>
        <link>https://arxiv.org/abs/2505.23368</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.23368v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Beiduo Chen, Yang Janet Liu, Anna Korhonen, Barbara Plank</dc:creator>
        <description><![CDATA[
            背景：推理调优的大语言模型（LLM）兴起，其在给出最终答案前生成思维链（CoT），为理解人类标注差异带来新契机。此前工作多基于给定答案生成解释，而CoT可在生成答案前隐式嵌入各答案选项的理由。方法：提出基于LLM的新流程，用话语分割器从CoT中提取各答案选项的支持和反对陈述；提出基于排名的HLV评估框架。效果：在三个数据集上，该方法优于直接生成法和基线，且排名方法与人类更契合，凸显其有效性。
            arXiv:2505.23368v2 Announce Type: replace 
Abstract: The recent rise of reasoning-tuned Large Language Models (LLMs)--which generate chains of thought (CoTs) before giving the final answer--has attracted significant attention and offers new opportunities for gaining insights into human label variation, which refers to plausible differences in how multiple annotators label the same data instance. Prior work has shown that LLM-generated explanations can help align model predictions with human label distributions, but typically adopt a reverse paradigm: producing explanations based on given answers. In contrast, CoTs provide a forward reasoning path that may implicitly embed rationales for each answer option, before generating the answers. We thus propose a novel LLM-based pipeline enriched with linguistically-grounded discourse segmenters to extract supporting and opposing statements for each answer option from CoTs with improved accuracy. We also propose a rank-based HLV evaluation framework that prioritizes the ranking of answers over exact scores, which instead favor direct comparison of label distributions. Our method outperforms a direct generation method as well as baselines on three datasets, and shows better alignment of ranking methods with humans, highlighting the effectiveness of our approach.
        ]]></description>
    </item>
    <item>
        <title>R-KV: Redundancy-aware KV Cache Compression for Training-Free Reasoning Models Acceleration</title>
        <link>https://arxiv.org/abs/2505.24133</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.24133v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zefan Cai, Wen Xiao, Hanshi Sun, Cheng Luo, Yikai Zhang, Ke Wan, Yucheng Li, Yeyang Zhou, Li-Wen Chang, Jiuxiang Gu, Zhen Dong, Anima Anandkumar, Abedelkadir Asi, Junjie Hu</dc:creator>
        <description><![CDATA[
            背景：推理模型在自我反思和思维链推理中表现出色，但推理时会产生过长输出，导致键值（KV）缓存过大，现有KV缓存压缩方法会导致推理失败。方法：提出针对推理模型冗余标记的冗余感知KV缓存压缩方法（R - KV）。效果：仅用10%的KV缓存就能保留近100%的完整KV缓存性能，16%的KV缓存甚至能达到105%的性能，还能节省90%的内存，吞吐量是标准思维链推理的6.6倍，在两个数学推理数据集上均优于现有基线。
            arXiv:2505.24133v2 Announce Type: replace 
Abstract: Reasoning models have demonstrated impressive performance in self-reflection and chain-of-thought reasoning. However, they often produce excessively long outputs, leading to prohibitively large key-value (KV) caches during inference. While chain-of-thought inference significantly improves performance on complex reasoning tasks, it can also lead to reasoning failures when deployed with existing KV cache compression approaches. To address this, we propose Redundancy-aware KV Cache Compression for Reasoning models (R-KV), a novel method specifically targeting redundant tokens in reasoning models. Our method preserves nearly 100% of the full KV cache performance using only 10% of the KV cache, substantially outperforming existing KV cache baselines, which reach only 60% of the performance. Remarkably, R-KV even achieves 105% of full KV cache performance with 16% of the KV cache. This KV-cache reduction also leads to a 90% memory saving and a 6.6X throughput over standard chain-of-thought reasoning inference. Experimental results show that R-KV consistently outperforms existing KV cache compression baselines across two mathematical reasoning datasets.
        ]]></description>
    </item>
    <item>
        <title>Enhancing Clinical Multiple-Choice Questions Benchmarks with Knowledge Graph Guided Distractor Generation</title>
        <link>https://arxiv.org/abs/2506.00612</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.00612v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Running Yang, Wenlong Deng, Minghui Chen, Yuyin Zhou, Xiaoxiao Li</dc:creator>
        <description><![CDATA[
            临床诊断和治疗等任务需强大决策能力，严格评估基准对评估大语言模型可靠性至关重要。本文提出知识引导的数据增强框架，通过生成干扰项提升临床多项选择题数据集难度。该方法在医学知识图谱上进行多步、语义引导的游走，识别干扰路径，引导大语言模型生成更具误导性的干扰项。将其应用于六个医学问答基准，结果显示该方法会降低现有大模型准确率，可用于对医学大模型进行更可靠、有效的评估。
            arXiv:2506.00612v2 Announce Type: replace 
Abstract: Clinical tasks such as diagnosis and treatment require strong decision-making abilities, highlighting the importance of rigorous evaluation benchmarks to assess the reliability of large language models (LLMs). In this work, we introduce a knowledge-guided data augmentation framework that enhances the difficulty of clinical multiple-choice question (MCQ) datasets by generating distractors (i.e., incorrect choices that are similar to the correct one and may confuse existing LLMs). Using our KG-based pipeline, the generated choices are both clinically plausible and deliberately misleading. Our approach involves multi-step, semantically informed walks on a medical knowledge graph to identify distractor paths-associations that are medically relevant but factually incorrect-which then guide the LLM in crafting more deceptive distractors. We apply the designed knowledge graph guided distractor generation (KGGDG) pipline, to six widely used medical QA benchmarks and show that it consistently reduces the accuracy of state-of-the-art LLMs. These findings establish KGGDG as a powerful tool for enabling more robust and diagnostic evaluations of medical LLMs.
        ]]></description>
    </item>
    <item>
        <title>Pi-SQL: Enhancing Text-to-SQL with Fine-Grained Guidance from Pivot Programming Languages</title>
        <link>https://arxiv.org/abs/2506.00912</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.00912v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yongdong chi, Hanqing Wang, Zonghan Yang, Jian Yang, Xiao Yan, Yun Chen, Guanhua Chen</dc:creator>
        <description><![CDATA[
            背景：文本到SQL旨在将自然语言查询转换为可执行SQL程序，但现有基于提示的方法因文本与低资源SQL程序语义差距大，准确性受限。方法：提出Pi - SQL，引入高资源Python程序作为枢纽，先生成提供细粒度逐步指导的Python程序，再依其指导生成SQL程序，并从不同策略生成的候选中选择。效果：最终SQL程序与参考Python程序查询结果匹配，执行速度更优，基于奖励的有效效率得分比最佳基线高4.55，执行准确率最多提高3.20。
            arXiv:2506.00912v2 Announce Type: replace 
Abstract: Text-to-SQL transforms the user queries from natural language to executable SQL programs, enabling non-experts to interact with complex databases. Existing prompt-based methods craft meticulous text guidelines and examples to facilitate SQL generation, but their accuracy is hindered by the large semantic gap between the texts and the low-resource SQL programs. In this work, we propose Pi-SQL, which incorporates the high-resource Python program as a pivot to bridge between the natural language query and SQL program. In particular, Pi-SQL first generates Python programs that provide fine-grained step-by-step guidelines in their code blocks or comments, and then produces an SQL program following the guidance of each Python program. The final SQL program matches the reference Python program's query results and, through selection from candidates generated by different strategies, achieves superior execution speed, with a reward-based valid efficiency score up to 4.55 higher than the best-performing baseline. Extensive experiments demonstrate the effectiveness of Pi-SQL, which improves the execution accuracy of the best-performing baseline by up to 3.20.
        ]]></description>
    </item>
    <item>
        <title>Kimi k1.5: Scaling Reinforcement Learning with LLMs</title>
        <link>https://arxiv.org/abs/2501.12599</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2501.12599v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kimi Team, Angang Du, Bofei Gao, Bowei Xing, Changjiu Jiang, Cheng Chen, Cheng Li, Chenjun Xiao, Chenzhuang Du, Chonghua Liao, Chuning Tang, Congcong Wang, Dehao Zhang, Enming Yuan, Enzhe Lu, Fengxiang Tang, Flood Sung, Guangda Wei, Guokun Lai, Haiqing Guo, Han Zhu, Hao Ding, Hao Hu, Hao Yang, Hao Zhang, Haotian Yao, Haotian Zhao, Haoyu Lu, Haoze Li, Haozhen Yu, Hongcheng Gao, Huabin Zheng, Huan Yuan, Jia Chen, Jianhang Guo, Jianlin Su, Jianzhou Wang, Jie Zhao, Jin Zhang, Jingyuan Liu, Junjie Yan, Junyan Wu, Lidong Shi, Ling Ye, Longhui Yu, Mengnan Dong, Neo Zhang, Ningchen Ma, Qiwei Pan, Qucheng Gong, Shaowei Liu, Shengling Ma, Shupeng Wei, Sihan Cao, Siying Huang, Tao Jiang, Weihao Gao, Weimin Xiong, Weiran He, Weixiao Huang, Weixin Xu, Wenhao Wu, Wenyang He, Xianghui Wei, Xianqing Jia, Xingzhe Wu, Xinran Xu, Xinxing Zu, Xinyu Zhou, Xuehai Pan, Y. Charles, Yang Li, Yangyang Hu, Yangyang Liu, Yanru Chen, Yejie Wang, Yibo Liu, Yidao Qin, Yifeng Liu, Ying Yang, Yiping Bao, Yulun Du, Yuxin Wu, Yuzhi Wang, Zaida Zhou, Zhaoji Wang, Zhaowei Li, Zhen Zhu, Zheng Zhang, Zhexu Wang, Zhilin Yang, Zhiqi Huang, Zihao Huang, Ziyao Xu, Zonghan Yang, Zongyu Lin</dc:creator>
        <description><![CDATA[
            背景：基于下一个标记预测的语言模型预训练受限于训练数据量，此前强化学习（RL）相关工作未取得有竞争力的结果。方法：介绍最新多模态大语言模型Kimi k1.5的训练实践，包括RL训练技术、多模态数据方法和基础设施优化，采用长上下文扩展和改进的策略优化方法。效果：在多个基准测试和模态上达到了最先进的推理性能，如AIME得77.5分等；长2短方法也取得优异结果，大幅超越现有短思维链模型。
            arXiv:2501.12599v4 Announce Type: replace-cross 
Abstract: Language model pretraining with next token prediction has proved effective for scaling compute but is limited to the amount of available training data. Scaling reinforcement learning (RL) unlocks a new axis for the continued improvement of artificial intelligence, with the promise that large language models (LLMs) can scale their training data by learning to explore with rewards. However, prior published work has not produced competitive results. In light of this, we report on the training practice of Kimi k1.5, our latest multi-modal LLM trained with RL, including its RL training techniques, multi-modal data recipes, and infrastructure optimization. Long context scaling and improved policy optimization methods are key ingredients of our approach, which establishes a simplistic, effective RL framework without relying on more complex techniques such as Monte Carlo tree search, value functions, and process reward models. Notably, our system achieves state-of-the-art reasoning performance across multiple benchmarks and modalities -- e.g., 77.5 on AIME, 96.2 on MATH 500, 94-th percentile on Codeforces, 74.9 on MathVista -- matching OpenAI's o1. Moreover, we present effective long2short methods that use long-CoT techniques to improve short-CoT models, yielding state-of-the-art short-CoT reasoning results -- e.g., 60.8 on AIME, 94.6 on MATH500, 47.3 on LiveCodeBench -- outperforming existing short-CoT models such as GPT-4o and Claude Sonnet 3.5 by a large margin (up to +550%).
        ]]></description>
    </item>
    <item>
        <title>X-Driver: Explainable Autonomous Driving with Vision-Language Models</title>
        <link>https://arxiv.org/abs/2505.05098</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.05098v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wei Liu, Jiyuan Zhang, Binxiong Zheng, Yufeng Hu, Yingzhan Lin, Zengfeng Zeng</dc:creator>
        <description><![CDATA[
            背景：端到端自动驾驶虽有进展，但现有框架在闭环评估中成功率低，限制了实际应用。方法：提出X - Driver，这是一个用于闭环自动驾驶的统一多模态大语言模型框架，利用思维链和自回归建模提升感知与决策能力。效果：在CARLA仿真环境多个自动驾驶任务中验证，实验结果显示其闭环性能超越当前最优水平，还提高了驾驶决策的可解释性，凸显了结构化推理在端到端驾驶中的重要性。
            arXiv:2505.05098v2 Announce Type: replace-cross 
Abstract: End-to-end autonomous driving has advanced significantly, offering benefits such as system simplicity and stronger driving performance in both open-loop and closed-loop settings than conventional pipelines. However, existing frameworks still suffer from low success rates in closed-loop evaluations, highlighting their limitations in real-world deployment. In this paper, we introduce X-Driver, a unified multi-modal large language models(MLLMs) framework designed for closed-loop autonomous driving, leveraging Chain-of-Thought(CoT) and autoregressive modeling to enhance perception and decision-making. We validate X-Driver across multiple autonomous driving tasks using public benchmarks in CARLA simulation environment, including Bench2Drive[6]. Our experimental results demonstrate superior closed-loop performance, surpassing the current state-of-the-art(SOTA) while improving the interpretability of driving decisions. These findings underscore the importance of structured reasoning in end-to-end driving and establish X-Driver as a strong baseline for future research in closed-loop autonomous driving.
        ]]></description>
    </item>
    <item>
        <title>GPR: Empowering Generation with Graph-Pretrained Retriever</title>
        <link>https://arxiv.org/abs/2506.00261</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.00261v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiaochen Wang, Zongyu Wu, Yuan Zhong, Xiang Zhang, Suhang Wang, Fenglong Ma</dc:creator>
        <description><![CDATA[
            背景：图检索增强生成（GRAG）对特定图的检索器要求高，现有检索器常依赖纯文本预训练的语言模型，存在领域不对齐和忽略结构的问题。方法：提出GPR，一种直接在知识图谱上预训练的基于图的检索器，通过大语言模型引导的图增强使自然语言问题与相关子图对齐，并采用结构感知目标学习细粒度检索策略。效果：在两个数据集、三个大语言模型骨干和五个基线的实验中，GPR持续提升检索质量和下游生成效果。
            arXiv:2506.00261v2 Announce Type: replace-cross 
Abstract: Graph retrieval-augmented generation (GRAG) places high demands on graph-specific retrievers. However, existing retrievers often rely on language models pretrained on plain text, limiting their effectiveness due to domain misalignment and structure ignorance. To address these challenges, we propose GPR, a graph-based retriever pretrained directly on knowledge graphs. GPR aligns natural language questions with relevant subgraphs through LLM-guided graph augmentation and employs a structure-aware objective to learn fine-grained retrieval strategies. Experiments on two datasets, three LLM backbones, and five baselines show that GPR consistently improves both retrieval quality and downstream generation, demonstrating its effectiveness as a robust retrieval solution for GRAG.
        ]]></description>
    </item>
    <item>
        <title>No Audiogram: Leveraging Existing Scores for Personalized Speech Intelligibility Prediction</title>
        <link>https://arxiv.org/abs/2506.02039</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02039v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Haoshuai Zhou, Changgeng Mo, Boxuan Cao, Linkai Li, Shan Xiang Wang</dc:creator>
        <description><![CDATA[
            个性化语音可懂度预测具有挑战性，以往方法多依赖听力图，其仅能捕捉纯音听力阈值，精度有限。本文提出一种新方法，利用个体现有的可懂度数据预测其在新音频上的表现。引入基于支持样本的可懂度预测网络（SSIPNet），该深度学习模型借助语音基础模型，从多组（音频，得分）对构建听者语音识别能力的高维表示，实现对未见音频的准确预测。在Clarity Prediction Challenge数据集上的结果显示，即使支持对数量少，该方法也优于基于听力图的预测。
            arXiv:2506.02039v1 Announce Type: new 
Abstract: Personalized speech intelligibility prediction is challenging. Previous approaches have mainly relied on audiograms, which are inherently limited in accuracy as they only capture a listener's hearing threshold for pure tones. Rather than incorporating additional listener features, we propose a novel approach that leverages an individual's existing intelligibility data to predict their performance on new audio. We introduce the Support Sample-Based Intelligibility Prediction Network (SSIPNet), a deep learning model that leverages speech foundation models to build a high-dimensional representation of a listener's speech recognition ability from multiple support (audio, score) pairs, enabling accurate predictions for unseen audio. Results on the Clarity Prediction Challenge dataset show that, even with a small number of support (audio, score) pairs, our method outperforms audiogram-based predictions. Our work presents a new paradigm for personalized speech intelligibility prediction.
        ]]></description>
    </item>
    <item>
        <title>Evaluating the Effectiveness of Pre-Trained Audio Embeddings for Classification of Parkinson's Disease Speech Data</title>
        <link>https://arxiv.org/abs/2506.02078</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02078v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Emmy Postma, Cristian Tejedor-Garcia</dc:creator>
        <description><![CDATA[
            语音障碍是帕金森病的常见生物标志物，推动了利用语音数据进行诊断技术的发展。但现有研究未充分探讨个体说话者差异对深度声学特征分类效果的影响。该研究使用NeuroVoz数据集，探究三种预训练音频嵌入（OpenL3、VGGish和Wav2Vec2.0模型）对帕金森病分类的有效性。结果显示，OpenL3在特定任务中表现更优，能捕捉关键声学特征；Wav2Vec2.0在特定任务中存在显著性别偏差。研究还指出需提升特征提取和模型鲁棒性。
            arXiv:2506.02078v1 Announce Type: new 
Abstract: Speech impairments are prevalent biomarkers for Parkinson's Disease (PD), motivating the development of diagnostic techniques using speech data for clinical applications. Although deep acoustic features have shown promise for PD classification, their effectiveness often varies due to individual speaker differences, a factor that has not been thoroughly explored in the existing literature. This study investigates the effectiveness of three pre-trained audio embeddings (OpenL3, VGGish and Wav2Vec2.0 models) for PD classification. Using the NeuroVoz dataset, OpenL3 outperforms others in diadochokinesis (DDK) and listen and repeat (LR) tasks, capturing critical acoustic features for PD detection. Only Wav2Vec2.0 shows significant gender bias, achieving more favorable results for male speakers, in DDK tasks. The misclassified cases reveal challenges with atypical speech patterns, highlighting the need for improved feature extraction and model robustness in PD detection.
        ]]></description>
    </item>
    <item>
        <title>Comparison of spectrogram scaling in multi-label Music Genre Recognition</title>
        <link>https://arxiv.org/abs/2506.02091</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02091v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Bartosz Karpi\'nski, Cyryl Leszczy\'nski</dc:creator>
        <description><![CDATA[
            背景：随着数字音频工作站易用性提升，音乐数量增多，且音乐流派差异不明确。方法：考虑当今专辑的多样性，描述并比较多种预处理方法和模型训练方法，利用超18000条记录的自定义手动标注数据集进行实验。效果：论文未提及具体效果，但通过对比不同方法，有望为多标签音乐流派识别找到更优策略。
            arXiv:2506.02091v1 Announce Type: new 
Abstract: As the accessibility and ease-of-use of digital audio workstations increases, so does the quantity of music available to the average listener; additionally, differences between genres are not always well defined and can be abstract, with widely varying combinations of genres across individual records. In this article, multiple preprocessing methods and approaches to model training are described and compared, accounting for the eclectic nature of today's albums. A custom, manually labeled dataset of more than 18000 entries has been used to perform the experiments.
        ]]></description>
    </item>
    <item>
        <title>Breaking the Barriers of Text-Hungry and Audio-Deficient AI</title>
        <link>https://arxiv.org/abs/2506.02443</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02443v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hamidou Tembine, Issa Bamia, Massa NDong, Bakary Coulibaly, Oumar Issiaka Traore, Moussa Traore, Moussa Sanogo, Mamadou Eric Sangare, Salif Kante, Daryl Noupa Yongueng, Hafiz Tiomoko Ali, Malik Tiomoko, Frejus Laleye, Boualem Djehiche, Wesmanegda Elisee Dipama, Idris Baba Saje, Hammid Mohammed Ibrahim, Moumini Sanogo, Marie Coursel Nininahazwe, Abdul-Latif Siita, Haine Mhlongo, Teddy Nelvy Dieu Merci Kouka, Mariam Serine Jeridi, Mutiyamuogo Parfait Mupenge, Lekoueiry Dehah, Abdoul Aziz Bio Sidi Bouko, Wilfried Franceslas Zokoue, Odette Richette Sambila, Alina RS Mbango, Mady Diagouraga, Oumarou Moussa Sanoussi, Gizachew Dessalegn, Mohamed Lamine Samoura, Bintou Laetitia Audrey Coulibaly</dc:creator>
        <description><![CDATA[
            背景：当前主流的机器智能架构偏向书面文本，使超7亿以音频为主要交流方式的人被排除在外。方法：提出全无文本的音频到音频机器智能框架，包括多种绕过文本的音频翻译架构，核心是多尺度音频语义变换（MAST），并将其集成到由分数布朗运动驱动的分数平均场扩散框架中。效果：能在无文本监督下生成高保真、语义一致的语音，可直接从原始音频学习，拓展了语言技术的覆盖范围。
            arXiv:2506.02443v1 Announce Type: new 
Abstract: While global linguistic diversity spans more than 7164 recognized languages, the current dominant architecture of machine intelligence remains fundamentally biased toward written text. This bias excludes over 700 million people particularly in rural and remote regions who are audio-literate. In this work, we introduce a fully textless, audio-to-audio machine intelligence framework designed to serve this underserved population, and all the people who prefer audio-efficiency. Our contributions include novel Audio-to-Audio translation architectures that bypass text entirely, including spectrogram-, scalogram-, wavelet-, and unit-based models. Central to our approach is the Multiscale Audio-Semantic Transform (MAST), a representation that encodes tonal, prosodic, speaker, and expressive features. We further integrate MAST into a fractional diffusion of mean-field-type framework powered by fractional Brownian motion. It enables the generation of high-fidelity, semantically consistent speech without reliance on textual supervision. The result is a robust and scalable system capable of learning directly from raw audio, even in languages that are unwritten or rarely digitized. This work represents a fundamental shift toward audio-native machine intelligence systems, expanding access to language technologies for communities historically left out of the current machine intelligence ecosystem.
        ]]></description>
    </item>
    <item>
        <title>SOVA-Bench: Benchmarking the Speech Conversation Ability for LLM-based Voice Assistant</title>
        <link>https://arxiv.org/abs/2506.02457</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02457v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yixuan Hou, Heyang Liu, Yuhao Wang, Ziyang Cheng, Ronghua Wu, Qunshan Gu, Yanfeng Wang, Yu Wang</dc:creator>
        <description><![CDATA[
            背景：随着大语言模型、语音编码算法和语音合成器的发展，可直接根据用户指令生成语音回复，但生成语音质量的评估被忽视。方法：提出语音对话式语音助手基准（SOVA - Bench），对现有语音大语言模型的常识理解、语音识别理解及语义和声学生成能力进行对比。效果：SOVA - Bench是较为系统的语音大语言模型评估框架，为语音交互系统指明方向。
            arXiv:2506.02457v1 Announce Type: new 
Abstract: Thanks to the steady progress of large language models (LLMs), speech encoding algorithms and vocoder structure, recent advancements have enabled generating speech response directly from a user instruction. However, benchmarking the generated speech quality has been a neglected but critical issue, considering the shift from the pursuit of semantic accuracy to vivid and spontaneous speech flow. Previous evaluation focused on the speech-understanding ability, lacking a quantification of acoustic quality. In this paper, we propose Speech cOnversational Voice Assistant Benchmark (SOVA-Bench), providing a comprehension comparison of the general knowledge, speech recognition and understanding, along with both semantic and acoustic generative ability between available speech LLMs. To the best of our knowledge, SOVA-Bench is one of the most systematic evaluation frameworks for speech LLMs, inspiring the direction of voice interaction systems.
        ]]></description>
    </item>
    <item>
        <title>Adaptive Differential Denoising for Respiratory Sounds Classification</title>
        <link>https://arxiv.org/abs/2506.02505</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02505v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Gaoyang Dong, Zhicheng Zhang, Ping Sun, Minghui Zhang</dc:creator>
        <description><![CDATA[
            这是一篇关于呼吸音分类的论文。自动化呼吸音分类面临背景噪声干扰、现有系统去噪不足的问题。为此，作者提出自适应差分去噪网络，通过三项创新实现噪声抑制和病理特征保留：一是自适应频率滤波器，利用可学习频谱掩码和软收缩去噪并保留高频诊断成分；二是差分去噪层，用差分注意力减少噪声变异；三是偏置去噪损失，无需干净标签联合优化分类和鲁棒性。在ICBHI2017数据集上，该方法得分65.53%，较之前最优方法提升1.99%。
            arXiv:2506.02505v1 Announce Type: new 
Abstract: Automated respiratory sound classification faces practical challenges from background noise and insufficient denoising in existing systems.
  We propose Adaptive Differential Denoising network, that integrates noise suppression and pathological feature preservation via three innovations:
  1) Adaptive Frequency Filter with learnable spectral masks and soft shrink to eliminate noise while retaining diagnostic high-frequency components;
  2) A Differential Denoise Layer using differential attention to reduce noise-induced variations through augmented sample comparisons;
  3) A bias denoising loss jointly optimizing classification and robustness without clean labels.
  Experiments on the ICBHI2017 dataset show that our method achieves 65.53\% of the Score, which is improved by 1.99\% over the previous sota method.
  The code is available in https://github.com/deegy666/ADD-RSC
        ]]></description>
    </item>
    <item>
        <title>Synthetic Speech Source Tracing using Metric Learning</title>
        <link>https://arxiv.org/abs/2506.02590</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02590v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Dimitrios Koutsianos, Stavros Zacharopoulos, Yannis Panagakis, Themos Stafylakis</dc:creator>
        <description><![CDATA[
            这篇论文聚焦合成语音的源追踪问题，即通过受说话人识别启发的流程识别被篡改音频背后的生成系统。此前研究多关注欺骗检测，源追踪缺乏可靠解决方案。论文评估了基于分类和度量学习两种方法，在MLAADv5基准上用ResNet和自监督学习（SSL）骨干网络进行测试。结果显示，ResNet在度量学习方法中表现出色，能媲美甚至超越基于SSL的系统，证明了ResNet用于源追踪的可行性，也强调了优化SSL表示的必要性，为打击合成媒体操纵提供了新方向。
            arXiv:2506.02590v1 Announce Type: new 
Abstract: This paper addresses source tracing in synthetic speech-identifying generative systems behind manipulated audio via speaker recognition-inspired pipelines. While prior work focuses on spoofing detection, source tracing lacks robust solutions. We evaluate two approaches: classification-based and metric-learning. We tested our methods on the MLAADv5 benchmark using ResNet and self-supervised learning (SSL) backbones. The results show that ResNet achieves competitive performance with the metric learning approach, matching and even exceeding SSL-based systems. Our work demonstrates ResNet's viability for source tracing while underscoring the need to optimize SSL representations for this task. Our work bridges speaker recognition methodologies with audio forensic challenges, offering new directions for combating synthetic media manipulation.
        ]]></description>
    </item>
    <item>
        <title>Prompt-Unseen-Emotion: Zero-shot Expressive Speech Synthesis with Prompt-LLM Contextual Knowledge for Mixed Emotions</title>
        <link>https://arxiv.org/abs/2506.02742</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02742v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiaoxue Gao, Huayun Zhang, Nancy F. Chen</dc:creator>
        <description><![CDATA[
            背景：现有表达性文本转语音（TTS）系统主要模拟有限的分类情感，而人类对话情感更丰富，需探索更多样的情感语音生成。方法：提出Prompt-Unseen-Emotion（PUE）方法，通过情感引导的提示学习生成未见情感语音，利用LLM - TTS架构训练，确保提示与语音情感一致，能定量捕捉每句话的不同情感权重。效果：推理时可灵活调整情感比例、利用LLM上下文知识生成混合情感语音，实现零样本未见情感的表达性语音合成。
            arXiv:2506.02742v1 Announce Type: new 
Abstract: Existing expressive text-to-speech (TTS) systems primarily model a limited set of categorical emotions, whereas human conversations extend far beyond these predefined emotions, making it essential to explore more diverse emotional speech generation for more natural interactions. To bridge this gap, this paper proposes a novel prompt-unseen-emotion (PUE) approach to generate unseen emotional speech via emotion-guided prompt learning. PUE is trained utilizing an LLM-TTS architecture to ensure emotional consistency between categorical emotion-relevant prompts and emotional speech, allowing the model to quantitatively capture different emotion weightings per utterance. During inference, mixed emotional speech can be generated by flexibly adjusting emotion proportions and leveraging LLM contextual knowledge, enabling the model to quantify different emotional styles. Our proposed PUE successfully facilitates expressive speech synthesis of unseen emotions in a zero-shot setting.
        ]]></description>
    </item>
    <item>
        <title>DGMO: Training-Free Audio Source Separation through Diffusion-Guided Mask Optimization</title>
        <link>https://arxiv.org/abs/2506.02858</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02858v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Geonyoung Lee, Geonhee Han, Paul Hongsuck Seo</dc:creator>
        <description><![CDATA[
            现有语言查询音频源分离方法依赖特定任务训练，本文探索预训练的音频生成扩散模型能否不经过额外训练实现分离。研究提出无训练框架，分析简单适配方法的局限性后，提出扩散引导掩码优化（DGMO）测试时优化框架，用于优化频谱图掩码以实现精确分离。该方法有效将预训练扩散模型用于源分离，在无特定任务监督下取得有竞争力的性能，拓展了扩散模型在音频分离的应用。
            arXiv:2506.02858v1 Announce Type: new 
Abstract: Language-queried Audio Source Separation (LASS) enables open-vocabulary sound separation via natural language queries. While existing methods rely on task-specific training, we explore whether pretrained diffusion models, originally designed for audio generation, can inherently perform separation without further training. In this study, we introduce a training-free framework leveraging generative priors for zero-shot LASS. Analyzing na\"ive adaptations, we identify key limitations arising from modality-specific challenges.To address these issues, we propose Diffusion-Guided Mask Optimization (DGMO), a test-time optimization framework that refines spectrogram masks for precise, input-aligned separation. Our approach effectively repurposes pretrained diffusion models for source separation, achieving competitive performance without task-specific supervision. This work expands the application of diffusion models beyond generation, establishing a new paradigm for zero-shot audio separation. The code is available at: https://wltschmrz.github.io/DGMO/
        ]]></description>
    </item>
    <item>
        <title>CapSpeech: Enabling Downstream Applications in Style-Captioned Text-to-Speech</title>
        <link>https://arxiv.org/abs/2506.02863</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02863v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Helin Wang, Jiarui Hai, Dading Chong, Karan Thakkar, Tiantian Feng, Dongchao Yang, Junhyeok Lee, Laureano Moro Velazquez, Jesus Villalba, Zengyi Qin, Shrikanth Narayanan, Mounya Elhiali, Najim Dehak</dc:creator>
        <description><![CDATA[
            背景：生成式人工智能推动风格描述文本转语音合成（CapTTS）发展，但因缺乏标准化数据集及下游任务研究，应用受限。方法：提出CapSpeech基准，包含超1000万机器标注和近36万人工标注的音频-描述对，还为特定任务引入新数据集，并在CapSpeech上用自回归和非自回归模型实验。效果：实现多种说话风格的高保真、高可懂度语音合成，是目前最大的CapTTS相关综合标注数据集，为开发CapTTS系统提供见解。
            arXiv:2506.02863v1 Announce Type: new 
Abstract: Recent advancements in generative artificial intelligence have significantly transformed the field of style-captioned text-to-speech synthesis (CapTTS). However, adapting CapTTS to real-world applications remains challenging due to the lack of standardized, comprehensive datasets and limited research on downstream tasks built upon CapTTS. To address these gaps, we introduce CapSpeech, a new benchmark designed for a series of CapTTS-related tasks, including style-captioned text-to-speech synthesis with sound events (CapTTS-SE), accent-captioned TTS (AccCapTTS), emotion-captioned TTS (EmoCapTTS), and text-to-speech synthesis for chat agent (AgentTTS). CapSpeech comprises over 10 million machine-annotated audio-caption pairs and nearly 0.36 million human-annotated audio-caption pairs. In addition, we introduce two new datasets collected and recorded by a professional voice actor and experienced audio engineers, specifically for the AgentTTS and CapTTS-SE tasks. Alongside the datasets, we conduct comprehensive experiments using both autoregressive and non-autoregressive models on CapSpeech. Our results demonstrate high-fidelity and highly intelligible speech synthesis across a diverse range of speaking styles. To the best of our knowledge, CapSpeech is the largest available dataset offering comprehensive annotations for CapTTS-related tasks. The experiments and findings further provide valuable insights into the challenges of developing CapTTS systems.
        ]]></description>
    </item>
    <item>
        <title>Diffusion Buffer: Online Diffusion-based Speech Enhancement with Sub-Second Latency</title>
        <link>https://arxiv.org/abs/2506.02908</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02908v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Bunlong Lay, Rostilav Makarov, Timo Gerkmann</dc:creator>
        <description><![CDATA[
            背景：扩散模型用于语音增强效果显著，但推理时计算成本高，难以实时处理流式数据。方法：将滑动窗口扩散框架应用于语音增强任务，随时间逐步破坏语音信号，给缓冲区中接近当前的帧分配更多噪声，输出去噪帧的延迟与所选缓冲区大小成正比。效果：优于标准扩散模型，在GPU上高效运行，输入输出延迟为0.3 - 1秒，是首个实用的在线语音增强扩散解决方案。
            arXiv:2506.02908v1 Announce Type: new 
Abstract: Diffusion models are a class of generative models that have been recently used for speech enhancement with remarkable success but are computationally expensive at inference time. Therefore, these models are impractical for processing streaming data in real-time. In this work, we adapt a sliding window diffusion framework to the speech enhancement task. Our approach progressively corrupts speech signals through time, assigning more noise to frames close to the present in a buffer. This approach outputs denoised frames with a delay proportional to the chosen buffer size, enabling a trade-off between performance and latency. Empirical results demonstrate that our method outperforms standard diffusion models and runs efficiently on a GPU, achieving an input-output latency in the order of 0.3 to 1 seconds. This marks the first practical diffusion-based solution for online speech enhancement.
        ]]></description>
    </item>
    <item>
        <title>InfiniteAudio: Infinite-Length Audio Generation with Consistency</title>
        <link>https://arxiv.org/abs/2506.03020</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.03020v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chaeyoung Jung, Hojoon Ki, Ji-Hoon Kim, Junmo Kim, Joon Son Chung</dc:creator>
        <description><![CDATA[
            这是一篇关于音频生成的论文。当前基于扩散的文本到音频方法在生成较长音频时，因输出大小随输入长度增加而面临内存限制，拼接短音频段又会因缺乏时间上下文导致不一致。为此，该论文提出InfiniteAudio策略，无需额外训练即可集成到现有流程。它引入FIFO采样和曲线去噪两种技术。实验表明，InfiniteAudio在各项指标上取得了相当或更优的性能。
            arXiv:2506.03020v1 Announce Type: new 
Abstract: This paper presents InfiniteAudio, a simple yet effective strategy for generating infinite-length audio using diffusion-based text-to-audio methods. Current approaches face memory constraints because the output size increases with input length, making long duration generation challenging. A common workaround is to concatenate short audio segments, but this often leads to inconsistencies due to the lack of shared temporal context. To address this, InfiniteAudio integrates seamlessly into existing pipelines without additional training. It introduces two key techniques: FIFO sampling, a first-in, first-out inference strategy with fixed-size inputs, and curved denoising, which selectively prioritizes key diffusion steps for efficiency. Experiments show that InfiniteAudio achieves comparable or superior performance across all metrics. Audio samples are available on our project page.
        ]]></description>
    </item>
    <item>
        <title>Sounding Like a Winner? Prosodic Differences in Post-Match Interviews</title>
        <link>https://arxiv.org/abs/2506.02283</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02283v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sofoklis Kakouros, Haoyu Chen</dc:creator>
        <description><![CDATA[
            该研究背景是探究网球赛后采访中与胜负相关的韵律特征。方法是分析音高、强度等韵律元素，结合Wav2Vec 2.0和HuBERT等自监督学习（SSL）模型，从数据中提取传统声学特征和深度语音表示，用机器学习分类器区分胜负运动员。效果显示，SSL表示能有效区分胜负结果，捕捉与情绪状态相关的细微语音模式，同时音高可变性等韵律线索仍是胜利的有力指标。
            arXiv:2506.02283v1 Announce Type: cross 
Abstract: This study examines the prosodic characteristics associated with winning and losing in post-match tennis interviews. Additionally, this research explores the potential to classify match outcomes solely based on post-match interview recordings using prosodic features and self-supervised learning (SSL) representations. By analyzing prosodic elements such as pitch and intensity, alongside SSL models like Wav2Vec 2.0 and HuBERT, the aim is to determine whether an athlete has won or lost their match. Traditional acoustic features and deep speech representations are extracted from the data, and machine learning classifiers are employed to distinguish between winning and losing players. Results indicate that SSL representations effectively differentiate between winning and losing outcomes, capturing subtle speech patterns linked to emotional states. At the same time, prosodic cues -- such as pitch variability -- remain strong indicators of victory.
        ]]></description>
    </item>
    <item>
        <title>StarVC: A Unified Auto-Regressive Framework for Joint Text and Speech Generation in Voice Conversion</title>
        <link>https://arxiv.org/abs/2506.02414</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02414v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Fengjin Li, Jie Wang, Yadong Niu, Yongqing Wang, Meng Meng, Jian Luan, Zhiyong Wu</dc:creator>
        <description><![CDATA[
            语音转换（VC）旨在改变语音以匹配目标说话者并保留语言内容，但传统方法忽视语言内容的显式利用。由于VC需分离说话者身份和语言内容，利用结构化语义特征可提升转换性能，不过此前结合语义特征的尝试效果有限。为此提出StarVC，这一统一自回归VC框架先预测文本标记，再合成声学特征。实验表明，StarVC在保留语言内容（WER和CER）和说话者特征（SECS和MOS）方面优于传统VC方法。
            arXiv:2506.02414v1 Announce Type: cross 
Abstract: Voice Conversion (VC) modifies speech to match a target speaker while preserving linguistic content. Traditional methods usually extract speaker information directly from speech while neglecting the explicit utilization of linguistic content. Since VC fundamentally involves disentangling speaker identity from linguistic content, leveraging structured semantic features could enhance conversion performance. However, previous attempts to incorporate semantic features into VC have shown limited effectiveness, motivating the integration of explicit text modeling. We propose StarVC, a unified autoregressive VC framework that first predicts text tokens before synthesizing acoustic features. The experiments demonstrate that StarVC outperforms conventional VC methods in preserving both linguistic content (i.e., WER and CER) and speaker characteristics (i.e., SECS and MOS). Audio demo can be found at: https://thuhcsi.github.io/StarVC/.
        ]]></description>
    </item>
    <item>
        <title>FlashAudio: Rectified Flows for Fast and High-Fidelity Text-to-Audio Generation</title>
        <link>https://arxiv.org/abs/2410.12266</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.12266v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Huadai Liu, Jialei Wang, Rongjie Huang, Yang Liu, Heng Lu, Zhou Zhao, Wei Xue</dc:creator>
        <description><![CDATA[
            背景：现有潜在扩散模型虽提升了文本到音频生成效果，但迭代采样计算成本高，基于一致性蒸馏的方法也受限于曲线轨迹。方法：提出FlashAudio，用整流流学习直流程以快速模拟；用双焦采样器优化整流流时间分布，提出不混溶流；提出锚定优化解决无分类器引导放大累积误差问题。效果：一步生成性能在音频质量上超数百步采样的扩散模型，在单块NVIDIA 4090Ti GPU上采样速度比实时快400倍。
            arXiv:2410.12266v2 Announce Type: replace 
Abstract: Recent advancements in latent diffusion models (LDMs) have markedly enhanced text-to-audio generation, yet their iterative sampling processes impose substantial computational demands, limiting practical deployment. While recent methods utilizing consistency-based distillation aim to achieve few-step or single-step inference, their one-step performance is constrained by curved trajectories, preventing them from surpassing traditional diffusion models. In this work, we introduce FlashAudio with rectified flows to learn straight flow for fast simulation. To alleviate the inefficient timesteps allocation and suboptimal distribution of noise, FlashAudio optimizes the time distribution of rectified flow with Bifocal Samplers and proposes immiscible flow to minimize the total distance of data-noise pairs in a batch vias assignment. Furthermore, to address the amplified accumulation error caused by the classifier-free guidance (CFG), we propose Anchored Optimization, which refines the guidance scale by anchoring it to a reference trajectory. Experimental results on text-to-audio generation demonstrate that FlashAudio's one-step generation performance surpasses the diffusion-based models with hundreds of sampling steps on audio quality and enables a sampling speed of 400x faster than real-time on a single NVIDIA 4090Ti GPU. Code will be available at https://github.com/liuhuadai/FlashAudio.
        ]]></description>
    </item>
    <item>
        <title>Score-informed Music Source Separation: Improving Synthetic-to-real Generalization in Classical Music</title>
        <link>https://arxiv.org/abs/2503.07352</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.07352v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Eetu Tunturi, David Diaz-Guerra, Archontis Politis, Tuomas Virtanen</dc:creator>
        <description><![CDATA[
            音乐源分离旨在将乐器混合音频分离为独立音轨，传统模型多仅用音频数据训练，利用额外信息可提升分离能力。本文提出两种利用乐谱辅助音乐源分离的方法：一是将乐谱与音频混合幅度谱拼接作为模型输入；二是仅用乐谱计算分离掩码。在SynthSOD合成数据集训练模型，在URMP和Aalto管弦乐队真实数据集评估。结果显示，前者分离效果优于基线方法，但合成到真实数据泛化能力弱；后者在泛化能力上有明显提升。
            arXiv:2503.07352v2 Announce Type: replace 
Abstract: Music source separation is the task of separating a mixture of instruments into constituent tracks. Music source separation models are typically trained using only audio data, although additional information can be used to improve the model's separation capability. In this paper, we propose two ways of using musical scores to aid music source separation: a score-informed model where the score is concatenated with the magnitude spectrogram of the audio mixture as the input of the model, and a model where we use only the score to calculate the separation mask. We train our models on synthetic data in the SynthSOD dataset and evaluate our methods on the URMP and Aalto anechoic orchestra datasets, comprised of real recordings. The score-informed model improves separation results compared to a baseline approach, but struggles to generalize from synthetic to real data, whereas the score-only model shows a clear improvement in synthetic-to-real generalization.
        ]]></description>
    </item>
    <item>
        <title>OmniAudio: Generating Spatial Audio from 360-Degree Video</title>
        <link>https://arxiv.org/abs/2504.14906</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.14906v3</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Huadai Liu, Tianyi Luo, Kaicheng Luo, Qikai Jiang, Peiwen Sun, Jialei Wang, Rongjie Huang, Qian Chen, Wen Wang, Xiangtai Li, Shiliang Zhang, Zhijie Yan, Zhou Zhao, Wei Xue</dc:creator>
        <description><![CDATA[
            传统视频到音频生成技术主要关注透视视频和非空间音频，缺少3D环境中声源的空间线索。为此提出360V2SA任务，从360度视频生成空间音频，即一阶环绕声（FOA）音频。创建了适用于该任务的Sphere360数据集，并设计了收集和清理视频音频对数据的半自动化流程。提出OmniAudio框架，利用自监督预训练结合空间和非空间音频数据，采用双分支结构利用全景和透视视频输入。实验表明，OmniAudio在Sphere360数据集上主客观指标均达最优。
            arXiv:2504.14906v3 Announce Type: replace 
Abstract: Traditional video-to-audio generation techniques primarily focus on perspective video and non-spatial audio, often missing the spatial cues necessary for accurately representing sound sources in 3D environments. To address this limitation, we introduce a novel task, 360V2SA, to generate spatial audio from 360-degree videos, specifically producing First-order Ambisonics (FOA) audio - a standard format for representing 3D spatial audio that captures sound directionality and enables realistic 3D audio reproduction. We first create Sphere360, a novel dataset tailored for this task that is curated from real-world data. We also design an efficient semi-automated pipeline for collecting and cleaning paired video-audio data. To generate spatial audio from 360-degree video, we propose a novel framework OmniAudio, which leverages self-supervised pre-training using both spatial audio data (in FOA format) and large-scale non-spatial data. Furthermore, OmniAudio features a dual-branch framework that utilizes both panoramic and perspective video inputs to capture comprehensive local and global information from 360-degree videos. Experimental results demonstrate that OmniAudio achieves state-of-the-art performance across both objective and subjective metrics on Sphere360. Code and datasets are available at https://github.com/liuhuadai/OmniAudio. The project website is available at https://OmniAudio-360V2SA.github.io.
        ]]></description>
    </item>
    <item>
        <title>Accelerating Autoregressive Speech Synthesis Inference With Speech Speculative Decoding</title>
        <link>https://arxiv.org/abs/2505.15380</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.15380v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zijian Lin, Yang Zhang, Yougen Yuan, Yuming Yan, Jinjiang Liu, Zhiyong Wu, Pengfei Hu, Qun Yu</dc:creator>
        <description><![CDATA[
            现代基于语言模型的自回归语音合成模型性能出色，但顺序预测下一令牌的方式导致显著延迟。为此，本文提出了用于自回归语音合成加速的新型框架——语音推测解码（SSD）。该方法用轻量级草稿模型生成候选令牌序列，再由目标模型使用SSD框架并行验证。实验表明，与传统自回归解码相比，SSD加速比达1.4倍，且保持高保真度和自然度，主观评价也验证了其在加速推理时能保留目标模型感知质量。
            arXiv:2505.15380v2 Announce Type: replace 
Abstract: Modern autoregressive speech synthesis models leveraging language models have demonstrated remarkable performance. However, the sequential nature of next token prediction in these models leads to significant latency, hindering their deployment in scenarios where inference speed is critical. In this work, we propose Speech Speculative Decoding (SSD), a novel framework for autoregressive speech synthesis acceleration. Specifically, our method employs a lightweight draft model to generate candidate token sequences, which are subsequently verified in parallel by the target model using the proposed SSD framework. Experimental results demonstrate that SSD achieves a significant speedup of 1.4x compared with conventional autoregressive decoding, while maintaining high fidelity and naturalness. Subjective evaluations further validate the effectiveness of SSD in preserving the perceptual quality of the target model while accelerating inference.
        ]]></description>
    </item>
    <item>
        <title>Ola: Pushing the Frontiers of Omni-Modal Language Model</title>
        <link>https://arxiv.org/abs/2502.04328</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.04328v3</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zuyan Liu, Yuhao Dong, Jiahui Wang, Ziwei Liu, Winston Hu, Jiwen Lu, Yongming Rao</dc:creator>
        <description><![CDATA[
            背景：大语言模型发展促使人们关注多模态模型，但现有开源多模态模型性能落后于单模态模型。方法：提出全模态语言模型Ola，对架构设计、数据管理和训练策略进行全面探索，在主流基线基础上改进以融入视觉理解和音频识别能力，重新思考模态关系，提出渐进式训练流程。效果：Ola在各模态上超越现有开源多模态大语言模型，与同规模单模态模型相比性能具竞争力。
            arXiv:2502.04328v3 Announce Type: replace-cross 
Abstract: Recent advances in large language models, particularly following GPT-4o, have sparked increasing interest in developing omni-modal models capable of understanding more modalities. While some open-source alternatives have emerged, there is still a notable lag behind specialized single-modality models in performance. In this paper, we present Ola, an Omni-modal Language model that achieves competitive performance across image, video, and audio understanding compared to specialized counterparts, pushing the frontiers of the omni-modal language model to a large extent. We conduct a comprehensive exploration of architectural design, data curation, and training strategies essential for building a robust omni-modal model. Ola incorporates advanced visual understanding and audio recognition capabilities through several critical and effective improvements over mainstream baselines. Moreover, we rethink inter-modal relationships during omni-modal training, emphasizing cross-modal alignment with video as a central bridge, and propose a progressive training pipeline that begins with the most distinct modalities and gradually moves towards closer modality alignment. Extensive experiments demonstrate that Ola surpasses existing open omni-modal LLMs across all modalities while achieving highly competitive performance compared to state-of-the-art specialized models of similar sizes. We aim to make Ola a fully open omni-modal understanding solution to advance future research in this emerging field. Model weights, code, and data are open-sourced at https://github.com/Ola-Omni/Ola.
        ]]></description>
    </item>
    <item>
        <title>Contextual Paralinguistic Data Creation for Multi-Modal Speech-LLM: Data Condensation and Spoken QA Generation</title>
        <link>https://arxiv.org/abs/2505.13338</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13338v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qiongqiong Wang, Hardik B. Sailor, Tianchi Liu, Ai Ti Aw</dc:creator>
        <description><![CDATA[
            背景：当前语音大语言模型在上下文推理和副语言理解方面能力有限，原因是缺乏涵盖这两方面的问答数据集。方法：提出一种从自然语音数据生成数据集的框架，包括基于伪副语言标签的数据浓缩和基于大语言模型的上下文副语言问答生成。效果：在基于该框架创建的数据集上，Qwen2 - Audio - 7B - Instruct模型评估结果与人工生成的问答数据集有强相关性，同时也揭示了语音大语言模型在移情推理任务上的局限，该框架有潜力训练出更强的副语言推理语音大模型。
            arXiv:2505.13338v2 Announce Type: replace-cross 
Abstract: Current speech-LLMs exhibit limited capability in contextual reasoning alongside paralinguistic understanding, primarily due to the lack of Question-Answer (QA) datasets that cover both aspects. We propose a novel framework for dataset generation from in-the-wild speech data, that integrates contextual reasoning with paralinguistic information. It consists of a pseudo paralinguistic label-based data condensation of in-the-wild speech and LLM-based Contextual Paralinguistic QA (CPQA) generation. The effectiveness is validated by a strong correlation in evaluations of the Qwen2-Audio-7B-Instruct model on a dataset created by our framework and human-generated CPQA dataset. The results also reveal the speech-LLM's limitations in handling empathetic reasoning tasks, highlighting the need for such datasets and more robust models. The proposed framework is first of its kind and has potential in training more robust speech-LLMs with paralinguistic reasoning capabilities.
        ]]></description>
    </item>
</channel>
</rss>