<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
<channel>
    <title>arXiv Paper Filter</title>
    <link>https://github.com/None/arxiv_filter</link>
    <description>根据研究兴趣筛选的arXiv论文</description>
    <atom:link href="https://raw.githubusercontent.com/None/arxiv_filter/main/feed.xml" rel="self" type="application/rss+xml" />
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>zh-CN</language>
    <lastBuildDate>Wed, 11 Jun 2025 12:20:32 +0800</lastBuildDate>
    <managingEditor>None@github.com</managingEditor>
    <pubDate>Wed, 11 Jun 2025 12:20:32 +0800</pubDate>
    <skipDays>
        <day>Saturday</day>
        <day>Sunday</day>
    </skipDays>

    <item>
        <title>Modality-Balancing Preference Optimization of Large Multimodal Models by Adversarial Negative Mining</title>
        <link>https://arxiv.org/abs/2506.08022</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08022v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chenxi Liu, Tianyi Xiong, Ruibo Chen, Yihan Wu, Junfeng Guo, Tianyi Zhou, Heng Huang</dc:creator>
        <description><![CDATA[
            背景：当前大语言模型推理时存在严重的模态不平衡问题，现有偏好优化方法存在不足。方法：本文提出模态平衡偏好优化（MBPO）框架，通过对抗性扰动输入图像生成硬负样本构建离线偏好数据集，利用封闭任务易验证的特性生成带验证奖励的在线响应，用GRPO结合离线 - 在线混合数据训练模型。效果：大量实验表明，MBPO能提升大多模态模型在视觉 - 语言任务上的表现，有效减少幻觉。
            arXiv:2506.08022v1 Announce Type: new 
Abstract: The task adaptation and alignment of Large Multimodal Models (LMMs) have been significantly advanced by instruction tuning and further strengthened by recent preference optimization. Yet, most LMMs still suffer from severe modality imbalance during reasoning, i.e., outweighing language prior biases over visual inputs, which bottlenecks their generalization to downstream tasks and causes hallucinations. However, existing preference optimization approaches for LMMs do not focus on restraining the internal biases of their Large Language Model (LLM) backbones when curating the training data. Moreover, they heavily rely on offline data and lack the capacity to explore diverse responses adaptive to dynamic distributional shifts during training. Meanwhile, Group Relative Policy Optimization (GRPO), a recent method using online-generated data and verified rewards to improve reasoning capabilities, remains largely underexplored in LMM alignment. In this paper, we propose a novel preference learning framework, Modality-Balancing Preference Optimization (MBPO), to address the modality imbalance in LMMs. MBPO constructs a more effective offline preference dataset by generating hard negatives, i.e., rejected responses misled by LLM biases due to limited usage of visual information, through adversarial perturbation of input images. Moreover, MBPO leverages the easy-to-verify nature of close-ended tasks to generate online responses with verified rewards. GRPO is then employed to train the model with offline-online hybrid data. Extensive experiments demonstrate that MBPO can enhance LMM performance on challenging vision-language tasks and effectively reduce hallucinations.
        ]]></description>
    </item>
    <item>
        <title>ST-GraphNet: A Spatio-Temporal Graph Neural Network for Understanding and Predicting Automated Vehicle Crash Severity</title>
        <link>https://arxiv.org/abs/2506.08051</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08051v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mahmuda Sultana Mimi, Md Monzurul Islam, Anannya Ghosh Tusti, Shriyank Somvanshi, Subasish Das</dc:creator>
        <description><![CDATA[
            本文背景是理解自动驾驶汽车（AV）碰撞严重程度的时空动态对提升城市出行安全和基础设施规划至关重要。方法上，提出ST - GraphNet时空图神经网络框架，构建细粒度和粗粒度两种图表示，节点融入多模态数据，评估多种GNN架构。效果方面，采用DSTGCN骨干网络的ST - GraphNet在粗粒度图上测试准确率达97.74%，远超最佳细粒度模型的64.7%，凸显了空间聚合、动态消息传递和多模态特征集成的有效性。
            arXiv:2506.08051v1 Announce Type: new 
Abstract: Understanding the spatial and temporal dynamics of automated vehicle (AV) crash severity is critical for advancing urban mobility safety and infrastructure planning. In this work, we introduce ST-GraphNet, a spatio-temporal graph neural network framework designed to model and predict AV crash severity by using both fine-grained and region-aggregated spatial graphs. Using a balanced dataset of 2,352 real-world AV-related crash reports from Texas (2024), including geospatial coordinates, crash timestamps, SAE automation levels, and narrative descriptions, we construct two complementary graph representations: (1) a fine-grained graph with individual crash events as nodes, where edges are defined via spatio-temporal proximity; and (2) a coarse-grained graph where crashes are aggregated into Hexagonal Hierarchical Spatial Indexing (H3)-based spatial cells, connected through hexagonal adjacency. Each node in the graph is enriched with multimodal data, including semantic, spatial, and temporal attributes, including textual embeddings from crash narratives using a pretrained Sentence-BERT model. We evaluate various graph neural network (GNN) architectures, such as Graph Convolutional Networks (GCN), Graph Attention Networks (GAT), and Dynamic Spatio-Temporal GCN (DSTGCN), to classify crash severity and predict high-risk regions. Our proposed ST-GraphNet, which utilizes a DSTGCN backbone on the coarse-grained H3 graph, achieves a test accuracy of 97.74\%, substantially outperforming the best fine-grained model (64.7\% test accuracy). These findings highlight the effectiveness of spatial aggregation, dynamic message passing, and multi-modal feature integration in capturing the complex spatio-temporal patterns underlying AV crash severity.
        ]]></description>
    </item>
    <item>
        <title>Benchmarking Pre-Trained Time Series Models for Electricity Price Forecasting</title>
        <link>https://arxiv.org/abs/2506.08113</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08113v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Timoth\'ee Hornek Amir Sartipi, Igor Tchappi, Gilbert Fridgen</dc:creator>
        <description><![CDATA[
            背景：准确的电价预测对现货市场电力交易决策至关重要，预训练时间序列基础模型在电价预测中的有效性尚不明确。方法：将Chronos - Bolt、Chronos - T5等多个预训练模型与传统统计和机器学习方法进行基准测试，利用德、法等国2024年日前拍卖电价数据进行一日超前的每日预测。效果：Chronos - Bolt和Time - MoE在时间序列基础模型中表现突出，与传统模型相当，但能捕捉日、周季节性的biseasonal MSTL模型表现稳定，无时间序列基础模型在统计上超越它。
            arXiv:2506.08113v1 Announce Type: new 
Abstract: Accurate electricity price forecasting (EPF) is crucial for effective decision-making in power trading on the spot market. While recent advances in generative artificial intelligence (GenAI) and pre-trained large language models (LLMs) have inspired the development of numerous time series foundation models (TSFMs) for time series forecasting, their effectiveness in EPF remains uncertain. To address this gap, we benchmark several state-of-the-art pretrained models--Chronos-Bolt, Chronos-T5, TimesFM, Moirai, Time-MoE, and TimeGPT--against established statistical and machine learning (ML) methods for EPF. Using 2024 day-ahead auction (DAA) electricity prices from Germany, France, the Netherlands, Austria, and Belgium, we generate daily forecasts with a one-day horizon. Chronos-Bolt and Time-MoE emerge as the strongest among the TSFMs, performing on par with traditional models. However, the biseasonal MSTL model, which captures daily and weekly seasonality, stands out for its consistent performance across countries and evaluation metrics, with no TSFM statistically outperforming it.
        ]]></description>
    </item>
    <item>
        <title>Bingo: Boosting Efficient Reasoning of LLMs via Dynamic and Significance-based Reinforcement Learning</title>
        <link>https://arxiv.org/abs/2506.08125</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08125v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hanbing Liu, Lang Cao, Yuanyi Ren, Mengyu Zhou, Haoyu Dong, Xiaojun Ma, Shi Han, Dongmei Zhang</dc:creator>
        <description><![CDATA[
            背景：大语言模型推理能力强，但输出冗长冗余致效率低，现有强化学习多关注准确率，对效率关注有限，直接基于长度的奖励易致准确率下降。方法：提出Bingo强化学习框架，包含显著感知长度奖励和动态长度奖励两种机制。效果：在多个推理基准测试中，Bingo提升了准确率和效率，优于普通奖励及其他基于长度的奖励基线，实现了准确率与效率的良好平衡。
            arXiv:2506.08125v1 Announce Type: new 
Abstract: Large language models have demonstrated impressive reasoning capabilities, yet they often suffer from inefficiencies due to unnecessarily verbose or redundant outputs. While many works have explored reinforcement learning (RL) to enhance reasoning abilities, most primarily focus on improving accuracy, with limited attention to reasoning efficiency. Some existing approaches introduce direct length-based rewards to encourage brevity, but this often leads to noticeable drops in accuracy. In this paper, we propose Bingo, an RL framework that advances length-based reward design to boost efficient reasoning. Bingo incorporates two key mechanisms: a significance-aware length reward, which gradually guides the model to reduce only insignificant tokens, and a dynamic length reward, which initially encourages elaborate reasoning for hard questions but decays over time to improve overall efficiency. Experiments across multiple reasoning benchmarks show that Bingo improves both accuracy and efficiency. It outperforms the vanilla reward and several other length-based reward baselines in RL, achieving a favorable trade-off between accuracy and efficiency. These results underscore the potential of training LLMs explicitly for efficient reasoning.
        ]]></description>
    </item>
    <item>
        <title>EconWebArena: Benchmarking Autonomous Agents on Economic Tasks in Realistic Web Environments</title>
        <link>https://arxiv.org/abs/2506.08136</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08136v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zefang Liu, Yinzhu Quan</dc:creator>
        <description><![CDATA[
            背景：现有研究缺乏对复杂多模态经济任务中自主代理的评估。方法：提出EconWebArena基准，涵盖82个权威网站的360个精心策划任务，通过提示大语言模型生成候选任务并经人工筛选构建。评估多种多模态大语言模型，分析失败案例和开展消融研究。效果：揭示模型性能存在差距，凸显在基础、导航和多模态理解方面的挑战，为经济网络智能提供严格测试平台。
            arXiv:2506.08136v1 Announce Type: new 
Abstract: We introduce EconWebArena, a benchmark for evaluating autonomous agents on complex, multimodal economic tasks in realistic web environments. The benchmark comprises 360 curated tasks from 82 authoritative websites spanning domains such as macroeconomics, labor, finance, trade, and public policy. Each task challenges agents to navigate live websites, interpret structured and visual content, interact with real interfaces, and extract precise, time-sensitive data through multi-step workflows. We construct the benchmark by prompting multiple large language models (LLMs) to generate candidate tasks, followed by rigorous human curation to ensure clarity, feasibility, and source reliability. Unlike prior work, EconWebArena emphasizes fidelity to authoritative data sources and the need for grounded web-based economic reasoning. We evaluate a diverse set of state-of-the-art multimodal LLMs as web agents, analyze failure cases, and conduct ablation studies to assess the impact of visual grounding, plan-based reasoning, and interaction design. Our results reveal substantial performance gaps and highlight persistent challenges in grounding, navigation, and multimodal understanding, positioning EconWebArena as a rigorous testbed for economic web intelligence.
        ]]></description>
    </item>
    <item>
        <title>ETT-CKGE: Efficient Task-driven Tokens for Continual Knowledge Graph Embedding</title>
        <link>https://arxiv.org/abs/2506.08158</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08158v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Lijing Zhu, Qizhen Lan, Qing Tian, Wenbo Sun, Li Yang, Lu Xia, Yixin Xie, Xi Xiao, Tiehang Duan, Cui Tao, Shuteng Niu</dc:creator>
        <description><![CDATA[
            这篇论文聚焦于持续知识图谱嵌入（CKGE），现有方法存在效率和可扩展性问题，一是手动设计的节点/关系重要性得分忽略下游任务相关图依赖，二是计算节点/关系重要性的图遍历计算成本高。为此提出ETT - CKGE方法，引入可学习的标记直接捕获任务相关信号，无需显式节点评分或遍历，通过简单矩阵运算实现知识转移。实验表明，该方法在六个基准数据集上表现优异，相比现有方法显著提高训练效率和可扩展性。
            arXiv:2506.08158v1 Announce Type: new 
Abstract: Continual Knowledge Graph Embedding (CKGE) seeks to integrate new knowledge while preserving past information. However, existing methods struggle with efficiency and scalability due to two key limitations: (1) suboptimal knowledge preservation between snapshots caused by manually designed node/relation importance scores that ignore graph dependencies relevant to the downstream task, and (2) computationally expensive graph traversal for node/relation importance calculation, leading to slow training and high memory overhead. To address these limitations, we introduce ETT-CKGE (Efficient, Task-driven, Tokens for Continual Knowledge Graph Embedding), a novel task-guided CKGE method that leverages efficient task-driven tokens for efficient and effective knowledge transfer between snapshots. Our method introduces a set of learnable tokens that directly capture task-relevant signals, eliminating the need for explicit node scoring or traversal. These tokens serve as consistent and reusable guidance across snapshots, enabling efficient token-masked embedding alignment between snapshots. Importantly, knowledge transfer is achieved through simple matrix operations, significantly reducing training time and memory usage. Extensive experiments across six benchmark datasets demonstrate that ETT-CKGE consistently achieves superior or competitive predictive performance, while substantially improving training efficiency and scalability compared to state-of-the-art CKGE methods. The code is available at: https://github.com/lijingzhu1/ETT-CKGE/tree/main
        ]]></description>
    </item>
    <item>
        <title>Surgeon Style Fingerprinting and Privacy Risk Quantification via Discrete Diffusion Models in a Vision-Language-Action Framework</title>
        <link>https://arxiv.org/abs/2506.08185</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08185v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Huixin Zhan, Jason H. Moore</dc:creator>
        <description><![CDATA[
            背景：因训练、经验和运动行为差异，外科医生有独特手术风格，但现有AI系统常忽略该个性化信号。方法：提出用集成视觉 - 语言 - 动作（VLA）管道的离散扩散框架，将手势预测作为结构化序列去噪任务，通过第三方语言模型的自然语言提示编码个性化外科医生特征。效果：在JIGSAWS数据集上准确重建手势序列，学习到每位医生独特的运动特征，但发现更具表现力的嵌入虽提高任务性能，却增加身份泄露风险。
            arXiv:2506.08185v1 Announce Type: new 
Abstract: Surgeons exhibit distinct operating styles due to differences in training, experience, and motor behavior - yet current AI systems often ignore this personalization signal. We propose a novel approach to model fine-grained, surgeon-specific fingerprinting in robotic surgery using a discrete diffusion framework integrated with a vision-language-action (VLA) pipeline. Our method formulates gesture prediction as a structured sequence denoising task, conditioned on multimodal inputs including endoscopic video, surgical intent language, and a privacy-aware embedding of surgeon identity and skill. Personalized surgeon fingerprinting is encoded through natural language prompts using third-party language models, allowing the model to retain individual behavioral style without exposing explicit identity. We evaluate our method on the JIGSAWS dataset and demonstrate that it accurately reconstructs gesture sequences while learning meaningful motion fingerprints unique to each surgeon. To quantify the privacy implications of personalization, we perform membership inference attacks and find that more expressive embeddings improve task performance but simultaneously increase susceptibility to identity leakage. These findings demonstrate that while personalized embeddings improve performance, they also increase vulnerability to identity leakage, revealing the importance of balancing personalization with privacy risk in surgical modeling. Code is available at: https://github.com/huixin-zhan-ai/Surgeon_style_fingerprinting.
        ]]></description>
    </item>
    <item>
        <title>Open World Scene Graph Generation using Vision Language Models</title>
        <link>https://arxiv.org/abs/2506.08189</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08189v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Amartya Dutta, Kazi Sajeed Mehrab, Medha Sawhney, Abhilash Neog, Mridul Khurana, Sepideh Fatemi, Aanish Pradhan, M. Maruf, Ismini Lourentzou, Arka Daw, Anuj Karpatne</dc:creator>
        <description><![CDATA[
            场景图生成（SGG）旨在识别图像中物体及其关系，但多数方法依赖特定数据集监督，在开放世界场景实用性受限。本文提出无训练、高效且与模型无关的Open - World SGG框架，将SGG视为零样本结构化推理问题，结合多模态提示、嵌入对齐和轻量级对细化策略。还制定开放世界评估协议。实验表明，预训练视觉语言模型无需任务级训练就能在多个数据集上实现关系理解。
            arXiv:2506.08189v1 Announce Type: new 
Abstract: Scene-Graph Generation (SGG) seeks to recognize objects in an image and distill their salient pairwise relationships. Most methods depend on dataset-specific supervision to learn the variety of interactions, restricting their usefulness in open-world settings, involving novel objects and/or relations. Even methods that leverage large Vision Language Models (VLMs) typically require benchmark-specific fine-tuning. We introduce Open-World SGG, a training-free, efficient, model-agnostic framework that taps directly into the pretrained knowledge of VLMs to produce scene graphs with zero additional learning. Casting SGG as a zero-shot structured-reasoning problem, our method combines multimodal prompting, embedding alignment, and a lightweight pair-refinement strategy, enabling inference over unseen object vocabularies and relation sets. To assess this setting, we formalize an Open-World evaluation protocol that measures performance when no SGG-specific data have been observed either in terms of objects and relations. Experiments on Visual Genome, Open Images V6, and the Panoptic Scene Graph (PSG) dataset demonstrate the capacity of pretrained VLMs to perform relational understanding without task-level training.
        ]]></description>
    </item>
    <item>
        <title>Can AI Validate Science? Benchmarking LLMs for Accurate Scientific Claim $\rightarrow$ Evidence Reasoning</title>
        <link>https://arxiv.org/abs/2506.08235</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08235v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Shashidhar Reddy Javaji, Yupeng Cao, Haohang Li, Yangyang Yu, Nikhil Muralidhar, Zining Zhu</dc:creator>
        <description><![CDATA[
            背景：大语言模型虽用于复杂研究任务，但对其理解复杂研究论文中主张与证据逻辑关系的能力探索较少。方法：提出综合基准CLAIM - BENCH评估大语言模型的科学主张 - 证据提取和验证能力，系统比较三种受分治法启发的方法，在六个不同大语言模型上进行实验。效果：通过超300对多领域主张 - 证据对评估，发现大语言模型处理复杂科学内容能力有限，闭源模型在精度和召回率上优于开源模型，特定提示方法能提升关联能力但增加计算成本。
            arXiv:2506.08235v1 Announce Type: new 
Abstract: Large language models (LLMs) are increasingly being used for complex research tasks such as literature review, idea generation, and scientific paper analysis, yet their ability to truly understand and process the intricate relationships within complex research papers, such as the logical links between claims and supporting evidence remains largely unexplored. In this study, we present CLAIM-BENCH, a comprehensive benchmark for evaluating LLMs' capabilities in scientific claim-evidence extraction and validation, a task that reflects deeper comprehension of scientific argumentation. We systematically compare three approaches which are inspired by divide and conquer approaches, across six diverse LLMs, highlighting model-specific strengths and weaknesses in scientific comprehension. Through evaluation involving over 300 claim-evidence pairs across multiple research domains, we reveal significant limitations in LLMs' ability to process complex scientific content. Our results demonstrate that closed-source models like GPT-4 and Claude consistently outperform open-source counterparts in precision and recall across claim-evidence identification tasks. Furthermore, strategically designed three-pass and one-by-one prompting approaches significantly improve LLMs' abilities to accurately link dispersed evidence with claims, although this comes at increased computational cost. CLAIM-BENCH sets a new standard for evaluating scientific comprehension in LLMs, offering both a diagnostic tool and a path forward for building systems capable of deeper, more reliable reasoning across full-length papers.
        ]]></description>
    </item>
    <item>
        <title>Temporalizing Confidence: Evaluation of Chain-of-Thought Reasoning with Signal Temporal Logic</title>
        <link>https://arxiv.org/abs/2506.08243</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08243v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhenjiang Mao, Artem Bisliouk, Rohith Reddy Nama, Ivan Ruchkin</dc:creator>
        <description><![CDATA[
            大语言模型在思维链提示下进行数学推理表现出色，但常输出高置信度却错误的结果，在教育等领域有风险。为此，研究提出结构化框架，将逐步置信度建模为时间信号，用信号时间逻辑评估。定义基于STL的约束条件来捕捉理想的时间属性，计算鲁棒性得分作为可解释的置信度估计。还引入不确定性重塑策略，确保推理轨迹的平滑性、单调性和因果一致性。实验表明，该方法能持续改善校准指标，比传统方法提供更可靠的不确定性估计。
            arXiv:2506.08243v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have shown impressive performance in mathematical reasoning tasks when guided by Chain-of-Thought (CoT) prompting. However, they tend to produce highly confident yet incorrect outputs, which poses significant risks in domains like education, where users may lack the expertise to assess reasoning steps. To address this, we propose a structured framework that models stepwise confidence as a temporal signal and evaluates it using Signal Temporal Logic (STL). In particular, we define formal STL-based constraints to capture desirable temporal properties and compute robustness scores that serve as structured, interpretable confidence estimates. Our approach also introduces a set of uncertainty reshaping strategies to enforce smoothness, monotonicity, and causal consistency across the reasoning trajectory. Experiments show that our approach consistently improves calibration metrics and provides more reliable uncertainty estimates than conventional confidence aggregation and post-hoc calibration.
        ]]></description>
    </item>
    <item>
        <title>From Debate to Equilibrium: Belief-Driven Multi-Agent LLM Reasoning via Bayesian Nash Equilibrium</title>
        <link>https://arxiv.org/abs/2506.08292</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08292v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xie Yi, Zhanke Zhou, Chentao Cao, Qiyu Niu, Tongliang Liu, Bo Han</dc:creator>
        <description><![CDATA[
            背景：多智能体框架虽能提升大语言模型推理能力，但存在计算成本高且缺乏收敛保证的问题。方法：将多语言模型协调视为不完全信息博弈，寻求贝叶斯纳什均衡，引入基于纳什均衡的高效协调（ECON）这一强化学习范式，让各语言模型基于对其他智能体的信念独立选择使预期奖励最大化的响应。效果：数学证明 ECON 比非均衡多智能体方案的遗憾边界更紧，在六个基准测试中平均比现有多语言模型方法高出 11.2%，还能灵活整合更多模型。
            arXiv:2506.08292v1 Announce Type: new 
Abstract: Multi-agent frameworks can substantially boost the reasoning power of large language models (LLMs), but they typically incur heavy computational costs and lack convergence guarantees. To overcome these challenges, we recast multi-LLM coordination as an incomplete-information game and seek a Bayesian Nash equilibrium (BNE), in which each agent optimally responds to its probabilistic beliefs about the strategies of others. We introduce Efficient Coordination via Nash Equilibrium (ECON), a hierarchical reinforcement-learning paradigm that marries distributed reasoning with centralized final output. Under ECON, each LLM independently selects responses that maximize its expected reward, conditioned on its beliefs about co-agents, without requiring costly inter-agent exchanges. We mathematically prove that ECON attains a markedly tighter regret bound than non-equilibrium multi-agent schemes. Empirically, ECON outperforms existing multi-LLM approaches by 11.2% on average across six benchmarks spanning complex reasoning and planning tasks. Further experiments demonstrate ECON's ability to flexibly incorporate additional models, confirming its scalability and paving the way toward larger, more powerful multi-LLM ensembles. The code is publicly available at: https://github.com/tmlr-group/ECON.
        ]]></description>
    </item>
    <item>
        <title>From Passive to Active Reasoning: Can Large Language Models Ask the Right Questions under Incomplete Information?</title>
        <link>https://arxiv.org/abs/2506.08295</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08295v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhanke Zhou, Xiao Feng, Zhaocheng Zhu, Jiangchao Yao, Sanmi Koyejo, Bo Han</dc:creator>
        <description><![CDATA[
            背景：现有基准主要评估大语言模型的被动推理能力，而主动推理能力缺乏系统研究。方法：提出AR - Bench这一专门评估大语言模型主动推理技能的基准，包含侦探案例、情景谜题和猜数字三个任务族。效果：实证评估显示当代大语言模型在主动推理上存在明显困难，即便采用树搜索或后训练等策略，提升也有限，凸显了发展主动推理方法的迫切需求。
            arXiv:2506.08295v1 Announce Type: new 
Abstract: While existing benchmarks probe the reasoning abilities of large language models (LLMs) across diverse domains, they predominantly assess passive reasoning, providing models with all the information needed to reach a solution. By contrast, active reasoning-where an LLM must interact with external systems to acquire missing evidence or data-has received little systematic attention. To address this shortfall, we present AR-Bench, a novel benchmark designed explicitly to evaluate an LLM's active reasoning skills. AR-Bench comprises three task families-detective cases, situation puzzles, and guessing numbers-that together simulate real-world, agentic scenarios and measure performance across commonsense, logical, and symbolic reasoning challenges. Empirical evaluation on AR-Bench demonstrates that contemporary LLMs exhibit pronounced difficulties with active reasoning: they frequently fail to acquire or leverage the information needed to solve tasks. This gap highlights a stark divergence between their passive and active reasoning abilities. Moreover, ablation studies indicate that even advanced strategies, such as tree-based searching or post-training approaches, yield only modest gains and fall short of the levels required for real-world deployment. Collectively, these findings highlight the critical need to advance methodology for active reasoning, e.g., incorporating interactive learning, real-time feedback loops, and environment-aware objectives for training. The benchmark is publicly available at: https://github.com/tmlr-group/AR-Bench.
        ]]></description>
    </item>
    <item>
        <title>H$^2$GFM: Towards unifying Homogeneity and Heterogeneity on Text-Attributed Graphs</title>
        <link>https://arxiv.org/abs/2506.08298</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08298v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Trung-Kien Nguyen, Heng Ping, Shixuan Li, Peiyu Zhang, Nikos Kanakaris, Nicholas Kotov, Paul Bogdan</dc:creator>
        <description><![CDATA[
            图学习在多领域的应用推动了图基础模型（GFM）发展。现有研究利用文本属性图（TAGs）处理图中节点特征的异质性，但主要关注同质TAGs，对异质TAGs研究不足。为此，本文提出H²GFM框架，它将图间的多种元关系投影到统一文本空间，用上下文编码捕获空间和高阶语义关系。还提出上下文自适应图变换器（CGT）以获得鲁棒节点表示，并采用CGT专家混合体捕获图结构模式的异质性。综合实验证明了模型有效性。
            arXiv:2506.08298v1 Announce Type: new 
Abstract: The growing interests and applications of graph learning in diverse domains have propelled the development of a unified model generalizing well across different graphs and tasks, known as the Graph Foundation Model (GFM). Existing research has leveraged text-attributed graphs (TAGs) to tackle the heterogeneity in node features among graphs. However, they primarily focus on homogeneous TAGs (HoTAGs), leaving heterogeneous TAGs (HeTAGs), where multiple types of nodes/edges reside, underexplored. To enhance the capabilities and applications of GFM, we introduce H$^2$GFM, a novel framework designed to generalize across both HoTAGs and HeTAGs. Our model projects diverse meta-relations among graphs under a unified textual space, and employs a context encoding to capture spatial and higher-order semantic relationships. To achieve robust node representations, we propose a novel context-adaptive graph transformer (CGT), effectively capturing information from both context neighbors and their relationships. Furthermore, we employ a mixture of CGT experts to capture the heterogeneity in structural patterns among graph types. Comprehensive experiments on a wide range of HoTAGs and HeTAGs as well as learning scenarios demonstrate the effectiveness of our model.
        ]]></description>
    </item>
    <item>
        <title>Learnable Spatial-Temporal Positional Encoding for Link Prediction</title>
        <link>https://arxiv.org/abs/2506.08309</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08309v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Katherine Tieu, Dongqi Fu, Zihao Li, Ross Maciejewski, Jingrui He</dc:creator>
        <description><![CDATA[
            当前图深度学习框架中位置编码机制存在不足，如多采用预定义固定函数、多关注结构信息而忽视时空信息、在大规模结构化数据上注意力机制开销大等。为此，研究人员提出可学习的时空位置编码方法和简单的时间链接预测模型L - STEP。通过多方面验证，证明该方法能从时空频谱角度保留图属性，MLPs可充分发挥其表达能力，且具有鲁棒性。在13个经典数据集和10种算法上表现出色，在最新大规模TGB基准测试中领先，运行时间也少于SOTA。
            arXiv:2506.08309v1 Announce Type: new 
Abstract: Accurate predictions rely on the expressiveness power of graph deep learning frameworks like graph neural networks and graph transformers, where a positional encoding mechanism has become much more indispensable in recent state-of-the-art works to record the canonical position information. However, the current positional encoding is limited in three aspects: (1) most positional encoding methods use pre-defined, and fixed functions, which are inadequate to adapt to the complex attributed graphs; (2) a few pioneering works proposed the learnable positional encoding but are still limited to the structural information, not considering the real-world time-evolving topological and feature information; (3) most positional encoding methods are equipped with transformers' attention mechanism to fully leverage their capabilities, where the dense or relational attention is often unaffordable on large-scale structured data. Hence, we aim to develop Learnable Spatial-Temporal Positional Encoding in an effective and efficient manner and propose a simple temporal link prediction model named L-STEP. Briefly, for L-STEP, we (1) prove the proposed positional learning scheme can preserve the graph property from the spatial-temporal spectral viewpoint, (2) verify that MLPs can fully exploit the expressiveness and reach transformers' performance on that encoding, (3) change different initial positional encoding inputs to show robustness, (4) analyze the theoretical complexity and obtain less empirical running time than SOTA, and (5) demonstrate its temporal link prediction out-performance on 13 classic datasets and with 10 algorithms in both transductive and inductive settings using 3 different sampling strategies. Also, \name\ obtains the leading performance in the newest large-scale TGB benchmark. Our code is available at https://github.com/kthrn22/L-STEP.
        ]]></description>
    </item>
    <item>
        <title>Graph Prompting for Graph Learning Models: Recent Advances and Future Directions</title>
        <link>https://arxiv.org/abs/2506.08326</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08326v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xingbo Fu, Zehong Wang, Zihan Chen, Jiazheng Li, Yaochen Zhu, Zhenyu Lei, Cong Shen, Yanfang Ye, Chuxu Zhang, Jundong Li</dc:creator>
        <description><![CDATA[
            背景：图学习模型在从大规模图数据中学习表达性表示方面表现出色，“预训练、适配”方案是常用策略，图提示是适配阶段有前景的方法。方法：对图提示的近期进展进行系统综述，介绍作为基础的图预训练方法，回顾主流图提示技术及可学习提示的设计，总结不同领域应用。效果：探讨现有研究挑战与未来方向，为图提示研究提供参考。 
            arXiv:2506.08326v1 Announce Type: new 
Abstract: Graph learning models have demonstrated great prowess in learning expressive representations from large-scale graph data in a wide variety of real-world scenarios. As a prevalent strategy for training powerful graph learning models, the "pre-training, adaptation" scheme first pre-trains graph learning models on unlabeled graph data in a self-supervised manner and then adapts them to specific downstream tasks. During the adaptation phase, graph prompting emerges as a promising approach that learns trainable prompts while keeping the pre-trained graph learning models unchanged. In this paper, we present a systematic review of recent advancements in graph prompting. First, we introduce representative graph pre-training methods that serve as the foundation step of graph prompting. Next, we review mainstream techniques in graph prompting and elaborate on how they design learnable prompts for graph prompting. Furthermore, we summarize the real-world applications of graph prompting from different domains. Finally, we discuss several open challenges in existing studies with promising future directions in this field.
        ]]></description>
    </item>
    <item>
        <title>Wait, We Don't Need to "Wait"! Removing Thinking Tokens Improves Reasoning Efficiency</title>
        <link>https://arxiv.org/abs/2506.08343</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08343v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chenlong Wang, Yuanning Feng, Dongping Chen, Zhaoyang Chu, Ranjay Krishna, Tianyi Zhou</dc:creator>
        <description><![CDATA[
            背景：大型推理模型虽能进行复杂的逐步推理，但常出现过度思考，导致输出冗长冗余、效率低下。方法：提出NoWait方法，在推理时通过抑制“Wait”“Hmm”等标记来禁用显式自我反思。效果：在文本、视觉和视频推理任务的十个基准测试中，NoWait在五个R1风格模型系列中最多可将思维链轨迹长度减少27% - 51%，且不影响模型效用，为多模态推理提供了即插即用的高效解决方案。
            arXiv:2506.08343v1 Announce Type: new 
Abstract: Recent advances in large reasoning models have enabled complex, step-by-step reasoning but often introduce significant overthinking, resulting in verbose and redundant outputs that hinder efficiency. In this study, we examine whether explicit self-reflection, signaled by tokens such as "Wait" and "Hmm", is necessary for advanced reasoning. We propose NoWait, a simple yet effective approach that disables explicit self-reflection by suppressing these tokens during inference. Extensive experiments on ten benchmarks across textual, visual, and video reasoning tasks show that NoWait reduces chain-of-thought trajectory length by up to 27%-51% in five R1-style model series, without compromising model utility. NoWait thus offers a plug-and-play solution for efficient and utility-preserving multimodal reasoning.
        ]]></description>
    </item>
    <item>
        <title>MedMoE: Modality-Specialized Mixture of Experts for Medical Vision-Language Understanding</title>
        <link>https://arxiv.org/abs/2506.08356</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08356v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Shivang Chopra, Lingchao Mao, Gabriela Sanchez-Rodriguez, Andrew J Feola, Jing Li, Zsolt Kira</dc:creator>
        <description><![CDATA[
            背景：不同医学成像模态在不同空间分辨率下捕捉诊断信息，而现有医学领域的视觉语言框架多采用统一策略提取局部特征，忽略了模态特定需求。方法：提出MedMoE，一个模块化且可扩展的视觉语言处理框架，通过基于报告类型的专家混合（MoE）模块，让多尺度图像特征通过专门的专家分支，在Swin Transformer骨干网络的特征金字塔上操作。效果：该框架能产生与文本描述对齐的局部视觉表示，在多个医学基准测试中提升了跨成像模态的对齐和检索性能。
            arXiv:2506.08356v1 Announce Type: new 
Abstract: Different medical imaging modalities capture diagnostic information at varying spatial resolutions, from coarse global patterns to fine-grained localized structures. However, most existing vision-language frameworks in the medical domain apply a uniform strategy for local feature extraction, overlooking the modality-specific demands. In this work, we present MedMoE, a modular and extensible vision-language processing framework that dynamically adapts visual representation based on the diagnostic context. MedMoE incorporates a Mixture-of-Experts (MoE) module conditioned on the report type, which routes multi-scale image features through specialized expert branches trained to capture modality-specific visual semantics. These experts operate over feature pyramids derived from a Swin Transformer backbone, enabling spatially adaptive attention to clinically relevant regions. This framework produces localized visual representations aligned with textual descriptions, without requiring modality-specific supervision at inference. Empirical results on diverse medical benchmarks demonstrate that MedMoE improves alignment and retrieval performance across imaging modalities, underscoring the value of modality-specialized visual representations in clinical vision-language systems.
        ]]></description>
    </item>
    <item>
        <title>CC-RAG: Structured Multi-Hop Reasoning via Theme-Based Causal Graphs</title>
        <link>https://arxiv.org/abs/2506.08364</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08364v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jash Rajesh Parekh, Pengcheng Jiang, Jiawei Han</dc:creator>
        <description><![CDATA[
            背景：大语言模型理解因果关系是挑战，标准RAG管道缺乏结构来建模真实因果依赖。方法：提出CC - RAG，将零样本三元组提取和主题感知图链接集成到RAG管道，构建有向无环图，用前向/后向链接引导结构化答案生成。效果：在比特币价格波动和戈谢病两个领域实验表明，CC - RAG在链相似度、信息密度和词汇多样性上优于标准RAG和零样本大语言模型，且得到大语言模型评判和人类评估的认可。
            arXiv:2506.08364v1 Announce Type: new 
Abstract: Understanding cause and effect relationships remains a formidable challenge for Large Language Models (LLMs), particularly in specialized domains where reasoning requires more than surface-level correlations. Retrieval-Augmented Generation (RAG) improves factual accuracy, but standard RAG pipelines treat evidence as flat context, lacking the structure required to model true causal dependencies. We introduce Causal-Chain RAG (CC-RAG), a novel approach that integrates zero-shot triple extraction and theme-aware graph chaining into the RAG pipeline, enabling structured multi-hop inference. Given a domain specific corpus, CC-RAG constructs a Directed Acyclic Graph (DAG) of  triples and uses forward/backward chaining to guide structured answer generation. Experiments on two real-world domains: Bitcoin price fluctuations and Gaucher disease, show that CC-RAG outperforms standard RAG and zero-shot LLMs in chain similarity, information density, and lexical diversity. Both LLM-as-a-Judge and human evaluations consistently favor CC-RAG. Our results demonstrate that explicitly modeling causal structure enables LLMs to generate more accurate and interpretable responses, especially in specialized domains where flat retrieval fails.
        ]]></description>
    </item>
    <item>
        <title>Reinforce LLM Reasoning through Multi-Agent Reflection</title>
        <link>https://arxiv.org/abs/2506.08379</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08379v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yurun Yuan, Tengyang Xie</dc:creator>
        <description><![CDATA[
            背景：利用更多测试时计算量可提升大语言模型推理能力，但现有验证改进范式存在反馈空间受限、各方缺乏协同训练等问题。方法：将多轮改进过程建模为马尔可夫决策过程，引入强化学习算法DPSDP，通过对自生成数据的直接偏好学习训练演员 - 评论家大语言模型系统迭代改进答案。效果：理论上DPSDP能匹配训练分布内任何策略性能，实证中在多个基准测试有提升，如在MATH 500基准上，基于Ministral模型经五步改进后首轮准确率从58.2%提升到63.2% 。
            arXiv:2506.08379v1 Announce Type: new 
Abstract: Leveraging more test-time computation has proven to be an effective way to boost the reasoning capabilities of large language models (LLMs). Among various methods, the verify-and-improve paradigm stands out for enabling dynamic solution exploration and feedback incorporation. However, existing approaches often suffer from restricted feedback spaces and lack of coordinated training of different parties, leading to suboptimal performance. To address this, we model this multi-turn refinement process as a Markov Decision Process and introduce DPSDP (Direct Policy Search by Dynamic Programming), a reinforcement learning algorithm that trains an actor-critic LLM system to iteratively refine answers via direct preference learning on self-generated data. Theoretically, DPSDP can match the performance of any policy within the training distribution. Empirically, we instantiate DPSDP with various base models and show improvements on both in- and out-of-distribution benchmarks. For example, on benchmark MATH 500, majority voting over five refinement steps increases first-turn accuracy from 58.2% to 63.2% with Ministral-based models. An ablation study further confirms the benefits of multi-agent collaboration and out-of-distribution generalization.
        ]]></description>
    </item>
    <item>
        <title>Efficient Context Selection for Long-Context QA: No Tuning, No Iteration, Just Adaptive-$k$</title>
        <link>https://arxiv.org/abs/2506.08479</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08479v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chihiro Taguchi, Seiji Maekawa, Nikita Bhutani</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）和长上下文语言模型（LCLMs）虽能解决大语言模型（LLMs）在开放域问答中的上下文限制问题，但如何检索最优外部上下文仍是难题。方法：提出Adaptive - $k$检索，这是一种基于查询与候选段落相似度得分分布自适应选择段落数量的单遍方法，无需模型微调等。效果：在事实类和聚合类问答基准测试中，该方法能匹配或超越固定$k$基线，使用的令牌最多减少10倍，还能检索到70%的相关段落，提高了五个LCLMs和两个嵌入模型的准确率。
            arXiv:2506.08479v1 Announce Type: new 
Abstract: Retrieval-augmented generation (RAG) and long-context language models (LCLMs) both address context limitations of LLMs in open-domain question answering (QA). However, optimal external context to retrieve remains an open problem: fixing the retrieval size risks either wasting tokens or omitting key evidence. Existing adaptive methods like Self-RAG and Self-Route rely on iterative LLM prompting and perform well on factoid QA, but struggle with aggregation QA, where the optimal context size is both unknown and variable. We present Adaptive-$k$ retrieval, a simple and effective single-pass method that adaptively selects the number of passages based on the distribution of the similarity scores between the query and the candidate passages. It does not require model fine-tuning, extra LLM inferences or changes to existing retriever-reader pipelines. On both factoid and aggregation QA benchmarks, Adaptive-$k$ matches or outperforms fixed-$k$ baselines while using up to 10x fewer tokens than full-context input, yet still retrieves 70% of relevant passages. It improves accuracy across five LCLMs and two embedding models, highlighting that dynamically adjusting context size leads to more efficient and accurate QA.
        ]]></description>
    </item>
    <item>
        <title>DRAGged into Conflicts: Detecting and Addressing Conflicting Sources in Search-Augmented LLMs</title>
        <link>https://arxiv.org/abs/2506.08500</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08500v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Arie Cattan, Alon Jacovi, Ori Ram, Jonathan Herzig, Roee Aharoni, Sasha Goldshtein, Eran Ofek, Idan Szpektor, Avi Caciularu</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）用于增强大语言模型信息，但检索源常存在冲突信息，模型如何处理尚不明确。方法：提出RAG中知识冲突类型的新分类法及对应模型行为，引入有专家标注的高质量基准CONFLICTS。效果：实验表明大语言模型难以恰当解决源间冲突，提示模型明确推理检索文档中的潜在冲突能显著提升回答质量与恰当性，但仍有改进空间。
            arXiv:2506.08500v1 Announce Type: new 
Abstract: Retrieval Augmented Generation (RAG) is a commonly used approach for enhancing large language models (LLMs) with relevant and up-to-date information. However, the retrieved sources can often contain conflicting information and it remains unclear how models should address such discrepancies. In this work, we first propose a novel taxonomy of knowledge conflict types in RAG, along with the desired model behavior for each type. We then introduce CONFLICTS, a high-quality benchmark with expert annotations of conflict types in a realistic RAG setting. CONFLICTS is the first benchmark that enables tracking progress on how models address a wide range of knowledge conflicts. We conduct extensive experiments on this benchmark, showing that LLMs often struggle to appropriately resolve conflicts between sources. While prompting LLMs to explicitly reason about the potential conflict in the retrieved documents significantly improves the quality and appropriateness of their responses, substantial room for improvement in future research remains.
        ]]></description>
    </item>
    <item>
        <title>Convergence of Spectral Principal Paths: How Deep Networks Distill Linear Representations from Noisy Inputs</title>
        <link>https://arxiv.org/abs/2506.08543</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08543v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Bowei Tian, Xuntao Lyu, Meng Liu, Hongyi Wang, Ang Li</dc:creator>
        <description><![CDATA[
            背景：高级表征成为提升AI透明度和可控性的关键，人们关注与人类可解释概念对齐的结构化语义方向。方法：受线性表征假设启发，提出输入空间线性假设，认为概念对齐方向源于输入空间并随网络深度增强；引入光谱主路径（SPP）框架，阐述深度网络沿主导光谱方向提炼线性表征的过程。效果：证明了这些表征在视觉语言模型中的多模态鲁棒性，推动了深度网络表征形成的结构化理论发展，有助于提升AI的鲁棒性、公平性和透明度。
            arXiv:2506.08543v1 Announce Type: new 
Abstract: High-level representations have become a central focus in enhancing AI transparency and control, shifting attention from individual neurons or circuits to structured semantic directions that align with human-interpretable concepts. Motivated by the Linear Representation Hypothesis (LRH), we propose the Input-Space Linearity Hypothesis (ISLH), which posits that concept-aligned directions originate in the input space and are selectively amplified with increasing depth. We then introduce the Spectral Principal Path (SPP) framework, which formalizes how deep networks progressively distill linear representations along a small set of dominant spectral directions. Building on this framework, we further demonstrate the multimodal robustness of these representations in Vision-Language Models (VLMs). By bridging theoretical insights with empirical validation, this work advances a structured theory of representation formation in deep networks, paving the way for improving AI robustness, fairness, and transparency.
        ]]></description>
    </item>
    <item>
        <title>Efficient Post-Training Refinement of Latent Reasoning in Large Language Models</title>
        <link>https://arxiv.org/abs/2506.08552</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08552v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xinyuan Wang, Dongjie Wang, Wangyang Ying, Haoyue Bai, Nanxu Gong, Sixun Dong, Kunpeng Liu, Yanjie Fu</dc:creator>
        <description><![CDATA[
            推理是大语言模型语言理解的关键部分。思维链提示虽能通过显式中间步骤提升性能，但存在标记开销大、推理轨迹固定等问题。近期潜在推理研究虽有进展，但如何在训练后有效更新推理嵌入仍是挑战。为此，本文提出轻量级训练后框架，采用对比推理反馈和残差嵌入细化两种策略优化潜在推理轨迹。在五个推理基准测试的实验表明，该框架有效，如在MathQA上无额外训练就提升了5%的准确率。
            arXiv:2506.08552v1 Announce Type: new 
Abstract: Reasoning is a key component of language understanding in Large Language Models. While Chain-of-Thought prompting enhances performance via explicit intermediate steps, it suffers from sufficient token overhead and a fixed reasoning trajectory, preventing step-wise refinement. Recent advances in latent reasoning address these limitations by refining internal reasoning processes directly in the model's latent space, without producing explicit outputs. However, a key challenge remains: how to effectively update reasoning embeddings during post-training to guide the model toward more accurate solutions. To overcome this challenge, we propose a lightweight post-training framework that refines latent reasoning trajectories using two novel strategies: 1) Contrastive reasoning feedback, which compares reasoning embeddings against strong and weak baselines to infer effective update directions via embedding enhancement; 2) Residual embedding refinement, which stabilizes updates by progressively integrating current and historical gradients, enabling fast yet controlled convergence. Extensive experiments and case studies are conducted on five reasoning benchmarks to demonstrate the effectiveness of the proposed framework. Notably, a 5\% accuracy gain on MathQA without additional training.
        ]]></description>
    </item>
    <item>
        <title>From Pixels to Graphs: using Scene and Knowledge Graphs for HD-EPIC VQA Challenge</title>
        <link>https://arxiv.org/abs/2506.08553</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08553v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Agnese Taluzzi, Davide Gesualdi, Riccardo Santambrogio, Chiara Plizzari, Francesca Palermo, Simone Mentasti, Matteo Matteucci</dc:creator>
        <description><![CDATA[
            该论文背景是应对HD - EPIC VQA Challenge 2025。方法上提出SceneNet和KnowledgeNet，SceneNet利用多模态大模型生成场景图，捕捉细粒度对象交互、空间关系和时间事件；KnowledgeNet引入ConceptNet外部常识知识，建立实体间高级语义联系。效果上，两种方法在HD - EPIC基准七类任务各有优势，结合后在挑战中整体准确率达44.21%，对复杂第一人称视角视觉问答任务有效。
            arXiv:2506.08553v1 Announce Type: new 
Abstract: This report presents SceneNet and KnowledgeNet, our approaches developed for the HD-EPIC VQA Challenge 2025. SceneNet leverages scene graphs generated with a multi-modal large language model (MLLM) to capture fine-grained object interactions, spatial relationships, and temporally grounded events. In parallel, KnowledgeNet incorporates ConceptNet's external commonsense knowledge to introduce high-level semantic connections between entities, enabling reasoning beyond directly observable visual evidence. Each method demonstrates distinct strengths across the seven categories of the HD-EPIC benchmark, and their combination within our framework results in an overall accuracy of 44.21% on the challenge, highlighting its effectiveness for complex egocentric VQA tasks.
        ]]></description>
    </item>
    <item>
        <title>Diffusion-based Time Series Forecasting for Sewerage Systems</title>
        <link>https://arxiv.org/abs/2506.08577</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08577v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Nicholas A. Pearson, Francesca Cairoli, Luca Bortolussi, Davide Russo, Francesca Zanello</dc:creator>
        <description><![CDATA[
            背景：为提高污水系统情境预测的准确性。方法：开发一种基于扩散的模型处理多元时间序列数据，以捕捉不同环境信号间的复杂关联；用适用于概率时间序列数据的共形推理技术校准模型预测。效果：能在极端天气事件中进行可靠预测，通过对真实污水系统数据的实证测试，证实该模型可提供可靠的情境预测，即使在恶劣天气条件下也能保持准确性。
            arXiv:2506.08577v1 Announce Type: new 
Abstract: We introduce a novel deep learning approach that harnesses the power of generative artificial intelligence to enhance the accuracy of contextual forecasting in sewerage systems. By developing a diffusion-based model that processes multivariate time series data, our system excels at capturing complex correlations across diverse environmental signals, enabling robust predictions even during extreme weather events. To strengthen the model's reliability, we further calibrate its predictions with a conformal inference technique, tailored for probabilistic time series data, ensuring that the resulting prediction intervals are statistically reliable and cover the true target values with a desired confidence level. Our empirical tests on real sewerage system data confirm the model's exceptional capability to deliver reliable contextual predictions, maintaining accuracy even under severe weather conditions.
        ]]></description>
    </item>
    <item>
        <title>CALT: A Library for Computer Algebra with Transformer</title>
        <link>https://arxiv.org/abs/2506.08600</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08600v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hiroshi Kera, Shun Arakawa, Yuta Sato</dc:creator>
        <description><![CDATA[
            背景：人工智能的发展使通过端到端深度学习实现符号计算的可学习性成为可能，Transformer 模型可经训练模拟计算，这带来新挑战与研究方向。方法：介绍了一个名为 CALT 的用户友好型 Python 库。效果：该库旨在帮助深度学习非专家训练用于符号计算任务的模型，有助于推动相关研究发展。
            arXiv:2506.08600v1 Announce Type: new 
Abstract: Recent advances in artificial intelligence have demonstrated the learnability of symbolic computation through end-to-end deep learning. Given a sufficient number of examples of symbolic expressions before and after the target computation, Transformer models - highly effective learners of sequence-to-sequence functions - can be trained to emulate the computation. This development opens up several intriguing challenges and new research directions, which require active contributions from the symbolic computation community. In this work, we introduce Computer Algebra with Transformer (CALT), a user-friendly Python library designed to help non-experts in deep learning train models for symbolic computation tasks.
        ]]></description>
    </item>
    <item>
        <title>Time Series Representations for Classification Lie Hidden in Pretrained Vision Transformers</title>
        <link>https://arxiv.org/abs/2506.08641</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08641v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Simon Roschmann, Quentin Bouniot, Vasilii Feofanov, Ievgen Redko, Zeynep Akata</dc:creator>
        <description><![CDATA[
            时间序列分类是医疗和工业领域的基础任务，但时间序列基础模型发展受公开数据集稀缺限制。本文提出Time Vision Transformer（TiViT）框架，将时间序列转换为图像以利用预训练视觉Transformer（ViT）的表征能力。理论上分析ViT二维分块用于时间序列可增加标签相关标记数量、降低样本复杂度；实验表明，利用大模型OpenCLIP的隐藏表征，TiViT在标准时间序列分类基准上达最优性能。研究发现中间高本征维度层最有效，且TiViT与时间序列基础模型表征空间有强互补性，结合特征可进一步提升性能。
            arXiv:2506.08641v1 Announce Type: new 
Abstract: Time series classification is a fundamental task in healthcare and industry, yet the development of time series foundation models (TSFMs) remains limited by the scarcity of publicly available time series datasets. In this work, we propose Time Vision Transformer (TiViT), a framework that converts time series into images to leverage the representational power of frozen Vision Transformers (ViTs) pretrained on large-scale image datasets. First, we theoretically motivate our approach by analyzing the 2D patching of ViTs for time series, showing that it can increase the number of label-relevant tokens and reduce the sample complexity. Second, we empirically demonstrate that TiViT achieves state-of-the-art performance on standard time series classification benchmarks by utilizing the hidden representations of large OpenCLIP models. We explore the structure of TiViT representations and find that intermediate layers with high intrinsic dimension are the most effective for time series classification. Finally, we assess the alignment between TiViT and TSFM representation spaces and identify a strong complementarity, with further performance gains achieved by combining their features. Our findings reveal yet another direction for reusing vision representations in a non-visual domain.
        ]]></description>
    </item>
    <item>
        <title>MEMETRON: Metaheuristic Mechanisms for Test-time Response Optimization of Large Language Models</title>
        <link>https://arxiv.org/abs/2506.08643</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08643v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Son The Nguyen, Theja Tulabandhula</dc:creator>
        <description><![CDATA[
            背景：大语言模型在开放式和结构化任务中应用渐多，但推理时多依赖启发式解码策略，对特定任务目标优化有限。方法：提出MEMETRON框架，将大语言模型解码视为离散黑盒优化问题，利用混合元启发式算法搜索响应空间，由奖励模型和大语言模型自身的上下文操作引导。效果：该框架无需模型再训练或梯度访问，模块化且适用于多样任务，在人类偏好对齐任务中显著优于标准解码和重排序方法。
            arXiv:2506.08643v1 Announce Type: new 
Abstract: Large language models (LLMs) are increasingly used for both open-ended and structured tasks, yet their inference-time behavior is still largely dictated by heuristic decoding strategies such as greedy search, sampling, or reranking. These methods provide limited control and do not explicitly optimize for task-specific objectives. We introduce MEMETRON, a task-agnostic framework that formulates LLM decoding as a discrete black-box optimization problem. MEMETRON leverages hybrid metaheuristic algorithms, GENETRON and ANNETRON, to search the response space, guided by reward models and contextual operations performed by the LLM itself. This approach enables efficient discovery of high-reward responses without requiring model retraining or gradient access. The framework is modular and generalizes across diverse tasks, requiring only a reward function and lightweight prompt templates. We evaluate our framework on the critical human preference alignment task and demonstrate that it significantly outperforms standard decoding and reranking methods, highlighting its potential to improve alignment without model retraining.
        ]]></description>
    </item>
    <item>
        <title>TableDreamer: Progressive and Weakness-guided Data Synthesis from Scratch for Table Instruction Tuning</title>
        <link>https://arxiv.org/abs/2506.08646</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08646v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mingyu Zheng, Zhifan Feng, Jia Wang, Lanrui Wang, Zheng Lin, Yang Hao, Weiping Wang</dc:creator>
        <description><![CDATA[
            近期基于大语言模型的数据合成方法在生成表格指令调优数据时存在局限，一是无法充分探索表格理解任务输入空间，数据多样性有限；二是忽视目标大模型弱点，盲目增加数据量，效率不佳。为此，本文提出针对表格指令调优的渐进式、弱点引导的数据合成框架TableDreamer。先合成多样表格及相关指令作为种子数据，再在新识别的弱点数据引导下迭代探索输入空间，生成最终训练数据。在10个表格基准测试上的实验表明，该框架有效，用2.7万条GPT - 4o合成数据使Llama3.1 - 8B - instruct平均准确率提升11.62%，优于使用更多训练数据的现有方法。
            arXiv:2506.08646v1 Announce Type: new 
Abstract: Despite the commendable progress of recent LLM-based data synthesis methods, they face two limitations in generating table instruction tuning data. First, they can not thoroughly explore the vast input space of table understanding tasks, leading to limited data diversity. Second, they ignore the weaknesses in table understanding ability of the target LLM and blindly pursue the increase of data quantity, resulting in suboptimal data efficiency. In this paper, we introduce a progressive and weakness-guided data synthesis framework tailored for table instruction tuning, named TableDreamer, to mitigate the above issues. Specifically, we first synthesize diverse tables and related instructions as seed data, and then perform an iterative exploration of the input space under the guidance of the newly identified weakness data, which eventually serve as the final training data for fine-tuning the target LLM. Extensive experiments on 10 tabular benchmarks demonstrate the effectiveness of the proposed framework, which boosts the average accuracy of Llama3.1-8B-instruct by 11.62% (49.07% to 60.69%) with 27K GPT-4o synthetic data and outperforms state-of-the-art data synthesis baselines which use more training data. The code and data is available at https://github.com/SpursGoZmy/TableDreamer
        ]]></description>
    </item>
    <item>
        <title>Summarization for Generative Relation Extraction in the Microbiome Domain</title>
        <link>https://arxiv.org/abs/2506.08647</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08647v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Oumaima El Khettari, Solen Quiniou, Samuel Chaffron</dc:creator>
        <description><![CDATA[
            该论文背景是肠道微生物组这一复杂且资源有限的生物医学领域的相互作用研究。方法是利用大语言模型（LLMs）进行摘要提炼，在通过指令调优生成来提取关系之前优化上下文。初步结果显示，摘要提炼通过减少噪声和引导模型，提高了生成式关系提取（RE）的性能，但基于BERT的RE方法仍优于生成式模型。此研究展示了生成式方法在低资源环境下支持专业领域研究的潜力。
            arXiv:2506.08647v1 Announce Type: new 
Abstract: We explore a generative relation extraction (RE) pipeline tailored to the study of interactions in the intestinal microbiome, a complex and low-resource biomedical domain. Our method leverages summarization with large language models (LLMs) to refine context before extracting relations via instruction-tuned generation. Preliminary results on a dedicated corpus show that summarization improves generative RE performance by reducing noise and guiding the model. However, BERT-based RE approaches still outperform generative models. This ongoing work demonstrates the potential of generative methods to support the study of specialized domains in low-resources setting.
        ]]></description>
    </item>
    <item>
        <title>JoFormer (Journey-based Transformer): Theory and Empirical Analysis on the Tiny Shakespeare Dataset</title>
        <link>https://arxiv.org/abs/2506.08652</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08652v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mahesh Godavarti</dc:creator>
        <description><![CDATA[
            背景：Transformer在序列建模中取得成功，但有效融入位置信息仍是研究难点。方法：提出基于旅程的Transformer架构JoFormer，基于非交换代数，通过可学习的方向变换表示相对位置，推导其注意力机制。效果：在Tiny Shakespeare字符级语言建模任务中与RoFormer对比，JoFormer困惑度更低、收敛更快，虽其单令牌版本是初步概念变体，但已展现良好性能，为更具表达力的架构提供了思路。
            arXiv:2506.08652v1 Announce Type: new 
Abstract: Transformers have demonstrated remarkable success in sequence modeling, yet effectively incorporating positional information remains a challenging and active area of research. In this paper, we introduce JoFormer, a journey-based Transformer architecture grounded in a recently proposed non-commutative algebra for composing transformations across positions. JoFormer represents relative positions through learnable directional transforms that are sequentially composed along the input, thereby extending and generalizing existing approaches based on relative position representations. We derive the JoFormer attention mechanism from first principles and show that it subsumes standard methods such as rotary transformations as special cases. To evaluate its effectiveness, we compare JoFormer to the RoFormer baseline on the Tiny Shakespeare character-level language modeling task. Our results demonstrate that
  JoFormer consistently achieves lower perplexity and faster convergence, highlighting the advantages of its more expressive, journey-based treatment of position. Notably, the per-token JoFormer is still a primitive, conceptual variant with layer-independent angles, yet it already demonstrates strong performance-underscoring its promise as a proof of concept for more expressive architectures. We conclude by discussing how JoFormer offers a principled approach to integrating positional structure into Transformer architectures. The code used in this work is available at https://github.com/mahesh-godavarti/joformer.
        ]]></description>
    </item>
    <item>
        <title>Towards Robust Real-World Multivariate Time Series Forecasting: A Unified Framework for Dependency, Asynchrony, and Missingness</title>
        <link>https://arxiv.org/abs/2506.08660</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08660v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jinkwan Jang, Hyungjin Park, Jinmyeong Choi, Taesup Kim</dc:creator>
        <description><![CDATA[
            现实世界的多元时间序列数据存在复杂的通道间依赖、采样异步和缺失值问题，而现有模型假设过于简化，难以应对实际场景。为此，研究人员提出了基于Transformer的ChannelTokenFormer模型，该模型能捕捉跨通道交互、适应通道异步采样并处理缺失值。在三个模拟实际场景的基准数据集和一个真实工业数据集上的实验表明，该模型在现实复杂条件下具有更强的鲁棒性和更高的准确性。
            arXiv:2506.08660v1 Announce Type: new 
Abstract: Real-world time series data are inherently multivariate, often exhibiting complex inter-channel dependencies. Each channel is typically sampled at its own period and is prone to missing values due to various practical and operational constraints. These characteristics pose fundamental challenges related to channel dependency, sampling asynchrony, and missingness, all of which must be addressed to enable robust and reliable forecasting in practical settings. However, most existing architectures are built on oversimplified assumptions, such as identical sampling periods across channels and fully observed inputs at test time, which often do not hold in real-world scenarios. To bridge this gap, we propose ChannelTokenFormer, a Transformer-based forecasting model with a flexible architecture designed to explicitly capture cross-channel interactions, accommodate channel-wise asynchronous sampling, and effectively handle missing values. Extensive experiments on three benchmark datasets modified to reflect practical settings, along with one real-world industrial dataset, demonstrate the superior robustness and accuracy of ChannelTokenFormer under challenging real-world conditions.
        ]]></description>
    </item>
    <item>
        <title>ClimateViz: A Benchmark for Statistical Reasoning and Fact Verification on Scientific Charts</title>
        <link>https://arxiv.org/abs/2506.08700</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08700v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ruiran Su, Jiasheng Si, Zhijiang Guo, Janet B. Pierrehumbert</dc:creator>
        <description><![CDATA[
            背景：科学事实核查多关注文本和表格，忽略了用于呈现定量证据和统计推理的科学图表。方法：引入首个使用专家整理科学图表的大规模基准ClimateViz，包含49,862条与2,896个可视化关联的声明，并标注支持、反驳或信息不足，每个示例含结构化知识图谱解释；评估零样本和少样本设置下的先进多模态语言模型。效果：当前模型图表推理能力欠佳，最佳系统准确率仅76.2 - 77.8%，远低于人类的89.3 - 92.7%，部分模型解释增强输出可提升性能。
            arXiv:2506.08700v1 Announce Type: new 
Abstract: Scientific fact-checking has mostly focused on text and tables, overlooking scientific charts, which are key for presenting quantitative evidence and statistical reasoning. We introduce ClimateViz, the first large-scale benchmark for scientific fact-checking using expert-curated scientific charts. ClimateViz contains 49,862 claims linked to 2,896 visualizations, each labeled as support, refute, or not enough information. To improve interpretability, each example includes structured knowledge graph explanations covering trends, comparisons, and causal relations. We evaluate state-of-the-art multimodal language models, including both proprietary and open-source systems, in zero-shot and few-shot settings. Results show that current models struggle with chart-based reasoning: even the best systems, such as Gemini 2.5 and InternVL 2.5, reach only 76.2 to 77.8 percent accuracy in label-only settings, far below human performance (89.3 and 92.7 percent). Explanation-augmented outputs improve performance in some models. We released our dataset and code alongside the paper.
        ]]></description>
    </item>
    <item>
        <title>Explainable Compliance Detection with Multi-Hop Natural Language Inference on Assurance Case Structure</title>
        <link>https://arxiv.org/abs/2506.08713</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08713v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Fariz Ikhwantri, Dusica Marijan</dc:creator>
        <description><![CDATA[
            背景：确保复杂系统符合法规需通过声明 - 论证 - 证据框架检查保证案例的有效性，存在法律和技术文本复杂、需模型解释、保证案例数据有限等挑战。方法：提出基于自然语言推理（NLI）的合规检测方法EXCLAIM，将保证案例结构化为多跳推理，用大语言模型（LLMs）生成保证案例，引入衡量覆盖度和结构一致性的指标。效果：通过案例研究证明生成的保证案例在多跳推理任务中的有效性，凸显基于NLI方法在自动化合规流程中的潜力。
            arXiv:2506.08713v1 Announce Type: new 
Abstract: Ensuring complex systems meet regulations typically requires checking the validity of assurance cases through a claim-argument-evidence framework. Some challenges in this process include the complicated nature of legal and technical texts, the need for model explanations, and limited access to assurance case data. We propose a compliance detection approach based on Natural Language Inference (NLI): EXplainable CompLiance detection with Argumentative Inference of Multi-hop reasoning (EXCLAIM). We formulate the claim-argument-evidence structure of an assurance case as a multi-hop inference for explainable and traceable compliance detection. We address the limited number of assurance cases by generating them using large language models (LLMs). We introduce metrics that measure the coverage and structural consistency. We demonstrate the effectiveness of the generated assurance case from GDPR requirements in a multi-hop inference task as a case study. Our results highlight the potential of NLI-based approaches in automating the regulatory compliance process.
        ]]></description>
    </item>
    <item>
        <title>Improved LLM Agents for Financial Document Question Answering</title>
        <link>https://arxiv.org/abs/2506.08726</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08726v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Nelvin Tan, Zian Seng, Liang Zhang, Yu-Ching Shih, Dong Yang, Amol Salunkhe</dc:creator>
        <description><![CDATA[
            背景：大语言模型在自然语言处理任务表现出色，但处理含表格和文本数据的金融文档数值问答仍有困难，此前有研究表明在有标签时批评代理用于此任务有效。方法：本文研究无标签时传统批评代理效果，提出改进的批评代理和计算器代理，还探究了代理间的交互。效果：改进的代理优于此前最优方法（思维程序）且更安全。
            arXiv:2506.08726v1 Announce Type: new 
Abstract: Large language models (LLMs) have shown impressive capabilities on numerous natural language processing tasks. However, LLMs still struggle with numerical question answering for financial documents that include tabular and textual data. Recent works have showed the effectiveness of critic agents (i.e., self-correction) for this task given oracle labels. Building upon this framework, this paper examines the effectiveness of the traditional critic agent when oracle labels are not available, and show, through experiments, that this critic agent's performance deteriorates in this scenario. With this in mind, we present an improved critic agent, along with the calculator agent which outperforms the previous state-of-the-art approach (program-of-thought) and is safer. Furthermore, we investigate how our agents interact with each other, and how this interaction affects their performance.
        ]]></description>
    </item>
    <item>
        <title>Video-CoT: A Comprehensive Dataset for Spatiotemporal Understanding of Videos Based on Chain-of-Thought</title>
        <link>https://arxiv.org/abs/2506.08817</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08817v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Shuyi Zhang, Xiaoshuai Hao, Yingbo Tang, Lingfeng Zhang, Pengwei Wang, Zhongyuan Wang, Hongxuan Ma, Shanghang Zhang</dc:creator>
        <description><![CDATA[
            视频内容理解对诸多应用至关重要，但现有大规模视觉语言模型难以捕捉视频的时空细节。为此，研究团队引入Video - CoT数据集，其包含192000个细粒度时空问答对和23000个高质量思维链标注样本，还提供含750张图像及定制评估指标的综合基准。大量实验表明，当前视觉语言模型在时空理解任务中表现不佳。该数据集和基准为多媒体理解研究开辟新途径，推动智能系统的视频分析能力创新。
            arXiv:2506.08817v1 Announce Type: new 
Abstract: Video content comprehension is essential for various applications, ranging from video analysis to interactive systems. Despite advancements in large-scale vision-language models (VLMs), these models often struggle to capture the nuanced, spatiotemporal details essential for thorough video analysis. To address this gap, we introduce Video-CoT, a groundbreaking dataset designed to enhance spatiotemporal understanding using Chain-of-Thought (CoT) methodologies. Video-CoT contains 192,000 fine-grained spa-tiotemporal question-answer pairs and 23,000 high-quality CoT-annotated samples, providing a solid foundation for evaluating spatiotemporal understanding in video comprehension. Additionally, we provide a comprehensive benchmark for assessing these tasks, with each task featuring 750 images and tailored evaluation metrics. Our extensive experiments reveal that current VLMs face significant challenges in achieving satisfactory performance, high-lighting the difficulties of effective spatiotemporal understanding. Overall, the Video-CoT dataset and benchmark open new avenues for research in multimedia understanding and support future innovations in intelligent systems requiring advanced video analysis capabilities. By making these resources publicly available, we aim to encourage further exploration in this critical area. Project website:https://video-cot.github.io/ .
        ]]></description>
    </item>
    <item>
        <title>Adapting to Heterophilic Graph Data with Structure-Guided Neighbor Discovery</title>
        <link>https://arxiv.org/abs/2506.08871</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08871v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Victor M. Tenorio, Madeline Navarro, Samuel Rey, Santiago Segarra, Antonio G. Marques</dc:creator>
        <description><![CDATA[
            背景：图神经网络（GNNs）处理异质图数据时，因常假设同质性和依赖局部消息传递而面临挑战。方法：提出通过连接具有相似结构属性的节点创建新图结构，以提高标签同质性；理论证明利用假正边少的图可提升GNN性能，考虑多图视图更易找到有益结构；引入SG - GNN架构，同时处理原图和新图并自适应加权。效果：在多个基准数据集上，尤其异质图数据，SG - GNN达最优或极具竞争力的性能。
            arXiv:2506.08871v1 Announce Type: new 
Abstract: Graph Neural Networks (GNNs) often struggle with heterophilic data, where connected nodes may have dissimilar labels, as they typically assume homophily and rely on local message passing. To address this, we propose creating alternative graph structures by linking nodes with similar structural attributes (e.g., role-based or global), thereby fostering higher label homophily on these new graphs. We theoretically prove that GNN performance can be improved by utilizing graphs with fewer false positive edges (connections between nodes of different classes) and that considering multiple graph views increases the likelihood of finding such beneficial structures. Building on these insights, we introduce Structure-Guided GNN (SG-GNN), an architecture that processes the original graph alongside the newly created structural graphs, adaptively learning to weigh their contributions. Extensive experiments on various benchmark datasets, particularly those with heterophilic characteristics, demonstrate that our SG-GNN achieves state-of-the-art or highly competitive performance, highlighting the efficacy of exploiting structural information to guide GNNs.
        ]]></description>
    </item>
    <item>
        <title>InfoDPCCA: Information-Theoretic Dynamic Probabilistic Canonical Correlation Analysis</title>
        <link>https://arxiv.org/abs/2506.08884</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08884v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Shiqin Tang, Shujian Yu</dc:creator>
        <description><![CDATA[
            从高维序列数据中提取有意义的潜在表征是机器学习的关键挑战。本文提出InfoDPCCA，一个动态概率典型相关分析框架，用于建模两个相互依赖的观测序列。它利用信息论目标提取共享潜在表征，捕捉数据流间的相互结构，平衡表征压缩与预测充分性，还学习特定于每个序列的潜在分量。与以往模型不同，它强制共享潜在空间仅编码序列间的互信息，提升了可解释性和鲁棒性。采用两步训练方案和残差连接机制，实验表明其在表征学习方面表现出色。
            arXiv:2506.08884v1 Announce Type: new 
Abstract: Extracting meaningful latent representations from high-dimensional sequential data is a crucial challenge in machine learning, with applications spanning natural science and engineering. We introduce InfoDPCCA, a dynamic probabilistic Canonical Correlation Analysis (CCA) framework designed to model two interdependent sequences of observations. InfoDPCCA leverages a novel information-theoretic objective to extract a shared latent representation that captures the mutual structure between the data streams and balances representation compression and predictive sufficiency while also learning separate latent components that encode information specific to each sequence. Unlike prior dynamic CCA models, such as DPCCA, our approach explicitly enforces the shared latent space to encode only the mutual information between the sequences, improving interpretability and robustness. We further introduce a two-step training scheme to bridge the gap between information-theoretic representation learning and generative modeling, along with a residual connection mechanism to enhance training stability. Through experiments on synthetic and medical fMRI data, we demonstrate that InfoDPCCA excels as a tool for representation learning. Code of InfoDPCCA is available at https://github.com/marcusstang/InfoDPCCA.
        ]]></description>
    </item>
    <item>
        <title>From Legal Texts to Defeasible Deontic Logic via LLMs: A Study in Automated Semantic Analysis</title>
        <link>https://arxiv.org/abs/2506.08899</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08899v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Elias Horner, Cristinel Mateis, Guido Governatori, Agata Ciabattoni</dc:creator>
        <description><![CDATA[
            背景：旨在利用大语言模型对法律文本进行自动化语义分析并转化为可废止道义逻辑的形式表示。方法：提出结构化流程，将复杂规范语言分割成原子片段，提取道义规则并评估其句法和语义连贯性，还在多种大语言模型配置下进行评估。效果：实证结果显示，机器生成的形式化表示与专家制作的有良好的一致性，表明有效提示的大语言模型能显著推动可扩展的法律信息学发展。
            arXiv:2506.08899v1 Announce Type: new 
Abstract: We present a novel approach to the automated semantic analysis of legal texts using large language models (LLMs), targeting their transformation into formal representations in Defeasible Deontic Logic (DDL). We propose a structured pipeline that segments complex normative language into atomic snippets, extracts deontic rules, and evaluates them for syntactic and semantic coherence. Our methodology is evaluated across various LLM configurations, including prompt engineering strategies, fine-tuned models, and multi-stage pipelines, focusing on legal norms from the Australian Telecommunications Consumer Protections Code. Empirical results demonstrate promising alignment between machine-generated and expert-crafted formalizations, showing that LLMs - particularly when prompted effectively - can significantly contribute to scalable legal informatics.
        ]]></description>
    </item>
    <item>
        <title>Socratic-MCTS: Test-Time Visual Reasoning by Asking the Right Questions</title>
        <link>https://arxiv.org/abs/2506.08927</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08927v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>David Acuna, Ximing Lu, Jaehun Jung, Hyunwoo Kim, Amlan Kar, Sanja Fidler, Yejin Choi</dc:creator>
        <description><![CDATA[
            背景：现有研究围绕通过蒸馏和强化学习让视觉语言模型具备隐式长形式思维链推理能力，而对于已部署的非推理模型，需探索不额外训练或监督来激发其隐藏知识和诱导长推理轨迹的方法。方法：采用受蒙特卡罗树搜索启发的算法，向模型输出流注入子问题 - 子答案对。效果：在三个基准测试中表现一致提升，在MMMU - PRO上总体提升2%，文科方面显著提升9%。
            arXiv:2506.08927v1 Announce Type: new 
Abstract: Recent research in vision-language models (VLMs) has centered around the possibility of equipping them with implicit long-form chain-of-thought reasoning -- akin to the success observed in language models -- via distillation and reinforcement learning. But what about the non-reasoning models already trained and deployed across the internet? Should we simply abandon them, or is there hope for a search mechanism that can elicit hidden knowledge and induce long reasoning traces -- without any additional training or supervision? In this paper, we explore this possibility using a Monte Carlo Tree Search (MCTS)-inspired algorithm, which injects subquestion-subanswer pairs into the model's output stream. We show that framing reasoning as a search process -- where subquestions act as latent decisions within a broader inference trajectory -- helps the model "connect the dots" between fragmented knowledge and produce extended reasoning traces in non-reasoning models. We evaluate our method across three benchmarks and observe consistent improvements. Notably, our approach yields a 2% overall improvement on MMMU-PRO, including a significant 9% gain in Liberal Arts.
        ]]></description>
    </item>
    <item>
        <title>What Limits Virtual Agent Application? OmniBench: A Scalable Multi-Dimensional Benchmark for Essential Virtual Agent Capabilities</title>
        <link>https://arxiv.org/abs/2506.08933</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08933v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wendong Bu, Yang Wu, Qifan Yu, Minghe Gao, Bingchen Miao, Zhenkui Zhang, Kaihang Pan, Yunfei Li, Mengze Li, Wei Ji, Juncheng Li, Siliang Tang, Yueting Zhuang</dc:creator>
        <description><![CDATA[
            随着多模态大语言模型发展，基于其的虚拟代理表现出色，但现有基准存在任务复杂度不可控、手动标注场景有限、缺乏多维评估等问题。为此，研究团队推出OmniBench，这是一个基于图的可自我生成、跨平台的基准，可通过子任务组合合成复杂度可控的任务；还提出OmniEval多维评估框架。合成数据集含20个场景下3.6万个图结构任务，人类接受率达91%。用图结构数据训练能更高效引导代理。对多种模型进行评估，为后续发展奠基。
            arXiv:2506.08933v1 Announce Type: new 
Abstract: As multimodal large language models (MLLMs) advance, MLLM-based virtual agents have demonstrated remarkable performance. However, existing benchmarks face significant limitations, including uncontrollable task complexity, extensive manual annotation with limited scenarios, and a lack of multidimensional evaluation. In response to these challenges, we introduce OmniBench, a self-generating, cross-platform, graph-based benchmark with an automated pipeline for synthesizing tasks of controllable complexity through subtask composition. To evaluate the diverse capabilities of virtual agents on the graph, we further present OmniEval, a multidimensional evaluation framework that includes subtask-level evaluation, graph-based metrics, and comprehensive tests across 10 capabilities. Our synthesized dataset contains 36k graph-structured tasks across 20 scenarios, achieving a 91\% human acceptance rate. Training on our graph-structured data shows that it can more efficiently guide agents compared to manually annotated data. We conduct multidimensional evaluations for various open-source and closed-source models, revealing their performance across various capabilities and paving the way for future advancements. Our project is available at https://omni-bench.github.io/.
        ]]></description>
    </item>
    <item>
        <title>BioLangFusion: Multimodal Fusion of DNA, mRNA, and Protein Language Models</title>
        <link>https://arxiv.org/abs/2506.08936</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08936v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Amina Mollaysa, Artem Moskale, Pushpak Pati, Tommaso Mansi, Mangal Prakash, Rui Liao</dc:creator>
        <description><![CDATA[
            该论文背景是为了将预训练的DNA、mRNA和蛋白质语言模型整合为统一分子表示。方法上，受分子生物学中心法则启发，在有生物学意义的密码子层面（三个核苷酸编码一个氨基酸）对齐各模态嵌入，研究了三种标准融合技术，包括密码子级嵌入拼接、受多实例学习启发的熵正则化注意力池化和跨模态多头注意力，且无需对基础模型额外预训练或修改。效果上，在五项分子属性预测任务中，该方法优于强单模态基线，能以最小开销捕捉互补多组学信息。
            arXiv:2506.08936v1 Announce Type: new 
Abstract: We present BioLangFusion, a simple approach for integrating pre-trained DNA, mRNA, and protein language models into unified molecular representations. Motivated by the central dogma of molecular biology (information flow from gene to transcript to protein), we align per-modality embeddings at the biologically meaningful codon level (three nucleotides encoding one amino acid) to ensure direct cross-modal correspondence. BioLangFusion studies three standard fusion techniques: (i) codon-level embedding concatenation, (ii) entropy-regularized attention pooling inspired by multiple-instance learning, and (iii) cross-modal multi-head attention -- each technique providing a different inductive bias for combining modality-specific signals. These methods require no additional pre-training or modification of the base models, allowing straightforward integration with existing sequence-based foundation models. Across five molecular property prediction tasks, BioLangFusion outperforms strong unimodal baselines, showing that even simple fusion of pre-trained models can capture complementary multi-omic information with minimal overhead.
        ]]></description>
    </item>
    <item>
        <title>FaithfulRAG: Fact-Level Conflict Modeling for Context-Faithful Retrieval-Augmented Generation</title>
        <link>https://arxiv.org/abs/2506.08938</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08938v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qinggang Zhang, Zhishang Xiang, Yilin Xiao, Le Wang, Junhui Li, Xinrun Wang, Jinsong Su</dc:creator>
        <description><![CDATA[
            检索增强的大语言模型在处理知识密集型任务上潜力巨大，但存在不忠实问题，尤其在知识冲突时，现有方法强制抑制模型参数知识，破坏内部知识结构且易误解上下文。本文提出FaithfulRAG框架，通过显式建模参数知识与检索上下文的差异解决知识冲突，识别事实层面的冲突知识并设计自思考过程，让模型推理整合冲突事实后生成回复。实验表明该方法优于现有技术。
            arXiv:2506.08938v1 Announce Type: new 
Abstract: Large language models (LLMs) augmented with retrieval systems have demonstrated significant potential in handling knowledge-intensive tasks. However, these models often struggle with unfaithfulness issues, generating outputs that either ignore the retrieved context or inconsistently blend it with the LLM`s parametric knowledge. This issue is particularly severe in cases of knowledge conflict, where the retrieved context conflicts with the model`s parametric knowledge. While existing faithful RAG approaches enforce strict context adherence through well-designed prompts or modified decoding strategies, our analysis reveals a critical limitation: they achieve faithfulness by forcibly suppressing the model`s parametric knowledge, which undermines the model`s internal knowledge structure and increases the risk of misinterpreting the context. To this end, this paper proposes FaithfulRAG, a novel framework that resolves knowledge conflicts by explicitly modeling discrepancies between the model`s parametric knowledge and retrieved context. Specifically, FaithfulRAG identifies conflicting knowledge at the fact level and designs a self-thinking process, allowing LLMs to reason about and integrate conflicting facts before generating responses. Extensive experiments demonstrate that our method outperforms state-of-the-art methods. The code is available at https:// github.com/DeepLearnXMU/Faithful-RAG
        ]]></description>
    </item>
    <item>
        <title>Tailored Architectures for Time Series Forecasting: Evaluating Deep Learning Models on Gaussian Process-Generated Data</title>
        <link>https://arxiv.org/abs/2506.08977</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08977v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Victoria Hankemeier, Malte Schilling</dc:creator>
        <description><![CDATA[
            背景：深度学习虽提升了时间序列预测能力，但特定数据特征与模型架构优势的关联尚不明确。方法：研究引入用高斯过程生成的新数据集，以评估模型对特定特征的适应性；提出新模型TimeFlex，其模块化架构可处理多种时间动态。效果：将该模型与现有先进模型对比，能让人更深入了解各模型在不同时间序列条件下的表现。 
            arXiv:2506.08977v1 Announce Type: new 
Abstract: Developments in Deep Learning have significantly improved time series forecasting by enabling more accurate modeling of complex temporal dependencies inherent in sequential data. The effectiveness of such models is often demonstrated on limited sets of specific real-world data. Although this allows for comparative analysis, it still does not demonstrate how specific data characteristics align with the architectural strengths of individual models. Our research aims at uncovering clear connections between time series characteristics and particular models. We introduce a novel dataset generated using Gaussian Processes, specifically designed to display distinct, known characteristics for targeted evaluations of model adaptability to them. Furthermore, we present TimeFlex, a new model that incorporates a modular architecture tailored to handle diverse temporal dynamics, including trends and periodic patterns. This model is compared to current state-of-the-art models, offering a deeper understanding of how models perform under varied time series conditions.
        ]]></description>
    </item>
    <item>
        <title>Propositional Logic for Probing Generalization in Neural Networks</title>
        <link>https://arxiv.org/abs/2506.08978</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08978v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Anna Langedijk, Jaap Jumelet, Willem Zuidema</dc:creator>
        <description><![CDATA[
            背景：神经网络获取和表示符号规则的程度是研究和争论的关键话题，大语言模型在推理任务上的失败也常令人费解。方法：在基于命题逻辑的受控任务中研究Transformer、图卷积网络和LSTM三种关键神经网络架构的泛化行为，引入现有数据集的平衡扩展以消除表面模式。效果：所有模型在分布内表现良好，但泛化到未见模式尤其是涉及否定的模式仍是重大挑战，Transformer除非引入结构偏差，否则无法组合应用否定，凸显标准架构学习逻辑算子系统表示的局限性。
            arXiv:2506.08978v1 Announce Type: new 
Abstract: The extent to which neural networks are able to acquire and represent symbolic rules remains a key topic of research and debate. Much current work focuses on the impressive capabilities of large language models, as well as their often ill-understood failures on a wide range of reasoning tasks. In this paper, in contrast, we investigate the generalization behavior of three key neural architectures (Transformers, Graph Convolution Networks and LSTMs) in a controlled task rooted in propositional logic. The task requires models to generate satisfying assignments for logical formulas, making it a structured and interpretable setting for studying compositionality. We introduce a balanced extension of an existing dataset to eliminate superficial patterns and enable testing on unseen operator combinations. Using this dataset, we evaluate the ability of the three architectures to generalize beyond the training distribution. While all models perform well in-distribution, we find that generalization to unseen patterns, particularly those involving negation, remains a significant challenge. Transformers fail to apply negation compositionally, unless structural biases are introduced. Our findings highlight persistent limitations in the ability of standard architectures to learn systematic representations of logical operators, suggesting the need for stronger inductive biases to support robust rule-based reasoning.
        ]]></description>
    </item>
    <item>
        <title>SwS: Self-aware Weakness-driven Problem Synthesis in Reinforcement Learning for LLM Reasoning</title>
        <link>https://arxiv.org/abs/2506.08989</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08989v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiao Liang, Zhong-Zhi Li, Yeyun Gong, Yang Wang, Hengyuan Zhang, Yelong Shen, Ying Nian Wu, Weizhu Chen</dc:creator>
        <description><![CDATA[
            背景：强化学习与可验证奖励（RLVR）在训练大语言模型解决复杂推理任务时，面临高质量问题集稀缺及问题合成策略效率低的问题。方法：引入自我感知弱点驱动的问题合成框架（SwS），系统识别模型缺陷并利用其进行问题扩充，从失败案例中提取核心概念合成新问题。效果：在八个主流推理基准测试中，7B和32B模型平均性能分别提升10.0%和7.7%，能让模型自我识别并克服弱点，实现稳健泛化。
            arXiv:2506.08989v1 Announce Type: new 
Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has proven effective for training large language models (LLMs) on complex reasoning tasks, such as mathematical problem solving. A prerequisite for the scalability of RLVR is a high-quality problem set with precise and verifiable answers. However, the scarcity of well-crafted human-labeled math problems and limited-verification answers in existing distillation-oriented synthetic datasets limit their effectiveness in RL. Additionally, most problem synthesis strategies indiscriminately expand the problem set without considering the model's capabilities, leading to low efficiency in generating useful questions. To mitigate this issue, we introduce a Self-aware Weakness-driven problem Synthesis framework (SwS) that systematically identifies model deficiencies and leverages them for problem augmentation. Specifically, we define weaknesses as questions that the model consistently fails to learn through its iterative sampling during RL training. We then extract the core concepts from these failure cases and synthesize new problems to strengthen the model's weak areas in subsequent augmented training, enabling it to focus on and gradually overcome its weaknesses. Without relying on external knowledge distillation, our framework enables robust generalization byempowering the model to self-identify and address its weaknesses in RL, yielding average performance gains of 10.0% and 7.7% on 7B and 32B models across eight mainstream reasoning benchmarks.
        ]]></description>
    </item>
    <item>
        <title>UD-KSL Treebank v1.3: A semi-automated framework for aligning XPOS-extracted units with UPOS tags</title>
        <link>https://arxiv.org/abs/2506.09009</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.09009v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hakyung Sung, Gyu-Ho Shin, Chanyoung Lee, You Kyung Sung, Boo Kyung Jung</dc:creator>
        <description><![CDATA[
            背景：对第二语言韩语的通用依存标注有相关研究需求。方法：引入半自动化框架，从XPOS序列中识别形态句法结构并将其与相应的UPOS类别对齐，还通过标注2998个新句子扩展现有韩语语料库，用两个NLP工具包在有无对齐的数据集上微调韩语形态句法分析模型。效果：对齐的数据集不仅提高了标注层的一致性，还提升了形态句法标注和依存句法分析的准确性，在标注数据有限时效果尤其明显。
            arXiv:2506.09009v1 Announce Type: new 
Abstract: The present study extends recent work on Universal Dependencies annotations for second-language (L2) Korean by introducing a semi-automated framework that identifies morphosyntactic constructions from XPOS sequences and aligns those constructions with corresponding UPOS categories. We also broaden the existing L2-Korean corpus by annotating 2,998 new sentences from argumentative essays. To evaluate the impact of XPOS-UPOS alignments, we fine-tune L2-Korean morphosyntactic analysis models on datasets both with and without these alignments, using two NLP toolkits. Our results indicate that the aligned dataset not only improves consistency across annotation layers but also enhances morphosyntactic tagging and dependency-parsing accuracy, particularly in cases of limited annotated data.
        ]]></description>
    </item>
    <item>
        <title>Learning to Reason Across Parallel Samples for LLM Reasoning</title>
        <link>https://arxiv.org/abs/2506.09014</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.09014v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jianing Qi, Xi Ye, Hao Tang, Zhigang Zhu, Eunsol Choi</dc:creator>
        <description><![CDATA[
            背景：大规模语言模型（LLMs）在测试时增加计算量能带来性能提升，现有通过采样多个答案并聚合的方法在数学领域有效。方法：提出训练一个紧凑的LLM即样本集聚合器（SSA），它接收多个样本的拼接序列并输出最终答案，用强化学习优化答案准确性。效果：在多个推理数据集上实验表明，SSA优于基于奖励模型的重排序等测试时扩展方法，且有良好泛化能力，还能高效处理黑盒模型输出。
            arXiv:2506.09014v1 Announce Type: new 
Abstract: Scaling test-time compute brings substantial performance gains for large language models (LLMs). By sampling multiple answers and heuristically aggregate their answers (e.g., either through majority voting or using verifiers to rank the answers), one can achieve consistent performance gains in math domains. In this paper, we propose a new way to leverage such multiple sample set. We train a compact LLM, called Sample Set Aggregator (SSA), that takes a concatenated sequence of multiple samples and output the final answer, optimizing it for the answer accuracy with reinforcement learning. Experiments on multiple reasoning datasets show that SSA outperforms other test-time scaling methods such as reward model-based re-ranking. Our approach also shows a promising generalization ability, across sample set sizes, base model families and scales, and tasks. By separating LLMs to generate answers and LLMs to analyze and aggregate sampled answers, our approach can work with the outputs from premier black box models easily and efficiently.
        ]]></description>
    </item>
    <item>
        <title>SPEED-RL: Faster Training of Reasoning Models via Online Curriculum Learning</title>
        <link>https://arxiv.org/abs/2506.09016</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.09016v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ruiqi Zhang, Daman Arora, Song Mei, Andrea Zanette</dc:creator>
        <description><![CDATA[
            背景：用强化学习训练大语言模型可提升推理能力，但因低效的统一提示采样导致计算成本高。方法：引入选择性提示与高效难度估计（SPEED），这是一种自适应在线强化学习课程，能选择性地选择中等难度的训练示例以提高学习效率。效果：理论上，中等难度提示能提高梯度估计器的信噪比，加速收敛；实证上，高效实现可使训练速度提高2至6倍，且不降低准确率，无需手动调整，能无缝集成到标准强化学习算法中。
            arXiv:2506.09016v1 Announce Type: new 
Abstract: Training large language models with reinforcement learning (RL) against verifiable rewards significantly enhances their reasoning abilities, yet remains computationally expensive due to inefficient uniform prompt sampling. We introduce Selective Prompting with Efficient Estimation of Difficulty (SPEED), an adaptive online RL curriculum that selectively chooses training examples of intermediate difficulty to maximize learning efficiency. Theoretically, we establish that intermediate-difficulty prompts improve the gradient estimator's signal-to-noise ratio, accelerating convergence. Empirically, our efficient implementation leads to 2x to 6x faster training without degrading accuracy, requires no manual tuning, and integrates seamlessly into standard RL algorithms.
        ]]></description>
    </item>
    <item>
        <title>Edit Flows: Flow Matching with Edit Operations</title>
        <link>https://arxiv.org/abs/2506.09018</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.09018v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Marton Havasi, Brian Karrer, Itai Gat, Ricky T. Q. Chen</dc:creator>
        <description><![CDATA[
            背景：自回归生成模型能自然生成可变长度序列，而非自回归模型存在困难，常施加严格的逐令牌结构。方法：提出Edit Flows非自回归模型，通过编辑操作（插入、删除和替换）在序列上定义离散流，在序列空间的连续时间马尔可夫链中对这些操作建模，利用带辅助变量的扩展状态空间进行训练。效果：在图像字幕任务上优于自回归和掩码模型，在文本和代码生成中显著优于掩码构造。
            arXiv:2506.09018v1 Announce Type: new 
Abstract: Autoregressive generative models naturally generate variable-length sequences, while non-autoregressive models struggle, often imposing rigid, token-wise structures. We propose Edit Flows, a non-autoregressive model that overcomes these limitations by defining a discrete flow over sequences through edit operations-insertions, deletions, and substitutions. By modeling these operations within a Continuous-time Markov Chain over the sequence space, Edit Flows enable flexible, position-relative generation that aligns more closely with the structure of sequence data. Our training method leverages an expanded state space with auxiliary variables, making the learning process efficient and tractable. Empirical results show that Edit Flows outperforms both autoregressive and mask models on image captioning and significantly outperforms the mask construction in text and code generation.
        ]]></description>
    </item>
    <item>
        <title>e3: Learning to Explore Enables Extrapolation of Test-Time Compute for LLMs</title>
        <link>https://arxiv.org/abs/2506.09026</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.09026v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Amrith Setlur, Matthew Y. R. Yang, Charlie Snell, Jeremy Greer, Ian Wu, Virginia Smith, Max Simchowitz, Aviral Kumar</dc:creator>
        <description><![CDATA[
            背景：测试时扩展虽能提升大语言模型推理能力，但多数现有推理模型外推性不佳。方法：提出e3方法，训练大语言模型进行上下文内探索，包括链式操作、利用错误轨迹的“负”梯度、通过特定课程将任务难度与训练令牌预算耦合。效果：e3生成的1.7B模型在AIME'25和HMMT'25评分中表现最佳，能外推至2倍训练令牌预算，不仅有高pass@1分数，还提升了基础模型的pass@k。
            arXiv:2506.09026v1 Announce Type: new 
Abstract: Test-time scaling offers a promising path to improve LLM reasoning by utilizing more compute at inference time; however, the true promise of this paradigm lies in extrapolation (i.e., improvement in performance on hard problems as LLMs keep "thinking" for longer, beyond the maximum token budget they were trained on). Surprisingly, we find that most existing reasoning models do not extrapolate well. We show that one way to enable extrapolation is by training the LLM to perform in-context exploration: training the LLM to effectively spend its test time budget by chaining operations (such as generation, verification, refinement, etc.), or testing multiple hypotheses before it commits to an answer. To enable in-context exploration, we identify three key ingredients as part of our recipe e3: (1) chaining skills that the base LLM has asymmetric competence in, e.g., chaining verification (easy) with generation (hard), as a way to implement in-context search; (2) leveraging "negative" gradients from incorrect traces to amplify exploration during RL, resulting in longer search traces that chains additional asymmetries; and (3) coupling task difficulty with training token budget during training via a specifically-designed curriculum to structure in-context exploration. Our recipe e3 produces the best known 1.7B model according to AIME'25 and HMMT'25 scores, and extrapolates to 2x the training token budget. Our e3-1.7B model not only attains high pass@1 scores, but also improves pass@k over the base model.
        ]]></description>
    </item>
    <item>
        <title>Aligning Proteins and Language: A Foundation Model for Protein Retrieval</title>
        <link>https://arxiv.org/abs/2506.08023</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08023v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qifeng Wu, Zhengzhe Liu, Han Zhu, Yizhou Zhao, Daisuke Kihara, Min Xu</dc:creator>
        <description><![CDATA[
            背景：为从大规模蛋白质数据集中检索出结构和语义相似的蛋白质，助力对蛋白质结构的功能阐释。方法：受视觉语言模型进展启发，提出用对比学习将3D蛋白质结构与功能注释对齐的CLIP风格框架，还构建约20万对含丰富功能描述符的蛋白质-文本对大规模数据集。效果：在PDB和EMDB数据集的域内及跨数据库检索任务中，该方法均展现出良好的零样本检索性能，凸显了多模态基础模型在蛋白质生物学中理解结构与功能的潜力。
            arXiv:2506.08023v1 Announce Type: cross 
Abstract: This paper aims to retrieve proteins with similar structures and semantics from large-scale protein dataset, facilitating the functional interpretation of protein structures derived by structural determination methods like cryo-Electron Microscopy (cryo-EM). Motivated by the recent progress of vision-language models (VLMs), we propose a CLIP-style framework for aligning 3D protein structures with functional annotations using contrastive learning. For model training, we propose a large-scale dataset of approximately 200,000 protein-caption pairs with rich functional descriptors. We evaluate our model in both in-domain and more challenging cross-database retrieval on Protein Data Bank (PDB) and Electron Microscopy Data Bank (EMDB) dataset, respectively. In both cases, our approach demonstrates promising zero-shot retrieval performance, highlighting the potential of multimodal foundation models for structure-function understanding in protein biology.
        ]]></description>
    </item>
    <item>
        <title>Hierarchical Lexical Graph for Enhanced Multi-Hop Retrieval</title>
        <link>https://arxiv.org/abs/2506.08074</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08074v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Abdellah Ghassel, Ian Robinson, Gabriel Tanase, Hal Cooper, Bryan Thompson, Zhen Han, Vassilis N. Ioannidis, Soji Adeshina, Huzefa Rangwala</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）在处理语义距离远的多文档答案拼凑时存在不足，且现有基准缺乏评估多跳检索系统的复杂性。方法：提出三层索引的分层词法图（HLG），并基于其构建两个检索器，还引入合成数据集生成管道。效果：在五个数据集的实验中，方法优于基于块的RAG，检索召回率和正确性平均相对提升23.1%。开源代码见https://github.com/awslabs/graphrag-toolkit 。
            arXiv:2506.08074v1 Announce Type: cross 
Abstract: Retrieval-Augmented Generation (RAG) grounds large language models in external evidence, yet it still falters when answers must be pieced together across semantically distant documents. We close this gap with the Hierarchical Lexical Graph (HLG), a three-tier index that (i) traces every atomic proposition to its source, (ii) clusters propositions into latent topics, and (iii) links entities and relations to expose cross-document paths. On top of HLG we build two complementary, plug-and-play retrievers: StatementGraphRAG, which performs fine-grained entity-aware beam search over propositions for high-precision factoid questions, and TopicGraphRAG, which selects coarse topics before expanding along entity links to supply broad yet relevant context for exploratory queries. Additionally, existing benchmarks lack the complexity required to rigorously evaluate multi-hop summarization systems, often focusing on single-document queries or limited datasets. To address this, we introduce a synthetic dataset generation pipeline that curates realistic, multi-document question-answer pairs, enabling robust evaluation of multi-hop retrieval systems. Extensive experiments across five datasets demonstrate that our methods outperform naive chunk-based RAG achieving an average relative improvement of 23.1% in retrieval recall and correctness. Open-source Python library is available at https://github.com/awslabs/graphrag-toolkit.
        ]]></description>
    </item>
    <item>
        <title>RADAR: Benchmarking Language Models on Imperfect Tabular Data</title>
        <link>https://arxiv.org/abs/2506.08249</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08249v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ken Gu, Zhihan Zhang, Kate Lin, Yuwei Zhang, Akshay Paruchuri, Hong Yu, Mehran Kazemi, Kumar Ayush, A. Ali Heydari, Maxwell A. Xu, Girish Narayanswamy, Yun Liu, Ming-Zher Poh, Yuzhe Yang, Mark Malhotra, Shwetak Patel, Hamid Palangi, Xuhai Xu, Daniel McDuff, Tim Althoff, Xin Liu</dc:creator>
        <description><![CDATA[
            背景：语言模型用于自主数据分析时，其对数据（如缺失值、异常值等）的识别、推理和处理能力研究不足，这些问题在真实表格数据中常见，处理不当会影响分析结论。方法：提出RADAR基准，通过编程扰动模拟数据问题，包含2980个表查询对，覆盖9个领域和5种数据问题类型，还改变表格大小研究推理性能。效果：前沿模型在无问题表格表现尚可，但有问题时性能大幅下降，RADAR为提升表格推理提供资源。
            arXiv:2506.08249v1 Announce Type: cross 
Abstract: Language models (LMs) are increasingly being deployed to perform autonomous data analyses. However, their data awareness -- the ability to recognize, reason over, and appropriately handle data artifacts such as missing values, outliers, and logical inconsistencies -- remains underexplored. These artifacts are especially common in real-world tabular data and, if mishandled, can significantly compromise the validity of analytical conclusions. To address this gap, we present RADAR, a benchmark for systematically evaluating data-aware reasoning on tabular data. We develop a framework to simulate data artifacts via programmatic perturbations to enable targeted evaluation of model behavior. RADAR comprises 2980 table query pairs, grounded in real-world data spanning 9 domains and 5 data artifact types. In addition to evaluating artifact handling, RADAR systematically varies table size to study how reasoning performance holds when increasing table size. Our evaluation reveals that, despite decent performance on tables without data artifacts, frontier models degrade significantly when data artifacts are introduced, exposing critical gaps in their capacity for robust, data-aware analysis. Designed to be flexible and extensible, RADAR supports diverse perturbation types and controllable table sizes, offering a valuable resource for advancing tabular reasoning.
        ]]></description>
    </item>
    <item>
        <title>SafeCoT: Improving VLM Safety with Minimal Reasoning</title>
        <link>https://arxiv.org/abs/2506.08399</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08399v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiachen Ma, Zhanhui Zhou, Chao Yang, Chaochao Lu</dc:creator>
        <description><![CDATA[
            背景：确保视觉语言模型（VLMs）在高风险或模糊场景中给出安全合适的回复是关键挑战。方法：提出轻量级、可解释的SafeCoT框架，利用基于规则的思维链（CoT）监督，用最少的监督帮助模型推理安全风险并进行上下文感知的拒绝。效果：多基准实验显示，即便训练数据有限，SafeCoT也能显著减少过度拒绝，增强泛化能力，为VLMs与安全关键目标对齐提供可扩展方案。
            arXiv:2506.08399v1 Announce Type: cross 
Abstract: Ensuring safe and appropriate responses from vision-language models (VLMs) remains a critical challenge, particularly in high-risk or ambiguous scenarios. We introduce SafeCoT, a lightweight, interpretable framework that leverages rule-based chain-of-thought (CoT) supervision to improve refusal behavior in VLMs. Unlike prior methods that rely on large-scale safety annotations or complex modeling, SafeCoT uses minimal supervision to help models reason about safety risks and make context-aware refusals. Experiments across multiple benchmarks show that SafeCoT significantly reduces overrefusal and enhances generalization, even with limited training data. Our approach offers a scalable solution for aligning VLMs with safety-critical objectives.
        ]]></description>
    </item>
    <item>
        <title>MasHost Builds It All: Autonomous Multi-Agent System Directed by Reinforcement Learning</title>
        <link>https://arxiv.org/abs/2506.08507</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08507v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kuo Yang, Xingjie Yang, Linhui Yu, Qing Xu, Yan Fang, Xu Wang, Zhengyang Zhou, Yang Wang</dc:creator>
        <description><![CDATA[
            背景：大语言模型驱动的多智能体系统在处理复杂任务时，现有构建方法存在依赖人工、自主性受限等问题。方法：提出基于强化学习的框架MasHost，将多智能体系统构建视为图搜索问题，通过统一概率采样机制联合采样智能体角色及其交互，还引入组件合理性原则，并提出分层相对策略优化（HRPO）策略。效果：在六个基准测试中，MasHost始终优于多数竞争基线，验证了其有效性、效率和结构合理性。
            arXiv:2506.08507v1 Announce Type: cross 
Abstract: Large Language Model (LLM)-driven Multi-agent systems (Mas) have recently emerged as a powerful paradigm for tackling complex real-world tasks. However, existing Mas construction methods typically rely on manually crafted interaction mechanisms or heuristic rules, introducing human biases and constraining the autonomous ability. Even with recent advances in adaptive Mas construction, existing systems largely remain within the paradigm of semi-autonomous patterns. In this work, we propose MasHost, a Reinforcement Learning (RL)-based framework for autonomous and query-adaptive Mas design. By formulating Mas construction as a graph search problem, our proposed MasHost jointly samples agent roles and their interactions through a unified probabilistic sampling mechanism. Beyond the accuracy and efficiency objectives pursued in prior works, we introduce component rationality as an additional and novel design principle in Mas. To achieve this multi-objective optimization, we propose Hierarchical Relative Policy Optimization (HRPO), a novel RL strategy that collaboratively integrates group-relative advantages and action-wise rewards. To our knowledge, our proposed MasHost is the first RL-driven framework for autonomous Mas graph construction. Extensive experiments on six benchmarks demonstrate that MasHost consistently outperforms most competitive baselines, validating its effectiveness, efficiency, and structure rationality.
        ]]></description>
    </item>
    <item>
        <title>PhyBlock: A Progressive Benchmark for Physical Understanding and Planning via 3D Block Assembly</title>
        <link>https://arxiv.org/abs/2506.08708</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08708v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Liang Ma, Jiajun Wen, Min Lin, Rongtao Xu, Xiwen Liang, Bingqian Lin, Jun Ma, Yongxin Wang, Ziming Wei, Haokun Lin, Mingfei Han, Meng Cao, Bokui Chen, Ivan Laptev, Xiaodan Liang</dc:creator>
        <description><![CDATA[
            背景：视觉语言模型（VLMs）在具身智能体的推理和规划方面有一定能力，但在理解物理现象，尤其是结构化3D环境中的物理现象时能力有限。方法：提出PhyBlock基准，通过机器人3D积木组装任务评估VLMs的物理理解和规划能力，包含四级认知层次组装任务和针对性视觉问答样本，从三个维度评估21个先进VLMs。效果：VLMs在高级规划和推理能力上有明显局限，任务复杂度增加时性能下降，链式思维提示改进效果甚微，PhyBlock可作为统一测试平台推动具身推理。
            arXiv:2506.08708v1 Announce Type: cross 
Abstract: While vision-language models (VLMs) have demonstrated promising capabilities in reasoning and planning for embodied agents, their ability to comprehend physical phenomena, particularly within structured 3D environments, remains severely limited. To close this gap, we introduce PhyBlock, a progressive benchmark designed to assess VLMs on physical understanding and planning through robotic 3D block assembly tasks. PhyBlock integrates a novel four-level cognitive hierarchy assembly task alongside targeted Visual Question Answering (VQA) samples, collectively aimed at evaluating progressive spatial reasoning and fundamental physical comprehension, including object properties, spatial relationships, and holistic scene understanding. PhyBlock includes 2600 block tasks (400 assembly tasks, 2200 VQA tasks) and evaluates models across three key dimensions: partial completion, failure diagnosis, and planning robustness. We benchmark 21 state-of-the-art VLMs, highlighting their strengths and limitations in physically grounded, multi-step planning. Our empirical findings indicate that the performance of VLMs exhibits pronounced limitations in high-level planning and reasoning capabilities, leading to a notable decline in performance for the growing complexity of the tasks. Error analysis reveals persistent difficulties in spatial orientation and dependency reasoning. Surprisingly, chain-of-thought prompting offers minimal improvements, suggesting spatial tasks heavily rely on intuitive model comprehension. We position PhyBlock as a unified testbed to advance embodied reasoning, bridging vision-language understanding and real-world physical problem-solving.
        ]]></description>
    </item>
    <item>
        <title>Bridging RDF Knowledge Graphs with Graph Neural Networks for Semantically-Rich Recommender Systems</title>
        <link>https://arxiv.org/abs/2506.08743</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08743v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Michael F\"arber, David Lamprecht, Yuni Susanti</dc:creator>
        <description><![CDATA[
            图神经网络（GNNs）推动了推荐系统发展，但基于W3C标准RDF的知识图谱（KGs）丰富语义信息未在GNN推荐系统中充分利用。为此，该研究提出将RDF KGs与GNNs全面集成，利用RDF对象属性拓扑信息和数据类型属性内容信息。深入评估不同GNNs，分析语义特征初始化和图结构异质性对推荐任务的影响。多场景实验表明，利用RDF KGs语义信息显著提升推荐系统性能，为关联开放数据云的GNN推荐系统奠定基础。
            arXiv:2506.08743v1 Announce Type: cross 
Abstract: Graph Neural Networks (GNNs) have substantially advanced the field of recommender systems. However, despite the creation of more than a thousand knowledge graphs (KGs) under the W3C standard RDF, their rich semantic information has not yet been fully leveraged in GNN-based recommender systems. To address this gap, we propose a comprehensive integration of RDF KGs with GNNs that utilizes both the topological information from RDF object properties and the content information from RDF datatype properties. Our main focus is an in-depth evaluation of various GNNs, analyzing how different semantic feature initializations and types of graph structure heterogeneity influence their performance in recommendation tasks. Through experiments across multiple recommendation scenarios involving multi-million-node RDF graphs, we demonstrate that harnessing the semantic richness of RDF KGs significantly improves recommender systems and lays the groundwork for GNN-based recommender systems for the Linked Open Data cloud. The code and data are available on our GitHub repository: https://github.com/davidlamprecht/rdf-gnn-recommendation
        ]]></description>
    </item>
    <item>
        <title>Consistent Paths Lead to Truth: Self-Rewarding Reinforcement Learning for LLM Reasoning</title>
        <link>https://arxiv.org/abs/2506.08745</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08745v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kongcheng Zhang, Qi Yao, Shunyu Liu, Yingjie Wang, Baisheng Lai, Jieping Ye, Mingli Song, Dacheng Tao</dc:creator>
        <description><![CDATA[
            背景：强化学习在复杂推理任务中潜力大，但有效训练常依赖外部监督，限制了广泛应用。方法：提出一种新颖的自奖励强化学习框架，利用不同推理轨迹中中间推理状态的一致性来增强大语言模型推理能力，引入结合一致性和波动性的内在奖励机制CoVo，并辅以好奇心奖励促进探索。效果：在多种推理基准测试中，CoVo性能与有监督强化学习相当甚至更优。
            arXiv:2506.08745v1 Announce Type: cross 
Abstract: Recent advances of Reinforcement Learning (RL) have highlighted its potential in complex reasoning tasks, yet effective training often relies on external supervision, which limits the broader applicability. In this work, we propose a novel self-rewarding reinforcement learning framework to enhance Large Language Model (LLM) reasoning by leveraging the consistency of intermediate reasoning states across different reasoning trajectories. Our key insight is that correct responses often exhibit consistent trajectory patterns in terms of model likelihood: their intermediate reasoning states tend to converge toward their own final answers (high consistency) with minimal deviation toward other candidates (low volatility). Inspired by this observation, we introduce CoVo, an intrinsic reward mechanism that integrates Consistency and Volatility via a robust vector-space aggregation strategy, complemented by a curiosity bonus to promote diverse exploration. CoVo enables LLMs to perform RL in a self-rewarding manner, offering a scalable pathway for learning to reason without external supervision. Extensive experiments on diverse reasoning benchmarks show that CoVo achieves performance comparable to or even surpassing supervised RL. Our code is available at https://github.com/sastpg/CoVo.
        ]]></description>
    </item>
    <item>
        <title>Paths to Causality: Finding Informative Subgraphs Within Knowledge Graphs for Knowledge-Based Causal Discovery</title>
        <link>https://arxiv.org/abs/2506.08771</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08771v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuni Susanti, Michael F\"arber</dc:creator>
        <description><![CDATA[
            背景：推断变量对间的因果关系对理解复杂系统中多变量交互至关重要，基于知识的因果发现是传统方法的有力替代，但现有使用大语言模型（LLMs）的方法结果不稳定。方法：提出将知识图谱（KGs）与LLMs集成的新方法，在KGs中识别基于元路径的信息子图，用基于排序学习的模型优化子图选择，将排名靠前的子图融入零样本提示。效果：在生物医学和开放领域数据集上实验表明，该方法在不同LLMs和KGs上的F1分数比多数基线最高高出44.4分。
            arXiv:2506.08771v1 Announce Type: cross 
Abstract: Inferring causal relationships between variable pairs is crucial for understanding multivariate interactions in complex systems. Knowledge-based causal discovery -- which involves inferring causal relationships by reasoning over the metadata of variables (e.g., names or textual context) -- offers a compelling alternative to traditional methods that rely on observational data. However, existing methods using Large Language Models (LLMs) often produce unstable and inconsistent results, compromising their reliability for causal inference. To address this, we introduce a novel approach that integrates Knowledge Graphs (KGs) with LLMs to enhance knowledge-based causal discovery. Our approach identifies informative metapath-based subgraphs within KGs and further refines the selection of these subgraphs using Learning-to-Rank-based models. The top-ranked subgraphs are then incorporated into zero-shot prompts, improving the effectiveness of LLMs in inferring the causal relationship. Extensive experiments on biomedical and open-domain datasets demonstrate that our method outperforms most baselines by up to 44.4 points in F1 scores, evaluated across diverse LLMs and KGs. Our code and datasets are available on GitHub: https://github.com/susantiyuni/path-to-causality
        ]]></description>
    </item>
    <item>
        <title>VIKI-R: Coordinating Embodied Multi-Agent Cooperation via Reinforcement Learning</title>
        <link>https://arxiv.org/abs/2506.09049</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.09049v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Li Kang, Xiufeng Song, Heng Zhou, Yiran Qin, Jie Yang, Xiaohong Liu, Philip Torr, Lei Bai, Zhenfei Yin</dc:creator>
        <description><![CDATA[
            在动态环境中协调多个具身智能体是人工智能的核心挑战，现有基于视觉语言模型（VLM）的方法对多样具身类型支持有限。为此，本文引入首个针对具身多智能体协作的分层基准VIKI - Bench，有智能体激活、任务规划和轨迹感知三个结构化层次。还提出两阶段框架VIKI - R，先利用思维链注释示例微调预训练VLM，再在多级奖励信号下进行强化学习。实验表明，VIKI - R在各任务级别均显著优于基线方法，且强化学习能使异构智能体产生组合协作模式。
            arXiv:2506.09049v1 Announce Type: cross 
Abstract: Coordinating multiple embodied agents in dynamic environments remains a core challenge in artificial intelligence, requiring both perception-driven reasoning and scalable cooperation strategies. While recent works have leveraged large language models (LLMs) for multi-agent planning, a few have begun to explore vision-language models (VLMs) for visual reasoning. However, these VLM-based approaches remain limited in their support for diverse embodiment types. In this work, we introduce VIKI-Bench, the first hierarchical benchmark tailored for embodied multi-agent cooperation, featuring three structured levels: agent activation, task planning, and trajectory perception. VIKI-Bench includes diverse robot embodiments, multi-view visual observations, and structured supervision signals to evaluate reasoning grounded in visual inputs. To demonstrate the utility of VIKI-Bench, we propose VIKI-R, a two-stage framework that fine-tunes a pretrained vision-language model (VLM) using Chain-of-Thought annotated demonstrations, followed by reinforcement learning under multi-level reward signals. Our extensive experiments show that VIKI-R significantly outperforms baselines method across all task levels. Furthermore, we show that reinforcement learning enables the emergence of compositional cooperation patterns among heterogeneous agents. Together, VIKI-Bench and VIKI-R offer a unified testbed and method for advancing multi-agent, visual-driven cooperation in embodied AI systems.
        ]]></description>
    </item>
    <item>
        <title>SK-VQA: Synthetic Knowledge Generation at Scale for Training Context-Augmented Multimodal LLMs</title>
        <link>https://arxiv.org/abs/2406.19593</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2406.19593v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xin Su, Man Luo, Kris W Pan, Tien Pei Chou, Vasudev Lal, Phillip Howard</dc:creator>
        <description><![CDATA[
            多模态检索增强生成（RAG）在基于知识的视觉问答（KB - VQA）等领域至关重要，但现有多模态大模型（MLLMs）不适用于上下文增强生成。合成数据生成用于训练MLLMs受关注，但在上下文增强生成方面应用不足。为此提出SK - VQA，这是包含超200万视觉问答对的大规模合成多模态数据集，问题独特性是以往11倍，领域更多样、图像来源更广。经人工评估，问答对质量高且与上下文相关。实验表明，它可作KB - VQA基准和训练资源，使模型在上下文感知VQA和多模态RAG中泛化能力增强。
            arXiv:2406.19593v2 Announce Type: replace 
Abstract: Multimodal retrieval augmented generation (RAG) plays a crucial role in domains such as knowledge-based visual question answering (KB-VQA), where external knowledge is needed to answer a question. However, existing multimodal LLMs (MLLMs) are not designed for context-augmented generation, limiting their effectiveness in such tasks. While synthetic data generation has recently gained attention for training MLLMs, its application for context-augmented generation remains underexplored. To address this gap, we introduce SK-VQA, a large-scale synthetic multimodal dataset containing over 2 million visual question-answer pairs, each associated with context documents containing information necessary to determine the final answer. Compared to previous datasets, SK-VQA contains 11x more unique questions, exhibits greater domain diversity, and covers a broader spectrum of image sources. Through human evaluations, we confirm the high quality of the generated question-answer pairs and their contextual relevance. Extensive experiments show that SK-VQA serves both as a challenging KB-VQA benchmark and as an effective training resource for adapting MLLMs to context-augmented generation. Our results further indicate that models trained on SK-VQA demonstrate enhanced generalization in both context-aware VQA and multimodal RAG settings. SK-VQA is publicly available via Hugging Face Hub.
        ]]></description>
    </item>
    <item>
        <title>How transformers learn structured data: insights from hierarchical filtering</title>
        <link>https://arxiv.org/abs/2408.15138</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2408.15138v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jerome Garnier-Brun, Marc M\'ezard, Emanuele Moscato, Luca Saglietti</dc:creator>
        <description><![CDATA[
            背景：理解Transformer的学习过程和内置计算是可解释AI发展的核心目标。方法：本文针对树上序列的数据模型引入分层过滤程序，可手动调整数据中位置相关性范围，在此可控环境下，研究仅编码器的Transformer在根分类和掩码语言建模任务中的表现，探究其计算过程。效果：发现网络在训练时会依次纳入对应层级增加的更大距离的相关性，通过比较不同过滤程度模型的注意力图和探测不同编码器层级，证明模型能重建对应层级的相关性，可能实现了精确推理算法。
            arXiv:2408.15138v3 Announce Type: replace 
Abstract: Understanding the learning process and the embedded computation in transformers is becoming a central goal for the development of interpretable AI. In the present study, we introduce a hierarchical filtering procedure for data models of sequences on trees, allowing us to hand-tune the range of positional correlations in the data. Leveraging this controlled setting, we provide evidence that vanilla encoder-only transformers can approximate the exact inference algorithm when trained on root classification and masked language modeling tasks, and study how this computation is discovered and implemented. We find that correlations at larger distances, corresponding to increasing layers of the hierarchy, are sequentially included by the network during training. By comparing attention maps from models trained with varying degrees of filtering and by probing the different encoder levels, we find clear evidence of a reconstruction of correlations on successive length scales corresponding to the various levels of the hierarchy, which we relate to a plausible implementation of the exact inference algorithm within the same architecture.
        ]]></description>
    </item>
    <item>
        <title>TPP-LLM: Modeling Temporal Point Processes by Efficiently Fine-Tuning Large Language Models</title>
        <link>https://arxiv.org/abs/2410.02062</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.02062v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zefang Liu, Yinzhu Quan</dc:creator>
        <description><![CDATA[
            这是一篇关于将大语言模型与时间点过程（TPPs）结合的研究。背景是TPPs广泛用于建模事件，但传统方法依赖类别表示，缺乏语义信息，且大模型不擅长捕捉时间模式。方法是提出TPP - LLM框架，直接利用事件类型的文本描述，结合时间嵌入和参数高效微调方法。效果是提升了预测准确性和计算效率，在多个真实数据集上，TPP - LLM在序列建模和事件预测方面优于现有基线模型。
            arXiv:2410.02062v2 Announce Type: replace 
Abstract: Temporal point processes (TPPs) are widely used to model the timing and occurrence of events in domains such as social networks, transportation systems, and e-commerce. In this paper, we introduce TPP-LLM, a novel framework that integrates large language models (LLMs) with TPPs to capture both the semantic and temporal aspects of event sequences. Unlike traditional methods that rely on categorical event type representations, TPP-LLM directly utilizes the textual descriptions of event types, enabling the model to capture rich semantic information embedded in the text. While LLMs excel at understanding event semantics, they are less adept at capturing temporal patterns. To address this, TPP-LLM incorporates temporal embeddings and employs parameter-efficient fine-tuning (PEFT) methods to effectively learn temporal dynamics without extensive retraining. This approach improves both predictive accuracy and computational efficiency. Experimental results across diverse real-world datasets demonstrate that TPP-LLM outperforms state-of-the-art baselines in sequence modeling and event prediction, highlighting the benefits of combining LLMs with TPPs.
        ]]></description>
    </item>
    <item>
        <title>DiffLM: Controllable Synthetic Data Generation via Diffusion Language Models</title>
        <link>https://arxiv.org/abs/2411.03250</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2411.03250v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ying Zhou, Xinyao Wang, Yulei Niu, Yaojie Shen, Lexin Tang, Fan Chen, Ben He, Le Sun, Longyin Wen</dc:creator>
        <description><![CDATA[
            背景：大语言模型虽提升了知识与生成能力，但通过提示生成结构化格式的合成数据仍面临挑战。方法：提出基于变分自编码器的可控数据合成框架DiffLM，利用扩散模型保留原分布和格式结构信息，通过即插即用的潜在特征注入模块解耦目标分布知识学习。还引入潜在扩散模块学习完全表达性的潜在分布。效果：在七个结构化格式的真实数据集上评估，DiffLM能生成高质量数据，部分情况下下游任务性能超真实数据2%-7%。
            arXiv:2411.03250v2 Announce Type: replace 
Abstract: Recent advancements in large language models (LLMs) have significantly enhanced their knowledge and generative capabilities, leading to a surge of interest in leveraging LLMs for high-quality data synthesis. However, synthetic data generation via prompting LLMs remains challenging due to LLMs' limited understanding of target data distributions and the complexity of prompt engineering, especially for structured formatted data. To address these issues, we introduce DiffLM, a controllable data synthesis framework based on variational autoencoder (VAE), which further (1) leverages diffusion models to reserve more information of original distribution and format structure in the learned latent distribution and (2) decouples the learning of target distribution knowledge from the LLM's generative objectives via a plug-and-play latent feature injection module. As we observed significant discrepancies between the VAE's latent representations and the real data distribution, the latent diffusion module is introduced into our framework to learn a fully expressive latent distribution. Evaluations on seven real-world datasets with structured formatted data (i.e., Tabular, Code, and Tool data) demonstrate that DiffLM generates high-quality data, with performance on downstream tasks surpassing that of real data by 2%-7% in certain cases. Data and code are available at https://github.com/bytedance/DiffLM.
        ]]></description>
    </item>
    <item>
        <title>Autonomous Imagination: Closed-Loop Decomposition of Visual-to-Textual Conversion in Visual Reasoning for Multimodal Large Language Models</title>
        <link>https://arxiv.org/abs/2411.18142</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2411.18142v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jingming Liu, Yumeng Li, Boyuan Xiao, Yichang Jian, Ziang Qin, Tianjia Shao, Yao-Xiang Ding, Kun Zhou</dc:creator>
        <description><![CDATA[
            背景：大语言模型在纯文本模态复杂推理任务中表现出色，但多模态大语言模型在一些视觉任务上仍有困难，原因在于视觉到文本转换能力不足。方法：提出“自主想象”方法，让多模态大语言模型迭代修改视觉输入为中间视觉状态，将视觉到文本转换分解为闭环视觉修改步骤。效果：无需重新训练，多模态大语言模型就能解决原本超出其感知能力的任务，表明闭环视觉修改可有效分解视觉推理任务。
            arXiv:2411.18142v2 Announce Type: replace 
Abstract: Under pure textual modality, Large Language Models (LLMs) have demonstrated remarkable success in complex reasoning tasks by decomposing them into simpler sub-problems. However, Multimodal Large Language Models (MLLMs) still struggle with some seemingly straightforward visual tasks, such as counting and solving jigsaw puzzles. We argue that these tasks challenge the ability of visual-to-textual conversion, where MLLMs convert visual information perceived from the input scene, to textual information for further reasoning and generating the answer. If the complexity of the visual input is beyond the perceptual capability of the MLLMs, without decomposing this conversion process, simply scaling inference-time reasoning cannot solve the task because it repeatedly encounters the same perceptual bottleneck. We propose an approach, autonomous imagination, to enable MLLMs to iteratively modify visual inputs (e.g. isolating objects, rearranging puzzle pieces) into intermediate visual states, decomposing visual-to-textual conversion into closed-loop visual modification steps. We show that, without any retraining, MLLMs can now solve tasks initially beyond their perceptual capability, highlighting that closed-loop visual modification can be an effective way of decomposing the visual reasoning task into solvable substeps. Project page: https://future-item.github.io/autoimagine-site/
        ]]></description>
    </item>
    <item>
        <title>TinyLLaVA-Video: Towards Smaller LMMs for Video Understanding with Group Resampler</title>
        <link>https://arxiv.org/abs/2501.15513</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2501.15513v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xingjian Zhang, Xi Weng, Yihao Yue, Zhaoxin Fan, Wenjun Wu, Lei Huang</dc:creator>
        <description><![CDATA[
            视频行为识别和场景理解是多模态智能的基础任务，但现有开源大模型参数多、训练需大规模数据集，轻量级模型处理长视觉序列和时间理解能力差。为此，研究人员提出约36亿参数的轻量级视频理解模型TinyLLaVA - Video。其核心是视频级组重采样器，能减少和控制视频级视觉令牌数量，减轻冗余、增强时间理解。该模型仅需8块A100 - 40G GPU训练一天，在多个基准测试中超越现有70亿参数模型。
            arXiv:2501.15513v2 Announce Type: replace 
Abstract: Video behavior recognition and scene understanding are fundamental tasks in multimodal intelligence, serving as critical building blocks for numerous real-world applications. Through large multimodal models (LMMs) have achieved remarkable progress in video understanding, most existing open-source models rely on over 7B parameters and require large-scale datasets for training, making them resource-intensive and inaccessible to many researchers. Furthermore, lightweight models face persistent challenges in effectively processing long visual sequences and temporal understanding. In this work, we introduce TinyLLaVA-Video, a lightweight yet powerful video understanding model with approximately 3.6B parameters. The cornerstone of our design is the video-level group resampler, a novel mechanism that significantly reduces and controls the number of visual tokens at the video level. Unlike traditional image-level resampler, our approach effectively mitigates redundancy while enhancing temporal comprehension, leading to improved performance on video-based tasks. In addition, TinyLLaVA-Video demonstrates exceptional efficiency, requiring only one day of training on 8 A100-40G GPUs. It surpasses several existing 7B-parameter models on multiple benchmarks. We believe this work provides a valuable foundation for future research on lightweight video understanding models. The code and weights is available at https://github.com/ZhangXJ199/TinyLLaVA-Video.
        ]]></description>
    </item>
    <item>
        <title>LLM Alignment as Retriever Optimization: An Information Retrieval Perspective</title>
        <link>https://arxiv.org/abs/2502.03699</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.03699v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Bowen Jin, Jinsung Yoon, Zhen Qin, Ziqi Wang, Wei Xiong, Yu Meng, Jiawei Han, Sercan O. Arik</dc:creator>
        <description><![CDATA[
            背景：大语言模型虽推动各行业创新，但需有效对齐以解决错误信息、幻觉等问题，现有基于强化学习的对齐方法复杂。方法：引入基于信息检索原理的直接优化方法，提出系统框架连接大语言模型对齐与信息检索方法，在此基础上提出LarPO方法。效果：在AlpacaEval2和MixEval - Hard上平均分别提升38.9%和13.7%，为大语言模型对齐研究开辟新方向。
            arXiv:2502.03699v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have revolutionized artificial intelligence with capabilities in reasoning, coding, and communication, driving innovation across industries. Their true potential depends on effective alignment to ensure correct, trustworthy and ethical behavior, addressing challenges like misinformation, hallucinations, bias and misuse. While existing Reinforcement Learning (RL)-based alignment methods are notoriously complex, direct optimization approaches offer a simpler alternative. In this work, we introduce a novel direct optimization approach for LLM alignment by drawing on established Information Retrieval (IR) principles. We present a systematic framework that bridges LLM alignment and IR methodologies, mapping LLM generation and reward models to IR's retriever-reranker paradigm. Building on this foundation, we propose LLM Alignment as Retriever Preference Optimization (LarPO), a new alignment method that enhances overall alignment quality. Extensive experiments validate LarPO's effectiveness with 38.9 % and 13.7 % averaged improvement on AlpacaEval2 and MixEval-Hard respectively. Our work opens new avenues for advancing LLM alignment by integrating IR foundations, offering a promising direction for future research.
        ]]></description>
    </item>
    <item>
        <title>TRAVEL: Training-Free Retrieval and Alignment for Vision-and-Language Navigation</title>
        <link>https://arxiv.org/abs/2502.07306</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.07306v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Navid Rajabi, Jana Kosecka</dc:creator>
        <description><![CDATA[
            背景：视觉语言导航任务需处理自然语言指令与视觉信息。方法：将问题分解为四个子模块，利用大语言模型和视觉语言模型进行零样本学习。先让大语言模型提取地标及访问顺序，基于环境拓扑图生成路径假设，用动态规划计算全景序列与地标名称序列的对齐分数，以nDTW指标评估路径保真度。效果：在复杂的R2R - Habitat指令数据集上，比使用联合语义地图的方法性能更优，还详细量化了视觉定位对导航性能的影响。
            arXiv:2502.07306v2 Announce Type: replace 
Abstract: In this work, we propose a modular approach for the Vision-Language Navigation (VLN) task by decomposing the problem into four sub-modules that use state-of-the-art Large Language Models (LLMs) and Vision-Language Models (VLMs) in a zero-shot setting. Given navigation instruction in natural language, we first prompt LLM to extract the landmarks and the order in which they are visited. Assuming the known model of the environment, we retrieve the top-k locations of the last landmark and generate $k$ path hypotheses from the starting location to the last landmark using the shortest path algorithm on the topological map of the environment. Each path hypothesis is represented by a sequence of panoramas. We then use dynamic programming to compute the alignment score between the sequence of panoramas and the sequence of landmark names, which match scores obtained from VLM. Finally, we compute the nDTW metric between the hypothesis that yields the highest alignment score to evaluate the path fidelity. We demonstrate superior performance compared to other approaches that use joint semantic maps like VLMaps on the complex R2R-Habitat instruction dataset and quantify in detail the effect of visual grounding on navigation performance.
        ]]></description>
    </item>
    <item>
        <title>Self-Training Elicits Concise Reasoning in Large Language Models</title>
        <link>https://arxiv.org/abs/2502.20122</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.20122v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tergel Munkhbat, Namgyu Ho, Seo Hyun Kim, Yongjin Yang, Yujin Kim, Se-Young Yun</dc:creator>
        <description><![CDATA[
            背景：思维链推理使大语言模型能通过中间标记解决复杂任务，但典型推理轨迹存在冗余标记，增加推理成本。方法：提出简单微调方法，利用通过最佳N采样和少样本调节获得的自生成简洁推理路径。效果：在GSM8K和MATH上，对五个模型家族平均减少30%的输出标记，同时保持平均准确率，能在包括大量训练后的模型等广泛模型上有效引出简洁推理。
            arXiv:2502.20122v3 Announce Type: replace 
Abstract: Chain-of-thought (CoT) reasoning has enabled large language models (LLMs) to utilize additional computation through intermediate tokens to solve complex tasks. However, we posit that typical reasoning traces contain many redundant tokens, incurring extraneous inference costs. Upon examination of the output distribution of current LLMs, we find evidence on their latent ability to reason more concisely, relative to their default behavior. To elicit this capability, we propose simple fine-tuning methods which leverage self-generated concise reasoning paths obtained by best-of-N sampling and few-shot conditioning, in task-specific settings. Our combined method achieves a 30% reduction in output tokens on average, across five model families on GSM8K and MATH, while maintaining average accuracy. By exploiting the fundamental stochasticity and in-context learning capabilities of LLMs, our self-training approach robustly elicits concise reasoning on a wide range of models, including those with extensive post-training. Code is available at https://github.com/TergelMunkhbat/concise-reasoning
        ]]></description>
    </item>
    <item>
        <title>Compositional Causal Reasoning Evaluation in Language Models</title>
        <link>https://arxiv.org/abs/2503.04556</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.04556v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jacqueline R. M. A. Maasch, Alihan H\"uy\"uk, Xinnuo Xu, Aditya V. Nori, Javier Gonzalez</dc:creator>
        <description><![CDATA[
            因果推理和组合推理是人工智能的两大核心目标，测量其能力需有原则性评估方法。本文提出组合因果推理（CCR）的统一视角，即推断因果度量如何组合及因果量如何在图中传播的能力。作者构建了一个系统评估CCR的框架，以平均处理效应和必要性与充分性概率为评估对象。通过对LLama、Phi和GPT系列语言模型的评估，在数学应用题中发现了不同的错误模式，除o1外，所有模型的CCR错误随因果路径复杂度增加而上升。
            arXiv:2503.04556v4 Announce Type: replace 
Abstract: Causal reasoning and compositional reasoning are two core aspirations in AI. Measuring the extent of these behaviors requires principled evaluation methods. We explore a unified perspective that considers both behaviors simultaneously, termed compositional causal reasoning (CCR): the ability to infer how causal measures compose and, equivalently, how causal quantities propagate through graphs. We instantiate a framework for the systematic evaluation of CCR for the average treatment effect and the probability of necessity and sufficiency. As proof of concept, we demonstrate CCR evaluation for language models in the LLama, Phi, and GPT families. On a math word problem, our framework revealed a range of taxonomically distinct error patterns. CCR errors increased with the complexity of causal paths for all models except o1.
        ]]></description>
    </item>
    <item>
        <title>Everything Can Be Described in Words: A Simple Unified Multi-Modal Framework with Semantic and Temporal Alignment</title>
        <link>https://arxiv.org/abs/2503.09081</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.09081v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiaowei Bi, Zheyuan Xu</dc:creator>
        <description><![CDATA[
            背景：多模态学习虽有进展，但当前方法在不同模态的表示和推理上常存在不一致问题。方法：提出UMaT框架，将视觉和听觉输入统一为大语言模型的结构化文本，解决语义对齐、时间同步和高效稀疏信息检索问题。效果：通过减少冗余和采用结构化文本表示进行统一多模态推理，显著提升了长视频问答的准确率，在长视频上最高提升13.7%，可达16.9%。
            arXiv:2503.09081v2 Announce Type: replace 
Abstract: While multi-modal learning has advanced significantly, current approaches often create inconsistencies in representation and reasoning of different modalities. We propose UMaT, a theoretically-grounded framework that unifies visual and auditory inputs as structured text for large language models, addressing semantic alignment, temporal synchronization, and efficient sparse information retrieval. It significantly improves state-of-the-art Long Video Question Answering accuracy (up to 13.7%, and 16.9% on long videos) via redundancy minimization and structured textual representation for unified multi-modal reasoning
        ]]></description>
    </item>
    <item>
        <title>PatchTrAD: A Patch-Based Transformer focusing on Patch-Wise Reconstruction Error for Time Series Anomaly Detection</title>
        <link>https://arxiv.org/abs/2504.08827</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.08827v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Samy-Melwan Vilhes (LITIS), Gilles Gasso (LITIS), Mokhtar Z Alaya (LMAC)</dc:creator>
        <description><![CDATA[
            背景：时间序列异常检测旨在识别流数据中的观测值是否显著偏离正常模式，随着联网设备的普及，该检测变得至关重要。方法：提出基于补丁的Transformer模型PatchTrAD，利用Transformer编码器，在基于重建的框架下使用补丁进行异常检测。效果：在多个基准数据集上的实证评估表明，PatchTrAD在检测性能上与最先进的深度学习异常检测模型相当，且推理时效率更高。
            arXiv:2504.08827v2 Announce Type: replace 
Abstract: Time series anomaly detection (TSAD) focuses on identifying whether observations in streaming data deviate significantly from normal patterns. With the prevalence of connected devices, anomaly detection on time series has become paramount, as it enables real-time monitoring and early detection of irregular behaviors across various application domains. In this work, we introduce PatchTrAD, a Patch-based Transformer model for time series anomaly detection. Our approach leverages a Transformer encoder along with the use of patches under a reconstructionbased framework for anomaly detection. Empirical evaluations on multiple benchmark datasets show that PatchTrAD is on par, in terms of detection performance, with state-of-the-art deep learning models for anomaly detection while being time efficient during inference.
        ]]></description>
    </item>
    <item>
        <title>On Large-scale Evaluation of Embedding Models for Knowledge Graph Completion</title>
        <link>https://arxiv.org/abs/2504.08970</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.08970v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Nasim Shirvani-Mahdavi, Farahnaz Akrami, Chengkai Li</dc:creator>
        <description><![CDATA[
            背景：知识图嵌入（KGE）模型虽被广泛研究用于知识图补全，但现有评估受不现实基准限制，标准评估指标存在缺陷，常用数据集有问题且小。方法：在大规模数据集FB - CVT - REV和FB + CVT - REV上对四个有代表性的KGE模型进行全面评估。效果：分析揭示了关键见解，如大小数据集在相对排名和绝对指标上有显著性能差异，二值化n元关系时会系统性高估模型能力，当前评估协议和指标存在根本局限。
            arXiv:2504.08970v2 Announce Type: replace 
Abstract: Knowledge graph embedding (KGE) models are extensively studied for knowledge graph completion, yet their evaluation remains constrained by unrealistic benchmarks. Standard evaluation metrics rely on the closed-world assumption, which penalizes models for correctly predicting missing triples, contradicting the fundamental goals of link prediction. These metrics often compress accuracy assessment into a single value, obscuring models' specific strengths and weaknesses. The prevailing evaluation protocol, link prediction, operates under the unrealistic assumption that an entity's properties, for which values are to be predicted, are known in advance. While alternative protocols such as property prediction, entity-pair ranking, and triple classification address some of these limitations, they remain underutilized. Moreover, commonly used datasets are either faulty or too small to reflect real-world data. Few studies examine the role of mediator nodes, which are essential for modeling n-ary relationships, or investigate model performance variation across domains. This paper conducts a comprehensive evaluation of four representative KGE models on large-scale datasets FB-CVT-REV and FB+CVT-REV. Our analysis reveals critical insights, including substantial performance variations between small and large datasets, both in relative rankings and absolute metrics, systematic overestimation of model capabilities when n-ary relations are binarized, and fundamental limitations in current evaluation protocols and metrics.
        ]]></description>
    </item>
    <item>
        <title>SpatialReasoner: Towards Explicit and Generalizable 3D Spatial Reasoning</title>
        <link>https://arxiv.org/abs/2504.20024</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.20024v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wufei Ma, Yu-Cheng Chou, Qihao Liu, Xingrui Wang, Celso de Melo, Jianwen Xie, Alan Yuille</dc:creator>
        <description><![CDATA[
            背景：尽管多模态模型有进展，但3D空间推理对现有模型仍是挑战，现有方法隐式推理，复杂问题表现不佳。方法：提出SpatialReasoner，在多阶段共享显式3D表征进行3D空间推理，还分析推理轨迹研究现有模型不足。效果：在多种空间推理基准测试中表现提升，在3DSRBench上比Gemini 2.0高9.2%，对新问题泛化性更好，为3D空间推理开辟新方向。
            arXiv:2504.20024v2 Announce Type: replace 
Abstract: Despite recent advances on multi-modal models, 3D spatial reasoning remains a challenging task for state-of-the-art open-source and proprietary models. Recent studies explore data-driven approaches and achieve enhanced spatial reasoning performance by fine-tuning models on 3D-related visual question-answering data. However, these methods typically perform spatial reasoning in an implicit manner and often fail on questions that are trivial to humans, even with long chain-of-thought reasoning. In this work, we introduce SpatialReasoner, a novel large vision-language model (LVLM) that addresses 3D spatial reasoning with explicit 3D representations shared between multiple stages--3D perception, computation, and reasoning. Explicit 3D representations provide a coherent interface that supports advanced 3D spatial reasoning and improves the generalization ability to novel question types. Furthermore, by analyzing the explicit 3D representations in multi-step reasoning traces of SpatialReasoner, we study the factual errors and identify key shortcomings of current LVLMs. Results show that our SpatialReasoner achieves improved performance on a variety of spatial reasoning benchmarks, outperforming Gemini 2.0 by 9.2% on 3DSRBench, and generalizes better when evaluating on novel 3D spatial reasoning questions. Our study bridges the 3D parsing capabilities of prior visual foundation models with the powerful reasoning abilities of large language models, opening new directions for 3D spatial reasoning.
        ]]></description>
    </item>
    <item>
        <title>An Analysis of Hyper-Parameter Optimization Methods for Retrieval Augmented Generation</title>
        <link>https://arxiv.org/abs/2505.03452</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.03452v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Matan Orbach, Ohad Eytan, Benjamin Sznajder, Ariel Gera, Odellia Boni, Yoav Kantor, Gal Bloch, Omri Levy, Hadas Abraham, Nitzan Barzilay, Eyal Shnarch, Michael E. Factor, Shila Ofek-Koifman, Paula Ta-Shma, Assaf Toledo</dc:creator>
        <description><![CDATA[
            背景：为特定用例找到最优的检索增强生成（RAG）配置复杂且成本高，现有RAG超参数优化（HPO）框架有效性未严格评估。方法：对来自不同领域的5个数据集采用5种HPO算法开展综合研究，探索迄今最大的HPO搜索空间，以3种评估指标为优化目标。效果：研究表明，贪婪或随机搜索可高效进行RAG HPO，显著提升所有数据集的RAG性能，且贪婪HPO中先优化模型选择比按RAG管道顺序优化更优。
            arXiv:2505.03452v2 Announce Type: replace 
Abstract: Finding the optimal Retrieval-Augmented Generation (RAG) configuration for a given use case can be complex and expensive. Motivated by this challenge, frameworks for RAG hyper-parameter optimization (HPO) have recently emerged, yet their effectiveness has not been rigorously benchmarked. To address this gap, we present a comprehensive study involving 5 HPO algorithms over 5 datasets from diverse domains, including a new one collected for this work on real-world product documentation. Our study explores the largest HPO search space considered to date, with three evaluation metrics as optimization targets. Analysis of the results shows that RAG HPO can be done efficiently, either greedily or with random search, and that it significantly boosts RAG performance for all datasets. For greedy HPO approaches, we show that optimizing model selection first is preferable to the prevalent practice of optimizing according to RAG pipeline order.
        ]]></description>
    </item>
    <item>
        <title>CAD-Llama: Leveraging Large Language Models for Computer-Aided Design Parametric 3D Model Generation</title>
        <link>https://arxiv.org/abs/2505.04481</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.04481v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiahao Li, Weijian Ma, Xueyang Li, Yunzhong Lou, Guichun Zhou, Xiangdong Zhou</dc:creator>
        <description><![CDATA[
            背景：大语言模型虽成功，但在生成计算机辅助设计（CAD）模型参数序列方面面临挑战，因其预训练阶段未接触参数序列且不了解3D结构。方法：提出CAD - Llama框架，开发分层注释管道和类代码格式将参数3D CAD命令序列转换为结构化参数CAD代码，采用自适应预训练和遵循CAD准则的指令调优。效果：实验表明该框架显著优于先前的自回归方法和现有大语言模型基线。
            arXiv:2505.04481v2 Announce Type: replace 
Abstract: Recently, Large Language Models (LLMs) have achieved significant success, prompting increased interest in expanding their generative capabilities beyond general text into domain-specific areas. This study investigates the generation of parametric sequences for computer-aided design (CAD) models using LLMs. This endeavor represents an initial step towards creating parametric 3D shapes with LLMs, as CAD model parameters directly correlate with shapes in three-dimensional space. Despite the formidable generative capacities of LLMs, this task remains challenging, as these models neither encounter parametric sequences during their pretraining phase nor possess direct awareness of 3D structures. To address this, we present CAD-Llama, a framework designed to enhance pretrained LLMs for generating parametric 3D CAD models. Specifically, we develop a hierarchical annotation pipeline and a code-like format to translate parametric 3D CAD command sequences into Structured Parametric CAD Code (SPCC), incorporating hierarchical semantic descriptions. Furthermore, we propose an adaptive pretraining approach utilizing SPCC, followed by an instruction tuning process aligned with CAD-specific guidelines. This methodology aims to equip LLMs with the spatial knowledge inherent in parametric sequences. Experimental results demonstrate that our framework significantly outperforms prior autoregressive methods and existing LLM baselines.
        ]]></description>
    </item>
    <item>
        <title>Fusing Bidirectional Chains of Thought and Reward Mechanisms A Method for Enhancing Question-Answering Capabilities of Large Language Models for Chinese Intangible Cultural Heritage</title>
        <link>https://arxiv.org/abs/2505.08167</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.08167v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ruilin Liu, Zhixiao Zhao, Jieqiong Li, Chang Liu, Dongbo Wang</dc:creator>
        <description><![CDATA[
            背景：大语言模型发展为特定领域大模型进步提供支持，但用非遗数据微调大模型面临偏差、知识继承错误等问题。方法：提出融合双向思维链和奖励机制的训练方法，基于非遗领域大模型ICH - Qwen，利用反向提问和推理激活潜在知识，训练中引入奖励机制优化决策。效果：对比实验显示该方法在问答任务的准确率、Bleu - 4和Rouge - L得分上优于多种方法，消融及泛化实验证明其有效性和多领域适应性。
            arXiv:2505.08167v4 Announce Type: replace 
Abstract: The rapid development of large language models (LLMs) has provided significant support and opportunities for the advancement of domain-specific LLMs. However, fine-tuning these large models using Intangible Cultural Heritage (ICH) data inevitably faces challenges such as bias, incorrect knowledge inheritance, and catastrophic forgetting. To address these issues, we propose a novel training method that integrates a bidirectional chains of thought and a reward mechanism. This method is built upon ICH-Qwen, a large language model specifically designed for the field of intangible cultural heritage. The proposed method enables the model to not only perform forward reasoning but also enhances the accuracy of the generated answers by utilizing reverse questioning and reverse reasoning to activate the model's latent knowledge. Additionally, a reward mechanism is introduced during training to optimize the decision-making process. This mechanism improves the quality of the model's outputs through structural and content evaluations with different weighting schemes. We conduct comparative experiments on ICH-Qwen, with results demonstrating that our method outperforms 0-shot, step-by-step reasoning, knowledge distillation, and question augmentation methods in terms of accuracy, Bleu-4, and Rouge-L scores on the question-answering task. Furthermore, the paper highlights the effectiveness of combining the bidirectional chains of thought and reward mechanism through ablation experiments. In addition, a series of generalizability experiments are conducted, with results showing that the proposed method yields improvements on various domain-specific datasets and advanced models in areas such as Finance, Wikidata, and StrategyQA. This demonstrates that the method is adaptable to multiple domains and provides a valuable approach for model training in future applications across diverse fields.
        ]]></description>
    </item>
    <item>
        <title>DisCO: Reinforcing Large Reasoning Models with Discriminative Constrained Optimization</title>
        <link>https://arxiv.org/abs/2505.12366</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12366v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Gang Li, Ming Lin, Tomer Galanti, Zhengzhong Tu, Tianbao Yang</dc:creator>
        <description><![CDATA[
            背景：DeepSeek - R1的成功使GRPO作为大推理模型的强化学习方法备受关注，但GRPO存在问题层面难度偏差的固有局限。方法：提出基于判别学习原理的DisCO框架，用判别目标取代群体相对目标，采用非裁剪的强化学习替代目标作评分函数，用约束优化方法确保训练稳定。效果：消除难度偏差，解决熵不稳定问题，可处理数据不平衡。实验显示，1.5B模型在六项基准任务中，DisCO比GRPO平均高7%，比DAPO高6%。
            arXiv:2505.12366v2 Announce Type: replace 
Abstract: The recent success and openness of DeepSeek-R1 have brought widespread attention to Group Relative Policy Optimization (GRPO) as a reinforcement learning method for large reasoning models (LRMs). In this work, we analyze the GRPO objective under a binary reward setting and reveal an inherent limitation of question-level difficulty bias. We also identify a connection between GRPO and traditional discriminative methods in supervised learning. Motivated by these insights, we introduce a new Discriminative Constrained Optimization (DisCO) framework for reinforcing LRMs, grounded in the principle of discriminative learning. The main differences between DisCO and GRPO and its recent variants are: (1) it replaces the group relative objective with a discriminative objective defined by a scoring function; (2) it abandons clipping-based surrogates in favor of non-clipping RL surrogate objectives used as scoring functions; (3) it employs a simple yet effective constrained optimization approach to enforce the KL divergence constraint, ensuring stable training. As a result, DisCO offers notable advantages over GRPO and its variants: (i) it completely eliminates difficulty bias by adopting discriminative objectives; (ii) it addresses the entropy instability in GRPO and its variants through the use of non-clipping scoring functions and a constrained optimization approach; (iii) it allows the incorporation of advanced discriminative learning techniques to address data imbalance, where a significant number of questions have more negative than positive generated answers during training. Our experiments on enhancing the mathematical reasoning capabilities of SFT-finetuned models show that DisCO significantly outperforms GRPO and its improved variants such as DAPO, achieving average gains of 7\% over GRPO and 6\% over DAPO across six benchmark tasks for an 1.5B model.
        ]]></description>
    </item>
    <item>
        <title>Learning to Reason via Mixture-of-Thought for Logical Reasoning</title>
        <link>https://arxiv.org/abs/2505.15817</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.15817v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tong Zheng, Lichang Chen, Simeng Han, R. Thomas McCoy, Heng Huang</dc:creator>
        <description><![CDATA[
            背景：人类能运用多种推理模式解决逻辑问题，而现有大语言模型训练多采用单一模式，限制了模态间的协同作用。方法：提出Mixture-of-Thought（MoT）框架，使大语言模型能跨自然语言、代码和真值表三种互补模态进行推理，采用自进化训练和推理两阶段设计。效果：在FOLIO和ProofWriter等逻辑推理基准测试中，MoT框架显著优于单模态思维链方法，平均准确率最高提升11.7个百分点，对较难问题尤其有效。
            arXiv:2505.15817v2 Announce Type: replace 
Abstract: Human beings naturally utilize multiple reasoning modalities to learn and solve logical problems, i.e., different representational formats such as natural language, code, and symbolic logic. In contrast, most existing LLM-based approaches operate with a single reasoning modality during training, typically natural language. Although some methods explored modality selection or augmentation at inference time, the training process remains modality-blind, limiting synergy among modalities. To fill in this gap, we propose Mixture-of-Thought (MoT), a framework that enables LLMs to reason across three complementary modalities: natural language, code, and a newly introduced symbolic modality, truth-table, which systematically enumerates logical cases and partially mitigates key failure modes in natural language reasoning. MoT adopts a two-phase design: (1) self-evolving MoT training, which jointly learns from filtered, self-generated rationales across modalities; and (2) MoT inference, which fully leverages the synergy of three modalities to produce better predictions. Experiments on logical reasoning benchmarks including FOLIO and ProofWriter demonstrate that our MoT framework consistently and significantly outperforms strong LLM baselines with single-modality chain-of-thought approaches, achieving up to +11.7pp average accuracy gain. Further analyses show that our MoT framework benefits both training and inference stages; that it is particularly effective on harder logical reasoning problems; and that different modalities contribute complementary strengths, with truth-table reasoning helping to overcome key bottlenecks in natural language inference.
        ]]></description>
    </item>
    <item>
        <title>Mixture of Decoding: An Attention-Inspired Adaptive Decoding Strategy to Mitigate Hallucinations in Large Vision-Language Models</title>
        <link>https://arxiv.org/abs/2505.17061</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17061v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xinlong Chen, Yuanxing Zhang, Qiang Liu, Junfei Wu, Fuzheng Zhang, Tieniu Tan</dc:creator>
        <description><![CDATA[
            大视觉语言模型（LVLMs）在视觉任务中表现出色，但受幻觉问题困扰。为解决这一问题，研究提出混合解码（MoD）方法，通过评估模型对图像标记注意力的正确性来动态调整解码策略。具体是衡量原图像标记和模型关注的图像标记生成输出的一致性，一致时采用互补策略强化关键信息，不一致时用对比策略抑制误导信息。大量实验表明，MoD在多个主流基准测试中显著优于现有解码方法，有效减轻了LVLMs的幻觉问题。
            arXiv:2505.17061v3 Announce Type: replace 
Abstract: Large Vision-Language Models (LVLMs) have exhibited impressive capabilities across various visual tasks, yet they remain hindered by the persistent challenge of hallucinations. To address this critical issue, we propose Mixture of Decoding (MoD), a novel approach for hallucination mitigation that dynamically adapts decoding strategies by evaluating the correctness of the model's attention on image tokens. Specifically, MoD measures the consistency between outputs generated from the original image tokens and those derived from the model's attended image tokens, to distinguish the correctness aforementioned. If the outputs are consistent, indicating correct attention, MoD employs a complementary strategy to amplify critical information. Conversely, if the outputs are inconsistent, suggesting erroneous attention, MoD utilizes a contrastive strategy to suppress misleading information. Extensive experiments demonstrate that MoD significantly outperforms existing decoding methods across multiple mainstream benchmarks, effectively mitigating hallucinations in LVLMs. The code is available at https://github.com/xlchen0205/MoD.
        ]]></description>
    </item>
    <item>
        <title>How Do Images Align and Complement LiDAR? Towards a Harmonized Multi-modal 3D Panoptic Segmentation</title>
        <link>https://arxiv.org/abs/2505.18956</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.18956v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yining Pan, Qiongjie Cui, Xulei Yang, Na Zhao</dc:creator>
        <description><![CDATA[
            这是一篇关于多模态研究的论文。背景是基于激光雷达的3D全景分割因激光雷达数据稀疏，难以准确识别远处或小物体，虽有研究结合相机图像，但存在数据增强时未对齐等问题。方法是提出IAL多模态3D全景分割框架，采用PieAug策略确保输入对齐，用变压器解码器预测结果，设计GTF模块融合特征，用PQG模块增强解码器能力。效果是在两个常用基准测试中达到了最先进的性能。
            arXiv:2505.18956v2 Announce Type: replace 
Abstract: LiDAR-based 3D panoptic segmentation often struggles with the inherent sparsity of data from LiDAR sensors, which makes it challenging to accurately recognize distant or small objects. Recently, a few studies have sought to overcome this challenge by integrating LiDAR inputs with camera images, leveraging the rich and dense texture information provided by the latter. While these approaches have shown promising results, they still face challenges, such as misalignment during data augmentation and the reliance on post-processing steps. To address these issues, we propose Image-Assists-LiDAR (IAL), a novel multi-modal 3D panoptic segmentation framework. In IAL, we first introduce a modality-synchronized data augmentation strategy, PieAug, to ensure alignment between LiDAR and image inputs from the start. Next, we adopt a transformer decoder to directly predict panoptic segmentation results. To effectively fuse LiDAR and image features into tokens for the decoder, we design a Geometric-guided Token Fusion (GTF) module. Additionally, we leverage the complementary strengths of each modality as priors for query initialization through a Prior-based Query Generation (PQG) module, enhancing the decoder's ability to generate accurate instance masks. Our IAL framework achieves state-of-the-art performance compared to previous multi-modal 3D panoptic segmentation methods on two widely used benchmarks. Code and models are publicly available at .
        ]]></description>
    </item>
    <item>
        <title>Curse of High Dimensionality Issue in Transformer for Long-context Modeling</title>
        <link>https://arxiv.org/abs/2505.22107</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22107v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Shuhai Zhang, Zeng You, Yaofo Chen, Zhiquan Wen, Qianyue Wang, Zhijie Qiu, Yuanqing Li, Mingkui Tan</dc:creator>
        <description><![CDATA[
            背景：基于Transformer的大语言模型在长上下文建模时，因冗余的注意力计算面临显著的计算效率问题。方法：将传统概率序列建模重新表述为监督学习任务，分析注意力稀疏性，把注意力优化表述为线性编码问题并提出组编码策略，进而提出动态组注意力（DGA），在注意力计算中聚合次要标记以减少冗余。效果：DGA能显著降低计算成本，同时保持有竞争力的性能。
            arXiv:2505.22107v3 Announce Type: replace 
Abstract: Transformer-based large language models (LLMs) excel in natural language processing tasks by capturing long-range dependencies through self-attention mechanisms. However, long-context modeling faces significant computational inefficiencies due to \textit{redundant} attention computations: while attention weights are often \textit{sparse}, all tokens consume \textit{equal} computational resources. In this paper, we reformulate traditional probabilistic sequence modeling as a \textit{supervised learning task}, enabling the separation of relevant and irrelevant tokens and providing a clearer understanding of redundancy. Based on this reformulation, we theoretically analyze attention sparsity, revealing that only a few tokens significantly contribute to predictions. Building on this, we formulate attention optimization as a linear coding problem and propose a \textit{group coding strategy}, theoretically showing its ability to improve robustness against random noise and enhance learning efficiency. Motivated by this, we propose \textit{Dynamic Group Attention} (DGA), which leverages the group coding to explicitly reduce redundancy by aggregating less important tokens during attention computation. Empirical results show that our DGA significantly reduces computational costs while maintaining competitive performance.Code is available at https://github.com/bolixinyu/DynamicGroupAttention.
        ]]></description>
    </item>
    <item>
        <title>Flexible Tool Selection through Low-dimensional Attribute Alignment of Vision and Language</title>
        <link>https://arxiv.org/abs/2505.22146</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22146v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Guangfu Hao, Haojie Wen, Liangxuna Guo, Yang Chen, Yanchao Bi, Shan Yu</dc:creator>
        <description><![CDATA[
            背景：灵活的工具选择反映复杂认知能力，但相关计算模型发展不足。方法：开发用低维属性表征连接视觉工具感知和语言任务理解的框架，构建含115种工具及13种属性的数据集，用视觉编码器提取图像属性，微调语言模型从任务描述中获取所需属性。效果：在工具选择任务中准确率达74%，远超直接工具匹配及部分小多模态模型，参数更少且接近GPT - 4o性能，消融研究表明操作相关属性最关键。
            arXiv:2505.22146v2 Announce Type: replace 
Abstract: Flexible tool selection reflects a complex cognitive ability that distinguishes humans from other species, yet computational models that capture this ability remain underdeveloped. We developed a framework using low-dimensional attribute representations to bridge visual tool perception and linguistic task understanding. We constructed a comprehensive dataset (ToolNet) containing 115 common tools labeled with 13 carefully designed attributes spanning physical, functional, and psychological properties, paired with natural language scenarios describing tool usage. Visual encoders (ResNet or ViT) extract attributes from tool images while fine-tuned language models (GPT-2, LLaMA, DeepSeek) derive required attributes from task descriptions. Our approach achieves 74% accuracy in tool selection tasks-significantly outperforming direct tool matching (20%) and smaller multimodal models (21%-58%), while approaching performance of much larger models like GPT-4o (73%) with substantially fewer parameters. Ablation studies revealed that manipulation-related attributes (graspability, hand-relatedness, elongation) consistently prove most critical across modalities. This work provides a parameter-efficient, interpretable solution that mimics human-like tool cognition, advancing both cognitive science understanding and practical applications in tool selection tasks.
        ]]></description>
    </item>
    <item>
        <title>Can Slow-thinking LLMs Reason Over Time? Empirical Studies in Time Series Forecasting</title>
        <link>https://arxiv.org/abs/2505.24511</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.24511v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiahao Wang, Mingyue Cheng, Qi Liu</dc:creator>
        <description><![CDATA[
            时间序列预测（TSF）现有方法多遵循快速思维范式，忽略对时间动态和上下文依赖的显式推理。新兴的慢思考大语言模型展现出多步推理能力，为将TSF重构为结构化推理任务带来新机遇。为此，本文提出TimeReasoner，将TSF表述为条件推理任务，设计提示策略激发预训练慢思考大语言模型的推理能力，并在多种TSF基准上评估。结果显示，慢思考大语言模型有一定零样本预测能力，尤其在捕捉高级趋势和上下文变化方面。研究揭示了大语言模型在时间领域推理行为的潜力与局限，有望推动基于推理的预测范式研究。
            arXiv:2505.24511v2 Announce Type: replace 
Abstract: Time series forecasting (TSF) is a fundamental and widely studied task, spanning methods from classical statistical approaches to modern deep learning and multimodal language modeling. Despite their effectiveness, these methods often follow a fast thinking paradigm emphasizing pattern extraction and direct value mapping, while overlooking explicit reasoning over temporal dynamics and contextual dependencies. Meanwhile, emerging slow-thinking LLMs (e.g., ChatGPT-o1, DeepSeek-R1) have demonstrated impressive multi-step reasoning capabilities across diverse domains, suggesting a new opportunity for reframing TSF as a structured reasoning task. This motivates a key question: can slow-thinking LLMs effectively reason over temporal patterns to support time series forecasting, even in zero-shot manner? To investigate this, in this paper, we propose TimeReasoner, an extensive empirical study that formulates TSF as a conditional reasoning task. We design a series of prompting strategies to elicit inference-time reasoning from pretrained slow-thinking LLMs and evaluate their performance across diverse TSF benchmarks. Our findings reveal that slow-thinking LLMs exhibit non-trivial zero-shot forecasting capabilities, especially in capturing high-level trends and contextual shifts. While preliminary, our study surfaces important insights into the reasoning behaviors of LLMs in temporal domains highlighting both their potential and limitations. We hope this work catalyzes further research into reasoning-based forecasting paradigms and paves the way toward more interpretable and generalizable TSF frameworks.
        ]]></description>
    </item>
    <item>
        <title>TL;DR: Too Long, Do Re-weighting for Efficient LLM Reasoning Compression</title>
        <link>https://arxiv.org/abs/2506.02678</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02678v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhong-Zhi Li, Xiao Liang, Zihao Tang, Lei Ji, Peijie Wang, Haotian Xu, Xing W, Haizhen Huang, Weiwei Deng, Ying Nian Wu, Yeyun Gong, Zhijiang Guo, Xiao Liu, Fei Yin, Cheng-Lin Liu</dc:creator>
        <description><![CDATA[
            背景：大语言模型虽借助强化学习和思维链技术取得进展，但高效语言推理尤其是长输出推理仍面临挑战。方法：提出不依赖复杂数据标注和多模型插值的基于动态比率的训练管道，持续平衡模型System - 1和System - 2数据的权重，以消除冗余推理过程。效果：在不同难度基准测试和特定模型上验证，该方法能在保持推理准确性的同时，使输出令牌数量减少近40%。
            arXiv:2506.02678v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have recently achieved remarkable progress by leveraging Reinforcement Learning and extended Chain-of-Thought (CoT) techniques. However, the challenge of performing efficient language reasoning--especially during inference with extremely long outputs--has drawn increasing attention from the research community. In this work, we propose a dynamic ratio-based training pipeline that does not rely on sophisticated data annotations or interpolation between multiple models. We continuously balance the weights between the model's System-1 and System-2 data to eliminate redundant reasoning processes while preserving the model's reasoning capability. We validate our approach across models on DeepSeek-R1-Distill-7B and DeepSeek-R1-Distill-14B and on a diverse set of benchmarks with varying difficulty levels. Our method significantly reduces the number of output tokens by nearly 40% while maintaining the accuracy of the reasoning. Our code and data will be available soon.
        ]]></description>
    </item>
    <item>
        <title>Selective Matching Losses -- Not All Scores Are Created Equal</title>
        <link>https://arxiv.org/abs/2506.04446</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04446v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Gil I. Shamir, Manfred K. Warmuth</dc:creator>
        <description><![CDATA[
            背景：学习系统需将预测分数与观测值匹配，在某些领域子集准确预测很关键。方法：通过在分数域设计递增的链接函数构建选择性匹配损失函数，利用复合Softmax函数开发多维选择性损失框架。效果：选择性损失能解决模型欠定问题，使其在高灵敏度区域更好预测，在重要分数区域的应用中比传统损失有显著优势，还可用于大语言模型的微调对齐。
            arXiv:2506.04446v2 Announce Type: replace 
Abstract: Learning systems match predicted scores to observations over some domain. Often, it is critical to produce accurate predictions in some subset (or region) of the domain, yet less important to accurately predict in other regions. We construct selective matching loss functions by design of increasing link functions over score domains. A matching loss is an integral over the link. A link defines loss sensitivity as function of the score, emphasizing high slope high sensitivity regions over flat ones. Loss asymmetry drives a model and resolves its underspecification to predict better in high sensitivity regions where it is more important, and to distinguish between high and low importance regions. A large variety of selective scalar losses can be designed with scaled and shifted Sigmoid and hyperbolic sine links. Their properties, however, do not extend to multi-class. Applying them per dimension lacks ranking sensitivity that assigns importance according to class score ranking. Utilizing composite Softmax functions, we develop a framework for multidimensional selective losses. We overcome limitations of the standard Softmax function, that is good for classification, but not for distinction between adjacent scores. Selective losses have substantial advantage over traditional losses in applications with more important score regions, including dwell-time prediction, retrieval, ranking with either pointwise, contrastive pairwise, or listwise losses, distillation problems, and fine-tuning alignment of Large Language Models (LLMs).
        ]]></description>
    </item>
    <item>
        <title>Pruning Spurious Subgraphs for Graph Out-of-Distribtuion Generalization</title>
        <link>https://arxiv.org/abs/2506.05957</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.05957v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tianjun Yao, Haoxuan Li, Yongqiang Chen, Tongliang Liu, Le Song, Eric Xing, Zhiqiang Shen</dc:creator>
        <description><![CDATA[
            背景：图神经网络在训练和测试数据分布变化时性能会大幅下降，现有方法直接识别不变子图存在挑战。方法：提出PrunE，首个基于剪枝的图OOD方法，通过两个正则化项剪去虚假边，一是图大小约束排除无信息的虚假边，二是ε概率对齐进一步抑制虚假边出现。效果：理论分析和大量实验表明，PrunE的OOD性能优越，显著超越先前的先进方法。
            arXiv:2506.05957v2 Announce Type: replace 
Abstract: Graph Neural Networks (GNNs) often encounter significant performance degradation under distribution shifts between training and test data, hindering their applicability in real-world scenarios. Recent studies have proposed various methods to address the out-of-distribution generalization challenge, with many methods in the graph domain focusing on directly identifying an invariant subgraph that is predictive of the target label. However, we argue that identifying the edges from the invariant subgraph directly is challenging and error-prone, especially when some spurious edges exhibit strong correlations with the targets. In this paper, we propose PrunE, the first pruning-based graph OOD method that eliminates spurious edges to improve OOD generalizability. By pruning spurious edges, PrunE retains the invariant subgraph more comprehensively, which is critical for OOD generalization. Specifically, PrunE employs two regularization terms to prune spurious edges: 1) graph size constraint to exclude uninformative spurious edges, and 2) $\epsilon$-probability alignment to further suppress the occurrence of spurious edges. Through theoretical analysis and extensive experiments, we show that PrunE achieves superior OOD performance and outperforms previous state-of-the-art methods significantly. Codes are available at: \href{https://github.com/tianyao-aka/PrunE-GraphOOD}{https://github.com/tianyao-aka/PrunE-GraphOOD}.
        ]]></description>
    </item>
    <item>
        <title>From Generation to Generalization: Emergent Few-Shot Learning in Video Diffusion Models</title>
        <link>https://arxiv.org/abs/2506.07280</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07280v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Pablo Acuaviva, Aram Davtyan, Mariam Hassan, Sebastian Stapf, Ahmad Rahimi, Alexandre Alahi, Paolo Favaro</dc:creator>
        <description><![CDATA[
            背景：视频扩散模型（VDMs）是强大的生成工具，其潜力远超视频生成，训练动态促使其内化结构化表征和对视觉世界的理解。方法：引入少样本微调框架，将任务转化为视觉过渡，在短输入输出序列上训练LoRA权重且不改变冻结VDM的生成接口。效果：模型在从低级视觉到高级推理等多样任务中展现出强大泛化能力，VDMs有望成为未来视觉基础模型的骨干。
            arXiv:2506.07280v2 Announce Type: replace 
Abstract: Video Diffusion Models (VDMs) have emerged as powerful generative tools, capable of synthesizing high-quality spatiotemporal content. Yet, their potential goes far beyond mere video generation. We argue that the training dynamics of VDMs, driven by the need to model coherent sequences, naturally pushes them to internalize structured representations and an implicit understanding of the visual world. To probe the extent of this internal knowledge, we introduce a few-shot fine-tuning framework that repurposes VDMs for new tasks using only a handful of examples. Our method transforms each task into a visual transition, enabling the training of LoRA weights on short input-output sequences without altering the generative interface of a frozen VDM. Despite minimal supervision, the model exhibits strong generalization across diverse tasks, from low-level vision (for example, segmentation and pose estimation) to high-level reasoning (for example, on ARC-AGI). These results reframe VDMs as more than generative engines. They are adaptable visual learners with the potential to serve as the backbone for future foundation models in vision.
        ]]></description>
    </item>
    <item>
        <title>Multi-SpaCE: Multi-Objective Subsequence-based Sparse Counterfactual Explanations for Multivariate Time Series Classification</title>
        <link>https://arxiv.org/abs/2501.04009</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2501.04009v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mario Refoyo, David Luengo</dc:creator>
        <description><![CDATA[
            背景：深度学习系统虽擅长复杂任务，但缺乏透明度，现有时间序列数据的反事实解释方法存在局限。方法：本文提出Multi - SpaCE，一种用于多变量时间序列的多目标反事实解释方法，利用非支配排序遗传算法II（NSGA - II）平衡接近性、稀疏性、合理性和连续性。效果：与现有方法相比，它能确保完美有效性，支持多变量数据，提供帕累托最优解，在不同数据集实验中表现更优。
            arXiv:2501.04009v2 Announce Type: replace-cross 
Abstract: Deep Learning systems excel in complex tasks but often lack transparency, limiting their use in critical applications. Counterfactual explanations, a core tool within eXplainable Artificial Intelligence (XAI), offer insights into model decisions by identifying minimal changes to an input to alter its predicted outcome. However, existing methods for time series data are limited by univariate assumptions, rigid constraints on modifications, or lack of validity guarantees. This paper introduces Multi-SpaCE, a multi-objective counterfactual explanation method for multivariate time series. Using non-dominated ranking genetic algorithm II (NSGA-II), Multi-SpaCE balances proximity, sparsity, plausibility, and contiguity. Unlike most methods, it ensures perfect validity, supports multivariate data and provides a Pareto front of solutions, enabling flexibility to different end-user needs. Comprehensive experiments in diverse datasets demonstrate the ability of Multi-SpaCE to consistently achieve perfect validity and deliver superior performance compared to existing methods.
        ]]></description>
    </item>
    <item>
        <title>EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations</title>
        <link>https://arxiv.org/abs/2502.14760</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.14760v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Haotian Zhai, Connor Lawless, Ellen Vitercik, Liu Leqi</dc:creator>
        <description><![CDATA[
            背景：组合优化中识别等价公式的需求增长，但现有方法依赖简单启发式，难以可靠检查公式等价性。方法：引入准卡普等价作为判断优化公式等价的标准，提出EquivaMap框架，利用大语言模型自动发现映射，还有验证阶段确保解的可行性和最优性。效果：构建了首个等价优化公式开源数据集EquivaFormulation，实验显示EquivaMap显著优于现有方法，在正确识别公式等价性上有大幅提升。
            arXiv:2502.14760v2 Announce Type: replace-cross 
Abstract: A fundamental problem in combinatorial optimization is identifying equivalent formulations. Despite the growing need for automated equivalence checks -- driven, for example, by optimization copilots, which generate problem formulations from natural language descriptions -- current approaches rely on simple heuristics that fail to reliably check formulation equivalence. Inspired by Karp reductions, in this work we introduce Quasi-Karp equivalence, a formal criterion for determining when two optimization formulations are equivalent based on the existence of a mapping between their decision variables. We propose EquivaMap, a framework that leverages large language models to automatically discover such mappings for scalable, reliable equivalence checking, with a verification stage that ensures mapped solutions preserve feasibility and optimality without additional solver calls. To evaluate our approach, we construct EquivaFormulation, the first open-source dataset of equivalent optimization formulations, generated by applying transformations such as adding slack variables or valid inequalities to existing formulations. Empirically, EquivaMap significantly outperforms existing methods, achieving substantial improvements in correctly identifying formulation equivalence.
        ]]></description>
    </item>
    <item>
        <title>Towards Reliable Proof Generation with LLMs: A Neuro-Symbolic Approach</title>
        <link>https://arxiv.org/abs/2505.14479</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14479v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Oren Sultan, Eitan Stern, Dafna Shahaf</dc:creator>
        <description><![CDATA[
            大语言模型在需要严格逻辑演绎和符号推理的形式领域（如数学证明生成）表现不佳。为此，提出一种神经符号方法，结合大语言模型的生成能力和结构化组件来应对挑战。以几何问题为例，该方法一是检索相似问题并以其证明引导模型，二是用形式验证器评估生成的证明并提供反馈以修正错误。实验表明，此方法使OpenAI的o1模型证明准确率提升58% - 70%，有助于提高模型可靠性、准确性和一致性。
            arXiv:2505.14479v2 Announce Type: replace-cross 
Abstract: Large language models (LLMs) struggle with formal domains that require rigorous logical deduction and symbolic reasoning, such as mathematical proof generation. We propose a neuro-symbolic approach that combines LLMs' generative strengths with structured components to overcome this challenge. As a proof-of-concept, we focus on geometry problems. Our approach is two-fold: (1) we retrieve analogous problems and use their proofs to guide the LLM, and (2) a formal verifier evaluates the generated proofs and provides feedback, helping the model fix incorrect proofs. We demonstrate that our method significantly improves proof accuracy for OpenAI's o1 model (58%-70% improvement); both analogous problems and the verifier's feedback contribute to these gains. More broadly, shifting to LLMs that generate provably correct conclusions could dramatically improve their reliability, accuracy and consistency, unlocking complex tasks and critical real-world applications that require trustworthiness.
        ]]></description>
    </item>
    <item>
        <title>Multimodal Zero-Shot Framework for Deepfake Hate Speech Detection in Low-Resource Languages</title>
        <link>https://arxiv.org/abs/2506.08372</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08372v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Rishabh Ranjan, Likhith Ayinala, Mayank Vatsa, Richa Singh</dc:creator>
        <description><![CDATA[
            背景：现有方法在低资源语言的深度伪造音频仇恨言论检测方面存在不足。方法：本文提出一种多模态框架，利用对比学习联合对齐跨语言的音频和文本表示，还创建了含127290对多语言文本和合成语音样本的基准数据集。效果：在两个多语言测试集上，该方法准确率分别达0.819和0.701，优于基线模型，且对未见语言泛化能力强，显示出多模态结合在低资源场景下检测仇恨言论的优势。
            arXiv:2506.08372v1 Announce Type: new 
Abstract: This paper introduces a novel multimodal framework for hate speech detection in deepfake audio, excelling even in zero-shot scenarios. Unlike previous approaches, our method uses contrastive learning to jointly align audio and text representations across languages. We present the first benchmark dataset with 127,290 paired text and synthesized speech samples in six languages: English and five low-resource Indian languages (Hindi, Bengali, Marathi, Tamil, Telugu). Our model learns a shared semantic embedding space, enabling robust cross-lingual and cross-modal classification. Experiments on two multilingual test sets show our approach outperforms baselines, achieving accuracies of 0.819 and 0.701, and generalizes well to unseen languages. This demonstrates the advantage of combining modalities for hate speech detection in synthetic media, especially in low-resource settings where unimodal models falter. The Dataset is available at https://www.iab-rubric.org/resources.
        ]]></description>
    </item>
    <item>
        <title>A Review on Score-based Generative Models for Audio Applications</title>
        <link>https://arxiv.org/abs/2506.08457</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08457v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ge Zhu, Yutong Wen, Zhiyao Duan</dc:creator>
        <description><![CDATA[
            背景：扩散模型在音频等领域应用广泛，但现有综述缺乏对其设计选择的深入讨论，音频扩散模型文献也缺少设计选择实施及比较的原则性指导。方法：从分数建模视角进行全面综述，系统研究扩散模型训练和采样程序及音频应用，介绍开源代码库。效果：通过三个案例研究展示其能力，在标准数据集上进行基准评估，推动可复现研究和快速原型开发。
            arXiv:2506.08457v1 Announce Type: new 
Abstract: Diffusion models have emerged as powerful deep generative techniques, producing high-quality and diverse samples in applications in various domains including audio. These models have many different design choices suitable for different applications, however, existing reviews lack in-depth discussions of these design choices. The audio diffusion model literature also lacks principled guidance for the implementation of these design choices and their comparisons for different applications. This survey provides a comprehensive review of diffusion model design with an emphasis on design principles for quality improvement and conditioning for audio applications. We adopt the score modeling perspective as a unifying framework that accommodates various interpretations, including recent approaches like flow matching. We systematically examine the training and sampling procedures of diffusion models, and audio applications through different conditioning mechanisms. To address the lack of audio diffusion model codebases and to promote reproducible research and rapid prototyping, we introduce an open-source codebase at https://github.com/gzhu06/AudioDiffuser that implements our reviewed framework for various audio applications. We demonstrate its capabilities through three case studies: audio generation, speech enhancement, and text-to-speech synthesis, with benchmark evaluations on standard datasets.
        ]]></description>
    </item>
    <item>
        <title>Teaching Physical Awareness to LLMs through Sounds</title>
        <link>https://arxiv.org/abs/2506.08524</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08524v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Weiguo Wang, Andy Nie, Wenrui Zhou, Yi Kai, Chengchen Hu</dc:creator>
        <description><![CDATA[
            大语言模型（LLMs）在文本和多模态处理方面能力出色，但缺乏对现实物理现象的理解。为此，本文提出ACORN框架，通过声音赋予LLMs物理感知能力，聚焦多普勒效应、多径效应和空间关系等基本物理现象。为解决数据稀缺问题，ACORN引入基于物理的模拟器生成训练数据，构建了AQA - PHY音频问答数据集，提出能处理幅度和相位信息的音频编码器。将其与先进的LLMs相连，在模拟和现实任务中取得合理结果，为LLMs理解物理世界奠定基础。
            arXiv:2506.08524v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have shown remarkable capabilities in text and multimodal processing, yet they fundamentally lack physical awareness--understanding of real-world physical phenomena. In this work, we present ACORN, a framework that teaches LLMs physical awareness through sound, focusing on fundamental physical phenomena like the Doppler effect, multipath effect, and spatial relationships. To overcome data scarcity, ACORN introduce a physics-based simulator combining real-world sound sources with controlled physical channels to generate diverse training data. Using this simulator, we build AQA-PHY, a comprehensive Audio Question-Answer dataset, and propose an audio encoder that processes both magnitude and phase information. By connecting our audio encoder to state-of-the-art LLMs, we demonstrate reasonable results in both simulated and real-world tasks, such as line-of-sight detection, Doppler effect estimation, and Direction-of-Arrival estimation, paving the way for enabling LLMs to understand physical world.
        ]]></description>
    </item>
    <item>
        <title>Auto-Regressive vs Flow-Matching: a Comparative Study of Modeling Paradigms for Text-to-Music Generation</title>
        <link>https://arxiv.org/abs/2506.08570</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08570v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Or Tal, Felix Kreuk, Yossi Adi</dc:creator>
        <description><![CDATA[
            背景：当前文本到音乐生成领域发展迅速，但不同模型在多方面差异大，难以公平评估。方法：该研究聚焦建模范式，系统对比自回归解码和条件流匹配这两种常见范式，使用相同数据集、训练配置和相似骨干架构从零开始训练模型，从生成质量、推理鲁棒性等多维度评估。效果：揭示了两种范式的优缺点，为文本到音乐生成的架构和训练决策提供了可行建议。
            arXiv:2506.08570v1 Announce Type: new 
Abstract: Recent progress in text-to-music generation has enabled models to synthesize high-quality musical segments, full compositions, and even respond to fine-grained control signals, e.g. chord progressions. State-of-the-art (SOTA) systems differ significantly across many dimensions, such as training datasets, modeling paradigms, and architectural choices. This diversity complicates efforts to evaluate models fairly and pinpoint which design choices most influence performance. While factors like data and architecture are important, in this study we focus exclusively on the modeling paradigm. We conduct a systematic empirical analysis to isolate its effects, offering insights into associated trade-offs and emergent behaviors that can guide future text-to-music generation systems. Specifically, we compare the two arguably most common modeling paradigms: Auto-Regressive decoding and Conditional Flow-Matching. We conduct a controlled comparison by training all models from scratch using identical datasets, training configurations, and similar backbone architectures. Performance is evaluated across multiple axes, including generation quality, robustness to inference configurations, scalability, adherence to both textual and temporally aligned conditioning, and editing capabilities in the form of audio inpainting. This comparative study sheds light on distinct strengths and limitations of each paradigm, providing actionable insights that can inform future architectural and training decisions in the evolving landscape of text-to-music generation. Audio sampled examples are available at: https://huggingface.co/spaces/ortal1602/ARvsFM
        ]]></description>
    </item>
    <item>
        <title>Step-Audio-AQAA: a Fully End-to-End Expressive Large Audio Language Model</title>
        <link>https://arxiv.org/abs/2506.08967</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08967v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ailin Huang, Bingxin Li, Bruce Wang, Boyong Wu, Chao Yan, Chengli Feng, Heng Wang, Hongyu Zhou, Hongyuan Wang, Jingbei Li, Jianjian Sun, Joanna Wang, Mingrui Chen, Peng Liu, Ruihang Miao, Shilei Jiang, Tian Fei, Wang You, Xi Chen, Xuerui Yang, Yechang Huang, Yuxiang Zhang, Zheng Ge, Zheng Gong, Zhewei Huang, Zixin Zhang, Bin Wang, Bo Li, Buyun Ma, Changxin Miao, Changyi Wan, Chen Xu, Dapeng Shi, Dingyuan Hu, Enle Liu, Guanzhe Huang, Gulin Yan, Hanpeng Hu, Haonan Jia, Jiahao Gong, Jiaoren Wu, Jie Wu, Jie Yang, Junzhe Lin, Kaixiang Li, Lei Xia, Longlong Gu, Ming Li, Nie Hao, Ranchen Ming, Shaoliang Pang, Siqi Liu, Song Yuan, Tiancheng Cao, Wen Li, Wenqing He, Xu Zhao, Xuelin Zhang, Yanbo Yu, Yinmin Zhong, Yu Zhou, Yuanwei Liang, Yuanwei Lu, Yuxiang Yang, Zidong Yang, Zili Zhang, Binxing Jiao, Heung-Yeung Shum, Jiansheng Chen, Jing Li, Xiangyu Zhang, Xinhao Zhang, Yibo Zhu, Daxin Jiang, Shuchang Zhou, Chen Hu</dc:creator>
        <description><![CDATA[
            这是一篇关于音频生成领域中大型音频语言模型的研究。背景是现有大模型依赖文本输出，限制了直接生成自然语音回应的能力。方法上，提出全端到端模型Step - Audio - AQAA，集成双码本音频分词器、1300亿参数骨干大模型和神经声码器，采用文本和音频交错输出的后训练方法，结合直接偏好优化和模型合并。效果上，在StepEval - Audio - 360基准测试中表现出色，尤其在语音控制方面超越了现有模型。
            arXiv:2506.08967v1 Announce Type: new 
Abstract: Large Audio-Language Models (LALMs) have significantly advanced intelligent human-computer interaction, yet their reliance on text-based outputs limits their ability to generate natural speech responses directly, hindering seamless audio interactions. To address this, we introduce Step-Audio-AQAA, a fully end-to-end LALM designed for Audio Query-Audio Answer (AQAA) tasks. The model integrates a dual-codebook audio tokenizer for linguistic and semantic feature extraction, a 130-billion-parameter backbone LLM and a neural vocoder for high-fidelity speech synthesis. Our post-training approach employs interleaved token-output of text and audio to enhance semantic coherence and combines Direct Preference Optimization (DPO) with model merge to improve performance. Evaluations on the StepEval-Audio-360 benchmark demonstrate that Step-Audio-AQAA excels especially in speech control, outperforming the state-of-art LALMs in key areas. This work contributes a promising solution for end-to-end LALMs and highlights the critical role of token-based vocoder in enhancing overall performance for AQAA tasks.
        ]]></description>
    </item>
    <item>
        <title>mSTEB: Massively Multilingual Evaluation of LLMs on Speech and Text Tasks</title>
        <link>https://arxiv.org/abs/2506.08400</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08400v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Luel Hagos Beyene, Vivek Verma, Min Ma, Jesujoba O. Alabi, Fabian David Schmidt, Joyce Nakatumba-Nabende, David Ifeoluwa Adelani</dc:creator>
        <description><![CDATA[
            这是一篇关于大语言模型（LLM）在语音和文本任务评估的论文。背景是LLM在多模态任务表现出色，但评估多限于英语和高资源语言，低资源语言缺乏标准化评估基准。方法是引入新基准mSTEB，对多种语音和文本任务进行评估，测试了Gemini 2.0 Flash等模型。效果显示，高资源和低资源语言在模型表现上差距大，尤其非洲、美洲/大洋洲语言，需加大投入解决其在LLM覆盖不足问题。
            arXiv:2506.08400v1 Announce Type: cross 
Abstract: Large Language models (LLMs) have demonstrated impressive performance on a wide range of tasks, including in multimodal settings such as speech. However, their evaluation is often limited to English and a few high-resource languages. For low-resource languages, there is no standardized evaluation benchmark. In this paper, we address this gap by introducing mSTEB, a new benchmark to evaluate the performance of LLMs on a wide range of tasks covering language identification, text classification, question answering, and translation tasks on both speech and text modalities. We evaluated the performance of leading LLMs such as Gemini 2.0 Flash and GPT-4o (Audio) and state-of-the-art open models such as Qwen 2 Audio and Gemma 3 27B. Our evaluation shows a wide gap in performance between high-resource and low-resource languages, especially for languages spoken in Africa and Americas/Oceania. Our findings show that more investment is needed to address their under-representation in LLMs coverage.
        ]]></description>
    </item>
    <item>
        <title>Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU</title>
        <link>https://arxiv.org/abs/2506.08911</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08911v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Petar Jaku\v{s}, Hrvoje D\v{z}apo</dc:creator>
        <description><![CDATA[
            这是一篇关于关键词检测系统的论文。背景是为了在资源受限设备上实现实时语音交互。方法是在集成神经处理单元（NPU）的NXP MCXN947微控制器上实现关键词检测系统，结合MFCC特征提取与CNN分类器，并采用量化感知训练优化。效果显著，与仅使用CPU执行相比，利用NPU时推理时间加快59倍，模型大小为30.58 KB时准确率达97.06%，证明了在嵌入式平台实现高效低功耗语音接口的可行性。
            arXiv:2506.08911v1 Announce Type: cross 
Abstract: This paper presents a keyword spotting (KWS) system implemented on the NXP MCXN947 microcontroller with an integrated Neural Processing Unit (NPU), enabling real-time voice interaction on resource-constrained devices. The system combines MFCC feature extraction with a CNN classifier, optimized using Quantization Aware Training to reduce model size with minimal accuracy drop. Experimental results demonstrate a 59x speedup in inference time when leveraging the NPU compared to CPU-only execution, achieving 97.06% accuracy with a model size of 30.58 KB, demonstrating the feasibility of efficient, low-power voice interfaces on embedded platforms.
        ]]></description>
    </item>
    <item>
        <title>Enhancing Retrieval-Augmented Audio Captioning with Generation-Assisted Multimodal Querying and Progressive Learning</title>
        <link>https://arxiv.org/abs/2410.10913</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.10913v3</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Choi Changin, Lim Sungjun, Rhee Wonjong</dc:creator>
        <description><![CDATA[
            这是一篇关于音频描述生成的研究。背景是现有检索增强生成方法在音频描述任务中多依赖单模态查询。方法上，提出生成辅助多模态查询，为输入音频生成文本描述以实现多模态查询，还引入渐进学习策略逐步增加交错的音频 - 文本对。效果方面，在AudioCaps、Clotho和Auto - ACD数据集上实验表明，该方法达到了当前最优结果。
            arXiv:2410.10913v3 Announce Type: replace 
Abstract: Retrieval-augmented generation can improve audio captioning by incorporating relevant audio-text pairs from a knowledge base. Existing methods typically rely solely on the input audio as a unimodal retrieval query. In contrast, we propose Generation-Assisted Multimodal Querying, which generates a text description of the input audio to enable multimodal querying. This approach aligns the query modality with the audio-text structure of the knowledge base, leading to more effective retrieval. Furthermore, we introduce a novel progressive learning strategy that gradually increases the number of interleaved audio-text pairs to enhance the training process. Our experiments on AudioCaps, Clotho, and Auto-ACD demonstrate that our approach achieves state-of-the-art results across these benchmarks.
        ]]></description>
    </item>
    <item>
        <title>LLaSE-G1: Incentivizing Generalization Capability for LLaMA-based Speech Enhancement</title>
        <link>https://arxiv.org/abs/2503.00493</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.00493v4</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Boyi Kang, Xinfa Zhu, Zihan Zhang, Zhen Ye, Mingshuai Liu, Ziqian Wang, Yike Zhu, Guobin Ma, Jun Chen, Longshuai Xiao, Chao Weng, Wei Xue, Lei Xie</dc:creator>
        <description><![CDATA[
            这是一篇关于语音增强的研究。背景是现有基于语言模型的语音增强方法重语义轻声学信息，导致增强后声学不一致、泛化能力有限。方法上，LLaSE - G1模型以WavLM的连续表征为输入，预测X - Codec2的语音标记，采用双通道输入输出统一多任务。效果上，它优于先前特定任务的判别式和生成式语音增强模型，在测试时有缩放效应，对未见任务有泛化能力，还公开代码和模型。
            arXiv:2503.00493v4 Announce Type: replace 
Abstract: Recent advancements in language models (LMs) have demonstrated strong capabilities in semantic understanding and contextual modeling, which have flourished in generative speech enhancement (SE). However, many LM-based SE approaches primarily focus on semantic information, often neglecting the critical role of acoustic information, which leads to acoustic inconsistency after enhancement and limited generalization across diverse SE tasks. In this paper, we introduce LLaSE-G1, a LLaMA-based language model that incentivizes generalization capabilities for speech enhancement. LLaSE-G1 offers the following key contributions: First, to mitigate acoustic inconsistency, LLaSE-G1 employs continuous representations from WavLM as input and predicts speech tokens from X-Codec2, maximizing acoustic preservation. Second, to promote generalization capability, LLaSE-G1 introduces dual-channel inputs and outputs, unifying multiple SE tasks without requiring task-specific IDs. Third, LLaSE-G1 outperforms prior task-specific discriminative and generative SE models, demonstrating scaling effects at test time and emerging capabilities for unseen SE tasks. Additionally, we release our code and models to support further research in this area.
        ]]></description>
    </item>
    <item>
        <title>Are you really listening? Boosting Perceptual Awareness in Music-QA Benchmarks</title>
        <link>https://arxiv.org/abs/2504.00369</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.00369v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yongyi Zang, Sean O'Brien, Taylor Berg-Kirkpatrick, Julian McAuley, Zachary Novack</dc:creator>
        <description><![CDATA[
            这是一篇关于音频大语言模型评估的研究。背景是当前音乐问答基准测试主要评估推理能力而非音频感知能力，文本大模型在音乐问答基准测试中准确率高达56.4%。方法是提出RUListening框架，引入感知指数（PI），生成需要真实音频感知的问答对。效果是过滤后的数据集让文本大模型表现接近随机水平，音频大模型在音频输入替换为噪声时性能下降，验证了框架在评估音频感知能力上的有效性。
            arXiv:2504.00369v2 Announce Type: replace 
Abstract: Large Audio Language Models (LALMs), where pretrained text LLMs are finetuned with audio input, have made remarkable progress in music understanding. However, current evaluation methodologies exhibit critical limitations: on the leading Music Question Answering benchmark, MuchoMusic, text-only LLMs without audio perception capabilities achieve surprisingly high accuracy of up to 56.4%, on par or above most LALMs. Furthermore, when presented with random Gaussian noise instead of actual audio, LALMs still perform significantly above chance. These findings suggest existing benchmarks predominantly assess reasoning abilities rather than audio perception. To overcome this challenge, we present RUListening: Robust Understanding through Listening, a framework that enhances perceptual evaluation in Music-QA benchmarks. We introduce the Perceptual Index (PI), a quantitative metric that measures a question's reliance on audio perception by analyzing log probability distributions from text-only language models. Using this metric, we generate synthetic, challenging distractors to create QA pairs that necessitate genuine audio perception. When applied to MuchoMusic, our filtered dataset successfully forces models to rely on perceptual information-text-only LLMs perform at chance levels, while LALMs similarly deteriorate when audio inputs are replaced with noise. These results validate our framework's effectiveness in creating benchmarks that more accurately evaluate audio perception capabilities.
        ]]></description>
    </item>
    <item>
        <title>Voice Impression Control in Zero-Shot TTS</title>
        <link>https://arxiv.org/abs/2506.05688</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.05688v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Keinichi Fujita, Shota Horiguchi, Yusuke Ijima</dc:creator>
        <description><![CDATA[
            语音中的副语言/非语言信息对塑造听众印象至关重要。零样本文本转语音虽能实现较高的说话人保真度，但调控微妙的副语言/非语言信息以控制语音印象仍具挑战。为此，研究人员开发了一种零样本TTS中的语音印象控制方法，利用低维向量表示不同语音印象对的强度。客观和主观评估结果证明了该方法在印象控制方面的有效性。此外，通过大语言模型生成向量，可根据自然语言描述生成目标印象，无需手动优化。
            arXiv:2506.05688v2 Announce Type: replace 
Abstract: Para-/non-linguistic information in speech is pivotal in shaping the listeners' impression. Although zero-shot text-to-speech (TTS) has achieved high speaker fidelity, modulating subtle para-/non-linguistic information to control perceived voice characteristics, i.e., impressions, remains challenging. We have therefore developed a voice impression control method in zero-shot TTS that utilizes a low-dimensional vector to represent the intensities of various voice impression pairs (e.g., dark-bright). The results of both objective and subjective evaluations have demonstrated our method's effectiveness in impression control. Furthermore, generating this vector via a large language model enables target-impression generation from a natural language description of the desired impression, thus eliminating the need for manual optimization. Audio examples are available on our demo page (https://ntt-hilab-gensp.github.io/is2025voiceimpression/).
        ]]></description>
    </item>
    <item>
        <title>Towards Generalized Source Tracing for Codec-Based Deepfake Speech</title>
        <link>https://arxiv.org/abs/2506.07294</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07294v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xuanjun Chen, I-Ming Lin, Lin Zhang, Haibin Wu, Hung-yi Lee, Jyh-Shing Roger Jang</dc:creator>
        <description><![CDATA[
            背景：基于神经音频编解码器的语音生成（CoSG）模型生成的基于编解码器的深度伪造语音（CodecFake）溯源效果欠佳，且用模拟CoSG数据训练溯源模型在真实CoSG生成音频上保持高性能仍是挑战。方法：提出语义 - 声学溯源网络（SASTNet），联合利用Whisper进行语义特征编码，用Wav2vec2和AudioMAE进行声学特征编码。效果：SASTNet在CodecFake+数据集的CoSG测试集上达到了最先进的性能，可实现可靠溯源。
            arXiv:2506.07294v2 Announce Type: replace 
Abstract: Recent attempts at source tracing for codec-based deepfake speech (CodecFake), generated by neural audio codec-based speech generation (CoSG) models, have exhibited suboptimal performance. However, how to train source tracing models using simulated CoSG data while maintaining strong performance on real CoSG-generated audio remains an open challenge. In this paper, we show that models trained solely on codec-resynthesized data tend to overfit to non-speech regions and struggle to generalize to unseen content. To mitigate these challenges, we introduce the Semantic-Acoustic Source Tracing Network (SASTNet), which jointly leverages Whisper for semantic feature encoding and Wav2vec2 with AudioMAE for acoustic feature encoding. Our proposed SASTNet achieves state-of-the-art performance on the CoSG test set of the CodecFake+ dataset, demonstrating its effectiveness for reliable source tracing.
        ]]></description>
    </item>
    <item>
        <title>An introduction to pitch strength in contemporary popular music analysis and production</title>
        <link>https://arxiv.org/abs/2506.07473</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07473v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Emmanuel Deruty</dc:creator>
        <description><![CDATA[
            背景：音乐信息检索区分音乐的低层次和高层次描述，当前生成式AI模型依赖的文本描述对专业音乐人而言过于抽象。方法：研究低层次的感知参数——音高强度，通过信号和感知分析其特性。效果：音高强度在歌曲内外有显著变化，有助于构建大小尺度的音乐结构，能处理复调不协和音，还可能是丰富感知视角下高次谐波的特征，或让AI模型更适用于音乐制作。
            arXiv:2506.07473v2 Announce Type: replace 
Abstract: Music information retrieval distinguishes between low- and high-level descriptions of music. Current generative AI models rely on text descriptions that are higher level than the controls familiar to studio musicians. Pitch strength, a low-level perceptual parameter of contemporary popular music, may be one feature that could make such AI models more suited to music production. Signal and perceptual analyses suggest that pitch strength (1) varies significantly across and inside songs; (2) contributes to both small- and large-scale structure; (3) contributes to the handling of polyphonic dissonance; and (4) may be a feature of upper harmonics made audible in a perspective of perceptual richness.
        ]]></description>
    </item>
</channel>
</rss>