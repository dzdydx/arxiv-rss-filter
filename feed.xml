<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
<channel>
    <title>arXiv Paper Filter</title>
    <link>https://github.com/None/arxiv_filter</link>
    <description>根据研究兴趣筛选的arXiv论文</description>
    <atom:link href="https://raw.githubusercontent.com/None/arxiv_filter/main/feed.xml" rel="self" type="application/rss+xml" />
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>zh-CN</language>
    <lastBuildDate>Tue, 08 Apr 2025 12:12:03 +0800</lastBuildDate>
    <managingEditor>None@github.com</managingEditor>
    <pubDate>Tue, 08 Apr 2025 12:12:03 +0800</pubDate>
    <skipDays>
        <day>Saturday</day>
        <day>Sunday</day>
    </skipDays>

    <item>
        <title>RLDBF: Enhancing LLMs Via Reinforcement Learning With DataBase FeedBack</title>
        <link>https://arxiv.org/abs/2504.03713</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.03713v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Weichen Dai, Zijie Dai, Zhijie Huang, Yixuan Pan, Xinhe Li, Xi Li, Yi Zhou, Ji Qi, Wu Jiang</dc:creator>
        <description><![CDATA[
            背景：当前大语言模型虽在非结构化文本训练中展现能力，但在利用结构化科学数据上不足。方法：以化学分子科学为试验台，研究在持续预训练、监督微调、强化学习等阶段融入分子属性数据的影响，提出“基于数据库反馈的强化学习”（RLDBF）方法解决大模型对数值不敏感问题。效果：模型在未见数据和其他化学任务上有显著泛化能力，证明该方法在大模型结构化科学数据处理领域有潜力。
            arXiv:2504.03713v1 Announce Type: new 
Abstract: While current large language models (LLMs) demonstrate remarkable linguistic capabilities through training on massive unstructured text corpora, they remain inadequate in leveraging structured scientific data (e.g., chemical molecular properties in databases) that encapsulate centuries of accumulated scientific expertise. These structured datasets hold strategic significance for advancing AI for Science yet current approaches merely treat them as auxiliary supplements to unstructured text. This study pioneers a systematic investigation into enhancing LLMs with structured scientific data, using chemical molecular science as a testbed. We investigate the impact of incorporating molecular property data on LLM across distinct training phases, including continual pre-training, supervised fine-tuning, and reinforcement learning. Notably, to address the inherent limitation of numerical insensitivity in large models, we propose an innovative methodology termed "Reinforcement Learning with Database Feedback" (RLDBF). Experimental evaluations demonstrate the efficacy of the proposed approach, with the model exhibiting remarkable generalization capabilities on previously unseen data and other chemical tasks. The results substantiate the potential of our method in advancing the field of structured scientific data processing within LLMs.
        ]]></description>
    </item>
    <item>
        <title>Timeseries Foundation Models for Mobility: A Benchmark Comparison with Traditional and Deep Learning Models</title>
        <link>https://arxiv.org/abs/2504.03725</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.03725v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Anita Graser</dc:creator>
        <description><![CDATA[
            背景：人群和流量预测在移动性数据科学中被广泛研究，传统预测方法依赖统计模型，后有深度学习方法补充，近期又出现时间序列预测基础模型。方法：本研究使用纽约市和奥地利维也纳的两个共享单车数据集，评估TimeGPT与传统方法在预测全市移动性时间序列上的性能，评估涵盖短、中、长期预测。效果：结果凸显了基础模型在移动性预测方面的潜力，同时也指出了实验的局限性。 
            arXiv:2504.03725v1 Announce Type: new 
Abstract: Crowd and flow predictions have been extensively studied in mobility data science. Traditional forecasting methods have relied on statistical models such as ARIMA, later supplemented by deep learning approaches like ST-ResNet. More recently, foundation models for time series forecasting, such as TimeGPT, Chronos, and LagLlama, have emerged. A key advantage of these models is their ability to generate zero-shot predictions, allowing them to be applied directly to new tasks without retraining. This study evaluates the performance of TimeGPT compared to traditional approaches for predicting city-wide mobility timeseries using two bike-sharing datasets from New York City and Vienna, Austria. Model performance is assessed across short (1-hour), medium (12-hour), and long-term (24-hour) forecasting horizons. The results highlight the potential of foundation models for mobility forecasting while also identifying limitations of our experiments.
        ]]></description>
    </item>
    <item>
        <title>TGraphX: Tensor-Aware Graph Neural Network for Multi-Dimensional Feature Learning</title>
        <link>https://arxiv.org/abs/2504.03953</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.03953v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Arash Sajjadi, Mark Eramian</dc:creator>
        <description><![CDATA[
            背景：传统CNN能提取图像空间特征，但难以建模对象间关系；传统GNN依赖扁平化节点特征，会丢失空间细节。方法：TGraphX将CNN与GNN结合，用CNN生成保留局部空间语义的多维节点特征，在图中用1*1卷积进行消息传递以融合相邻特征并保持结构，还用带残差连接的深度CNN聚合器精炼融合消息。效果：该方法弥合了空间特征提取与关系推理的差距，在目标检测细化和集成推理方面有显著提升。
            arXiv:2504.03953v1 Announce Type: new 
Abstract: TGraphX presents a novel paradigm in deep learning by unifying convolutional neural networks (CNNs) with graph neural networks (GNNs) to enhance visual reasoning tasks. Traditional CNNs excel at extracting rich spatial features from images but lack the inherent capability to model inter-object relationships. Conversely, conventional GNNs typically rely on flattened node features, thereby discarding vital spatial details. TGraphX overcomes these limitations by employing CNNs to generate multi-dimensional node features (e.g., (3*128*128) tensors) that preserve local spatial semantics. These spatially aware nodes participate in a graph where message passing is performed using 1*1 convolutions, which fuse adjacent features while maintaining their structure. Furthermore, a deep CNN aggregator with residual connections is used to robustly refine the fused messages, ensuring stable gradient flow and end-to-end trainability. Our approach not only bridges the gap between spatial feature extraction and relational reasoning but also demonstrates significant improvements in object detection refinement and ensemble reasoning.
        ]]></description>
    </item>
    <item>
        <title>Structured Extraction of Process Structure Properties Relationships in Materials Science</title>
        <link>https://arxiv.org/abs/2504.03979</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.03979v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Amit K Verma, Zhisong Zhang, Junwon Seo, Robin Kuo, Runbo Jiang, Emma Strubell, Anthony D Rollett</dc:creator>
        <description><![CDATA[
            背景：大语言模型虽让学术论文非结构化文本利于材料发现，但通用模型需适配才能解决材料特定查询。方法：引入新注释模式从科学文献提取通用过程 - 结构 - 属性关系，用 128 篇摘要数据集，先基于 MatBERT 开发条件随机场模型并在领域 I 评估，后与微调的 GPT - 4o 对比。效果：微调大模型在领域 I 上实体提取性能比 BERT - CRF 基线显著提升，加入领域 II 示例后，BERT - CRF 模型性能与 GPT - 4o 相当。
            arXiv:2504.03979v1 Announce Type: new 
Abstract: With the advent of large language models (LLMs), the vast unstructured text within millions of academic papers is increasingly accessible for materials discovery, although significant challenges remain. While LLMs offer promising few- and zero-shot learning capabilities, particularly valuable in the materials domain where expert annotations are scarce, general-purpose LLMs often fail to address key materials-specific queries without further adaptation. To bridge this gap, fine-tuning LLMs on human-labeled data is essential for effective structured knowledge extraction. In this study, we introduce a novel annotation schema designed to extract generic process-structure-properties relationships from scientific literature. We demonstrate the utility of this approach using a dataset of 128 abstracts, with annotations drawn from two distinct domains: high-temperature materials (Domain I) and uncertainty quantification in simulating materials microstructure (Domain II). Initially, we developed a conditional random field (CRF) model based on MatBERT, a domain-specific BERT variant, and evaluated its performance on Domain I. Subsequently, we compared this model with a fine-tuned LLM (GPT-4o from OpenAI) under identical conditions. Our results indicate that fine-tuning LLMs can significantly improve entity extraction performance over the BERT-CRF baseline on Domain I. However, when additional examples from Domain II were incorporated, the performance of the BERT-CRF model became comparable to that of the GPT-4o model. These findings underscore the potential of our schema for structured knowledge extraction and highlight the complementary strengths of both modeling approaches.
        ]]></description>
    </item>
    <item>
        <title>Foundation Models for Time Series: A Survey</title>
        <link>https://arxiv.org/abs/2504.04011</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.04011v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Siva Rama Krishna Kottapalli, Karthik Hubli, Sandeep Chandrashekhara, Garima Jain, Sunayana Hubli, Gayathri Botla, Ramesh Doddaiah</dc:creator>
        <description><![CDATA[
            背景：基于Transformer的基础模型在时间序列分析中成为主流范式，可用于预测、异常检测等任务。方法：该综述全面介绍当前预训练基础模型，提出新分类法，从架构设计（基于补丁表示或直接处理原始序列）、预测类型（概率或确定性）、处理序列类型（单变量或多变量）、模型规模复杂度及训练阶段目标函数类型等维度分类。效果：为研究者和从业者提供资源，洞察趋势并指明未来研究方向。
            arXiv:2504.04011v1 Announce Type: new 
Abstract: Transformer-based foundation models have emerged as a dominant paradigm in time series analysis, offering unprecedented capabilities in tasks such as forecasting, anomaly detection, classification, trend analysis and many more time series analytical tasks. This survey provides a comprehensive overview of the current state of the art pre-trained foundation models, introducing a novel taxonomy to categorize them across several dimensions. Specifically, we classify models by their architecture design, distinguishing between those leveraging patch-based representations and those operating directly on raw sequences. The taxonomy further includes whether the models provide probabilistic or deterministic predictions, and whether they are designed to work with univariate time series or can handle multivariate time series out of the box. Additionally, the taxonomy encompasses model scale and complexity, highlighting differences between lightweight architectures and large-scale foundation models. A unique aspect of this survey is its categorization by the type of objective function employed during training phase. By synthesizing these perspectives, this survey serves as a resource for researchers and practitioners, providing insights into current trends and identifying promising directions for future research in transformer-based time series modeling.
        ]]></description>
    </item>
    <item>
        <title>Multi-resolution Score-Based Variational Graphical Diffusion for Causal Disaster System Modeling and Inference</title>
        <link>https://arxiv.org/abs/2504.04015</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.04015v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xuechun Li, Shan Gao, Susu Xu</dc:creator>
        <description><![CDATA[
            背景：复杂因果依赖系统的准确建模面临挑战，现有方法难以兼顾多分辨率、物理关系、因果依赖和时间动态。方法：提出Temporal - SVGDM，为各变量在其原生分辨率下构建SDE，通过因果得分机制耦合，在时间模型中用序列预测模型处理状态表示。效果：在真实数据集实验中，较现有方法提高了预测准确性和因果理解能力，在不同背景知识水平下表现稳健，能处理不同灾害场景，数据有限时性能也较优。
            arXiv:2504.04015v1 Announce Type: new 
Abstract: Complex systems with intricate causal dependencies challenge accurate prediction. Effective modeling requires precise physical process representation, integration of interdependent factors, and incorporation of multi-resolution observational data. These systems manifest in both static scenarios with instantaneous causal chains and temporal scenarios with evolving dynamics, complicating modeling efforts. Current methods struggle to simultaneously handle varying resolutions, capture physical relationships, model causal dependencies, and incorporate temporal dynamics, especially with inconsistently sampled data from diverse sources. We introduce Temporal-SVGDM: Score-based Variational Graphical Diffusion Model for Multi-resolution observations. Our framework constructs individual SDEs for each variable at its native resolution, then couples these SDEs through a causal score mechanism where parent nodes inform child nodes' evolution. This enables unified modeling of both immediate causal effects in static scenarios and evolving dependencies in temporal scenarios. In temporal models, state representations are processed through a sequence prediction model to predict future states based on historical patterns and causal relationships. Experiments on real-world datasets demonstrate improved prediction accuracy and causal understanding compared to existing methods, with robust performance under varying levels of background knowledge. Our model exhibits graceful degradation across different disaster types, successfully handling both static earthquake scenarios and temporal hurricane and wildfire scenarios, while maintaining superior performance even with limited data.
        ]]></description>
    </item>
    <item>
        <title>SyLeR: A Framework for Explicit Syllogistic Legal Reasoning in Large Language Models</title>
        <link>https://arxiv.org/abs/2504.04042</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.04042v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kepu Zhang, Weijie Yu, Zhongxiang Sun, Jun Xu</dc:creator>
        <description><![CDATA[
            背景：现有大语言模型处理法律问题时无法进行明确三段论推理，答案缺乏可解释性和可信度。方法：提出SyLeR框架，集成树状分层检索机制结合相关法律条文和先例形成大前提，采用两阶段微调，先监督微调预热，再用结构感知奖励机制强化学习。效果：在多维度实验中，SyLeR显著提高了回答准确率，能持续输出明确、可解释且可信的法律推理。
            arXiv:2504.04042v1 Announce Type: new 
Abstract: Syllogistic reasoning is a fundamental aspect of legal decision-making, enabling logical conclusions by connecting general legal principles with specific case facts. Although existing large language models (LLMs) can generate responses to legal questions, they fail to perform explicit syllogistic reasoning, often producing implicit and unstructured answers that lack explainability and trustworthiness. To address this limitation, we propose SyLeR, a novel framework that empowers LLMs to engage in explicit syllogistic legal reasoning. SyLeR integrates a tree-structured hierarchical retrieval mechanism to effectively combine relevant legal statutes and precedent cases, forming comprehensive major premises. This is followed by a two-stage fine-tuning process: supervised fine-tuning warm-up establishes a foundational understanding of syllogistic reasoning, while reinforcement learning with a structure-aware reward mechanism refines the ability of the model to generate diverse logically sound and well-structured reasoning paths. We conducted extensive experiments across various dimensions, including in-domain and cross-domain user groups (legal laypersons and practitioners), multiple languages (Chinese and French), and different LLM backbones (legal-specific and open-domain LLMs). The results show that SyLeR significantly improves response accuracy and consistently delivers explicit, explainable, and trustworthy legal reasoning.
        ]]></description>
    </item>
    <item>
        <title>A Benchmark for End-to-End Zero-Shot Biomedical Relation Extraction with LLMs: Experiments with OpenAI Models</title>
        <link>https://arxiv.org/abs/2504.04083</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.04083v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Aviv Brokman, Xuguang Ai, Yuhang Jiang, Shashank Gupta, Ramakanth Kavuluru</dc:creator>
        <description><![CDATA[
            背景：零样本方法可降低数据集标注成本，但大语言模型在生物医学关系提取（RE）任务中的表现尚不明确。方法：使用OpenAI GPT - 4 - turbo和推理模型o1在七个数据集上进行端到端RE实验，利用GPT模型JSON生成能力以两种方式生成结构化输出。效果：该研究首次对比两者在多数据集上的端到端零样本生物医学RE任务表现，发现零样本性能接近微调方法，但在含多关系实例及文本提及边界处表现不佳。
            arXiv:2504.04083v1 Announce Type: new 
Abstract: Objective: Zero-shot methodology promises to cut down on costs of dataset annotation and domain expertise needed to make use of NLP. Generative large language models trained to align with human goals have achieved high zero-shot performance across a wide variety of tasks. As of yet, it is unclear how well these models perform on biomedical relation extraction (RE). To address this knowledge gap, we explore patterns in the performance of OpenAI LLMs across a diverse sampling of RE tasks.
  Methods: We use OpenAI GPT-4-turbo and their reasoning model o1 to conduct end-to-end RE experiments on seven datasets. We use the JSON generation capabilities of GPT models to generate structured output in two ways: (1) by defining an explicit schema describing the structure of relations, and (2) using a setting that infers the structure from the prompt language.
  Results: Our work is the first to study and compare the performance of the GPT-4 and o1 for the end-to-end zero-shot biomedical RE task across a broad array of datasets. We found the zero-shot performances to be proximal to that of fine-tuned methods. The limitations of this approach are that it performs poorly on instances containing many relations and errs on the boundaries of textual mentions.
  Conclusion: Recent large language models exhibit promising zero-shot capabilities in complex biomedical RE tasks, offering competitive performance with reduced dataset curation and NLP modeling needs at the cost of increased computing, potentially increasing medical community accessibility. Addressing the limitations we identify could further boost reliability. The code, data, and prompts for all our experiments are publicly available: https://github.com/bionlproc/ZeroShotRE
        ]]></description>
    </item>
    <item>
        <title>Evaluating Graphical Perception with Multimodal LLMs</title>
        <link>https://arxiv.org/abs/2504.04221</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.04221v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Rami Huu Nguyen, Kenichi Maeda, Mahsa Geshvadi, Daniel Haehn</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型（MLLMs）在图像分析理解上进步显著，但在图表值回归方面研究不足，其在图形感知任务上的表现待探究。方法：重现Cleveland和McGill 1984年的实验，对比MLLMs与人类在任务中的表现，评估微调、预训练模型和零样本提示。效果：发现MLLMs在某些情况下表现优于人类，某些情况则不然，研究结果有助于理解MLLMs在数据可视化应用中的优劣。
            arXiv:2504.04221v1 Announce Type: new 
Abstract: Multimodal Large Language Models (MLLMs) have remarkably progressed in analyzing and understanding images. Despite these advancements, accurately regressing values in charts remains an underexplored area for MLLMs. For visualization, how do MLLMs perform when applied to graphical perception tasks? Our paper investigates this question by reproducing Cleveland and McGill's seminal 1984 experiment and comparing it against human task performance. Our study primarily evaluates fine-tuned and pretrained models and zero-shot prompting to determine if they closely match human graphical perception. Our findings highlight that MLLMs outperform human task performance in some cases but not in others. We highlight the results of all experiments to foster an understanding of where MLLMs succeed and fail when applied to data visualization.
        ]]></description>
    </item>
    <item>
        <title>CATS: Mitigating Correlation Shift for Multivariate Time Series Classification</title>
        <link>https://arxiv.org/abs/2504.04283</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.04283v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiao Lin, Zhichen Zeng, Tianxin Wei, Zhining Liu, Yuzhong chen, Hanghang Tong</dc:creator>
        <description><![CDATA[
            背景：多变量时间序列（MTS）分类的无监督域适应（UDA）任务面临挑战，现有工作多忽略变量间相关性在不同领域的差异。方法：提出一种新的领域偏移“相关性偏移”，并设计可扩展且参数高效的CATS，利用时间卷积和图注意力模块，通过重加权目标相关性、提出相关性对齐损失来缓解偏移。效果：在四个真实数据集上，与普通基于Transformer的模型相比，CATS平均准确率提高超10%，仅增加约1%参数，配备CATS的Transformer变体达或超现有最优基线。
            arXiv:2504.04283v1 Announce Type: new 
Abstract: Unsupervised Domain Adaptation (UDA) leverages labeled source data to train models for unlabeled target data. Given the prevalence of multivariate time series (MTS) data across various domains, the UDA task for MTS classification has emerged as a critical challenge. However, for MTS data, correlations between variables often vary across domains, whereas most existing UDA works for MTS classification have overlooked this essential characteristic. To bridge this gap, we introduce a novel domain shift, {\em correlation shift}, measuring domain differences in multivariate correlation. To mitigate correlation shift, we propose a scalable and parameter-efficient \underline{C}orrelation \underline{A}dapter for M\underline{TS} (CATS). Designed as a plug-and-play technique compatible with various Transformer variants, CATS employs temporal convolution to capture local temporal patterns and a graph attention module to model the changing multivariate correlation. The adapter reweights the target correlations to align the source correlations with a theoretically guaranteed precision. A correlation alignment loss is further proposed to mitigate correlation shift, bypassing the alignment challenge from the non-i.i.d. nature of MTS data. Extensive experiments on four real-world datasets demonstrate that (1) compared with vanilla Transformer-based models, CATS increases over $10\%$ average accuracy while only adding around $1\%$ parameters, and (2) all Transformer variants equipped with CATS either reach or surpass state-of-the-art baselines.
        ]]></description>
    </item>
    <item>
        <title>The Point, the Vision and the Text: Does Point Cloud Boost Spatial Reasoning of Large Language Models?</title>
        <link>https://arxiv.org/abs/2504.04540</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.04540v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Weichen Zhang, Ruiying Peng, Chen Gao, Jianjie Fang, Xin Zeng, Kaiyuan Li, Ziyou Wang, Jinqiang Cui, Xin Wang, Xinlei Chen, Yong Li</dc:creator>
        <description><![CDATA[
            背景：利用点云空间信息进行3D空间推理的3D大语言模型受关注，但点云在3D空间推理中的作用待探索。方法：通过用视觉和文本输入替代点云，评估不同输入模态下大模型的空间推理能力；提出新的3D问答基准ScanReQA，评估模型对二元空间关系的理解。效果：发现无点云输入的大模型零样本表现也有竞争力，现有3D大模型理解二元空间关系有困难，且利用点云结构坐标进行细粒度空间推理存在局限。
            arXiv:2504.04540v1 Announce Type: new 
Abstract: 3D Large Language Models (LLMs) leveraging spatial information in point clouds for 3D spatial reasoning attract great attention. Despite some promising results, the role of point clouds in 3D spatial reasoning remains under-explored. In this work, we comprehensively evaluate and analyze these models to answer the research question: \textit{Does point cloud truly boost the spatial reasoning capacities of 3D LLMs?} We first evaluate the spatial reasoning capacity of LLMs with different input modalities by replacing the point cloud with the visual and text counterparts. We then propose a novel 3D QA (Question-answering) benchmark, ScanReQA, that comprehensively evaluates models' understanding of binary spatial relationships. Our findings reveal several critical insights: 1) LLMs without point input could even achieve competitive performance even in a zero-shot manner; 2) existing 3D LLMs struggle to comprehend the binary spatial relationships; 3) 3D LLMs exhibit limitations in exploiting the structural coordinates in point clouds for fine-grained spatial reasoning. We think these conclusions can help the next step of 3D LLMs and also offer insights for foundation models in other modalities. We release datasets and reproducible codes in the anonymous project page: https://3d-llm.xyz.
        ]]></description>
    </item>
    <item>
        <title>EquiCPI: SE(3)-Equivariant Geometric Deep Learning for Structure-Aware Prediction of Compound-Protein Interactions</title>
        <link>https://arxiv.org/abs/2504.04654</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.04654v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ngoc-Quang Nguyen</dc:creator>
        <description><![CDATA[
            在计算药物发现中，准确预测化合物 - 蛋白质相互作用（CPI）是关键挑战。现有基于序列的方法忽略了结合亲和力的三维结构决定因素。为此提出EquiCPI，这是一个端到端的几何深度学习框架，将第一性原理结构建模与SE(3)等变神经网络相结合。先将原始序列转换为3D原子坐标，再进行构象重排和等变特征学习。核心是在原子点云上进行SE(3)等变消息传递。该模型在BindingDB和DUD - E上评估，表现与或超过现有深度学习模型。
            arXiv:2504.04654v1 Announce Type: new 
Abstract: Accurate prediction of compound-protein interactions (CPI) remains a cornerstone challenge in computational drug discovery. While existing sequence-based approaches leverage molecular fingerprints or graph representations, they critically overlook three-dimensional (3D) structural determinants of binding affinity. To bridge this gap, we present EquiCPI, an end-to-end geometric deep learning framework that synergizes first-principles structural modeling with SE(3)-equivariant neural networks. Our pipeline transforms raw sequences into 3D atomic coordinates via ESMFold for proteins and DiffDock-L for ligands, followed by physics-guided conformer re-ranking and equivariant feature learning. At its core, EquiCPI employs SE(3)-equivariant message passing over atomic point clouds, preserving symmetry under rotations, translations, and reflections, while hierarchically encoding local interaction patterns through tensor products of spherical harmonics. The proposed model is evaluated on BindingDB (affinity prediction) and DUD-E (virtual screening), EquiCPI achieves performance on par with or exceeding the state-of-the-art deep learning competitors.
        ]]></description>
    </item>
    <item>
        <title>Sequential-NIAH: A Needle-In-A-Haystack Benchmark for Extracting Sequential Needles from Long Contexts</title>
        <link>https://arxiv.org/abs/2504.04713</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.04713v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yifei Yu, Qian-Wen Zhang, Lingfeng Qiao, Di Yin, Fang Li, Jie Wang, Zengxi Chen, Suncong Zheng, Xiaolong Liang, Xing Sun</dc:creator>
        <description><![CDATA[
            背景：评估大语言模型处理长文本并提取特定信息的能力至关重要。方法：提出Sequential - NIAH基准，含合成、真实和开放域问答三种信息抽取管道，有8K到128K词元长度的文本，共14000个样本。训练合成数据驱动评估模型，能按顺序评估答案正确性。效果：评估模型在合成测试数据上准确率达99.49%，对六个知名大模型实验显示，最佳模型准确率仅63.15%，表明提升空间大，且验证了基准可靠性。
            arXiv:2504.04713v1 Announce Type: new 
Abstract: Evaluating the ability of large language models (LLMs) to handle extended contexts is critical, particularly for retrieving information relevant to specific queries embedded within lengthy inputs. We introduce Sequential-NIAH, a benchmark specifically designed to evaluate the capability of LLMs to extract sequential information items (known as needles) from long contexts. The benchmark comprises three types of needle generation pipelines: synthetic, real, and open-domain QA. It includes contexts ranging from 8K to 128K tokens in length, with a dataset of 14,000 samples (2,000 reserved for testing). To facilitate evaluation on this benchmark, we trained a synthetic data-driven evaluation model capable of evaluating answer correctness based on chronological or logical order, achieving an accuracy of 99.49% on synthetic test data. We conducted experiments on six well-known LLMs, revealing that even the best-performing model achieved a maximum accuracy of only 63.15%. Further analysis highlights the growing challenges posed by increasing context lengths and the number of needles, underscoring substantial room for improvement. Additionally, noise robustness experiments validate the reliability of the benchmark, making Sequential-NIAH an important reference for advancing research on long text extraction capabilities of LLMs.
        ]]></description>
    </item>
    <item>
        <title>Can LLMs Interpret and Leverage Structured Linguistic Representations? A Case Study with AMRs</title>
        <link>https://arxiv.org/abs/2504.04745</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.04745v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ankush Raut, Xiaofeng Zhu, Maria Leonor Pacheco</dc:creator>
        <description><![CDATA[
            背景：评估大语言模型（LLMs）利用结构化语言表征形式的上下文信息的能力。方法：使用Llama 3.1（8B）、Phi - 3和Mistral 7B的8位量化和指令调优版本，研究抽象意义表征（AMR）结构编码短、长上下文对多种语言任务的影响。效果：短上下文任务中，用AMR增强提示常降低LLM性能；长上下文任务（如SAMSum数据集对话摘要）中，可提升性能，如Llama 3.1零样本余弦相似度从66.2%提升到76%，新的大型LLMs提升更明显，且LLMs能有效从线性化AMR重构原文，最佳余弦相似度达81.3%。
            arXiv:2504.04745v1 Announce Type: new 
Abstract: This paper evaluates the ability of Large Language Models (LLMs) to leverage contextual information in the form of structured linguistic representations. Specifically, we examine the impact of encoding both short and long contexts using Abstract Meaning Representation (AMR) structures across a diverse set of language tasks. We perform our analysis using 8-bit quantized and instruction-tuned versions of Llama 3.1 (8B), Phi-3, and Mistral 7B. Our results indicate that, for tasks involving short contexts, augmenting the prompt with the AMR of the original language context often degrades the performance of the underlying LLM. However, for tasks that involve long contexts, such as dialogue summarization in the SAMSum dataset, this enhancement improves LLM performance, for example, by increasing the zero-shot cosine similarity score of Llama 3.1 from 66.2% to 76%. This improvement is more evident in the newer and larger LLMs, but does not extend to the older or smaller ones. In addition, we observe that LLMs can effectively reconstruct the original text from a linearized AMR, achieving a cosine similarity of 81.3% in the best-case scenario.
        ]]></description>
    </item>
    <item>
        <title>Bidirectional Hierarchical Protein Multi-Modal Representation Learning</title>
        <link>https://arxiv.org/abs/2504.04770</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.04770v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xuefeng Liu, Songhao Jiang, Chih-chan Tien, Jinbo Xu, Rick Stevens</dc:creator>
        <description><![CDATA[
            蛋白质表示学习对生物任务至关重要。当前基于Transformer的蛋白质语言模型（pLMs）缺乏结构信息，而图神经网络（GNNs）受限于标注结构数据稀缺。为此，提出多模态双向分层融合框架，用注意力和门控机制使pLMs生成的序列表示与GNN提取的结构特征有效交互。还引入局部和全局双向分层融合方法。实验表明，该方法在多种蛋白质相关任务上，较基线和现有融合技术有持续提升，为多模态蛋白质表示学习树立新标杆。
            arXiv:2504.04770v1 Announce Type: new 
Abstract: Protein representation learning is critical for numerous biological tasks. Recently, large transformer-based protein language models (pLMs) pretrained on large scale protein sequences have demonstrated significant success in sequence-based tasks. However, pLMs lack structural information. Conversely, graph neural networks (GNNs) designed to leverage 3D structural information have shown promising generalization in protein-related prediction tasks, but their effectiveness is often constrained by the scarcity of labeled structural data. Recognizing that sequence and structural representations are complementary perspectives of the same protein entity, we propose a multimodal bidirectional hierarchical fusion framework to effectively merge these modalities. Our framework employs attention and gating mechanisms to enable effective interaction between pLMs-generated sequential representations and GNN-extracted structural features, improving information exchange and enhancement across layers of the neural network. Based on the framework, we further introduce local Bi-Hierarchical Fusion with gating and global Bi-Hierarchical Fusion with multihead self-attention approaches. Through extensive experiments on a diverse set of protein-related tasks, our method demonstrates consistent improvements over strong baselines and existing fusion techniques in a variety of protein representation learning benchmarks, including react (enzyme/EC classification), model quality assessment (MQA), protein-ligand binding affinity prediction (LBA), protein-protein binding site prediction (PPBS), and B cell epitopes prediction (BCEs). Our method establishes a new state-of-the-art for multimodal protein representation learning, emphasizing the efficacy of BIHIERARCHICAL FUSION in bridging sequence and structural modalities.
        ]]></description>
    </item>
    <item>
        <title>Improving Multilingual Retrieval-Augmented Language Models through Dialectic Reasoning Argumentations</title>
        <link>https://arxiv.org/abs/2504.04771</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.04771v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Leonardo Ranaldi, Federico Ranaldi, Fabio Massimo Zanzotto, Barry Haddow, Alexandra Birch</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）可让大语言模型获取更丰富知识，但在多语言检索中，模型需处理可能冲突的知识。方法：提出Dialectic - RAG（DRAG），这是一种由论证性解释引导的模块化方法，通过比较、对比和解决冲突观点来系统评估检索信息，筛选出相关知识给出辩证解释。效果：实验表明，DRAG作为上下文学习策略及指导小模型构建示例时，显著改进了RAG方法，计算量小且对知识扰动有鲁棒性。
            arXiv:2504.04771v1 Announce Type: new 
Abstract: Retrieval-augmented generation (RAG) is key to enhancing large language models (LLMs) to systematically access richer factual knowledge. Yet, using RAG brings intrinsic challenges, as LLMs must deal with potentially conflicting knowledge, especially in multilingual retrieval, where the heterogeneity of knowledge retrieved may deliver different outlooks. To make RAG more analytical, critical and grounded, we introduce Dialectic-RAG (DRAG), a modular approach guided by Argumentative Explanations, i.e., structured reasoning process that systematically evaluates retrieved
  information by comparing, contrasting, and resolving conflicting perspectives. Given a query and a set of multilingual related documents, DRAG selects and exemplifies relevant knowledge for delivering dialectic explanations that, by critically weighing opposing arguments and filtering extraneous content, clearly determine the final response. Through a series of in-depth experiments, we show the impact of our framework both as an in-context learning strategy and for constructing demonstrations to instruct smaller models. The final results demonstrate that DRAG significantly improves RAG approaches, requiring low-impact computational effort and providing robustness to knowledge perturbations.
        ]]></description>
    </item>
    <item>
        <title>OCC-MLLM-CoT-Alpha: Towards Multi-stage Occlusion Recognition Based on Large Language Models via 3D-Aware Supervision and Chain-of-Thoughts Guidance</title>
        <link>https://arxiv.org/abs/2504.04781</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.04781v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chaoyi Wang, Baoqing Li, Xinhan Di</dc:creator>
        <description><![CDATA[
            现有大规模视觉语言多模态模型在理解遮挡物体方面研究不足，通用视觉编码器和监督学习策略难以取得满意效果。为此，提出OCC - MLLM - CoT - Alpha框架，结合3D感知监督和思维链引导。构建由多模态大模型和3D重建专家模型组成的框架；通过监督和强化训练策略学习多模态思维链以提升识别能力；构建含110k样本的大规模多模态思维链推理数据集。评估显示，该方法使多种先进模型在两种设置下决策得分分别提升15.75%等和4.42%等。
            arXiv:2504.04781v1 Announce Type: new 
Abstract: Comprehending occluded objects are not well studied in existing large-scale visual-language multi-modal models. Current state-of-the-art multi-modal large models struggles to provide satisfactory results in understanding occluded objects through universal visual encoders and supervised learning strategies. Therefore, we propose OCC-MLLM-CoT-Alpha, a multi-modal large vision language framework that integrates 3D-aware supervision and Chain-of-Thoughts guidance. Particularly, (1) we build a multi-modal large vision-language model framework which is consisted of a large multi-modal vision-language model and a 3D reconstruction expert model. (2) the corresponding multi-modal Chain-of-Thoughts is learned through a combination of supervised and reinforcement training strategies, allowing the multi-modal vision-language model to enhance the recognition ability with learned multi-modal chain-of-thoughts guidance. (3) A large-scale multi-modal chain-of-thoughts reasoning dataset, consisting of $110k$ samples of occluded objects held in hand, is built. In the evaluation, the proposed methods demonstrate decision score improvement of 15.75%,15.30%,16.98%,14.62%, and 4.42%,3.63%,6.94%,10.70% for two settings of a variety of state-of-the-art models.
        ]]></description>
    </item>
    <item>
        <title>Topological Schr\"odinger Bridge Matching</title>
        <link>https://arxiv.org/abs/2504.04799</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.04799v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Maosheng Yang</dc:creator>
        <description><![CDATA[
            背景：现有薛定谔桥（SB）方法在欧几里得域表现良好，但不适用于图等拓扑域。方法：提出拓扑薛定谔桥问题（TSBP）匹配拓扑域上的信号分布，设参考过程遵循拓扑热扩散等拓扑感知随机动力学，推导高斯边界分布下的封闭形式拓扑SB，一般情况证明最优过程遵循由未知量控制的前后向拓扑动力学，用（拓扑）神经网络参数化未知量并通过似然训练学习。效果：在合成和真实网络上验证了理论结果和模型实用性。 
            arXiv:2504.04799v1 Announce Type: new 
Abstract: Given two boundary distributions, the Schr\"odinger Bridge (SB) problem seeks the ``most likely`` random evolution between them with respect to a reference process. It has revealed rich connections to recent machine learning methods for generative modeling and distribution matching. While these methods perform well in Euclidean domains, they are not directly applicable to topological domains such as graphs and simplicial complexes, which are crucial for data defined over network entities, such as node signals and edge flows. In this work, we propose the Topological Schr\"odinger Bridge problem (TSBP) for matching signal distributions on a topological domain. We set the reference process to follow some linear tractable topology-aware stochastic dynamics such as topological heat diffusion. For the case of Gaussian boundary distributions, we derive a closed-form topological SB (TSB) in terms of its time-marginal and stochastic differential. In the general case, leveraging the well-known result, we show that the optimal process follows the forward-backward topological dynamics governed by some unknowns. Building on these results, we develop TSB-based models for matching topological signals by parameterizing the unknowns in the optimal process as (topological) neural networks and learning them through likelihood training. We validate the theoretical results and demonstrate the practical applications of TSB-based models on both synthetic and real-world networks, emphasizing the role of topology. Additionally, we discuss the connections of TSB-based models to other emerging models, and outline future directions for topological signal matching.
        ]]></description>
    </item>
    <item>
        <title>OrderChain: A General Prompting Paradigm to Improve Ordinal Understanding Ability of MLLM</title>
        <link>https://arxiv.org/abs/2504.04801</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.04801v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jinhong Wang, Shuo Tong, Jian liu, Dongqi Tang, Weiqiang Wang, Wentong Li, Hongxia Xu, Danny Chen, Jintai Chen, Jian Wu</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型在顺序回归任务上表现不佳。方法：提出OrderChain提示范式，包含任务感知提示进行特异性建模，以及范围优化思维链（RO - CoT）学习通用思维方式，还提出类别递归划分法生成指令候选类别提示支持RO - CoT自动优化。效果：在多个顺序回归数据集上，使用OrderChain的LLaVA模型显著提升性能，如在Adience数据集上准确率从47.5%提升到93.2%，远超现有方法。
            arXiv:2504.04801v1 Announce Type: new 
Abstract: Despite the remarkable progress of multimodal large language models (MLLMs), they continue to face challenges in achieving competitive performance on ordinal regression (OR; a.k.a. ordinal classification). To address this issue, this paper presents OrderChain, a novel and general prompting paradigm that improves the ordinal understanding ability of MLLMs by specificity and commonality modeling. Specifically, our OrderChain consists of a set of task-aware prompts to facilitate the specificity modeling of diverse OR tasks and a new range optimization Chain-of-Thought (RO-CoT), which learns a commonality way of thinking about OR tasks by uniformly decomposing them into multiple small-range optimization subtasks. Further, we propose a category recursive division (CRD) method to generate instruction candidate category prompts to support RO-CoT automatic optimization. Comprehensive experiments show that a Large Language and Vision Assistant (LLaVA) model with our OrderChain improves baseline LLaVA significantly on diverse OR datasets, e.g., from 47.5% to 93.2% accuracy on the Adience dataset for age estimation, and from 30.0% to 85.7% accuracy on the Diabetic Retinopathy dataset. Notably, LLaVA with our OrderChain also remarkably outperforms state-of-the-art methods by 27% on accuracy and 0.24 on MAE on the Adience dataset. To our best knowledge, our OrderChain is the first work that augments MLLMs for OR tasks, and the effectiveness is witnessed across a spectrum of OR datasets.
        ]]></description>
    </item>
    <item>
        <title>SAFT: Structure-aware Transformers for Textual Interaction Classification</title>
        <link>https://arxiv.org/abs/2504.04861</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.04861v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hongtao Wang, Renchi Yang, Hewen Wang, Haoran Zheng, Jianliang Xu</dc:creator>
        <description><![CDATA[
            背景：文本交互网络常用于建模用户与物品的交互，但现有文本交互分类（TIC）方案存在无法捕捉文本语义、忽视网络结构和节点异质性等问题。方法：提出SAFT架构，集成基于语言和图的模块，利用线图注意力、门控注意力单元和预训练语言模型分别建模交互级和词元级信号，通过代理词元迭代融合；还开发编码方法将拓扑信息融入结构嵌入。效果：在多个真实数据集上，SAFT的TIC准确率优于现有基线模型。
            arXiv:2504.04861v1 Announce Type: new 
Abstract: Textual interaction networks (TINs) are an omnipresent data structure used to model the interplay between users and items on e-commerce websites, social networks, etc., where each interaction is associated with a text description. Classifying such textual interactions (TIC) finds extensive use in detecting spam reviews in e-commerce, fraudulent transactions in finance, and so on. Existing TIC solutions either (i) fail to capture the rich text semantics due to the use of context-free text embeddings, and/or (ii) disregard the bipartite structure and node heterogeneity of TINs, leading to compromised TIC performance. In this work, we propose SAFT, a new architecture that integrates language- and graph-based modules for the effective fusion of textual and structural semantics in the representation learning of interactions. In particular, line graph attention (LGA)/gated attention units (GAUs) and pretrained language models (PLMs) are capitalized on to model the interaction-level and token-level signals, which are further coupled via the proxy token in an iterative and contextualized fashion. Additionally, an efficient and theoretically-grounded approach is developed to encode the local and global topology information pertaining to interactions into structural embeddings. The resulting embeddings not only inject the structural features underlying TINs into the textual interaction encoding but also facilitate the design of graph sampling strategies. Extensive empirical evaluations on multiple real TIN datasets demonstrate the superiority of SAFT over the state-of-the-art baselines in TIC accuracy.
        ]]></description>
    </item>
    <item>
        <title>SoK: LLM-based Log Parsing</title>
        <link>https://arxiv.org/abs/2504.04877</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.04877v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Viktor Beck, Max Landauer, Markus Wurzenberger, Florian Skopik, Andreas Rauber</dc:creator>
        <description><![CDATA[
            背景：日志数据需自动化解析成结构化表示，传统方法依赖手动配置，限制了可扩展性和可用性。方法：该文系统回顾29种基于大语言模型的日志解析方法，分析学习和提示工程范式、提效技术及大模型在解析中的作用，汇总调查结果，推导通用解析流程，还在公共数据集上对7种开源解析器进行基准测试。效果：总结了新研究领域的进展，为从业者提供见解，代码和结果公开。 
            arXiv:2504.04877v1 Announce Type: new 
Abstract: Log data, generated by software systems, provides crucial insights for tasks like monitoring, root cause analysis, and anomaly detection. Due to the vast volume of logs, automated log parsing is essential to transform semi-structured log messages into structured representations. Traditional log parsing techniques often require manual configurations, such as defining log formats or labeling data, which limits scalability and usability. Recent advances in large language models (LLMs) have introduced the new research field of LLM-based log parsing, offering potential improvements in automation and adaptability. Despite promising results, there is no structured overview of these approaches since this is a relatively new research field with the earliest advances published in late 2023. This paper systematically reviews 29 LLM-based log parsing methods, comparing their capabilities, limitations, and reliance on manual effort. We analyze the learning and prompt-engineering paradigms employed, efficiency- and effectiveness-enhancing techniques, and the role of LLMs in the parsing process. We aggregate the results of the survey in a large table comprising the characterizing features of LLM-based log parsing approaches and derive the general process of LLM-based log parsing, incorporating all reviewed approaches in a single flow chart. Additionally, we benchmark seven open-source LLM-based log parsers on public datasets and critically assess their reproducibility. Our findings summarize the advances of this new research field and provide insights for researchers and practitioners seeking efficient and user-friendly log parsing solutions, with all code and results made publicly available for transparency.
        ]]></description>
    </item>
    <item>
        <title>Collab-RAG: Boosting Retrieval-Augmented Generation for Complex Question Answering via White-Box and Black-Box LLM Collaboration</title>
        <link>https://arxiv.org/abs/2504.04915</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.04915v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ran Xu, Wenqi Shi, Yuchen Zhuang, Yue Yu, Joyce C. Ho, Haoyu Wang, Carl Yang</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）系统在处理多跳问答任务时，因无关上下文检索和复杂推理能力有限而表现不佳。方法：提出Collab - RAG协作训练框架，利用白盒小语言模型（SLM）和黑盒大语言模型（LLM）相互增强，SLM将复杂查询分解为子问题，LLM提供反馈提升SLM分解能力。效果：在五个多跳问答数据集上，平均比现有基线高出1.8% - 14.2%，微调后的3B SLM在问题分解上超32B冻结LLM。
            arXiv:2504.04915v1 Announce Type: new 
Abstract: Retrieval-Augmented Generation (RAG) systems often struggle to handle multi-hop question-answering tasks accurately due to irrelevant context retrieval and limited complex reasoning capabilities. We introduce Collab-RAG, a collaborative training framework that leverages mutual enhancement between a white-box small language model (SLM) and a blackbox large language model (LLM) for RAG. Specifically, the SLM decomposes complex queries into simpler sub-questions, thus enhancing the accuracy of the retrieval and facilitating more effective reasoning by the black-box LLM. Concurrently, the black-box LLM provides feedback signals to improve the SLM's decomposition capability. We observe that Collab-RAG relies solely on supervision from an affordable black-box LLM without additional distillation from frontier LLMs, yet demonstrates strong generalization across multiple black-box LLMs. Experimental evaluations across five multi-hop QA datasets demonstrate that Collab-RAG substantially outperforms existing black-box-only and SLM fine-tuning baselines by 1.8%-14.2% on average. In particular, our fine-tuned 3B SLM surpasses a frozen 32B LLM in question decomposition, highlighting the efficiency of Collab-RAG in improving reasoning and retrieval for complex questions. The code of Collab-RAG is available on https://github.com/ritaranx/Collab-RAG/.
        ]]></description>
    </item>
    <item>
        <title>AsyReC: A Multimodal Graph-based Framework for Spatio-Temporal Asymmetric Dyadic Relationship Classification</title>
        <link>https://arxiv.org/abs/2504.05030</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.05030v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wang Tang, Fethiye Irmak Dogan, Linbo Qing, Hatice Gunes</dc:creator>
        <description><![CDATA[
            背景：当前计算方法在建模二元社会关系时面临无法建模不对称关系、离散帧采样破坏交互连续性、未考虑周期性行为线索等挑战。方法：提出基于多模态图的AsyReC框架，包含带节点 - 边双注意力的三元图神经网络、保留时间连续性的片段级关系学习架构、将时间索引投影到正弦/余弦波形的周期性时间编码器。效果：在两个公开数据集上实验达最优性能，消融实验验证了不对称交互建模和周期性时间编码对提升鲁棒性的关键作用。
            arXiv:2504.05030v1 Announce Type: new 
Abstract: Dyadic social relationships, which refer to relationships between two individuals who know each other through repeated interactions (or not), are shaped by shared spatial and temporal experiences. Current computational methods for modeling these relationships face three major challenges: (1) the failure to model asymmetric relationships, e.g., one individual may perceive the other as a friend while the other perceives them as an acquaintance, (2) the disruption of continuous interactions by discrete frame sampling, which segments the temporal continuity of interaction in real-world scenarios, and (3) the limitation to consider periodic behavioral cues, such as rhythmic vocalizations or recurrent gestures, which are crucial for inferring the evolution of dyadic relationships. To address these challenges, we propose AsyReC, a multimodal graph-based framework for asymmetric dyadic relationship classification, with three core innovations: (i) a triplet graph neural network with node-edge dual attention that dynamically weights multimodal cues to capture interaction asymmetries (addressing challenge 1); (ii) a clip-level relationship learning architecture that preserves temporal continuity, enabling fine-grained modeling of real-world interaction dynamics (addressing challenge 2); and (iii) a periodic temporal encoder that projects time indices onto sine/cosine waveforms to model recurrent behavioral patterns (addressing challenge 3). Extensive experiments on two public datasets demonstrate state-of-the-art performance, while ablation studies validate the critical role of asymmetric interaction modeling and periodic temporal encoding in improving the robustness of dyadic relationship classification in real-world scenarios. Our code is publicly available at: https://github.com/tw-repository/AsyReC.
        ]]></description>
    </item>
    <item>
        <title>The Curse of CoT: On the Limitations of Chain-of-Thought in In-Context Learning</title>
        <link>https://arxiv.org/abs/2504.05081</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.05081v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tianshi Zheng, Yixiang Chen, Chengxi Li, Chunyang Li, Qing Zong, Haochen Shi, Baixuan Xu, Yangqiu Song, Ginny Y. Wong, Simon See</dc:creator>
        <description><![CDATA[
            背景：思维链（CoT）提示被认为能提升大语言模型推理能力。方法：对16个先进大语言模型和9个不同的上下文学习数据集开展实验，系统探究现象并验证假设解释。效果：实验表明，在不同模型规模和基准复杂度下，CoT及其推理变体表现始终不如直接回答；分析揭示了基于模式的上下文学习中驱动CoT性能的显式 - 隐式二元性，解释了其相对表现不佳的原因，为大语言模型推理方法研究提供新见解。
            arXiv:2504.05081v1 Announce Type: new 
Abstract: Chain-of-Thought (CoT) prompting has been widely recognized for its ability to enhance reasoning capabilities in large language models (LLMs) through the generation of explicit explanatory rationales. However, our study reveals a surprising contradiction to this prevailing perspective. Through extensive experiments involving 16 state-of-the-art LLMs and nine diverse pattern-based in-context learning (ICL) datasets, we demonstrate that CoT and its reasoning variants consistently underperform direct answering across varying model scales and benchmark complexities. To systematically investigate this unexpected phenomenon, we designed extensive experiments to validate several hypothetical explanations. Our analysis uncovers a fundamental explicit-implicit duality driving CoT's performance in pattern-based ICL: while explicit reasoning falters due to LLMs' struggles to infer underlying patterns from demonstrations, implicit reasoning-disrupted by the increased contextual distance of CoT rationales-often compensates, delivering correct answers despite flawed rationales. This duality explains CoT's relative underperformance, as noise from weak explicit inference undermines the process, even as implicit mechanisms partially salvage outcomes. Notably, even long-CoT reasoning models, which excel in abstract and symbolic reasoning, fail to fully overcome these limitations despite higher computational costs. Our findings challenge existing assumptions regarding the universal efficacy of CoT, yielding novel insights into its limitations and guiding future research toward more nuanced and effective reasoning methodologies for LLMs.
        ]]></description>
    </item>
    <item>
        <title>BRIDGES: Bridging Graph Modality and Large Language Models within EDA Tasks</title>
        <link>https://arxiv.org/abs/2504.05180</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.05180v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wei Li, Yang Zou, Christopher Ellis, Ruben Purdy, Shawn Blanton, Jos\'e M. F. Moura</dc:creator>
        <description><![CDATA[
            背景：现有电子设计自动化（EDA）领域的大语言模型（LLM）处理图数据存在将图表示为文本致性能下降、忽视有益图结构数据等问题。方法：提出BRIDGES框架，建立LLM驱动工作流生成大规模数据集，含超50万个图实例和超15亿个标记；提出轻量级跨模态投影器，将图表示编码为文本兼容提示。效果：相比仅用文本的基线，在多项任务上有2 - 10倍提升，计算开销小，未微调LLM时也远超仅用文本的结果。
            arXiv:2504.05180v1 Announce Type: new 
Abstract: While many EDA tasks already involve graph-based data, existing LLMs in EDA primarily either represent graphs as sequential text, or simply ignore graph-structured data that might be beneficial like dataflow graphs of RTL code. Recent studies have found that LLM performance suffers when graphs are represented as sequential text, and using additional graph information significantly boosts performance. To address these challenges, we introduce BRIDGES, a framework designed to incorporate graph modality into LLMs for EDA tasks. BRIDGES integrates an automated data generation workflow, a solution that combines graph modality with LLM, and a comprehensive evaluation suite. First, we establish an LLM-driven workflow to generate RTL and netlist-level data, converting them into dataflow and netlist graphs with function descriptions. This workflow yields a large-scale dataset comprising over 500,000 graph instances and more than 1.5 billion tokens. Second, we propose a lightweight cross-modal projector that encodes graph representations into text-compatible prompts, enabling LLMs to effectively utilize graph data without architectural modifications. Experimental results demonstrate 2x to 10x improvements across multiple tasks compared to text-only baselines, including accuracy in design retrieval, type prediction and perplexity in function description, with negligible computational overhead (<1% model weights increase and <30% additional runtime overhead). Even without additional LLM finetuning, our results outperform text-only by a large margin. We plan to release BRIDGES, including the dataset, models, and training flow.
        ]]></description>
    </item>
    <item>
        <title>Learning to Reason Over Time: Timeline Self-Reflection for Improved Temporal Reasoning in Language Models</title>
        <link>https://arxiv.org/abs/2504.05258</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.05258v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Adri\'an Bazaga, Rexhina Blloshmi, Bill Byrne, Adri\`a de Gispert</dc:creator>
        <description><![CDATA[
            背景：大语言模型在时间推理任务上表现不佳，而该能力对问答、调度等应用至关重要。方法：提出TISER框架，通过结合时间线构建与迭代自我反思的多阶段过程增强大语言模型的时间推理能力，利用测试时缩放来延长推理轨迹长度。效果：在多个基准测试（包括分布外测试集）中达到了最先进水平，能让较小的开源模型在具有挑战性的时间推理任务上超越更大的闭源权重模型。
            arXiv:2504.05258v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have emerged as powerful tools for generating coherent text, understanding context, and performing reasoning tasks. However, they struggle with temporal reasoning, which requires processing time-related information such as event sequencing, durations, and inter-temporal relationships. These capabilities are critical for applications including question answering, scheduling, and historical analysis. In this paper, we introduce TISER, a novel framework that enhances the temporal reasoning abilities of LLMs through a multi-stage process that combines timeline construction with iterative self-reflection. Our approach leverages test-time scaling to extend the length of reasoning traces, enabling models to capture complex temporal dependencies more effectively. This strategy not only boosts reasoning accuracy but also improves the traceability of the inference process. Experimental results demonstrate state-of-the-art performance across multiple benchmarks, including out-of-distribution test sets, and reveal that TISER enables smaller open-source models to surpass larger closed-weight models on challenging temporal reasoning tasks.
        ]]></description>
    </item>
    <item>
        <title>Truthful or Fabricated? Using Causal Attribution to Mitigate Reward Hacking in Explanations</title>
        <link>https://arxiv.org/abs/2504.05294</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.05294v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Pedro Ferreira, Wilker Aziz, Ivan Titov</dc:creator>
        <description><![CDATA[
            背景：思维链解释常用于检查大语言模型决策过程及评估输出可信度，但偏好优化可能降低解释的忠实性。方法：因奖励模型缺乏评估内部决策与解释一致性的机制，LLM可能进行“奖励欺骗”，为此提出用预测的因果归因丰富奖励模型输入，使其能检测解释与决策过程的差异。效果：在受控环境下，该方法减少了LLM生成误导性解释的倾向。
            arXiv:2504.05294v1 Announce Type: new 
Abstract: Chain-of-thought explanations are widely used to inspect the decision process of large language models (LLMs) and to evaluate the trustworthiness of model outputs, making them important for effective collaboration between LLMs and humans. We demonstrate that preference optimization - a key step in the alignment phase - can inadvertently reduce the faithfulness of these explanations. This occurs because the reward model (RM), which guides alignment, is tasked with optimizing both the expected quality of the response and the appropriateness of the explanations (e.g., minimizing bias or adhering to safety standards), creating potential conflicts. The RM lacks a mechanism to assess the consistency between the model's internal decision process and the generated explanation. Consequently, the LLM may engage in "reward hacking" by producing a final response that scores highly while giving an explanation tailored to maximize reward rather than accurately reflecting its reasoning. To address this issue, we propose enriching the RM's input with a causal attribution of the prediction, allowing the RM to detect discrepancies between the generated self-explanation and the model's decision process. In controlled settings, we show that this approach reduces the tendency of the LLM to generate misleading explanations.
        ]]></description>
    </item>
    <item>
        <title>TransNet: Transfer Knowledge for Few-shot Knowledge Graph Completion</title>
        <link>https://arxiv.org/abs/2504.03720</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.03720v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Lihui Liu, Zihao Wang, Dawei Zhou, Ruijie Wang, Yuchen Yan, Bo Xiong, Sihong He, Kai Shu, Hanghang Tong</dc:creator>
        <description><![CDATA[
            背景：现实中知识图谱多不完整，且关系呈长尾分布，少样本学习用于解决此问题，但现有方法忽略任务间相关性。方法：提出基于迁移学习的少样本知识图谱补全方法TransNet，学习不同任务间关系，将相似任务知识迁移以提升当前任务表现，还采用元学习提升对新关系的泛化能力。效果：在基准数据集上实验表明，TransNet优于现有方法。代码见https://github.com/lihuiliullh/TransNet/tree/main 。
            arXiv:2504.03720v1 Announce Type: cross 
Abstract: Knowledge graphs (KGs) are ubiquitous and widely used in various applications. However, most real-world knowledge graphs are incomplete, which significantly degrades their performance on downstream tasks. Additionally, the relationships in real-world knowledge graphs often follow a long-tail distribution, meaning that most relations are represented by only a few training triplets. To address these challenges, few-shot learning has been introduced. Few-shot KG completion aims to make accurate predictions for triplets involving novel relations when only a limited number of training triplets are available. Although many methods have been proposed, they typically learn each relation individually, overlooking the correlations between different tasks and the relevant information in previously trained tasks. In this paper, we propose a transfer learning-based few-shot KG completion method (TransNet). By learning the relationships between different tasks, TransNet effectively transfers knowledge from similar tasks to improve the current task's performance. Furthermore, by employing meta-learning, TransNet can generalize effectively to new, unseen relations. Extensive experiments on benchmark datasets demonstrate the superiority of TransNet over state-of-the-art methods. Code can be found at https://github.com/lihuiliullh/TransNet/tree/main
        ]]></description>
    </item>
    <item>
        <title>Misaligned Roles, Misplaced Images: Structural Input Perturbations Expose Multimodal Alignment Blind Spots</title>
        <link>https://arxiv.org/abs/2504.03735</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.03735v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Erfan Shayegani, G M Shahariar, Sara Abdali, Lei Yu, Nael Abu-Ghazaleh, Yue Dong</dc:creator>
        <description><![CDATA[
            背景：多模态语言模型后训练对齐主要关注助手角色，用户角色未对齐，且固定输入提示结构使模型面对输入偏差时脆弱。方法：提出角色 - 模态攻击（RMA），利用用户和助手角色混淆及改变图像标记位置引发有害输出，还提出对抗训练方法增强模型鲁棒性。效果：在多种视觉语言模型的八个设置中评估，RMA可组合成更强对抗提示；对抗训练有效降低攻击成功率，同时保留模型通用效用。
            arXiv:2504.03735v1 Announce Type: cross 
Abstract: Multimodal Language Models (MMLMs) typically undergo post-training alignment to prevent harmful content generation. However, these alignment stages focus primarily on the assistant role, leaving the user role unaligned, and stick to a fixed input prompt structure of special tokens, leaving the model vulnerable when inputs deviate from these expectations. We introduce Role-Modality Attacks (RMA), a novel class of adversarial attacks that exploit role confusion between the user and assistant and alter the position of the image token to elicit harmful outputs. Unlike existing attacks that modify query content, RMAs manipulate the input structure without altering the query itself. We systematically evaluate these attacks across multiple Vision Language Models (VLMs) on eight distinct settings, showing that they can be composed to create stronger adversarial prompts, as also evidenced by their increased projection in the negative refusal direction in the residual stream, a property observed in prior successful attacks. Finally, for mitigation, we propose an adversarial training approach that makes the model robust against input prompt perturbations. By training the model on a range of harmful and benign prompts all perturbed with different RMA settings, it loses its sensitivity to Role Confusion and Modality Manipulation attacks and is trained to only pay attention to the content of the query in the input prompt structure, effectively reducing Attack Success Rate (ASR) while preserving the model's general utility.
        ]]></description>
    </item>
    <item>
        <title>Have Large Language Models Learned to Reason? A Characterization via 3-SAT Phase Transition</title>
        <link>https://arxiv.org/abs/2504.03930</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.03930v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Rishi Hazra, Gabriele Venturato, Pedro Zuidberg Dos Martires, Luc De Raedt</dc:creator>
        <description><![CDATA[
            背景：大语言模型虽被认为有高级推理能力，但有研究指出其可能只是拟合统计特征。方法：从计算理论视角出发，以3 - SAT这一典型NP完全问题为核心设计实验，通过改变问题实例的固有难度，考察随机3 - SAT的相变，刻画大语言模型推理能力。效果：对比发现，当前模型在难题上准确率显著下降；DeepSeek R1与其他模型不同，显示出学习到潜在推理的迹象，研究为后续指明方向。
            arXiv:2504.03930v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) have been touted as AI models possessing advanced reasoning abilities. In theory, autoregressive LLMs with Chain-of-Thought (CoT) can perform more serial computations to solve complex reasoning tasks. However, recent studies suggest that, despite this capacity, LLMs do not truly learn to reason but instead fit on statistical features. To study the reasoning capabilities in a principled fashion, we adopt a computational theory perspective and propose an experimental protocol centered on 3-SAT -- the prototypical NP-complete problem lying at the core of logical reasoning and constraint satisfaction tasks. Specifically, we examine the phase transitions in random 3-SAT and characterize the reasoning abilities of state-of-the-art LLMs by varying the inherent hardness of the problem instances. By comparing DeepSeek R1 with other LLMs, our findings reveal two key insights (1) LLM accuracy drops significantly on harder instances, suggesting all current models struggle when statistical shortcuts are unavailable (2) Unlike other LLMs, R1 shows signs of having learned the underlying reasoning. Following a principled experimental protocol, our study moves beyond the benchmark-driven evidence often found in LLM reasoning research. Our findings highlight important gaps and suggest clear directions for future research.
        ]]></description>
    </item>
    <item>
        <title>Lifting Factor Graphs with Some Unknown Factors for New Individuals</title>
        <link>https://arxiv.org/abs/2504.04089</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.04089v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Malte Luttermann, Ralf M\"oller, Marcel Gehrke</dc:creator>
        <description><![CDATA[
            背景：在概率图模型中利用提升技术能高效进行查询回答，但含未知因子的因子图概率推理研究较少。方法：提出LIFAGU算法，识别含未知因子的因子图中不可区分的子图，将已知势转移到未知势；还扩展该算法以融入因子组背景知识。效果：融入背景知识后，LIFAGU能进一步降低已知势向未知势转移的模糊性，保证模型语义明确并实现（提升）概率推理。 
            arXiv:2504.04089v1 Announce Type: cross 
Abstract: Lifting exploits symmetries in probabilistic graphical models by using a representative for indistinguishable objects, allowing to carry out query answering more efficiently while maintaining exact answers. In this paper, we investigate how lifting enables us to perform probabilistic inference for factor graphs containing unknown factors, i.e., factors whose underlying function of potential mappings is unknown. We present the Lifting Factor Graphs with Some Unknown Factors (LIFAGU) algorithm to identify indistinguishable subgraphs in a factor graph containing unknown factors, thereby enabling the transfer of known potentials to unknown potentials to ensure a well-defined semantics of the model and allow for (lifted) probabilistic inference. We further extend LIFAGU to incorporate additional background knowledge about groups of factors belonging to the same individual object. By incorporating such background knowledge, LIFAGU is able to further reduce the ambiguity of possible transfers of known potentials to unknown potentials.
        ]]></description>
    </item>
    <item>
        <title>Crowdsourcing-Based Knowledge Graph Construction for Drug Side Effects Using Large Language Models with an Application on Semaglutide</title>
        <link>https://arxiv.org/abs/2504.04346</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.04346v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhijie Duan, Kai Wei, Zhaoqian Xue, Lingyao li, Jin Jin, Shu Yang, Jiayan Zhou, Siyuan Ma</dc:creator>
        <description><![CDATA[
            背景：从非结构化且嘈杂的社交媒体内容中挖掘药物副作用数据是一项挑战。方法：提出利用大语言模型（LLMs）从社交媒体提取药物副作用信息并构建知识图谱（KG）的系统框架，以Reddit上的司美格鲁肽减肥数据为例应用该框架，还基于构建的KG进行综合分析。效果：通过与FAERS数据库中的不良事件报告对比验证了结果，证明了用LLMs将社交媒体数据转化为结构化KG用于药物警戒的可行性。
            arXiv:2504.04346v1 Announce Type: cross 
Abstract: Social media is a rich source of real-world data that captures valuable patient experience information for pharmacovigilance. However, mining data from unstructured and noisy social media content remains a challenging task. We present a systematic framework that leverages large language models (LLMs) to extract medication side effects from social media and organize them into a knowledge graph (KG). We apply this framework to semaglutide for weight loss using data from Reddit. Using the constructed knowledge graph, we perform comprehensive analyses to investigate reported side effects across different semaglutide brands over time. These findings are further validated through comparison with adverse events reported in the FAERS database, providing important patient-centered insights into semaglutide's side effects that complement its safety profile and current knowledge base of semaglutide for both healthcare professionals and patients. Our work demonstrates the feasibility of using LLMs to transform social media data into structured KGs for pharmacovigilance.
        ]]></description>
    </item>
    <item>
        <title>Retro-Search: Exploring Untaken Paths for Deeper and Efficient Reasoning</title>
        <link>https://arxiv.org/abs/2504.04383</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.04383v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ximing Lu, Seungju Han, David Acuna, Hyunwoo Kim, Jaehun Jung, Shrimai Prabhumoye, Niklas Muennighoff, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro, Yejin Choi</dc:creator>
        <description><![CDATA[
            背景：大推理模型虽能通过长推理轨迹展现推理能力，但监督微调时轨迹常欠佳，导致思考不足等问题。方法：提出受MCTS启发的Retro - Search算法，回顾性修正推理路径，以提炼高质量推理路径。效果：有两种应用场景，自提升时，R1 - distill - 7B推理长度平均减少31.2%，七个数学基准测试性能提升7.7%；弱到强提升时，Qwen2.5 - 32B推理长度减少11.3%，性能较原数据微调提升2.4%。
            arXiv:2504.04383v1 Announce Type: cross 
Abstract: Large reasoning models exhibit remarkable reasoning capabilities via long, elaborate reasoning trajectories. Supervised fine-tuning on such reasoning traces, also known as distillation, can be a cost-effective way to boost reasoning capabilities of student models. However, empirical observations reveal that these reasoning trajectories are often suboptimal, switching excessively between different lines of thought, resulting in under-thinking, over-thinking, and even degenerate responses. We introduce Retro-Search, an MCTS-inspired search algorithm, for distilling higher quality reasoning paths from large reasoning models. Retro-Search retrospectively revises reasoning paths to discover better, yet shorter traces, which can then lead to student models with enhanced reasoning capabilities with shorter, thus faster inference. Our approach can enable two use cases: self-improvement, where models are fine-tuned on their own Retro-Search-ed thought traces, and weak-to-strong improvement, where a weaker model revises stronger model's thought traces via Retro-Search. For self-improving, R1-distill-7B, fine-tuned on its own Retro-Search-ed traces, reduces the average reasoning length by 31.2% while improving performance by 7.7% across seven math benchmarks. For weak-to-strong improvement, we retrospectively revise R1-671B's traces from the OpenThoughts dataset using R1-distill-32B as the Retro-Search-er, a model 20x smaller. Qwen2.5-32B, fine-tuned on this refined data, achieves performance comparable to R1-distill-32B, yielding an 11.3% reduction in reasoning length and a 2.4% performance improvement compared to fine-tuning on the original OpenThoughts data. Our work counters recently emergent viewpoints that question the relevance of search algorithms in the era of large reasoning models, by demonstrating that there are still opportunities for algorithmic advancements, even for frontier models.
        ]]></description>
    </item>
    <item>
        <title>Hierarchical Planning for Complex Tasks with Knowledge Graph-RAG and Symbolic Verification</title>
        <link>https://arxiv.org/abs/2504.04578</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.04578v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Cristina Cornelio, Flavio Petruzzellis, Pietro Lio</dc:creator>
        <description><![CDATA[
            背景：大语言模型作为机器人规划器处理长周期和复杂任务时存在困难，现有分层规划和检索增强生成方法单独使用仍不足。方法：提出神经符号方法，用基于知识图谱的RAG增强基于大语言模型的规划器以生成分层计划，将复杂任务分解为子任务并扩展为原子动作序列，还集成符号验证器确保正确性和检测失败。效果：与基线方法对比，在不同复杂度任务和不同大语言模型中均显示出显著优势，实验设置和指标可评估大模型推理和组合能力。
            arXiv:2504.04578v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) have shown promise as robotic planners but often struggle with long-horizon and complex tasks, especially in specialized environments requiring external knowledge. While hierarchical planning and Retrieval-Augmented Generation (RAG) address some of these challenges, they remain insufficient on their own and a deeper integration is required for achieving more reliable systems. To this end, we propose a neuro-symbolic approach that enhances LLMs-based planners with Knowledge Graph-based RAG for hierarchical plan generation. This method decomposes complex tasks into manageable subtasks, further expanded into executable atomic action sequences. To ensure formal correctness and proper decomposition, we integrate a Symbolic Validator, which also functions as a failure detector by aligning expected and observed world states. Our evaluation against baseline methods demonstrates the consistent significant advantages of integrating hierarchical planning, symbolic verification, and RAG across tasks of varying complexity and different LLMs. Additionally, our experimental setup and novel metrics not only validate our approach for complex planning but also serve as a tool for assessing LLMs' reasoning and compositional capabilities.
        ]]></description>
    </item>
    <item>
        <title>R2Vul: Learning to Reason about Software Vulnerabilities with Reinforcement Learning and Structured Reasoning Distillation</title>
        <link>https://arxiv.org/abs/2504.04699</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.04699v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Martin Weyssow, Chengran Yang, Junkai Chen, Yikun Li, Huihui Huang, Ratnadira Widyasari, Han Wei Ang, Frank Liauw, Eng Lieh Ouh, Lwin Khin Shar, David Lo</dc:creator>
        <description><![CDATA[
            背景：大语言模型在软件漏洞检测中表现良好，但推理能力不可靠，现有基于思维链的方法难提供有效安全评估。方法：提出R2Vul，利用基于AI反馈的强化学习（RLAIF）将结构化推理提炼到小型大语言模型中，使其能生成可靠的结构化推理，并区分有效和误导性评估。效果：在五种语言上评估，含结构化推理提炼的R2Vul让15亿参数的小模型媲美大模型，提升对分布外漏洞的泛化能力，还贡献了多语言偏好数据集。
            arXiv:2504.04699v1 Announce Type: cross 
Abstract: Large language models (LLMs) have shown promising performance in software vulnerability detection (SVD), yet their reasoning capabilities remain unreliable. Existing approaches relying on chain-of-thought (CoT) struggle to provide relevant and actionable security assessments. Additionally, effective SVD requires not only generating coherent reasoning but also differentiating between well-founded and misleading yet plausible security assessments, an aspect overlooked in prior work. To this end, we introduce R2Vul, a novel approach that distills structured reasoning into small LLMs using reinforcement learning from AI feedback (RLAIF). Through RLAIF, R2Vul enables LLMs to produce structured, security-aware reasoning that is actionable and reliable while explicitly learning to distinguish valid assessments from misleading ones. We evaluate R2Vul across five languages against SAST tools, CoT, instruction tuning, and classification-based baselines. Our results show that R2Vul with structured reasoning distillation enables a 1.5B student LLM to rival larger models while improving generalization to out-of-distribution vulnerabilities. Beyond model improvements, we contribute a large-scale, multilingual preference dataset featuring structured reasoning to support future research in SVD.
        ]]></description>
    </item>
    <item>
        <title>Boosting Relational Deep Learning with Pretrained Tabular Models</title>
        <link>https://arxiv.org/abs/2504.04934</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.04934v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Veronica Lachi, Antonio Longa, Beatrice Bevilacqua, Bruno Lepri, Andrea Passerini, Bruno Ribeiro</dc:creator>
        <description><![CDATA[
            背景：关系数据库以表形式组织数据，但用表连接和特征工程将其转换为扁平格式用于预测时，设计能捕捉复杂关系模式的特征较难；图神经网络虽能建模关系，但推理时间长。方法：利用现有特征工程提升图神经网络在关系数据库中的效率，用图神经网络捕捉难特征化的复杂关系，用工程特征编码时间信息。效果：所提LightRDL方法不仅提高效率，还优于现有模型，在RelBench基准测试中，与图神经网络相比，性能提升达33%，推理速度提升526倍，适合实时推理。
            arXiv:2504.04934v1 Announce Type: cross 
Abstract: Relational databases, organized into tables connected by primary-foreign key relationships, are a common format for organizing data. Making predictions on relational data often involves transforming them into a flat tabular format through table joins and feature engineering, which serve as input to tabular methods. However, designing features that fully capture complex relational patterns remains challenging. Graph Neural Networks (GNNs) offer a compelling alternative by inherently modeling these relationships, but their time overhead during inference limits their applicability for real-time scenarios. In this work, we aim to bridge this gap by leveraging existing feature engineering efforts to enhance the efficiency of GNNs in relational databases. Specifically, we use GNNs to capture complex relationships within relational databases, patterns that are difficult to featurize, while employing engineered features to encode temporal information, thereby avoiding the need to retain the entire historical graph and enabling the use of smaller, more efficient graphs. Our \textsc{LightRDL} approach not only improves efficiency, but also outperforms existing models. Experimental results on the RelBench benchmark demonstrate that our framework achieves up to $33\%$ performance improvement and a $526\times$ inference speedup compared to GNNs, making it highly suitable for real-time inference.
        ]]></description>
    </item>
    <item>
        <title>Leveraging LLMs for Utility-Focused Annotation: Reducing Manual Effort for Retrieval and RAG</title>
        <link>https://arxiv.org/abs/2504.05220</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.05220v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hengran Zhang, Minghao Tang, Keping Bi, Jiafeng Guo, Shihao Liu, Daiting Shi, Dawei Yin, Xueqi Cheng</dc:creator>
        <description><![CDATA[
            背景：检索模型训练和评估依赖人工标注，成本高，且检索强调相关性与RAG注重文档价值存在差异。方法：探索用大语言模型（LLMs）生成的标注替代人工标注，针对跨领域和领域内检索及RAG任务开展基于LLMs的实用标注研究，并设计Disj - InfoNCE损失函数减少低质量正样本影响。效果：领域外，实用标注训练的检索器表现远超人工标注；领域内，结合20%人工标注数据，实用标注训练的检索器可与全人工标注模型性能相当。
            arXiv:2504.05220v1 Announce Type: cross 
Abstract: Retrieval models typically rely on costly human-labeled query-document relevance annotations for training and evaluation. To reduce this cost and leverage the potential of Large Language Models (LLMs) in relevance judgments, we aim to explore whether LLM-generated annotations can effectively replace human annotations in training retrieval models. Retrieval usually emphasizes relevance, which indicates "topic-relatedness" of a document to a query, while in RAG, the value of a document (or utility) depends on how it contributes to answer generation. Recognizing this mismatch, some researchers use LLM performance on downstream tasks with documents as labels, but this approach requires manual answers for specific tasks, leading to high costs and limited generalization. In another line of work, prompting LLMs to select useful documents as RAG references eliminates the need for human annotation and is not task-specific. If we leverage LLMs' utility judgments to annotate retrieval data, we may retain cross-task generalization without human annotation in large-scale corpora. Therefore, we investigate utility-focused annotation via LLMs for large-scale retriever training data across both in-domain and out-of-domain settings on the retrieval and RAG tasks. To reduce the impact of low-quality positives labeled by LLMs, we design a novel loss function, i.e., Disj-InfoNCE. Our experiments reveal that: (1) Retrievers trained on utility-focused annotations significantly outperform those trained on human annotations in the out-of-domain setting on both tasks, demonstrating superior generalization capabilities. (2) LLM annotation does not replace human annotation in the in-domain setting. However, incorporating just 20% human-annotated data enables retrievers trained with utility-focused annotations to match the performance of models trained entirely with human annotations.
        ]]></description>
    </item>
    <item>
        <title>KERMIT: Knowledge Graph Completion of Enhanced Relation Modeling with Inverse Transformation</title>
        <link>https://arxiv.org/abs/2309.14770</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2309.14770v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Haotian Li, Bin Yu, Yuliang Wei, Kai Wang, Richard Yi Da Xu, Bailing Wang</dc:creator>
        <description><![CDATA[
            背景：知识图谱补全（KGC）是利用已有信息填充图谱中缺失三元组，但基于文本的方法在描述信息不足时预测困难。方法：先用大语言模型生成连贯描述，弥合查询与答案间的语义差距；利用逆关系创建对称图，为KGC提供更多训练样本；用知识图谱的标签信息增强对比框架，使其成为全监督模型。效果：在WN18RR和FB15k - 237数据集上表现显著提升，在WN18RR的Hit@1提高4.2%，在FB15k - 237的Hit@3提高3.4%。
            arXiv:2309.14770v3 Announce Type: replace 
Abstract: Knowledge graph completion (KGC) revolves around populating missing triples in a knowledge graph using available information. Text-based methods, which depend on textual descriptions of triples, often encounter difficulties when these descriptions lack sufficient information for accurate prediction-an issue inherent to the datasets and not easily resolved through modeling alone. To address this and ensure data consistency, we first use large language models (LLMs) to generate coherent descriptions, bridging the semantic gap between queries and answers. Secondly, we utilize inverse relations to create a symmetric graph, thereby providing augmented training samples for KGC. Additionally, we employ the label information inherent in knowledge graphs (KGs) to enhance the existing contrastive framework, making it fully supervised. These efforts have led to significant performance improvements on the WN18RR and FB15k-237 datasets. According to standard evaluation metrics, our approach achieves a 4.2% improvement in Hit@1 on WN18RR and a 3.4% improvement in Hit@3 on FB15k-237, demonstrating superior performance.
        ]]></description>
    </item>
    <item>
        <title>Large Language Models are In-Context Molecule Learners</title>
        <link>https://arxiv.org/abs/2403.04197</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2403.04197v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiatong Li, Wei Liu, Zhihao Ding, Wenqi Fan, Yuqiang Li, Qing Li</dc:creator>
        <description><![CDATA[
            背景：大语言模型在生化任务中表现出色，但此前适配分子-文本翻译任务的方法存在需额外预训练、分子与文本空间对齐弱等问题。方法：提出上下文分子适配（ICMA）范式，包含混合上下文检索、检索后重排序和上下文分子调优三个阶段，利用BM25标题检索和分子图检索获取示例，通过序列反转和随机游走选择提升检索质量，用检索示例激发模型上下文学习和推理能力。效果：无需额外训练语料和复杂结构，使模型达最优或相近性能。
            arXiv:2403.04197v4 Announce Type: replace 
Abstract: Large Language Models (LLMs) have demonstrated exceptional performance in biochemical tasks, especially the molecule caption translation task, which aims to bridge the gap between molecules and natural language texts. However, previous methods in adapting LLMs to the molecule-caption translation task required extra domain-specific pre-training stages, suffered weak alignment between molecular and textual spaces, or imposed stringent demands on the scale of LLMs. To resolve the challenges, we propose In-Context Molecule Adaptation (ICMA), as a new paradigm allowing LLMs to learn the molecule-text alignment from context examples via In-Context Molecule Tuning. Specifically, ICMA incorporates the following three stages: Hybrid Context Retrieval, Post-retrieval Re-ranking, and In-context Molecule Tuning. Initially, Hybrid Context Retrieval utilizes BM25 Caption Retrieval and Molecule Graph Retrieval to retrieve similar informative context examples. Additionally, Post-retrieval Re-ranking is composed of Sequence Reversal and Random Walk selection to further improve the quality of retrieval results. Finally, In-Context Molecule Tuning unlocks the in-context learning and reasoning capability of LLMs with the retrieved examples and adapts the parameters of LLMs for better alignment between molecules and texts. Experimental results demonstrate that ICMA can empower LLMs to achieve state-of-the-art or comparable performance without extra training corpora and intricate structures, showing that LLMs are inherently in-context molecule learners.
        ]]></description>
    </item>
    <item>
        <title>TANQ: An open domain dataset of table answered questions</title>
        <link>https://arxiv.org/abs/2405.07765</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2405.07765v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mubashara Akhtar, Chenxi Pang, Andreea Marzoca, Yasemin Altun, Julian Martin Eisenschlos</dc:creator>
        <description><![CDATA[
            背景：语言模型结合工具使用成解答问题常用手段，现实中解答问题常需从多源获取信息并构建结构化成果。方法：本文推出首个开放域问答数据集TANQ，答案需跨多源信息构建表格，对结果表格中每个单元格给出完整来源归属，并在不同设置下对先进语言模型进行基准测试。效果：最佳基线模型Gemini Flash整体F1分数达60.7，落后人类表现12.3分，还分析了不同属性下基线模型表现及常见失败情况。 
            arXiv:2405.07765v3 Announce Type: replace 
Abstract: Language models, potentially augmented with tool usage such as retrieval are becoming the go-to means of answering questions. Understanding and answering questions in real-world settings often requires retrieving information from different sources, processing and aggregating data to extract insights, and presenting complex findings in form of structured artifacts such as novel tables, charts, or infographics. In this paper, we introduce TANQ, the first open domain question answering dataset where the answers require building tables from information across multiple sources. We release the full source attribution for every cell in the resulting table and benchmark state-of-the-art language models in open, oracle, and closed book setups. Our best-performing baseline, Gemini Flash reaches an overall F1 score of 60.7, lagging behind human performance by 12.3 points. We analyse baselines' performance across different dataset attributes such as different skills required for this task, including multi-hop reasoning, math operations, and unit conversions. We further discuss common failures in model-generated answers, suggesting that TANQ is a complex task with many challenges ahead.
        ]]></description>
    </item>
    <item>
        <title>Interpreting the structure of multi-object representations in vision encoders</title>
        <link>https://arxiv.org/abs/2406.09067</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2406.09067v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tarun Khajuria, Braian Olmiro Dias, Marharyta Domnich, Jaan Aru</dc:creator>
        <description><![CDATA[
            背景：结构化表征在人类推理和泛化中至关重要，可用于多目标场景建模。方法：定义结构化表征需满足绑定对象信息到离散单元、分离对象表征以减少纠缠两特性，评估对比分类预训练图像编码器、大视觉 - 语言模型和自监督方法，通过创建对象解码任务分析token表征。效果：发现对象表征因与预训练目标相关性不同有显著差异，有更结构化表征的网络和层保留个体对象信息更好，还提出量化指标辅助下游任务选择和调整编码器。
            arXiv:2406.09067v3 Announce Type: replace 
Abstract: In this work, we interpret the representations of multi-object scenes in vision encoders through the lens of structured representations. Structured representations allow modeling of individual objects distinctly and their flexible use based on the task context for both scene-level and object-specific tasks. These capabilities play a central role in human reasoning and generalization, allowing us to abstract away irrelevant details and focus on relevant information in a compact and usable form. We define structured representations as those that adhere to two specific properties: binding specific object information into discrete representation units and segregating object representations into separate sets of tokens to minimize cross-object entanglement. Based on these properties, we evaluated and compared image encoders pre-trained on classification (ViT), large vision-language models (CLIP, BLIP, FLAVA), and self-supervised methods (DINO, DINOv2). We examine the token representations by creating object-decoding tasks that measure the ability of specific tokens to capture individual objects in multi-object scenes from the COCO dataset. This analysis provides insights into how object-wise representations are distributed across tokens and layers within these vision encoders. Our findings highlight significant differences in the representation of objects depending on their relevance to the pre-training objective, with this effect particularly pronounced in the CLS token (often used for downstream tasks). Meanwhile, networks and layers that exhibit more structured representations retain better information about individual objects. To guide practical applications, we propose formal measures to quantify the two properties of structured representations, aiding in selecting and adapting vision encoders for downstream tasks.
        ]]></description>
    </item>
    <item>
        <title>Semantic Parsing with Candidate Expressions for Knowledge Base Question Answering</title>
        <link>https://arxiv.org/abs/2410.00414</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.00414v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Daehwan Nam, Gary Geunbae Lee</dc:creator>
        <description><![CDATA[
            背景：现有语义解析器在处理知识库问答时，使用的语法难以利用知识库大量信息。方法：提出用候选表达式增强的语法，结合序列到序列预训练语言模型进行语义解析，定义动作作为产生式规则，预测推理时的动作；引入子类型推理、联合类型和掩码缓存算法。效果：在KQA Pro和Overnight两个基准测试中，候选表达式约束提高了解析器准确率，子类型推理和掩码缓存算法提升了解码速度。
            arXiv:2410.00414v3 Announce Type: replace 
Abstract: Semantic parsers convert natural language to logical forms, which can be evaluated on knowledge bases (KBs) to produce denotations. Recent semantic parsers have been developed with sequence-to-sequence (seq2seq) pre-trained language models (PLMs) or large language models, where the models treat logical forms as sequences of tokens. For syntactic and semantic validity, the semantic parsers use grammars that enable constrained decoding. However, the grammars lack the ability to utilize large information of KBs, although logical forms contain representations of KB elements, such as entities or relations. In this work, we propose a grammar augmented with candidate expressions for semantic parsing on a large KB with a seq2seq PLM. The grammar defines actions as production rules, and our semantic parser predicts actions during inference under the constraints by types and candidate expressions. We apply the grammar to knowledge base question answering, where the constraints by candidate expressions assist a semantic parser to generate valid KB elements. We also introduce two special rules, sub-type inference and union types, and a mask caching algorithm. In particular, sub-type inference and the mask caching algorithm greatly increase the decoding speed of our semantic parser. We experimented on two benchmarks, KQA Pro and Overnight, where the constraints by candidate expressions increased the accuracy of our semantic parser, whether it was trained with strong supervision or weak supervision. In addition, our semantic parser had a fast decoding speed in the experiments.
        ]]></description>
    </item>
    <item>
        <title>DeepNote: Note-Centric Deep Retrieval-Augmented Generation</title>
        <link>https://arxiv.org/abs/2410.08821</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.08821v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ruobing Wang, Qingfei Zhao, Yukun Yan, Daren Zha, Yuxuan Chen, Shi Yu, Zhenghao Liu, Yixuan Wang, Shuo Wang, Xu Han, Zhiyuan Liu, Maosong Sun</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）能减少大语言模型问答中的事实错误和幻觉，但现有自适应RAG方法难以反映真实信息需求和充分利用检索知识。方法：提出DeepNote，这是一种以笔记为中心的自适应RAG框架，用笔记提炼和积累知识，在深度探索中确定检索时机、制定检索查询、迭代评估知识增长，最后用最佳笔记生成答案。效果：实验显示，DeepNote显著优于所有基线（+10.2%至+20.1%），且能收集高密度、高质量知识，DPO进一步提升其性能。
            arXiv:2410.08821v2 Announce Type: replace 
Abstract: Retrieval-Augmented Generation (RAG) mitigates factual errors and hallucinations in Large Language Models (LLMs) for question-answering (QA) by incorporating external knowledge. However, existing adaptive RAG methods rely on LLMs to predict retrieval timing and directly use retrieved information for generation, often failing to reflect real information needs and fully leverage retrieved knowledge. We develop DeepNote, an adaptive RAG framework that achieves in-depth and robust exploration of knowledge sources through note-centric adaptive retrieval. DeepNote employs notes as carriers for refining and accumulating knowledge. During in-depth exploration, it uses these notes to determine retrieval timing, formulate retrieval queries, and iteratively assess knowledge growth, ultimately leveraging the best note for answer generation. Extensive experiments and analyses demonstrate that DeepNote significantly outperforms all baselines (+10.2% to +20.1%) and exhibits the ability to gather knowledge with both high density and quality. Additionally, DPO further improves the performance of DeepNote. The code and data are available at https://github.com/thunlp/DeepNote.
        ]]></description>
    </item>
    <item>
        <title>PrefRAG: Preference-Driven Multi-Source Retrieval Augmented Generation</title>
        <link>https://arxiv.org/abs/2411.00689</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2411.00689v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qingfei Zhao, Ruobing Wang, Yukuo Cen, Daren Zha, Shicheng Tan, Jie Tang</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）可缓解大语言模型幻觉和知识局限问题，但现有自适应RAG系统难以有效探索不同检索源。方法：提出PrefRAG系统，通过偏好驱动的自适应检索和自我反思，对不同检索源进行深度可控探索，先探索本地源并适时补充网络知识，再将答案质量反馈用于优化检索。效果：实验表明其具有优越性、高检索效率和知识可控性，比Vanilla RAG和领先的MS - ARAG最高分别提升25.6%和13.9%，用DPO训练性能更高。
            arXiv:2411.00689v2 Announce Type: replace 
Abstract: Retrieval-Augmented Generation (RAG) has emerged as a reliable external knowledge augmentation technique to mitigate hallucination issues and parameterized knowledge limitations in Large Language Models (LLMs). Existing adaptive RAG (ARAG) systems excel at in-depth exploration within a single source but struggle to effectively and controllably explore different retrieval sources, as they fail to foresee their internal knowledge features. We develop a novel multi-source ARAG system, PrefRAG, which enhances RAG by enabling in-depth and controllable exploration of diverse retrieval sources through preference-driven adaptive retrieval and self-reflection. PrefRAG first fully explores controllable local sources in adaptive retrieval and supplements with the web when appropriate, ultimately selecting the optimal source for knowledge observation. Subsequently, PrefRAG feeds answer quality feedback into the retrieval process, optimizing it from the generation perspective to produce higher-quality responses. Extensive experiments confirm its superiority, high retrieval efficiency, and knowledge controllability. PrefRAG outperforms Vanilla RAG and the leading MS-ARAG by up to 25.6% and 13.9% respectively. Additionally, PrefRAG trained with DPO achieves higher performance. The code and data are available at https://github.com/QingFei1/PrefRAG.git.
        ]]></description>
    </item>
    <item>
        <title>Enhancing the Reasoning Ability of Multimodal Large Language Models via Mixed Preference Optimization</title>
        <link>https://arxiv.org/abs/2411.10442</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2411.10442v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Weiyun Wang, Zhe Chen, Wenhai Wang, Yue Cao, Yangzhou Liu, Zhangwei Gao, Jinguo Zhu, Xizhou Zhu, Lewei Lu, Yu Qiao, Jifeng Dai</dc:creator>
        <description><![CDATA[
            背景：现有开源多模态大语言模型存在分布偏移问题，限制了多模态推理能力，尤其是思维链性能。方法：引入偏好优化（PO）过程，数据方面设计自动化偏好数据构建流程创建高质量大规模多模态推理偏好数据集MMPR；模型方面探索将PO与多模态大语言模型结合，提出混合偏好优化（MPO）方法。效果：提升了InternVL2 - 8B和InternVL2 - 76B的多模态推理能力，InternVL2 - 8B - MPO在MathVista上准确率达67.0，比InternVL2 - 8B高8.7个点，与大10倍的InternVL2 - 76B性能相当。
            arXiv:2411.10442v2 Announce Type: replace 
Abstract: Existing open-source multimodal large language models (MLLMs) generally follow a training process involving pre-training and supervised fine-tuning. However, these models suffer from distribution shifts, which limit their multimodal reasoning, particularly in the Chain-of-Thought (CoT) performance. To address this, we introduce a preference optimization (PO) process to enhance the multimodal reasoning capabilities of MLLMs. Specifically, (1) on the data side, we design an automated preference data construction pipeline to create MMPR, a high-quality, large-scale multimodal reasoning preference dataset; and (2) on the model side, we explore integrating PO with MLLMs, developing a simple yet effective method, termed Mixed Preference Optimization (MPO), which boosts multimodal CoT performance. Our approach enhances the multimodal reasoning abilities of both InternVL2-8B and InternVL2-76B. Notably, our model, InternVL2-8B-MPO, achieves an accuracy of 67.0 on MathVista, outperforming InternVL2-8B by 8.7 points and achieving performance comparable to the 10$\times$ larger InternVL2-76B. We hope this study could inspire further advancements in MLLMs. Code, data, and model are released.
        ]]></description>
    </item>
    <item>
        <title>PerLA: Perceptive 3D Language Assistant</title>
        <link>https://arxiv.org/abs/2411.19774</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2411.19774v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Guofeng Mei, Wei Lin, Luigi Riz, Yujiao Wu, Fabio Poiesi, Yiming Wang</dc:creator>
        <description><![CDATA[
            让大语言模型理解3D物理世界是新兴且具挑战的研究方向。现有处理点云的策略易丢失关键局部细节或全局上下文信息。本文提出PerLA，它能兼顾细节与上下文，使视觉表征对大语言模型更具信息性。该方法并行捕捉不同点云区域的高分辨率细节，并与低分辨率全量点云的全局信息融合，通过希尔伯特曲线保留局部性，用交叉注意力和图神经网络聚合信息，还引入新损失促进训练稳定。PerLA性能超现有3D语言助手，在ScanQA问答任务上CiDEr提升1.34，在ScanRefer和Nr3D密集字幕任务上分别提升4.22和3.88。
            arXiv:2411.19774v2 Announce Type: replace 
Abstract: Enabling Large Language Models (LLMs) to understand the 3D physical world is an emerging yet challenging research direction. Current strategies for processing point clouds typically downsample the scene or divide it into smaller parts for separate analysis. However, both approaches risk losing key local details or global contextual information. In this paper, we introduce PerLA, a 3D language assistant designed to be more perceptive to both details and context, making visual representations more informative for the LLM. PerLA captures high-resolution (local) details in parallel from different point cloud areas and integrates them with (global) context obtained from a lower-resolution whole point cloud. We present a novel algorithm that preserves point cloud locality through the Hilbert curve and effectively aggregates local-to-global information via cross-attention and a graph neural network. Lastly, we introduce a novel loss for local representation consensus to promote training stability. PerLA outperforms state-of-the-art 3D language assistants, with gains of up to +1.34 CiDEr on ScanQA for question answering, and +4.22 on ScanRefer and +3.88 on Nr3D for dense captioning. https://gfmei.github.io/PerLA/
        ]]></description>
    </item>
    <item>
        <title>GG-SSMs: Graph-Generating State Space Models</title>
        <link>https://arxiv.org/abs/2412.12423</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2412.12423v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Nikola Zubi\'c, Davide Scaramuzza</dc:creator>
        <description><![CDATA[
            背景：传统状态空间模型（SSMs）处理高维数据时受限于固定一维序列处理，难以捕捉非局部交互，现有改进方法依赖预设路径，无法有效捕捉复杂依赖。方法：提出图生成状态空间模型（GG - SSMs），基于特征关系动态构建图，利用Chazelle最小生成树算法适应数据固有结构，实现特征在动态图上的传播。效果：在11个不同数据集上验证，取得了最优性能，如在ImageNet上top - 1准确率达84.9%，优于现有SSMs 1%。
            arXiv:2412.12423v2 Announce Type: replace 
Abstract: State Space Models (SSMs) are powerful tools for modeling sequential data in computer vision and time series analysis domains. However, traditional SSMs are limited by fixed, one-dimensional sequential processing, which restricts their ability to model non-local interactions in high-dimensional data. While methods like Mamba and VMamba introduce selective and flexible scanning strategies, they rely on predetermined paths, which fails to efficiently capture complex dependencies. We introduce Graph-Generating State Space Models (GG-SSMs), a novel framework that overcomes these limitations by dynamically constructing graphs based on feature relationships. Using Chazelle's Minimum Spanning Tree algorithm, GG-SSMs adapt to the inherent data structure, enabling robust feature propagation across dynamically generated graphs and efficiently modeling complex dependencies. We validate GG-SSMs on 11 diverse datasets, including event-based eye-tracking, ImageNet classification, optical flow estimation, and six time series datasets. GG-SSMs achieve state-of-the-art performance across all tasks, surpassing existing methods by significant margins. Specifically, GG-SSM attains a top-1 accuracy of 84.9% on ImageNet, outperforming prior SSMs by 1%, reducing the KITTI-15 error rate to 2.77%, and improving eye-tracking detection rates by up to 0.33% with fewer parameters. These results demonstrate that dynamic scanning based on feature relationships significantly improves SSMs' representational power and efficiency, offering a versatile tool for various applications in computer vision and beyond.
        ]]></description>
    </item>
    <item>
        <title>CypherBench: Towards Precise Retrieval over Full-scale Modern Knowledge Graphs in the LLM Era</title>
        <link>https://arxiv.org/abs/2412.18702</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2412.18702v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yanlin Feng, Simone Papicchio, Sajjadur Rahman</dc:creator>
        <description><![CDATA[
            背景：从图数据中检索对增强大语言模型的知识至关重要，但现有大模型框架对从现代百科知识图谱中检索支持有限。方法：分析发现现代RDF知识图谱因模式过大等因素对大模型效率低，提出在RDF图上构建属性图视图，让大模型用Cypher高效查询，还开发转换引擎、生成任务管道和设计评估指标。效果：在Wikidata上实现该想法，推出首个含11个大规模多领域属性图、780万个实体和超10000个问题的CypherBench基准。
            arXiv:2412.18702v2 Announce Type: replace 
Abstract: Retrieval from graph data is crucial for augmenting large language models (LLM) with both open-domain knowledge and private enterprise data, and it is also a key component in the recent GraphRAG system (edge et al., 2024). Despite decades of research on knowledge graphs and knowledge base question answering, leading LLM frameworks (e.g. Langchain and LlamaIndex) have only minimal support for retrieval from modern encyclopedic knowledge graphs like Wikidata. In this paper, we analyze the root cause and suggest that modern RDF knowledge graphs (e.g. Wikidata, Freebase) are less efficient for LLMs due to overly large schemas that far exceed the typical LLM context window, use of resource identifiers, overlapping relation types and lack of normalization. As a solution, we propose property graph views on top of the underlying RDF graph that can be efficiently queried by LLMs using Cypher. We instantiated this idea on Wikidata and introduced CypherBench, the first benchmark with 11 large-scale, multi-domain property graphs with 7.8 million entities and over 10,000 questions. To achieve this, we tackled several key challenges, including developing an RDF-to-property graph conversion engine, creating a systematic pipeline for text-to-Cypher task generation, and designing new evaluation metrics.
        ]]></description>
    </item>
    <item>
        <title>Enhancing Uncertainty Modeling with Semantic Graph for Hallucination Detection</title>
        <link>https://arxiv.org/abs/2501.02020</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2501.02020v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kedi Chen, Qin Chen, Jie Zhou, Xinqi Tao, Bowen Ding, Jingwen Xie, Mingchen Xie, Peilong Li, Feng Zheng, Liang He</dc:creator>
        <description><![CDATA[
            背景：大语言模型易产生幻觉，现有基于不确定性的幻觉检测方法多只考虑单个token的不确定性，未充分研究token和句子间语义关系。方法：提出用语义图增强不确定性建模的幻觉检测方法，先构建语义图捕捉实体token和句子关系，利用实体关系进行不确定性传播，还提出基于图的不确定性校准方法，结合句子及其邻句矛盾概率计算不确定性。效果：在两个数据集实验显示优势，段落级幻觉检测提升19.78%。
            arXiv:2501.02020v3 Announce Type: replace 
Abstract: Large Language Models (LLMs) are prone to hallucination with non-factual or unfaithful statements, which undermines the applications in real-world scenarios. Recent researches focus on uncertainty-based hallucination detection, which utilizes the output probability of LLMs for uncertainty calculation and does not rely on external knowledge or frequent sampling from LLMs. Whereas, most approaches merely consider the uncertainty of each independent token, while the intricate semantic relations among tokens and sentences are not well studied, which limits the detection of hallucination that spans over multiple tokens and sentences in the passage. In this paper, we propose a method to enhance uncertainty modeling with semantic graph for hallucination detection. Specifically, we first construct a semantic graph that well captures the relations among entity tokens and sentences. Then, we incorporate the relations between two entities for uncertainty propagation to enhance sentence-level hallucination detection. Given that hallucination occurs due to the conflict between sentences, we further present a graph-based uncertainty calibration method that integrates the contradiction probability of the sentence with its neighbors in the semantic graph for uncertainty calculation. Extensive experiments on two datasets show the great advantages of our proposed approach. In particular, we obtain substantial improvements with 19.78% in passage-level hallucination detection.
        ]]></description>
    </item>
    <item>
        <title>Context-Alignment: Activating and Enhancing LLM Capabilities in Time Series</title>
        <link>https://arxiv.org/abs/2501.03747</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2501.03747v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuxiao Hu, Qian Li, Dongxiao Zhang, Jinyue Yan, Yuntian Chen</dc:creator>
        <description><![CDATA[
            背景：利用预训练大语言模型处理时间序列任务备受关注，但现有方法多基于词元级对齐，忽略了大模型对语言逻辑和结构的理解。方法：提出上下文对齐范式，包括结构对齐和逻辑对齐，通过双尺度上下文对齐图神经网络（DSCA - GNNs）实现，还构建了基于演示示例的上下文对齐（DECA），可灵活集成到预训练大模型各层。效果：大量实验表明，DECA有效，上下文对齐在各任务中重要，尤其在少样本和零样本预测中表现出色。
            arXiv:2501.03747v2 Announce Type: replace 
Abstract: Recently, leveraging pre-trained Large Language Models (LLMs) for time series (TS) tasks has gained increasing attention, which involves activating and enhancing LLMs' capabilities. Many methods aim to activate LLMs' capabilities based on token-level alignment but overlook LLMs' inherent strength on natural language processing -- their deep understanding of linguistic logic and structure rather than superficial embedding processing. We propose Context-Alignment, a new paradigm that aligns TS with a linguistic component in the language environments familiar to LLMs to enable LLMs to contextualize and comprehend TS data, thereby activating their capabilities. Specifically, such context-level alignment comprises structural alignment and logical alignment, which is achieved by a Dual-Scale Context-Alignment GNNs (DSCA-GNNs) applied to TS-language multimodal inputs. Structural alignment utilizes dual-scale nodes to describe hierarchical structure in TS-language, enabling LLMs treat long TS data as a whole linguistic component while preserving intrinsic token features. Logical alignment uses directed edges to guide logical relationships, ensuring coherence in the contextual semantics. Demonstration examples prompt are employed to construct Demonstration Examples based Context-Alignment (DECA) following DSCA-GNNs framework. DECA can be flexibly and repeatedly integrated into various layers of pre-trained LLMs to improve awareness of logic and structure, thereby enhancing performance. Extensive experiments show the effectiveness of DECA and the importance of Context-Alignment across tasks, particularly in few-shot and zero-shot forecasting, confirming that Context-Alignment provide powerful prior knowledge on context.
        ]]></description>
    </item>
    <item>
        <title>Graph-Based Multimodal Contrastive Learning for Chart Question Answering</title>
        <link>https://arxiv.org/abs/2501.04303</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2501.04303v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yue Dai, Soyeon Caren Han, Wei Liu</dc:creator>
        <description><![CDATA[
            背景：图表问答因图表元素的异构组成和其隐含的数据模式面临挑战。方法：提出一种联合多模态场景图框架，显式建模图表组件关系和结构，集成视觉和文本图以捕捉结构与语义特征；用图对比学习策略对齐多模态节点表示；提出定制思维链提示，减少幻觉以增强多模态大模型零样本能力。效果：在ChartQA、OpenCQA和ChartX等基准测试中显著提升性能，验证了方法有效性。
            arXiv:2501.04303v2 Announce Type: replace 
Abstract: Chart question answering (ChartQA) is challenged by the heterogeneous composition of chart elements and the subtle data patterns they encode. This work introduces a novel joint multimodal scene graph framework that explicitly models the relationships among chart components and their underlying structures. The framework integrates both visual and textual graphs to capture structural and semantic characteristics, while a graph contrastive learning strategy aligns node representations across modalities enabling their seamless incorporation into a transformer decoder as soft prompts. Moreover, a set of tailored Chain of Thought (CoT) prompts is proposed to enhance multimodal large language models (MLLMs) in zero-s ot scenarios by mitigating hallucinations. Extensive evaluations on benchmarks including ChartQA, OpenCQA, and ChartX demonstrate significant performance improvements and validate the efficacy of the proposed approach.
        ]]></description>
    </item>
    <item>
        <title>Crowd Comparative Reasoning: Unlocking Comprehensive Evaluations for LLM-as-a-Judge</title>
        <link>https://arxiv.org/abs/2502.12501</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.12501v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qiyuan Zhang, Yufei Wang, Yuxin Jiang, Liangyou Li, Chuhan Wu, Yasheng Wang, Xin Jiang, Lifeng Shang, Ruiming Tang, Fuyuan Lyu, Chen Ma</dc:creator>
        <description><![CDATA[
            背景：大语言模型作为评判者生成思维链判断的自动评估方法可靠性不足，因其思维链推理无法捕捉全面深入细节。方法：提出基于群体的比较评估法，引入额外群体回复与候选回复对比，引导大语言模型评判者给出更详细思维链判断。效果：实验表明该方法提升评估可靠性，在五个基准测试中平均准确率提高6.7%，生成的思维链质量更高，利于评判者蒸馏和监督微调的拒绝采样，评估准确性随推理规模提升。
            arXiv:2502.12501v2 Announce Type: replace 
Abstract: LLM-as-a-Judge, which generates chain-of-thought (CoT) judgments, has become a widely adopted auto-evaluation method. However, its reliability is compromised by the CoT reasoning's inability to capture comprehensive and deeper details, often leading to incomplete outcomes. Existing methods mainly rely on majority voting or criteria expansion, which is insufficient to address the limitation in CoT. We propose Crowd-based Comparative Evaluation, which introduces additional crowd responses to compare with the candidate responses, thereby exposing deeper and more comprehensive details within the candidate responses. This process effectively guides LLM-as-a-Judge to provide a more detailed CoT judgment. Extensive experiments demonstrate that our approach enhances evaluation reliability, achieving an average accuracy gain of 6.7% across five benchmarks. Moreover, our method produces higher-quality CoTs that facilitate judge distillation and exhibit superior performance in rejection sampling for supervised fine-tuning (SFT), referred to as crowd rejection sampling, thereby enabling more efficient SFT. Our analysis confirms that CoTs generated by ours are more comprehensive and of higher quality, and evaluation accuracy improves as inference scales.
        ]]></description>
    </item>
    <item>
        <title>CrossOver: 3D Scene Cross-Modal Alignment</title>
        <link>https://arxiv.org/abs/2502.15011</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.15011v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sayan Deb Sarkar, Ondrej Miksik, Marc Pollefeys, Daniel Barath, Iro Armeni</dc:creator>
        <description><![CDATA[
            背景：多模态3D对象理解受关注，但现有方法常假设数据完整且各模态严格对齐。方法：提出CrossOver框架，通过灵活的场景级模态对齐实现跨模态3D场景理解，学习统一、与模态无关的场景嵌入空间，利用特定维度编码器、多阶段训练流程和新兴跨模态行为。效果：在ScanNet和3RScan数据集上评估，在多种指标上表现出色，即使模态缺失也支持场景检索和对象定位，凸显其在3D场景理解实际应用中的适应性。
            arXiv:2502.15011v2 Announce Type: replace 
Abstract: Multi-modal 3D object understanding has gained significant attention, yet current approaches often assume complete data availability and rigid alignment across all modalities. We present CrossOver, a novel framework for cross-modal 3D scene understanding via flexible, scene-level modality alignment. Unlike traditional methods that require aligned modality data for every object instance, CrossOver learns a unified, modality-agnostic embedding space for scenes by aligning modalities -- RGB images, point clouds, CAD models, floorplans, and text descriptions -- with relaxed constraints and without explicit object semantics. Leveraging dimensionality-specific encoders, a multi-stage training pipeline, and emergent cross-modal behaviors, CrossOver supports robust scene retrieval and object localization, even with missing modalities. Evaluations on ScanNet and 3RScan datasets show its superior performance across diverse metrics, highlighting the adaptability for real-world applications in 3D scene understanding.
        ]]></description>
    </item>
    <item>
        <title>Forgotten Polygons: Multimodal Large Language Models are Shape-Blind</title>
        <link>https://arxiv.org/abs/2502.15969</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.15969v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>William Rudman, Michal Golovanevsky, Amir Bar, Vedant Palit, Yann LeCun, Carsten Eickhoff, Ritambhara Singh</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型（MLLMs）在视觉 - 语言任务表现好，但在数学问题解决上有困难，在视觉数学基准测试中不及人类。方法：评估MLLMs对几何基元的理解、测试多步推理，并提出Visually Cued Chain - of - Thought（VC - CoT）提示方法。效果：顶尖模型识别正多边形准确率低于50%，VC - CoT提示使GPT - 4o在不规则多边形边数计数任务上准确率从7%提升到93%，表明视觉引导提示对视觉推理很关键。
            arXiv:2502.15969v3 Announce Type: replace 
Abstract: Despite strong performance on vision-language tasks, Multimodal Large Language Models (MLLMs) struggle with mathematical problem-solving, with both open-source and state-of-the-art models falling short of human performance on visual-math benchmarks. To systematically examine visual-mathematical reasoning in MLLMs, we (1) evaluate their understanding of geometric primitives, (2) test multi-step reasoning, and (3) explore a potential solution to improve visual reasoning capabilities. Our findings reveal fundamental shortcomings in shape recognition, with top models achieving under 50% accuracy in identifying regular polygons. We analyze these failures through the lens of dual-process theory and show that MLLMs rely on System 1 (intuitive, memorized associations) rather than System 2 (deliberate reasoning). Consequently, MLLMs fail to count the sides of both familiar and novel shapes, suggesting they have neither learned the concept of sides nor effectively process visual inputs. Finally, we propose Visually Cued Chain-of-Thought (VC-CoT) prompting, which enhances multi-step mathematical reasoning by explicitly referencing visual annotations in diagrams, boosting GPT-4o's accuracy on an irregular polygon side-counting task from 7% to 93%. Our findings suggest that System 2 reasoning in MLLMs remains an open problem, and visually-guided prompting is essential for successfully engaging visual reasoning. Code available at: https://github.com/rsinghlab/Shape-Blind.
        ]]></description>
    </item>
    <item>
        <title>Unbiased Video Scene Graph Generation via Visual and Semantic Dual Debiasing</title>
        <link>https://arxiv.org/abs/2503.00548</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.00548v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yanjun Li, Zhaoyang Li, Honghui Chen, Lizhi Xu</dc:creator>
        <description><![CDATA[
            背景：视频场景图生成（VidSGG）旨在分析视频帧、融合视觉与语义信息以捕捉实体间动态关系，但存在显著偏差影响预测。方法：提出视觉和语义感知（VISA）框架，通过记忆增强的时间整合解决视觉偏差，增强对象表示；迭代整合对象特征与三元组关系的语义信息减少语义偏差。效果：该视觉 - 语义双去偏方法使复杂场景动态表示更无偏，实验显示VISA大幅优于现有无偏VidSGG方法，如半约束下SGCLS任务mR@20和mR@50提升13.1%。
            arXiv:2503.00548v2 Announce Type: replace 
Abstract: Video Scene Graph Generation (VidSGG) aims to capture dynamic relationships among entities by sequentially analyzing video frames and integrating visual and semantic information. However, VidSGG is challenged by significant biases that skew predictions. To mitigate these biases, we propose a VIsual and Semantic Awareness (VISA) framework for unbiased VidSGG. VISA addresses visual bias through memory-enhanced temporal integration that enhances object representations and concurrently reduces semantic bias by iteratively integrating object features with comprehensive semantic information derived from triplet relationships. This visual-semantics dual debiasing approach results in more unbiased representations of complex scene dynamics. Extensive experiments demonstrate the effectiveness of our method, where VISA outperforms existing unbiased VidSGG approaches by a substantial margin (e.g., +13.1% improvement in mR@20 and mR@50 for the SGCLS task under Semi Constraint).
        ]]></description>
    </item>
    <item>
        <title>Multi-agent Auto-Bidding with Latent Graph Diffusion Models</title>
        <link>https://arxiv.org/abs/2503.05805</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.05805v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Dom Huh, Prasant Mohapatra</dc:creator>
        <description><![CDATA[
            背景：在大规模拍卖环境中，智能体需在关键绩效指标约束及竞争环境下动态优化出价策略。方法：提出基于扩散的自动出价框架，结合基于图的可学习嵌入和基于规划的潜在扩散模型，通过图表示捕捉印象机会和多智能体动态模式，用奖励对齐技术微调模型后验以生成自动出价轨迹。效果：在真实和合成拍卖环境中，多个常见关键绩效指标下自动出价性能显著提升，拍卖结果预测准确性提高。
            arXiv:2503.05805v2 Announce Type: replace 
Abstract: This paper proposes a diffusion-based auto-bidding framework that leverages graph representations to model large-scale auction environments. In such settings, agents must dynamically optimize bidding strategies under constraints defined by key performance indicator (KPI) metrics, all while operating in competitive environments characterized by uncertain, sparse, and stochastic variables. To address these challenges, we introduce a novel approach combining learnable graph-based embeddings with a planning-based latent diffusion model (LDM). By capturing patterns and nuances underlying the interdependence of impression opportunities and the multi-agent dynamics of the auction environment, the graph representation enable expressive computations regarding auto-bidding outcomes. With reward alignment techniques, the LDM's posterior is fine-tuned to generate auto-bidding trajectories that maximize KPI metrics while satisfying constraint thresholds. Empirical evaluations on both real-world and synthetic auction environments demonstrate significant improvements in auto-bidding performance across multiple common KPI metrics, as well as accuracy in forecasting auction outcomes.
        ]]></description>
    </item>
    <item>
        <title>Real-Time Evaluation Models for RAG: Who Detects Hallucinations Best?</title>
        <link>https://arxiv.org/abs/2503.21157</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.21157v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ashish Sardana</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）存在幻觉问题，需自动检测。方法：对LLM - as - a - Judge、Prometheus等多种无参考评估模型进行研究，这些模型无需真实答案或标签就能捕捉大语言模型的错误响应，并在六个RAG应用中对其性能进行全面基准测试。效果：研究显示，在不同RAG应用中，部分方法能以较高的精确率/召回率持续检测出错误的RAG响应。
            arXiv:2503.21157v3 Announce Type: replace 
Abstract: This article surveys Evaluation models to automatically detect hallucinations in Retrieval-Augmented Generation (RAG), and presents a comprehensive benchmark of their performance across six RAG applications. Methods included in our study include: LLM-as-a-Judge, Prometheus, Lynx, the Hughes Hallucination Evaluation Model (HHEM), and the Trustworthy Language Model (TLM). These approaches are all reference-free, requiring no ground-truth answers/labels to catch incorrect LLM responses. Our study reveals that, across diverse RAG applications, some of these approaches consistently detect incorrect RAG responses with high precision/recall.
        ]]></description>
    </item>
    <item>
        <title>ThinkEdit: Interpretable Weight Editing to Mitigate Overly Short Thinking in Reasoning Models</title>
        <link>https://arxiv.org/abs/2503.22048</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.22048v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chung-En Sun, Ge Yan, Tsui-Wei Weng</dc:creator>
        <description><![CDATA[
            背景：大语言模型结合思维链推理虽有出色解题能力，但存在推理过短致简单数学题表现不佳的问题。方法：研究推理长度在模型隐藏表征中的嵌入方式及对准确率的影响，发现其由表征空间的线性方向决定，提出ThinkEdit方法，找出约2%主导短推理行为的注意力头，编辑其输出投影权重抑制短推理方向。效果：仅改动0.1%的模型参数，有效减少短推理，短推理输出准确率提升5.44%，多个数学基准测试整体提升2.43%。
            arXiv:2503.22048v2 Announce Type: replace 
Abstract: Recent studies have shown that Large Language Models (LLMs) augmented with chain-of-thought (CoT) reasoning demonstrate impressive problem-solving abilities. However, in this work, we identify a recurring issue where these models occasionally generate overly short reasoning, leading to degraded performance on even simple mathematical problems. Specifically, we investigate how reasoning length is embedded in the hidden representations of reasoning models and its impact on accuracy. Our analysis reveals that reasoning length is governed by a linear direction in the representation space, allowing us to induce overly short reasoning by steering the model along this direction. Building on this insight, we introduce ThinkEdit, a simple yet effective weight-editing approach to mitigate the issue of overly short reasoning. We first identify a small subset of attention heads (approximately 2%) that predominantly drive short reasoning behavior. We then edit the output projection weights of these heads to suppress the short reasoning direction. With changes to only 0.1% of the model's parameters, ThinkEdit effectively reduces overly short reasoning and yields notable accuracy gains for short reasoning outputs (+5.44%), along with an overall improvement across multiple math benchmarks (+2.43%). Our findings provide new mechanistic insights into how reasoning length is controlled within LLMs and highlight the potential of fine-grained model interventions to improve reasoning quality. Our code is available at https://github.com/Trustworthy-ML-Lab/ThinkEdit
        ]]></description>
    </item>
    <item>
        <title>GenPRM: Scaling Test-Time Compute of Process Reward Models via Generative Reasoning</title>
        <link>https://arxiv.org/abs/2504.00891</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.00891v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jian Zhao, Runze Liu, Kaiyan Zhang, Zhimu Zhou, Junqi Gao, Dong Li, Jiafei Lyu, Zhouyi Qian, Biqing Qi, Xiu Li, Bowen Zhou</dc:creator>
        <description><![CDATA[
            背景：当前过程奖励模型（PRMs）存在过程监督和泛化能力有限、依赖标量值预测、测试时计算难以扩展等问题。方法：提出生成式过程奖励模型GenPRM，在对每个推理步骤给出判断前进行显式思维链推理和代码验证，还提出相对进度估计（RPE）和结合代码验证的理由综合框架获取高质量监督标签和理由数据。效果：在ProcessBench和数学推理任务上，用MATH数据集23K数据训练的GenPRM显著优于先前模型，1.5B的GenPRM超GPT - 4o，7B的GenPRM在ProcessBench上超Qwen2.5 - Math - PRM - 72B。
            arXiv:2504.00891v2 Announce Type: replace 
Abstract: Recent advancements in Large Language Models (LLMs) have shown that it is promising to utilize Process Reward Models (PRMs) as verifiers to enhance the performance of LLMs. However, current PRMs face three key challenges: (1) limited process supervision and generalization capabilities, (2) dependence on scalar value prediction without leveraging the generative abilities of LLMs, and (3) inability to scale the test-time compute of PRMs. In this work, we introduce GenPRM, a generative process reward model that performs explicit Chain-of-Thought (CoT) reasoning with code verification before providing judgment for each reasoning step. To obtain high-quality process supervision labels and rationale data, we propose Relative Progress Estimation (RPE) and a rationale synthesis framework that incorporates code verification. Experimental results on ProcessBench and several mathematical reasoning tasks show that GenPRM significantly outperforms prior PRMs with only 23K training data from MATH dataset. Through test-time scaling, a 1.5B GenPRM outperforms GPT-4o, and a 7B GenPRM surpasses Qwen2.5-Math-PRM-72B on ProcessBench. Additionally, GenPRM demonstrates strong abilities to serve as a critic model for policy model refinement. This work establishes a new paradigm for process supervision that bridges the gap between PRMs and critic models in LLMs. Our code, model, and data will be available in https://ryanliu112.github.io/GenPRM.
        ]]></description>
    </item>
    <item>
        <title>MedReason: Eliciting Factual Medical Reasoning Steps in LLMs via Knowledge Graphs</title>
        <link>https://arxiv.org/abs/2504.00993</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.00993v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Juncheng Wu, Wenlong Deng, Xingxuan Li, Sheng Liu, Taomian Mi, Yifan Peng, Ziyang Xu, Yi Liu, Hyunjin Cho, Chang-In Choi, Yihan Cao, Hui Ren, Xiang Li, Xiaoxiao Li, Yuyin Zhou</dc:creator>
        <description><![CDATA[
            医学任务需精确复杂推理，但缺乏验证和提升AI模型医学推理能力的数据集。为此，研究人员引入大规模高质量医学推理数据集MedReason。利用结构化医学知识图谱将临床问答对转化为推理逻辑链，生成详细推理。该数据集含32,682个问答对，每个都有详细步骤解释。实验表明，用此数据集微调可提升医学问题解决能力，DeepSeek - Ditill - 8B最多提升7.7%，MedReason - 8B在临床基准测试中比Huatuo - o1 - 8B最多高4.2%。
            arXiv:2504.00993v2 Announce Type: replace 
Abstract: Medical tasks such as diagnosis and treatment planning require precise and complex reasoning, particularly in life-critical domains. Unlike mathematical reasoning, medical reasoning demands meticulous, verifiable thought processes to ensure reliability and accuracy. However, there is a notable lack of datasets that provide transparent, step-by-step reasoning to validate and enhance the medical reasoning ability of AI models. To bridge this gap, we introduce MedReason, a large-scale high-quality medical reasoning dataset designed to enable faithful and explainable medical problem-solving in large language models (LLMs). We utilize a structured medical knowledge graph (KG) to convert clinical QA pairs into logical chains of reasoning, or ``thinking paths'', which trace connections from question elements to answers via relevant KG entities. Each path is validated for consistency with clinical logic and evidence-based medicine. Our pipeline generates detailed reasoning for various medical questions from 7 medical datasets, resulting in a dataset of 32,682 question-answer pairs, each with detailed, step-by-step explanations. Experiments demonstrate that fine-tuning with our dataset consistently boosts medical problem-solving capabilities, achieving significant gains of up to 7.7% for DeepSeek-Ditill-8B. Our top-performing model, MedReason-8B, outperforms the Huatuo-o1-8B, a state-of-the-art medical reasoning model, by up to 4.2% on the clinical benchmark MedBullets. We also engage medical professionals from diverse specialties to assess our dataset's quality, ensuring MedReason offers accurate and coherent medical reasoning. Our data, models, and code is available at https://github.com/UCSC-VLAA/MedReason.
        ]]></description>
    </item>
    <item>
        <title>Review, Refine, Repeat: Understanding Iterative Decoding of AI Agents with Dynamic Evaluation and Selection</title>
        <link>https://arxiv.org/abs/2504.01931</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.01931v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Souradip Chakraborty, Mohammadreza Pourreza, Ruoxi Sun, Yiwen Song, Nino Scherrer, Furong Huang, Amrit Singh Bedi, Ahmad Beirami, Jindong Gu, Hamid Palangi, Tomas Pfister</dc:creator>
        <description><![CDATA[
            背景：AI 智能体在复杂多模态应用、结构化生成和战略规划任务中表现欠佳，标准微调难以实施，Best-of-N 采样缺乏迭代反馈机制。方法：提出迭代智能体解码（IAD），结合迭代细化与由验证器引导的动态候选评估和选择，优化反馈设计与整合。效果：在 Sketch2Code、Text2SQL 和 Webshop 任务中，IAD 始终优于基线，在 Sketch2Code 和 Text2SQL 上绝对增益 3 - 6%，在 Webshop 上多指标增益 8 - 10%。
            arXiv:2504.01931v2 Announce Type: replace 
Abstract: While AI agents have shown remarkable performance at various tasks, they still struggle with complex multi-modal applications, structured generation and strategic planning. Improvements via standard fine-tuning is often impractical, as solving agentic tasks usually relies on black box API access without control over model parameters. Inference-time methods such as Best-of-N (BON) sampling offer a simple yet effective alternative to improve performance. However, BON lacks iterative feedback integration mechanism. Hence, we propose Iterative Agent Decoding (IAD) which combines iterative refinement with dynamic candidate evaluation and selection guided by a verifier. IAD differs in how feedback is designed and integrated, specifically optimized to extract maximal signal from reward scores. We conduct a detailed comparison of baselines across key metrics on Sketch2Code, Text2SQL, and Webshop where IAD consistently outperforms baselines, achieving 3--6% absolute gains on Sketch2Code and Text2SQL (with and without LLM judges) and 8--10% gains on Webshop across multiple metrics. To better understand the source of IAD's gains, we perform controlled experiments to disentangle the effect of adaptive feedback from stochastic sampling, and find that IAD's improvements are primarily driven by verifier-guided refinement, not merely sampling diversity. We also show that both IAD and BON exhibit inference-time scaling with increased compute when guided by an optimal verifier. Our analysis highlights the critical role of verifier quality in effective inference-time optimization and examines the impact of noisy and sparse rewards on scaling behavior. Together, these findings offer key insights into the trade-offs and principles of effective inference-time optimization.
        ]]></description>
    </item>
    <item>
        <title>Leveraging LLM For Synchronizing Information Across Multilingual Tables</title>
        <link>https://arxiv.org/abs/2504.02559</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.02559v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Siddharth Khincha, Tushar Kataria, Ankita Anand, Dan Roth, Vivek Gupta</dc:creator>
        <description><![CDATA[
            背景：当前大量在线信息集中于英语、法语等资源丰富语言，低资源语言内容常过时或不完整，此前基于规则的跨语言同步方法存在复杂度高和泛化难问题。方法：本文探索用大语言模型（LLMs）进行多语言信息同步，采用零样本提示，引入信息更新数据集模拟更新过时维基百科表格，还提出任务分解策略。效果：所提方法优于现有基线，在信息更新任务上提升1.79%，信息添加任务上提升20.58%。 
            arXiv:2504.02559v2 Announce Type: replace 
Abstract: The vast amount of online information today poses challenges for non-English speakers, as much of it is concentrated in high-resource languages such as English and French. Wikipedia reflects this imbalance, with content in low-resource languages frequently outdated or incomplete. Recent research has sought to improve cross-language synchronization of Wikipedia tables using rule-based methods. These approaches can be effective, but they struggle with complexity and generalization. This paper explores large language models (LLMs) for multilingual information synchronization, using zero-shot prompting as a scalable solution. We introduce the Information Updation dataset, simulating the real-world process of updating outdated Wikipedia tables, and evaluate LLM performance. Our findings reveal that single-prompt approaches often produce suboptimal results, prompting us to introduce a task decomposition strategy that enhances coherence and accuracy. Our proposed method outperforms existing baselines, particularly in Information Updation (1.79%) and Information Addition (20.58%), highlighting the model strength in dynamically updating and enriching data across architectures.
        ]]></description>
    </item>
    <item>
        <title>Multiple Heads are Better than One: Mixture of Modality Knowledge Experts for Entity Representation Learning</title>
        <link>https://arxiv.org/abs/2405.16869</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2405.16869v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yichi Zhang, Zhuo Chen, Lingbing Guo, Yajing Xu, Binbin Hu, Ziqi Liu, Wen Zhang, Huajun Chen</dc:creator>
        <description><![CDATA[
            背景：学习高质量多模态实体表示对多模态知识图谱（MMKG）表示学习很重要，可提升推理任务，但现有方法未充分利用多视角特征。方法：提出混合模态知识专家（MoMoK）框架，设计关系引导的模态知识专家获取关系感知的模态嵌入，整合多模态预测进行联合决策，并通过最小化互信息分离专家。效果：在四个公共MMKG基准测试中，MoMoK在复杂场景下表现出色。
            arXiv:2405.16869v4 Announce Type: replace-cross 
Abstract: Learning high-quality multi-modal entity representations is an important goal of multi-modal knowledge graph (MMKG) representation learning, which can enhance reasoning tasks within the MMKGs, such as MMKG completion (MMKGC). The main challenge is to collaboratively model the structural information concealed in massive triples and the multi-modal features of the entities. Existing methods focus on crafting elegant entity-wise multi-modal fusion strategies, yet they overlook the utilization of multi-perspective features concealed within the modalities under diverse relational contexts. To address this issue, we introduce a novel framework with Mixture of Modality Knowledge experts (MoMoK for short) to learn adaptive multi-modal entity representations for better MMKGC. We design relation-guided modality knowledge experts to acquire relation-aware modality embeddings and integrate the predictions from multi-modalities to achieve joint decisions. Additionally, we disentangle the experts by minimizing their mutual information. Experiments on four public MMKG benchmarks demonstrate the outstanding performance of MoMoK under complex scenarios.
        ]]></description>
    </item>
    <item>
        <title>H-STAR: LLM-driven Hybrid SQL-Text Adaptive Reasoning on Tables</title>
        <link>https://arxiv.org/abs/2407.05952</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2407.05952v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Nikhil Abhyankar, Vivek Gupta, Dan Roth, Chandan K. Reddy</dc:creator>
        <description><![CDATA[
            背景：表格推理需结合语言理解与结构化数据分析，现有方法存在语义理解与数学运算难以兼顾的问题。方法：提出H - STAR算法，分两阶段集成符号和语义方法，一是用‘多视图’列检索和行提取进行逐步表格提取，二是根据问题类型自适应推理，直接查找和复杂词汇查询用语义推理，定量和逻辑任务结合符号推理增强文本推理。效果：在三个表格问答和事实验证数据集上显著优于现有方法。
            arXiv:2407.05952v3 Announce Type: replace-cross 
Abstract: Tabular reasoning involves interpreting natural language queries about tabular data, which presents a unique challenge of combining language understanding with structured data analysis. Existing methods employ either textual reasoning, which excels in semantic interpretation but struggles with mathematical operations, or symbolic reasoning, which handles computations well but lacks semantic understanding. This paper introduces a novel algorithm H-STAR that integrates both symbolic and semantic (textual) approaches in a two-stage process to address these limitations. H-STAR employs: (1) step-wise table extraction using `multi-view' column retrieval followed by row extraction, and (2) adaptive reasoning that adapts reasoning strategies based on question types, utilizing semantic reasoning for direct lookup and complex lexical queries while augmenting textual reasoning with symbolic reasoning support for quantitative and logical tasks. Our extensive experiments demonstrate that H-STAR significantly outperforms state-of-the-art methods across three tabular question-answering (QA) and fact-verification datasets, underscoring its effectiveness and efficiency.
        ]]></description>
    </item>
    <item>
        <title>Decoding Time Series with LLMs: A Multi-Agent Framework for Cross-Domain Annotation</title>
        <link>https://arxiv.org/abs/2410.17462</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.17462v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Minhua Lin, Zhengzhang Chen, Yanchi Liu, Xujiang Zhao, Zongyu Wu, Junxiang Wang, Xiang Zhang, Suhang Wang, Haifeng Chen</dc:creator>
        <description><![CDATA[
            背景：时间序列数据在多领域广泛存在，高质量标注对理解数据和下游任务至关重要，但获取标注颇具挑战。方法：提出多智能体系统TESSA，包含通用标注智能体和特定领域标注智能体。通用智能体捕捉多源领域的通用模式和知识，结合时间序列和文本特征生成通用标注；特定领域智能体利用目标领域的有限标注学习特定术语生成针对性标注。效果：在多数据集上实验表明，TESSA能有效生成高质量标注，优于现有方法。
            arXiv:2410.17462v2 Announce Type: replace-cross 
Abstract: Time series data is ubiquitous across various domains, including manufacturing, finance, and healthcare. High-quality annotations are essential for effectively understanding time series and facilitating downstream tasks; however, obtaining such annotations is challenging, particularly in mission-critical domains. In this paper, we propose TESSA, a multi-agent system designed to automatically generate both general and domain-specific annotations for time series data. TESSA introduces two agents: a general annotation agent and a domain-specific annotation agent. The general agent captures common patterns and knowledge across multiple source domains, leveraging both time-series-wise and text-wise features to generate general annotations. Meanwhile, the domain-specific agent utilizes limited annotations from the target domain to learn domain-specific terminology and generate targeted annotations. Extensive experiments on multiple synthetic and real-world datasets demonstrate that TESSA effectively generates high-quality annotations, outperforming existing methods.
        ]]></description>
    </item>
    <item>
        <title>MCP-Solver: Integrating Language Models with Constraint Programming Systems</title>
        <link>https://arxiv.org/abs/2501.00539</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2501.00539v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Stefan Szeider</dc:creator>
        <description><![CDATA[
            背景：大语言模型存在缺乏形式化求解和推理能力的不足。方法：MCP - Solver通过模型上下文协议（MCP）这一开源标准，将大语言模型与符号求解器相连接，为大语言模型提供形式化求解和推理能力，同时实现了约束编程、命题可满足性和SAT模理论的接口，采用带迭代验证的编辑方法确保模型修改时的一致性。效果：使大语言模型能借助符号求解器的能力，实现结构化改进，弥补其关键缺陷。
            arXiv:2501.00539v2 Announce Type: replace-cross 
Abstract: The MCP Solver bridges Large Language Models (LLMs) with symbolic solvers through the Model Context Protocol (MCP), an open-source standard for AI system integration. Providing LLMs access to formal solving and reasoning capabilities addresses their key deficiency while leveraging their strengths. Our implementation offers interfaces for constraint programming (Minizinc), propositional satisfiability (PySAT), and SAT modulo Theories (Python Z3). The system employs an editing approach with iterated validation to ensure model consistency during modifications and enable structured refinement.
        ]]></description>
    </item>
    <item>
        <title>Dynamic Chain-of-Thought: Towards Adaptive Deep Reasoning</title>
        <link>https://arxiv.org/abs/2502.10428</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.10428v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Libo Wang</dc:creator>
        <description><![CDATA[
            背景：长思维链存在计算冗余和延迟奖励分配问题，导致计算资源成本和消耗增加。方法：提出具有自适应推理时间和步骤的动态思维链（D-CoT），用Python 3.13 IDLE结合基于GPTs的Python模拟器进行模拟实验，并以DeepSeek R1为对照组，测试D-CoT模拟器处理MIT线性代数考试问题的性能。效果：在推理时间、思维链长度和标记数量三个指标上，D-CoT优于基于长思维链的DeepSeek R1，显著降低了计算资源消耗。
            arXiv:2502.10428v4 Announce Type: replace-cross 
Abstract: To reduce the cost and consumption of computing resources caused by computational redundancy and delayed reward assignment in long CoT, this research proposes the dynamic chain-of-thought (D-CoT) with adaptive reasoning time and steps. The researcher used simulation experiment to simulate the integration of D-CoT through Python 3.13 IDLE combined with a Python simulator based on GPTs. At the same time, the researcher used DeepSeek R1 as a control group to test and compare the performance of the D-CoT simulator in processing MIT OpenCourseWare's linear algebra exam questions. Experimental results show that D-CoT is better than DeepSeek R1 based on long CoT in three indicators: reasoning time, CoT length (reasoning steps) and token count, which achieves a significant reduction in computing resource consumption. In addition, this research has potential value in deep reasoning optimization that is used as a reference for future dynamic deep reasoning frameworks.
        ]]></description>
    </item>
    <item>
        <title>Formula-Supervised Sound Event Detection: Pre-Training Without Real Data</title>
        <link>https://arxiv.org/abs/2504.04428</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.04428v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuto Shibata, Keitaro Tanaka, Yoshiaki Bando, Keisuke Imoto, Hirokatsu Kataoka, Yoshimitsu Aoki</dc:creator>
        <description><![CDATA[
            声音事件检测（SED）任务面临获取足量准确标注训练数据难、人工标注有噪声和主观偏差等挑战。为此，本文提出公式驱动的监督学习（FDSL）框架进行环境声音分析模型预训练。该方法利用基于数学公式合成的声学数据构建Formula - SED合成数据集，以合成参数作为真实标签消除标签噪声和偏差。在DCASE2023挑战赛任务4所用的DESED数据集上的实验表明，该预训练方法显著提升了模型精度，加快了训练速度。
            arXiv:2504.04428v1 Announce Type: new 
Abstract: In this paper, we propose a novel formula-driven supervised learning (FDSL) framework for pre-training an environmental sound analysis model by leveraging acoustic signals parametrically synthesized through formula-driven methods. Specifically, we outline detailed procedures and evaluate their effectiveness for sound event detection (SED). The SED task, which involves estimating the types and timings of sound events, is particularly challenged by the difficulty of acquiring a sufficient quantity of accurately labeled training data. Moreover, it is well known that manually annotated labels often contain noises and are significantly influenced by the subjective judgment of annotators. To address these challenges, we propose a novel pre-training method that utilizes a synthetic dataset, Formula-SED, where acoustic data are generated solely based on mathematical formulas. The proposed method enables large-scale pre-training by using the synthesis parameters applied at each time step as ground truth labels, thereby eliminating label noise and bias. We demonstrate that large-scale pre-training with Formula-SED significantly enhances model accuracy and accelerates training, as evidenced by our results in the DESED dataset used for DCASE2023 Challenge Task 4. The project page is at https://yutoshibata07.github.io/Formula-SED/
        ]]></description>
    </item>
    <item>
        <title>LoopGen: Training-Free Loopable Music Generation</title>
        <link>https://arxiv.org/abs/2504.04466</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.04466v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Davide Marincione, Giorgio Strano, Donato Crisostomi, Roberto Ribuoli, Emanuele Rodol\`a</dc:creator>
        <description><![CDATA[
            背景：循环音频是许多音乐流派的核心，但当前生成音乐模型难以生成真正可循环的音频，常出现可听的不连续性。方法：修改非自回归模型MAGNeT，使其以循环模式生成token，让模型在生成结尾时关注音频开头，无需额外训练或数据。效果：通过计算循环接缝处的token困惑度，循环过渡一致性提升55%；盲听测试显示，相比基线方法有显著感知提升，平均评分提高70%。
            arXiv:2504.04466v1 Announce Type: new 
Abstract: Loops--short audio segments designed for seamless repetition--are central to many music genres, particularly those rooted in dance and electronic styles. However, current generative music models struggle to produce truly loopable audio, as generating a short waveform alone does not guarantee a smooth transition from its endpoint back to its start, often resulting in audible discontinuities.Loops--short audio segments designed for seamless repetition--are central to many music genres, particularly those rooted in dance and electronic styles. However, current generative music models struggle to produce truly loopable audio, as generating a short waveform alone does not guarantee a smooth transition from its endpoint back to its start, often resulting in audible discontinuities.We address this gap by modifying a non-autoregressive model (MAGNeT) to generate tokens in a circular pattern, letting the model attend to the beginning of the audio when creating its ending. This inference-only approach results in generations that are aware of future context and loop naturally, without the need for any additional training or data. We evaluate the consistency of loop transitions by computing token perplexity around the seam of the loop, observing a 55% improvement. Blind listening tests further confirm significant perceptual gains over baseline methods, improving mean ratings by 70%. Taken together, these results highlight the effectiveness of inference-only approaches in improving generative models and underscore the advantages of non-autoregressive methods for context-aware music generation.
        ]]></description>
    </item>
    <item>
        <title>Activation Patching for Interpretable Steering in Music Generation</title>
        <link>https://arxiv.org/abs/2504.04479</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.04479v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Simone Facchiano, Giorgio Strano, Donato Crisostomi, Irene Tallini, Tommaso Mencattini, Fabio Galasso, Emanuele Rodol\`a</dc:creator>
        <description><![CDATA[
            背景：理解大型音频模型如何表示音乐并控制生成具有挑战性且研究不足。方法：受语言模型机制可解释性启发，研究音频领域潜在方向向量，聚焦二元概念，用均值差异法计算引导向量，按系数缩放后注入中间激活层，以调节特定音乐特征。效果：能在保持整体音频质量的同时对音乐特征进行细粒度调节，分析了引导强度影响、比较注入策略并确定关键层，表明基于方向的引导是可控音乐生成更具机制性和可解释性的方法。
            arXiv:2504.04479v1 Announce Type: new 
Abstract: Understanding how large audio models represent music, and using that understanding to steer generation, is both challenging and underexplored. Inspired by mechanistic interpretability in language models, where direction vectors in transformer residual streams are key to model analysis and control, we investigate similar techniques in the audio domain. This paper presents the first study of latent direction vectors in large audio models and their use for continuous control of musical attributes in text-to-music generation. Focusing on binary concepts like tempo (fast vs. slow) and timbre (bright vs. dark), we compute steering vectors using the difference-in-means method on curated prompt sets. These vectors, scaled by a coefficient and injected into intermediate activations, allow fine-grained modulation of specific musical traits while preserving overall audio quality. We analyze the effect of steering strength, compare injection strategies, and identify layers with the greatest influence. Our findings highlight the promise of direction-based steering as a more mechanistic and interpretable approach to controllable music generation.
        ]]></description>
    </item>
    <item>
        <title>Diff-SSL-G-Comp: Towards a Large-Scale and Diverse Dataset for Virtual Analog Modeling</title>
        <link>https://arxiv.org/abs/2504.04589</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.04589v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yicheng Gu, Runsong Zhang, Lauri Juvela, Zhizheng Wu</dc:creator>
        <description><![CDATA[
            背景：基于神经网络的虚拟模拟（VA）建模在音频处理中有潜力，但数据量和多样性不足限制其泛化能力。方法：提出Diff - SSL - G - Comp，首个用于模拟SSL 500 G - Bus压缩器的大规模多样数据集。手动收集175首未混音歌曲，记录220种参数组合下的压缩音频，形成2528小时数据集。还在多种模型上做基准实验和消融研究。效果：证明了数据多样性和数量提升的有效性，数据集及演示见项目页面。
            arXiv:2504.04589v1 Announce Type: new 
Abstract: Virtual Analog (VA) modeling aims to simulate the behavior of hardware circuits via algorithms to replicate their tone digitally. Dynamic Range Compressor (DRC) is an audio processing module that controls the dynamics of a track by reducing and amplifying the volumes of loud and quiet sounds, which is essential in music production. In recent years, neural-network-based VA modeling has shown great potential in producing high-fidelity models. However, due to the lack of data quantity and diversity, their generalization ability in different parameter settings and input sounds is still limited. To tackle this problem, we present Diff-SSL-G-Comp, the first large-scale and diverse dataset for modeling the SSL 500 G-Bus Compressor. Specifically, we manually collected 175 unmastered songs from the Cambridge Multitrack Library. We recorded the compressed audio in 220 parameter combinations, resulting in an extensive 2528-hour dataset with diverse genres, instruments, tempos, and keys. Moreover, to facilitate the use of our proposed dataset, we conducted benchmark experiments in various open-sourced black-box and grey-box models, as well as white-box plugins. We also conducted ablation studies in different data subsets to illustrate the effectiveness of improved data diversity and quantity. The dataset and demos are on our project page: http://www.yichenggu.com/DiffSSLGComp/.
        ]]></description>
    </item>
    <item>
        <title>Unsupervised Estimation of Nonlinear Audio Effects: Comparing Diffusion-Based and Adversarial approaches</title>
        <link>https://arxiv.org/abs/2504.04751</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.04751v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Eloi Moliner, Michal \v{S}vento, Alec Wright, Lauri Juvela, Pavel Rajmic, Vesa V\"alim\"aki</dc:creator>
        <description><![CDATA[
            背景：在无配对输入输出信号情况下准确估计非线性音频效果是难题。方法：本文研究无监督概率方法，引入基于扩散生成模型的盲系统识别方法，还将其与此前提出的对抗方法对比，分析不同效果算子参数化和不同有效录音长度下两种方法的表现。效果：通过吉他失真效果实验，扩散方法结果更稳定、对数据可用性敏感度低，对抗方法在估计更明显失真效果上更优，展示了扩散模型在音乐技术系统识别中的潜力。
            arXiv:2504.04751v1 Announce Type: new 
Abstract: Accurately estimating nonlinear audio effects without access to paired input-output signals remains a challenging problem.This work studies unsupervised probabilistic approaches for solving this task. We introduce a method, novel for this application, based on diffusion generative models for blind system identification, enabling the estimation of unknown nonlinear effects using black- and gray-box models. This study compares this method with a previously proposed adversarial approach, analyzing the performance of both methods under different parameterizations of the effect operator and varying lengths of available effected recordings.Through experiments on guitar distortion effects, we show that the diffusion-based approach provides more stable results and is less sensitive to data availability, while the adversarial approach is superior at estimating more pronounced distortion effects. Our findings contribute to the robust unsupervised blind estimation of audio effects, demonstrating the potential of diffusion models for system identification in music technology.
        ]]></description>
    </item>
    <item>
        <title>One Quantizer is Enough: Toward a Lightweight Audio Codec</title>
        <link>https://arxiv.org/abs/2504.04949</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.04949v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Linwei Zhai, Han Ding, Cui Zhao, fei wang, Ge Wang, Wang Zhi, Wei Xi</dc:creator>
        <description><![CDATA[
            背景：神经音频编解码器能压缩高保真音频并生成离散令牌，但现有方法依赖资源密集型模型和多量化器架构，计算开销大、实际应用受限。方法：提出轻量级神经音频编解码器SQCodec，采用单个量化器，探索简化卷积网络和局部Transformer模块，引入TConv机制捕获多时间尺度声学变化。效果：在不同数据集上实验表明，SQCodec音频质量与多量化器基线相当，单量化器设计适应性更强，轻量级架构使资源消耗降低一个数量级。
            arXiv:2504.04949v1 Announce Type: new 
Abstract: Neural audio codecs have recently gained traction for their ability to compress high-fidelity audio and generate discrete tokens that can be utilized in downstream generative modeling tasks. However, leading approaches often rely on resource-intensive models and multi-quantizer architectures, resulting in considerable computational overhead and constrained real-world applicability. In this paper, we present SQCodec, a lightweight neural audio codec that leverages a single quantizer to address these limitations. SQCodec explores streamlined convolutional networks and local Transformer modules, alongside TConv, a novel mechanism designed to capture acoustic variations across multiple temporal scales, thereby enhancing reconstruction fidelity while reducing model complexity. Extensive experiments across diverse datasets show that SQCodec achieves audio quality comparable to multi-quantizer baselines, while its single-quantizer design offers enhanced adaptability and its lightweight architecture reduces resource consumption by an order of magnitude. The source code is publicly available at https://github.com/zhai-lw/SQCodec.
        ]]></description>
    </item>
    <item>
        <title>P2Mark: Plug-and-play Parameter-intrinsic Watermarking for Neural Speech Generation</title>
        <link>https://arxiv.org/abs/2504.05197</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.05197v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yong Ren, Jiangyan Yi, Tao Wang, Jianhua Tao, Zhengqi Wen, Chenxing Li, Zheng Lian, Ruibo Fu, Ye Bai, Xiaohui Zhang</dc:creator>
        <description><![CDATA[
            背景：开源社区中先进神经语音生成方法增多，增加了防止生成语音滥用和保护版权的难度，以往音频水印易被去除或篡改。方法：提出P2Mark方法，通过训练水印适配器将水印信息以参数形式灵活集成到神经语音生成模型中，而非以特征形式注入。效果：在语音合成的两种主要解码器上验证，在水印提取准确率、不可感知性和鲁棒性方面，与无法用于开源白盒保护场景的先进音频水印方法性能相当。 
            arXiv:2504.05197v1 Announce Type: new 
Abstract: Recently, a large number of advanced neural speech generation methods have emerged in the open-source community. Although this has facilitated the application and development of technology, it has also increased the difficulty of preventing the abuse of generated speech and protecting copyrights. Audio watermarking technology is an effective method for proactively protecting generated speech, but when the source codes and model weights of the neural speech generation methods are open-sourced, audio watermarks based on previous watermarking methods can be easily removed or manipulated. This paper proposes a Plug-and-play Parameter-intrinsic WaterMarking (P2Mark) method for neural speech generation system protection. The main advantage of P2Mark is that the watermark information is flexibly integrated into the neural speech generation model in the form of parameters by training a watermark adapter rather than injecting the watermark into the model in the form of features. After the watermark adapter with the watermark embedding is merged with the pre-trained generation model, the watermark information cannot be easily removed or manipulated. Therefore, P2Mark will be a reliable choice for proactively tracing and protecting the copyrights of neural speech generation models in open-source white-box scenarios. We validated P2Mark on two main types of decoders in neural speech generation: vocoder and codec. Experimental results show that P2Mark achieves performance comparable to state-of-the-art audio watermarking methods that cannot be used for open-source white-box protection scenarios in terms of watermark extraction accuracy, watermark imperceptibility, and robustness.
        ]]></description>
    </item>
    <item>
        <title>Continuous Boostlet Transform and Associated Uncertainty Principles</title>
        <link>https://arxiv.org/abs/2504.03679</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.03679v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Owais Ahmad, Jasifa Fayaz</dc:creator>
        <description><![CDATA[
            背景：经典小波在分析时空信号尤其是声波场时有局限性。方法：提出连续Boostlet变换（CBT），利用庞加莱群和各向同性伸缩来捕捉自然声场的稀疏特征，给出其数学框架及相关不确定性原理。效果：通过常数和指数函数实例体现了CBT的适应性，它在雷达、通信、音频处理等领域有应用，能提供灵活的时频分辨率，适合非平稳和瞬态信号，是现代信号处理的有力工具。
            arXiv:2504.03679v1 Announce Type: cross 
Abstract: The Continuous Boostlet Transform (CBT) is introduced as a powerful tool for analyzing spatiotemporal signals, particularly acoustic wavefields. Overcoming the limitations of classical wavelets, the CBT leverages the Poincar\'e group and isotropic dilations to capture sparse features of natural acoustic fields. This paper presents the mathematical framework of the CBT, including its definition, fundamental properties, and associated uncertainty principles, such as Heisenberg's, logarithmic, Pitt's, and Nazarov's inequalities. These results illuminate the trade-offs between time and frequency localization in the boostlet domain. Practical examples with constant and exponential functions highlight the CBT's adaptability. With applications in radar, communications, audio processing, and seismic analysis, the CBT offers flexible time-frequency resolution, making it ideal for non-stationary and transient signals, and a valuable tool for modern signal processing.
        ]]></description>
    </item>
    <item>
        <title>VocalNet: Speech LLM with Multi-Token Prediction for Faster and High-Quality Generation</title>
        <link>https://arxiv.org/abs/2504.04060</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.04060v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuhao Wang, Heyang Liu, Ziyang Cheng, Ronghua Wu, Qunshan Gu, Yanfeng Wang, Yu Wang</dc:creator>
        <description><![CDATA[
            背景：语音大语言模型是语音处理领域的研究热点。方法：提出VocalNet - 1B和VocalNet - 8B系列高性能、低延迟语音大语言模型，采用可扩展且与模型无关的训练框架；摒弃传统的下一令牌预测，引入多令牌预测优化语音大语言模型，同时提升生成速度和质量。效果：实验显示，VocalNet使用更少训练数据却超越主流Omni大语言模型，大幅领先现有开源语音大语言模型。论文发表后将开源所有模型权重等。
            arXiv:2504.04060v1 Announce Type: cross 
Abstract: Speech large language models (LLMs) have emerged as a prominent research focus in speech processing. We propose VocalNet-1B and VocalNet-8B, a series of high-performance, low-latency speech LLMs enabled by a scalable and model-agnostic training framework for real-time voice interaction. Departing from the conventional next-token prediction (NTP), we introduce multi-token prediction (MTP), a novel approach optimized for speech LLMs that simultaneously improves generation speed and quality. Experiments show that VocalNet outperforms mainstream Omni LLMs despite using significantly less training data, while also surpassing existing open-source speech LLMs by a substantial margin. To support reproducibility and community advancement, we will open-source all model weights, inference code, training data, and framework implementations upon publication.
        ]]></description>
    </item>
    <item>
        <title>FlowMAC: Conditional Flow Matching for Audio Coding at Low Bit Rates</title>
        <link>https://arxiv.org/abs/2409.17635</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2409.17635v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Nicola Pia, Martin Strauss, Markus Multrus, Bernd Edler</dc:creator>
        <description><![CDATA[
            背景：需低比特率下实现高质量通用音频压缩。方法：提出基于条件流匹配（CFM）的新型神经音频编解码器FlowMAC，联合学习梅尔频谱编码器、量化器和解码器，推理时解码器通过常微分方程求解器集成连续归一化流以生成高质量梅尔频谱。效果：主观评估显示，3 kbps的FlowMAC与两倍比特率的先进基于GAN和DDPM的神经音频编解码器质量相当，且推理管道可调，能在保持高感知质量的同时实现CPU实时编码。
            arXiv:2409.17635v2 Announce Type: replace 
Abstract: This paper introduces FlowMAC, a novel neural audio codec for high-quality general audio compression at low bit rates based on conditional flow matching (CFM). FlowMAC jointly learns a mel spectrogram encoder, quantizer and decoder. At inference time the decoder integrates a continuous normalizing flow via an ODE solver to generate a high-quality mel spectrogram. This is the first time that a CFM-based approach is applied to general audio coding, enabling a scalable, simple and memory efficient training. Our subjective evaluations show that FlowMAC at 3 kbps achieves similar quality as state-of-the-art GAN-based and DDPM-based neural audio codecs at double the bit rate. Moreover, FlowMAC offers a tunable inference pipeline, which permits to trade off complexity and quality. This enables real-time coding on CPU, while maintaining high perceptual quality.
        ]]></description>
    </item>
    <item>
        <title>Tell What You Hear From What You See -- Video to Audio Generation Through Text</title>
        <link>https://arxiv.org/abs/2411.05679</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2411.05679v3</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 08 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiulong Liu, Kun Su, Eli Shlizerman</dc:creator>
        <description><![CDATA[
            背景：视频到音频生成任务缺乏对生成音频的控制方法。方法：提出多模态生成框架VATT，输入视频和可选文本提示，生成音频及可选文本描述。它包含VATT Converter和VATT Audio两个关键模块，音频令牌通过预训练神经编解码器转换为波形。效果：客观指标显示，无音频字幕时性能有竞争力，提供字幕提示时表现更优，KLD分数低至1.41；主观研究表明其生成音频更受青睐，可实现可控生成及字幕提示。
            arXiv:2411.05679v3 Announce Type: replace-cross 
Abstract: The content of visual and audio scenes is multi-faceted such that a video can be paired with various audio and vice-versa. Thereby, in video-to-audio generation task, it is imperative to introduce steering approaches for controlling the generated audio. While Video-to-Audio generation is a well-established generative task, existing methods lack such controllability. In this work, we propose VATT, a multi-modal generative framework that takes a video and an optional text prompt as input, and generates audio and optional textual description of the audio. Such a framework has two advantages: i) Video-to-Audio generation process can be refined and controlled via text which complements the context of visual information, and ii) The model can suggest what audio to generate for the video by generating audio captions. VATT consists of two key modules: VATT Converter, a LLM that is fine-tuned for instructions and includes a projection layer that maps video features to the LLM vector space; and VATT Audio, a transformer that generates audio tokens from visual frames and from optional text prompt using iterative parallel decoding. The audio tokens are converted to a waveform by pretrained neural codec. Experiments show that when VATT is compared to existing video-to-audio generation methods in objective metrics, it achieves competitive performance when the audio caption is not provided. When the audio caption is provided as a prompt, VATT achieves even more refined performance (lowest KLD score of 1.41). Furthermore, subjective studies show that VATT Audio has been chosen as preferred generated audio than audio generated by existing methods. VATT enables controllable video-to-audio generation through text as well as suggesting text prompts for videos through audio captions, unlocking novel applications such as text-guided video-to-audio generation and video-to-audio captioning.
        ]]></description>
    </item>
</channel>
</rss>