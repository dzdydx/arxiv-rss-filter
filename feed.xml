<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
<channel>
    <title>arXiv Paper Filter</title>
    <link>https://github.com/dzdydx/arxiv_filter</link>
    <description>根据研究兴趣筛选的arXiv论文</description>
    <atom:link href="https://raw.githubusercontent.com/dzdydx/arxiv_filter/main/feed.xml" rel="self" type="application/rss+xml" />
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>zh-CN</language>
    <lastBuildDate>Thu, 03 Apr 2025 23:03:17 +0800</lastBuildDate>
    <managingEditor>dzdydx@github.com</managingEditor>
    <pubDate>Thu, 03 Apr 2025 23:03:17 +0800</pubDate>
    <skipDays>
        <day>Saturday</day>
        <day>Sunday</day>
    </skipDays>

    <item>
        <title>ffstruc2vec: Flat, Flexible and Scalable Learning of Node Representations from Structural Identities</title>
        <link>https://arxiv.org/abs/2504.01122</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.01122v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mario Heidrich, Jeffrey Heidemann, R\"udiger Buchkremer, Gonzalo Wandosell Fern\'andez de Bobadilla</dc:creator>
        <description><![CDATA[
            背景：节点嵌入需在保留节点特定属性的同时生成低维向量表示，现有方法在保留下游任务所需结构模式时缺乏灵活性。方法：提出ffstruc2vec，一种可扩展的深度学习框架，其扁平高效架构能灵活捕捉多种结构模式。效果：在实际应用的无监督和有监督任务中显著优于现有方法，还能通过量化结构模式对任务结果的影响实现可解释性，具有高灵活性、可扩展性和结构可解释性。
            arXiv:2504.01122v1 Announce Type: new 
Abstract: Node embedding refers to techniques that generate low-dimensional vector representations of nodes in a graph while preserving specific properties of the nodes. A key challenge in the field is developing scalable methods that can preserve structural properties suitable for the required types of structural patterns of a given downstream application task. While most existing methods focus on preserving node proximity, those that do preserve structural properties often lack the flexibility to preserve various types of structural patterns required by downstream application tasks. This paper introduces ffstruc2vec, a scalable deep-learning framework for learning node embedding vectors that preserve structural identities. Its flat, efficient architecture allows high flexibility in capturing diverse types of structural patterns, enabling broad adaptability to various downstream application tasks. The proposed framework significantly outperforms existing approaches across diverse unsupervised and supervised tasks in practical applications. Moreover, ffstruc2vec enables explainability by quantifying how individual structural patterns influence task outcomes, providing actionable interpretation. To our knowledge, no existing framework combines this level of flexibility, scalability, and structural interpretability, underscoring its unique capabilities.
        ]]></description>
    </item>
    <item>
        <title>Dynamic Graph Structure Estimation for Learning Multivariate Point Process using Spiking Neural Networks</title>
        <link>https://arxiv.org/abs/2504.01246</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.01246v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Biswadeep Chakraborty, Hemant Kumawat, Beomseok Kang, Saibal Mukhopadhyay</dc:creator>
        <description><![CDATA[
            背景：在神经科学、流行病学等领域，对时间点过程（TPPs）建模和预测至关重要。方法：提出尖峰动态图网络（SDGN），利用尖峰神经网络（SNNs）的时间处理能力和尖峰时间依赖可塑性（STDP）动态估计潜在的时空功能图，直接从事件数据学习动态时空依赖。效果：在合成和真实数据集上评估显示，SDGN预测准确性更高且保持计算效率，不过在处理稠密图和特定非高斯依赖有局限。
            arXiv:2504.01246v1 Announce Type: new 
Abstract: Modeling and predicting temporal point processes (TPPs) is critical in domains such as neuroscience, epidemiology, finance, and social sciences. We introduce the Spiking Dynamic Graph Network (SDGN), a novel framework that leverages the temporal processing capabilities of spiking neural networks (SNNs) and spike-timing-dependent plasticity (STDP) to dynamically estimate underlying spatio-temporal functional graphs. Unlike existing methods that rely on predefined or static graph structures, SDGN adapts to any dataset by learning dynamic spatio-temporal dependencies directly from the event data, enhancing generalizability and robustness. While SDGN offers significant improvements over prior methods, we acknowledge its limitations in handling dense graphs and certain non-Gaussian dependencies, providing opportunities for future refinement. Our evaluations, conducted on both synthetic and real-world datasets including NYC Taxi, 911, Reddit, and Stack Overflow, demonstrate that SDGN achieves superior predictive accuracy while maintaining computational efficiency. Furthermore, we include ablation studies to highlight the contributions of its core components.
        ]]></description>
    </item>
    <item>
        <title>Scaling Test-Time Inference with Policy-Optimized, Dynamic Retrieval-Augmented Generation via KV Caching and Decoding</title>
        <link>https://arxiv.org/abs/2504.01281</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.01281v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sakhinana Sagar Srinivas, Venkataramana Runkana</dc:creator>
        <description><![CDATA[
            背景：提升检索增强生成（RAG）系统性能，解决大语言模型在知识密集型任务中的问题。方法：提出综合框架，集成策略优化检索增强生成（PORAG）和自适应令牌层注意力评分（ATLAS），还提出CRITIC压缩键值缓存，结合测试时扩展技术与优化解码策略。效果：实验表明，该框架减少幻觉，增强特定领域推理能力，相比传统RAG系统，在效率和可扩展性上有显著提升，提高了输出准确性和响应质量。 
            arXiv:2504.01281v1 Announce Type: new 
Abstract: We present a comprehensive framework for enhancing Retrieval-Augmented Generation (RAG) systems through dynamic retrieval strategies and reinforcement fine-tuning. This approach significantly improves large language models on knowledge-intensive tasks, including opendomain question answering and complex reasoning. Our framework integrates two complementary techniques: Policy-Optimized RetrievalAugmented Generation (PORAG), which optimizes the use of retrieved information, and Adaptive Token-Layer Attention Scoring (ATLAS), which dynamically determines retrieval timing and content based on contextual needs. Together, these techniques enhance both the utilization and relevance of retrieved content, improving factual accuracy and response quality. Designed as a lightweight solution compatible with any Transformer-based LLM without requiring additional training, our framework excels in knowledge-intensive tasks, boosting output accuracy in RAG settings. We further propose CRITIC, a novel method to selectively compress key-value caches by token importance, mitigating memory bottlenecks in long-context applications. The framework also incorporates test-time scaling techniques to dynamically balance reasoning depth and computational resources, alongside optimized decoding strategies for faster inference. Experiments on benchmark datasets show that our framework reduces hallucinations, strengthens domain-specific reasoning, and achieves significant efficiency and scalability gains over traditional RAG systems. This integrated approach advances the development of robust, efficient, and scalable RAG systems across diverse applications.
        ]]></description>
    </item>
    <item>
        <title>ThinkPrune: Pruning Long Chain-of-Thought of LLMs via Reinforcement Learning</title>
        <link>https://arxiv.org/abs/2504.01296</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.01296v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Bairu Hou, Yang Zhang, Jiabao Ji, Yujian Liu, Kaizhi Qian, Jacob Andreas, Shiyu Chang</dc:creator>
        <description><![CDATA[
            背景：长思维大语言模型常产生低效冗余的思维过程，现有减少思维长度的方法未让模型优化整合思维过程，长度 - 性能权衡欠佳。方法：提出ThinkPrune，通过强化学习训练长思维大语言模型，设置令牌限制，超出则无奖励，还采用迭代长度修剪方法，逐步收紧令牌限制。效果：在AIME24数据集上，DeepSeek - R1 - Distill - Qwen - 1.5B推理长度减半，性能仅下降2%，且能绕过不必要步骤，保持核心推理完整。
            arXiv:2504.01296v1 Announce Type: new 
Abstract: We present ThinkPrune, a simple yet effective method for pruning the thinking length for long-thinking LLMs, which has been found to often produce inefficient and redundant thinking processes. Existing preliminary explorations of reducing thinking length primarily focus on forcing the thinking process to early exit, rather than adapting the LLM to optimize and consolidate the thinking process, and therefore the length-performance tradeoff observed so far is sub-optimal. To fill this gap, ThinkPrune offers a simple solution that continuously trains the long-thinking LLMs via reinforcement learning (RL) with an added token limit, beyond which any unfinished thoughts and answers will be discarded, resulting in a zero reward. To further preserve model performance, we introduce an iterative length pruning approach, where multiple rounds of RL are conducted, each with an increasingly more stringent token limit. We observed that ThinkPrune results in a remarkable performance-length tradeoff -- on the AIME24 dataset, the reasoning length of DeepSeek-R1-Distill-Qwen-1.5B can be reduced by half with only 2% drop in performance. We also observed that after pruning, the LLMs can bypass unnecessary steps while keeping the core reasoning process complete. Code is available at https://github.com/UCSB-NLP-Chang/ThinkPrune.
        ]]></description>
    </item>
    <item>
        <title>Biomedical Question Answering via Multi-Level Summarization on a Local Knowledge Graph</title>
        <link>https://arxiv.org/abs/2504.01309</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.01309v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Lingxiao Guan, Yuanhao Huang, Jie Liu</dc:creator>
        <description><![CDATA[
            背景：在问答任务中，检索增强生成（RAG）虽提升了多领域表现，但如何有效捕捉多文档关系，对生物医学任务尤为关键，仍是待解问题。方法：提出利用命题声明从检索文档构建局部知识图谱，再通过分层总结从知识图谱获取摘要，为小型语言模型提供上下文以进行问答。效果：在多个生物医学问答基准测试中，该方法表现与RAG基线相当或更优，经针对性指标评估，各步骤均有效。
            arXiv:2504.01309v1 Announce Type: new 
Abstract: In Question Answering (QA), Retrieval Augmented Generation (RAG) has revolutionized performance in various domains. However, how to effectively capture multi-document relationships, particularly critical for biomedical tasks, remains an open question. In this work, we propose a novel method that utilizes propositional claims to construct a local knowledge graph from retrieved documents. Summaries are then derived via layerwise summarization from the knowledge graph to contextualize a small language model to perform QA. We achieved comparable or superior performance with our method over RAG baselines on several biomedical QA benchmarks. We also evaluated each individual step of our methodology over a targeted set of metrics, demonstrating its effectiveness.
        ]]></description>
    </item>
    <item>
        <title>Adaptive Rectification Sampling for Test-Time Compute Scaling</title>
        <link>https://arxiv.org/abs/2504.01317</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.01317v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhendong Tan, Xingjun Zhang, Chaoyi Hu, Yancheng Pan, Shaoxun Wang</dc:creator>
        <description><![CDATA[
            背景：现有测试时间缩放方法生成思维链时，自校正虽能提升性能，但可能造成令牌浪费、降低可读性。方法：提出自适应校正采样（AR - Sampling），利用过程监督奖励模型作为验证器，构建触发语句引导大语言模型在适当步骤自校正。效果：在GSM8K和MATH500上实验表明，该方法能让模型更细粒度地重新思考，提高解答准确率，且生成合理数量的额外令牌。
            arXiv:2504.01317v1 Announce Type: new 
Abstract: The newly released OpenAI-o1 and DeepSeek-R1 have demonstrated that test-time scaling can significantly improve model performance, especially in complex tasks such as logical reasoning. Common test-time scaling methods involve generating more chain of thoughts (CoTs) or longer CoTs with self-correction. However, while self-correction can improve performance, it may lead to significant token waste and reduce readability of the CoT if the reasoning steps are already correct. To demonstrate that large language models (LLMs) can rectify errors at a more fine-grained level, we propose Adaptive Rectification Sampling (AR-Sampling), which can guide the LLMs to self-correction at the appropriate step. AR-Sampling leverages a process-supervised reward model (PRM) as a verifier and constructed trigger sentences to guide the model in adaptive step-level rethinking. Through the experiments on GSM8K and MATH500, it indicate that our approach enables the models to rethink in more fine-grained level, improving the accuracy of solutions, while generating a reasonable number of additional tokens.
        ]]></description>
    </item>
    <item>
        <title>GTR: Graph-Table-RAG for Cross-Table Question Answering</title>
        <link>https://arxiv.org/abs/2504.01346</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.01346v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiaru Zou, Dongqi Fu, Sirui Chen, Xinrui He, Zihao Li, Yada Zhu, Jiawei Han, Jingrui He</dc:creator>
        <description><![CDATA[
            背景：大量知识存于表格，现实中用户常需跨表检索答案，GraphRAG在跨表问答中有潜力但数据不足。方法：引入含60k表格和25k用户查询的多表基准MutliTableQA，提出Graph - Table - RAG框架GTR，将表格语料重组为异构图，用粗细结合检索提取相关表格，结合图感知提示用于下游大模型表格推理。效果：实验表明GTR跨表问答性能优越，部署效率高，有实际应用价值。
            arXiv:2504.01346v1 Announce Type: new 
Abstract: Beyond pure text, a substantial amount of knowledge is stored in tables. In real-world scenarios, user questions often require retrieving answers that are distributed across multiple tables. GraphRAG has recently attracted much attention for enhancing LLMs' reasoning capabilities by organizing external knowledge to address ad-hoc and complex questions, exemplifying a promising direction for cross-table question answering. In this paper, to address the current gap in available data, we first introduce a multi-table benchmark, MutliTableQA, comprising 60k tables and 25k user queries collected from real-world sources. Then, we propose the first Graph-Table-RAG framework, namely GTR, which reorganizes table corpora into a heterogeneous graph, employs a hierarchical coarse-to-fine retrieval process to extract the most relevant tables, and integrates graph-aware prompting for downstream LLMs' tabular reasoning. Extensive experiments show that GTR exhibits superior cross-table question-answering performance while maintaining high deployment efficiency, demonstrating its real-world practical applicability.
        ]]></description>
    </item>
    <item>
        <title>Refining Interactions: Enhancing Anisotropy in Graph Neural Networks with Language Semantics</title>
        <link>https://arxiv.org/abs/2504.01429</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.01429v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhaoxing Li, Xiaoming Zhang, Haifeng Zhang, Chengxiang Liu</dc:creator>
        <description><![CDATA[
            背景：大语言模型（LLMs）与图神经网络（GNNs）结合可提升文本属性图（TAGs）能力，但现有方法将图结构文本描述直接输入LLMs，使其将结构信息视为普通上下文文本，限制了图相关任务效果。方法：提出LanSAGNN框架，将各向异性GNNs概念拓展到自然语言层面，利用LLMs为节点对提取定制语义信息，还提出高效双层LLMs微调架构使输出与图任务更好对齐。效果：显著提升现有基于LLM方法效果，不增加复杂度，且抗干扰鲁棒性强。
            arXiv:2504.01429v1 Announce Type: new 
Abstract: The integration of Large Language Models (LLMs) with Graph Neural Networks (GNNs) has recently been explored to enhance the capabilities of Text Attribute Graphs (TAGs). Most existing methods feed textual descriptions of the graph structure or neighbouring nodes' text directly into LLMs. However, these approaches often cause LLMs to treat structural information simply as general contextual text, thus limiting their effectiveness in graph-related tasks. In this paper, we introduce LanSAGNN (Language Semantic Anisotropic Graph Neural Network), a framework that extends the concept of anisotropic GNNs to the natural language level. This model leverages LLMs to extract tailor-made semantic information for node pairs, effectively capturing the unique interactions within node relationships. In addition, we propose an efficient dual-layer LLMs finetuning architecture to better align LLMs' outputs with graph tasks. Experimental results demonstrate that LanSAGNN significantly enhances existing LLM-based methods without increasing complexity while also exhibiting strong robustness against interference.
        ]]></description>
    </item>
    <item>
        <title>CASCADE Your Datasets for Cross-Mode Knowledge Retrieval of Language Models</title>
        <link>https://arxiv.org/abs/2504.01450</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.01450v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Runlong Zhou, Yi Zhang</dc:creator>
        <description><![CDATA[
            背景：语言模型在跨模式知识检索方面存在困难，在不同格式下检索知识时准确率显著降低。方法：先探究数据集重写方案，发现有效跨模式检索需大量重写工作；提出CASCADE预训练算法，利用不同序列长度的级联数据集捕获不同尺度知识。效果：实验表明，即便用统一损失函数压缩成单模型，CASCADE也优于数据集重写方法，提升了语言模型跨格式获取知识的能力。
            arXiv:2504.01450v1 Announce Type: new 
Abstract: Language models often struggle with cross-mode knowledge retrieval -- the ability to access knowledge learned in one format (mode) when queried in another. We demonstrate that models trained on multiple data sources (e.g., Wikipedia and TinyStories) exhibit significantly reduced accuracy when retrieving knowledge in a format different from its original training mode. This paper quantitatively investigates this phenomenon through a controlled study of random token sequence memorization across different modes. We first explore dataset rewriting as a solution, revealing that effective cross-mode retrieval requires prohibitively extensive rewriting efforts that follow a sigmoid-like relationship. As an alternative, we propose CASCADE, a novel pretraining algorithm that uses cascading datasets with varying sequence lengths to capture knowledge at different scales. Our experiments demonstrate that CASCADE outperforms dataset rewriting approaches, even when compressed into a single model with a unified loss function. This work provides both qualitative evidence of cross-mode retrieval limitations and a practical solution to enhance language models' ability to access knowledge independently of its presentational format.
        ]]></description>
    </item>
    <item>
        <title>Enhanced Cross-modal 3D Retrieval via Tri-modal Reconstruction</title>
        <link>https://arxiv.org/abs/2504.01476</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.01476v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Junlong Ren, Hao Wang</dc:creator>
        <description><![CDATA[
            跨模态3D检索是关键且具挑战的任务，现有方法多依赖单一3D表示，未充分利用2D - 3D关系，限制了性能。本文提出用多视图图像和点云共同表示3D形状，实现三模态（图像、点、文本）对齐。引入三模态重建提升编码器泛化能力，在文本特征引导下相互重建图像和点特征。通过细粒度2D - 3D融合聚合特征，采用难负样本对比训练。在Text2Shape数据集上，该方法在形状到文本和文本到形状检索任务中大幅超越现有最优方法。
            arXiv:2504.01476v1 Announce Type: new 
Abstract: Cross-modal 3D retrieval is a critical yet challenging task, aiming to achieve bi-directional retrieval between 3D and text modalities. Current methods predominantly rely on a certain 3D representation (e.g., point cloud), with few exploiting the 2D-3D consistency and complementary relationships, which constrains their performance. To bridge this gap, we propose to adopt multi-view images and point clouds to jointly represent 3D shapes, facilitating tri-modal alignment (i.e., image, point, text) for enhanced cross-modal 3D retrieval. Notably, we introduce tri-modal reconstruction to improve the generalization ability of encoders. Given point features, we reconstruct image features under the guidance of text features, and vice versa. With well-aligned point cloud and multi-view image features, we aggregate them as multimodal embeddings through fine-grained 2D-3D fusion to enhance geometric and semantic understanding. Recognizing the significant noise in current datasets where many 3D shapes and texts share similar semantics, we employ hard negative contrastive training to emphasize harder negatives with greater significance, leading to robust discriminative embeddings. Extensive experiments on the Text2Shape dataset demonstrate that our method significantly outperforms previous state-of-the-art methods in both shape-to-text and text-to-shape retrieval tasks by a substantial margin.
        ]]></description>
    </item>
    <item>
        <title>Multi-Relation Graph-Kernel Strengthen Network for Graph-Level Clustering</title>
        <link>https://arxiv.org/abs/2504.01605</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.01605v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Renda Han, Guangzhen Yao, Wenxin Zhang, Yu Li, Wen Xin, Huajie Lei, Mengfei Li, Zeyu Zhang, Chengze Du, Yahe Tian</dc:creator>
        <description><![CDATA[
            背景：图级聚类是数据挖掘基础任务，但现有深度方法受池化限制难提取复杂图结构特征，传统图核方法难处理多关系数据。方法：提出多关系图核增强网络MGSN，结合多关系建模与图核技术，构建多关系图捕捉节点和图间语义关系，用图核方法提取相似度特征，设计关系感知表示细化策略增强图级特征。效果：在多个基准数据集实验显示，MGSN优于现有方法，为图级聚类建立新范式。
            arXiv:2504.01605v1 Announce Type: new 
Abstract: Graph-level clustering is a fundamental task of data mining, aiming at dividing unlabeled graphs into distinct groups. However, existing deep methods that are limited by pooling have difficulty extracting diverse and complex graph structure features, while traditional graph kernel methods rely on exhaustive substructure search, unable to adaptive handle multi-relational data. This limitation hampers producing robust and representative graph-level embeddings. To address this issue, we propose a novel Multi-Relation Graph-Kernel Strengthen Network for Graph-Level Clustering (MGSN), which integrates multi-relation modeling with graph kernel techniques to fully leverage their respective advantages. Specifically, MGSN constructs multi-relation graphs to capture diverse semantic relationships between nodes and graphs, which employ graph kernel methods to extract graph similarity features, enriching the representation space. Moreover, a relation-aware representation refinement strategy is designed, which adaptively aligns multi-relation information across views while enhancing graph-level features through a progressive fusion process. Extensive experiments on multiple benchmark datasets demonstrate the superiority of MGSN over state-of-the-art methods. The results highlight its ability to leverage multi-relation structures and graph kernel features, establishing a new paradigm for robust graph-level clustering.
        ]]></description>
    </item>
    <item>
        <title>ToM-RL: Reinforcement Learning Unlocks Theory of Mind in Small LLMs</title>
        <link>https://arxiv.org/abs/2504.01698</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.01698v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yi-Long Lu, Chunhui Zhang, Jiajun Song, Lifeng Fan, Wei Wang</dc:creator>
        <description><![CDATA[
            背景：基于规则的强化学习（RL）在大语言模型（LLM）后训练阶段提升了其结构化推理能力，但在社会推理尤其是心智理论（ToM）推理方面效果待探索。方法：研究表明RL能让小规模LLM（0.5B - 7B参数）具备ToM推理能力，用含3200个问题的数据集训练。效果：7B参数的模型在Hi - ToM基准测试中准确率达84.50%，超GPT - 4o和DeepSeek - v3。大模型推理稳定，且基于RL的模型泛化能力强，弥合了LLM结构化问题解决与社会推理的差距。
            arXiv:2504.01698v1 Announce Type: new 
Abstract: Recent advancements in rule-based reinforcement learning (RL), applied during the post-training phase of large language models (LLMs), have significantly enhanced their capabilities in structured reasoning tasks such as mathematics and logical inference. However, the effectiveness of RL in social reasoning, particularly in Theory of Mind (ToM), the ability to infer others' mental states, remains largely unexplored. In this study, we demonstrate that RL methods effectively unlock ToM reasoning capabilities even in small-scale LLMs (0.5B to 7B parameters). Using a modest dataset comprising 3200 questions across diverse scenarios, our RL-trained 7B model achieves 84.50\% accuracy on the Hi-ToM benchmark, surpassing models like GPT-4o and DeepSeek-v3 despite significantly fewer parameters. While smaller models ($\leq$3B parameters) suffer from reasoning collapse, larger models (7B parameters) maintain stable performance through consistent belief tracking. Additionally, our RL-based models demonstrate robust generalization to higher-order, out-of-distribution ToM problems, novel textual presentations, and previously unseen datasets. These findings highlight RL's potential to enhance social cognitive reasoning, bridging the gap between structured problem-solving and nuanced social inference in LLMs.
        ]]></description>
    </item>
    <item>
        <title>LARGE: Legal Retrieval Augmented Generation Evaluation Tool</title>
        <link>https://arxiv.org/abs/2504.01840</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.01840v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Minhu Park, Hongseok Oh, Eunkyung Choi, Wonseok Hwang</dc:creator>
        <description><![CDATA[
            背景：构建检索增强生成（RAG）系统提升大语言模型能力成普遍做法，在法律领域，先前司法判决对决策很重要，但RAG系统整体性能受多种组件影响。方法：提出开源工具LRAGE，用于法律领域RAG系统的整体评估，提供GUI和CLI接口，可探究各组件变化对整体准确性的影响。效果：用多语言法律测试集验证，展示了各组件变化时整体准确性的改变，代码开源。 
            arXiv:2504.01840v1 Announce Type: new 
Abstract: Recently, building retrieval-augmented generation (RAG) systems to enhance the capability of large language models (LLMs) has become a common practice. Especially in the legal domain, previous judicial decisions play a significant role under the doctrine of stare decisis which emphasizes the importance of making decisions based on (retrieved) prior documents. However, the overall performance of RAG system depends on many components: (1) retrieval corpora, (2) retrieval algorithms, (3) rerankers, (4) LLM backbones, and (5) evaluation metrics. Here we propose LRAGE, an open-source tool for holistic evaluation of RAG systems focusing on the legal domain. LRAGE provides GUI and CLI interfaces to facilitate seamless experiments and investigate how changes in the aforementioned five components affect the overall accuracy. We validated LRAGE using multilingual legal benches including Korean (KBL), English (LegalBench), and Chinese (LawBench) by demonstrating how the overall accuracy changes when varying the five components mentioned above. The source code is available at https://github.com/hoorangyee/LRAGE.
        ]]></description>
    </item>
    <item>
        <title>Cross-Lingual Consistency: A Novel Inference Framework for Advancing Reasoning in Large Language Models</title>
        <link>https://arxiv.org/abs/2504.01857</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.01857v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhiwei Yu, Tuo Li, Changhong Wang, Hui Chen, Lang Zhou</dc:creator>
        <description><![CDATA[
            背景：思维链能提升大语言模型推理能力，自一致性可提高性能，但多语言训练语料的语言偏差会导致语义漂移和逻辑不一致。方法：提出跨语言一致性（CLC）框架，通过多数投票集成多语言推理路径提升模型推理能力。效果：在CMATH数据集上，相比传统自一致性方法，DeepSeek - Math - 7B - Instruct等模型绝对准确率分别提升9.5%、6.5%和6.0%；在MGSM数据集上，Gemma2 - 9B - Instruct准确率提升4.1% - 18.5%。
            arXiv:2504.01857v1 Announce Type: new 
Abstract: Chain-of-thought (CoT) has emerged as a critical mechanism for enhancing reasoning capabilities in large language models (LLMs), with self-consistency demonstrating notable promise in boosting performance. However, inherent linguistic biases in multilingual training corpora frequently cause semantic drift and logical inconsistencies, especially in sub-10B parameter LLMs handling complex inference tasks. To overcome these constraints, we propose the Cross-Lingual Consistency (CLC) framework, an innovative inference paradigm that integrates multilingual reasoning paths through majority voting to elevate LLMs' reasoning capabilities. Empirical evaluations on the CMATH dataset reveal CLC's superiority over the conventional self-consistency method, delivering 9.5%, 6.5%, and 6.0% absolute accuracy gains for DeepSeek-Math-7B-Instruct, Qwen2.5-Math-7B-Instruct, and Gemma2-9B-Instruct respectively. Expanding CLC's linguistic scope to 11 diverse languages implies two synergistic benefits: 1) neutralizing linguistic biases in multilingual training corpora through multilingual ensemble voting, 2) escaping monolingual reasoning traps by exploring the broader multilingual solution space. This dual benefits empirically enables more globally optimal reasoning paths compared to monolingual self-consistency baselines, as evidenced by the 4.1%-18.5% accuracy gains using Gemma2-9B-Instruct on the MGSM dataset.
        ]]></description>
    </item>
    <item>
        <title>TransientTables: Evaluating LLMs' Reasoning on Temporally Evolving Semi-structured Tables</title>
        <link>https://arxiv.org/abs/2504.01879</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.01879v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Abhilash Shankarampeta, Harsh Mahajan, Tushar Kataria, Dan Roth, Vivek Gupta</dc:creator>
        <description><![CDATA[
            背景：人类不断有新发现，理解事件的时间序列对推动科学和社会发展至关重要，但大语言模型（LLMs）多在静态数据集上训练，时间推理能力受限。方法：提出包含3971个问题的TRANSIENTTABLES数据集，利用基于模板的问题生成流程借助LLMs优化模板和问题，用先进LLMs建立基线结果作基准，引入基于任务分解的建模策略。效果：新策略有望提升LLM在时间推理任务上的表现。
            arXiv:2504.01879v1 Announce Type: new 
Abstract: Humans continuously make new discoveries, and understanding temporal sequence of events leading to these breakthroughs is essential for advancing science and society. This ability to reason over time allows us to identify future steps and understand the effects of financial and political decisions on our lives. However, large language models (LLMs) are typically trained on static datasets, limiting their ability to perform effective temporal reasoning. To assess the temporal reasoning capabilities of LLMs, we present the TRANSIENTTABLES dataset, which comprises 3,971 questions derived from over 14,000 tables, spanning 1,238 entities across multiple time periods. We introduce a template-based question-generation pipeline that harnesses LLMs to refine both templates and questions. Additionally, we establish baseline results using state-of-the-art LLMs to create a benchmark. We also introduce novel modeling strategies centered around task decomposition, enhancing LLM performance.
        ]]></description>
    </item>
    <item>
        <title>Graphically Speaking: Unmasking Abuse in Social Media with Conversation Insights</title>
        <link>https://arxiv.org/abs/2504.01902</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.01902v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>C\'elia Nouri, Jean-Philippe Cointet, Chlo\'e Clavel</dc:creator>
        <description><![CDATA[
            背景：社交媒体对话中检测辱骂性语言有挑战，传统模型常忽略对话上下文，现有结合上下文的方法表示有限且结果不一致。方法：提出用图神经网络（GNNs）将社交媒体对话建模为图，节点代表评论，边捕捉回复结构，系统研究多种图表示和上下文窗口以确定最优配置。效果：GNN模型优于无上下文基线和线性上下文感知方法，F1分数有显著提升，证明了结构化对话上下文的重要性。
            arXiv:2504.01902v1 Announce Type: new 
Abstract: Detecting abusive language in social media conversations poses significant challenges, as identifying abusiveness often depends on the conversational context, characterized by the content and topology of preceding comments. Traditional Abusive Language Detection (ALD) models often overlook this context, which can lead to unreliable performance metrics. Recent Natural Language Processing (NLP) methods that integrate conversational context often depend on limited and simplified representations, and report inconsistent results. In this paper, we propose a novel approach that utilize graph neural networks (GNNs) to model social media conversations as graphs, where nodes represent comments, and edges capture reply structures. We systematically investigate various graph representations and context windows to identify the optimal configuration for ALD. Our GNN model outperform both context-agnostic baselines and linear context-aware methods, achieving significant improvements in F1 scores. These findings demonstrate the critical role of structured conversational context and establish GNNs as a robust framework for advancing context-aware abusive language detection.
        ]]></description>
    </item>
    <item>
        <title>Review, Refine, Repeat: Understanding Iterative Decoding of AI Agents with Dynamic Evaluation and Selection</title>
        <link>https://arxiv.org/abs/2504.01931</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.01931v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Souradip Chakraborty, Mohammadreza Pourreza, Ruoxi Sun, Yiwen Song, Nino Scherrer, Jindong Gu, Furong Huang, Amrit Singh Bedi, Ahmad Beirami, Hamid Palangi, Tomas Pfister</dc:creator>
        <description><![CDATA[
            背景：AI 代理在复杂多模态应用、结构化生成和战略规划任务中表现不佳，标准微调不实用，Best-of-N 采样缺乏迭代反馈机制。方法：提出迭代代理解码（IAD），结合迭代细化与动态候选评估选择，由验证器引导，优化反馈设计与整合。效果：在 Sketch2Code、Text2SQL 和 Webshop 任务上，IAD 始终优于基线，在 Sketch2Code 和 Text2SQL 上绝对增益 3 - 6%，在 Webshop 上多指标增益 8 - 10%。
            arXiv:2504.01931v1 Announce Type: new 
Abstract: While AI agents have shown remarkable performance at various tasks, they still struggle with complex multi-modal applications, structured generation and strategic planning. Improvements via standard fine-tuning is often impractical, as solving agentic tasks usually relies on black box API access without control over model parameters. Inference-time methods such as Best-of-N (BON) sampling offer a simple yet effective alternative to improve performance. However, BON lacks iterative feedback integration mechanism. Hence, we propose Iterative Agent Decoding (IAD) which combines iterative refinement with dynamic candidate evaluation and selection guided by a verifier. IAD differs in how feedback is designed and integrated, specifically optimized to extract maximal signal from reward scores. We conduct a detailed comparison of baselines across key metrics on Sketch2Code, Text2SQL, and Webshop where IAD consistently outperforms baselines, achieving 3--6% absolute gains on Sketch2Code and Text2SQL (with and without LLM judges) and 8--10% gains on Webshop across multiple metrics. To better understand the source of IAD's gains, we perform controlled experiments to disentangle the effect of adaptive feedback from stochastic sampling, and find that IAD's improvements are primarily driven by verifier-guided refinement, not merely sampling diversity. We also show that both IAD and BON exhibit inference-time scaling with increased compute when guided by an optimal verifier. Our analysis highlights the critical role of verifier quality in effective inference-time optimization and examines the impact of noisy and sparse rewards on scaling behavior. Together, these findings offer key insights into the trade-offs and principles of effective inference-time optimization.
        ]]></description>
    </item>
    <item>
        <title>DeformTime: Capturing Variable Dependencies with Deformable Attention for Time Series Forecasting</title>
        <link>https://arxiv.org/abs/2406.07438</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2406.07438v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuxuan Shu, Vasileios Lampos</dc:creator>
        <description><![CDATA[
            背景：多变量时间序列（MTS）预测中，现有深度学习方法常忽视外生变量对目标内生变量预测的提升作用。方法：提出DeformTime神经网络架构，通过可变形注意力块（DAB）的两个核心操作，即学习不同时间步变量间依赖关系（变量DAB）和保留前一时间步数据的时间依赖关系（时间DAB），还设计输入数据变换以增强学习。效果：在6个MTS数据集上实验，相比之前方法提升了预测准确性，平均降低平均绝对误差7.2%，长预测期表现也稳定。
            arXiv:2406.07438v3 Announce Type: replace 
Abstract: In multivariable time series (MTS) forecasting, existing state-of-the-art deep learning approaches tend to focus on autoregressive formulations and often overlook the potential of using exogenous variables in enhancing the prediction of the target endogenous variable. To address this limitation, we present DeformTime, a neural network architecture that attempts to capture correlated temporal patterns from the input space, and hence, improve forecasting accuracy. It deploys two core operations performed by deformable attention blocks (DABs): learning dependencies across variables from different time steps (variable DAB), and preserving temporal dependencies in data from previous time steps (temporal DAB). Input data transformation is explicitly designed to enhance learning from the deformed series of information while passing through a DAB. We conduct extensive experiments on 6 MTS data sets, using previously established benchmarks as well as challenging infectious disease modelling tasks with more exogenous variables. The results demonstrate that DeformTime improves accuracy against previous competitive methods across the vast majority of MTS forecasting tasks, reducing the mean absolute error by 7.2% on average. Notably, performance gains remain consistent across longer forecasting horizons.
        ]]></description>
    </item>
    <item>
        <title>Open-FinLLMs: Open Multimodal Large Language Models for Financial Applications</title>
        <link>https://arxiv.org/abs/2408.11878</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2408.11878v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jimin Huang, Mengxi Xiao, Dong Li, Zihao Jiang, Yuzhe Yang, Yifei Zhang, Lingfei Qian, Yan Wang, Xueqing Peng, Yang Ren, Ruoyu Xiang, Zhengyu Chen, Xiao Zhang, Yueru He, Weiguang Han, Shunian Chen, Lihang Shen, Daniel Kim, Yangyang Yu, Yupeng Cao, Zhiyang Deng, Haohang Li, Duanyu Feng, Yongfu Dai, VijayaSai Somasundaram, Peng Lu, Guojun Xiong, Zhiwei Liu, Zheheng Luo, Zhiyuan Yao, Ruey-Ling Weng, Meikang Qiu, Kaleb E Smith, Honghai Yu, Yanzhao Lai, Min Peng, Jian-Yun Nie, Jordan W. Suchow, Xiao-Yang Liu, Benyou Wang, Alejandro Lopez-Lira, Qianqian Xie, Sophia Ananiadou, Junichi Tsujii</dc:creator>
        <description><![CDATA[
            背景：现有金融大语言模型受语料稀缺、多模态能力弱和评估范围窄等限制，不适用于实际应用。方法：提出首个开源多模态金融大语言模型Open - FinLLMs，涵盖预训练的FinLLaMA、指令微调的FinLLaMA - Instruct和增强跨模态推理的FinLLaVA。在14个金融任务、30个数据集和4个多模态任务上进行评估，并引入两个新多模态评估数据集。效果：Open - FinLLMs在金融NLP、决策和多模态任务上优于GPT - 4等先进模型。
            arXiv:2408.11878v2 Announce Type: replace 
Abstract: Financial LLMs hold promise for advancing financial tasks and domain-specific applications. However, they are limited by scarce corpora, weak multimodal capabilities, and narrow evaluations, making them less suited for real-world application. To address this, we introduce \textit{Open-FinLLMs}, the first open-source multimodal financial LLMs designed to handle diverse tasks across text, tabular, time-series, and chart data, excelling in zero-shot, few-shot, and fine-tuning settings. The suite includes FinLLaMA, pre-trained on a comprehensive 52-billion-token corpus; FinLLaMA-Instruct, fine-tuned with 573K financial instructions; and FinLLaVA, enhanced with 1.43M multimodal tuning pairs for strong cross-modal reasoning. We comprehensively evaluate Open-FinLLMs across 14 financial tasks, 30 datasets, and 4 multimodal tasks in zero-shot, few-shot, and supervised fine-tuning settings, introducing two new multimodal evaluation datasets. Our results show that Open-FinLLMs outperforms afvanced financial and general LLMs such as GPT-4, across financial NLP, decision-making, and multi-modal tasks, highlighting their potential to tackle real-world challenges. To foster innovation and collaboration across academia and industry, we release all codes (https://anonymous.4open.science/r/PIXIU2-0D70/B1D7/LICENSE) and models under OSI-approved licenses.
        ]]></description>
    </item>
    <item>
        <title>AverageTime: Enhance Long-Term Time Series Forecasting with Simple Averaging</title>
        <link>https://arxiv.org/abs/2412.20727</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2412.20727v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Gaoxiang Zhao, Li Zhou, Xiaoqiang Wang</dc:creator>
        <description><![CDATA[
            背景：长期时间序列预测需有效建模序列和通道内的依赖关系，现有卷积神经网络和线性模型在捕捉复杂通道依赖上不足。方法：提出AverageTime方法，采用混合通道嵌入和平均操作，通过通道映射和结果平均分别捕捉序列和通道相关性，还集成聚类方法加速训练。效果：在真实数据集实验中，AverageTime预测性能超现有模型，效率与轻量级线性模型相当，为长序列建模提供新有效框架。
            arXiv:2412.20727v3 Announce Type: replace 
Abstract: Long-term time series forecasting focuses on leveraging historical data to predict future trends. The core challenge lies in effectively modeling dependencies both within sequences and channels. Convolutional Neural Networks and Linear models often excel in sequence modeling but frequently fall short in capturing complex channel dependencies. In contrast, Transformer-based models, with their attention mechanisms applied to both sequences and channels, have demonstrated strong predictive performance. Our research proposes a new approach for capturing sequence and channel dependencies: AverageTime, an exceptionally simple yet effective structure. By employing mixed channel embedding and averaging operations, AverageTime separately captures correlations for sequences and channels through channel mapping and result averaging. In addition, we integrate clustering methods to further accelerate the model's training process. Experiments on real-world datasets demonstrate that AverageTime surpasses state-of-the-art models in predictive performance while maintaining efficiency comparable to lightweight linear models. This provides a new and effective framework for modeling long time series.
        ]]></description>
    </item>
    <item>
        <title>LR$^2$Bench: Evaluating Long-chain Reflective Reasoning Capabilities of Large Language Models via Constraint Satisfaction Problems</title>
        <link>https://arxiv.org/abs/2502.17848</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.17848v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jianghao Chen, Zhenlin Wei, Zhenjiang Ren, Ziyong Li, Jiajun Zhang</dc:creator>
        <description><![CDATA[
            背景：当前大语言模型虽推理能力提升，但缺乏合适基准评估其反思推理能力。方法：提出LR²Bench基准，含850个样本、六种约束满足问题，涵盖不同约束模式以全面评估。效果：对传统和o1类模型评估发现，先进模型如DeepSeek - R1和OpenAI o1 - preview表现不佳，精确匹配得分仅20.0%和23.6%，表明当前大模型反思推理能力有很大提升空间。
            arXiv:2502.17848v3 Announce Type: replace 
Abstract: Recent progress in o1-like models has significantly enhanced the reasoning abilities of Large Language Models (LLMs), empowering them to tackle increasingly complex tasks through reflection capabilities, such as making assumptions, backtracking, and self-refinement. However, effectively evaluating such reflection capabilities remains challenging due to the lack of appropriate benchmarks. To bridge this gap, we introduce LR$^2$Bench, a novel benchmark designed to evaluate the Long-chain Reflective Reasoning capabilities of LLMs. LR$^2$Bench comprises 850 samples across six Constraint Satisfaction Problems (CSPs) where reflective reasoning is crucial for deriving solutions that meet all given constraints. Each type of task focuses on distinct constraint patterns, such as knowledge-based, logical, and spatial constraints, providing a comprehensive evaluation of diverse problem-solving scenarios. We conduct extensive evaluation on both conventional models and o1-like models. Our experimental results reveal that even the most advanced reasoning-specific models, such as DeepSeek-R1 and OpenAI o1-preview, struggle with tasks in LR$^2$Bench, achieving an average Exact Match score of only 20.0% and 23.6%, respectively. These findings underscore the significant room for improvement in the reflective reasoning capabilities of current LLMs. The leaderboard of our benchmark is available at https://huggingface.co/spaces/UltraRonin/LR2Bench
        ]]></description>
    </item>
    <item>
        <title>TS-RAG: Retrieval-Augmented Generation based Time Series Foundation Models are Stronger Zero-Shot Forecaster</title>
        <link>https://arxiv.org/abs/2503.07649</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.07649v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kanghui Ning, Zijie Pan, Yu Liu, Yushan Jiang, James Y. Zhang, Kashif Rasul, Anderson Schneider, Lintao Ma, Yuriy Nevmyvaka, Dongjin Song</dc:creator>
        <description><![CDATA[
            背景：大语言模型和基础模型用于时间序列预测时，微调大模型泛化性不佳，现有时间序列基础模型缺乏领域适应机制且可解释性有限。方法：提出TS - RAG框架，利用预训练时间序列编码器从知识库检索语义相关序列段，结合上下文模式；开发基于可学习专家混合体的增强模块，动态融合检索模式与输入表示。效果：在七个公开数据集上实现了零样本预测的最优性能，跨领域比现有模型最高提升6.51%，且有良好可解释性。
            arXiv:2503.07649v2 Announce Type: replace 
Abstract: Recently, Large Language Models (LLMs) and Foundation Models (FMs) have become prevalent for time series forecasting tasks. However, fine-tuning large language models (LLMs) for forecasting enables the adaptation to specific domains but may not generalize well across diverse, unseen datasets. Meanwhile, existing time series foundation models (TSFMs) lack inherent mechanisms for domain adaptation and suffer from limited interpretability, making them suboptimal for zero-shot forecasting. To this end, we present TS-RAG, a retrieval-augmented generation based time series forecasting framework that enhances the generalization capability and interpretability of TSFMs. Specifically, TS-RAG leverages pre-trained time series encoders to retrieve semantically relevant time series segments from a dedicated knowledge database, incorporating contextual patterns for the given time series query. Next, we develop a learnable Mixture-of-Experts (MoE)-based augmentation module, which dynamically fuses retrieved time series patterns with the TSFM's representation of the input query, improving forecasting accuracy without requiring task-specific fine-tuning. Thorough empirical studies on seven public benchmark datasets demonstrate that TS-RAG achieves state-of-the-art zero-shot forecasting performance, outperforming TSFMs by up to 6.51% across diverse domains and showcasing desired interpretability.
        ]]></description>
    </item>
    <item>
        <title>Accelerate Parallelizable Reasoning via Parallel Decoding within One Sequence</title>
        <link>https://arxiv.org/abs/2503.20533</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.20533v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yijiong Yu</dc:creator>
        <description><![CDATA[
            背景：当前推理模型虽在复杂任务上精度提升显著，但生成推理序列计算成本高、耗时长。方法：利用部分任务的内在并行性加速推理，当存在多个并行推理分支时，使用特殊注意力掩码，在单个序列中每步解码多个标记，避免额外内存使用。效果：实验表明，该方法在保持答案质量的同时，解码时间加速超100%。
            arXiv:2503.20533v2 Announce Type: replace 
Abstract: Recent advances in reasoning models have demonstrated significant improvements in accuracy, particularly for complex tasks such as mathematical reasoning, by employing detailed and comprehensive reasoning processes. However, generating these lengthy reasoning sequences is computationally expensive and time-consuming. To address this inefficiency, we leverage the inherent parallelizability of certain tasks to accelerate the reasoning process. Specifically, when multiple parallel reasoning branches exist, we decode multiple tokens per step using a specialized attention mask, processing them within a single sequence, avoiding additional memory usage. Experimental results show that our method achieves over 100% speedup in decoding time while maintaining the answer quality.
        ]]></description>
    </item>
    <item>
        <title>VGRP-Bench: Visual Grid Reasoning Puzzle Benchmark for Large Vision-Language Models</title>
        <link>https://arxiv.org/abs/2503.23064</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.23064v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yufan Ren, Konstantinos Tertikas, Shalini Maiti, Junlin Han, Tong Zhang, Sabine S\"usstrunk, Filippos Kokkinos</dc:creator>
        <description><![CDATA[
            背景：大型视觉语言模型（LVLMs）在解谜方面存在困难，现有基准存在评估不系统等问题。方法：提出VGRP - Bench视觉网格推理谜题基准，含20种多样谜题，对现有聊天和推理LVLMs进行实验，还探索两种监督微调策略。效果：实验显示，即使最先进的LVLMs解谜能力也有限；两种微调策略能显著提升在训练谜题上的表现，但对未见过谜题泛化能力有限，该基准将发布以推动相关研究。
            arXiv:2503.23064v2 Announce Type: replace 
Abstract: Large Vision-Language Models (LVLMs) struggle with puzzles, which require precise perception, rule comprehension, and logical reasoning. Assessing and enhancing their performance in this domain is crucial, as it reflects their ability to engage in structured reasoning - an essential skill for real-world problem-solving. However, existing benchmarks primarily evaluate pre-trained models without additional training or fine-tuning, often lack a dedicated focus on reasoning, and fail to establish a systematic evaluation framework. To address these limitations, we introduce VGRP-Bench, a Visual Grid Reasoning Puzzle Benchmark featuring 20 diverse puzzles. VGRP-Bench spans multiple difficulty levels, and includes extensive experiments not only on existing chat LVLMs (e.g., GPT-4o), but also on reasoning LVLMs (e.g., Gemini-Thinking). Our results reveal that even the state-of-the-art LVLMs struggle with these puzzles, highlighting fundamental limitations in their puzzle-solving capabilities. Most importantly, through systematic experiments, we identify and analyze key factors influencing LVLMs' puzzle-solving performance, including the number of clues, grid size, and rule complexity. Furthermore, we explore two Supervised Fine-Tuning (SFT) strategies that can be used in post-training: SFT on solutions (S-SFT) and SFT on synthetic reasoning processes (R-SFT). While both methods significantly improve performance on trained puzzles, they exhibit limited generalization to unseen ones. We will release VGRP-Bench to facilitate further research on LVLMs for complex, real-world problem-solving. Project page: https://yufan-ren.com/subpage/VGRP-Bench/.
        ]]></description>
    </item>
    <item>
        <title>Making Large Language Models Better Knowledge Miners for Online Marketing with Progressive Prompting Augmentation</title>
        <link>https://arxiv.org/abs/2312.05276</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2312.05276v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chunjing Gan, Dan Yang, Binbin Hu, Ziqi Liu, Yue Shen, Zhiqiang Zhang, Jinjie Gu, Jun Zhou, Guannan Zhang</dc:creator>
        <description><![CDATA[
            背景：移动经济发展推动线上营销繁荣，营销知识图谱是用户偏好与营销活动匹配的关键。但用大语言模型构建营销知识图谱存在关系生成难控、单提示能力不足、部署成本高等问题。方法：提出PAIR框架，用知识赋能提示技术将关系生成转为自适应过滤，用渐进提示增强实体扩展，再综合考虑一致性和语义相关性聚合；还推出LightPAIR，用强教师模型的高质量语料微调。效果：实验和应用验证了（Light）PAIR的有效性。
            arXiv:2312.05276v2 Announce Type: replace-cross 
Abstract: Nowadays, the rapid development of mobile economy has promoted the flourishing of online marketing campaigns, whose success greatly hinges on the efficient matching between user preferences and desired marketing campaigns where a well-established Marketing-oriented Knowledge Graph (dubbed as MoKG) could serve as the critical "bridge" for preference propagation. In this paper, we seek to carefully prompt a Large Language Model (LLM) with domain-level knowledge as a better marketing-oriented knowledge miner for marketing-oriented knowledge graph construction, which is however non-trivial, suffering from several inevitable issues in real-world marketing scenarios, i.e., uncontrollable relation generation of LLMs,insufficient prompting ability of a single prompt, the unaffordable deployment cost of LLMs. To this end, we propose PAIR, a novel Progressive prompting Augmented mIning fRamework for harvesting marketing-oriented knowledge graph with LLMs. In particular, we reduce the pure relation generation to an LLM based adaptive relation filtering process through the knowledge-empowered prompting technique. Next, we steer LLMs for entity expansion with progressive prompting augmentation,followed by a reliable aggregation with comprehensive consideration of both self-consistency and semantic relatedness. In terms of online serving, we specialize in a small and white-box PAIR (i.e.,LightPAIR),which is fine-tuned with a high-quality corpus provided by a strong teacher-LLM. Extensive experiments and practical applications in audience targeting verify the effectiveness of the proposed (Light)PAIR.
        ]]></description>
    </item>
    <item>
        <title>Automate Strategy Finding with LLM in Quant Investment</title>
        <link>https://arxiv.org/abs/2409.06289</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2409.06289v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhizhuo Kou, Holam Yu, Junyu Luo, Jingshu Peng, Lei Chen</dc:creator>
        <description><![CDATA[
            背景：现有金融交易深度学习模型存在不稳定和高不确定性问题，阻碍实际应用。方法：提出新的量化股票投资框架，利用大语言模型从多模态金融数据中挖掘阿尔法因子，结合多智能体架构。框架包含提取预测信号、构建交易智能体池、动态加权三个模块。效果：在中国股市的大量实验表明，该框架在多个金融指标上显著优于现有基线，展现出更好的交易表现和稳定性，为量化投资策略带来提升。 
            arXiv:2409.06289v2 Announce Type: replace-cross 
Abstract: Despite significant progress in deep learning for financial trading, existing models often face instability and high uncertainty, hindering their practical application. Leveraging advancements in Large Language Models (LLMs) and multi-agent architectures, we propose a novel framework for quantitative stock investment in portfolio management and alpha mining. Our framework addresses these issues by integrating LLMs to generate diversified alphas and employing a multi-agent approach to dynamically evaluate market conditions. This paper proposes a framework where large language models (LLMs) mine alpha factors from multimodal financial data, ensuring a comprehensive understanding of market dynamics. The first module extracts predictive signals by integrating numerical data, research papers, and visual charts. The second module uses ensemble learning to construct a diverse pool of trading agents with varying risk preferences, enhancing strategy performance through a broader market analysis. In the third module, a dynamic weight-gating mechanism selects and assigns weights to the most relevant agents based on real-time market conditions, enabling the creation of an adaptive and context-aware composite alpha formula. Extensive experiments on the Chinese stock markets demonstrate that this framework significantly outperforms state-of-the-art baselines across multiple financial metrics. The results underscore the efficacy of combining LLM-generated alphas with a multi-agent architecture to achieve superior trading performance and stability. This work highlights the potential of AI-driven approaches in enhancing quantitative investment strategies and sets a new benchmark for integrating advanced machine learning techniques in financial trading can also be applied on diverse markets.
        ]]></description>
    </item>
    <item>
        <title>EditRoom: LLM-parameterized Graph Diffusion for Composable 3D Room Layout Editing</title>
        <link>https://arxiv.org/abs/2410.12836</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.12836v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kaizhi Zheng, Xiaotong Chen, Xuehai He, Jing Gu, Linjie Li, Zhengyuan Yang, Kevin Lin, Jianfeng Wang, Lijuan Wang, Xin Eric Wang</dc:creator>
        <description><![CDATA[
            背景：专业3D软件学习曲线陡峭，管理3D资产耗时，现有语言引导3D场景编辑方法有局限。方法：提出EditRoom框架，利用大语言模型进行指令规划，用基于扩散的方法生成目标场景，支持六种编辑类型；开发自动管道扩充数据集，引入EditRoom - DB用于训练和评估。效果：实验表明该方法在所有指标上均优于其他基线，在语言引导的场景布局编辑中准确性和连贯性更高。
            arXiv:2410.12836v2 Announce Type: replace-cross 
Abstract: Given the steep learning curve of professional 3D software and the time-consuming process of managing large 3D assets, language-guided 3D scene editing has significant potential in fields such as virtual reality, augmented reality, and gaming. However, recent approaches to language-guided 3D scene editing either require manual interventions or focus only on appearance modifications without supporting comprehensive scene layout changes. In response, we propose EditRoom, a unified framework capable of executing a variety of layout edits through natural language commands, without requiring manual intervention. Specifically, EditRoom leverages Large Language Models (LLMs) for command planning and generates target scenes using a diffusion-based method, enabling six types of edits: rotate, translate, scale, replace, add, and remove. To address the lack of data for language-guided 3D scene editing, we have developed an automatic pipeline to augment existing 3D scene synthesis datasets and introduced EditRoom-DB, a large-scale dataset with 83k editing pairs, for training and evaluation. Our experiments demonstrate that our approach consistently outperforms other baselines across all metrics, indicating higher accuracy and coherence in language-guided scene layout editing.
        ]]></description>
    </item>
    <item>
        <title>Learning Graph Quantized Tokenizers</title>
        <link>https://arxiv.org/abs/2410.13798</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.13798v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Limei Wang, Kaveh Hassani, Si Zhang, Dongqi Fu, Baichuan Yuan, Weilin Cong, Zhigang Hua, Hao Wu, Ning Yao, Bo Long</dc:creator>
        <description><![CDATA[
            背景：Transformers是基础模型的骨干架构，特定领域分词器助其适应不同领域，但图的分词器发展滞后。方法：提出GQT，通过多任务图自监督学习将分词器训练与Transformer训练解耦，利用残差向量量化（RVQ）学习分层离散标记。效果：显著降低内存需求、提升泛化能力，结合标记调制后，Transformer编码器在22个基准测试中的20个取得了最优性能，涵盖大规模同构和异构数据集。
            arXiv:2410.13798v2 Announce Type: replace-cross 
Abstract: Transformers serve as the backbone architectures of Foundational Models, where domain-specific tokenizers allow them to adapt to various domains. Graph Transformers (GTs) have recently emerged as leading models in geometric deep learning, outperforming Graph Neural Networks (GNNs) in various graph learning tasks. However, the development of tokenizers for graphs has lagged behind other modalities. To address this, we introduce GQT (\textbf{G}raph \textbf{Q}uantized \textbf{T}okenizer), which decouples tokenizer training from Transformer training by leveraging multi-task graph self-supervised learning, yielding robust and generalizable graph tokens. Furthermore, the GQT utilizes Residual Vector Quantization (RVQ) to learn hierarchical discrete tokens, resulting in significantly reduced memory requirements and improved generalization capabilities. By combining the GQT with token modulation, a Transformer encoder achieves state-of-the-art performance on 20 out of 22 benchmarks, including large-scale homophilic and heterophilic datasets.
        ]]></description>
    </item>
    <item>
        <title>Long-context Protein Language Modeling Using Bidirectional Mamba with Shared Projection Layers</title>
        <link>https://arxiv.org/abs/2411.08909</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2411.08909v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yingheng Wang, Zichen Wang, Gil Sadeh, Luca Zancato, Alessandro Achille, George Karypis, Huzefa Rangwala</dc:creator>
        <description><![CDATA[
            背景：多数蛋白质语言模型基于Transformer架构，在短上下文长度的单个蛋白质上训练，难以处理长蛋白质和蛋白质复合物，也未考虑生物分子相互作用。方法：提出基于选择性结构化状态空间模型BiMamba - S的LC - PLM，用掩码语言建模学习氨基酸标记级别的高质量通用蛋白质表示，还引入图上下文变体LC - PLM - G进行第二阶段训练。效果：与基于Transformer的ESM - 2相比，在100B和1T标记训练时，下游任务分别提升达30%和16%，LC - PLM - G在蛋白质结构和功能预测任务上结果良好。
            arXiv:2411.08909v3 Announce Type: replace-cross 
Abstract: Self-supervised training of language models (LMs) has seen great success for protein sequences in learning meaningful representations and for generative drug design. Most protein LMs are based on the Transformer architecture trained on individual proteins with short context lengths. Such protein LMs cannot extrapolate to longer proteins and protein complexes well. They also fail to account for the underlying biological mechanisms carried out by biomolecular interactions and dynamics i.e., proteins often interact with other proteins, molecules, and pathways in complex biological systems. In this work, we propose LC-PLM based on an alternative protein LM architecture, BiMamba-S, built upon selective structured state-space models, to learn high-quality universal protein representations at the amino acid token level using masked language modeling. We also introduce its graph-contextual variant, LC-PLM, which contextualizes protein-protein interaction (PPI) graphs for a second stage of training. LC-PLM demonstrates favorable neural scaling laws, better length extrapolation capability, and up to 30% and 16% improvements on protein downstream tasks compared to Transformer-based ESM-2 when trained with 100B and 1T tokens, respectively. LC-PLM-G further trained within the context of PPI graphs shows promising results on protein structure and function prediction tasks. Our study demonstrates the benefit of increasing the context size with computationally efficient LM architecture (e.g., structured state space models) in learning universal protein representations and incorporating molecular interaction contexts contained in biological graphs.
        ]]></description>
    </item>
    <item>
        <title>Multilingual and Multi-Accent Jailbreaking of Audio LLMs</title>
        <link>https://arxiv.org/abs/2504.01094</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.01094v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jaechul Roh, Virat Shejwalkar, Amir Houmansadr</dc:creator>
        <description><![CDATA[
            大音频语言模型（LALMs）提升了音频理解能力，但带来音频越狱等安全风险。此前研究多聚焦英文攻击，本文揭示多语言多口音音频越狱漏洞更严重。提出Multi - AudioJail框架，构建多语言多口音音频越狱提示数据集，采用分层评估流程。研究发现声学扰动与跨语言语音交互使越狱成功率最高提升57.25个百分点，多模态LLMs比单模态更易受攻击，多语言纯音频攻击成功率是纯文本攻击的3.1倍。计划发布数据集以推动跨模态防御研究。
            arXiv:2504.01094v1 Announce Type: new 
Abstract: Large Audio Language Models (LALMs) have significantly advanced audio understanding but introduce critical security risks, particularly through audio jailbreaks. While prior work has focused on English-centric attacks, we expose a far more severe vulnerability: adversarial multilingual and multi-accent audio jailbreaks, where linguistic and acoustic variations dramatically amplify attack success. In this paper, we introduce Multi-AudioJail, the first systematic framework to exploit these vulnerabilities through (1) a novel dataset of adversarially perturbed multilingual/multi-accent audio jailbreaking prompts, and (2) a hierarchical evaluation pipeline revealing that how acoustic perturbations (e.g., reverberation, echo, and whisper effects) interacts with cross-lingual phonetics to cause jailbreak success rates (JSRs) to surge by up to +57.25 percentage points (e.g., reverberated Kenyan-accented attack on MERaLiON). Crucially, our work further reveals that multimodal LLMs are inherently more vulnerable than unimodal systems: attackers need only exploit the weakest link (e.g., non-English audio inputs) to compromise the entire model, which we empirically show by multilingual audio-only attacks achieving 3.1x higher success rates than text-only attacks. We plan to release our dataset to spur research into cross-modal defenses, urging the community to address this expanding attack surface in multimodality as LALMs evolve.
        ]]></description>
    </item>
    <item>
        <title>Token Pruning in Audio Transformers: Optimizing Performance and Decoding Patch Importance</title>
        <link>https://arxiv.org/abs/2504.01690</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.01690v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Taehan Lee, Hyukjun Lee</dc:creator>
        <description><![CDATA[
            背景：Vision Transformers在计算机视觉任务中表现出色，但计算成本高，虽有token pruning技术降成本，用于音频任务有挑战。方法：首次将token pruning应用于基于ViT的音频分类模型，使用Mel谱图，分析模型性能与计算成本的权衡。效果：TopK token pruning可使AudioMAE和AST的MAC操作减少30 - 40%，分类准确率下降不到1%。分析表明，高强度和低强度token对模型都重要，低强度token在通用音频分类任务中作用更关键。
            arXiv:2504.01690v1 Announce Type: new 
Abstract: Vision Transformers (ViTs) have achieved state-of-the-art performance across various computer vision tasks, but their high computational cost remains a challenge. Token pruning has been proposed to reduce this cost by selectively removing less important tokens. While effective in vision tasks by discarding non-object regions, applying this technique to audio tasks presents unique challenges, as distinguishing relevant from irrelevant regions in time-frequency representations is less straightforward. In this study, for the first time, we applied token pruning to ViT-based audio classification models using Mel-spectrograms and analyzed the trade-offs between model performance and computational cost: TopK token pruning can reduce MAC operations of AudioMAE and AST by 30-40%, with less than a 1% drop in classification accuracy. Our analysis reveals that while high-intensity tokens contribute significantly to model accuracy, low-intensity tokens remain important. In particular, they play a more critical role in general audio classification tasks than in speech-specific tasks.
        ]]></description>
    </item>
    <item>
        <title>Chain of Correction for Full-text Speech Recognition with Large Language Models</title>
        <link>https://arxiv.org/abs/2504.01519</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.01519v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhiyuan Tang, Dong Wang, Zhikai Zhou, Yong Liu, Shen Huang, Shidong Shang</dc:creator>
        <description><![CDATA[
            背景：大语言模型（LLMs）用于自动语音识别（ASR）全文纠错受关注，但存在稳定性、可控性等挑战。方法：提出逐段纠错链（CoC），在常规多轮对话格式中，以预识别文本为指导逐段纠错，利用预识别全文作上下文。效果：在开源全文纠错数据集ChFT上微调预训练LLM评估，实验表明CoC能有效纠正ASR全文输出错误，显著优于基线和基准系统，还进一步分析了阈值设置等问题。
            arXiv:2504.01519v1 Announce Type: cross 
Abstract: Full-text error correction with Large Language Models (LLMs) for Automatic Speech Recognition (ASR) has gained increased attention due to its potential to correct errors across long contexts and address a broader spectrum of error types, including punctuation restoration and inverse text normalization. Nevertheless, many challenges persist, including issues related to stability, controllability, completeness, and fluency. To mitigate these challenges, this paper proposes the Chain of Correction (CoC) for full-text error correction with LLMs, which corrects errors segment by segment using pre-recognized text as guidance within a regular multi-turn chat format. The CoC also uses pre-recognized full text for context, allowing the model to better grasp global semantics and maintain a comprehensive overview of the entire content. Utilizing the open-sourced full-text error correction dataset ChFT, we fine-tune a pre-trained LLM to evaluate the performance of the CoC framework. Experimental results demonstrate that the CoC effectively corrects errors in full-text ASR outputs, significantly outperforming baseline and benchmark systems. We further analyze how to set the correction threshold to balance under-correction and over-rephrasing, extrapolate the CoC model on extremely long ASR outputs, and investigate whether other types of information can be employed to guide the error correction process.
        ]]></description>
    </item>
    <item>
        <title>SAV-SE: Scene-aware Audio-Visual Speech Enhancement with Selective State Space Model</title>
        <link>https://arxiv.org/abs/2411.07751</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2411.07751v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xinyuan Qian, Jiaran Gao, Yaodan Zhang, Qiquan Zhang, Hexin Liu, Leibny Paola Garcia, Haizhou Li</dc:creator>
        <description><![CDATA[
            语音增强在诸多应用中至关重要，现有研究多关注面部和唇部动作，在遮挡或相机视角远时效果不佳，且忽略了环境视觉线索。本文提出SAV - SE任务，首次利用同步视频的环境信息辅助识别噪声类型以提升语音增强效果。具体提出VC - S²E方法，结合Conformer和Mamba模块。在MUSIC、AVSpeech和AudioSet数据集实验，结果显示该方法优于其他对比方法，代码将开源。
            arXiv:2411.07751v2 Announce Type: replace 
Abstract: Speech enhancement plays an essential role in various applications, and the integration of visual information has been demonstrated to bring substantial advantages. However, the majority of current research concentrates on the examination of facial and lip movements, which can be compromised or entirely inaccessible in scenarios where occlusions occur or when the camera view is distant. Whereas contextual visual cues from the surrounding environment have been overlooked: for example, when we see a dog bark, our brain has the innate ability to discern and filter out the barking noise. To this end, in this paper, we introduce a novel task, i.e. SAV-SE. To our best knowledge, this is the first proposal to use rich contextual information from synchronized video as auxiliary cues to indicate the type of noise, which eventually improves the speech enhancement performance. Specifically, we propose the VC-S$^2$E method, which incorporates the Conformer and Mamba modules for their complementary strengths. Extensive experiments are conducted on public MUSIC, AVSpeech and AudioSet datasets, where the results demonstrate the superiority of VC-S$^2$E over other competitive methods. We will make the source code publicly available. Project demo page: https://AVSEPage.github.io/
        ]]></description>
    </item>
    <item>
        <title>DGSNA: prompt-based Dynamic Generative Scene-based Noise Addition method</title>
        <link>https://arxiv.org/abs/2411.12363</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2411.12363v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zihao Chen, Zhentao Lin, Bi Zeng, Linyi Huang, Zhi Li, Jia Cai</dc:creator>
        <description><![CDATA[
            背景：为保障语音系统在不同环境可靠运行，现有噪声添加方法对真实噪声场景覆盖有限，且依赖既有场景信息和噪声。方法：提出基于提示的动态生成场景噪声添加方法（DGSNA），将场景信息动态生成（DGSI）与语音场景噪声添加（SNAS）结合，自动将纯净语音转换到不同噪声环境。效果：实验表明，DGSNA显著提升语音识别和关键词检测模型在不同噪声条件下的鲁棒性，相对提升最高达11.21%，还可与其他方法结合提升性能。
            arXiv:2411.12363v2 Announce Type: replace 
Abstract: To ensure the reliable operation of speech systems across diverse environments, noise addition methods have emerged as the prevailing solution. However, existing methods offer limited coverage of real-world noisy scenes and depend on pre-existing scene-based information and noise. This paper presents prompt-based Dynamic Generative Scene-based Noise Addition (DGSNA), a novel noise addition methodology that integrates Dynamic Generation of Scene-based Information (DGSI) with Scene-based Noise Addition for Speech (SNAS). This integration facilitates automated scene-based noise addition by transforming clean speech into various noise environments, thereby providing a more comprehensive and realistic simulation of diverse noise conditions. Experimental results demonstrate that DGSNA significantly enhances the robustness of speech recognition and keyword spotting models across various noise conditions, achieving a relative improvement of up to 11.21%. Furthermore, DGSNA can be effectively integrated with other noise addition methods to enhance performance. Our implementation and demonstrations are available at https://dgsna.github.io.
        ]]></description>
    </item>
    <item>
        <title>Comparative Study of Spike Encoding Methods for Environmental Sound Classification</title>
        <link>https://arxiv.org/abs/2503.11206</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.11206v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Andres Larroza, Javier Naranjo-Alcazar, Vicent Ortiz Castell\'o, Pedro Zuccarello</dc:creator>
        <description><![CDATA[
            背景：尖峰神经网络（SNNs）能降低能耗和计算需求，但需将传统数字传感器数据转换为尖峰序列，且环境声音分类因频率多变等面临挑战，现有尖峰音频编码研究多聚焦语音处理。方法：对常用尖峰编码技术进行全面比较，在ESC - 10数据集上评估其有效性。效果：该研究为环境声音分类中的尖峰编码提供基准，为神经形态音频处理未来研究提供基础参考，助力从业者为实际应用选合适方法。
            arXiv:2503.11206v2 Announce Type: replace 
Abstract: Spiking Neural Networks (SNNs) offer a promising approach to reduce energy consumption and computational demands, making them particularly beneficial for embedded machine learning in edge applications. However, data from conventional digital sensors must first be converted into spike trains to be processed using neuromorphic computing technologies. The classification of environmental sounds presents unique challenges due to the high variability of frequencies, background noise, and overlapping acoustic events. Despite these challenges, most studies on spike-based audio encoding focus on speech processing, leaving non-speech environmental sounds underexplored. In this work, we conduct a comprehensive comparison of widely used spike encoding techniques, evaluating their effectiveness on the ESC-10 dataset. By understanding the impact of encoding choices on environmental sound processing, researchers and practitioners can select the most suitable approach for real-world applications such as smart surveillance, environmental monitoring, and industrial acoustic analysis. This study serves as a benchmark for spike encoding in environmental sound classification, providing a foundational reference for future research in neuromorphic audio processing.
        ]]></description>
    </item>
    <item>
        <title>Large Language Model Can Transcribe Speech in Multi-Talker Scenarios with Versatile Instructions</title>
        <link>https://arxiv.org/abs/2409.08596</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2409.08596v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Lingwei Meng, Shujie Hu, Jiawen Kang, Zhaoqing Li, Yuejiao Wang, Wenxuan Wu, Xixin Wu, Xunying Liu, Helen Meng</dc:creator>
        <description><![CDATA[
            背景：大语言模型（LLMs）在语音相关任务有进展，但在多说话者场景中探索不足。方法：利用WavLM和Whisper编码器提取对说话人特征和语义上下文敏感的多方面语音表示，将其输入用LoRA微调的LLM，实现语音理解和转录。效果：综合实验显示，所提系统MT - LLM在鸡尾酒会场景中有良好表现，凸显了LLM在复杂场景中按用户指令处理语音任务的潜力。代码等资源见https://github.com/cuhealthybrains/MT - LLM。
            arXiv:2409.08596v2 Announce Type: replace-cross 
Abstract: Recent advancements in large language models (LLMs) have revolutionized various domains, bringing significant progress and new opportunities. Despite progress in speech-related tasks, LLMs have not been sufficiently explored in multi-talker scenarios. In this work, we present a pioneering effort to investigate the capability of LLMs in transcribing speech in multi-talker environments, following versatile instructions related to multi-talker automatic speech recognition (ASR), target talker ASR, and ASR based on specific talker attributes such as sex, occurrence order, language, and keyword spoken. Our approach utilizes WavLM and Whisper encoder to extract multi-faceted speech representations that are sensitive to speaker characteristics and semantic context. These representations are then fed into an LLM fine-tuned using LoRA, enabling the capabilities for speech comprehension and transcription. Comprehensive experiments reveal the promising performance of our proposed system, MT-LLM, in cocktail party scenarios, highlighting the potential of LLM to handle speech-related tasks based on user instructions in such complex settings. The code, model, and samples are available at https://github.com/cuhealthybrains/MT-LLM.
        ]]></description>
    </item>
</channel>
</rss>