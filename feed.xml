<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
<channel>
    <title>arXiv Paper Filter</title>
    <link>https://github.com/None/arxiv_filter</link>
    <description>根据研究兴趣筛选的arXiv论文</description>
    <atom:link href="https://raw.githubusercontent.com/None/arxiv_filter/main/feed.xml" rel="self" type="application/rss+xml" />
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>zh-CN</language>
    <lastBuildDate>Thu, 29 May 2025 12:15:01 +0800</lastBuildDate>
    <managingEditor>None@github.com</managingEditor>
    <pubDate>Thu, 29 May 2025 12:15:01 +0800</pubDate>
    <skipDays>
        <day>Saturday</day>
        <day>Sunday</day>
    </skipDays>

    <item>
        <title>The Role of Visualization in LLM-Assisted Knowledge Graph Systems: Effects on User Trust, Exploration, and Workflows</title>
        <link>https://arxiv.org/abs/2505.21512</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.21512v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Harry Li, Gabriel Appleby, Kenneth Alperin, Steven R Gomez, Ashley Suh</dc:creator>
        <description><![CDATA[
            背景：知识图谱强大但难有效探索，大语言模型用于解决此问题，但对其与知识图谱结合如何影响用户信任等缺乏实证研究。方法：开发LinkQ系统，用大语言模型将自然语言问题转为结构化查询，设计五种可视化机制助用户评估查询和响应准确性。效果：14位从业者评估显示，用户易因可视化“帮助”而过度信任输出，不同经验用户工作流不同，凸显盲目信任风险及可视化缓解作用需进一步研究。 
            arXiv:2505.21512v1 Announce Type: new 
Abstract: Knowledge graphs (KGs) are powerful data structures, but exploring them effectively remains difficult for even expert users. Large language models (LLMs) are increasingly used to address this gap, yet little is known empirically about how their usage with KGs shapes user trust, exploration strategies, or downstream decision-making - raising key design challenges for LLM-based KG visual analysis systems. To study these effects, we developed LinkQ, a KG exploration system that converts natural language questions into structured queries with an LLM. We collaborated with KG experts to design five visual mechanisms that help users assess the accuracy of both KG queries and LLM responses: an LLM-KG state diagram that illustrates which stage of the exploration pipeline LinkQ is in, a query editor displaying the generated query paired with an LLM explanation, an entity-relation ID table showing extracted KG entities and relations with semantic descriptions, a query structure graph that depicts the path traversed in the KG, and an interactive graph visualization of query results. From a qualitative evaluation with 14 practitioners, we found that users - even KG experts - tended to overtrust LinkQ's outputs due to its "helpful" visualizations, even when the LLM was incorrect. Users exhibited distinct workflows depending on their prior familiarity with KGs and LLMs, challenging the assumption that these systems are one-size-fits-all - despite often being designed as if they are. Our findings highlight the risks of false trust in LLM-assisted data analysis tools and the need for further investigation into the role of visualization as a mitigation technique.
        ]]></description>
    </item>
    <item>
        <title>More Thinking, Less Seeing? Assessing Amplified Hallucination in Multimodal Reasoning Models</title>
        <link>https://arxiv.org/abs/2505.21523</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.21523v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chengzhi Liu, Zhongxing Xu, Qingyue Wei, Juncheng Wu, James Zou, Xin Eric Wang, Yuyin Zhou, Sheng Liu</dc:creator>
        <description><![CDATA[
            背景：测试时计算使多模态大语言模型能生成更长推理链，在多模态数学推理等任务表现佳，但推理能力提升常伴随幻觉增加。方法：引入量化指标RH - AUC衡量模型感知准确性随推理长度的变化，发布诊断基准RH - Bench评估推理能力和幻觉的权衡。效果：分析发现更大模型在推理和感知间平衡更好，且这种平衡更多受训练数据类型和领域影响，而非总体量，强调需兼顾推理质量和感知保真度的评估框架。
            arXiv:2505.21523v1 Announce Type: new 
Abstract: Test-time compute has empowered multimodal large language models to generate extended reasoning chains, yielding strong performance on tasks such as multimodal math reasoning. However, this improved reasoning ability often comes with increased hallucination: as generations become longer, models tend to drift away from image-grounded content and rely more heavily on language priors. Attention analysis shows that longer reasoning chains lead to reduced focus on visual inputs, which contributes to hallucination. To systematically study this phenomenon, we introduce RH-AUC, a metric that quantifies how a model's perception accuracy changes with reasoning length, allowing us to evaluate whether the model preserves visual grounding during reasoning. We also release RH-Bench, a diagnostic benchmark that spans a variety of multimodal tasks, designed to assess the trade-off between reasoning ability and hallucination. Our analysis reveals that (i) larger models typically achieve a better balance between reasoning and perception, and (ii) this balance is influenced more by the types and domains of training data than by its overall volume. These findings underscore the importance of evaluation frameworks that jointly consider both reasoning quality and perceptual fidelity.
        ]]></description>
    </item>
    <item>
        <title>Image Tokens Matter: Mitigating Hallucination in Discrete Tokenizer-based Large Vision-Language Models via Latent Editing</title>
        <link>https://arxiv.org/abs/2505.21547</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.21547v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Weixing Wang, Zifeng Ding, Jindong Gu, Rui Cao, Christoph Meinel, Gerard de Melo, Haojin Yang</dc:creator>
        <description><![CDATA[
            背景：基于离散图像分词器的大视觉语言模型（LVLMs）虽能统一多模态表示，但仍会产生不存在对象的幻觉。方法：构建图像标记共现图，用图神经网络结合对比学习与聚类方法，对相似视觉上下文中频繁共现的标记分组，发现幻觉与占主导的标记簇有关，提出通过修改潜在图像嵌入抑制视觉缺失标记影响的缓解方法。效果：实验表明该方法在保留表达性的同时减少了幻觉。代码：https://github.com/weixingW/CGC-VTD/tree/main
            arXiv:2505.21547v1 Announce Type: new 
Abstract: Large Vision-Language Models (LVLMs) with discrete image tokenizers unify multimodal representations by encoding visual inputs into a finite set of tokens. Despite their effectiveness, we find that these models still hallucinate non-existent objects. We hypothesize that this may be due to visual priors induced during training: When certain image tokens frequently co-occur in the same spatial regions and represent shared objects, they become strongly associated with the verbalizations of those objects. As a result, the model may hallucinate by evoking visually absent tokens that often co-occur with present ones. To test this assumption, we construct a co-occurrence graph of image tokens using a segmentation dataset and employ a Graph Neural Network (GNN) with contrastive learning followed by a clustering method to group tokens that frequently co-occur in similar visual contexts. We find that hallucinations predominantly correspond to clusters whose tokens dominate the input, and more specifically, that the visually absent tokens in those clusters show much higher correlation with hallucinated objects compared to tokens present in the image. Based on this observation, we propose a hallucination mitigation method that suppresses the influence of visually absent tokens by modifying latent image embeddings during generation. Experiments show our method reduces hallucinations while preserving expressivity. Code is available at https://github.com/weixingW/CGC-VTD/tree/main
        ]]></description>
    </item>
    <item>
        <title>PreGenie: An Agentic Framework for High-quality Visual Presentation Generation</title>
        <link>https://arxiv.org/abs/2505.21660</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.21660v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiaojie Xu, Xinli Xu, Sirui Chen, Haoyu Chen, Fan Zhang, Ying-Cong Chen</dc:creator>
        <description><![CDATA[
            背景：早期用深度学习自动生成可视化演示文稿存在布局组织差、文本摘要不准确、缺乏图像理解等问题，限制其在正式场景应用。方法：提出PreGenie，基于多模态大语言模型的智能模块化框架，依托Slidev框架，分分析与初始生成、审查与重新生成两阶段，各阶段利用多个多模态大模型协作共享信息。效果：实验表明，该框架在多模态理解上表现出色，在美观度和内容一致性上优于现有模型，更贴合人类设计偏好。
            arXiv:2505.21660v1 Announce Type: new 
Abstract: Visual presentations are vital for effective communication. Early attempts to automate their creation using deep learning often faced issues such as poorly organized layouts, inaccurate text summarization, and a lack of image understanding, leading to mismatched visuals and text. These limitations restrict their application in formal contexts like business and scientific research. To address these challenges, we propose PreGenie, an agentic and modular framework powered by multimodal large language models (MLLMs) for generating high-quality visual presentations.
  PreGenie is built on the Slidev presentation framework, where slides are rendered from Markdown code. It operates in two stages: (1) Analysis and Initial Generation, which summarizes multimodal input and generates initial code, and (2) Review and Re-generation, which iteratively reviews intermediate code and rendered slides to produce final, high-quality presentations. Each stage leverages multiple MLLMs that collaborate and share information. Comprehensive experiments demonstrate that PreGenie excels in multimodal understanding, outperforming existing models in both aesthetics and content consistency, while aligning more closely with human design preferences.
        ]]></description>
    </item>
    <item>
        <title>multivariateGPT: a decoder-only transformer for multivariate categorical and numeric data</title>
        <link>https://arxiv.org/abs/2505.21680</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.21680v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Andrew J. Loza, Jun Yup Kim, Shangzheng Song, Yihang Liu, Joseph J. Y. Sung, R Andrew Taylor, Dennis L. Shung</dc:creator>
        <description><![CDATA[
            背景：现实数据常是类别与数值的混合，且记录间隔不规则，现有方法在处理这类数据时有局限。方法：提出multivariateGPT，通过自回归序列分解、嵌入方案和损失函数，将下一个标记预测任务扩展到下一个标记类别和值的联合分布似然估计，以处理混合数据。效果：能有效学习简单物理系统中的模式，对心电图和多变量电子健康记录等复杂时间序列建模，扩展了基于Transformer模型的数据处理范围。
            arXiv:2505.21680v1 Announce Type: new 
Abstract: Real-world processes often generate data that are a mix of categorical and numeric values that are recorded at irregular and informative intervals. Discrete token-based approaches are limited in numeric representation capacity while methods like neural ordinary differential equations are not well suited for categorical data or informative sampling and require augmentation to handle certain classes of trajectories. Here, we present multivariateGPT, a single architecture for modeling sequences of mixed categorical (including tokenized text) and numeric data. This is accomplished with an autoregressive sequence decomposition, embedding scheme, and loss function that extend the next token prediction task to likelihood estimation of the joint distribution of next token class and value. We demonstrate how this approach can efficiently learn to generalize patterns in simple physical systems and model complex time series including electrocardiograms and multivariate electronic health record data. This work extends the utility of transformer based models to additional classes of data.
        ]]></description>
    </item>
    <item>
        <title>MAKIEval: A Multilingual Automatic WiKidata-based Framework for Cultural Awareness Evaluation for LLMs</title>
        <link>https://arxiv.org/abs/2505.21693</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.21693v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Raoyuan Zhao, Beiduo Chen, Barbara Plank, Michael A. Hedderich</dc:creator>
        <description><![CDATA[
            背景：大语言模型多以英语预训练，存在跨语言文化意识差异及输出有偏问题，且综合多语言评估因基准有限和翻译质量存疑而具挑战。方法：提出MAKIEval框架，利用Wikidata多语言结构作跨语言锚点，自动识别模型输出中的文化实体并关联结构化知识，引入四个衡量文化意识的指标。效果：评估了7个来自不同地区的大模型，发现模型在英语中文化意识更强，代码和数据已公开。
            arXiv:2505.21693v1 Announce Type: new 
Abstract: Large language models (LLMs) are used globally across many languages, but their English-centric pretraining raises concerns about cross-lingual disparities for cultural awareness, often resulting in biased outputs. However, comprehensive multilingual evaluation remains challenging due to limited benchmarks and questionable translation quality. To better assess these disparities, we introduce MAKIEval, an automatic multilingual framework for evaluating cultural awareness in LLMs across languages, regions, and topics. MAKIEval evaluates open-ended text generation, capturing how models express culturally grounded knowledge in natural language. Leveraging Wikidata's multilingual structure as a cross-lingual anchor, it automatically identifies cultural entities in model outputs and links them to structured knowledge, enabling scalable, language-agnostic evaluation without manual annotation or translation. We then introduce four metrics that capture complementary dimensions of cultural awareness: granularity, diversity, cultural specificity, and consensus across languages. We assess 7 LLMs developed from different parts of the world, encompassing both open-source and proprietary systems, across 13 languages, 19 countries and regions, and 6 culturally salient topics (e.g., food, clothing). Notably, we find that models tend to exhibit stronger cultural awareness in English, suggesting that English prompts more effectively activate culturally grounded knowledge. We publicly release our code and data.
        ]]></description>
    </item>
    <item>
        <title>Broad Spectrum Structure Discovery in Large-Scale Higher-Order Networks</title>
        <link>https://arxiv.org/abs/2505.21748</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.21748v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>John Hood, Caterina De Bacco, Aaron Schein</dc:creator>
        <description><![CDATA[
            背景：复杂系统中的高阶交互常用超图表示，理解超图中的依赖结构对复杂系统研究至关重要，但因组合复杂性和计算需求面临挑战。方法：引入一类概率模型，将相似单元类视为潜在超图中的节点，通过低秩表示用类间潜在交互建模观测节点交互。效果：相比现有方法，该模型在链接预测上表现更优，能在药理和社交网络等真实系统中发现可解释结构，提升了将大规模高阶数据纳入科研的能力。
            arXiv:2505.21748v1 Announce Type: new 
Abstract: Complex systems are often driven by higher-order interactions among multiple units, naturally represented as hypergraphs. Understanding dependency structures within these hypergraphs is crucial for understanding and predicting the behavior of complex systems but is made challenging by their combinatorial complexity and computational demands. In this paper, we introduce a class of probabilistic models that efficiently represents and discovers a broad spectrum of mesoscale structure in large-scale hypergraphs. The key insight enabling this approach is to treat classes of similar units as themselves nodes in a latent hypergraph. By modeling observed node interactions through latent interactions among classes using low-rank representations, our approach tractably captures rich structural patterns while ensuring model identifiability. This allows for direct interpretation of distinct node- and class-level structures. Empirically, our model improves link prediction over state-of-the-art methods and discovers interpretable structures in diverse real-world systems, including pharmacological and social networks, advancing the ability to incorporate large-scale higher-order data into the scientific process.
        ]]></description>
    </item>
    <item>
        <title>MMTBENCH: A Unified Benchmark for Complex Multimodal Table Reasoning</title>
        <link>https://arxiv.org/abs/2505.21771</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.21771v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Prasham Yatinkumar Titiya, Jainil Trivedi, Chitta Baral, Vivek Gupta</dc:creator>
        <description><![CDATA[
            背景：现实中多模态表格普遍存在，但当前视觉语言模型处理复杂多模态表格推理能力待探索。方法：提出MMTBENCH基准，包含500个来自不同现实来源的多模态表格和4021个问答对，问题涵盖多种类型。效果：对现有模型评估显示存在显著性能差距，尤其在基于视觉推理和多步推理问题上。表明需改进架构，该基准对多模态表格研究有重要价值。
            arXiv:2505.21771v1 Announce Type: new 
Abstract: Multimodal tables those that integrate semi structured data with visual elements such as charts and maps are ubiquitous across real world domains, yet they pose a formidable challenge to current vision language models (VLMs). While Large Language models (LLMs) and VLMs have demonstrated strong capabilities in text and image understanding, their performance on complex, real world multimodal table reasoning remains unexplored. To bridge this gap, we introduce MMTBENCH (Multimodal Table Benchmark), a benchmark consisting of 500 real world multimodal tables drawn from diverse real world sources, with a total of 4021 question answer pairs. MMTBENCH questions cover four question types (Explicit, Implicit, Answer Mention, and Visual Based), five reasoning types (Mathematical, Extrema Identification, Fact Verification, Vision Based, and Others), and eight table types (Single/Multiple Entity, Maps and Charts with Entities, Single/Multiple Charts, Maps, and Visualizations). Extensive evaluation of state of the art models on all types reveals substantial performance gaps, particularly on questions requiring visual-based reasoning and multi-step inference. These findings show the urgent need for improved architectures that more tightly integrate vision and language processing. By providing a challenging, high-quality resource that mirrors the complexity of real-world tasks, MMTBENCH underscores its value as a resource for future research on multimodal tables.
        ]]></description>
    </item>
    <item>
        <title>Born a Transformer -- Always a Transformer?</title>
        <link>https://arxiv.org/abs/2505.21785</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.21785v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yana Veitsman, Mayank Jobanputra, Yash Sarrof, Aleksandra Bakalova, Vera Demberg, Ellie Pavlick, Michael Hahn</dc:creator>
        <description><![CDATA[
            背景：Transformers在建模特定序列到序列任务时有理论限制，其在大规模预训练大语言模型（LLMs）中的影响及LLMs能否克服这些限制尚不明确。方法：研究受Liu等人启发的检索和复制任务，用C - RASP框架提供保障，进行实证观察和机制分析。效果：观察到预训练模型在检索查询令牌右侧（归纳）比左侧（反归纳）的令牌表现更好，经针对性微调且理论保证长度泛化时该不对称性消失，结果表明预训练能增强特定能力，但无法克服基本的长度泛化限制。
            arXiv:2505.21785v1 Announce Type: new 
Abstract: Transformers have theoretical limitations in modeling certain sequence-to-sequence tasks, yet it remains largely unclear if these limitations play a role in large-scale pretrained LLMs, or whether LLMs might effectively overcome these constraints in practice due to the scale of both the models themselves and their pretraining data. We explore how these architectural constraints manifest after pretraining, by studying a family of $\textit{retrieval}$ and $\textit{copying}$ tasks inspired by Liu et al. [2024]. We use the recently proposed C-RASP framework for studying length generalization [Huang et al., 2025b] to provide guarantees for each of our settings. Empirically, we observe an $\textit{induction-versus-anti-induction}$ asymmetry, where pretrained models are better at retrieving tokens to the right (induction) rather than the left (anti-induction) of a query token. This asymmetry disappears upon targeted fine-tuning if length-generalization is guaranteed by theory. Mechanistic analysis reveals that this asymmetry is connected to the differences in the strength of induction versus anti-induction circuits within pretrained Transformers. We validate our findings through practical experiments on real-world tasks demonstrating reliability risks. Our results highlight that pretraining selectively enhances certain Transformer capabilities, but does not overcome fundamental length-generalization limits.
        ]]></description>
    </item>
    <item>
        <title>Multimodal Federated Learning: A Survey through the Lens of Different FL Paradigms</title>
        <link>https://arxiv.org/abs/2505.21792</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.21792v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuanzhe Peng, Jieming Bian, Lei Wang, Yin Huang, Jie Xu</dc:creator>
        <description><![CDATA[
            背景：多模态联邦学习（MFL）结合多模态信息与分布式训练，但缺乏基于不同联邦学习范式的全面分类。多模态数据在不同联邦学习场景带来新挑战。方法：系统研究水平、垂直和混合三种联邦学习范式下的MFL，给出问题公式，回顾代表性训练算法，指出多模态数据在分布式场景的突出挑战。效果：建立分类体系，为理解和推动MFL发展提供新视角，助力解决相关挑战。
            arXiv:2505.21792v1 Announce Type: new 
Abstract: Multimodal Federated Learning (MFL) lies at the intersection of two pivotal research areas: leveraging complementary information from multiple modalities to improve downstream inference performance and enabling distributed training to enhance efficiency and preserve privacy. Despite the growing interest in MFL, there is currently no comprehensive taxonomy that organizes MFL through the lens of different Federated Learning (FL) paradigms. This perspective is important because multimodal data introduces distinct challenges across various FL settings. These challenges, including modality heterogeneity, privacy heterogeneity, and communication inefficiency, are fundamentally different from those encountered in traditional unimodal or non-FL scenarios. In this paper, we systematically examine MFL within the context of three major FL paradigms: horizontal FL (HFL), vertical FL (VFL), and hybrid FL. For each paradigm, we present the problem formulation, review representative training algorithms, and highlight the most prominent challenge introduced by multimodal data in distributed settings. We also discuss open challenges and provide insights for future research. By establishing this taxonomy, we aim to uncover the novel challenges posed by multimodal data from the perspective of different FL paradigms and to offer a new lens through which to understand and advance the development of MFL.
        ]]></description>
    </item>
    <item>
        <title>TabReason: A Reinforcement Learning-Enhanced Reasoning LLM for Explainable Tabular Data Prediction</title>
        <link>https://arxiv.org/abs/2505.21807</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.21807v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tommy Xu, Zhitian Zhang, Xiangyu Sun, Lauren Kelly Zung, Hossein Hajimirsadeghi, Greg Mori</dc:creator>
        <description><![CDATA[
            背景：表格数据预测建模是众多实际应用的基础，现有梯度提升机和深度模型缺乏可解释性，大语言模型在表格数据预测上表现不佳。方法：提出利用基于推理的大语言模型，通过强化学习训练，引入自定义奖励函数，引导模型兼顾预测准确性和可解释性。效果：在金融基准数据集上表现出色，优于多数现有大语言模型。
            arXiv:2505.21807v1 Announce Type: new 
Abstract: Predictive modeling on tabular data is the cornerstone of many real-world applications. Although gradient boosting machines and some recent deep models achieve strong performance on tabular data, they often lack interpretability. On the other hand, large language models (LLMs) have demonstrated powerful capabilities to generate human-like reasoning and explanations, but remain under-performed for tabular data prediction. In this paper, we propose a new approach that leverages reasoning-based LLMs, trained using reinforcement learning, to perform more accurate and explainable predictions on tabular data. Our method introduces custom reward functions that guide the model not only toward high prediction accuracy but also toward human-understandable reasons for its predictions. Experimental results show that our model achieves promising performance on financial benchmark datasets, outperforming most existing LLMs.
        ]]></description>
    </item>
    <item>
        <title>Let Me Think! A Long Chain-of-Thought Can Be Worth Exponentially Many Short Ones</title>
        <link>https://arxiv.org/abs/2505.21825</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.21825v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Parsa Mirtaheri, Ezra Edelman, Samy Jelassi, Eran Malach, Enric Boix-Adsera</dc:creator>
        <description><![CDATA[
            背景：推理时计算是提升大语言模型推理能力的潜在途径，但推理时计算的最优分配尚不明确，如应优先顺序扩展还是并行扩展。方法：基于具有挑战性分布的图的连通性问题，证明在某些推理场景中顺序扩展比并行扩展有指数级优势。效果：通过对一系列语言模型（包括用不同思维链策略从头训练用于图连通性的模型及大型推理模型）进行全面实验，验证了理论发现。 
            arXiv:2505.21825v1 Announce Type: new 
Abstract: Inference-time computation has emerged as a promising scaling axis for improving large language model reasoning. However, despite yielding impressive performance, the optimal allocation of inference-time computation remains poorly understood. A central question is whether to prioritize sequential scaling (e.g., longer chains of thought) or parallel scaling (e.g., majority voting across multiple short chains of thought). In this work, we seek to illuminate the landscape of test-time scaling by demonstrating the existence of reasoning settings where sequential scaling offers an exponential advantage over parallel scaling. These settings are based on graph connectivity problems in challenging distributions of graphs. We validate our theoretical findings with comprehensive experiments across a range of language models, including models trained from scratch for graph connectivity with different chain of thought strategies as well as large reasoning models.
        ]]></description>
    </item>
    <item>
        <title>Beyond Perception: Evaluating Abstract Visual Reasoning through Multi-Stage Task</title>
        <link>https://arxiv.org/abs/2505.21850</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.21850v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yanbei Jiang, Yihao Ding, Chao Lei, Jiayang Ao, Jey Han Lau, Krista A. Ehinger</dc:creator>
        <description><![CDATA[
            背景：当前多模态大语言模型在抽象视觉推理（AVR）方面研究不足，现有AVR基准侧重单步推理，评估指标只关注最终结果。方法：引入基于RAVEN的多阶段AVR基准MultiStAR，用于评估不同复杂度的推理能力；提出考虑中间步骤正确性的新指标MSEval。效果：对17个代表性模型实验显示，现有模型在基础感知任务表现尚可，但在复杂规则检测阶段仍面临挑战。
            arXiv:2505.21850v1 Announce Type: new 
Abstract: Current Multimodal Large Language Models (MLLMs) excel in general visual reasoning but remain underexplored in Abstract Visual Reasoning (AVR), which demands higher-order reasoning to identify abstract rules beyond simple perception. Existing AVR benchmarks focus on single-step reasoning, emphasizing the end result but neglecting the multi-stage nature of reasoning process. Past studies found MLLMs struggle with these benchmarks, but it doesn't explain how they fail. To address this gap, we introduce MultiStAR, a Multi-Stage AVR benchmark, based on RAVEN, designed to assess reasoning across varying levels of complexity. Additionally, existing metrics like accuracy only focus on the final outcomes while do not account for the correctness of intermediate steps. Therefore, we propose a novel metric, MSEval, which considers the correctness of intermediate steps in addition to the final outcomes. We conduct comprehensive experiments on MultiStAR using 17 representative close-source and open-source MLLMs. The results reveal that while existing MLLMs perform adequately on basic perception tasks, they continue to face challenges in more complex rule detection stages.
        ]]></description>
    </item>
    <item>
        <title>Evaluating the Retrieval Robustness of Large Language Models</title>
        <link>https://arxiv.org/abs/2505.21870</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.21870v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Shuyang Cao, Karthik Radhakrishnan, David Rosenberg, Steven Lu, Pengxiang Cheng, Lu Wang, Shiyue Zhang</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）能提升大语言模型解决知识密集型任务的能力，但可能因检索不完美和模型利用检索内容能力有限导致性能下降。方法：聚焦三个研究问题，建立含1500个开放领域问题及对应维基百科检索文档的基准，引入三个对应研究问题的鲁棒性指标。效果：对11个大语言模型和3种提示策略的实验表明，这些模型检索鲁棒性高，但不同程度的不完美阻碍其充分利用RAG优势。
            arXiv:2505.21870v1 Announce Type: new 
Abstract: Retrieval-augmented generation (RAG) generally enhances large language models' (LLMs) ability to solve knowledge-intensive tasks. But RAG may also lead to performance degradation due to imperfect retrieval and the model's limited ability to leverage retrieved content. In this work, we evaluate the robustness of LLMs in practical RAG setups (henceforth retrieval robustness). We focus on three research questions: (1) whether RAG is always better than non-RAG; (2) whether more retrieved documents always lead to better performance; (3) and whether document orders impact results. To facilitate this study, we establish a benchmark of 1500 open-domain questions, each with retrieved documents from Wikipedia. We introduce three robustness metrics, each corresponds to one research question. Our comprehensive experiments, involving 11 LLMs and 3 prompting strategies, reveal that all of these LLMs exhibit surprisingly high retrieval robustness; nonetheless, different degrees of imperfect robustness hinders them from fully utilizing the benefits of RAG.
        ]]></description>
    </item>
    <item>
        <title>Beyond Completion: A Foundation Model for General Knowledge Graph Reasoning</title>
        <link>https://arxiv.org/abs/2505.21926</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.21926v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yin Hua, Zhiqiang Liu, Mingyang Chen, Zheng Fang, Chi Man Wong, Lingxiao Li, Chi Man Vong, Huajun Chen, Wen Zhang</dc:creator>
        <description><![CDATA[
            背景：现有知识图谱基础模型研究多关注结构信息，局限于图谱内任务，难以处理更具挑战的图谱外任务。方法：提出通用知识图谱推理基础模型MERRY，利用图谱结构和文本信息，采用多视角条件消息传递编码架构融合两种模态，引入动态残差融合模块和灵活边评分机制。效果：在28个数据集上综合评估，MERRY在多数场景下优于现有基线，在图谱内推理和图谱外问答等任务中展现出强大推理和泛化能力。
            arXiv:2505.21926v1 Announce Type: new 
Abstract: In natural language processing (NLP) and computer vision (CV), the successful application of foundation models across diverse tasks has demonstrated their remarkable potential. However, despite the rich structural and textual information embedded in knowledge graphs (KGs), existing research of foundation model for KG has primarily focused on their structural aspects, with most efforts restricted to in-KG tasks (e.g., knowledge graph completion, KGC). This limitation has hindered progress in addressing more challenging out-of-KG tasks. In this paper, we introduce MERRY, a foundation model for general knowledge graph reasoning, and investigate its performance across two task categories: in-KG reasoning tasks (e.g., KGC) and out-of-KG tasks (e.g., KG question answering, KGQA). We not only utilize the structural information, but also the textual information in KGs. Specifically, we propose a multi-perspective Conditional Message Passing (CMP) encoding architecture to bridge the gap between textual and structural modalities, enabling their seamless integration. Additionally, we introduce a dynamic residual fusion module to selectively retain relevant textual information and a flexible edge scoring mechanism to adapt to diverse downstream tasks. Comprehensive evaluations on 28 datasets demonstrate that MERRY outperforms existing baselines in most scenarios, showcasing strong reasoning capabilities within KGs and excellent generalization to out-of-KG tasks such as KGQA.
        ]]></description>
    </item>
    <item>
        <title>Graph-Assisted Culturally Adaptable Idiomatic Translation for Indic Languages</title>
        <link>https://arxiv.org/abs/2505.21937</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.21937v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Pratik Rakesh Singh, Kritarth Prasad, Mohammadi Zaki, Pankaj Wasnik</dc:creator>
        <description><![CDATA[
            背景：多词表达和习语翻译需理解源语言和目标语言文化细微差别，传统静态知识图和基于提示的方法难以捕捉复杂关系，导致翻译效果不佳。方法：提出基于自适应图神经网络的IdiomCE方法，学习习语表达间的复杂映射。效果：在资源受限情况下提升翻译质量，利于小模型进行习语翻译。在多个习语翻译数据集上评估，用无参考指标证明从英语到多种印度语言的习语翻译有显著提升。
            arXiv:2505.21937v1 Announce Type: new 
Abstract: Translating multi-word expressions (MWEs) and idioms requires a deep understanding of the cultural nuances of both the source and target languages. This challenge is further amplified by the one-to-many nature of idiomatic translations, where a single source idiom can have multiple target-language equivalents depending on cultural references and contextual variations. Traditional static knowledge graphs (KGs) and prompt-based approaches struggle to capture these complex relationships, often leading to suboptimal translations. To address this, we propose IdiomCE, an adaptive graph neural network (GNN) based methodology that learns intricate mappings between idiomatic expressions, effectively generalizing to both seen and unseen nodes during training. Our proposed method enhances translation quality even in resource-constrained settings, facilitating improved idiomatic translation in smaller models. We evaluate our approach on multiple idiomatic translation datasets using reference-less metrics, demonstrating significant improvements in translating idioms from English to various Indian languages.
        ]]></description>
    </item>
    <item>
        <title>RISE: Reasoning Enhancement via Iterative Self-Exploration in Multi-hop Question Answering</title>
        <link>https://arxiv.org/abs/2505.21940</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.21940v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Bolei He, Xinran He, Mengke Chen, Xianwei Xue, Ying Zhu, Zhenhua Ling</dc:creator>
        <description><![CDATA[
            背景：大语言模型在复杂推理任务如多跳问答（MHQA）中面临挑战，检索增强生成（RAG）在处理MHQA时也存在过滤噪声数据和检索证据不足的问题。方法：提出RISE框架，通过迭代自我探索增强模型推理能力，包含问题分解、先检索后阅读、自我批判三个关键步骤。效果：在多个MHQA基准测试上的实验表明，RISE显著提高了推理准确性和任务表现。
            arXiv:2505.21940v1 Announce Type: new 
Abstract: Large Language Models (LLMs) excel in many areas but continue to face challenges with complex reasoning tasks, such as Multi-Hop Question Answering (MHQA). MHQA requires integrating evidence from diverse sources while managing intricate logical dependencies, often leads to errors in reasoning. Retrieval-Augmented Generation (RAG), widely employed in MHQA tasks, faces challenges in effectively filtering noisy data and retrieving all necessary evidence, thereby limiting its effectiveness in addressing MHQA challenges. To address these challenges, we propose RISE:Reasoning Enhancement via Iterative Self-Exploration, a novel framework designed to enhance models' reasoning capability through iterative self-exploration. Specifically, RISE involves three key steps in addressing MHQA tasks: question decomposition, retrieve-then-read, and self-critique. By leveraging continuous self-exploration, RISE identifies accurate reasoning paths, iteratively self-improving the model's capability to integrate evidence, maintain logical consistency, and enhance performance in MHQA tasks. Extensive experiments on multiple MHQA benchmarks demonstrate that RISE significantly improves reasoning accuracy and task performance.
        ]]></description>
    </item>
    <item>
        <title>Towards Comprehensive Scene Understanding: Integrating First and Third-Person Views for LVLMs</title>
        <link>https://arxiv.org/abs/2505.21955</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.21955v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Insu Lee, Wooje Park, Jaeyun Jang, Minyoung Noh, Kyuhong Shim, Byonghyo Shim</dc:creator>
        <description><![CDATA[
            背景：大视觉语言模型在交互应用中，第一人称视角输入虽有细粒度线索，但视野窄、缺全局信息，处理复杂查询易失败。方法：提出用第三人称视角增强第一人称输入的框架，构建首个多视图问答基准E3VQA，还提出免训练的提示技术M3CoT，整合三视角场景图构建统一场景表征。效果：M3CoT让模型跨视图更有效推理，相比基线，GPT - 4o性能提升4.84%，Gemini 2.0 Flash提升5.94%。
            arXiv:2505.21955v1 Announce Type: new 
Abstract: Large vision-language models (LVLMs) are increasingly deployed in interactive applications such as virtual and augmented reality, where first-person (egocentric) view captured by head-mounted cameras serves as key input. While this view offers fine-grained cues about user attention and hand-object interactions, their narrow field of view and lack of global context often lead to failures on spatially or contextually demanding queries. To address this, we introduce a framework that augments egocentric inputs with third-person (exocentric) views, providing complementary information such as global scene layout and object visibility to LVLMs. We present E3VQA, the first benchmark for multi-view question answering with 4K high-quality question-answer pairs grounded in synchronized ego-exo image pairs. Additionally, we propose M3CoT, a training-free prompting technique that constructs a unified scene representation by integrating scene graphs from three complementary perspectives. M3CoT enables LVLMs to reason more effectively across views, yielding consistent performance gains (4.84% for GPT-4o and 5.94% for Gemini 2.0 Flash) over a recent CoT baseline. Our extensive evaluation reveals key strengths and limitations of LVLMs in multi-view reasoning and highlights the value of leveraging both egocentric and exocentric inputs.
        ]]></description>
    </item>
    <item>
        <title>Cross-modal RAG: Sub-dimensional Retrieval-Augmented Text-to-Image Generation</title>
        <link>https://arxiv.org/abs/2505.21956</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.21956v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mengdan Zhu, Senhao Cheng, Guangji Bai, Yifei Zhang, Liang Zhao</dc:creator>
        <description><![CDATA[
            背景：文本到图像生成需获取预训练模型无法完全捕捉的特定领域知识，现有RAG方法在处理复杂查询时存在不足。方法：提出Cross - modal RAG框架，将查询和图像分解为子维度组件，采用结合子维度稀疏检索器和密集检索器的混合检索策略，引导多模态大语言模型根据特定子查询对齐的视觉特征进行图像合成。效果：在多个数据集上实验表明，该方法在检索和生成质量上显著优于现有基线，且效率高。
            arXiv:2505.21956v1 Announce Type: new 
Abstract: Text-to-image generation increasingly demands access to domain-specific, fine-grained, and rapidly evolving knowledge that pretrained models cannot fully capture. Existing Retrieval-Augmented Generation (RAG) methods attempt to address this by retrieving globally relevant images, but they fail when no single image contains all desired elements from a complex user query. We propose Cross-modal RAG, a novel framework that decomposes both queries and images into sub-dimensional components, enabling subquery-aware retrieval and generation. Our method introduces a hybrid retrieval strategy - combining a sub-dimensional sparse retriever with a dense retriever - to identify a Pareto-optimal set of images, each contributing complementary aspects of the query. During generation, a multimodal large language model is guided to selectively condition on relevant visual features aligned to specific subqueries, ensuring subquery-aware image synthesis. Extensive experiments on MS-COCO, Flickr30K, WikiArt, CUB, and ImageNet-LT demonstrate that Cross-modal RAG significantly outperforms existing baselines in both retrieval and generation quality, while maintaining high efficiency.
        ]]></description>
    </item>
    <item>
        <title>Towards Structure-aware Model for Multi-modal Knowledge Graph Completion</title>
        <link>https://arxiv.org/abs/2505.21973</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.21973v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Linyu Li, Zhi Jin, Yichi Zhang, Dongming Jin, Chengfeng Dou, Yuanpeng He, Xuan Zhang, Haiyan Zhao</dc:creator>
        <description><![CDATA[
            知识图谱在多媒体和AI应用中至关重要，随着多模态信息爆炸式增长，传统知识图谱补全模型不再适用，多模态知识图谱补全（MMKGC）面临细粒度模态信息交互和图结构主导性两大挑战。本文提出TSAM模型，采用细粒度模态感知融合法（FgMAF）和结构感知对比学习法（SaCL），前者用预训练语言模型捕获语义信息交互，后者使其他模态与结构化模态更紧密对齐。实验表明，TSAM在多模态数据集上显著优于现有MMKGC模型。
            arXiv:2505.21973v1 Announce Type: new 
Abstract: Knowledge graphs (KGs) play a key role in promoting various multimedia and AI applications. However, with the explosive growth of multi-modal information, traditional knowledge graph completion (KGC) models cannot be directly applied. This has attracted a large number of researchers to study multi-modal knowledge graph completion (MMKGC). Since MMKG extends KG to the visual and textual domains, MMKGC faces two main challenges: (1) how to deal with the fine-grained modality information interaction and awareness; (2) how to ensure the dominant role of graph structure in multi-modal knowledge fusion and deal with the noise generated by other modalities during modality fusion. To address these challenges, this paper proposes a novel MMKGC model named TSAM, which integrates fine-grained modality interaction and dominant graph structure to form a high-performance MMKGC framework. Specifically, to solve the challenges, TSAM proposes the Fine-grained Modality Awareness Fusion method (FgMAF), which uses pre-trained language models to better capture fine-grained semantic information interaction of different modalities and employs an attention mechanism to achieve fine-grained modality awareness and fusion. Additionally, TSAM presents the Structure-aware Contrastive Learning method (SaCL), which utilizes two contrastive learning approaches to align other modalities more closely with the structured modality. Extensive experiments show that the proposed TSAM model significantly outperforms existing MMKGC models on widely used multi-modal datasets.
        ]]></description>
    </item>
    <item>
        <title>VRAG-RL: Empower Vision-Perception-Based RAG for Visually Rich Information Understanding via Iterative Reasoning with Reinforcement Learning</title>
        <link>https://arxiv.org/abs/2505.22019</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22019v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qiuchen Wang, Ruixue Ding, Yu Zeng, Zehui Chen, Lin Chen, Shihang Wang, Pengjun Xie, Fei Huang, Feng Zhao</dc:creator>
        <description><![CDATA[
            背景：现有RAG方法在处理视觉丰富信息的检索、推理和理解上存在挑战，传统文本方法无法处理视觉信息，现有视觉RAG方法受固定流程限制，模型基础能力激活不足。方法：提出VRAG - RL框架，让视觉语言模型与搜索引擎交互，借助视觉感知令牌自主采样推理轨迹并优化；定义适合视觉输入的动作空间，采用结合查询重写和检索性能的奖励机制。效果：用专门设计的强化学习策略优化视觉语言模型，使其更贴合实际应用，代码已开源。
            arXiv:2505.22019v1 Announce Type: new 
Abstract: Effectively retrieving, reasoning and understanding visually rich information remains a challenge for RAG methods. Traditional text-based methods cannot handle visual-related information. On the other hand, current vision-based RAG approaches are often limited by fixed pipelines and frequently struggle to reason effectively due to the insufficient activation of the fundamental capabilities of models. As RL has been proven to be beneficial for model reasoning, we introduce VRAG-RL, a novel RL framework tailored for complex reasoning across visually rich information. With this framework, VLMs interact with search engines, autonomously sampling single-turn or multi-turn reasoning trajectories with the help of visual perception tokens and undergoing continual optimization based on these samples. Our approach highlights key limitations of RL in RAG domains: (i) Prior Multi-modal RAG approaches tend to merely incorporate images into the context, leading to insufficient reasoning token allocation and neglecting visual-specific perception; and (ii) When models interact with search engines, their queries often fail to retrieve relevant information due to the inability to articulate requirements, thereby leading to suboptimal performance. To address these challenges, we define an action space tailored for visually rich inputs, with actions including cropping and scaling, allowing the model to gather information from a coarse-to-fine perspective. Furthermore, to bridge the gap between users' original inquiries and the retriever, we employ a simple yet effective reward that integrates query rewriting and retrieval performance with a model-based reward. Our VRAG-RL optimizes VLMs for RAG tasks using specially designed RL strategies, aligning the model with real-world applications. The code is available at \hyperlink{https://github.com/Alibaba-NLP/VRAG}{https://github.com/Alibaba-NLP/VRAG}.
        ]]></description>
    </item>
    <item>
        <title>Detecting Undesired Process Behavior by Means of Retrieval Augmented Generation</title>
        <link>https://arxiv.org/abs/2505.22041</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22041v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Michael Grohs, Adrian Rebmann, Jana-Rebecca Rehse</dc:creator>
        <description><![CDATA[
            背景：传统一致性检查技术依赖专用流程模型，无模型时不适用，现有用大语言模型（LLMs）的方法需微调，资源消耗大且泛化性差。方法：提出一种无需专用流程模型和资源密集型微调的方法，利用检索增强生成（RAG）让LLM直接访问包含其他流程行为的知识库，使其将知识迁移到当前流程。效果：评估显示该方法在检测不良行为上优于微调的LLMs，表明RAG是资源密集型微调的可行替代方案。
            arXiv:2505.22041v1 Announce Type: new 
Abstract: Conformance checking techniques detect undesired process behavior by comparing process executions that are recorded in event logs to desired behavior that is captured in a dedicated process model. If such models are not available, conformance checking techniques are not applicable, but organizations might still be interested in detecting undesired behavior in their processes. To enable this, existing approaches use Large Language Models (LLMs), assuming that they can learn to distinguish desired from undesired behavior through fine-tuning. However, fine-tuning is highly resource-intensive and the fine-tuned LLMs often do not generalize well. To address these limitations, we propose an approach that requires neither a dedicated process model nor resource-intensive fine-tuning to detect undesired process behavior. Instead, we use Retrieval Augmented Generation (RAG) to provide an LLM with direct access to a knowledge base that contains both desired and undesired process behavior from other processes, assuming that the LLM can transfer this knowledge to the process at hand. Our evaluation shows that our approach outperforms fine-tuned LLMs in detecting undesired behavior, demonstrating that RAG is a viable alternative to resource-intensive fine-tuning, particularly when enriched with relevant context from the event log, such as frequent traces and activities.
        ]]></description>
    </item>
    <item>
        <title>Beyond path selection: Better LLMs for Scientific Information Extraction with MimicSFT and Relevance and Rule-induced(R$^2$)GRPO</title>
        <link>https://arxiv.org/abs/2505.22068</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22068v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ran Li, Shimin Di, Yuchen Liu, Chen Jing, Yu Qiu, Lei Chen</dc:creator>
        <description><![CDATA[
            背景：在科学信息提取任务中，大语言模型和推理大模型表现不如基于Bert的小模型，该任务需推理和记忆能力。方法：提出两阶段训练方法，一是MimicSFT，使用结构化推理模板，无需高质量思维链数据；二是R²GRPO，结合相关性和规则诱导奖励。效果：实验表明两种方法都能提升推理能力，结合MimicSFT的R²GRPO在关系提取上超越基线大模型和专业监督模型。代码见https://github.com/ranlislz/R2GRPO。
            arXiv:2505.22068v1 Announce Type: new 
Abstract: Previous study suggest that powerful Large Language Models (LLMs) trained with Reinforcement Learning with Verifiable Rewards (RLVR) only refines reasoning path without improving the reasoning capacity in math tasks while supervised-finetuning(SFT) with distillation can. We study this from the view of Scientific information extraction (SciIE) where LLMs and reasoning LLMs underperforms small Bert-based models. SciIE require both the reasoning and memorization. We argue that both SFT and RLVR can refine the reasoning path and improve reasoning capacity in a simple way based on SciIE. We propose two-stage training with 1. MimicSFT, using structured reasoning templates without needing high-quality chain-of-thought data, 2. R$^2$GRPO with relevance and rule-induced rewards. Experiments on scientific IE benchmarks show that both methods can improve the reasoning capacity. R$^2$GRPO with mimicSFT surpasses baseline LLMs and specialized supervised models in relation extraction. Our code is available at https://github.com/ranlislz/R2GRPO.
        ]]></description>
    </item>
    <item>
        <title>Learning to Route Queries Across Knowledge Bases for Step-wise Retrieval-Augmented Reasoning</title>
        <link>https://arxiv.org/abs/2505.22095</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22095v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chunyi Peng, Zhipeng Xu, Zhenghao Liu, Yishan Li, Yukun Yan, Shuo Wang, Zhiyuan Liu, Yu Gu, Minghe Yu, Ge Yu, Maosong Sun</dc:creator>
        <description><![CDATA[
            背景：多模态检索增强生成（MRAG）可减少多模态大语言模型（MLLMs）幻觉，但现有MRAG方法忽视MLLMs在推理中与不同知识库交互的能力。方法：提出R1 - Router框架，能根据推理状态决定何时、从哪检索知识，生成后续查询并路由到合适知识库；引入Step - GRPO强化学习算法优化推理行为。效果：在多模态问答基准测试中，R1 - Router比基线模型性能高超7%，能有效利用知识库，提升效率和准确性。
            arXiv:2505.22095v1 Announce Type: new 
Abstract: Multimodal Retrieval-Augmented Generation (MRAG) has shown promise in mitigating hallucinations in Multimodal Large Language Models (MLLMs) by incorporating external knowledge during generation. Existing MRAG methods typically adopt a static retrieval pipeline that fetches relevant information from multiple Knowledge Bases (KBs), followed by a refinement step. However, these approaches overlook the reasoning and planning capabilities of MLLMs to dynamically determine how to interact with different KBs during the reasoning process. To address this limitation, we propose R1-Router, a novel MRAG framework that learns to decide when and where to retrieve knowledge based on the evolving reasoning state. Specifically, R1-Router can generate follow-up queries according to the current reasoning step, routing these intermediate queries to the most suitable KB, and integrating external knowledge into a coherent reasoning trajectory to answer the original query. Furthermore, we introduce Step-wise Group Relative Policy Optimization (Step-GRPO), a tailored reinforcement learning algorithm that assigns step-specific rewards to optimize the reasoning behavior of MLLMs. Experimental results on various open-domain QA benchmarks across multiple modalities demonstrate that R1-Router outperforms baseline models by over 7%. Further analysis shows that R1-Router can adaptively and effectively leverage diverse KBs, reducing unnecessary retrievals and improving both efficiency and accuracy.
        ]]></description>
    </item>
    <item>
        <title>Knowledge Base Construction for Knowledge-Augmented Text-to-SQL</title>
        <link>https://arxiv.org/abs/2505.22096</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22096v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jinheon Baek, Horst Samulowitz, Oktie Hassanzadeh, Dharmashankar Subramanian, Sola Shirai, Alfio Gliozzo, Debarun Bhattacharjya</dc:creator>
        <description><![CDATA[
            背景：文本到SQL旨在将自然语言查询转换为SQL语句，现有大语言模型（LLMs）方法因参数知识有限，生成的SQL准确性欠佳。方法：提出构建文本到SQL的知识库，结合所有可用问题、关联数据库模式及相关知识构建全面知识库，为给定查询检索和生成必要知识。效果：在多个文本到SQL数据集上验证，考虑重叠和非重叠数据库场景，大幅超越相关基线模型。
            arXiv:2505.22096v1 Announce Type: new 
Abstract: Text-to-SQL aims to translate natural language queries into SQL statements, which is practical as it enables anyone to easily retrieve the desired information from databases. Recently, many existing approaches tackle this problem with Large Language Models (LLMs), leveraging their strong capability in understanding user queries and generating corresponding SQL code. Yet, the parametric knowledge in LLMs might be limited to covering all the diverse and domain-specific queries that require grounding in various database schemas, which makes generated SQLs less accurate oftentimes. To tackle this, we propose constructing the knowledge base for text-to-SQL, a foundational source of knowledge, from which we retrieve and generate the necessary knowledge for given queries. In particular, unlike existing approaches that either manually annotate knowledge or generate only a few pieces of knowledge for each query, our knowledge base is comprehensive, which is constructed based on a combination of all the available questions and their associated database schemas along with their relevant knowledge, and can be reused for unseen databases from different datasets and domains. We validate our approach on multiple text-to-SQL datasets, considering both the overlapping and non-overlapping database scenarios, where it outperforms relevant baselines substantially.
        ]]></description>
    </item>
    <item>
        <title>The quest for the GRAph Level autoEncoder (GRALE)</title>
        <link>https://arxiv.org/abs/2505.22109</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22109v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Paul Krzakala, Gabriel Melo, Charlotte Laclau, Florence d'Alch\'e-Buc, R\'emi Flamary</dc:creator>
        <description><![CDATA[
            背景：图表示学习是具有挑战性的任务，其解决可能影响化学、生物学等关键应用领域。方法：提出GRALE，一种将不同大小图编码和解码到共享嵌入空间的图自编码器，用受最优传输启发的损失函数训练，结合可微节点匹配模块，基于AlphaFold核心组件Evoformer构建注意力架构以支持图的编解码。效果：在模拟和分子数据实验中，GRALE可实现高度通用的预训练，适用于分类、回归等多种下游任务。
            arXiv:2505.22109v1 Announce Type: new 
Abstract: Although graph-based learning has attracted a lot of attention, graph representation learning is still a challenging task whose resolution may impact key application fields such as chemistry or biology. To this end, we introduce GRALE, a novel graph autoencoder that encodes and decodes graphs of varying sizes into a shared embedding space. GRALE is trained using an Optimal Transport-inspired loss that compares the original and reconstructed graphs and leverages a differentiable node matching module, which is trained jointly with the encoder and decoder. The proposed attention-based architecture relies on Evoformer, the core component of AlphaFold, which we extend to support both graph encoding and decoding. We show, in numerical experiments on simulated and molecular data, that GRALE enables a highly general form of pre-training, applicable to a wide range of downstream tasks, from classification and regression to more complex tasks such as graph interpolation, editing, matching, and prediction.
        ]]></description>
    </item>
    <item>
        <title>THINK-Bench: Evaluating Thinking Efficiency and Chain-of-Thought Quality of Large Reasoning Models</title>
        <link>https://arxiv.org/abs/2505.22113</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22113v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhiyuan Li, Yi Chang, Yuan Wu</dc:creator>
        <description><![CDATA[
            背景：大型推理模型（LRMs）在复杂任务中表现出色，但过度思考问题严重限制计算效率。方法：引入Think - Bench基准来评估LRMs推理效率，提出新的效率指标，并从推理过程、结果质量和思维链（CoT）特征等多维度全面评估不同LRMs。效果：分析发现多数LRMs处理简单问题时会过度思考，生成过长推理链，很多LRMs虽CoT质量高，但效率低。该基准有望推动LRMs研究。
            arXiv:2505.22113v1 Announce Type: new 
Abstract: Large reasoning models (LRMs) have achieved impressive performance in complex tasks, often outperforming conventional large language models (LLMs). However, the prevalent issue of overthinking severely limits their computational efficiency. Overthinking occurs when models generate excessive and redundant tokens that contribute little to accurate outcomes, especially in simple tasks, resulting in a significant waste of computational resources. To systematically investigate this issue, we introduce Think-Bench, a benchmark designed to evaluate the reasoning efficiency of LRMs. We also propose novel efficiency metrics and conduct a comprehensive evaluation of various LRMs across multiple dimensions, including the reasoning process, outcome quality, and chain-of-thought (CoT) characteristics. Our analysis reveals that most LRMs exhibit overthinking in handling easy questions, generating unnecessarily lengthy reasoning chains. While many LRMs demonstrate high CoT quality, several suffer from low efficiency. We hope that Think-Bench can serve as a robust foundation for advancing research into LRMs.
        ]]></description>
    </item>
    <item>
        <title>Multimodal Forecasting of Sparse Intraoperative Hypotension Events Powered by Language Model</title>
        <link>https://arxiv.org/abs/2505.22116</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22116v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jintao Zhang, Zirui Liu, Mingyue Cheng, Shilong Zhang, Tingyue Pan, Qi Liu, Yanhu Xie</dc:creator>
        <description><![CDATA[
            背景：术中低血压（IOH）频发且危害大，但事件稀疏及多源数据融合难题阻碍其预测。方法：提出多模态语言模型框架IOHFuseLM，采用两阶段训练策略，先在增强的IOH生理时间序列上进行领域自适应预训练，再在原临床数据集上微调；在令牌级别对齐结构化临床描述和生理时间序列，将静态患者属性转为结构化文本。效果：在两个术中数据集上实验表明，IOHFuseLM识别IOH事件能力优于现有基线模型，适用于临床决策支持。
            arXiv:2505.22116v1 Announce Type: new 
Abstract: Intraoperative hypotension (IOH) frequently occurs under general anesthesia and is strongly linked to adverse outcomes such as myocardial injury and increased mortality. Despite its significance, IOH prediction is hindered by event sparsity and the challenge of integrating static and dynamic data across diverse patients. In this paper, we propose \textbf{IOHFuseLM}, a multimodal language model framework. To accurately identify and differentiate sparse hypotensive events, we leverage a two-stage training strategy. The first stage involves domain adaptive pretraining on IOH physiological time series augmented through diffusion methods, thereby enhancing the model sensitivity to patterns associated with hypotension. Subsequently, task fine-tuning is performed on the original clinical dataset to further enhance the ability to distinguish normotensive from hypotensive states. To enable multimodal fusion for each patient, we align structured clinical descriptions with the corresponding physiological time series at the token level. Such alignment enables the model to capture individualized temporal patterns alongside their corresponding clinical semantics. In addition, we convert static patient attributes into structured text to enrich personalized information. Experimental evaluations on two intraoperative datasets demonstrate that IOHFuseLM outperforms established baselines in accurately identifying IOH events, highlighting its applicability in clinical decision support scenarios. Our code is publicly available to promote reproducibility at https://github.com/zjt-gpu/IOHFuseLM.
        ]]></description>
    </item>
    <item>
        <title>TabXEval: Why this is a Bad Table? An eXhaustive Rubric for Table Evaluation</title>
        <link>https://arxiv.org/abs/2505.22176</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22176v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Vihang Pancholi, Jainit Bafna, Tejas Anvekar, Manish Shrivastava, Vivek Gupta</dc:creator>
        <description><![CDATA[
            传统指标难以捕捉表格细微结构和内容差异，定性与定量评估表格面临挑战。为此，提出结合多级结构描述符与细粒度上下文量化的评估规则，并构建TabXEval两阶段评估框架。该框架先通过TabAlign进行结构对齐，再用TabCompare进行语义和句法比较。利用新开发的TabXBench基准评估其效果，通过敏感性 - 特异性权衡分析现有评估方法，证明TabXEval在多任务和领域中定性与定量评估的有效性。
            arXiv:2505.22176v1 Announce Type: new 
Abstract: Evaluating tables qualitatively & quantitatively presents a significant challenge, as traditional metrics often fail to capture nuanced structural and content discrepancies. To address this, we introduce a novel, methodical rubric integrating multi-level structural descriptors with fine-grained contextual quantification, thereby establishing a robust foundation for comprehensive table comparison. Building on this foundation, we propose TabXEval, an eXhaustive and eXplainable two-phase evaluation framework. TabXEval initially aligns reference tables structurally via TabAlign & subsequently conducts a systematic semantic and syntactic comparison using TabCompare; this approach clarifies the evaluation process and pinpoints subtle discrepancies overlooked by conventional methods. The efficacy of this framework is assessed using TabXBench, a novel, diverse, multi-domain benchmark we developed, featuring realistic table perturbations and human-annotated assessments. Finally, a systematic analysis of existing evaluation methods through sensitivity-specificity trade-offs demonstrates the qualitative and quantitative effectiveness of TabXEval across diverse table-related tasks and domains, paving the way for future innovations in explainable table evaluation.
        ]]></description>
    </item>
    <item>
        <title>Let's Predict Sentence by Sentence</title>
        <link>https://arxiv.org/abs/2505.22202</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22202v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hyeonbin Hwang, Byeongguk Jeon, Seungone Kim, Jiyeon Kim, Hoyeon Chang, Sohee Yang, Seungpil Won, Dohaeng Lee, Youbin Ahn, Minjoon Seo</dc:creator>
        <description><![CDATA[
            背景：自回归语言模型逐词生成，而人类推理基于句子等高级抽象，因此探究语言模型能否基于学习到的表征进行结构化语义单元推理。方法：提出框架，让预训练语言模型在句子空间中工作，通过自回归预测下一句的连续嵌入，探索语义和上下文两种嵌入范式，并在离散和连续两种推理机制下评估。效果：在四个领域中，连续推理下的上下文嵌入与思维链表现相当，推理时浮点运算次数平均减半，还展现出可扩展性和模块化适应迹象。
            arXiv:2505.22202v1 Announce Type: new 
Abstract: Autoregressive language models (LMs) generate one token at a time, yet human reasoning operates over higher-level abstractions - sentences, propositions, and concepts. This contrast raises a central question- Can LMs likewise learn to reason over structured semantic units rather than raw token sequences? In this work, we investigate whether pretrained LMs can be lifted into such abstract reasoning spaces by building on their learned representations. We present a framework that adapts a pretrained token-level LM to operate in sentence space by autoregressively predicting continuous embeddings of next sentences. We explore two embedding paradigms inspired by classical representation learning: 1) semantic embeddings, learned via autoencoding to preserve surface meaning; and 2) contextual embeddings, trained via next-sentence prediction to encode anticipatory structure. We evaluate both under two inference regimes: Discretized, which decodes each predicted embedding into text before re-encoding; and Continuous, which reasons entirely in embedding space for improved efficiency. Across four domains - mathematics, logic, commonsense, and planning - contextual embeddings under continuous inference show competitive performance with Chain-of-Thought (CoT) while reducing inference-time FLOPs on average by half. We also present early signs of scalability and modular adaptation. Finally, to visualize latent trajectories, we introduce SentenceLens, a diagnostic tool that decodes intermediate model states into interpretable sentences. Together, our results indicate that pretrained LMs can effectively transition to abstract, structured reasoning within latent embedding spaces.
        ]]></description>
    </item>
    <item>
        <title>BioHopR: A Benchmark for Multi-Hop, Multi-Answer Reasoning in Biomedical Domain</title>
        <link>https://arxiv.org/abs/2505.22240</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22240v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yunsoo Kim, Yusuf Abdulle, Honghan Wu</dc:creator>
        <description><![CDATA[
            背景：生物医学推理需遍历实体间的相互关系，但现有基准缺乏对生物医学领域多跳推理的评估能力。方法：提出BioHopR这一新型基准，基于PrimeKG构建，包含反映现实生物医学复杂性的1跳和2跳推理任务。效果：评估显示，推理模型O3 - mini在1跳任务上精确率达37.93%，2跳任务达14.57%，优于GPT4O等专有模型和华驼GPT - o1 - 70B等开源模型，但所有模型多跳性能均显著下降，凸显生物医学领域推理挑战。
            arXiv:2505.22240v1 Announce Type: new 
Abstract: Biomedical reasoning often requires traversing interconnected relationships across entities such as drugs, diseases, and proteins. Despite the increasing prominence of large language models (LLMs), existing benchmarks lack the ability to evaluate multi-hop reasoning in the biomedical domain, particularly for queries involving one-to-many and many-to-many relationships. This gap leaves the critical challenges of biomedical multi-hop reasoning underexplored. To address this, we introduce BioHopR, a novel benchmark designed to evaluate multi-hop, multi-answer reasoning in structured biomedical knowledge graphs. Built from the comprehensive PrimeKG, BioHopR includes 1-hop and 2-hop reasoning tasks that reflect real-world biomedical complexities.
  Evaluations of state-of-the-art models reveal that O3-mini, a proprietary reasoning-focused model, achieves 37.93% precision on 1-hop tasks and 14.57% on 2-hop tasks, outperforming proprietary models such as GPT4O and open-source biomedical models including HuatuoGPT-o1-70B and Llama-3.3-70B. However, all models exhibit significant declines in multi-hop performance, underscoring the challenges of resolving implicit reasoning steps in the biomedical domain. By addressing the lack of benchmarks for multi-hop reasoning in biomedical domain, BioHopR sets a new standard for evaluating reasoning capabilities and highlights critical gaps between proprietary and open-source models while paving the way for future advancements in biomedical LLMs.
        ]]></description>
    </item>
    <item>
        <title>YH-MINER: Multimodal Intelligent System for Natural Ecological Reef Metric Extraction</title>
        <link>https://arxiv.org/abs/2505.22250</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22250v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mingzhuang Wang, Yvyang Li, Xiyang Zhang, Fei Tan, Qi Shi, Guotao Zhang, Siqi Chen, Yufei Liu, Lei Lei, Ming Zhou, Qiang Lin, Hongqiang Yang</dc:creator>
        <description><![CDATA[
            背景：珊瑚礁生态监测面临人工分析效率低和复杂水下场景分割精度不足的问题。方法：开发YH - OSI系统，构建以多模态大模型为核心的“目标检测 - 语义分割 - 先验输入”智能框架，用目标检测模块生成空间先验框，驱动分割模块完成分割，再将分割掩码和微调分类指令作为先验输入到基于Qwen2 - VL的多模态模型。效果：目标检测模块mAP@0.5为0.78，属级分类准确率达88%，还能提取核心生态指标。 
            arXiv:2505.22250v1 Announce Type: new 
Abstract: Coral reefs, crucial for sustaining marine biodiversity and ecological processes (e.g., nutrient cycling, habitat provision), face escalating threats, underscoring the need for efficient monitoring. Coral reef ecological monitoring faces dual challenges of low efficiency in manual analysis and insufficient segmentation accuracy in complex underwater scenarios. This study develops the YH-OSI system, establishing an intelligent framework centered on the Multimodal Large Model (MLLM) for "object detection-semantic segmentation-prior input". The system uses the object detection module (mAP@0.5=0.78) to generate spatial prior boxes for coral instances, driving the segment module to complete pixel-level segmentation in low-light and densely occluded scenarios. The segmentation masks and finetuned classification instructions are fed into the Qwen2-VL-based multimodal model as prior inputs, achieving a genus-level classification accuracy of 88% and simultaneously extracting core ecological metrics. Meanwhile, the system retains the scalability of the multimodal model through standardized interfaces, laying a foundation for future integration into multimodal agent-based underwater robots and supporting the full-process automation of "image acquisition-prior generation-real-time analysis."
        ]]></description>
    </item>
    <item>
        <title>MRT at SemEval-2025 Task 8: Maximizing Recovery from Tables with Multiple Steps</title>
        <link>https://arxiv.org/abs/2505.22264</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22264v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Maximiliano Hormaz\'abal Lagos, \'Alvaro Bueno Saez, H\'ector Cerezo-Costas, Pedro Alonso Doval, Jorge Alcalde Vesteiro</dc:creator>
        <description><![CDATA[
            背景：解决SemEval 2025任务8中表格数据问答挑战。方法：利用大语言模型生成Python代码与表格交互获取答案，包含理解表格内容、生成获取答案的自然语言步骤指令、将指令转化为代码、运行代码并处理错误等多步骤，各步骤使用开源大语言模型和针对任务优化的提示。效果：在子任务1中取得了70.50%的得分。
            arXiv:2505.22264v1 Announce Type: new 
Abstract: In this paper we expose our approach to solve the \textit{SemEval 2025 Task 8: Question-Answering over Tabular Data} challenge. Our strategy leverages Python code generation with LLMs to interact with the table and get the answer to the questions. The process is composed of multiple steps: understanding the content of the table, generating natural language instructions in the form of steps to follow in order to get the answer, translating these instructions to code, running it and handling potential errors or exceptions. These steps use open source LLMs and fine grained optimized prompts for each task (step). With this approach, we achieved a score of $70.50\%$ for subtask 1.
        ]]></description>
    </item>
    <item>
        <title>CADReview: Automatically Reviewing CAD Programs with Error Detection and Correction</title>
        <link>https://arxiv.org/abs/2505.22304</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22304v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiali Chen, Xusen Hei, HongFei Liu, Yuancheng Wei, Zikun Deng, Jiayuan Xie, Yi Cai, Li Qing</dc:creator>
        <description><![CDATA[
            背景：在CAD设计中，设计师需对比参考图像对3D原型进行审查和改进，而现有多模态大模型难以识别CAD程序中的几何组件和执行空间几何操作，审查不准确。方法：提出CAD程序修复器（ReCAD）框架，用于检测程序错误并提供纠错反馈，还创建含超2万对程序 - 图像对的CADReview数据集。效果：大量实验表明，ReCAD显著优于现有多模态大模型，在设计应用中潜力巨大。
            arXiv:2505.22304v1 Announce Type: new 
Abstract: Computer-aided design (CAD) is crucial in prototyping 3D objects through geometric instructions (i.e., CAD programs). In practical design workflows, designers often engage in time-consuming reviews and refinements of these prototypes by comparing them with reference images. To bridge this gap, we introduce the CAD review task to automatically detect and correct potential errors, ensuring consistency between the constructed 3D objects and reference images. However, recent advanced multimodal large language models (MLLMs) struggle to recognize multiple geometric components and perform spatial geometric operations within the CAD program, leading to inaccurate reviews. In this paper, we propose the CAD program repairer (ReCAD) framework to effectively detect program errors and provide helpful feedback on error correction. Additionally, we create a dataset, CADReview, consisting of over 20K program-image pairs, with diverse errors for the CAD review task. Extensive experiments demonstrate that our ReCAD significantly outperforms existing MLLMs, which shows great potential in design applications.
        ]]></description>
    </item>
    <item>
        <title>Skywork Open Reasoner 1 Technical Report</title>
        <link>https://arxiv.org/abs/2505.22312</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22312v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jujie He, Jiacai Liu, Chris Yuhao Liu, Rui Yan, Chaojie Wang, Peng Cheng, Xiaoyu Zhang, Fuxiang Zhang, Jiacheng Xu, Wei Shen, Siyuan Li, Liang Zeng, Tianwen Wei, Cheng Cheng, Bo An, Yang Liu, Yahui Zhou</dc:creator>
        <description><![CDATA[
            背景：DeepSeek - R1表明强化学习对提升大语言模型推理能力有重要作用。方法：基于DeepSeek - R1 - Distill模型系列，提出适用于长思维链模型的有效且可扩展的强化学习实现Skywork - OR1。效果：显著提升性能，32B模型在AIME24、AIME25和LiveCodeBench上平均准确率从57.8%提升到72.8%，7B模型从43.6%提升到57.5%。Skywork - OR1 - 32B在部分基准测试中超越对比模型，小模型也展现出竞争力。还开源了模型权重、代码和数据集。
            arXiv:2505.22312v1 Announce Type: new 
Abstract: The success of DeepSeek-R1 underscores the significant role of reinforcement learning (RL) in enhancing the reasoning capabilities of large language models (LLMs). In this work, we present Skywork-OR1, an effective and scalable RL implementation for long Chain-of-Thought (CoT) models. Building on the DeepSeek-R1-Distill model series, our RL approach achieves notable performance gains, increasing average accuracy across AIME24, AIME25, and LiveCodeBench from 57.8% to 72.8% (+15.0%) for the 32B model and from 43.6% to 57.5% (+13.9%) for the 7B model. Our Skywork-OR1-32B model surpasses both DeepSeek-R1 and Qwen3-32B on the AIME24 and AIME25 benchmarks, while achieving comparable results on LiveCodeBench. The Skywork-OR1-7B and Skywork-OR1-Math-7B models demonstrate competitive reasoning capabilities among models of similar size. We perform comprehensive ablation studies on the core components of our training pipeline to validate their effectiveness. Additionally, we thoroughly investigate the phenomenon of entropy collapse, identify key factors affecting entropy dynamics, and demonstrate that mitigating premature entropy collapse is critical for improved test performance. To support community research, we fully open-source our model weights, training code, and training datasets.
        ]]></description>
    </item>
    <item>
        <title>Advancing Multimodal Reasoning via Reinforcement Learning with Cold Start</title>
        <link>https://arxiv.org/abs/2505.22334</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22334v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Lai Wei, Yuting Li, Kaipeng Zheng, Chen Wang, Yue Wang, Linghe Kong, Lichao Sun, Weiran Huang</dc:creator>
        <description><![CDATA[
            背景：大语言模型的思维链推理能力发展中，强化学习作用显著，但“顿悟时刻”模式与推理性能的关系尚不明确。方法：采用两阶段方法提升多模态推理能力，先以结构化思维链推理模式进行监督微调作为冷启动，再通过GRPO强化学习进一步优化。效果：该组合方法在多模态推理基准测试中优于仅监督微调或仅强化学习的方法。3B和7B规模模型达开源多模态模型的最优性能，7B模型在MathVista等数据集上有显著提升，3B模型性能可与部分7B模型竞争。
            arXiv:2505.22334v1 Announce Type: new 
Abstract: Recent advancements in large language models (LLMs) have demonstrated impressive chain-of-thought reasoning capabilities, with reinforcement learning (RL) playing a crucial role in this progress. While "aha moment" patterns--where models exhibit self-correction through reflection--are often attributed to emergent properties from RL, we first demonstrate that these patterns exist in multimodal LLMs (MLLMs) prior to RL training but may not necessarily correlate with improved reasoning performance. Building on these insights, we present a comprehensive study on enhancing multimodal reasoning through a two-stage approach: (1) supervised fine-tuning (SFT) as a cold start with structured chain-of-thought reasoning patterns, followed by (2) reinforcement learning via GRPO to further refine these capabilities. Our extensive experiments show that this combined approach consistently outperforms both SFT-only and RL-only methods across challenging multimodal reasoning benchmarks. The resulting models achieve state-of-the-art performance among open-source MLLMs at both 3B and 7B scales, with our 7B model showing substantial improvements over base models (e.g., 66.3 %$\rightarrow$73.4 % on MathVista, 62.9 %$\rightarrow$70.4 % on We-Math) and our 3B model achieving performance competitive with several 7B models. Overall, this work provides practical guidance for building advanced multimodal reasoning models. Our code is available at https://github.com/waltonfuture/RL-with-Cold-Start.
        ]]></description>
    </item>
    <item>
        <title>Directed Homophily-Aware Graph Neural Network</title>
        <link>https://arxiv.org/abs/2505.22362</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22362v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Aihu Zhang, Jiaxing Xu, Mengcheng Lan, Shili Xiang, Yiping Ke</dc:creator>
        <description><![CDATA[
            背景：图神经网络在图结构数据学习任务中取得成功，但多数难以泛化到异质邻域，且忽略图的方向性，在非对称有向图上表现不佳。方法：提出有向同质性感知图神经网络（DHGNN），通过同质性感知和方向敏感组件解决问题，采用可重置门控机制和结构感知抗噪融合模块。效果：在有向图数据集上的节点分类和链接预测任务中优于现有方法，链接预测最高比最佳基线提升15.07%，门控机制能捕捉复杂图结构的消息传递行为。
            arXiv:2505.22362v1 Announce Type: new 
Abstract: Graph Neural Networks (GNNs) have achieved significant success in various learning tasks on graph-structured data. Nevertheless, most GNNs struggle to generalize to heterophilic neighborhoods. Additionally, many GNNs ignore the directional nature of real-world graphs, resulting in suboptimal performance on directed graphs with asymmetric structures. In this work, we propose Directed Homophily-aware Graph Neural Network (DHGNN), a novel framework that addresses these limitations by incorporating homophily-aware and direction-sensitive components. DHGNN employs a resettable gating mechanism to adaptively modulate message contributions based on homophily levels and informativeness, and a structure-aware noise-tolerant fusion module to effectively integrate node representations from the original and reverse directions. Extensive experiments on both homophilic and heterophilic directed graph datasets demonstrate that DHGNN outperforms state-of-the-art methods in node classification and link prediction. In particular, DHGNN improves over the best baseline by up to 15.07% in link prediction. Our analysis further shows that the gating mechanism captures directional homophily gaps and fluctuating homophily across layers, providing deeper insights into message-passing behavior on complex graph structures.
        ]]></description>
    </item>
    <item>
        <title>Scaling Reasoning without Attention</title>
        <link>https://arxiv.org/abs/2505.22425</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22425v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xueliang Zhao, Wei Wu, Lingpeng Kong</dc:creator>
        <description><![CDATA[
            背景：大语言模型在复杂推理任务取得进展，但受限于Transformer架构低效和高难度领域缺乏结构化微调。方法：提出无注意力语言模型，基于Mamba - 2的SSD层，消除自注意力和键值缓存需求，实现固定内存、恒定时间推理；采用基于PromptCoT合成范式的两阶段课程微调策略。效果：7B模型在基准评估中优于同等规模的Transformer和混合模型，在AIME 24、AIME 25和Livecodebench上分别超Gemma3 - 27B 2.6%、0.6%和3.0%。
            arXiv:2505.22425v1 Announce Type: new 
Abstract: Large language models (LLMs) have made significant advances in complex reasoning tasks, yet they remain bottlenecked by two core challenges: architectural inefficiency due to reliance on Transformers, and a lack of structured fine-tuning for high-difficulty domains. We introduce \ourmodel, an attention-free language model that addresses both issues through architectural and data-centric innovations. Built on the state space dual (SSD) layers of Mamba-2, our model eliminates the need for self-attention and key-value caching, enabling fixed-memory, constant-time inference. To train it for complex reasoning, we propose a two-phase curriculum fine-tuning strategy based on the \textsc{PromptCoT} synthesis paradigm, which generates pedagogically structured problems via abstract concept selection and rationale-guided generation. On benchmark evaluations, \ourmodel-7B outperforms strong Transformer and hybrid models of comparable scale, and even surpasses the much larger Gemma3-27B by 2.6\% on AIME 24, 0.6\% on AIME 25, and 3.0\% on Livecodebench. These results highlight the potential of state space models as efficient and scalable alternatives to attention-based architectures for high-capacity reasoning.
        ]]></description>
    </item>
    <item>
        <title>Unsupervised Post-Training for Multi-Modal LLM Reasoning via GRPO</title>
        <link>https://arxiv.org/abs/2505.22453</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22453v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Lai Wei, Yuting Li, Chen Wang, Yue Wang, Linghe Kong, Weiran Huang, Lichao Sun</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型（MLLMs）后训练阶段的有监督方法需昂贵的人工标注数据，无监督后训练方法复杂难迭代。方法：首次使用GRPO算法，提出MM - UPT框架，用基于多采样响应多数投票的自我奖励机制替代传统奖励信号。效果：在无真实标签标准数据集上显著提升Qwen2.5 - VL - 7B推理能力，如MathVista从66.3%提升到72.9%，We - Math从62.9%提升到68.7%，优于先前无监督基线，接近有监督GRPO结果。
            arXiv:2505.22453v1 Announce Type: new 
Abstract: Improving Multi-modal Large Language Models (MLLMs) in the post-training stage typically relies on supervised fine-tuning (SFT) or reinforcement learning (RL). However, these supervised methods require expensive and manually annotated multi-modal data--an ultimately unsustainable resource. While recent efforts have explored unsupervised post-training, their methods are complex and difficult to iterate. In this work, we are the first to investigate the use of GRPO, a stable and scalable online RL algorithm, for enabling continual self-improvement without any external supervision. We propose MM-UPT, a simple yet effective framework for unsupervised post-training of MLLMs. MM-UPT builds upon GRPO, replacing traditional reward signals with a self-rewarding mechanism based on majority voting over multiple sampled responses. Our experiments demonstrate that MM-UPT significantly improves the reasoning ability of Qwen2.5-VL-7B (e.g., 66.3 %$\rightarrow$72.9 % on MathVista, 62.9 %$\rightarrow$68.7 % on We-Math), using standard dataset without ground truth labels. MM-UPT also outperforms prior unsupervised baselines and even approaches the results of supervised GRPO. Furthermore, we show that incorporating synthetic questions, generated solely by MLLM itself, can boost performance as well, highlighting a promising approach for scalable self-improvement. Overall, MM-UPT offers a new paradigm for continual, autonomous enhancement of MLLMs in the absence of external supervision. Our code is available at https://github.com/waltonfuture/MM-UPT.
        ]]></description>
    </item>
    <item>
        <title>Multi-MLLM Knowledge Distillation for Out-of-Context News Detection</title>
        <link>https://arxiv.org/abs/2505.22517</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22517v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yimeng Gu, Zhao Tong, Ignacio Castro, Shu Wu, Gareth Tyson</dc:creator>
        <description><![CDATA[
            背景：多模态脱离上下文新闻是一种虚假信息，现有多模态大语言模型（MLLMs）检测此类新闻时，小模型零样本性能有限，需大量标注微调或调用昂贵GPT模型，在低资源场景不实用。方法：先让多个教师MLLMs生成标签预测和理由作为知识，再用两阶段知识蒸馏框架将知识转移给学生MLLM，第一阶段用所有训练数据进行LoRA微调，第二阶段在教师预测冲突的数据点上结合LoRA和DPO进一步微调。效果：用少于10%标注数据达到了最先进性能。
            arXiv:2505.22517v1 Announce Type: new 
Abstract: Multimodal out-of-context news is a type of misinformation in which the image is used outside of its original context. Many existing works have leveraged multimodal large language models (MLLMs) for detecting out-of-context news. However, observing the limited zero-shot performance of smaller MLLMs, they generally require label-rich fine-tuning and/or expensive API calls to GPT models to improve the performance, which is impractical in low-resource scenarios. In contrast, we aim to improve the performance of small MLLMs in a more label-efficient and cost-effective manner. To this end, we first prompt multiple teacher MLLMs to generate both label predictions and corresponding rationales, which collectively serve as the teachers' knowledge. We then introduce a two-stage knowledge distillation framework to transfer this knowledge to a student MLLM. In Stage 1, we apply LoRA fine-tuning to the student model using all training data. In Stage 2, we further fine-tune the student model using both LoRA fine-tuning and DPO on the data points where teachers' predictions conflict. This two-stage strategy reduces annotation costs and helps the student model uncover subtle patterns in more challenging cases. Experimental results demonstrate that our approach achieves state-of-the-art performance using less than 10% labeled data.
        ]]></description>
    </item>
    <item>
        <title>ClaimPKG: Enhancing Claim Verification via Pseudo-Subgraph Generation with Lightweight Specialized LLM</title>
        <link>https://arxiv.org/abs/2505.22552</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22552v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hoang Pham, Thanh-Do Nguyen, Khac-Hoai Nam Bui</dc:creator>
        <description><![CDATA[
            在声明验证中，将知识图谱（KGs）与大语言模型（LLMs）结合以增强推理能力是新兴挑战。现有方法多依赖非结构化文本语料，限制了对KGs的利用，且现代LLMs在多步模块化流程和KGs推理上有困难。为此提出ClaimPKG框架，用轻量级专用LLM将输入声明表示为伪子图，引导子图检索模块识别相关KG子图，再由通用LLM处理得出最终结论。在FactKG数据集上实验表明，其准确率比强基线高9%-12%，对非结构化数据集有零样本泛化能力。
            arXiv:2505.22552v1 Announce Type: new 
Abstract: Integrating knowledge graphs (KGs) to enhance the reasoning capabilities of large language models (LLMs) is an emerging research challenge in claim verification. While KGs provide structured, semantically rich representations well-suited for reasoning, most existing verification methods rely on unstructured text corpora, limiting their ability to effectively leverage KGs. Additionally, despite possessing strong reasoning abilities, modern LLMs struggle with multi-step modular pipelines and reasoning over KGs without adaptation. To address these challenges, we propose ClaimPKG, an end-to-end framework that seamlessly integrates LLM reasoning with structured knowledge from KGs. Specifically, the main idea of ClaimPKG is to employ a lightweight, specialized LLM to represent the input claim as pseudo-subgraphs, guiding a dedicated subgraph retrieval module to identify relevant KG subgraphs. These retrieved subgraphs are then processed by a general-purpose LLM to produce the final verdict and justification. Extensive experiments on the FactKG dataset demonstrate that ClaimPKG achieves state-of-the-art performance, outperforming strong baselines in this research field by 9%-12% accuracy points across multiple categories. Furthermore, ClaimPKG exhibits zero-shot generalizability to unstructured datasets such as HoVer and FEVEROUS, effectively combining structured knowledge from KGs with LLM reasoning across various LLM backbones.
        ]]></description>
    </item>
    <item>
        <title>Agent-UniRAG: A Trainable Open-Source LLM Agent Framework for Unified Retrieval-Augmented Generation Systems</title>
        <link>https://arxiv.org/abs/2505.22571</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22571v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hoang Pham, Khac-Hoai Nam Bui</dc:creator>
        <description><![CDATA[
            背景：现有RAG系统研究多单独解决单跳或多跳问题，限制了其在实际中的应用。方法：提出可训练的Agent-UniRAG框架用于统一检索增强大语言模型系统，基于输入复杂度逐步解决RAG任务，同时端到端处理单跳和多跳查询；还引入SynAgent - RAG合成数据集，使框架适用于小型开源大模型。效果：在各种RAG基准测试中，与闭源和更大的开源大模型表现相当，代码和数据集公开。
            arXiv:2505.22571v1 Announce Type: new 
Abstract: This paper presents a novel approach for unified retrieval-augmented generation (RAG) systems using the recent emerging large language model (LLM) agent concept. Specifically, Agent LLM, which utilizes LLM as fundamental controllers, has become a promising approach to enable the interpretability of RAG tasks, especially for complex reasoning question-answering systems (e.g., multi-hop queries). Nonetheless, previous works mainly focus on solving RAG systems with either single-hop or multi-hop approaches separately, which limits the application of those approaches to real-world applications. In this study, we propose a trainable agent framework called Agent-UniRAG for unified retrieval-augmented LLM systems, which enhances the effectiveness and interpretability of RAG systems. The main idea is to design an LLM agent framework to solve RAG tasks step-by-step based on the complexity of the inputs, simultaneously including single-hop and multi-hop queries in an end-to-end manner. Furthermore, we introduce SynAgent-RAG, a synthetic dataset to enable the proposed agent framework for small open-source LLMs (e.g., Llama-3-8B). The results show comparable performances with closed-source and larger open-source LLMs across various RAG benchmarks. Our source code and dataset are publicly available for further exploitation.
        ]]></description>
    </item>
    <item>
        <title>Spatial Knowledge Graph-Guided Multimodal Synthesis</title>
        <link>https://arxiv.org/abs/2505.22633</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22633v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yida Xue, Zhen Bi, Jinnan Yang, Jungang Lou, Huajun Chen, Ningyu Zhang</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型空间感知能力有限，多模态数据合成是解决之道，但保证合成数据符合空间常识较难。方法：提出SKG2Data，一种由空间知识图谱引导的多模态合成方法，自动构建空间知识图谱模拟人类对空间方向和距离的感知，以指导多模态数据合成。效果：实验表明，从方向、距离等多种空间知识合成的数据，能提升多模态大语言模型的空间感知和推理能力，且有强泛化能力。
            arXiv:2505.22633v1 Announce Type: new 
Abstract: Recent advances in multimodal large language models (MLLMs) have significantly enhanced their capabilities; however, their spatial perception abilities remain a notable limitation. To address this challenge, multimodal data synthesis offers a promising solution. Yet, ensuring that synthesized data adhere to spatial common sense is a non-trivial task. In this work, we introduce SKG2Data, a novel multimodal synthesis approach guided by spatial knowledge graphs, grounded in the concept of knowledge-to-data generation. SKG2Data automatically constructs a Spatial Knowledge Graph (SKG) to emulate human-like perception of spatial directions and distances, which is subsequently utilized to guide multimodal data synthesis. Extensive experiments demonstrate that data synthesized from diverse types of spatial knowledge, including direction and distance, not only enhance the spatial perception and reasoning abilities of MLLMs but also exhibit strong generalization capabilities. We hope that the idea of knowledge-based data synthesis can advance the development of spatial intelligence.
        ]]></description>
    </item>
    <item>
        <title>Learning Composable Chains-of-Thought</title>
        <link>https://arxiv.org/abs/2505.22635</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22635v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Fangcong Yin, Zeyu Leo Liu, Liu Leqi, Xi Ye, Greg Durrett</dc:creator>
        <description><![CDATA[
            背景：用思维链（CoT）训练大语言模型推理，获取标注数据成本高，且需模型有组合泛化能力。方法：针对无标注CoT数据的目标组合任务，发现简单用原子任务CoT数据训练泛化有限，将原子任务CoT格式改为可组合能改进，用可组合CoT数据训练“原子CoT”模型，结合多任务学习或模型合并，还可用拒绝采样微调进一步提升。效果：在字符串操作和自然语言技能组合任务中，用可组合CoT训练表现优于多任务学习和持续微调基线。
            arXiv:2505.22635v1 Announce Type: new 
Abstract: A common approach for teaching large language models (LLMs) to reason is to train on chain-of-thought (CoT) traces of in-distribution reasoning problems, but such annotated data is costly to obtain for every problem of interest. We want reasoning models to generalize beyond their training distribution, and ideally to generalize compositionally: combine atomic reasoning skills to solve harder, unseen reasoning tasks. We take a step towards compositional generalization of reasoning skills when addressing a target compositional task that has no labeled CoT data. We find that simply training models on CoT data of atomic tasks leads to limited generalization, but minimally modifying CoT formats of constituent atomic tasks to be composable can lead to improvements. We can train "atomic CoT" models on the atomic tasks with Composable CoT data and combine them with multitask learning or model merging for better zero-shot performance on the target compositional task. Such a combined model can be further bootstrapped on a small amount of compositional data using rejection sampling fine-tuning (RFT). Results on string operations and natural language skill compositions show that training LLMs on Composable CoT outperforms multitask learning and continued fine-tuning baselines within a given training data budget.
        ]]></description>
    </item>
    <item>
        <title>On Learning Verifiers for Chain-of-Thought Reasoning</title>
        <link>https://arxiv.org/abs/2505.22650</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22650v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Maria-Florina Balcan, Avrim Blum, Zhiyuan Li, Dravyansh Sharma</dc:creator>
        <description><![CDATA[
            背景：思维链推理在解决复杂数学和逻辑问题时易因错误推断偏离正轨，而用形式验证器检查的形式数学推理，当前大语言模型难以解决复杂问题。方法：考虑为自然语言思维链推理学习可靠验证器，给出形式化PAC学习框架研究该问题，提出并分析不同强度的验证目标。效果：给出满足目标的验证器学习样本复杂度上界，以及无额外假设下学习其他验证目标的下界和不可能结果。
            arXiv:2505.22650v1 Announce Type: new 
Abstract: Chain-of-Thought reasoning has emerged as a powerful approach for solving complex mathematical and logical problems. However, it can often veer off track through incorrect or unsubstantiated inferences. Formal mathematical reasoning, which can be checked with a formal verifier, is one approach to addressing this issue. However, currently LLMs are simply not good enough to solve complex problems in a formal way, and even just formalizing an informal problem statement can be challenging. Motivated by this fact, in this work we consider the problem of learning reliable verifiers for natural language Chain-of-Thought reasoning. That is, given a problem statement and step-by-step solution in natural language, the aim of the verifier is to output [Yes] if the reasoning steps in the solution are all valid, and [No] otherwise. In this work we give a formal PAC-learning framework for studying this problem. We propose and analyze several natural verification goals, at different levels of strength, in this framework. We provide sample complexity upper-bounds for learning verifiers satisfying these goals, as well as lower-bound and impossibility results for learning other natural verification objectives without additional assumptions.
        ]]></description>
    </item>
    <item>
        <title>Sherlock: Self-Correcting Reasoning in Vision-Language Models</title>
        <link>https://arxiv.org/abs/2505.22651</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22651v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yi Ding, Ruqi Zhang</dc:creator>
        <description><![CDATA[
            推理视觉语言模型（VLMs）在复杂多模态任务上表现不错，但存在易出错、依赖大量标注数据或准确验证器、泛化能力差等问题。为此，研究人员深入分析其自我修正能力，提出Sherlock自修正与自提升训练框架，引入轨迹级自修正目标、基于视觉扰动的偏好数据构建方法和动态偏好调整参数。基于Llama3.2 - Vision - 11B模型，仅用2万随机采样标注数据让模型获得自修正能力后可无监督自提升，在8个基准测试中平均准确率达64.1（直接生成）和65.4（自修正后），优于对比模型且使用标注数据少于20%。
            arXiv:2505.22651v1 Announce Type: new 
Abstract: Reasoning Vision-Language Models (VLMs) have shown promising performance on complex multimodal tasks. However, they still face significant challenges: they are highly sensitive to reasoning errors, require large volumes of annotated data or accurate verifiers, and struggle to generalize beyond specific domains. To address these limitations, we explore self-correction as a strategy to enhance reasoning VLMs. We first conduct an in-depth analysis of reasoning VLMs' self-correction abilities and identify key gaps. Based on our findings, we introduce Sherlock, a self-correction and self-improvement training framework. Sherlock introduces a trajectory-level self-correction objective, a preference data construction method based on visual perturbation, and a dynamic $\beta$ for preference tuning. Once the model acquires self-correction capabilities using only 20k randomly sampled annotated data, it continues to self-improve without external supervision. Built on the Llama3.2-Vision-11B model, Sherlock achieves remarkable results across eight benchmarks, reaching an average accuracy of 64.1 with direct generation and 65.4 after self-correction. It outperforms LLaVA-CoT (63.2), Mulberry (63.9), and LlamaV-o1 (63.4) while using less than 20% of the annotated data.
        ]]></description>
    </item>
    <item>
        <title>AutoL2S: Auto Long-Short Reasoning for Efficient Large Language Models</title>
        <link>https://arxiv.org/abs/2505.22662</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22662v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Feng Luo, Yu-Neng Chuang, Guanchu Wang, Hoang Anh Duy Le, Shaochen Zhong, Hongyi Liu, Jiayi Yuan, Yang Sui, Vladimir Braverman, Vipin Chaudhary, Xia Hu</dc:creator>
        <description><![CDATA[
            背景：有推理能力的大语言模型在复杂推理任务中表现出色，但处理简单问题时会过度思考，生成不必要的长思维链，增加推理成本和延迟，现有方法缺乏动态调整思维链长度的灵活性。方法：提出AutoL2S动态且与模型无关的框架，通过在含长、短思维链及特殊标记的数据上训练，让大语言模型根据问题复杂度动态压缩推理路径。效果：实验表明，AutoL2S能在不降低性能的前提下，将推理生成长度最多减少57%。
            arXiv:2505.22662v1 Announce Type: new 
Abstract: The reasoning-capable large language models (LLMs) demonstrate strong performance on complex reasoning tasks but often suffer from overthinking, generating unnecessarily long chain-of-thought (CoT) reasoning paths for easy reasoning questions, thereby increasing inference cost and latency. Recent approaches attempt to address this challenge by manually deciding when to apply long or short reasoning. However, they lack the flexibility to adapt CoT length dynamically based on question complexity. In this paper, we propose Auto Long-Short Reasoning (AutoL2S), a dynamic and model-agnostic framework that enables LLMs to dynamically compress their generated reasoning path based on the complexity of the reasoning question. AutoL2S enables a learned paradigm, in which LLMs themselves can decide when longer reasoning is necessary and when shorter reasoning suffices, by training on data annotated with our proposed method, which includes both long and short CoT paths and a special  token. We then use  token to indicate when the model can skip generating lengthy CoT reasoning. This proposed annotation strategy can enhance the LLMs' ability to generate shorter CoT reasoning paths with improved quality after training. Extensive evaluation results show that AutoL2S reduces the length of reasoning generation by up to 57% without compromising performance, demonstrating the effectiveness of AutoL2S for scalable and efficient LLM reasoning.
        ]]></description>
    </item>
    <item>
        <title>Towards Safety Reasoning in LLMs: AI-agentic Deliberation for Policy-embedded CoT Data Creation</title>
        <link>https://arxiv.org/abs/2505.21784</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.21784v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tharindu Kumarage, Ninareh Mehrabi, Anil Ramakrishna, Xinyan Zhao, Richard Zemel, Kai-Wei Chang, Aram Galstyan, Rahul Gupta, Charith Peris</dc:creator>
        <description><![CDATA[
            背景：安全推理可缓解大语言模型现有安全措施的局限，但创建高质量策略嵌入思维链数据集面临挑战。方法：提出AIDSAFE，利用多智能体审议迭代扩展安全策略推理，通过数据精炼阶段确保输出质量，还引入补充方法创建偏好数据。效果：AIDSAFE生成的思维链在策略遵循和推理质量上表现出色，基于其微调开源大语言模型可显著提升安全泛化性和抗越狱能力，同时保持可接受的实用性和拒绝准确率。
            arXiv:2505.21784v1 Announce Type: cross 
Abstract: Safety reasoning is a recent paradigm where LLMs reason over safety policies before generating responses, thereby mitigating limitations in existing safety measures such as over-refusal and jailbreak vulnerabilities. However, implementing this paradigm is challenging due to the resource-intensive process of creating high-quality policy-embedded chain-of-thought (CoT) datasets while ensuring reasoning remains accurate and free from hallucinations or policy conflicts. To tackle this, we propose AIDSAFE: Agentic Iterative Deliberation for Safety Reasoning, a novel data generation recipe that leverages multi-agent deliberation to iteratively expand reasoning on safety policies. A data refiner stage in AIDSAFE ensures high-quality outputs by eliminating repetitive, redundant, and deceptive thoughts. AIDSAFE-generated CoTs provide a strong foundation for supervised fine-tuning (SFT)-based safety training. Additionally, to address the need of preference data in alignment stages, such as DPO training, we introduce a supplemental recipe that uses belief augmentation to create distinct selected and rejected CoT samples. Our evaluations demonstrate that AIDSAFE-generated CoTs achieve superior policy adherence and reasoning quality. Consequently, we show that fine-tuning open-source LLMs on these CoTs can significantly improve safety generalization and jailbreak robustness while maintaining acceptable utility and over-refusal accuracy. AIDSAFE-generated CoT datasets can be found here: https://huggingface.co/datasets/AmazonScience/AIDSAFE
        ]]></description>
    </item>
    <item>
        <title>Efficiently Enhancing General Agents With Hierarchical-categorical Memory</title>
        <link>https://arxiv.org/abs/2505.22006</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22006v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Changze Qiao, Mingming Lu</dc:creator>
        <description><![CDATA[
            背景：当前利用大语言模型构建通用多模态智能体的研究增多，但现有方法存在计算成本高或缺乏持续学习能力的问题。方法：提出无参数更新学习的通用智能体EHC，包含分层记忆检索（HMR）模块和面向任务类别的经验学习（TOEL）模块，前者可快速检索记忆并持续存储新信息，后者通过分类经验和提取模式提升智能体对任务特征的理解。效果：在多标准数据集上实验表明，EHC优于现有方法，达最优性能。
            arXiv:2505.22006v1 Announce Type: cross 
Abstract: With large language models (LLMs) demonstrating remarkable capabilities, there has been a surge in research on leveraging LLMs to build general-purpose multi-modal agents. However, existing approaches either rely on computationally expensive end-to-end training using large-scale multi-modal data or adopt tool-use methods that lack the ability to continuously learn and adapt to new environments. In this paper, we introduce EHC, a general agent capable of learning without parameter updates. EHC consists of a Hierarchical Memory Retrieval (HMR) module and a Task-Category Oriented Experience Learning (TOEL) module. The HMR module facilitates rapid retrieval of relevant memories and continuously stores new information without being constrained by memory capacity. The TOEL module enhances the agent's comprehension of various task characteristics by classifying experiences and extracting patterns across different categories. Extensive experiments conducted on multiple standard datasets demonstrate that EHC outperforms existing methods, achieving state-of-the-art performance and underscoring its effectiveness as a general agent for handling complex multi-modal tasks.
        ]]></description>
    </item>
    <item>
        <title>Rethinking the Unsolvable: When In-Context Search Meets Test-Time Scaling</title>
        <link>https://arxiv.org/abs/2505.22290</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22290v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Fanzeng Xia, Yidong Luo, Tinko Sebastian Bartels, Yaqi Xu, Tongxin Li</dc:creator>
        <description><![CDATA[
            背景：大语言模型在复杂推理问题上面临挑战，现有评估多采用简单上下文学习示例，易低估其推理能力。方法：系统探索上下文搜索与测试时缩放相结合的潜力，通过先进的上下文搜索提示结合内部缩放。效果：在控制的NP难任务和复杂现实规划基准上，成功率比之前无外部机制的结果最多提升30倍；理论上，该方法显著扩展可解推理问题的复杂度类别，挑战了对大模型在复杂任务上局限性的普遍认知。
            arXiv:2505.22290v1 Announce Type: cross 
Abstract: Recent research has highlighted that Large Language Models (LLMs), even when trained to generate extended long reasoning steps, still face significant challenges on hard reasoning problems. However, much of the existing literature relies on direct prompting with simple in-context learning examples for evaluation, which largely overlooks advanced techniques to elicit LLMs' deliberate reasoning before drawing conclusions that LLMs hit a performance ceiling. In this paper, we systematically explore the combined potential of in-context search and test-time scaling on super hard reasoning tasks. We find that by employing advanced in-context search prompting to LLMs augmented with internal scaling, one can achieve transformative performance breakthroughs on tasks previously deemed "unsolvable" (e.g., reported success rates below 5%). We provide both empirical results and theoretical analysis of how this combination can unleash LLM reasoning capabilities: i) Empirically, on controlled NP-hard tasks and complex real-world planning benchmarks, our approach achieves up to a 30x improvement in success rates compared to previously reported results without any external mechanisms; ii) Theoretically, we show that in-context search prompting, when combined with internal scaling, significantly extends the complexity class of solvable reasoning problems. These findings challenge prevailing assumptions about the limitations of LLMs on complex tasks, indicating that current evaluation paradigms systematically underestimate their true potential. Our work calls for a critical reassessment of how LLM reasoning is benchmarked and a more robust evaluation strategy that fully captures the true capabilities of contemporary LLMs, which can lead to a better understanding of their operational reasoning boundaries in real-world deployments.
        ]]></description>
    </item>
    <item>
        <title>Topological Structure Learning Should Be A Research Priority for LLM-Based Multi-Agent Systems</title>
        <link>https://arxiv.org/abs/2505.22467</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22467v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiaxi Yang, Mengqi Zhang, Yiqiao Jin, Hao Chen, Qingsong Wen, Lu Lin, Yi He, Weijie Xu, James Evans, Jindong Wang</dc:creator>
        <description><![CDATA[
            背景：基于大语言模型的多智能体系统（MASs）是解决复杂任务的有力范式，但智能体如何进行结构组织以实现最优合作尚待探索。方法：提出一个三阶段框架，包括智能体选择、结构分析和拓扑合成，涉及语言模型、强化学习、图学习和生成式建模等领域。效果：该框架有望挖掘MASs在复杂现实应用中的全部潜力，为多系统评估带来新机遇，为智能体AI时代提供新见解。
            arXiv:2505.22467v1 Announce Type: cross 
Abstract: Large Language Model-based Multi-Agent Systems (MASs) have emerged as a powerful paradigm for tackling complex tasks through collaborative intelligence. Nevertheless, the question of how agents should be structurally organized for optimal cooperation remains largely unexplored. In this position paper, we aim to gently redirect the focus of the MAS research community toward this critical dimension: develop topology-aware MASs for specific tasks. Specifically, the system consists of three core components - agents, communication links, and communication patterns - that collectively shape its coordination performance and efficiency. To this end, we introduce a systematic, three-stage framework: agent selection, structure profiling, and topology synthesis. Each stage would trigger new research opportunities in areas such as language models, reinforcement learning, graph learning, and generative modeling; together, they could unleash the full potential of MASs in complicated real-world applications. Then, we discuss the potential challenges and opportunities in the evaluation of multiple systems. We hope our perspective and framework can offer critical new insights in the era of agentic AI.
        ]]></description>
    </item>
    <item>
        <title>Decoupled Subgraph Federated Learning</title>
        <link>https://arxiv.org/abs/2402.19163</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2402.19163v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Javad Aliakbari, Johan \"Ostman, Alexandre Graell i Amat</dc:creator>
        <description><![CDATA[
            背景：解决跨多客户端的图结构数据联邦学习难题，尤其关注相互连接子图的常见场景。方法：提出名为FedStruct的框架，利用深度结构依赖，不共享或生成敏感节点特征或嵌入，而是借助显式全局图结构信息捕捉节点间依赖。效果：在六个半监督节点分类数据集上实验验证，在不同数据划分方法、标签可用性和客户端数量等场景下，性能接近集中式方法。
            arXiv:2402.19163v3 Announce Type: replace 
Abstract: We address the challenge of federated learning on graph-structured data distributed across multiple clients. Specifically, we focus on the prevalent scenario of interconnected subgraphs, where interconnections between different clients play a critical role. We present a novel framework for this scenario, named FedStruct, that harnesses deep structural dependencies. To uphold privacy, unlike existing methods, FedStruct eliminates the necessity of sharing or generating sensitive node features or embeddings among clients. Instead, it leverages explicit global graph structure information to capture inter-node dependencies. We validate the effectiveness of FedStruct through experimental results conducted on six datasets for semi-supervised node classification, showcasing performance close to the centralized approach across various scenarios, including different data partitioning methods, varying levels of label availability, and number of clients.
        ]]></description>
    </item>
    <item>
        <title>Learning Latent Graph Structures and their Uncertainty</title>
        <link>https://arxiv.org/abs/2405.19933</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2405.19933v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Alessandro Manenti, Daniele Zambon, Cesare Alippi</dc:creator>
        <description><![CDATA[
            背景：图神经网络利用关系信息提升预测性能，但任务相关关系常未知，需从数据中学习图结构，且无图观测为可学习关系提供训练信号。方法：证明最小化点预测损失不能保证学习潜在关系信息及其不确定性，提出合适损失函数可同时解决学习潜在图未知分布和实现目标变量最优预测两个任务，并给出基于采样的联合学习方法。效果：实证结果验证了理论，证明了方法的有效性。
            arXiv:2405.19933v2 Announce Type: replace 
Abstract: Graph neural networks use relational information as an inductive bias to enhance prediction performance. Not rarely, task-relevant relations are unknown and graph structure learning approaches have been proposed to learn them from data. Given their latent nature, no graph observations are available to provide a direct training signal to the learnable relations. Therefore, graph topologies are typically learned on the prediction task alongside the other graph neural network parameters. In this paper, we demonstrate that minimizing point-prediction losses does not guarantee proper learning of the latent relational information and its associated uncertainty. Conversely, we prove that suitable loss functions on the stochastic model outputs simultaneously grant solving two tasks: (i) learning the unknown distribution of the latent graph and (ii) achieving optimal predictions of the target variable. Finally, we propose a sampling-based method that solves this joint learning task. Empirical results validate our theoretical claims and demonstrate the effectiveness of the proposed approach.
        ]]></description>
    </item>
    <item>
        <title>Rethinking GNN Expressive Power from a Distributed Computational Model Perspective</title>
        <link>https://arxiv.org/abs/2410.01308</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.01308v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Guanyu Cui, Yuhe Guo, Zhewei Wei, Hsin-Hao Su</dc:creator>
        <description><![CDATA[
            背景：现有图神经网络（GNN）表达能力的理论研究常通过与Weisfeiler - Lehman（WL）测试对齐，但多关注区分图结构能力，而非计算或逼近特定函数类。方法：采用修改后的CONGEST模型分析GNN表达能力。结果：发现无限制预处理或引入外部计算特征可能有问题，模拟WL测试一次迭代的GNN容量下界随图规模近线性增长，WL测试与消息传递GNN不匹配；也从计算模型角度给出虚拟节点和边影响的积极结果，并指出待探索问题。
            arXiv:2410.01308v3 Announce Type: replace 
Abstract: The success of graph neural networks (GNNs) has motivated theoretical studies on their expressive power, often through alignments with the Weisfeiler-Lehman (WL) tests. However, such analyses typically focus on the ability of GNNs to distinguish between graph structures, rather than to compute or approximate specific function classes. The latter is more commonly studied in machine learning theory, including results such as the Turing completeness of recurrent networks and the universal approximation property of feedforward networks. We argue that using well-defined computational models, such as a modified CONGEST model with clearly specified preprocessing and postprocessing, offers a more sound framework for analyzing GNN expressiveness. Within this framework, we show that allowing unrestricted preprocessing or incorporating externally computed features, while claiming that these precomputations enhance the expressiveness, can sometimes lead to problems. We also show that the lower bound on a GNN's capacity (depth multiplied by width) to simulate one iteration of the WL test actually grows nearly linearly with graph size, indicating that the WL test is not locally computable and is misaligned with message-passing GNNs. Despite these negative results, we also present positive results that characterize the effects of virtual nodes and edges from a computational model perspective. Finally, we highlight several open problems regarding GNN expressiveness for further exploration.
        ]]></description>
    </item>
    <item>
        <title>Exploring the Limitations of Mamba in COPY and CoT Reasoning</title>
        <link>https://arxiv.org/abs/2410.03810</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.03810v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ruifeng Ren, Zhicong Li, Yong Liu</dc:creator>
        <description><![CDATA[
            背景：Transformer在长序列建模时推理开销随序列长度线性增长，Mamba因推理大小恒定受关注。方法：分析Mamba执行COPY操作和思维链（CoT）推理的表达能力，对比其与Transformer的表现。结果：固定大小的Mamba执行COPY操作较难，当大小随输入序列长度线性增长时可准确执行，但无开销节省；解决任意动态规划问题时，Mamba总开销与Transformer相当，在局部性问题上有开销节省，实验也显示其在学习COPY和CoT任务上有局限。
            arXiv:2410.03810v2 Announce Type: replace 
Abstract: Transformers have become the backbone of modern Large Language Models (LLMs); however, their inference overhead grows linearly with the sequence length, posing challenges for modeling long sequences. In light of this, Mamba has attracted attention for maintaining a constant inference size, with empirical evidence demonstrating that it can match Transformer performance in sequence modeling while significantly reducing computational costs. However, an open question remains: can Mamba always bring savings while achieving performance comparable to Transformers? In this paper, we focus on analyzing the expressive ability of Mamba to perform our defined COPY operation and Chain of Thought (CoT) reasoning. First, inspired by the connection between Mamba and linear attention, we show that constant-sized Mamba may struggle to perform COPY operations while Transformers can handle them more easily. However, when the size of Mamba grows linearly with the input sequence length, it can accurately perform COPY, but in this case, Mamba no longer provides overhead savings. Based on this observation, we further analyze Mamba's ability to tackle CoT tasks, which can be described by the Dynamic Programming (DP) problems. Our findings suggest that to solve arbitrary DP problems, the total cost of Mamba is still comparable to standard Transformers. However, similar to efficient Transformers, when facing DP problems with favorable properties such as locality, Mamba can provide savings in overhead. Our experiments on the copy and CoT tasks further demonstrate Mamba's limitations compared to Transformers in learning these tasks.
        ]]></description>
    </item>
    <item>
        <title>Graph-constrained Reasoning: Faithful Reasoning on Knowledge Graphs with Large Language Models</title>
        <link>https://arxiv.org/abs/2410.13080</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.13080v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Linhao Luo, Zicheng Zhao, Gholamreza Haffari, Yuan-Fang Li, Chen Gong, Shirui Pan</dc:creator>
        <description><![CDATA[
            背景：大语言模型推理时存在知识缺口和幻觉问题，现有知识图谱增强方法在检索知识和遍历图谱上有困难。方法：提出图约束推理（GCR）框架，通过KG - Trie将知识图谱结构融入大模型解码过程，消除幻觉；利用轻量级知识图谱专用大模型进行图约束推理，结合通用大模型对多推理路径归纳推理。效果：在多个知识图谱问答基准测试中达最优，对未见知识图谱零样本泛化能力强，推理无幻觉。
            arXiv:2410.13080v2 Announce Type: replace 
Abstract: Large language models (LLMs) have demonstrated impressive reasoning abilities, but they still struggle with faithful reasoning due to knowledge gaps and hallucinations. To address these issues, knowledge graphs (KGs) have been utilized to enhance LLM reasoning through their structured knowledge. However, existing KG-enhanced methods, either retrieval-based or agent-based, encounter difficulties in accurately retrieving knowledge and efficiently traversing KGs at scale. In this work, we introduce graph-constrained reasoning (GCR), a novel framework that bridges structured knowledge in KGs with unstructured reasoning in LLMs. To eliminate hallucinations, GCR ensures faithful KG-grounded reasoning by integrating KG structure into the LLM decoding process through KG-Trie, a trie-based index that encodes KG reasoning paths. KG-Trie constrains the decoding process, allowing LLMs to directly reason on graphs and generate faithful reasoning paths grounded in KGs. Additionally, GCR leverages a lightweight KG-specialized LLM for graph-constrained reasoning alongside a powerful general LLM for inductive reasoning over multiple reasoning paths, resulting in accurate reasoning with zero reasoning hallucination. Extensive experiments on several KGQA benchmarks demonstrate that GCR achieves state-of-the-art performance and exhibits strong zero-shot generalizability to unseen KGs without additional training.
        ]]></description>
    </item>
    <item>
        <title>GNNs-to-MLPs by Teacher Injection and Dirichlet Energy Distillation</title>
        <link>https://arxiv.org/abs/2412.11180</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2412.11180v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ziang Zhou, Zhihao Ding, Jieming Shi, Qing Li, Shiqi Shen</dc:creator>
        <description><![CDATA[
            背景：图神经网络（GNNs）在图学习中至关重要，但推理时需多跳数据，限制了其在低延迟场景的应用，且现有将GNNs蒸馏为多层感知机（MLPs）的方法未充分利用GNNs的层级信息。方法：提出TINED方法，通过教师注入和狄利克雷能量蒸馏技术逐层将GNNs蒸馏为MLPs，直接转移GNN中特征变换（FT）的参数到MLP的全连接层并微调，用狄利克雷能量开发DE比率测量FT和图传播（GP）的平滑效果并进行蒸馏。效果：在多个设置和七个数据集上优于GNNs和领先的蒸馏方法。
            arXiv:2412.11180v2 Announce Type: replace 
Abstract: Graph Neural Networks (GNNs) are pivotal in graph-based learning, particularly excelling in node classification. However, their scalability is hindered by the need for multi-hop data during inference, limiting their application in latency-sensitive scenarios. Recent efforts to distill GNNs into multi-layer perceptrons (MLPs) for faster inference often underutilize the layer-level insights of GNNs. In this paper, we present TINED, a novel approach that distills GNNs to MLPs on a layer-by-layer basis using Teacher Injection and Dirichlet Energy Distillation techniques. We focus on two key operations in GNN layers: feature transformation (FT) and graph propagation (GP). We recognize that FT is computationally equivalent to a fully-connected (FC) layer in MLPs. Thus, we propose directly transferring teacher parameters from an FT in a GNN to an FC layer in the student MLP, enhanced by fine-tuning. In TINED, the FC layers in an MLP replicate the sequence of FTs and GPs in the GNN. We also establish a theoretical bound for GP approximation. Furthermore, we note that FT and GP operations in GNN layers often exhibit opposing smoothing effects: GP is aggressive, while FT is conservative. Using Dirichlet energy, we develop a DE ratio to measure these effects and propose Dirichlet Energy Distillation to convey these characteristics from GNN layers to MLP layers. Extensive experiments show that TINED outperforms GNNs and leading distillation methods across various settings and seven datasets. Source code are available at https://github.com/scottjiao/TINED_ICML25/.
        ]]></description>
    </item>
    <item>
        <title>Domaino1s: Guiding LLM Reasoning for Explainable Answers in High-Stakes Domains</title>
        <link>https://arxiv.org/abs/2501.14431</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2501.14431v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xu Chu, Zhijie Tan, Hanlin Xue, Guanyu Wang, Tong Mo, Weiping Li</dc:creator>
        <description><![CDATA[
            背景：大语言模型用于高风险领域任务时，通常只生成无推理过程和解释的简短答案，原思维链缺乏推理中的自我修正机制。方法：提出Domaino1s，通过监督微调与树搜索增强大模型在领域任务的推理能力，构建数据集用于微调模型，提出选择性树探索来探索解空间和采样最优推理路径，引入新指标PROOF - Score评估可解释性。效果：在股票投资推荐和法律推理问答任务中表现领先且可解释性强。
            arXiv:2501.14431v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) are widely applied to downstream domains. However, current LLMs for high-stakes domain tasks, such as financial investment and legal QA, typically generate brief answers without reasoning processes and explanations. This limits users' confidence in making decisions based on their responses. While original CoT shows promise, it lacks self-correction mechanisms during reasoning. This work introduces Domain$o1$s, which enhances LLMs' reasoning capabilities on domain tasks through supervised fine-tuning and tree search. We construct CoT-stock-2k and CoT-legal-2k datasets for fine-tuning models that activate domain-specific reasoning steps based on their judgment. Additionally, we propose Selective Tree Exploration to spontaneously explore solution spaces and sample optimal reasoning paths to improve performance. We also introduce PROOF-Score, a new metric for evaluating domain models' explainability, complementing traditional accuracy metrics with richer assessment dimensions. Extensive experiments on stock investment recommendation and legal reasoning QA tasks demonstrate Domaino1s's leading performance and explainability. Our code is available at https://github.com/Hyalinesky/Domaino1s.
        ]]></description>
    </item>
    <item>
        <title>Improving Rule-based Reasoning in LLMs using Neurosymbolic Representations</title>
        <link>https://arxiv.org/abs/2502.01657</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.01657v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Varun Dhanraj, Chris Eliasmith</dc:creator>
        <description><![CDATA[
            背景：大语言模型在解决推理任务，尤其是需精确遵循规则的数学推理任务时存在挑战。方法：提出一种神经符号方法，将隐藏状态编码为神经符号向量，在神经符号向量空间中解决问题，解码结果并与原始隐藏状态合并。效果：该方法提升了模型在数值推理任务中的表现，在数学推理任务中，相比思维链提示和监督微调（LoRA），平均交叉熵损失降低88.6%，正确解决问题数量多15.4倍，且不影响其他任务性能。
            arXiv:2502.01657v3 Announce Type: replace 
Abstract: Large language models (LLMs) continue to face challenges in reliably solving reasoning tasks, particularly those that require precise rule following, as often found in mathematical reasoning. This paper introduces a novel neurosymbolic method that improves LLM reasoning by encoding hidden states into neurosymbolic vectors, enabling problem-solving within a neurosymbolic vector space. The results are decoded and merged with the original hidden state, significantly boosting the model's performance on numerical reasoning tasks. By offloading computation through neurosymbolic representations, this method enhances efficiency, reliability, and interpretability. Experimental results demonstrate an average of 88.6% lower cross-entropy loss and 15.4 times more problems correctly solved on a suite of mathematical reasoning tasks compared to chain-of-thought prompting and supervised fine-tuning (LoRA), without degrading performance on other tasks. We make our code available at: https://github.com/vdhanraj/Neurosymbolic-LLM.
        ]]></description>
    </item>
    <item>
        <title>Advancing Reasoning in Large Language Models: Promising Methods and Approaches</title>
        <link>https://arxiv.org/abs/2502.03671</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.03671v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Avinash Patil, Aryan Jadon</dc:creator>
        <description><![CDATA[
            背景：大语言模型在自然语言处理任务表现出色，但推理能力仍是挑战，复杂推理常难达人类预期。方法：该综述对提升大语言模型推理能力的新兴技术进行全面回顾，将现有方法分为提示策略、架构创新和学习范式等。还探讨了评估框架，指出幻觉、鲁棒性等开放挑战。效果：综合近期进展，为推理增强大语言模型的未来研究和应用提供了有前景的方向。
            arXiv:2502.03671v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have succeeded remarkably in various natural language processing (NLP) tasks, yet their reasoning capabilities remain a fundamental challenge. While LLMs exhibit impressive fluency and factual recall, their ability to perform complex reasoning-spanning logical deduction, mathematical problem-solving, commonsense inference, and multi-step reasoning-often falls short of human expectations. This survey provides a comprehensive review of emerging techniques enhancing reasoning in LLMs. We categorize existing methods into key approaches, including prompting strategies (e.g., Chain-of-Thought reasoning, Self-Consistency, and Tree-of-Thought reasoning), architectural innovations (e.g., retrieval-augmented models, modular reasoning networks, and neuro-symbolic integration), and learning paradigms (e.g., fine-tuning with reasoning-specific datasets, reinforcement learning, and self-supervised reasoning objectives). Additionally, we explore evaluation frameworks used to assess reasoning in LLMs and highlight open challenges, such as hallucinations, robustness, and reasoning generalization across diverse tasks. By synthesizing recent advancements, this survey aims to provide insights into promising directions for future research and practical applications of reasoning-augmented LLMs.
        ]]></description>
    </item>
    <item>
        <title>Beyond External Monitors: Enhancing Transparency of Large Language Models for Easier Monitoring</title>
        <link>https://arxiv.org/abs/2502.05242</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.05242v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Guanxu Chen, Dongrui Liu, Tao Luo, Lijie Hu, Jing Shao</dc:creator>
        <description><![CDATA[
            背景：大语言模型能力渐强，但思维和决策机制不明，思维链难以准确反映其思维过程，以往方法多开发外部监控器。方法：提出TELLME方法，提升大语言模型透明度，助监控器识别不当和敏感行为。效果：在可信度任务中，大语言模型在透明度和任务表现上持续提升，且通过最优传输理论从理论上分析了该方法对大语言模型泛化能力的提升。
            arXiv:2502.05242v2 Announce Type: replace 
Abstract: Large language models (LLMs) are becoming increasingly capable, but the mechanisms of their thinking and decision-making process remain unclear. Chain-of-thoughts (CoTs) have been commonly utilized to monitor LLMs, but this strategy fails to accurately reflect LLMs' thinking process. Techniques based on LLMs' hidden representations provide an inner perspective to monitor their latent thinking. However, previous methods only try to develop external monitors instead of making LLMs themselves easier to monitor. In this paper, we propose a novel method TELLME, improving the transparency of LLMs and helping monitors identify unsuitable and sensitive behaviors. Furthermore, we showcase the applications of TELLME on trustworthiness tasks (\eg, safety risks monitoring tasks and detoxification tasks), where LLMs achieve consistent improvement in transparency and task performance. More crucially, we theoretically analyze the improvement of TELLME on LLMs' generalization ability through optimal transport theory.
        ]]></description>
    </item>
    <item>
        <title>Non-Markovian Discrete Diffusion with Causal Language Models</title>
        <link>https://arxiv.org/abs/2502.09767</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.09767v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yangtian Zhang, Sizhuang He, Daniel Levine, Lawrence Zhao, David Zhang, Syed A Rizvi, Emanuele Zappala, Rex Ying, David van Dijk</dc:creator>
        <description><![CDATA[
            背景：离散扩散模型用于结构化序列生成有优势，但表达能力不如因果语言模型，依赖马尔可夫假设会导致错误积累。方法：提出CaDDi离散扩散模型，基于整个生成轨迹进行条件设置，解除马尔可夫约束，可修正过去状态；在非马尔可夫变压器中统一顺序和时间推理，能直接复用预训练大语言模型权重。效果：在自然语言基准测试中，CaDDi优于现有离散扩散模型基线，大幅缩小与大型自回归变压器的差距。
            arXiv:2502.09767v2 Announce Type: replace 
Abstract: Discrete diffusion models offer a flexible, controllable approach to structured sequence generation, yet they still lag behind causal language models in expressive power. A key limitation lies in their reliance on the Markovian assumption, which restricts each step to condition only on the current state, leading to potential uncorrectable error accumulation. In this paper, we introduce CaDDi, a discrete diffusion model that conditions on the entire generative trajectory, thereby lifting the Markov constraint and allowing the model to revisit and improve past states. By unifying sequential (causal) and temporal (diffusion) reasoning in a single non-Markovian transformer, CaDDi also treats standard causal language models as a special case and permits the direct reuse of pretrained LLM weights with no architectural changes. Empirically, CaDDi outperforms state-of-the-art discrete diffusion baselines on natural-language benchmarks, substantially narrowing the remaining gap to large autoregressive transformers.
        ]]></description>
    </item>
    <item>
        <title>How Do LLMs Perform Two-Hop Reasoning in Context?</title>
        <link>https://arxiv.org/abs/2502.13913</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.13913v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tianyu Guo, Hanlin Zhu, Ruiqi Zhang, Jiantao Jiao, Song Mei, Michael I. Jordan, Stuart Russell</dc:creator>
        <description><![CDATA[
            背景：两跳推理是人类推理基本组成部分，但大语言模型（LLMs）在有干扰项时解决简单两跳推理问题常失败。方法：在合成数据集上观察预训练LLMs表现，经少量微调训练模型，还从零训练3层Transformer并逆向分析其信息流。效果：微调后模型接近完美准确率且有强长度泛化能力；训练中注意力对数有明显变化，从随机猜测过渡到结构化顺序查询机制；三参数仅注意力网络可捕捉这些动态。
            arXiv:2502.13913v2 Announce Type: replace 
Abstract: ``Socrates is human. All humans are mortal. Therefore, Socrates is mortal.'' This form of argument illustrates a typical pattern of two-hop reasoning. Formally, two-hop reasoning refers to the process of inferring a conclusion by making two logical steps, each connecting adjacent concepts, such that the final conclusion depends on the integration of both steps. It is one of the most fundamental components of human reasoning and plays a crucial role in both formal logic and everyday decision-making. Despite recent progress in large language models (LLMs), we surprisingly find that they can fail at solving simple two-hop reasoning problems when distractors are present. We observe on a synthetic dataset that pre-trained LLMs often resort to random guessing among all plausible conclusions. However, after few steps of fine-tuning, models achieve near-perfect accuracy and exhibit strong length generalization. To understand the underlying mechanisms, we train a 3-layer Transformer from scratch on a synthetic two-hop reasoning task and reverse-engineer its internal information flow. We observe a clear progression in the attention logits throughout training. This pictures a sharp phase transition from an initial stage of random guessing to the emergence of a structured sequential query mechanism, where the model first retrieves the preceding and the bridge concepts in the early layers and then uses them to infer the final answer. Finally, we show that these dynamics can be captured by a minimal three-parameter attention-only network.
        ]]></description>
    </item>
    <item>
        <title>Mitigating Lost-in-Retrieval Problems in Retrieval Augmented Multi-Hop Question Answering</title>
        <link>https://arxiv.org/abs/2502.14245</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.14245v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Rongzhi Zhu, Xiangyu Liu, Zequn Sun, Yiwei Wang, Wei Hu</dc:creator>
        <description><![CDATA[
            背景：检索增强的多跳问答中存在“lost-in-retrieval”问题，即大语言模型在子问题分解时遗漏关键实体，影响检索性能和推理链。方法：提出渐进式检索和重写方法ChainRAG，通过补充缺失关键实体、从句子图中检索相关句子依次处理子问题，各步骤相互衔接。效果：在三个多跳问答数据集上用三种大模型评估，结果显示ChainRAG在有效性和效率上均优于基线。
            arXiv:2502.14245v2 Announce Type: replace 
Abstract: In this paper, we identify a critical problem, "lost-in-retrieval", in retrieval-augmented multi-hop question answering (QA): the key entities are missed in LLMs' sub-question decomposition. "Lost-in-retrieval" significantly degrades the retrieval performance, which disrupts the reasoning chain and leads to the incorrect answers. To resolve this problem, we propose a progressive retrieval and rewriting method, namely ChainRAG, which sequentially handles each sub-question by completing missing key entities and retrieving relevant sentences from a sentence graph for answer generation. Each step in our retrieval and rewriting process builds upon the previous one, creating a seamless chain that leads to accurate retrieval and answers. Finally, all retrieved sentences and sub-question answers are integrated to generate a comprehensive answer to the original question. We evaluate ChainRAG on three multi-hop QA datasets - MuSiQue, 2Wiki, and HotpotQA - using three large language models: GPT4o-mini, Qwen2.5-72B, and GLM-4-Plus. Empirical results demonstrate that ChainRAG consistently outperforms baselines in both effectiveness and efficiency.
        ]]></description>
    </item>
    <item>
        <title>GraphCheck: Breaking Long-Term Text Barriers with Extracted Knowledge Graph-Powered Fact-Checking</title>
        <link>https://arxiv.org/abs/2502.16514</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.16514v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yingjian Chen, Haoran Liu, Yinhong Liu, Jinxiang Xie, Rui Yang, Han Yuan, Yanran Fu, Peng Yuan Zhou, Qingyu Chen, James Caverlee, Irene Li</dc:creator>
        <description><![CDATA[
            背景：大语言模型常产生事实错误，现有基于文档的事实核查方法存在难以理解长文档复杂多跳关系、成本高等问题。方法：提出GraphCheck框架，利用提取的知识图谱增强文本表示，用图神经网络处理图谱作为软提示，使大模型更有效整合结构化知识，结合基于图的推理。效果：在七个通用和医学领域基准测试中，较基线模型整体提升达7.1%，优于现有专业核查器，参数更少时与先进大模型性能相当。
            arXiv:2502.16514v4 Announce Type: replace 
Abstract: Large language models (LLMs) are widely used, but they often generate subtle factual errors, especially in long-form text. These errors are fatal in some specialized domains such as medicine. Existing fact-checking with grounding documents methods face two main challenges: (1) they struggle to understand complex multihop relations in long documents, often overlooking subtle factual errors; (2) most specialized methods rely on pairwise comparisons, requiring multiple model calls, leading to high resource and computational costs. To address these challenges, we propose GraphCheck, a fact-checking framework that uses extracted knowledge graphs to enhance text representation. Graph Neural Networks further process these graphs as a soft prompt, enabling LLMs to incorporate structured knowledge more effectively. Enhanced with graph-based reasoning, GraphCheck captures multihop reasoning chains that are often overlooked by existing methods, enabling precise and efficient fact-checking in a single inference call. Experimental results on seven benchmarks spanning both general and medical domains demonstrate up to a 7.1% overall improvement over baseline models. Notably, GraphCheck outperforms existing specialized fact-checkers and achieves comparable performance with state-of-the-art LLMs, such as DeepSeek-V3 and OpenAI-o1, with significantly fewer parameters.
        ]]></description>
    </item>
    <item>
        <title>Personalized Causal Graph Reasoning for LLMs: A Case Study on Dietary Recommendations</title>
        <link>https://arxiv.org/abs/2503.00134</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.00134v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhongqi Yang, Amir Rahmani</dc:creator>
        <description><![CDATA[
            背景：大语言模型在利用常识知识进行通用推理时表现有效，但在解读多因素个人数据进行个性化推理时存在困难，限制了其在需个性化决策领域的应用。方法：提出个性化因果图推理框架，将从个人数据中提取的因果图融入大语言模型推理过程。效果：在营养导向的饮食推荐案例中，该方法能有效提供个性化饮食推荐，降低三个时间窗口内的平均血糖iAUC，优于先前方法，且经评估提升了推理过程的个性化程度。
            arXiv:2503.00134v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) effectively leverage common-sense knowledge for general reasoning, yet they struggle with personalized reasoning when tasked with interpreting multifactor personal data. This limitation restricts their applicability in domains that require context-aware decision-making tailored to individuals. This paper introduces Personalized Causal Graph Reasoning as an agentic framework that enhances LLM reasoning by incorporating personal causal graphs derived from data of individuals. These graphs provide a foundation that guides the LLM's reasoning process. We evaluate it on a case study on nutrient-oriented dietary recommendations, which requires personal reasoning due to the implicit unique dietary effects. We propose a counterfactual evaluation to estimate the efficiency of LLM-recommended foods for glucose management. Results demonstrate that the proposed method efficiently provides personalized dietary recommendations to reduce average glucose iAUC across three time windows, which outperforms the previous approach. LLM-as-a-judge evaluation results indicate that our proposed method enhances personalization in the reasoning process.
        ]]></description>
    </item>
    <item>
        <title>Explainable Multi-modal Time Series Prediction with LLM-in-the-Loop</title>
        <link>https://arxiv.org/abs/2503.01013</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.01013v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yushan Jiang, Wenchao Yu, Geon Lee, Dongjin Song, Kijung Shin, Wei Cheng, Yanchi Liu, Haifeng Chen</dc:creator>
        <description><![CDATA[
            背景：现有时间序列分析方法常忽略辅助模态中的丰富上下文信号。方法：提出多模态预测框架TimeXL，将基于原型的时间序列编码器与三个协作大语言模型集成。先用编码器处理时间序列和文本输入得到初步预测与解释，再由预测大模型细化预测，反思大模型对比预测与真实值，细化大模型迭代提升文本质量并触发编码器再训练。效果：在四个真实数据集上，AUC最多提升8.9%，能生成以人类为中心的多模态解释。
            arXiv:2503.01013v2 Announce Type: replace 
Abstract: Time series analysis provides essential insights for real-world system dynamics and informs downstream decision-making, yet most existing methods often overlook the rich contextual signals present in auxiliary modalities. To bridge this gap, we introduce TimeXL, a multi-modal prediction framework that integrates a prototype-based time series encoder with three collaborating Large Language Models (LLMs) to deliver more accurate predictions and interpretable explanations. First, a multi-modal prototype-based encoder processes both time series and textual inputs to generate preliminary forecasts alongside case-based rationales. These outputs then feed into a prediction LLM, which refines the forecasts by reasoning over the encoder's predictions and explanations. Next, a reflection LLM compares the predicted values against the ground truth, identifying textual inconsistencies or noise. Guided by this feedback, a refinement LLM iteratively enhances text quality and triggers encoder retraining. This closed-loop workflow -- prediction, critique (reflect), and refinement -- continuously boosts the framework's performance and interpretability. Empirical evaluations on four real-world datasets demonstrate that TimeXL achieves up to 8.9\% improvement in AUC and produces human-centric, multi-modal explanations, highlighting the power of LLM-driven reasoning for time series prediction.
        ]]></description>
    </item>
    <item>
        <title>TS-RAG: Retrieval-Augmented Generation based Time Series Foundation Models are Stronger Zero-Shot Forecaster</title>
        <link>https://arxiv.org/abs/2503.07649</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.07649v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kanghui Ning, Zijie Pan, Yu Liu, Yushan Jiang, James Y. Zhang, Kashif Rasul, Anderson Schneider, Lintao Ma, Yuriy Nevmyvaka, Dongjin Song</dc:creator>
        <description><![CDATA[
            背景：大语言模型和基础模型用于时间序列预测时，微调模型泛化能力差，现有时间序列基础模型处理非平稳动态和分布偏移能力不足。方法：提出TS - RAG，利用预训练时间序列编码器从知识库检索相关片段，丰富输入查询的上下文表示，还提出自适应检索混合器模块动态融合检索模式和模型内部表示。效果：在七个公开基准数据集上实现了零样本预测的最优性能，在不同领域比现有模型最高提升6.84%，且具有良好可解释性。
            arXiv:2503.07649v3 Announce Type: replace 
Abstract: Large Language Models (LLMs) and Foundation Models (FMs) have recently become prevalent for time series forecasting tasks. While fine-tuning LLMs enables domain adaptation, they often struggle to generalize across diverse and unseen datasets. Moreover, existing Time Series Foundation Models (TSFMs) still face challenges in handling non-stationary dynamics and distribution shifts, largely due to the lack of effective mechanisms for adaptation. To this end, we present TS-RAG, a retrieval-augmented generation framework for time series forecasting that enhances the generalization and interpretability of TSFMs. Specifically, TS-RAG leverages pre-trained time series encoders to retrieve semantically relevant segments from a dedicated knowledge base, enriching the contextual representation of the input query. Furthermore, we propose an Adaptive Retrieval Mixer (ARM) module that dynamically fuses the retrieved patterns with the TSFM's internal representation, improving forecasting accuracy without requiring task-specific fine-tuning. Thorough empirical studies on seven public benchmark datasets demonstrate that TS-RAG achieves state-of-the-art zero-shot forecasting performance, outperforming the existing TSFMs by up to 6.84% across diverse domains while also providing desirable interpretability.
        ]]></description>
    </item>
    <item>
        <title>Light-R1: Curriculum SFT, DPO and RL for Long COT from Scratch and Beyond</title>
        <link>https://arxiv.org/abs/2503.10460</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.10460v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Liang Wen, Yunke Cai, Fenrui Xiao, Xin He, Qi An, Zhenyu Duan, Yimin Du, Junchen Liu, Lifu Tang, Xiaowei Lv, Haosheng Zou, Yongchao Deng, Shousheng Jia, Xiangzheng Zhang</dc:creator>
        <description><![CDATA[
            背景：DeepSeek - R1系列使用专有数据，本文开发替代方法。方法：提出开源套件Light - R1，采用课程训练逐步增加数据难度，结合多阶段后训练，还在长推理模型上应用GRPO。效果：基于Qwen2.5 - 32B - Instruct训练的Light - R1 - 32B在数学推理上优于DeepSeek - R1 - Distill - Qwen - 32B；Light - R1 - 14B - DS在数学推理上达14B模型最优，AIME24和25得分分别为74.0和60.2，超越众多32B模型和DeepSeek - R1 - Distill - Llama - 70B，且有强跨领域泛化能力。
            arXiv:2503.10460v4 Announce Type: replace 
Abstract: This paper introduces Light-R1, an open-source suite for training long reasoning models using reproducible and cost-effective methodology. Given the proprietary nature of data used in the DeepSeek-R1 series, we develop an alternative approach leveraging exclusively public data and models. Our curriculum training progressively increases data difficulty, combined with multi-staged post-training. Our Light-R1-32B model, trained from Qwen2.5-32B-Instruct, outperforms DeepSeek-R1-Distill-Qwen-32B in math reasoning.
  Experimental results show that this curriculum approach becomes more effective when distinct, diverse datasets are available for different training stages: fine-tuning DeepSeek-R1-Distilled models (pre-tuned by DeepSeek team on proprietary data) with 3,000 challenging examples from our curriculum dataset yielded state-of-the-art 7B and 14B models, while the 32B model, Light-R1-32B-DS performed comparably to QwQ-32B and DeepSeek-R1.
  Furthermore, we extend our work by applying GRPO on long reasoning models. Our final Light-R1-14B-DS achieves SOTA performance among 14B models in math, with AIME24 & 25 scores of 74.0 and 60.2 respectively, surpassing many 32B models and DeepSeek-R1-Distill-Llama-70B. Despite math-focused training, Light-R1-14B-DS demonstrates strong cross-domain generalization.
  Light-R1 represents a significant advancement in making sophisticated reasoning models more accessible and implementable in real-world applications. Our models, training data and code have been made available at https://github.com/Qihoo360/Light-R1.
        ]]></description>
    </item>
    <item>
        <title>Experience Retrieval-Augmentation with Electronic Health Records Enables Accurate Discharge QA</title>
        <link>https://arxiv.org/abs/2503.17933</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.17933v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Justice Ou, Tinglin Huang, Yilun Zhao, Ziyang Yu, Peiqing Lu, Rex Ying</dc:creator>
        <description><![CDATA[
            背景：为提升大语言模型在临床应用中的可靠性，检索增强生成（RAG）被广泛应用，但基于临床案例的知识对有效医疗推理也很关键。方法：提出基于电子健康记录（EHR）的经验检索增强ExpRAG框架，通过粗到细的检索过程，利用基于EHR的报告排序器识别相似患者，再用经验检索器提取相关内容用于医疗推理。效果：在新引入的含1280个问题的临床问答数据集DischargeQA上，ExpRAG平均相对提升5.2%，优于基于文本的排序器。 
            arXiv:2503.17933v2 Announce Type: replace 
Abstract: To improve the reliability of Large Language Models (LLMs) in clinical applications, retrieval-augmented generation (RAG) is extensively applied to provide factual medical knowledge. However, beyond general medical knowledge from open-ended datasets, clinical case-based knowledge is also critical for effective medical reasoning, as it provides context grounded in real-world patient experiences.Motivated by this, we propose Experience Retrieval-Augmentation ExpRAG framework based on Electronic Health Record(EHR), aiming to offer the relevant context from other patients' discharge reports. ExpRAG performs retrieval through a coarse-to-fine process, utilizing an EHR-based report ranker to efficiently identify similar patients, followed by an experience retriever to extract task-relevant content for enhanced medical reasoning.To evaluate ExpRAG, we introduce DischargeQA, a clinical QA dataset with 1,280 discharge-related questions across diagnosis, medication, and instruction tasks. Each problem is generated using EHR data to ensure realistic and challenging scenarios. Experimental results demonstrate that ExpRAG consistently outperforms a text-based ranker, achieving an average relative improvement of 5.2%, highlighting the importance of case-based knowledge for medical reasoning.
        ]]></description>
    </item>
    <item>
        <title>GraphOmni: A Comprehensive and Extendable Benchmark Framework for Large Language Models on Graph-theoretic Tasks</title>
        <link>https://arxiv.org/abs/2504.12764</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.12764v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hao Xu, Xiangru Jian, Xinjian Zhao, Wei Pang, Chao Zhang, Suyuchen Wang, Qixin Zhang, Zhengyuan Dong, Joao Monteiro, Bang Liu, Qiuzhuang Sun, Tianshu Yu</dc:creator>
        <description><![CDATA[
            背景：现有研究在评估大语言模型图论任务推理能力方面存在不足。方法：提出GraphOmni综合基准，涵盖多种图类型、序列化格式和提示方案，还提出受强化学习启发的框架自适应选择影响推理能力的最优因素。效果：实验表明Claude - 3.5和o4 - mini等模型表现较好，但仍有提升空间，不同因素组合下性能有差异，开源和闭源模型受序列化和提示策略影响不同，该基准为图推理研究提供了基础。
            arXiv:2504.12764v3 Announce Type: replace 
Abstract: This paper introduces GraphOmni, a comprehensive benchmark designed to evaluate the reasoning capabilities of LLMs on graph-theoretic tasks articulated in natural language. GraphOmni encompasses diverse graph types, serialization formats, and prompting schemes, significantly exceeding prior efforts in both scope and depth. Through extensive systematic evaluation, we identify critical interactions among these dimensions, demonstrating their substantial impact on model performance. Our experiments reveal that state-of-the-art models like Claude-3.5 and o4-mini consistently outperform other models, yet even these leading models exhibit substantial room for improvement. Performance variability is evident depending on the specific combinations of factors we considered, underscoring the necessity of comprehensive evaluations across these interconnected dimensions. Additionally, we observe distinct impacts of serialization and prompting strategies between open-source and closed-source models, encouraging the development of tailored approaches. Motivated by the findings, we also propose a reinforcement learning-inspired framework that adaptively selects the optimal factors influencing LLM reasoning capabilities. This flexible and extendable benchmark not only deepens our understanding of LLM performance on structured tasks but also provides a robust foundation for advancing research in LLM-based graph reasoning. The code and datasets are available at https://github.com/GAI-Community/GraphOmni.
        ]]></description>
    </item>
    <item>
        <title>Learning When to Think: Shaping Adaptive Reasoning in R1-Style Models via Multi-Stage RL</title>
        <link>https://arxiv.org/abs/2505.10832</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.10832v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Songjun Tu, Jiahao Lin, Qichao Zhang, Xiangyu Tian, Linjing Li, Xiangyuan Lan, Dongbin Zhao</dc:creator>
        <description><![CDATA[
            大推理模型在给出答案前生成详细推理序列会带来计算开销和延迟，尤其在处理简单问题时存在“过度思考”问题。为解决该问题，研究基于R1风格蒸馏模型，发现提示中插入省略号可随机触发思考或不思考模式。提出AutoThink多阶段强化学习框架，通过分阶段奖励塑造逐步优化推理策略，必要时进行显式推理，简单任务默认简洁回答。在五个数学基准测试中，相比现有方法实现了更好的准确率 - 效率权衡，在特定模型上相对准确率提升6.4%，减少52%的token使用。
            arXiv:2505.10832v2 Announce Type: replace 
Abstract: Large reasoning models (LRMs) are proficient at generating explicit, step-by-step reasoning sequences before producing final answers. However, such detailed reasoning can introduce substantial computational overhead and latency, particularly for simple problems. To address this over-thinking problem, we explore how to equip LRMs with adaptive thinking capabilities: enabling them to dynamically decide whether or not to engage in explicit reasoning based on problem complexity. Building on R1-style distilled models, we observe that inserting a simple ellipsis ("...") into the prompt can stochastically trigger either a thinking or no-thinking mode, revealing a latent controllability in the reasoning behavior. Leveraging this property, we propose AutoThink, a multi-stage reinforcement learning (RL) framework that progressively optimizes reasoning policies via stage-wise reward shaping. AutoThink learns to invoke explicit reasoning only when necessary, while defaulting to succinct responses for simpler tasks. Experiments on five mainstream mathematical benchmarks demonstrate that AutoThink achieves favorable accuracy-efficiency trade-offs compared to recent prompting and RL-based pruning methods. It can be seamlessly integrated into any R1-style model, including both distilled and further fine-tuned variants. Notably, AutoThink improves relative accuracy by 6.4 percent while reducing token usage by 52 percent on DeepSeek-R1-Distill-Qwen-1.5B, establishing a scalable and adaptive reasoning paradigm for LRMs. Project Page: https://github.com/ScienceOne-AI/AutoThink.
        ]]></description>
    </item>
    <item>
        <title>Search and Refine During Think: Autonomous Retrieval-Augmented Reasoning of LLMs</title>
        <link>https://arxiv.org/abs/2505.11277</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.11277v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yaorui Shi, Sihang Li, Chang Wu, Zhiyuan Liu, Junfeng Fang, Hengxing Cai, An Zhang, Xiang Wang</dc:creator>
        <description><![CDATA[
            背景：大语言模型推理能力强，但受知识储备限制，现有检索增强推理方法常获取无关或嘈杂信息，影响推理准确性。方法：提出AutoRefine强化学习后训练框架，采用“思考中搜索与提炼”范式，在连续搜索调用间增加知识提炼步骤，结合定制检索奖励和答案正确性奖励。效果：在单跳和多跳问答基准测试中显著优于现有方法，尤其在复杂多跳推理场景，能有效进行高质量搜索和证据合成。
            arXiv:2505.11277v2 Announce Type: replace 
Abstract: Large language models have demonstrated impressive reasoning capabilities but are inherently limited by their knowledge reservoir. Retrieval-augmented reasoning mitigates this limitation by allowing LLMs to query external resources, but existing methods often retrieve irrelevant or noisy information, hindering accurate reasoning. In this paper, we propose AutoRefine, a reinforcement learning post-training framework that adopts a new ``search-and-refine-during-think'' paradigm. AutoRefine introduces explicit knowledge refinement steps between successive search calls, enabling the model to iteratively filter, distill, and organize evidence before generating an answer. Furthermore, we incorporate tailored retrieval-specific rewards alongside answer correctness rewards using group relative policy optimization. Experiments on single-hop and multi-hop QA benchmarks demonstrate that AutoRefine significantly outperforms existing approaches, particularly in complex, multi-hop reasoning scenarios. Detailed analysis shows that AutoRefine issues frequent, higher-quality searches and synthesizes evidence effectively.
        ]]></description>
    </item>
    <item>
        <title>Advancing Sequential Numerical Prediction in Autoregressive Models</title>
        <link>https://arxiv.org/abs/2505.13077</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13077v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiang Fei, Jinghui Lu, Qi Sun, Hao Feng, Yanjie Wang, Wei Shi, An-Lan Wang, Jingqun Tang, Can Huang</dc:creator>
        <description><![CDATA[
            背景：自回归模型是序列生成任务常用模型，但标准方法将数字视为独立标记，忽略数值序列的连贯结构。方法：提出数值标记完整性损失（NTIL），在标记层面扩展地球移动距离以保留数值间顺序关系，在序列层面惩罚预测与实际序列的整体差异，该方法可与大语言模型/多模态大模型有效集成。效果：大量实验表明，NTIL显著提升了数值预测性能。
            arXiv:2505.13077v2 Announce Type: replace 
Abstract: Autoregressive models have become the de facto choice for sequence generation tasks, but standard approaches treat digits as independent tokens and apply cross-entropy loss, overlooking the coherent structure of numerical sequences. This paper introduces Numerical Token Integrity Loss (NTIL) to address this gap. NTIL operates at two levels: (1) token-level, where it extends the Earth Mover's Distance (EMD) to preserve ordinal relationships between numerical values, and (2) sequence-level, where it penalizes the overall discrepancy between the predicted and actual sequences. This dual approach improves numerical prediction and integrates effectively with LLMs/MLLMs. Extensive experiments show significant performance improvements with NTIL.
        ]]></description>
    </item>
    <item>
        <title>General-Reasoner: Advancing LLM Reasoning Across All Domains</title>
        <link>https://arxiv.org/abs/2505.14652</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14652v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xueguang Ma, Qian Liu, Dongfu Jiang, Ge Zhang, Zejun Ma, Wenhu Chen</dc:creator>
        <description><![CDATA[
            背景：现有大语言模型推理研究多聚焦数学和编码领域，在其他领域因答案多样、数据稀缺，适用性和泛化性受限。方法：提出General - Reasoner训练范式，通过网络爬虫构建大规模高质量可验证答案的问题数据集，开发基于生成模型的答案验证器，具备思维链和上下文感知能力。效果：在涵盖物理、化学等多领域的12个基准测试中，General - Reasoner表现优于现有基线方法，推理性能稳健且可泛化，数学推理任务效果也佳。
            arXiv:2505.14652v4 Announce Type: replace 
Abstract: Reinforcement learning (RL) has recently demonstrated strong potential in enhancing the reasoning capabilities of large language models (LLMs). Particularly, the "Zero" reinforcement learning introduced by Deepseek-R1-Zero, enables direct RL training of base LLMs without relying on an intermediate supervised fine-tuning stage. Despite these advancements, current works for LLM reasoning mainly focus on mathematical and coding domains, largely due to data abundance and the ease of answer verification. This limits the applicability and generalization of such models to broader domains, where questions often have diverse answer representations, and data is more scarce. In this paper, we propose General-Reasoner, a novel training paradigm designed to enhance LLM reasoning capabilities across diverse domains. Our key contributions include: (1) constructing a large-scale, high-quality dataset of questions with verifiable answers curated by web crawling, covering a wide range of disciplines; and (2) developing a generative model-based answer verifier, which replaces traditional rule-based verification with the capability of chain-of-thought and context-awareness. We train a series of models and evaluate them on a wide range of datasets covering wide domains like physics, chemistry, finance, electronics etc. Our comprehensive evaluation across these 12 benchmarks (e.g. MMLU-Pro, GPQA, SuperGPQA, TheoremQA, BBEH and MATH AMC) demonstrates that General-Reasoner outperforms existing baseline methods, achieving robust and generalizable reasoning performance while maintaining superior effectiveness in mathematical reasoning tasks.
        ]]></description>
    </item>
    <item>
        <title>AKRMap: Adaptive Kernel Regression for Trustworthy Visualization of Cross-Modal Embeddings</title>
        <link>https://arxiv.org/abs/2505.14664</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14664v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yilin Ye, Junchao Huang, Xingchen Zeng, Jiazhi Xia, Wei Zeng</dc:creator>
        <description><![CDATA[
            跨模态嵌入是多模态模型基础，但现有可视化方法局限于传统降维技术，未考虑多模态指标。本文提出AKRMap，通过学习投影空间中度量格局的核回归，以更高精度可视化跨模态嵌入度量。它构建由投影后核回归损失引导的监督投影网络，采用可与投影联合优化的自适应广义核。实验表明，AKRMap在生成更准确可信的可视化效果上优于现有降维方法，还展示了其在文本到图像模型跨模态嵌入可视化和比较中的有效性。
            arXiv:2505.14664v2 Announce Type: replace 
Abstract: Cross-modal embeddings form the foundation for multi-modal models. However, visualization methods for interpreting cross-modal embeddings have been primarily confined to traditional dimensionality reduction (DR) techniques like PCA and t-SNE. These DR methods primarily focus on feature distributions within a single modality, whilst failing to incorporate metrics (e.g., CLIPScore) across multiple modalities. This paper introduces AKRMap, a new DR technique designed to visualize cross-modal embeddings metric with enhanced accuracy by learning kernel regression of the metric landscape in the projection space. Specifically, AKRMap constructs a supervised projection network guided by a post-projection kernel regression loss, and employs adaptive generalized kernels that can be jointly optimized with the projection. This approach enables AKRMap to efficiently generate visualizations that capture complex metric distributions, while also supporting interactive features such as zoom and overlay for deeper exploration. Quantitative experiments demonstrate that AKRMap outperforms existing DR methods in generating more accurate and trustworthy visualizations. We further showcase the effectiveness of AKRMap in visualizing and comparing cross-modal embeddings for text-to-image models. Code and demo are available at https://github.com/yilinye/AKRMap.
        ]]></description>
    </item>
    <item>
        <title>Few-Shot Learning from Gigapixel Images via Hierarchical Vision-Language Alignment and Modeling</title>
        <link>https://arxiv.org/abs/2505.17982</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17982v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Bryan Wong, Jong Woo Kim, Huazhu Fu, Mun Yong Yi</dc:creator>
        <description><![CDATA[
            背景：现有视觉语言模型用于全切片图像少样本弱监督分类时，存在跨尺度同模态交互建模不足、同尺度视觉与文本模态对齐不充分的问题。方法：提出HiVE - MIL分层视觉语言框架，构建统一图捕捉层次关系，引入跨尺度边和异质同尺度边；采用两阶段文本引导动态过滤机制，引入分层对比损失。效果：在TCGA乳腺癌、肺癌和肾癌数据集上，HiVE - MIL优于传统和基于VLM的MIL方法，16样本设置下宏观F1最高提升4.1%。
            arXiv:2505.17982v3 Announce Type: replace 
Abstract: Vision-language models (VLMs) have recently been integrated into multiple instance learning (MIL) frameworks to address the challenge of few-shot, weakly supervised classification of whole slide images (WSIs). A key trend involves leveraging multi-scale information to better represent hierarchical tissue structures. However, existing methods often face two key limitations: (1) insufficient modeling of interactions within the same modalities across scales (e.g., 5x and 20x) and (2) inadequate alignment between visual and textual modalities on the same scale. To address these gaps, we propose HiVE-MIL, a hierarchical vision-language framework that constructs a unified graph consisting of (1) parent-child links between coarse (5x) and fine (20x) visual/textual nodes to capture hierarchical relationships, and (2) heterogeneous intra-scale edges linking visual and textual nodes on the same scale. To further enhance semantic consistency, HiVE-MIL incorporates a two-stage, text-guided dynamic filtering mechanism that removes weakly correlated patch-text pairs, and introduces a hierarchical contrastive loss to align textual semantics across scales. Extensive experiments on TCGA breast, lung, and kidney cancer datasets demonstrate that HiVE-MIL consistently outperforms both traditional MIL and recent VLM-based MIL approaches, achieving gains of up to 4.1% in macro F1 under 16-shot settings. Our results demonstrate the value of jointly modeling hierarchical structure and multimodal alignment for efficient and scalable learning from limited pathology data. The code is available at https://github.com/bryanwong17/HiVE-MIL
        ]]></description>
    </item>
    <item>
        <title>VTool-R1: VLMs Learn to Think with Images via Reinforcement Learning on Multimodal Tool Use</title>
        <link>https://arxiv.org/abs/2505.19255</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.19255v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mingyuan Wu, Jingcheng Yang, Jize Jiang, Meitang Li, Kaizhuo Yan, Hanchao Yu, Minjia Zhang, Chengxiang Zhai, Klara Nahrstedt</dc:creator>
        <description><![CDATA[
            背景：强化学习微调（RFT）提升了大语言模型推理能力，但扩展到视觉语言模型（VLMs）时多为基于静态图像输入的纯文本推理，缺乏真正多模态推理。方法：提出VTool - R1框架，将基于Python的视觉编辑工具集成到RFT过程，训练VLMs生成文本和中间视觉推理步骤交错的多模态思维链，用基于任务准确率的奖励训练，无需过程监督。效果：在图表结构化视觉问答实验中，VTool - R1通过让VLMs“用图像思考”，提升了推理性能。
            arXiv:2505.19255v2 Announce Type: replace 
Abstract: Reinforcement Learning Finetuning (RFT) has significantly advanced the reasoning capabilities of large language models (LLMs) by enabling long chains of thought, self-correction, and effective tool use. While recent works attempt to extend RFT to vision-language models (VLMs), these efforts largely produce text-only reasoning conditioned on static image inputs, falling short of true multimodal reasoning in the response. In contrast, test-time methods like Visual Sketchpad incorporate visual steps but lack training mechanisms.
  We introduce VTool-R1, the first framework that trains VLMs to generate multimodal chains of thought by interleaving text and intermediate visual reasoning steps. VTool-R1 integrates Python-based visual editing tools into the RFT process, enabling VLMs to learn when and how to generate visual reasoning steps that benefit final reasoning. Trained with outcome-based rewards tied to task accuracy, our approach elicits strategic visual tool use for reasoning without relying on process-based supervision. Experiments on structured visual question answering over charts and tables show that VTool-R1 enhances reasoning performance by teaching VLMs to "think with images" and generate multimodal chain of thoughts with tools.
        ]]></description>
    </item>
    <item>
        <title>Towards Large Reasoning Models for Agriculture</title>
        <link>https://arxiv.org/abs/2505.19259</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.19259v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hossein Zaremehrjerdi, Shreyan Ganguly, Ashlyn Rairdin, Elizabeth Tranel, Benjamin Feuer, Juan Ignacio Di Salvo, Srikanth Panthulugiri, Hernan Torres Pacin, Victoria Moser, Sarah Jones, Joscif G Raigne, Yanben Shen, Heidi M. Dornath, Aditya Balu, Adarsh Krishnamurthy, Asheesh K Singh, Arti Singh, Baskar Ganapathysubramanian, Chinmay Hegde, Soumik Sarkar</dc:creator>
        <description><![CDATA[
            背景：农业决策需复杂推理，传统大语言模型因推理能力有限难以应对。方法：引入含100个问题的农业推理基准AgReason，评估13种模型；构建含44.6K问答对且有人工监督和推理轨迹的数据集AgThoughts，开发可在消费级GPU运行的小型推理模型AgThinker。效果：评估显示大推理模型优于传统模型，最强的基于Gemini的基线准确率达36%，数据集能有效提升大语言模型农业推理能力。
            arXiv:2505.19259v2 Announce Type: replace 
Abstract: Agricultural decision-making involves complex, context-specific reasoning, where choices about crops, practices, and interventions depend heavily on geographic, climatic, and economic conditions. Traditional large language models (LLMs) often fall short in navigating this nuanced problem due to limited reasoning capacity. We hypothesize that recent advances in large reasoning models (LRMs) can better handle such structured, domain-specific inference. To investigate this, we introduce AgReason, the first expert-curated open-ended science benchmark with 100 questions for agricultural reasoning. Evaluations across thirteen open-source and proprietary models reveal that LRMs outperform conventional ones, though notable challenges persist, with the strongest Gemini-based baseline achieving 36% accuracy. We also present AgThoughts, a large-scale dataset of 44.6K question-answer pairs generated with human oversight and equipped with synthetically generated reasoning traces. Using AgThoughts, we develop AgThinker, a suite of small reasoning models that can be run on consumer-grade GPUs, and show that our dataset can be effective in unlocking agricultural reasoning abilities in LLMs. Our project page is here: https://baskargroup.github.io/Ag_reasoning/
        ]]></description>
    </item>
    <item>
        <title>VisCRA: A Visual Chain Reasoning Attack for Jailbreaking Multimodal Large Language Models</title>
        <link>https://arxiv.org/abs/2505.19684</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.19684v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Bingrui Sima, Linhua Cong, Wenxuan Wang, Kun He</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型（MLRMs）结合强化学习和思维链监督提升了视觉推理能力，但也带来新的安全风险。方法：系统研究MLRMs高级视觉推理的安全影响，提出VisCRA攻击框架，结合目标视觉注意力掩码和两阶段推理诱导策略。效果：实验表明VisCRA效果显著，在主流闭源MLRMs上攻击成功率高，如Gemini 2.0 Flash Thinking为76.48%，QvQ - Max为68.56%，GPT - 4o为56.60%。
            arXiv:2505.19684v2 Announce Type: replace 
Abstract: The emergence of Multimodal Large Language Models (MLRMs) has enabled sophisticated visual reasoning capabilities by integrating reinforcement learning and Chain-of-Thought (CoT) supervision. However, while these enhanced reasoning capabilities improve performance, they also introduce new and underexplored safety risks. In this work, we systematically investigate the security implications of advanced visual reasoning in MLRMs. Our analysis reveals a fundamental trade-off: as visual reasoning improves, models become more vulnerable to jailbreak attacks. Motivated by this critical finding, we introduce VisCRA (Visual Chain Reasoning Attack), a novel jailbreak framework that exploits the visual reasoning chains to bypass safety mechanisms. VisCRA combines targeted visual attention masking with a two-stage reasoning induction strategy to precisely control harmful outputs. Extensive experiments demonstrate VisCRA's significant effectiveness, achieving high attack success rates on leading closed-source MLRMs: 76.48% on Gemini 2.0 Flash Thinking, 68.56% on QvQ-Max, and 56.60% on GPT-4o. Our findings highlight a critical insight: the very capability that empowers MLRMs -- their visual reasoning -- can also serve as an attack vector, posing significant security risks.
        ]]></description>
    </item>
    <item>
        <title>Incentivizing Strong Reasoning from Weak Supervision</title>
        <link>https://arxiv.org/abs/2505.20072</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.20072v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yige Yuan, Teng Xiao, Shuchang Tao, Xue Wang, Jinyang Gao, Bolin Ding, Bingbing Xu</dc:creator>
        <description><![CDATA[
            背景：提升大语言模型推理能力通常依赖强化学习或高质量思维链监督微调，成本高昂。方法：研究在无昂贵高质量示范和强化学习情况下，能否通过较弱模型监督激励大模型推理能力，并分析弱监督成功激发推理能力的时机和原因。效果：较弱推理器监督能大幅提升学生模型推理表现，以较低成本恢复近94%昂贵强化学习的收益，在不同基准和模型架构实验中，能持续提升推理任务表现。
            arXiv:2505.20072v2 Announce Type: replace 
Abstract: Large language models (LLMs) have demonstrated impressive performance on reasoning-intensive tasks, but enhancing their reasoning abilities typically relies on either reinforcement learning (RL) with verifiable signals or supervised fine-tuning (SFT) with high-quality long chain-of-thought (CoT) demonstrations, both of which are expensive. In this paper, we study a novel problem of incentivizing the reasoning capacity of LLMs without expensive high-quality demonstrations and reinforcement learning. We investigate whether the reasoning capabilities of LLMs can be effectively incentivized via supervision from significantly weaker models. We further analyze when and why such weak supervision succeeds in eliciting reasoning abilities in stronger models. Our findings show that supervision from significantly weaker reasoners can substantially improve student reasoning performance, recovering close to 94% of the gains of expensive RL at a fraction of the cost. Experiments across diverse benchmarks and model architectures demonstrate that weak reasoners can effectively incentivize reasoning in stronger student models, consistently improving performance across a wide range of reasoning tasks. Our results suggest that this simple weak-to-strong paradigm is a promising and generalizable alternative to costly methods for incentivizing strong reasoning capabilities at inference-time in LLMs. The code is publicly available at https://github.com/yuanyige/w2sr.
        ]]></description>
    </item>
    <item>
        <title>DIPO: Dual-State Images Controlled Articulated Object Generation Powered by Diverse Data</title>
        <link>https://arxiv.org/abs/2505.20460</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.20460v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ruiqi Wu, Xinjie Wang, Liu Liu, Chunle Guo, Jiaxiong Qiu, Chongyi Li, Lichao Huang, Zhizhong Su, Ming-Ming Cheng</dc:creator>
        <description><![CDATA[
            背景：现有单图像生成铰接3D对象方法有局限，缺乏运动信息。方法：提出DIPO框架，采用双图像扩散模型捕捉图像对关系生成部件布局和关节参数，引入基于思维链的图推理器推断部件连接关系，还开发LEGO - Art数据集扩展管道、提出PM - X数据集。效果：实验表明，DIPO在静止和铰接状态下均显著优于现有基线，PM - X数据集增强了对复杂铰接对象的泛化能力。
            arXiv:2505.20460v2 Announce Type: replace 
Abstract: We present DIPO, a novel framework for the controllable generation of articulated 3D objects from a pair of images: one depicting the object in a resting state and the other in an articulated state. Compared to the single-image approach, our dual-image input imposes only a modest overhead for data collection, but at the same time provides important motion information, which is a reliable guide for predicting kinematic relationships between parts. Specifically, we propose a dual-image diffusion model that captures relationships between the image pair to generate part layouts and joint parameters. In addition, we introduce a Chain-of-Thought (CoT) based graph reasoner that explicitly infers part connectivity relationships. To further improve robustness and generalization on complex articulated objects, we develop a fully automated dataset expansion pipeline, name LEGO-Art, that enriches the diversity and complexity of PartNet-Mobility dataset. We propose PM-X, a large-scale dataset of complex articulated 3D objects, accompanied by rendered images, URDF annotations, and textual descriptions. Extensive experiments demonstrate that DIPO significantly outperforms existing baselines in both the resting state and the articulated state, while the proposed PM-X dataset further enhances generalization to diverse and structurally complex articulated objects. Our code and dataset will be released to the community upon publication.
        ]]></description>
    </item>
    <item>
        <title>RSCF: Relation-Semantics Consistent Filter for Entity Embedding of Knowledge Graph</title>
        <link>https://arxiv.org/abs/2505.20813</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.20813v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Junsik Kim, Jinwook Park, Kangil Kim</dc:creator>
        <description><![CDATA[
            背景：知识图谱嵌入中利用特定关系的实体转换提升了性能，但转换前后嵌入差异的一致性未得到解决，存在损失有价值归纳偏差的风险。方法：提出插件式KGE方法RSCF，其实体转换有增强语义一致性的三个特征，还添加关系转换和预测模块增强语义。效果：在基于距离和张量分解模型的知识图谱补全任务中，显著优于现有KGE方法，在所有关系及其频率上都表现出鲁棒性。
            arXiv:2505.20813v2 Announce Type: replace 
Abstract: In knowledge graph embedding, leveraging relation specific entity transformation has markedly enhanced performance. However, the consistency of embedding differences before and after transformation remains unaddressed, risking the loss of valuable inductive bias inherent in the embeddings. This inconsistency stems from two problems. First, transformation representations are specified for relations in a disconnected manner, allowing dissimilar transformations and corresponding entity embeddings for similar relations. Second, a generalized plug-in approach as a SFBR (Semantic Filter Based on Relations) disrupts this consistency through excessive concentration of entity embeddings under entity-based regularization, generating indistinguishable score distributions among relations. In this paper, we introduce a plug-in KGE method, Relation-Semantics Consistent Filter (RSCF). Its entity transformation has three features for enhancing semantic consistency: 1) shared affine transformation of relation embeddings across all relations, 2) rooted entity transformation that adds an entity embedding to its change represented by the transformed vector, and 3) normalization of the change to prevent scale reduction. To amplify the advantages of consistency that preserve semantics on embeddings, RSCF adds relation transformation and prediction modules for enhancing the semantics. In knowledge graph completion tasks with distance-based and tensor decomposition models, RSCF significantly outperforms state-of-the-art KGE methods, showing robustness across all relations and their frequencies.
        ]]></description>
    </item>
    <item>
        <title>Cooperation of Experts: Fusing Heterogeneous Information with Large Margin</title>
        <link>https://arxiv.org/abs/2505.20853</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.20853v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Shuo Wang, Shunyang Huang, Jinghui Yuan, Zhixiang Shen, Zhao Kang</dc:creator>
        <description><![CDATA[
            背景：现代数据分析中融合异构信息是难题，现有方法难以处理不同语义空间中对象模式的异质性。方法：提出专家合作（CoE）框架，将多类型信息编码为统一的异构多重网络，通过专用编码器作为特定领域专家学习不同语义空间的关系模式，用大边界机制和定制优化策略让专家协作。效果：理论分析保证可行性和稳定性，多样基准实验显示其性能优越、适用性广。
            arXiv:2505.20853v2 Announce Type: replace 
Abstract: Fusing heterogeneous information remains a persistent challenge in modern data analysis. While significant progress has been made, existing approaches often fail to account for the inherent heterogeneity of object patterns across different semantic spaces. To address this limitation, we propose the Cooperation of Experts (CoE) framework, which encodes multi-typed information into unified heterogeneous multiplex networks. By overcoming modality and connection differences, CoE provides a powerful and flexible model for capturing the intricate structures of real-world complex data. In our framework, dedicated encoders act as domain-specific experts, each specializing in learning distinct relational patterns in specific semantic spaces. To enhance robustness and extract complementary knowledge, these experts collaborate through a novel large margin mechanism supported by a tailored optimization strategy. Rigorous theoretical analyses guarantee the framework's feasibility and stability, while extensive experiments across diverse benchmarks demonstrate its superior performance and broad applicability. Our code is available at https://github.com/strangeAlan/CoE.
        ]]></description>
    </item>
    <item>
        <title>Faithfulness-Aware Uncertainty Quantification for Fact-Checking the Output of Retrieval Augmented Generation</title>
        <link>https://arxiv.org/abs/2505.21072</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.21072v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ekaterina Fadeeva, Aleksandr Rubashevskii, Roman Vashurin, Shehzaad Dhuliawala, Artem Shelmanov, Timothy Baldwin, Preslav Nakov, Mrinmaya Sachan, Maxim Panov</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）在开放域问答中表现出色，但易产生幻觉问题，现有方法常混淆事实性和对检索上下文的忠实性。方法：提出FRANQ，根据陈述是否忠实于检索上下文，应用不同的不确定性量化（UQ）技术来估计事实性，还构建了新的长文本问答数据集。效果：在多个数据集和大语言模型上的长、短文本问答实验表明，与现有方法相比，FRANQ能更准确地检测RAG生成响应中的事实性错误。
            arXiv:2505.21072v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) enhanced with external knowledge retrieval, an approach known as Retrieval-Augmented Generation (RAG), have shown strong performance in open-domain question answering. However, RAG systems remain susceptible to hallucinations: factually incorrect outputs that may arise either from inconsistencies in the model's internal knowledge or incorrect use of the retrieved context. Existing approaches often conflate factuality with faithfulness to the retrieved context, misclassifying factually correct statements as hallucinations if they are not directly supported by the retrieval. In this paper, we introduce FRANQ (Faithfulness-based Retrieval Augmented UNcertainty Quantification), a novel method for hallucination detection in RAG outputs. FRANQ applies different Uncertainty Quantification (UQ) techniques to estimate factuality based on whether a statement is faithful to the retrieved context or not. To evaluate FRANQ and other UQ techniques for RAG, we present a new long-form Question Answering (QA) dataset annotated for both factuality and faithfulness, combining automated labeling with manual validation of challenging examples. Extensive experiments on long- and short-form QA across multiple datasets and LLMs show that FRANQ achieves more accurate detection of factual errors in RAG-generated responses compared to existing methods.
        ]]></description>
    </item>
    <item>
        <title>LLMs Think, But Not In Your Flow: Reasoning-Level Personalization for Black-Box Large Language Models</title>
        <link>https://arxiv.org/abs/2505.21082</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.21082v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jieyong Kim, Tongyoung Kim, Soojin Yoon, Jaehyung Kim, Dongha Lee</dc:creator>
        <description><![CDATA[
            背景：黑盒大语言模型虽应用广泛，但输出常忽略个人偏好和推理风格，现有个性化方法多聚焦响应层面，未建模个人思维过程。方法：提出RPM框架，先从用户历史中提取分组特征构建特定因素，再构建个性化推理路径，推理时通过特征相似度检索示例并结合结构化因素和路径推理。效果：大量实验表明，RPM在不同任务上始终优于响应级个性化方法，提升了预测准确性和可解释性。
            arXiv:2505.21082v2 Announce Type: replace 
Abstract: Large language models (LLMs) have recently achieved impressive performance across a wide range of natural language tasks and are now widely used in real-world applications. Among them, black-box LLMs--served via APIs without access to model internals--are especially dominant due to their scalability and ease of deployment. Despite their strong capabilities, these models typically produce generalized responses that overlook personal preferences and reasoning styles. This has led to growing interest in black-box LLM personalization, which aims to tailor model outputs to user-specific context without modifying model parameters. However, existing approaches primarily focus on response-level personalization, attempting to match final outputs without modeling personal thought process. To address this limitation, we propose RPM, a framework for reasoning-level personalization that aligns the model's reasoning process with a user's personalized logic. RPM first constructs statistical user-specific factors by extracting and grouping response-influential features from user history. It then builds personalized reasoning paths that reflect how these factors are used in context. In the inference stage, RPM retrieves reasoning-aligned examples for new queries via feature-level similarity and performs inference conditioned on the structured factors and retrieved reasoning paths, enabling the model to follow user-specific reasoning trajectories. This reasoning-level personalization enhances both predictive accuracy and interpretability by grounding model outputs in user-specific logic through structured information. Extensive experiments across diverse tasks show that RPM consistently outperforms response-level personalization methods, demonstrating the effectiveness of reasoning-level personalization in black-box LLMs.
        ]]></description>
    </item>
    <item>
        <title>Copresheaf Topological Neural Networks: A Generalized Deep Learning Framework</title>
        <link>https://arxiv.org/abs/2505.21251</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.21251v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mustafa Hajij, Lennart Bastian, Sarah Osentoski, Hardik Kabaria, John L. Davenport, Sheik Dawood, Balaji Cherukuri, Joseph G. Kocheemoolayil, Nastaran Shahmansouri, Adrian Lew, Theodore Papamarkou, Tolga Birdal</dc:creator>
        <description><![CDATA[
            背景：深度学习虽影响广泛，但针对特定任务和数据类型设计神经网络架构仍是难题。方法：提出余预层拓扑神经网络（CTNNs），将模型设计建立在代数拓扑中的余预层概念上，能处理图像、点云、图等结构化数据。效果：在结构化数据基准测试中，CTNNs始终优于传统基线，尤其在需要分层或局部敏感性的任务中表现出色，为下一代深度学习架构提供了多尺度基础。
            arXiv:2505.21251v2 Announce Type: replace 
Abstract: We introduce copresheaf topological neural networks (CTNNs), a powerful and unifying framework that encapsulates a wide spectrum of deep learning architectures, designed to operate on structured data: including images, point clouds, graphs, meshes, and topological manifolds. While deep learning has profoundly impacted domains ranging from digital assistants to autonomous systems, the principled design of neural architectures tailored to specific tasks and data types remains one of the field's most persistent open challenges. CTNNs address this gap by grounding model design in the language of copresheaves, a concept from algebraic topology that generalizes and subsumes most practical deep learning models in use today. This abstract yet constructive formulation yields a rich design space from which theoretically sound and practically effective solutions can be derived to tackle core challenges in representation learning: long-range dependencies, oversmoothing, heterophily, and non-Euclidean domains. Our empirical results on structured data benchmarks demonstrate that CTNNs consistently outperform conventional baselines, particularly in tasks requiring hierarchical or localized sensitivity. These results underscore CTNNs as a principled, multi-scale foundation for the next generation of deep learning architectures.
        ]]></description>
    </item>
    <item>
        <title>Topological Eigenvalue Theorems for Tensor Analysis in Multi-Modal Data Fusion</title>
        <link>https://arxiv.org/abs/2409.09392</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2409.09392v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ronald Katende</dc:creator>
        <description><![CDATA[
            背景：多模态数据融合中传统张量特征值分析常扩展矩阵理论，缺乏拓扑视角。方法：本文提出一种利用贝蒂数等拓扑不变量进行多模态数据融合中张量特征值分析的新框架，建立特征值与拓扑特征相关的新定理。效果：该框架能深入洞察数据潜在结构，提升可解释性和鲁棒性，在数据融合应用中展现出理论和实践意义，有望在机器学习和数据科学领域产生广泛影响。
            arXiv:2409.09392v3 Announce Type: replace-cross 
Abstract: This paper presents a novel framework for tensor eigenvalue analysis in the context of multi-modal data fusion, leveraging topological invariants such as Betti numbers. Traditional approaches to tensor eigenvalue analysis often extend matrix theory, whereas this work introduces a topological perspective to enhance the understanding of tensor structures. By establishing new theorems that link eigenvalues to topological features, the proposed framework provides deeper insights into the latent structure of data, improving both interpretability and robustness. Applications in data fusion demonstrate the theoretical and practical significance of this approach, with potential for broad impact in machine learning and data science.
        ]]></description>
    </item>
    <item>
        <title>WiseMind: Recontextualizing AI with a Knowledge-Guided, Theory-Informed Multi-Agent Framework for Instrumental and Humanistic Benefits</title>
        <link>https://arxiv.org/abs/2502.20689</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.20689v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuqi Wu, Guangya Wan, Jingjing Li, Shengming Zhao, Lingfeng Ma, Tianyi Ye, Ion Pop, Yanbo Zhang, Jie Chen</dc:creator>
        <description><![CDATA[
            背景：将先进NLP应用于实践时，常因目标领域知识、流程和评估的情境化不足而受阻，如精神病鉴别诊断。方法：提出WiseMind框架，包含结构化知识引导的主动推理，将DSM - 5标准嵌入知识图引导提问；受辩证行为疗法启发的双智能体架构，协调推理和共情智能体；多方面评估策略。效果：在抑郁、焦虑和双相情感障碍测试中，诊断准确率达84.2%，与人类专家相当，在共情和可信度上优于单智能体基线。
            arXiv:2502.20689v2 Announce Type: replace-cross 
Abstract: Translating state-of-the-art NLP into practice often stalls at the "last mile" owing to insufficient contextualization of the target domain's knowledge, processes, and evaluation. Psychiatric differential diagnosis exemplifies this challenge: accurate assessments depend on nuanced clinical knowledge, a delicate cognitive-affective interview process, and downstream outcomes that extend far beyond benchmark accuracy. We present WiseMind, a systematic interdisciplinary contextualization framework that delivers both instrumental (diagnostic precision) and humanistic (empathy) gains. WiseMind comprises three components:(i) structured knowledge-guided proactive reasoning, which embeds DSM-5 criteria in a knowledge graph to steer questioning; (ii) a theory-informed dual-agent architecture that coordinates a "reasonable-mind" reasoning agent and an "emotional-mind" empathy agent, inspired by Dialectical Behavior Therapy; and (iii) a multi-faceted evaluation strategy covering simulated patients, user studies, clinician review, and ethical assessment. Tested on depression, anxiety, and bipolar disorder, WiseMind attains up to 84.2% diagnostic accuracy, which is comparable to human experts, while outperforming single-agent baselines in perceived empathy and trustworthiness. These results show that deep contextualization-across knowledge, process, and evaluation layers-can transform benchmark-driven NLP into clinically meaningful impact.
        ]]></description>
    </item>
    <item>
        <title>Walk&Retrieve: Simple Yet Effective Zero-shot Retrieval-Augmented Generation via Knowledge Graph Walks</title>
        <link>https://arxiv.org/abs/2505.16849</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.16849v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Martin B\"ockling, Heiko Paulheim, Andreea Iana</dc:creator>
        <description><![CDATA[
            背景：大语言模型存在幻觉或知识过时问题，基于知识图谱的检索增强生成（RAG）可解决，但现有方法存在图谱与文本表示对齐、检索效率与准确性平衡及适应图谱动态更新等难题。方法：提出Walk&Retrieve框架，利用基于游走的图遍历和知识语言化进行零样本RAG的语料生成，无需特定领域数据微调。效果：表现有竞争力，在回复准确性和减少幻觉方面常超现有RAG系统，查询延迟低，对大图有强扩展性。
            arXiv:2505.16849v2 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) have showcased impressive reasoning abilities, but often suffer from hallucinations or outdated knowledge. Knowledge Graph (KG)-based Retrieval-Augmented Generation (RAG) remedies these shortcomings by grounding LLM responses in structured external information from a knowledge base. However, many KG-based RAG approaches struggle with (i) aligning KG and textual representations, (ii) balancing retrieval accuracy and efficiency, and (iii) adapting to dynamically updated KGs. In this work, we introduce Walk&amp;Retrieve, a simple yet effective KG-based framework that leverages walk-based graph traversal and knowledge verbalization for corpus generation for zero-shot RAG. Built around efficient KG walks, our method does not require fine-tuning on domain-specific data, enabling seamless adaptation to KG updates, reducing computational overhead, and allowing integration with any off-the-shelf backbone LLM. Despite its simplicity, Walk&amp;Retrieve performs competitively, often outperforming existing RAG systems in response accuracy and hallucination reduction. Moreover, it demonstrates lower query latency and robust scalability to large KGs, highlighting the potential of lightweight retrieval strategies as strong baselines for future RAG research.
        ]]></description>
    </item>
    <item>
        <title>VoiceMark: Zero-Shot Voice Cloning-Resistant Watermarking Approach Leveraging Speaker-Specific Latents</title>
        <link>https://arxiv.org/abs/2505.21568</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.21568v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Haiyun Li, Zhiyong Wu, Xiaofeng Xie, Jingran Xie, Yaoxun Xu, Hanyang Peng</dc:creator>
        <description><![CDATA[
            背景：抗语音克隆水印技术可追踪和防止未经授权的克隆，但现有方法在零样本语音克隆场景下失效。方法：提出VoiceMark，首个利用说话人特定潜在特征作为水印载体的零样本抗语音克隆水印方法，让水印能在零样本语音克隆过程中转移到合成音频中，还引入语音克隆模拟增强和基于语音活动检测的损失以增强抗失真鲁棒性。效果：在多个零样本语音克隆模型实验中，零样本语音克隆合成后水印检测准确率超95%，显著优于仅达50%左右的现有方法。
            arXiv:2505.21568v1 Announce Type: new 
Abstract: Voice cloning (VC)-resistant watermarking is an emerging technique for tracing and preventing unauthorized cloning. Existing methods effectively trace traditional VC models by training them on watermarked audio but fail in zero-shot VC scenarios, where models synthesize audio from an audio prompt without training. To address this, we propose VoiceMark, the first zero-shot VC-resistant watermarking method that leverages speaker-specific latents as the watermark carrier, allowing the watermark to transfer through the zero-shot VC process into the synthesized audio. Additionally, we introduce VC-simulated augmentations and VAD-based loss to enhance robustness against distortions. Experiments on multiple zero-shot VC models demonstrate that VoiceMark achieves over 95% accuracy in watermark detection after zero-shot VC synthesis, significantly outperforming existing methods, which only reach around 50%. See our code and demos at: https://huggingface.co/spaces/haiyunli/VoiceMark
        ]]></description>
    </item>
    <item>
        <title>Leveraging LLM for Stuttering Speech: A Unified Architecture Bridging Recognition and Event Detection</title>
        <link>https://arxiv.org/abs/2505.22005</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22005v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Shangkun Huang, Jing Deng, Jintao Kang, Rong Zheng</dc:creator>
        <description><![CDATA[
            背景：自动语音识别（ASR）在口吃语音场景下性能受限，影响其在语音康复等领域应用。方法：提出由大语言模型（LLM）驱动的ASR - SED多任务学习框架，采用动态交互机制，ASR分支用CTC生成软提示辅助LLM上下文建模，SED分支输出结巴嵌入增强LLM理解；结合对比学习强化特征判别力，用Focal Loss缓解长尾分布问题。效果：在AS - 70普通话口吃数据集上，框架使ASR字符错误率降至5.45%（相对降低37.71%），SED平均F1分数达73.63%（相对提升46.58%）。
            arXiv:2505.22005v1 Announce Type: new 
Abstract: The performance bottleneck of Automatic Speech Recognition (ASR) in stuttering speech scenarios has limited its applicability in domains such as speech rehabilitation. This paper proposed an LLM-driven ASR-SED multi-task learning framework that jointly optimized the ASR and Stuttering Event Detection (SED) tasks. We proposed a dynamic interaction mechanism where the ASR branch leveraged CTC-generated soft prompts to assist LLM context modeling, while the SED branch output stutter embeddings to enhance LLM comprehension of stuttered speech. We incorporated contrastive learning to strengthen the discriminative power of stuttering acoustic features and applied Focal Loss to mitigate the long-tailed distribution in stuttering event categories. Evaluations on the AS-70 Mandarin stuttering dataset demonstrated that our framework reduced the ASR character error rate (CER) to 5.45% (-37.71% relative reduction) and achieved an average SED F1-score of 73.63% (+46.58% relative improvement).
        ]]></description>
    </item>
    <item>
        <title>AudioGenie: A Training-Free Multi-Agent Framework for Diverse Multimodality-to-Multiaudio Generation</title>
        <link>https://arxiv.org/abs/2505.22053</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22053v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yan Rong, Jinting Wang, Shan Yang, Guangzhi Lei, Li Liu</dc:creator>
        <description><![CDATA[
            多模态到多音频（MM2MA）生成面临合成多样且上下文对齐音频的挑战，因高质量配对数据集稀缺和缺乏多任务学习框架。现有多智能体系统直接应用于该任务有理解不足等问题。为此提出AudioGenie，一种免训练的多智能体系统，采用双层架构。生成团队设计了细粒度任务分解和自适应专家混合协作实体用于动态模型选择，还有试错迭代细化模块用于自我修正；监督团队确保时空一致性。构建了首个MM2MA任务基准MA - Bench。实验表明，该方法在8个任务的9个指标上优于现有方法，用户研究也验证了其有效性。
            arXiv:2505.22053v1 Announce Type: new 
Abstract: Multimodality-to-Multiaudio (MM2MA) generation faces significant challenges in synthesizing diverse and contextually aligned audio types (e.g., sound effects, speech, music, and songs) from multimodal inputs (e.g., video, text, images), owing to the scarcity of high-quality paired datasets and the lack of robust multi-task learning frameworks. Recently, multi-agent system shows great potential in tackling the above issues. However, directly applying it to MM2MA task presents three critical challenges: (1) inadequate fine-grained understanding of multimodal inputs (especially for video), (2) the inability of single models to handle diverse audio events, and (3) the absence of self-correction mechanisms for reliable outputs. To this end, we propose AudioGenie, a novel training-free multi-agent system featuring a dual-layer architecture with a generation team and a supervisor team. For the generation team, a fine-grained task decomposition and an adaptive Mixture-of-Experts (MoE) collaborative entity are designed for dynamic model selection, and a trial-and-error iterative refinement module is designed for self-correction. The supervisor team ensures temporal-spatial consistency and verifies outputs through feedback loops. Moreover, we build MA-Bench, the first benchmark for MM2MA tasks, comprising 198 annotated videos with multi-type audios. Experiments demonstrate that our AudioGenie outperforms state-of-the-art (SOTA) methods across 9 metrics in 8 tasks. User study further validate the effectiveness of the proposed method in terms of quality, accuracy, alignment, and aesthetic. The anonymous project website with samples can be found at https://audiogenie.github.io/.
        ]]></description>
    </item>
    <item>
        <title>AudioTurbo: Fast Text-to-Audio Generation with Rectified Diffusion</title>
        <link>https://arxiv.org/abs/2505.22106</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22106v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Junqi Zhao, Jinzheng Zhao, Haohe Liu, Yun Chen, Lu Han, Xubo Liu, Mark Plumbley, Wenwu Wang</dc:creator>
        <description><![CDATA[
            背景：扩散模型提升了音频生成质量和多样性，但推理速度慢，整流流虽能加速推理，但需从头训练且低步数表现不佳。方法：本研究将预训练模型与整流扩散方法结合，提出AudioTurbo，从预训练文本到音频模型生成的确定性噪声样本对中学习一阶常微分方程路径。效果：在AudioCaps数据集实验表明，该模型仅10步采样就优于先前模型，与基于流匹配的加速模型相比，推理步数减至3步。
            arXiv:2505.22106v1 Announce Type: new 
Abstract: Diffusion models have significantly improved the quality and diversity of audio generation but are hindered by slow inference speed. Rectified flow enhances inference speed by learning straight-line ordinary differential equation (ODE) paths. However, this approach requires training a flow-matching model from scratch and tends to perform suboptimally, or even poorly, at low step counts. To address the limitations of rectified flow while leveraging the advantages of advanced pre-trained diffusion models, this study integrates pre-trained models with the rectified diffusion method to improve the efficiency of text-to-audio (TTA) generation. Specifically, we propose AudioTurbo, which learns first-order ODE paths from deterministic noise sample pairs generated by a pre-trained TTA model. Experiments on the AudioCaps dataset demonstrate that our model, with only 10 sampling steps, outperforms prior models and reduces inference to 3 steps compared to a flow-matching-based acceleration model.
        ]]></description>
    </item>
    <item>
        <title>Evaluation of LLMs in Speech is Often Flawed: Test Set Contamination in Large Language Models for Speech Recognition</title>
        <link>https://arxiv.org/abs/2505.22251</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22251v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuan Tseng, Titouan Parcollet, Rogier van Dalen, Shucong Zhang, Sourav Bhattacharya</dc:creator>
        <description><![CDATA[
            背景：近期研究表明大语言模型（LLM）可提升语音任务表现，常引用LibriSpeech和Common Voice数据集的结果。方法：研究发现这两个数据集的评估集大量出现在公开LLM预训练语料库中，对比有无数据污染训练的LLM，测量污染影响。效果：受污染的LLM更易生成训练中见过的测试句子，使用受污染LLM的语音识别器错误率差异小，但对训练中见过的转录赋予更高概率。结果表明少量数据污染会使LLM输出有偏差，凸显用预留数据评估基于LLM的语音系统的重要性。
            arXiv:2505.22251v1 Announce Type: new 
Abstract: Recent work suggests that large language models (LLMs) can improve performance of speech tasks compared to existing systems. To support their claims, results on LibriSpeech and Common Voice are often quoted. However, this work finds that a substantial amount of the LibriSpeech and Common Voice evaluation sets appear in public LLM pretraining corpora. This calls into question the reliability of findings drawn from these two datasets. To measure the impact of contamination, LLMs trained with or without contamination are compared, showing that a contaminated LLM is more likely to generate test sentences it has seen during training. Speech recognisers using contaminated LLMs shows only subtle differences in error rates, but assigns significantly higher probabilities to transcriptions seen during training. Results show that LLM outputs can be biased by tiny amounts of data contamination, highlighting the importance of evaluating LLM-based speech systems with held-out data.
        ]]></description>
    </item>
    <item>
        <title>Effective Context in Neural Speech Models</title>
        <link>https://arxiv.org/abs/2505.22487</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22487v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yen Meng, Sharon Goldwater, Hao Tang</dc:creator>
        <description><![CDATA[
            背景：现代神经语音模型受益于更长上下文，但少有研究测量其实际使用的有效上下文。方法：提出两种测量有效上下文的方法，用于分析不同语音Transformer。效果：对于监督模型，有效上下文与任务性质密切相关，基频跟踪、音素分类和单词分类所需有效上下文逐渐增加；自监督模型的有效上下文主要在早期层增加且相对较短，与监督音素模型类似。还表明HuBERT可在不修改架构和进一步微调下以流式模式运行。
            arXiv:2505.22487v1 Announce Type: new 
Abstract: Modern neural speech models benefit from having longer context, and many approaches have been proposed to increase the maximum context a model can use. However, few have attempted to measure how much context these models actually use, i.e., the effective context. Here, we propose two approaches to measuring the effective context, and use them to analyze different speech Transformers. For supervised models, we find that the effective context correlates well with the nature of the task, with fundamental frequency tracking, phone classification, and word classification requiring increasing amounts of effective context. For self-supervised models, we find that effective context increases mainly in the early layers, and remains relatively short -- similar to the supervised phone model. Given that these models do not use a long context during prediction, we show that HuBERT can be run in streaming mode without modification to the architecture and without further fine-tuning.
        ]]></description>
    </item>
    <item>
        <title>Mitigating Audiovisual Mismatch in Visual-Guide Audio Captioning</title>
        <link>https://arxiv.org/abs/2505.22045</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22045v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Le Xu, Chenxing Li, Yong Ren, Yujie Chen, Yu Gu, Ruibo Fu, Shan Yang, Dong Yu</dc:creator>
        <description><![CDATA[
            背景：现有视觉引导的音频字幕系统难以解决现实场景中的视听不对齐问题。方法：提出熵感知门控融合框架，通过跨模态不确定性量化动态调节视觉信息流；利用交叉注意力层的注意力熵分析，识别并抑制模态融合中误导性视觉线索；开发批量视听洗牌技术，生成合成不匹配训练对增强模型抗噪性。效果：在AudioCaps基准测试中表现优于现有基线，尤其在模态不匹配场景；推理速度比基线提升约6倍。
            arXiv:2505.22045v1 Announce Type: cross 
Abstract: Current vision-guided audio captioning systems frequently fail to address audiovisual misalignment in real-world scenarios, such as dubbed content or off-screen sounds. To bridge this critical gap, we present an entropy-aware gated fusion framework that dynamically modulates visual information flow through cross-modal uncertainty quantification. Our novel approach employs attention entropy analysis in cross-attention layers to automatically identify and suppress misleading visual cues during modal fusion. Complementing this architecture, we develop a batch-wise audiovisual shuffling technique that generates synthetic mismatched training pairs, greatly enhancing model resilience against alignment noise. Evaluations on the AudioCaps benchmark demonstrate our system's superior performance over existing baselines, especially in mismatched modality scenarios. Furthermore, our solution demonstrates an approximately 6x improvement in inference speed compared to the baseline.
        ]]></description>
    </item>
    <item>
        <title>VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing</title>
        <link>https://arxiv.org/abs/2408.05758</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2408.05758v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chunyu Qiang, Wang Geng, Yi Zhao, Ruibo Fu, Tao Wang, Cheng Gong, Tianrui Wang, Qiuyu Liu, Jiangyan Yi, Zhengqi Wen, Chen Zhang, Hao Che, Longbiao Wang, Jianwu Dang, Jianhua Tao</dc:creator>
        <description><![CDATA[
            深度学习推动了跨模态表征学习发展，文本转语音等任务需要跨模态细粒度序列表征。该文提出VQ - CTAP方法，用跨模态对齐序列转码器将文本和语音映射到联合多模态空间，学习帧级连接。它是跨模态序列表征学习范式，可直接用于语音转换和自动语音识别任务。还提出序列感知语义连接器用于文本转语音任务，设计步进优化策略确保收敛，提出语义转移式副语言一致性损失增强表征能力。此外，能将24kHz输入波形以25Hz速率高压缩编码，采样率降低960倍。
            arXiv:2408.05758v2 Announce Type: replace 
Abstract: Deep learning has brought significant improvements to the field of cross-modal representation learning. For tasks such as text-to-speech (TTS), voice conversion (VC), and automatic speech recognition (ASR), a cross-modal fine-grained (frame-level) sequence representation is desired, emphasizing the semantic content of the text modality while de-emphasizing the paralinguistic information of the speech modality. We propose a method called "Vector Quantized Contrastive Token-Acoustic Pre-training (VQ-CTAP)", which uses the cross-modal aligned sequence transcoder to bring text and speech into a joint multimodal space, learning how to connect text and speech at the frame level. The proposed VQ-CTAP is a paradigm for cross-modal sequence representation learning, offering a promising solution for fine-grained generation and recognition tasks in speech processing. The VQ-CTAP can be directly applied to VC and ASR tasks without fine-tuning or additional structures. We propose a sequence-aware semantic connector, which connects multiple frozen pre-trained modules for the TTS task, exhibiting a plug-and-play capability. We design a stepping optimization strategy to ensure effective model convergence by gradually injecting and adjusting the influence of various loss components. Furthermore, we propose a semantic-transfer-wise paralinguistic consistency loss to enhance representational capabilities, allowing the model to better generalize to unseen data and capture the nuances of paralinguistic information. In addition, VQ-CTAP achieves high-compression speech coding at a rate of 25Hz from 24kHz input waveforms, which is a 960-fold reduction in the sampling rate. The audio demo is available at https://qiangchunyu.github.io/VQCTAP/
        ]]></description>
    </item>
    <item>
        <title>Zero-Shot Mono-to-Binaural Speech Synthesis</title>
        <link>https://arxiv.org/abs/2412.08356</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2412.08356v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Alon Levkovitch, Julian Salazar, Soroosh Mariooryad, RJ Skerry-Ryan, Nadav Bar, Bastiaan Kleijn, Eliya Nachmani</dc:creator>
        <description><![CDATA[
            背景：当前缺乏无需双耳数据训练的零样本单声道转双耳音频合成方法。方法：提出ZeroBAS，基于源位置进行无参数几何时间扭曲和幅度缩放得到初始双耳合成，再用预训练去噪声码器迭代优化。还引入TUT Mono - to - Binaural数据集评估。效果：该零样本方法在标准数据集上感知性能与有监督方法相当，在TUT Mono - to - Binaural数据集上超越有监督方法，凸显预训练生成音频模型和零样本学习在双耳音频合成中的潜力。
            arXiv:2412.08356v2 Announce Type: replace 
Abstract: We present ZeroBAS, a neural method to synthesize binaural audio from monaural audio recordings and positional information without training on any binaural data. To our knowledge, this is the first published zero-shot neural approach to mono-to-binaural audio synthesis. Specifically, we show that a parameter-free geometric time warping and amplitude scaling based on source location suffices to get an initial binaural synthesis that can be refined by iteratively applying a pretrained denoising vocoder. Furthermore, we find this leads to generalization across room conditions, which we measure by introducing a new dataset, TUT Mono-to-Binaural, to evaluate state-of-the-art monaural-to-binaural synthesis methods on unseen conditions. Our zero-shot method is perceptually on-par with the performance of supervised methods on the standard mono-to-binaural dataset, and even surpasses them on our out-of-distribution TUT Mono-to-Binaural dataset. Our results highlight the potential of pretrained generative audio models and zero-shot learning to unlock robust binaural audio synthesis.
        ]]></description>
    </item>
    <item>
        <title>The Search for Squawk: Agile Modeling in Bioacoustics</title>
        <link>https://arxiv.org/abs/2505.03071</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.03071v3</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Vincent Dumoulin, Otilia Stretcu, Jenny Hamer, Lauren Harrell, Rob Laber, Hugo Larochelle, Bart van Merri\"enboer, Amanda Navine, Patrick Hart, Ben Williams, Timothy A. C. Lamont, Tries B. Rasak, Mars Coral Restoration Team, Sheryn Brodie, Brendan Doohan, Phil Eichinski, Paul Roe, Lin Schwarzkopf, Tom Denton</dc:creator>
        <description><![CDATA[
            背景：被动声学监测（PAM）助生态学家了解动物种群和生态系统健康，但从大量音频记录中提取信息需开发专业识别器，这任务具挑战性，需大量训练数据和机器学习专业知识。方法：引入通用、可扩展且数据高效的系统，含预训练的高泛化声学嵌入、索引音频搜索和预计算嵌入以解决先前生物声学工作流程问题。效果：生态学家用该系统开展三个案例研究，模拟实验探索设计决策范围，展示了系统的可扩展性、效率和泛化性，能让科学家快速应对新生物声学挑战。
            arXiv:2505.03071v3 Announce Type: replace 
Abstract: Passive acoustic monitoring (PAM) has shown great promise in helping ecologists understand the health of animal populations and ecosystems. However, extracting insights from millions of hours of audio recordings requires the development of specialized recognizers. This is typically a challenging task, necessitating large amounts of training data and machine learning expertise. In this work, we introduce a general, scalable and data-efficient system for developing recognizers for novel bioacoustic problems in under an hour. Our system consists of several key components that tackle problems in previous bioacoustic workflows: 1) highly generalizable acoustic embeddings pre-trained for birdsong classification minimize data hunger; 2) indexed audio search allows the efficient creation of classifier training datasets, and 3) precomputation of embeddings enables an efficient active learning loop, improving classifier quality iteratively with minimal wait time. Ecologists employed our system in three novel case studies: analyzing coral reef health through unidentified sounds; identifying juvenile Hawaiian bird calls to quantify breeding success and improve endangered species monitoring; and Christmas Island bird occupancy modeling. We augment the case studies with simulated experiments which explore the range of design decisions in a structured way and help establish best practices. Altogether these experiments showcase our system's scalability, efficiency, and generalizability, enabling scientists to quickly address new bioacoustic challenges.
        ]]></description>
    </item>
    <item>
        <title>Optimal Scalogram for Computational Complexity Reduction in Acoustic Recognition Using Deep Learning</title>
        <link>https://arxiv.org/abs/2505.13017</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13017v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Dang Thoai Phan, Tuan Anh Huynh, Van Tuan Pham, Cao Minh Tran, Van Thuan Mai, Ngoc Quy Tran</dc:creator>
        <description><![CDATA[
            背景：连续小波变换（CWT）用于卷积神经网络（CNN）声学识别特征提取效果好，但计算成本高，导致研究者常选短时傅里叶变换（STFT）。方法：提出优化小波核长度和输出尺度图跳数的方法，以降低CWT计算复杂度。效果：实验表明，该方法显著降低计算成本，且在声学识别任务中能使训练模型保持稳健性能。 
            arXiv:2505.13017v2 Announce Type: replace 
Abstract: The Continuous Wavelet Transform (CWT) is an effective tool for feature extraction in acoustic recognition using Convolutional Neural Networks (CNNs), particularly when applied to non-stationary audio. However, its high computational cost poses a significant challenge, often leading researchers to prefer alternative methods such as the Short-Time Fourier Transform (STFT). To address this issue, this paper proposes a method to reduce the computational complexity of CWT by optimizing the length of the wavelet kernel and the hop size of the output scalogram. Experimental results demonstrate that the proposed approach significantly reduces computational cost while maintaining the robust performance of the trained model in acoustic recognition tasks.
        ]]></description>
    </item>
    <item>
        <title>Neurodyne: Neural Pitch Manipulation with Representation Learning and Cycle-Consistency GAN</title>
        <link>https://arxiv.org/abs/2505.15368</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.15368v3</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yicheng Gu, Chaoren Wang, Zhizheng Wu, Lauri Juvela</dc:creator>
        <description><![CDATA[
            在音乐制作中，音高调整至关重要。基于神经网络的音高调整系统虽比传统数字信号处理方法合成质量好，但因使用源 - 滤波器模型进行特征分离不准确以及缺乏成对的训练数据，性能受限。为此，本文提出Neurodyne，通过对抗表示学习学习与音高无关的潜在表示，避免不准确的特征分离，利用循环一致性训练隐式创建成对训练数据。在全局音高和基于模板的音高调整实验中，该系统有效提升了合成质量，同时保留了原歌手特征。
            arXiv:2505.15368v3 Announce Type: replace 
Abstract: Pitch manipulation is the process of producers adjusting the pitch of an audio segment to a specific key and intonation, which is essential in music production. Neural-network-based pitch-manipulation systems have been popular in recent years due to their superior synthesis quality compared to classical DSP methods. However, their performance is still limited due to their inaccurate feature disentanglement using source-filter models and the lack of paired in- and out-of-tune training data. This work proposes Neurodyne to address these issues. Specifically, Neurodyne uses adversarial representation learning to learn a pitch-independent latent representation to avoid inaccurate disentanglement and cycle-consistency training to create paired training data implicitly. Experimental results on global-key and template-based pitch manipulation demonstrate the effectiveness of the proposed system, marking improved synthesis quality while maintaining the original singer identity.
        ]]></description>
    </item>
    <item>
        <title>GOAT-TTS: Expressive and Realistic Speech Generation via A Dual-Branch LLM</title>
        <link>https://arxiv.org/abs/2504.12339</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.12339v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yaodong Song, Hongjie Chen, Jie Lian, Yuxin Zhang, Guangmin Xia, Zehan Li, Genliang Zhao, Jian Kang, Jie Li, Yongxiang Li, Xuelong Li</dc:creator>
        <description><![CDATA[
            背景：现有基于大语言模型（LLM）的文本转语音（TTS）合成存在语音提示量化导致声学特征不可逆损失、依赖精确对齐的语音 - 文本对、优化语音令牌生成时遗忘文本理解能力等问题。方法：提出基于LLM的GOAT - TTS方法，包括模态对齐分支捕捉连续声学嵌入，语音生成分支对LLM的top - k层微调、冻结bottom - n层，并引入多令牌预测支持实时流式合成。效果：表现与现有先进TTS模型相当，方言语音合成数据有效。
            arXiv:2504.12339v2 Announce Type: replace-cross 
Abstract: While large language models (LLMs) have revolutionized text-to-speech (TTS) synthesis through discrete tokenization paradigms, current architectures exhibit fundamental tensions between three critical dimensions: 1) irreversible loss of acoustic characteristics caused by quantization of speech prompts; 2) stringent dependence on precisely aligned prompt speech-text pairs that limit real-world deployment; and 3) catastrophic forgetting of the LLM's native text comprehension during optimization for speech token generation. To address these challenges, we propose an LLM-based text-to-speech Generation approach Optimized via a novel dual-branch ArchiTecture (GOAT-TTS). Our framework introduces two key innovations: (1) The modality-alignment branch combines a speech encoder and projector to capture continuous acoustic embeddings, enabling bidirectional correlation between paralinguistic features (language, timbre, emotion) and semantic text representations without transcript dependency; (2) The speech-generation branch employs modular fine-tuning on top-k layers of an LLM for speech token prediction while freezing the bottom-n layers to preserve foundational linguistic knowledge. Moreover, multi-token prediction is introduced to support real-time streaming TTS synthesis. Experimental results demonstrate that our GOAT-TTS achieves performance comparable to state-of-the-art TTS models while validating the efficacy of synthesized dialect speech data.
        ]]></description>
    </item>
    <item>
        <title>Hearing from Silence: Reasoning Audio Descriptions from Silent Videos via Vision-Language Model</title>
        <link>https://arxiv.org/abs/2505.13062</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13062v3</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yong Ren, Chenxing Li, Le Xu, Hao Gu, Duzhen Zhang, Yujie Chen, Manjie Xu, Ruibo Fu, Shan Yang, Dong Yu</dc:creator>
        <description><![CDATA[
            背景：人类能从无声视频直观推断声音，但多模态大语言模型在不接触目标模态时能否进行模态不匹配推理尚待研究，现有文本辅助视频转音频方法在推理时获取音频描述存在困难。方法：提出从无声视频推理音频描述任务（SVAD），构建CoT - AudioCaps数据集，提出基于思维链的监督微调策略。效果：在SVAD及后续视频转音频任务实验中，显著提升了视觉语言模型在SVAD上的模态不匹配推理能力，有效解决视频转音频推理时获取音频描述的难题。
            arXiv:2505.13062v3 Announce Type: replace-cross 
Abstract: Humans can intuitively infer sounds from silent videos, but whether multimodal large language models can perform modal-mismatch reasoning without accessing target modalities remains relatively unexplored. Current text-assisted-video-to-audio (VT2A) methods excel in video foley tasks but struggle to acquire audio descriptions during inference. We introduce the task of Reasoning Audio Descriptions from Silent Videos (SVAD) to address this challenge and investigate vision-language models' (VLMs) capabilities on this task. To further enhance the VLMs' reasoning capacity for the SVAD task, we construct a CoT-AudioCaps dataset and propose a Chain-of-Thought-based supervised fine-tuning strategy. Experiments on SVAD and subsequent VT2A tasks demonstrate our method's effectiveness in two key aspects: significantly improving VLMs' modal-mismatch reasoning for SVAD and effectively addressing the challenge of acquiring audio descriptions during VT2A inference.
        ]]></description>
    </item>
</channel>
</rss>