<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
<channel>
    <title>arXiv Paper Filter</title>
    <link>https://github.com/None/arxiv_filter</link>
    <description>根据研究兴趣筛选的arXiv论文</description>
    <atom:link href="https://raw.githubusercontent.com/None/arxiv_filter/main/feed.xml" rel="self" type="application/rss+xml" />
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>zh-CN</language>
    <lastBuildDate>Tue, 22 Jul 2025 12:42:49 +0800</lastBuildDate>
    <managingEditor>None@github.com</managingEditor>
    <pubDate>Tue, 22 Jul 2025 12:42:49 +0800</pubDate>
    <skipDays>
        <day>Saturday</day>
        <day>Sunday</day>
    </skipDays>

    <item>
        <title>HuggingGraph: Understanding the Supply Chain of LLM Ecosystem</title>
        <link>https://arxiv.org/abs/2507.14240</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.14240v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mohammad Shahedur Rahman, Peng Gao, Yuede Ji</dc:creator>
        <description><![CDATA[
            背景：大型语言模型（LLMs）开发、训练和部署的规模与复杂性不断增加，且模型构建易继承风险，因此理解其供应链组件的起源和发展十分关键。方法：设计系统收集LLM供应链数据的方法，构建有向异质图来建模模型与数据集的关系。效果：得到含397376个节点和453469条边的图结构，并发现LLM供应链图规模大、稀疏、呈幂律度分布，有紧密核心与分散边缘等特征。
            arXiv:2507.14240v1 Announce Type: new 
Abstract: Large language models (LLMs) leverage deep learning to process and predict sequences of words from context, enabling them to perform various NLP tasks, such as translation, summarization, question answering, and content generation. However, the growing size and complexity of developing, training, and deploying advanced LLMs require extensive computational resources and large datasets. This creates a barrier for users. As a result, platforms that host models and datasets are widely used. For example, Hugging Face, one of the most popular platforms, hosted 1.8 million models and 450K datasets by June 2025, with no sign of slowing down. Since many LLMs are built from base models, pre-trained models, and external datasets, they can inherit vulnerabilities, biases, or malicious components from earlier models or datasets. Therefore, it is critical to understand the origin and development of these components to better detect potential risks, improve model fairness, and ensure compliance. Motivated by this, our project aims to study the relationships between models and datasets, which are core components of the LLM supply chain. First, we design a method to systematically collect LLM supply chain data. Using this data, we build a directed heterogeneous graph to model the relationships between models and datasets, resulting in a structure with 397,376 nodes and 453,469 edges. We then perform various analyses and uncover several findings, such as: (i) the LLM supply chain graph is large, sparse, and follows a power-law degree distribution; (ii) it features a densely connected core and a fragmented periphery; (iii) datasets play pivotal roles in training; (iv) strong interdependence exists between models and datasets; and (v) the graph is dynamic, with daily updates reflecting the ecosystem's ongoing evolution.
        ]]></description>
    </item>
    <item>
        <title>In-Depth and In-Breadth: Pre-training Multimodal Language Models Customized for Comprehensive Chart Understanding</title>
        <link>https://arxiv.org/abs/2507.14298</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.14298v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wan-Cyuan Fan, Yen-Chun Chen, Mengchen Liu, Alexander Jacobson, Lu Yuan, Leonid Sigal</dc:creator>
        <description><![CDATA[
            现有定制大视觉语言模型用于科学图表理解的方法存在局限，一是依赖少数图表类型的配对数据，泛化性差；二是缺乏针对图表数据对齐的预训练，影响模型对数据的理解。本文提出ChartScope模型，设计了高效的数据生成管道来合成多种图表类型的配对数据，采用双路径训练策略，使模型能捕获关键数据细节并保留推理能力。还建立了新基准ChartDQA。实验表明，ChartScope显著提升了对多种图表类型的理解。
            arXiv:2507.14298v1 Announce Type: new 
Abstract: Recent methods for customizing Large Vision Language Models (LVLMs) for domain-specific tasks have shown promising results in scientific chart comprehension. However, existing approaches face two major limitations: First, they rely on paired data from only a few chart types, limiting generalization to wide range of chart types. Secondly, they lack targeted pre-training for chart-data alignment, which hampers the model's understanding of underlying data. In this paper, we introduce ChartScope, an LVLM optimized for in-depth chart comprehension across diverse chart types. We propose an efficient data generation pipeline that synthesizes paired data for a wide range of chart types, along with a novel Dual-Path training strategy that enabling the model to succinctly capture essential data details while preserving robust reasoning capabilities by incorporating reasoning over the underlying data. Lastly, we establish ChartDQA, a new benchmark for evaluating not only question-answering at different levels but also underlying data understanding. Experimental results demonstrate that ChartScope significantly enhances comprehension on a wide range of chart types. The code and data are available at https://davidhalladay.github.io/chartscope_demo.
        ]]></description>
    </item>
    <item>
        <title>CRAFT: A Neuro-Symbolic Framework for Visual Functional Affordance Grounding</title>
        <link>https://arxiv.org/abs/2507.14426</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.14426v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhou Chen, Joe Lin, Sathyanarayanan N. Aakur</dc:creator>
        <description><![CDATA[
            背景：需实现可解释的功能接地，识别场景中能实现特定动作的物体。方法：提出神经符号框架CRAFT，将ConceptNet的结构化常识先验和语言模型与CLIP的视觉证据相结合，通过基于能量的推理循环迭代优化预测。效果：在多对象、无标签设置的实验中，CRAFT提高了准确性和可解释性，向可靠、可信的场景理解迈进了一步。
            arXiv:2507.14426v1 Announce Type: new 
Abstract: We introduce CRAFT, a neuro-symbolic framework for interpretable affordance grounding, which identifies the objects in a scene that enable a given action (e.g., "cut"). CRAFT integrates structured commonsense priors from ConceptNet and language models with visual evidence from CLIP, using an energy-based reasoning loop to refine predictions iteratively. This process yields transparent, goal-driven decisions to ground symbolic and perceptual structures. Experiments in multi-object, label-free settings demonstrate that CRAFT enhances accuracy while improving interpretability, providing a step toward robust and trustworthy scene understanding.
        ]]></description>
    </item>
    <item>
        <title>ReDiSC: A Reparameterized Masked Diffusion Model for Scalable Node Classification with Structured Predictions</title>
        <link>https://arxiv.org/abs/2507.14484</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.14484v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yule Li, Yifeng Lu, Zhen Wang, Zhewei Wei, Yaliang Li, Bolin Ding</dc:creator>
        <description><![CDATA[
            背景：图神经网络在节点分类任务取得成功，但多数方法在优化目标中隐含节点标签条件独立假设，与图中节点标签存在相关性矛盾。方法：提出ReDiSC，用重新参数化的掩码扩散模型估计节点标签联合分布，通过变分期望最大化框架学习。效果：理论分析显示其在E步比DPM - SNC更高效，M步目标与流行的GNN和标签传播混合方法有明确联系。实验表明，在不同规模同构和异构图上，ReDiSC比现有方法表现更优，且能有效处理大规模数据集。
            arXiv:2507.14484v1 Announce Type: new 
Abstract: In recent years, graph neural networks (GNN) have achieved unprecedented successes in node classification tasks. Although GNNs inherently encode specific inductive biases (e.g., acting as low-pass or high-pass filters), most existing methods implicitly assume conditional independence among node labels in their optimization objectives. While this assumption is suitable for traditional classification tasks such as image recognition, it contradicts the intuitive observation that node labels in graphs remain correlated, even after conditioning on the graph structure. To make structured predictions for node labels, we propose ReDiSC, namely, Reparameterized masked Diffusion model for Structured node Classification. ReDiSC estimates the joint distribution of node labels using a reparameterized masked diffusion model, which is learned through the variational expectation-maximization (EM) framework. Our theoretical analysis shows the efficiency advantage of ReDiSC in the E-step compared to DPM-SNC, a state-of-the-art model that relies on a manifold-constrained diffusion model in continuous domain. Meanwhile, we explicitly link ReDiSC's M-step objective to popular GNN and label propagation hybrid approaches. Extensive experiments demonstrate that ReDiSC achieves superior or highly competitive performance compared to state-of-the-art GNN, label propagation, and diffusion-based baselines across both homophilic and heterophilic graphs of varying sizes. Notably, ReDiSC scales effectively to large-scale datasets on which previous structured diffusion methods fail due to computational constraints, highlighting its significant practical advantage in structured node classification tasks.
        ]]></description>
    </item>
    <item>
        <title>Benefit from Reference: Retrieval-Augmented Cross-modal Point Cloud Completion</title>
        <link>https://arxiv.org/abs/2507.14485</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.14485v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hongye Hou, Liu Zhan, Yang Yang</dc:creator>
        <description><![CDATA[
            基于不完整点云完成整个3D结构是具有挑战性的任务，尤其是剩余点云缺乏典型结构特征时。现有跨模态学习方法关注特定输入类别，限制了生成能力。本文提出检索增强的点云补全框架，设计结构共享特征编码器联合提取跨模态特征并重构参考特征作为先验，通过双通道控制门增强相关特征、抑制无关信息；提出渐进式检索增强生成器，采用分层特征融合机制从全局到局部融合参考先验与输入特征。通过多数据集和真实场景评估，该方法在生成细粒度点云、处理稀疏数据和未知类别上有效且具泛化能力。
            arXiv:2507.14485v1 Announce Type: new 
Abstract: Completing the whole 3D structure based on an incomplete point cloud is a challenging task, particularly when the residual point cloud lacks typical structural characteristics. Recent methods based on cross-modal learning attempt to introduce instance images to aid the structure feature learning. However, they still focus on each particular input class, limiting their generation abilities. In this work, we propose a novel retrieval-augmented point cloud completion framework. The core idea is to incorporate cross-modal retrieval into completion task to learn structural prior information from similar reference samples. Specifically, we design a Structural Shared Feature Encoder (SSFE) to jointly extract cross-modal features and reconstruct reference features as priors. Benefiting from a dual-channel control gate in the encoder, relevant structural features in the reference sample are enhanced and irrelevant information interference is suppressed. In addition, we propose a Progressive Retrieval-Augmented Generator (PRAG) that employs a hierarchical feature fusion mechanism to integrate reference prior information with input features from global to local. Through extensive evaluations on multiple datasets and real-world scenes, our method shows its effectiveness in generating fine-grained point clouds, as well as its generalization capability in handling sparse data and unseen categories.
        ]]></description>
    </item>
    <item>
        <title>Docopilot: Improving Multimodal Models for Document-Level Understanding</title>
        <link>https://arxiv.org/abs/2507.14675</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.14675v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuchen Duan, Zhe Chen, Yusong Hu, Weiyun Wang, Shenglong Ye, Botian Shi, Lewei Lu, Qibin Hou, Tong Lu, Hongsheng Li, Jifeng Dai, Wenhai Wang</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型在复杂多页文档理解上表现欠佳，现有RAG方法存在缺陷。方法：提出高质量文档级数据集Doc - 750K，包含多样文档结构、跨页依赖和真实问答对；基于该数据集开发原生多模态模型Docopilot，可不依赖RAG处理文档级依赖。效果：实验表明Docopilot在文档理解任务和多轮交互中，连贯性、准确性和效率表现出色，为文档级多模态理解设立新基线。
            arXiv:2507.14675v1 Announce Type: new 
Abstract: Despite significant progress in multimodal large language models (MLLMs), their performance on complex, multi-page document comprehension remains inadequate, largely due to the lack of high-quality, document-level datasets. While current retrieval-augmented generation (RAG) methods offer partial solutions, they suffer from issues, such as fragmented retrieval contexts, multi-stage error accumulation, and extra time costs of retrieval. In this work, we present a high-quality document-level dataset, Doc-750K, designed to support in-depth understanding of multimodal documents. This dataset includes diverse document structures, extensive cross-page dependencies, and real question-answer pairs derived from the original documents. Building on the dataset, we develop a native multimodal model, Docopilot, which can accurately handle document-level dependencies without relying on RAG. Experiments demonstrate that Docopilot achieves superior coherence, accuracy, and efficiency in document understanding tasks and multi-turn interactions, setting a new baseline for document-level multimodal understanding. Data, code, and models are released at https://github.com/OpenGVLab/Docopilot
        ]]></description>
    </item>
    <item>
        <title>GRACE: Generative Recommendation via Journey-Aware Sparse Attention on Chain-of-Thought Tokenization</title>
        <link>https://arxiv.org/abs/2507.14758</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.14758v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Luyi Ma, Wanjia Zhang, Kai Zhao, Abhishek Kulkarni, Lalitesh Morishetti, Anjana Ganesh, Ashish Ranjan, Aashika Padmanabhan, Jianpeng Xu, Jason Cho, Praveen Kanumala, Kaushiki Nag, Sumit Dutta, Kamiya Motwani, Malay Patel, Evren Korpeoglu, Sushant Kumar, Kannan Achan</dc:creator>
        <description><![CDATA[
            当前生成模型在多行为推荐系统虽有潜力，但存在缺乏标记推理显式信息、计算成本高和多尺度建模有限等问题。本文提出GRACE框架，引入混合思维链（CoT）标记化方法，结合产品知识图谱显式属性编码用户 - 商品交互；设计旅程感知稀疏注意力（JSA）机制，选择性关注标记序列中的压缩及上下文片段。实验表明，GRACE在两个数据集上显著优于基线，在家用领域HR@10和NDCG@10提升超100%，电子领域HR@10提升22.1%，长序列下注意力计算减少48%。
            arXiv:2507.14758v1 Announce Type: new 
Abstract: Generative models have recently demonstrated strong potential in multi-behavior recommendation systems, leveraging the expressive power of transformers and tokenization to generate personalized item sequences. However, their adoption is hindered by (1) the lack of explicit information for token reasoning, (2) high computational costs due to quadratic attention complexity and dense sequence representations after tokenization, and (3) limited multi-scale modeling over user history. In this work, we propose GRACE (Generative Recommendation via journey-aware sparse Attention on Chain-of-thought tokEnization), a novel generative framework for multi-behavior sequential recommendation. GRACE introduces a hybrid Chain-of-Thought (CoT) tokenization method that encodes user-item interactions with explicit attributes from product knowledge graphs (e.g., category, brand, price) over semantic tokenization, enabling interpretable and behavior-aligned generation. To address the inefficiency of standard attention, we design a Journey-Aware Sparse Attention (JSA) mechanism, which selectively attends to compressed, intra-, inter-, and current-context segments in the tokenized sequence. Experiments on two real-world datasets show that GRACE significantly outperforms state-of-the-art baselines, achieving up to +106.9% HR@10 and +106.7% NDCG@10 improvement over the state-of-the-art baseline on the Home domain, and +22.1% HR@10 on the Electronics domain. GRACE also reduces attention computation by up to 48% with long sequences.
        ]]></description>
    </item>
    <item>
        <title>Exploring the In-Context Learning Capabilities of LLMs for Money Laundering Detection in Financial Graphs</title>
        <link>https://arxiv.org/abs/2507.14785</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.14785v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Erfan Pirmorad</dc:creator>
        <description><![CDATA[
            背景：洗钱涉及实体的复杂性和相互关联性要求对图结构数据进行推理。方法：本文将大语言模型作为推理引擎，提出轻量级流程，提取金融知识图中感兴趣实体的k跳邻域，将其序列化为结构化文本，通过少样本上下文学习提示大语言模型评估可疑性并给出理由。效果：利用反映常见洗钱行为的合成反洗钱场景，表明大语言模型能模拟分析师逻辑、突出风险点并给出合理解释，为基于语言的金融犯罪分析奠定基础。
            arXiv:2507.14785v1 Announce Type: new 
Abstract: The complexity and interconnectivity of entities involved in money laundering demand investigative reasoning over graph-structured data. This paper explores the use of large language models (LLMs) as reasoning engines over localized subgraphs extracted from a financial knowledge graph. We propose a lightweight pipeline that retrieves k-hop neighborhoods around entities of interest, serializes them into structured text, and prompts an LLM via few-shot in-context learning to assess suspiciousness and generate justifications. Using synthetic anti-money laundering (AML) scenarios that reflect common laundering behaviors, we show that LLMs can emulate analyst-style logic, highlight red flags, and provide coherent explanations. While this study is exploratory, it illustrates the potential of LLM-based graph reasoning in AML and lays groundwork for explainable, language-driven financial crime analytics.
        ]]></description>
    </item>
    <item>
        <title>Doc2Chart: Intent-Driven Zero-Shot Chart Generation from Documents</title>
        <link>https://arxiv.org/abs/2507.14819</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.14819v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Akriti Jain, Pritika Ramu, Aparna Garimella, Apoorv Saxena</dc:creator>
        <description><![CDATA[
            背景：大语言模型虽可通过指令微调将文本描述或表格转化为可视化数据，但难以直接用于基于用户意图从长文档中可视化数据。方法：提出基于意图的文档图表生成任务，采用无监督两阶段框架，先由大语言模型分解意图提取相关信息并验证、细化，再由启发式模块选图表类型后生成代码，还提出基于归因的评估指标。效果：构建含1242个元组的数据集验证，在图表数据准确性和类型选择上分别比最佳基线高出9分和17分。
            arXiv:2507.14819v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have demonstrated strong capabilities in transforming text descriptions or tables to data visualizations via instruction-tuning methods. However, it is not straightforward to apply these methods directly for a more real-world use case of visualizing data from long documents based on user-given intents, as opposed to the user pre-selecting the relevant content manually. We introduce the task of intent-based chart generation from documents: given a user-specified intent and document(s), the goal is to generate a chart adhering to the intent and grounded on the document(s) in a zero-shot setting. We propose an unsupervised, two-staged framework in which an LLM first extracts relevant information from the document(s) by decomposing the intent and iteratively validates and refines this data. Next, a heuristic-guided module selects an appropriate chart type before final code generation. To assess the data accuracy of the generated charts, we propose an attribution-based metric that uses a structured textual representation of charts, instead of relying on visual decoding metrics that often fail to capture the chart data effectively. To validate our approach, we curate a dataset comprising of 1,242 $<$intent, document, charts$>$ tuples from two domains, finance and scientific, in contrast to the existing datasets that are largely limited to parallel text descriptions/ tables and their corresponding charts. We compare our approach with baselines using single-shot chart generation using LLMs and query-based retrieval methods; our method outperforms by upto $9$ points and $17$ points in terms of chart data accuracy and chart type respectively over the best baselines.
        ]]></description>
    </item>
    <item>
        <title>Time-Aware Attention for Enhanced Electronic Health Records Modeling</title>
        <link>https://arxiv.org/abs/2507.14847</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.14847v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Junhan Yu, Zhunyi Feng, Junwei Lu, Tianxi Cai, Doudou Zhou</dc:creator>
        <description><![CDATA[
            电子病历（EHR）包含预测患者结果和指导医疗决策的关键信息，但有效建模EHR需解决数据异质性和复杂时间模式问题，常规方法难以处理临床事件间不规则时间间隔。为此提出TALE - EHR框架，采用新型时间感知注意力机制，明确建模连续时间间隔以捕捉细粒度序列动态；利用预训练大语言模型从标准代码描述中获取嵌入，增强语义理解。实验表明，该方法在MIMIC - IV和PIC数据集疾病进展预测等任务上优于现有基线。
            arXiv:2507.14847v1 Announce Type: new 
Abstract: Electronic Health Records (EHR) contain valuable clinical information for predicting patient outcomes and guiding healthcare decisions. However, effectively modeling Electronic Health Records (EHRs) requires addressing data heterogeneity and complex temporal patterns. Standard approaches often struggle with irregular time intervals between clinical events. We propose TALE-EHR, a Transformer-based framework featuring a novel time-aware attention mechanism that explicitly models continuous temporal gaps to capture fine-grained sequence dynamics. To complement this temporal modeling with robust semantics, TALE-EHR leverages embeddings derived from standardized code descriptions using a pre-trained Large Language Model (LLM), providing a strong foundation for understanding clinical concepts. Experiments on the MIMIC-IV and PIC dataset demonstrate that our approach outperforms state-of-the-art baselines on tasks such as disease progression forecasting. TALE-EHR underscores the benefit of integrating explicit, continuous temporal modeling with strong semantic representations provides a powerful solution for advancing EHR analysis.
        ]]></description>
    </item>
    <item>
        <title>RefCritic: Training Long Chain-of-Thought Critic Models with Refinement Feedback</title>
        <link>https://arxiv.org/abs/2507.15024</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.15024v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qiaoyu Tang, Hao Xiang, Le Yu, Bowen Yu, Hongyu Lin, Yaojie Lu, Xianpei Han, Le Sun, Junyang Lin</dc:creator>
        <description><![CDATA[
            随着大语言模型快速发展，开发有效批评模块进行精准引导十分关键但具挑战。现有监督微调构建批评模块无法真正提升模型批评能力。为此提出基于强化学习和双规则奖励的长思维链批评模块RefCritic，以生成高质量评估和可操作反馈。在五个基准测试中评估，在批评和改进设置上，各基准测试中均有优势，如在AIME25上对应基础模型分别提升6.8%和7.2%，且在多数投票下表现出色，还在数学推理错误步骤识别基准上优于基于步骤监督的方法。
            arXiv:2507.15024v1 Announce Type: new 
Abstract: With the rapid advancement of Large Language Models (LLMs), developing effective critic modules for precise guidance has become crucial yet challenging. In this paper, we initially demonstrate that supervised fine-tuning for building critic modules (which is widely adopted in current solutions) fails to genuinely enhance models' critique abilities, producing superficial critiques with insufficient reflections and verifications. To unlock the unprecedented critique capabilities, we propose RefCritic, a long-chain-of-thought critic module based on reinforcement learning with dual rule-based rewards: (1) instance-level correctness of solution judgments and (2) refinement accuracies of the policy model based on critiques, aiming to generate high-quality evaluations with actionable feedback that effectively guides model refinement. We evaluate RefCritic on Qwen2.5-14B-Instruct and DeepSeek-R1-Distill-Qwen-14B across five benchmarks. On critique and refinement settings, RefCritic demonstrates consistent advantages across all benchmarks, e.g., 6.8\% and 7.2\% gains on AIME25 for the respective base models. Notably, under majority voting, policy models filtered by RefCritic show superior scaling with increased voting numbers. Moreover, despite training on solution-level supervision, RefCritic outperforms step-level supervised approaches on ProcessBench, a benchmark to identify erroneous steps in mathematical reasoning.
        ]]></description>
    </item>
    <item>
        <title>Evaluation of Coding Schemes for Transformer-based Gene Sequence Modeling</title>
        <link>https://arxiv.org/abs/2507.15087</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.15087v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chenlei Gong, Yuanhe Tian, Lei Mao, Yan Song</dc:creator>
        <description><![CDATA[
            背景：当前很多研究将DNA序列视为特殊语言，用Transformers建模，采用固定长度k - mer分割和BPE子词标记化，但缺乏系统评估。方法：比较不同k值的k - mer分割、4096个标记的BPE词汇表和三种位置编码方法，在不同层数的Transformer编码器中从头训练并在GUE基准数据集上评估。效果：BPE表现更优且稳定；RoPE擅长捕捉周期性基序，AliBi在局部依赖任务表现好；层数从3增加到12有显著提升，24层时提升微弱或有过拟合。该研究为DNA Transformer模型设计提供指导。
            arXiv:2507.15087v1 Announce Type: new 
Abstract: Currently, many studies view DNA sequences as a special type of language and utilize Transformers to model them. These studies use fixed-length k-mer segmentation and BPE subword tokenization but lack a systematic evaluation to determine which is superior. We compare k-mer segmentation with k=1,3,4,5,6, a 4,096-token BPE vocabulary, and three positional encoding methods-sinusoidal, AliBi, and RoPE. Each configuration is trained from scratch in 3, 6, 12, and 24-layer Transformer encoders and evaluated on GUE benchmark dataset. In general, BPE delivers higher and more stable performance across tasks by compressing frequent motifs into variable-length tokens, reducing sequence length, and improving model generalization. RoPE excels at capturing periodic motifs and extrapolating to long sequences, while AliBi also performs well on tasks driven by local dependencies. In terms of depth, we observe significant gains when increasing layers from 3 to 12, with only marginal improvements or slight overfitting at 24 layers. This study provides practical guidance for designing tokenization and positional encoding in DNA Transformer models.
        ]]></description>
    </item>
    <item>
        <title>Long-Short Distance Graph Neural Networks and Improved Curriculum Learning for Emotion Recognition in Conversation</title>
        <link>https://arxiv.org/abs/2507.15205</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.15205v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xinran Li, Xiujuan Xu, Jiaqi Qiao</dc:creator>
        <description><![CDATA[
            对话情感识别是具有挑战性的任务。本文提出长-短距离图神经网络（LSDGNN）多模态方法，基于有向无环图构建长、短距离图神经网络，获取远距离和邻近话语的多模态特征，用差分正则化器和双仿射模块使特征既区分度高又能相互影响。还提出改进课程学习法（ICL）应对数据不平衡问题，计算情感相似度设计“加权情感转移”指标和难度测量器，先易后难训练。在IEMOCAP和MELD数据集上实验，模型优于现有基准。
            arXiv:2507.15205v1 Announce Type: new 
Abstract: Emotion Recognition in Conversation (ERC) is a practical and challenging task. This paper proposes a novel multimodal approach, the Long-Short Distance Graph Neural Network (LSDGNN). Based on the Directed Acyclic Graph (DAG), it constructs a long-distance graph neural network and a short-distance graph neural network to obtain multimodal features of distant and nearby utterances, respectively. To ensure that long- and short-distance features are as distinct as possible in representation while enabling mutual influence between the two modules, we employ a Differential Regularizer and incorporate a BiAffine Module to facilitate feature interaction. In addition, we propose an Improved Curriculum Learning (ICL) to address the challenge of data imbalance. By computing the similarity between different emotions to emphasize the shifts in similar emotions, we design a "weighted emotional shift" metric and develop a difficulty measurer, enabling a training process that prioritizes learning easy samples before harder ones. Experimental results on the IEMOCAP and MELD datasets demonstrate that our model outperforms existing benchmarks.
        ]]></description>
    </item>
    <item>
        <title>Towards Holistic Surgical Scene Graph</title>
        <link>https://arxiv.org/abs/2507.15541</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.15541v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jongmin Shin, Enki Cho, Ka Yong Kim, Jung Yong Kim, Seong Tae Kim, Namkee Oh</dc:creator>
        <description><![CDATA[
            手术场景理解对计算机辅助干预系统至关重要，以往基于图的方法虽能表示手术场景，但工具 - 动作 - 目标组合及操作工具的手的身份等方面研究不足。为此，本文提出Endoscapes - SG201数据集，标注了工具 - 动作 - 目标组合和手的身份；还引入图方法SSG - Com学习和表示关键元素。通过安全评估关键视图和动作三元组识别等下游任务实验，证明整合这些元素对手术场景理解贡献显著。
            arXiv:2507.15541v1 Announce Type: new 
Abstract: Surgical scene understanding is crucial for computer-assisted intervention systems, requiring visual comprehension of surgical scenes that involves diverse elements such as surgical tools, anatomical structures, and their interactions. To effectively represent the complex information in surgical scenes, graph-based approaches have been explored to structurally model surgical entities and their relationships. Previous surgical scene graph studies have demonstrated the feasibility of representing surgical scenes using graphs. However, certain aspects of surgical scenes-such as diverse combinations of tool-action-target and the identity of the hand operating the tool-remain underexplored in graph-based representations, despite their importance. To incorporate these aspects into graph representations, we propose Endoscapes-SG201 dataset, which includes annotations for tool-action-target combinations and hand identity. We also introduce SSG-Com, a graph-based method designed to learn and represent these critical elements. Through experiments on downstream tasks such as critical view of safety assessment and action triplet recognition, we demonstrated the importance of integrating these essential scene graph components, highlighting their significant contribution to surgical scene understanding. The code and dataset are available at https://github.com/ailab-kyunghee/SSG-Com
        ]]></description>
    </item>
    <item>
        <title>ExCyTIn-Bench: Evaluating LLM agents on Cyber Threat Investigation</title>
        <link>https://arxiv.org/abs/2507.14201</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.14201v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yiran Wu, Mauricio Velazco, Andrew Zhao, Manuel Ra\'ul Mel\'endez Luj\'an, Srisuma Movva, Yogesh K Roy, Quang Nguyen, Roberto Rodriguez, Qingyun Wu, Michael Albada, Julia Kiseleva, Anand Mudgerikar</dc:creator>
        <description><![CDATA[
            现实中安全分析师需处理大量安全信息进行威胁调查，基于大语言模型构建自动调查代理是有前景的方向。为此本文提出ExCyTIn - Bench基准。从受控Azure租户构建数据集，涵盖模拟攻击、日志表和自动生成的问题。利用安全日志构建威胁调查图，基于图上节点生成问题。该方法能提供可解释答案，使流程可复用扩展，还能生成可验证奖励的程序任务用于强化学习训练。实验表明任务有难度，各模型平均奖励0.249，最佳为0.368，有很大研究空间。
            arXiv:2507.14201v1 Announce Type: cross 
Abstract: We present ExCyTIn-Bench, the first benchmark to Evaluate an LLM agent x on the task of Cyber Threat Investigation through security questions derived from investigation graphs. Real-world security analysts must sift through a large number of heterogeneous alert signals and security logs, follow multi-hop chains of evidence, and compile an incident report. With the developments of LLMs, building LLM-based agents for automatic thread investigation is a promising direction. To assist the development and evaluation of LLM agents, we construct a dataset from a controlled Azure tenant that covers 8 simulated real-world multi-step attacks, 57 log tables from Microsoft Sentinel and related services, and 589 automatically generated questions. We leverage security logs extracted with expert-crafted detection logic to build threat investigation graphs, and then generate questions with LLMs using paired nodes on the graph, taking the start node as background context and the end node as answer. Anchoring each question to these explicit nodes and edges not only provides automatic, explainable ground truth answers but also makes the pipeline reusable and readily extensible to new logs. This also enables the automatic generation of procedural tasks with verifiable rewards, which can be naturally extended to training agents via reinforcement learning. Our comprehensive experiments with different models confirm the difficulty of the task: with the base setting, the average reward across all evaluated models is 0.249, and the best achieved is 0.368, leaving substantial headroom for future research. Code and data are coming soon!
        ]]></description>
    </item>
    <item>
        <title>Schemora: schema matching via multi-stage recommendation and metadata enrichment using off-the-shelf llms</title>
        <link>https://arxiv.org/abs/2507.14376</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.14376v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Osman Erman Gungor, Derak Paulsen, William Kang</dc:creator>
        <description><![CDATA[
            背景：模式匹配对异构数据源集成及数据集发现至关重要，但问题复杂且耗资源。方法：提出SCHEMORA框架，采用基于提示的方法，结合大语言模型与混合检索技术，丰富模式元数据，利用基于向量和词汇的检索，无需标注训练数据和穷举配对比较来识别候选匹配。效果：在MIMIC - OMOP基准测试中创最佳性能，HitRate@5提升7.49%，HitRate@3提升3.75%，且是首个有开源实现的基于大语言模型的模式匹配方法。
            arXiv:2507.14376v1 Announce Type: cross 
Abstract: Schema matching is essential for integrating heterogeneous data sources and enhancing dataset discovery, yet it remains a complex and resource-intensive problem. We introduce SCHEMORA, a schema matching framework that combines large language models with hybrid retrieval techniques in a prompt-based approach, enabling efficient identification of candidate matches without relying on labeled training data or exhaustive pairwise comparisons. By enriching schema metadata and leveraging both vector-based and lexical retrieval, SCHEMORA improves matching accuracy and scalability. Evaluated on the MIMIC-OMOP benchmark, it establishes new state-of-the-art performance, with gains of 7.49% in HitRate@5 and 3.75% in HitRate@3 over previous best results. To our knowledge, this is the first LLM-based schema matching method with an open-source implementation, accompanied by analysis that underscores the critical role of retrieval and provides practical guidance on model selection.
        ]]></description>
    </item>
    <item>
        <title>Assessing the Reliability of Large Language Models for Deductive Qualitative Coding: A Comparative Study of ChatGPT Interventions</title>
        <link>https://arxiv.org/abs/2507.14384</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.14384v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Angjelin Hila, Elliott Hauser</dc:creator>
        <description><![CDATA[
            该研究聚焦大语言模型用于结构化演绎定性编码。当前研究多侧重归纳编码，而演绎分类任务潜力尚待挖掘。研究借助比较议程项目主编码手册，将美国最高法院案例摘要分类到21个主要政策领域。测试了零样本、少样本、基于定义和逐步任务分解四种干预方法。通过标准分类指标和卡方检验等评估。结果显示干预策略显著影响分类行为，逐步任务分解策略可靠性最强（准确率0.775等），表明经针对性干预，大模型可用于严谨定性编码工作流程。
            arXiv:2507.14384v1 Announce Type: cross 
Abstract: In this study, we investigate the use of large language models (LLMs), specifically ChatGPT, for structured deductive qualitative coding. While most current research emphasizes inductive coding applications, we address the underexplored potential of LLMs to perform deductive classification tasks aligned with established human-coded schemes. Using the Comparative Agendas Project (CAP) Master Codebook, we classified U.S. Supreme Court case summaries into 21 major policy domains. We tested four intervention methods: zero-shot, few-shot, definition-based, and a novel Step-by-Step Task Decomposition strategy, across repeated samples. Performance was evaluated using standard classification metrics (accuracy, F1-score, Cohen's kappa, Krippendorff's alpha), and construct validity was assessed using chi-squared tests and Cramer's V. Chi-squared and effect size analyses confirmed that intervention strategies significantly influenced classification behavior, with Cramer's V values ranging from 0.359 to 0.613, indicating moderate to strong shifts in classification patterns. The Step-by-Step Task Decomposition strategy achieved the strongest reliability (accuracy = 0.775, kappa = 0.744, alpha = 0.746), achieving thresholds for substantial agreement. Despite the semantic ambiguity within case summaries, ChatGPT displayed stable agreement across samples, including high F1 scores in low-support subclasses. These findings demonstrate that with targeted, custom-tailored interventions, LLMs can achieve reliability levels suitable for integration into rigorous qualitative coding workflows.
        ]]></description>
    </item>
    <item>
        <title>Diffusion Models for Time Series Forecasting: A Survey</title>
        <link>https://arxiv.org/abs/2507.14507</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.14507v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chen Su, Zhengzhou Cai, Yuanhe Tian, Zihong Zheng, Yan Song</dc:creator>
        <description><![CDATA[
            背景：扩散模型最初用于图像合成，现其应用拓展到时间序列预测（TSF）且成果显著。方法：该综述先介绍标准扩散模型及其常见变体在TSF任务中的适配情况，全面回顾用于TSF的扩散模型，关注条件信息来源及融入机制，对现有方法分类总结，还考察基础模型、常用数据集和评估指标。效果：阐述了扩散模型在TSF领域的进展与前景，为相关研究提供参考。
            arXiv:2507.14507v1 Announce Type: cross 
Abstract: Diffusion models, initially developed for image synthesis, demonstrate remarkable generative capabilities. Recently, their application has expanded to time series forecasting (TSF), yielding promising results. In this survey, we firstly introduce the standard diffusion models and their prevalent variants, explaining their adaptation to TSF tasks. We then provide a comprehensive review of diffusion models for TSF, paying special attention to the sources of conditional information and the mechanisms for integrating this conditioning within the models. In analyzing existing approaches using diffusion models for TSF, we provide a systematic categorization and a comprehensive summary of them in this survey. Furthermore, we examine several foundational diffusion models applied to TSF, alongside commonly used datasets and evaluation metrics. Finally, we discuss current limitations in these approaches and potential future research directions. Overall, this survey details recent progress and future prospects for diffusion models in TSF, serving as a reference for researchers in the field.
        ]]></description>
    </item>
    <item>
        <title>Disentangling Homophily and Heterophily in Multimodal Graph Clustering</title>
        <link>https://arxiv.org/abs/2507.15253</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.15253v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhaochen Guo, Zhixiang Shen, Xuanting Xie, Liangjian Wen, Zhao Kang</dc:creator>
        <description><![CDATA[
            这篇论文聚焦多模态图聚类。背景是多模态图结合非结构化异质数据和结构化连接，在无监督学习中研究不足。方法上，提出了DMGC框架，将原混合图分解为同质性增强图和异质性感知图，引入多模态双频融合机制，通过双通策略过滤分解图实现多模态有效集成，并以自监督对齐目标引导学习。效果方面，在多模态和多关系图数据集上的实验表明，DMGC取得了最优性能，展现出有效性和泛化性。
            arXiv:2507.15253v1 Announce Type: cross 
Abstract: Multimodal graphs, which integrate unstructured heterogeneous data with structured interconnections, offer substantial real-world utility but remain insufficiently explored in unsupervised learning. In this work, we initiate the study of multimodal graph clustering, aiming to bridge this critical gap. Through empirical analysis, we observe that real-world multimodal graphs often exhibit hybrid neighborhood patterns, combining both homophilic and heterophilic relationships. To address this challenge, we propose a novel framework -- \textsc{Disentangled Multimodal Graph Clustering (DMGC)} -- which decomposes the original hybrid graph into two complementary views: (1) a homophily-enhanced graph that captures cross-modal class consistency, and (2) heterophily-aware graphs that preserve modality-specific inter-class distinctions. We introduce a \emph{Multimodal Dual-frequency Fusion} mechanism that jointly filters these disentangled graphs through a dual-pass strategy, enabling effective multimodal integration while mitigating category confusion. Our self-supervised alignment objectives further guide the learning process without requiring labels. Extensive experiments on both multimodal and multi-relational graph datasets demonstrate that DMGC achieves state-of-the-art performance, highlighting its effectiveness and generalizability across diverse settings. Our code is available at https://github.com/Uncnbb/DMGC.
        ]]></description>
    </item>
    <item>
        <title>Predictive Process Monitoring Using Object-centric Graph Embeddings</title>
        <link>https://arxiv.org/abs/2507.15411</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.15411v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wissam Gherissi (LAMSADE), Mehdi Acheli (LAMSADE), Joyce El Haddad (LAMSADE), Daniela Grigori (LAMSADE)</dc:creator>
        <description><![CDATA[
            背景：以对象为中心的预测过程监控面临提取相关信息和构建有效模型的挑战。方法：本文提出端到端模型预测未来过程行为，聚焦下一活动预测和下一事件时间两个任务，采用图注意力网络编码活动及其关系，结合LSTM网络处理时间依赖。效果：在一个真实和三个合成事件日志上评估，模型与现有先进方法相比表现出色。
            arXiv:2507.15411v1 Announce Type: cross 
Abstract: Object-centric predictive process monitoring explores and utilizes object-centric event logs to enhance process predictions. The main challenge lies in extracting relevant information and building effective models. In this paper, we propose an end-to-end model that predicts future process behavior, focusing on two tasks: next activity prediction and next event time. The proposed model employs a graph attention network to encode activities and their relationships, combined with an LSTM network to handle temporal dependencies. Evaluated on one reallife and three synthetic event logs, the model demonstrates competitive performance compared to state-of-the-art methods.
        ]]></description>
    </item>
    <item>
        <title>Chart-R1: Chain-of-Thought Supervision and Reinforcement for Advanced Chart Reasoner</title>
        <link>https://arxiv.org/abs/2507.15509</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.15509v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Lei Chen, Xuanle Zhao, Zhixiong Zeng, Jing Huang, Yufeng Zhong, Lin Ma</dc:creator>
        <description><![CDATA[
            背景：此前 R1 风格方法多用于数学推理和代码智能，在更通用的多模态数据上验证其优势有重要研究意义，图表复杂推理是挑战。方法：提出 Chart-R1 模型，用强化学习微调实现复杂图表推理；提出编程数据合成技术生成高质量推理数据；采用两阶段训练策略，即逐步思维链监督的 Chart-COT 和对数值敏感的强化微调的 Chart-RFT。效果：在开源基准和自建数据集实验表明，相比图表领域方法有显著优势，可与大模型媲美。
            arXiv:2507.15509v1 Announce Type: cross 
Abstract: Recently, inspired by OpenAI-o1/o3 and Deepseek-R1, the R1-Style method based on reinforcement learning fine-tuning has received widespread attention from the community. Previous R1-Style methods mainly focus on mathematical reasoning and code intelligence. It is of great research significance to verify their advantages on more general multimodal data. Chart is an important multimodal data type with rich information, which brings important research challenges in complex reasoning. In this work, we introduce Chart-R1, a chart-domain vision-language model with reinforcement learning fine-tuning to enable complex chart reasoning. To support Chart-R1, we first propose a novel programmatic data synthesis technology to generate high-quality step-by-step chart reasoning data covering single- and multi-subcharts, which makes up for the lack of reasoning data in the chart domain. Then we develop a two-stage training strategy: Chart-COT with step-by-step chain-of-thought supervision, and Chart-RFT with numerically sensitive reinforcement fine-tuning. Chart-COT aims to decompose complex chart reasoning tasks into fine-grained, understandable subtasks through step-by-step supervision, which lays a good foundation for improving the reasoning level of reinforcement learning. Chart-RFT utilize the typical group relative policy optimization strategy, in which a relatively soft reward is adopted for numerical response to emphasize the numerical sensitivity in the chart domain. We conduct extensive experiments on open-source benchmarks and self-built chart reasoning dataset (\emph{i.e., ChartRQA}). Experimental results show that Chart-R1 has significant advantages compared to chart-domain methods, even comparable to open/closed source large-scale models (\emph{e.g., GPT-4o, Claude-3.5}).
        ]]></description>
    </item>
    <item>
        <title>Dissociating model architectures from inference computations</title>
        <link>https://arxiv.org/abs/2507.15776</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.15776v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Noor Sajid, Johan Medrano</dc:creator>
        <description><![CDATA[
            背景：Parr等人研究了自回归和深度时间模型在处理非马尔可夫序列建模上的差异。方法：强调将模型架构（预测分布的分解方式）与推理时的计算分离，通过在迭代推理中构建上下文访问，让自回归模型模拟深度时间计算，用基于下一个标记预测训练的变压器模型，在迭代推理中引入分层时间分解。效果：在减少计算量的同时保持了预测能力，表明预测构建和细化过程未必与底层模型架构绑定。
            arXiv:2507.15776v1 Announce Type: cross 
Abstract: Parr et al., 2025 examines how auto-regressive and deep temporal models differ in their treatment of non-Markovian sequence modelling. Building on this, we highlight the need for dissociating model architectures, i.e., how the predictive distribution factorises, from the computations invoked at inference. We demonstrate that deep temporal computations are mimicked by autoregressive models by structuring context access during iterative inference. Using a transformer trained on next-token prediction, we show that inducing hierarchical temporal factorisation during iterative inference maintains predictive capacity while instantiating fewer computations. This emphasises that processes for constructing and refining predictions are not necessarily bound to their underlying model architectures.
        ]]></description>
    </item>
    <item>
        <title>Hypergraphs on high dimensional time series sets using signature transform</title>
        <link>https://arxiv.org/abs/2507.15802</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.15802v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>R\'emi Vaucher, Paul Minchella</dc:creator>
        <description><![CDATA[
            背景：超图及其拓扑数据分析是理解复杂数据结构的有力工具，此前构建超图的研究多聚焦单变量时间序列。方法：本文针对多变量时间序列集合构建超图的挑战，通过利用签名变换的特性引入可控随机性，扩展现有框架以处理此类时间序列集合。效果：在合成数据集上验证了该方法，取得了有前景的结果，增强了构建过程的鲁棒性。
            arXiv:2507.15802v1 Announce Type: cross 
Abstract: In recent decades, hypergraphs and their analysis through Topological Data Analysis (TDA) have emerged as powerful tools for understanding complex data structures. Various methods have been developed to construct hypergraphs -- referred to as simplicial complexes in the TDA framework -- over datasets, enabling the formation of edges between more than two vertices. This paper addresses the challenge of constructing hypergraphs from collections of multivariate time series. While prior work has focused on the case of a single multivariate time series, we extend this framework to handle collections of such time series. Our approach generalizes the method proposed in Chretien and al. by leveraging the properties of signature transforms to introduce controlled randomness, thereby enhancing the robustness of the construction process. We validate our method on synthetic datasets and present promising results.
        ]]></description>
    </item>
    <item>
        <title>A Mathematical Framework and a Suite of Learning Techniques for Neural-Symbolic Systems</title>
        <link>https://arxiv.org/abs/2407.09693</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2407.09693v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Charles Dickens, Connor Pryor, Changyu Gao, Alon Albalak, Eriq Augustine, William Wang, Stephen Wright, Lise Getoor</dc:creator>
        <description><![CDATA[
            神经符号（NeSy）系统领域发展迅速，但缺乏统一框架来组织通用建模模式和开发通用学习方法。本文提出神经符号能量基模型（NeSy - EBMs）这一统一数学框架，可推导主要学习损失梯度的通用表达式，并引入四种结合多领域方法的学习途径。还基于NeuPSL库为其提供支撑。经多数据集实证分析，NeSy - EBMs在图像分类、图节点标注等多任务中展现出实际优势。
            arXiv:2407.09693v2 Announce Type: replace 
Abstract: The field of Neural-Symbolic (NeSy) systems is growing rapidly. Proposed approaches show great promise in achieving symbiotic unions of neural and symbolic methods. However, a unifying framework is needed to organize common NeSy modeling patterns and develop general learning approaches. In this paper, we introduce Neural-Symbolic Energy-Based Models (NeSy-EBMs), a unifying mathematical framework for discriminative and generative NeSy modeling. Importantly, NeSy-EBMs allow the derivation of general expressions for gradients of prominent learning losses, and we introduce a suite of four learning approaches that leverage methods from multiple domains, including bilevel and stochastic policy optimization. Finally, we ground the NeSy-EBM framework with Neural Probabilistic Soft Logic (NeuPSL), an open-source NeSy-EBM library designed for scalability and expressivity, facilitating the real-world application of NeSy systems. Through extensive empirical analysis across multiple datasets, we demonstrate the practical advantages of NeSy-EBMs in various tasks, including image classification, graph node labeling, autonomous vehicle situation awareness, and question answering.
        ]]></description>
    </item>
    <item>
        <title>Layerwise Recall and the Geometry of Interwoven Knowledge in LLMs</title>
        <link>https://arxiv.org/abs/2502.10871</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.10871v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ge Lei, Samuel J. Cooper</dc:creator>
        <description><![CDATA[
            背景：研究大语言模型如何编码交织的科学知识。方法：以化学元素和LLaMA系列模型为例，发现隐藏状态中存在与元素周期表概念结构对齐的3D螺旋结构，通过线性探测分析各层特点。效果：表明大模型能反映从文本中学到的科学概念的几何组织，中间层编码连续、重叠属性实现间接回忆，深层锐化分类区别并结合语言上下文，知识以结构化几何流形形式跨层交织语义信息，有望启发科学知识表征与推理研究。
            arXiv:2502.10871v2 Announce Type: replace 
Abstract: This study explores how large language models (LLMs) encode interwoven scientific knowledge, using chemical elements and LLaMA-series models as a case study. We identify a 3D spiral structure in the hidden states that aligns with the conceptual structure of the periodic table, suggesting that LLMs can reflect the geometric organization of scientific concepts learned from text. Linear probing reveals that middle layers encode continuous, overlapping attributes that enable indirect recall, while deeper layers sharpen categorical distinctions and incorporate linguistic context. These findings suggest that LLMs represent symbolic knowledge not as isolated facts, but as structured geometric manifolds that intertwine semantic information across layers. We hope this work inspires further exploration of how LLMs represent and reason about scientific knowledge, particularly in domains such as materials science.
        ]]></description>
    </item>
    <item>
        <title>FastMCTS: A Simple Sampling Strategy for Data Synthesis</title>
        <link>https://arxiv.org/abs/2502.11476</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.11476v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Peiji Li, Kai Lv, Yunfan Shao, Yichuan Ma, Linyang Li, Xiaoqing Zheng, Xipeng Qiu, Qipeng Guo</dc:creator>
        <description><![CDATA[
            背景：合成高质量多步推理数据可提升大语言模型性能，但现有方法多依赖拒绝采样，效率低且不同难度问题采样不均衡。方法：提出受蒙特卡洛树搜索启发的FastMCTS数据合成策略，提供更高效的多步推理数据采样方法，有步骤级评估信号，促进不同难度问题的均衡采样。效果：在中英文推理数据集实验表明，随生成令牌数增加，比拒绝采样多生成超30%正确推理路径；同等合成数据预算下，在多基准测试中比拒绝采样数据训练的模型性能高3.9%。
            arXiv:2502.11476v2 Announce Type: replace 
Abstract: Synthetic high-quality multi-step reasoning data can significantly enhance the performance of large language models on various tasks. However, most existing methods rely on rejection sampling, which generates trajectories independently and suffers from inefficiency and imbalanced sampling across problems of varying difficulty. In this work, we introduce FastMCTS, an innovative data synthesis strategy inspired by Monte Carlo Tree Search. FastMCTS provides a more efficient sampling method for multi-step reasoning data, offering step-level evaluation signals and promoting balanced sampling across problems of different difficulty levels. Experiments on both English and Chinese reasoning datasets demonstrate that FastMCTS generates over 30\% more correct reasoning paths compared to rejection sampling as the number of generated tokens scales up. Furthermore, under comparable synthetic data budgets, models trained on FastMCTS-generated data outperform those trained on rejection sampling data by 3.9\% across multiple benchmarks. As a lightweight sampling strategy, FastMCTS offers a practical and efficient alternative for synthesizing high-quality reasoning data. Our code will be released soon.
        ]]></description>
    </item>
    <item>
        <title>BriLLM: Brain-inspired Large Language Model</title>
        <link>https://arxiv.org/abs/2503.11299</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.11299v5</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hai Zhao, Hongqiu Wu, Dongjie Yang, Anni Zou, Jiale Hong</dc:creator>
        <description><![CDATA[
            背景：现有传统机器学习模型解释性有限。方法：提出首个受大脑启发的大语言模型BriLLM，它是非Transformer、非GPT的生成式语言模型，基于神经网络有向图的信号全连接流动定义，将token定义为图中节点，信号流按“最小阻力”原则在节点间流动。效果：理论上支持无限长n - gram模型，工作信号流提供召回激活和多模态支持可能。目前发布的中文版本有4000个token、32维节点宽度、16个token长序列预测能力，语言模型预测性能与GPT - 1相当。
            arXiv:2503.11299v5 Announce Type: replace 
Abstract: This paper reports the first brain-inspired large language model (BriLLM). This is a non-Transformer, non-GPT, non-traditional machine learning input-output controlled generative language model. The model is based on the Signal Fully-connected flowing (SiFu) definition on the directed graph in terms of the neural network, and has the interpretability of all nodes on the graph of the whole model, instead of the traditional machine learning model that only has limited interpretability at the input and output ends. In the language model scenario, the token is defined as a node in the graph. A randomly shaped or user-defined signal flow flows between nodes on the principle of "least resistance" along paths. The next token or node to be predicted or generated is the target of the signal flow. As a language model, BriLLM theoretically supports infinitely long $n$-gram models when the model size is independent of the input and predicted length of the model. The model's working signal flow provides the possibility of recall activation and innate multi-modal support similar to the cognitive patterns of the human brain. At present, we released the first BriLLM version in Chinese, with 4000 tokens, 32-dimensional node width, 16-token long sequence prediction ability, and language model prediction performance comparable to GPT-1. More computing power will help us explore the infinite possibilities depicted above.
        ]]></description>
    </item>
    <item>
        <title>Federated Continual Instruction Tuning</title>
        <link>https://arxiv.org/abs/2503.12897</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.12897v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Haiyang Guo, Fanhu Zeng, Fei Zhu, Wenzhuo Liu, Da-Han Wang, Jian Xu, Xu-Yao Zhang, Cheng-Lin Liu</dc:creator>
        <description><![CDATA[
            大模型的指令调优需要大量数据，但监督微调的计算成本和数据收集要求让多数研究者难以负担。联邦学习能利用分布式数据和资源降低联合训练成本，但现有方法假设任务数量固定，无法应对现实中客户不断遇到新知识且受内存限制难以保留旧任务的问题。为此，本文提出联邦持续指令调优（FCIT）基准，包含两种场景、四种设置和十二个数据集。还提出动态知识组织和子空间选择性激活方法。实验表明，该方法显著提升了不同数据异质性和灾难性遗忘水平下的模型性能。
            arXiv:2503.12897v2 Announce Type: replace 
Abstract: A vast amount of instruction tuning data is crucial for the impressive performance of Large Multimodal Models (LMMs), but the associated computational costs and data collection demands during supervised fine-tuning make it impractical for most researchers. Federated learning (FL) has the potential to leverage all distributed data and training resources to reduce the overhead of joint training. However, most existing methods assume a fixed number of tasks, while in real-world scenarios, clients continuously encounter new knowledge and often struggle to retain old tasks due to memory constraints. In this work, we introduce the Federated Continual Instruction Tuning (FCIT) benchmark to model this real-world challenge. Our benchmark includes two realistic scenarios, encompassing four different settings and twelve carefully curated instruction tuning datasets. To address the challenges posed by FCIT, we propose dynamic knowledge organization to effectively integrate updates from different tasks during training and subspace selective activation to allocate task-specific output during inference. Extensive experimental results demonstrate that our proposed method significantly enhances model performance across varying levels of data heterogeneity and catastrophic forgetting. Code and dataset are released at https://github.com/Ghy0501/FCIT.
        ]]></description>
    </item>
    <item>
        <title>Supervised Graph Contrastive Learning for Gene Regulatory Network</title>
        <link>https://arxiv.org/abs/2505.17786</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17786v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sho Oshima, Yuji Okamoto, Taisei Tosaki, Ryosuke Kojima, Yasushi Okuno</dc:creator>
        <description><![CDATA[
            图表示学习能利用图数据结构获取有意义的潜在空间，图对比学习（GCL）是强大的自监督方法。但现有GCL应用于生物网络时，忽略了如基因敲除等有生物学意义的扰动。为此，研究提出SupGCL，将基因敲除实验的生物扰动作为监督，把利用非生物扰动的GCL方法扩展到引入实际生物基因扰动的概率模型。将其应用于多种癌症患者的真实基因调控网络数据集，在患者风险预测、疾病亚型分类和基因功能分类等下游任务中，性能均优于现有基线。
            arXiv:2505.17786v3 Announce Type: replace 
Abstract: Graph representation learning is effective for obtaining a meaningful latent space utilizing the structure of graph data and is widely applied, including biological networks. In particular, Graph Contrastive Learning (GCL) has emerged as a powerful self-supervised method that relies on applying perturbations to graphs for data augmentation. However, when applying existing GCL methods to biological networks such as Gene Regulatory Networks (GRNs), they overlooked meaningful biologically relevant perturbations, e.g., gene knockdowns. In this study, we introduce SupGCL (Supervised Graph Contrastive Learning), a novel GCL method for GRNs that directly incorporates biological perturbations derived from gene knockdown experiments as the supervision. SupGCL mathematically extends existing GCL methods that utilize non-biological perturbations to probabilistic models that introduce actual biological gene perturbation utilizing gene knockdown data. Using the GRN representation obtained by our proposed method, our aim is to improve the performance of biological downstream tasks such as patient hazard prediction and disease subtype classification (graph-level task), and gene function classification (node-level task). We applied SupGCL on real GRN datasets derived from patients with multiple types of cancer, and in all experiments SupGCL achieves better performance than state-of-the-art baselines.
        ]]></description>
    </item>
    <item>
        <title>Smarter Together: Combining Large Language Models and Small Models for Physiological Signals Visual Inspection</title>
        <link>https://arxiv.org/abs/2501.16215</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2501.16215v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Huayu Li, Zhengxiao He, Xiwen Chen, Ci Zhang, Stuart F. Quan, William D. S. Killgore, Shu-Fen Wung, Chen X. Chen, Geng Yuan, Jin Lu, Ao Li</dc:creator>
        <description><![CDATA[
            大语言模型在医学时间序列数据视觉解读上有潜力，但通用设计限制其特定领域精度，且多数模型的专有性给微调带来挑战；小模型在特定任务表现好，但缺乏复杂医疗决策推理能力。为此，研究提出ConMIL框架，融合多实例学习、保形预测及结构化方法，增强大语言模型视觉检查能力。实验表明，ConMIL可提升ChatGPT4.0等模型准确性，如支持下的Qwen2 - VL - 7B和MiMo - VL - 7B - RL在心律失常检测和睡眠阶段分类任务表现良好。
            arXiv:2501.16215v2 Announce Type: replace-cross 
Abstract: Large language models (LLMs) have shown promising capabilities in visually interpreting medical time-series data. However, their general-purpose design can limit domain-specific precision, and the proprietary nature of many models poses challenges for fine-tuning on specialized clinical datasets. Conversely, small specialized models (SSMs) offer strong performance on focused tasks but lack the broader reasoning needed for complex medical decision-making. To address these complementary limitations, we introduce \ConMIL{} (Conformalized Multiple Instance Learning), a novel decision-support framework distinctively synergizes three key components: (1) a new Multiple Instance Learning (MIL) mechanism, QTrans-Pooling, designed for per-class interpretability in identifying clinically relevant physiological signal segments; (2) conformal prediction, integrated with MIL to generate calibrated, set-valued outputs with statistical reliability guarantees; and (3) a structured approach for these interpretable and uncertainty-quantified SSM outputs to enhance the visual inspection capabilities of LLMs. Our experiments on arrhythmia detection and sleep stage classification demonstrate that \ConMIL{} can enhance the accuracy of LLMs such as ChatGPT4.0, Qwen2-VL-7B, and MiMo-VL-7B-RL. For example, \ConMIL{}-supported Qwen2-VL-7B and MiMo-VL-7B-RL both achieves 94.92% and 96.82% precision on confident samples and (70.61% and 78.02%)/(78.10% and 71.98%) on uncertain samples for the two tasks, compared to 46.13% and 13.16% using the LLM alone. These results suggest that integrating task-specific models with LLMs may offer a promising pathway toward more interpretable and trustworthy AI-driven clinical decision support.
        ]]></description>
    </item>
    <item>
        <title>Parameter-Efficient Fine-Tuning of Foundation Models for CLP Speech Classification</title>
        <link>https://arxiv.org/abs/2507.14898</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.14898v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Susmita Bhattacharjee, Jagabandhu Mishra, H. S. Shekhawat, S. R. Mahadeva Prasanna</dc:creator>
        <description><![CDATA[
            这是一篇关于音频分类的论文。背景是唇腭裂患者病情加重时鼻音增加，会改变语音特征。方法是提出使用参数高效微调（PEFT）基础模型进行唇腭裂检测和严重程度分类，在英语和卡纳达语两个数据集上实验，对比自监督模型、弱监督模型的嵌入特征与传统手工特征，并使用LoRA和DoRA技术微调表现最佳的Whisper模型。效果是在NMCPC数据集上，相比最佳基础模型和手工特征基线，宏观平均F1分数分别提升26.4%和63.4%；在AIISH数据集上分别提升6.1%和52.9%。
            arXiv:2507.14898v1 Announce Type: new 
Abstract: We propose the use of parameter-efficient fine-tuning (PEFT) of foundation models for cleft lip and palate (CLP) detection and severity classification. In CLP, nasalization increases with severity due to the abnormal passage between the oral and nasal tracts; this causes oral stops to be replaced by glottal stops and alters formant trajectories and vowel space. Since foundation models are trained for grapheme prediction or long-term quantized representation prediction, they may better discriminate CLP severity when fine-tuned on domain-specific data. We conduct experiments on two datasets: English (NMCPC) and Kannada (AIISH). We perform a comparative analysis using embeddings from self-supervised models Wav2Vec2 and WavLM, and the weakly supervised Whisper, each paired with SVM classifiers, and compare them with traditional handcrafted features eGeMAPS and ComParE. Finally, we fine-tune the best-performing Whisper model using PEFT techniques: Low-Rank Adapter (LoRA) and Decomposed Low-Rank Adapter (DoRA). Our results demonstrate that the proposed approach achieves relative improvements of 26.4% and 63.4% in macro-average F1 score over the best foundation model and handcrafted feature baselines on the NMCPC dataset, and improvements of 6.1% and 52.9% on the AIISH dataset, respectively.
        ]]></description>
    </item>
    <item>
        <title>DMOSpeech 2: Reinforcement Learning for Duration Prediction in Metric-Optimized Speech Synthesis</title>
        <link>https://arxiv.org/abs/2507.14988</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.14988v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yinghao Aaron Li, Xilin Jiang, Fei Tao, Cheng Niu, Kaifeng Xu, Juntong Song, Nima Mesgarani</dc:creator>
        <description><![CDATA[
            基于扩散的文本转语音（TTS）系统在零样本语音合成方面取得显著进展，但优化各组件以适应感知指标仍具挑战。此前DMOSpeech实现了语音生成组件的指标优化，而时长预测未优化。本文提出DMOSpeech 2，通过强化学习将指标优化拓展到时长预测器，采用组相对偏好优化（GRPO）构建新的时长策略框架，以说话人相似度和字错误率为奖励信号。还引入教师引导采样，先借助教师模型去噪再过渡到学生模型。评估显示，该系统各指标表现更优，采样步数减半且质量不减。
            arXiv:2507.14988v1 Announce Type: new 
Abstract: Diffusion-based text-to-speech (TTS) systems have made remarkable progress in zero-shot speech synthesis, yet optimizing all components for perceptual metrics remains challenging. Prior work with DMOSpeech demonstrated direct metric optimization for speech generation components, but duration prediction remained unoptimized. This paper presents DMOSpeech 2, which extends metric optimization to the duration predictor through a reinforcement learning approach. The proposed system implements a novel duration policy framework using group relative preference optimization (GRPO) with speaker similarity and word error rate as reward signals. By optimizing this previously unoptimized component, DMOSpeech 2 creates a more complete metric-optimized synthesis pipeline. Additionally, this paper introduces teacher-guided sampling, a hybrid approach leveraging a teacher model for initial denoising steps before transitioning to the student model, significantly improving output diversity while maintaining efficiency. Comprehensive evaluations demonstrate superior performance across all metrics compared to previous systems, while reducing sampling steps by half without quality degradation. These advances represent a significant step toward speech synthesis systems with metric optimization across multiple components. The audio samples, code and pre-trained models are available at https://dmospeech2.github.io/.
        ]]></description>
    </item>
    <item>
        <title>Multichannel Keyword Spotting for Noisy Conditions</title>
        <link>https://arxiv.org/abs/2507.15558</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.15558v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Dzmitry Saladukha, Ivan Koriabkin, Kanstantsin Artsiom, Aliaksei Rak, Nikita Ryzhikov</dc:creator>
        <description><![CDATA[
            这是一篇关于音频分类中关键词检测的论文。背景是在噪声环境下，波束形成和自适应噪声消除技术可能会因扭曲或抑制有用信号而降低激活系统性能。方法是作者提出一种使用多个输入通道和注意力机制的神经网络架构，使网络能确定最有用的通道或其组合。效果是在两个数据集上证明了算法质量的提升，并与多个基线在降噪指标、关键词检测指标和计算资源方面进行了比较。
            arXiv:2507.15558v1 Announce Type: new 
Abstract: This article presents a method for improving a keyword spotter (KWS) algorithm in noisy environments. Although beamforming (BF) and adaptive noise cancellation (ANC) techniques are robust in some conditions, they may degrade the performance of the activation system by distorting or suppressing useful signals. The authors propose a neural network architecture that uses several input channels and an attention mechanism that allows the network to determine the most useful channel or their combination. The improved quality of the algorithm was demonstrated on two datasets: from a laboratory with controlled conditions and from smart speakers in natural conditions. The proposed algorithm was compared against several baselines in terms of the quality of noise reduction metrics, KWS metrics, and computing resources in comparison with existing solutions.
        ]]></description>
    </item>
    <item>
        <title>Developing an AI-Guided Assistant Device for the Deaf and Hearing Impaired</title>
        <link>https://arxiv.org/abs/2507.14215</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.14215v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiayu (Jerry),  Liu</dc:creator>
        <description><![CDATA[
            该研究旨在为聋哑或听力障碍人士开发辅助设备的深度学习系统，以实时准确地定位和识别声源。系统包含三部分：自定义CNN架构JerryNet确定声源方向；基于微调CLAP模型的音频分类模块识别声音类别；结合音频、视觉和文本数据的多模态集成模型定位声源。硬件由四个麦克风、相机和腕带构成。在自定义数据集上，JerryNet声音方向精度达91.1%，CLAP模型在自定义和AudioSet数据集上准确率分别为98.5%和95%，多模态模型cIoU为0.892、AUC为0.658，均超基线模型。
            arXiv:2507.14215v1 Announce Type: cross 
Abstract: This study aims to develop a deep learning system for an accessibility device for the deaf or hearing impaired. The device will accurately localize and identify sound sources in real time. This study will fill an important gap in current research by leveraging machine learning techniques to target the underprivileged community. The system includes three main components. 1. JerryNet: A custom designed CNN architecture that determines the direction of arrival (DoA) for nine possible directions. 2. Audio Classification: This model is based on fine-tuning the Contrastive Language-Audio Pretraining (CLAP) model to identify the exact sound classes only based on audio. 3. Multimodal integration model: This is an accurate sound localization model that combines audio, visual, and text data to locate the exact sound sources in the images. The part consists of two modules, one object detection using Yolov9 to generate all the bounding boxes of the objects, and an audio visual localization model to identify the optimal bounding box using complete Intersection over Union (CIoU). The hardware consists of a four-microphone rectangular formation and a camera mounted on glasses with a wristband for displaying necessary information like direction. On a custom collected data set, JerryNet achieved a precision of 91. 1% for the sound direction, outperforming all the baseline models. The CLAP model achieved 98.5% and 95% accuracy on custom and AudioSet datasets, respectively. The audio-visual localization model within component 3 yielded a cIoU of 0.892 and an AUC of 0.658, surpassing other similar models. There are many future potentials to this study, paving the way to creating a new generation of accessibility devices.
        ]]></description>
    </item>
    <item>
        <title>An Investigation of Test-time Adaptation for Audio Classification under Background Noise</title>
        <link>https://arxiv.org/abs/2507.15523</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2507.15523v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Weichuang Shao, Iman Yi Liao, Tomas Henrique Bode Maul, Tissa Chandesa</dc:creator>
        <description><![CDATA[
            深度学习中领域偏移是突出问题，会使模型在测试集上性能下降。本文旨在利用测试时自适应（TTA）技术解决背景噪声导致的领域偏移下的音频分类问题。采用TTT、TENT两种常见TTA方法及先进的CoNMix方法，在AudioMNIST和SpeechCommands V1数据集上，针对不同背景噪声类型和强度进行实验。结果显示，改进的CoNMix在领域偏移下分类准确率最高，如在AudioMNIST数据集上，10 dB健身车背景噪声下错误率5.31%，3 dB水龙头流水背景噪声下错误率12.75%。该研究为利用TTA技术进行音频分类的首次探索。
            arXiv:2507.15523v1 Announce Type: cross 
Abstract: Domain shift is a prominent problem in Deep Learning, causing a model pre-trained on a source dataset to suffer significant performance degradation on test datasets. This research aims to address the issue of audio classification under domain shift caused by background noise using Test-Time Adaptation (TTA), a technique that adapts a pre-trained model during testing using only unlabelled test data before making predictions. We adopt two common TTA methods, TTT and TENT, and a state-of-the-art method CoNMix, and investigate their respective performance on two popular audio classification datasets, AudioMNIST (AM) and SpeechCommands V1 (SC), against different types of background noise and noise severity levels. The experimental results reveal that our proposed modified version of CoNMix produced the highest classification accuracy under domain shift (5.31% error rate under 10 dB exercise bike background noise and 12.75% error rate under 3 dB running tap background noise for AM) compared to TTT and TENT. The literature search provided no evidence of similar works, thereby motivating the work reported here as the first study to leverage TTA techniques for audio classification under domain shift.
        ]]></description>
    </item>
    <item>
        <title>RingFormer: A Neural Vocoder with Ring Attention and Convolution-Augmented Transformer</title>
        <link>https://arxiv.org/abs/2501.01182</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2501.01182v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Seongho Hong, Yong-Hoon Choi</dc:creator>
        <description><![CDATA[
            背景：Transformer在音频任务表现出色，但应用于神经声码器有挑战，因需生成高时间分辨率的长音频信号，计算成本高，且顺序生成样本难实时处理。方法：提出RingFormer，将环形注意力机制融入卷积增强Transformer，采用双判别器的对抗训练。效果：将其应用于TTS模型VITS解码器，与先进声码器对比，实验表明RingFormer性能相当或更优，尤其在实时音频生成方面表现出色。
            arXiv:2501.01182v2 Announce Type: replace 
Abstract: While transformers demonstrate outstanding performance across various audio tasks, their application to neural vocoders remains challenging. Neural vocoders require the generation of long audio signals at the sample level, which demands high temporal resolution. This results in significant computational costs for attention map generation and limits their ability to efficiently process both global and local information. Additionally, the sequential nature of sample generation in neural vocoders poses difficulties for real-time processing, making the direct adoption of transformers impractical. To address these challenges, we propose RingFormer, a neural vocoder that incorporates the ring attention mechanism into a lightweight transformer variant, the convolution-augmented transformer (Conformer). Ring attention effectively captures local details while integrating global information, making it well-suited for processing long sequences and enabling real-time audio generation. RingFormer is trained using adversarial training with two discriminators. The proposed model is applied to the decoder of the text-to-speech model VITS and compared with state-of-the-art vocoders such as HiFi-GAN, iSTFT-Net, and BigVGAN under identical conditions using various objective and subjective metrics. Experimental results show that RingFormer achieves comparable or superior performance to existing models, particularly excelling in real-time audio generation. Our code and audio samples are available on GitHub.
        ]]></description>
    </item>
    <item>
        <title>The Perception of Phase Intercept Distortion and its Application in Data Augmentation</title>
        <link>https://arxiv.org/abs/2506.14571</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.14571v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Venkatakrishnan Vaidyanathapuram Krishnan, Nathaniel Condit-Schultz</dc:creator>
        <description><![CDATA[
            背景：相位失真会改变信号频率间相位关系，本文聚焦频率无关相移产生的相位截距失真。方法：提出该失真虽大幅改变信号波形但人难以察觉的假设，并通过人体实验验证，还将其用于机器学习中的数据增强。效果：以相位截距失真作为数据增强新方法开展多次实验，在音频机器学习任务上取得了更好的结果。
            arXiv:2506.14571v2 Announce Type: replace-cross 
Abstract: Phase distortion refers to the alteration of the phase relationships between frequencies in a signal, which can be perceptible. In this paper, we discuss a special case of phase distortion known as phase-intercept distortion, which is created by a frequency-independent phase shift. We hypothesize that, though this form of distortion changes a signal's waveform significantly, the distortion is imperceptible. Human-subject experiment results are reported which are consistent with this hypothesis. Furthermore, we discuss how the imperceptibility of phase-intercept distortion can be useful for machine learning, specifically for data augmentation. We conducted multiple experiments using phase-intercept distortion as a novel approach to data augmentation, and obtained improved results for audio machine learning tasks.
        ]]></description>
    </item>
</channel>
</rss>