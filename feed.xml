<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
<channel>
    <title>arXiv Paper Filter</title>
    <link>https://github.com/None/arxiv_filter</link>
    <description>根据研究兴趣筛选的arXiv论文</description>
    <atom:link href="https://raw.githubusercontent.com/None/arxiv_filter/main/feed.xml" rel="self" type="application/rss+xml" />
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>zh-CN</language>
    <lastBuildDate>Fri, 06 Jun 2025 12:22:14 +0800</lastBuildDate>
    <managingEditor>None@github.com</managingEditor>
    <pubDate>Fri, 06 Jun 2025 12:22:14 +0800</pubDate>
    <skipDays>
        <day>Saturday</day>
        <day>Sunday</day>
    </skipDays>

    <item>
        <title>ExDiff: A Framework for Simulating Diffusion Processes on Complex Networks with Explainable AI Integration</title>
        <link>https://arxiv.org/abs/2506.04271</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04271v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Annamaria Defilippo, Ugo Lomoio, Barbara Puccio, Pierangelo Veltri, Pietro Hiram Guzzi</dc:creator>
        <description><![CDATA[
            背景：理解和控制复杂网络中的扩散过程在多个领域至关重要。方法：提出ExDiff框架，它集成网络模拟、图神经网络和可解释人工智能，结合经典隔室模型与深度学习技术，具备网络分析、神经建模等模块，通过谷歌Colab的直观界面访问。效果：以SIRVD模型为例，展示了模拟疾病传播、评估干预策略等能力，通过可解释人工智能技术揭示传染的结构决定因素，为研究网络系统扩散现象提供有力平台。
            arXiv:2506.04271v1 Announce Type: new 
Abstract: Understanding and controlling diffusion processes in complex networks is critical across domains ranging from epidemiology to information science. Here, we present ExDiff, an interactive and modular computational framework that integrates network simulation, graph neural networks (GNNs), and explainable artificial intelligence (XAI) to model and interpret diffusion dynamics. ExDiff combines classical compartmental models with deep learning techniques to capture both the structural and temporal characteristics of diffusion across diverse network topologies. The framework features dedicated modules for network analysis, neural modeling, simulation, and interpretability, all accessible via an intuitive interface built on Google Colab. Through a case study of the Susceptible Infectious Recovered Vaccinated Dead (SIRVD) model, we demonstrate the capacity to simulate disease spread, evaluate intervention strategies, classify node states, and reveal the structural determinants of contagion through XAI techniques. By unifying simulation and interpretability, ExDiff provides a powerful, flexible, and accessible platform for studying diffusion phenomena in networked systems, enabling both methodological innovation and practical insight.
        ]]></description>
    </item>
    <item>
        <title>RSVP: Reasoning Segmentation via Visual Prompting and Multi-modal Chain-of-Thought</title>
        <link>https://arxiv.org/abs/2506.04277</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04277v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yi Lu, Jiawang Cao, Yongliang Wu, Bozheng Li, Licheng Tang, Yangguang Ji, Chong Wu, Jay Wu, Wenbo Zhu</dc:creator>
        <description><![CDATA[
            多模态大语言模型有显著推理能力，但在视觉基础和分割方面缺乏明确机制。为弥补这一差距，本文提出RSVP框架。它是两阶段结构化框架，推理阶段利用多模态思维链视觉提示帮助模型理解查询并推断目标，生成可解释区域建议；分割阶段用视觉语言分割模块优化建议，整合文本和视觉线索生成精确分割掩码。实验表明，RSVP在ReasonSeg上超现有方法最多+6.5 gIoU和+9.2 cIoU，在SegInW零样本设置下达49.7 mAP。
            arXiv:2506.04277v1 Announce Type: new 
Abstract: Multi-modal Large Language Models (MLLMs) have demonstrated remarkable reasoning capability while lack explicit mechanisms for visual grounding and segmentation, creating a gap between cognitive reasoning and visual perception. To bridge this gap, we introduce Reasoning Segmentation via Visual Prompting (RSVP), a novel framework that unifies multi-step multimodal reasoning with grounded visual understanding. RSVP is a two-stage structuralized framework that integrates reasoning-driven localization with segmentation refinement. In the reasoning stage, RSVP employs multimodal chain-of-thought visual prompts to help MLLMs understand queries and infer targets, generating interpretable region proposals that enhance visual grounding. In segmentation stage, RSVP refines these proposals with a Vision-Language Segmentation Module (VLSM), seamlessly integrates textual and visual cues to produce precise segmentation masks. By explicitly modelling the interaction between multimodal reasoning and segmentation, RSVP introduces a new paradigm for interpretable reasoning segmentation. It exploits MLLMs' inherent localization capabilities, enabling the models to not only reason about objects but also generate structured visual representations. Our extensive experiments demonstrate that RSVP achieves state-of-the-art performance, surpasses state-of-the-art methods by up to +6.5 gIoU and +9.2 cIoU on ReasonSeg, and achieves 49.7 mAP on SegInW under zero-shot settings. These results validate RSVP as an effective and scalable framework for integrating cognitive reasoning with structured visual understanding.
        ]]></description>
    </item>
    <item>
        <title>DrSR: LLM based Scientific Equation Discovery with Dual Reasoning from Data and Experience</title>
        <link>https://arxiv.org/abs/2506.04282</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04282v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Runxiang Wang, Boxiao Wang, Kai Li, Yifan Zhang, Jian Cheng</dc:creator>
        <description><![CDATA[
            符号回归是从数据中发现可解释数学表达式的基础工具。现有基于大语言模型（LLM）的方法，如LLM - SR，过度依赖内部先验知识，缺乏对数据的理解和生成方程时的系统反思。为此提出DrSR框架，结合数据驱动洞察与反思学习。它引导LLM分析数据结构关系生成结构化描述，同时监测方程性能并建立反馈循环。实验表明，DrSR显著提高有效方程率，在准确性、泛化性和搜索效率上均优于经典及近期基于LLM的方法。
            arXiv:2506.04282v1 Announce Type: new 
Abstract: Symbolic regression is a fundamental tool for discovering interpretable mathematical expressions from data, with broad applications across scientific and engineering domains. Recently, large language models (LLMs) have demonstrated strong performance in this task, leveraging embedded scientific priors and reasoning capabilities to surpass traditional methods. However, existing LLM-based approaches, such as LLM-SR, often over-rely on internal priors, lacking explicit data understanding and systematic reflection during equation generation. To address these limitations, we propose DrSR (Dual Reasoning Symbolic Regression), a framework that combines data-driven insight with reflective learning to enhance both robustness and discovery capability. Specifically, DrSR guides LLMs to analyze structural relationships (e.g., monotonicity, nonlinearity, and correlation) within the data to generate structured descriptions. Simultaneously, it monitors equation performance and establishes a feedback loop to refine subsequent generations. By integrating data understanding and generation reflection in a closed loop, DrSR enables more efficient exploration of the symbolic expression space. Experiments across interdisciplinary datasets in physics, chemistry, biology, and materials science demonstrate that DrSR substantially improves the valid equation rate and consistently outperforms both classical and recent LLM-based methods in terms of accuracy, generalization, and search efficiency. These results underscore its potential for scientific equation discovery.
        ]]></description>
    </item>
    <item>
        <title>Relational reasoning and inductive bias in transformers trained on a transitive inference task</title>
        <link>https://arxiv.org/abs/2506.04289</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04289v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jesse Geerts, Stephanie Chan, Claudia Clopath, Kimberly Stachenfeld</dc:creator>
        <description><![CDATA[
            背景：基于Transformer的模型虽展现出强大推理能力，但不同学习机制下关系推理的底层机制尚不明晰。方法：研究Transformer在传递性推理任务中的表现，对比权重内学习（IWL）和上下文内学习（ICL）两种学习机制。结果：IWL自然会产生传递性推理的泛化偏差；仅在相邻项目上训练的ICL模型无法进行传递性泛化，其采用的匹配复制策略不能编码间接相关项目的层次关系；在上下文线性回归任务上预训练后，Transformer能成功进行上下文可泛化的传递性推理，且无归纳电路。
            arXiv:2506.04289v1 Announce Type: new 
Abstract: Transformer-based models have demonstrated remarkable reasoning abilities, but the mechanisms underlying relational reasoning in different learning regimes remain poorly understood. In this work, we investigate how transformers perform a classic relational reasoning task from the Psychology literature, \textit{transitive inference}, which requires inference about indirectly related items by integrating information across observed adjacent item pairs (e.g., if A>B and B>C, then A>C). We compare transitive inference behavior across two distinct learning regimes: in-weights learning (IWL), where models store information in network parameters, and in-context learning (ICL), where models flexibly utilize information presented within the input sequence. Our findings reveal that IWL naturally induces a generalization bias towards transitive inference, despite being trained only on adjacent items, whereas ICL models trained solely on adjacent items do not generalize transitively. Mechanistic analysis shows that ICL models develop induction circuits that implement a simple match-and-copy strategy that performs well at relating adjacent pairs, but does not encoding hierarchical relationships among indirectly related items. Interestingly, when pre-trained on in-context linear regression tasks, transformers successfully exhibit in-context generalizable transitive inference. Moreover, like IWL, they display both \textit{symbolic distance} and \textit{terminal item effects} characteristic of human and animal performance, without forming induction circuits. These results suggest that pre-training on tasks with underlying structure promotes the development of representations that can scaffold in-context relational reasoning.
        ]]></description>
    </item>
    <item>
        <title>GEM: Empowering LLM for both Embedding Generation and Language Understanding</title>
        <link>https://arxiv.org/abs/2506.04344</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04344v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Caojin Zhang, Qiang Zhang, Ke Li, Sai Vidyaranya Nuthalapati, Benyu Zhang, Jason Liu, Serena Li, Lizhu Zhang, Xiangjun Fan</dc:creator>
        <description><![CDATA[
            背景：大型解码器语言模型在生成和推理任务中表现出色，但检索增强生成等应用依赖单独嵌入模型，导致系统复杂且存在理解差异。方法：提出生成式嵌入大语言模型（GEM），通过在文本中插入特殊标记、操纵注意力掩码生成文本摘要嵌入，可集成到现有大语言模型的训练或微调阶段。效果：应用于两个流行大语言模型家族，在文本嵌入和NLP基准测试中，显著提升MTEB表现，对MMLU影响极小。
            arXiv:2506.04344v1 Announce Type: new 
Abstract: Large decoder-only language models (LLMs) have achieved remarkable success in generation and reasoning tasks, where they generate text responses given instructions. However, many applications, e.g., retrieval augmented generation (RAG), still rely on separate embedding models to generate text embeddings, which can complicate the system and introduce discrepancies in understanding of the query between the embedding model and LLMs. To address this limitation, we propose a simple self-supervised approach, Generative Embedding large language Model (GEM), that enables any large decoder-only LLM to generate high-quality text embeddings while maintaining its original text generation and reasoning capabilities. Our method inserts new special token(s) into a text body, and generates summarization embedding of the text by manipulating the attention mask. This method could be easily integrated into post-training or fine tuning stages of any existing LLMs. We demonstrate the effectiveness of our approach by applying it to two popular LLM families, ranging from 1B to 8B parameters, and evaluating the transformed models on both text embedding benchmarks (MTEB) and NLP benchmarks (MMLU). The results show that our proposed method significantly improves the original LLMs on MTEB while having a minimal impact on MMLU. Our strong results indicate that our approach can empower LLMs with state-of-the-art text embedding capabilities while maintaining their original NLP performance
        ]]></description>
    </item>
    <item>
        <title>Selective Matching Losses -- Not All Scores Are Created Equal</title>
        <link>https://arxiv.org/abs/2506.04446</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04446v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Gil I. Shamir, Manfred K. Warmuth</dc:creator>
        <description><![CDATA[
            背景：学习系统需将预测分数与观测值匹配，不同区域对预测准确性的要求不同。方法：通过在分数域设计递增的链接函数构建选择性匹配损失函数，利用复合Softmax函数开发多维选择性损失框架。效果：损失不对称性可使模型在高灵敏度区域更好地预测，能区分高低重要性区域。选择性损失在包括大语言模型微调对齐等重要分数区域的应用中，相比传统损失有显著优势。
            arXiv:2506.04446v1 Announce Type: new 
Abstract: Learning systems match predicted scores to observations over some domain. Often, it is critical to produce accurate predictions in some subset (or region) of the domain, yet less important to accurately predict in other regions. We construct selective matching loss functions by design of increasing link functions over score domains. A matching loss is an integral over the link. A link defines loss sensitivity as function of the score, emphasizing high slope high sensitivity regions over flat ones. Loss asymmetry drives a model and resolves its underspecification to predict better in high sensitivity regions where it is more important, and to distinguish between high and low importance regions. A large variety of selective scalar losses can be designed with scaled and shifted Sigmoid and hyperbolic sine links. Their properties, however, do not extend to multi-class. Applying them per dimension lacks ranking sensitivity that assigns importance according to class score ranking. Utilizing composite Softmax functions, we develop a framework for multidimensional selective losses. We overcome limitations of the standard Softmax function, that is good for classification, but not for distinction between adjacent scores. Selective losses have substantial advantage over traditional losses in applications with more important score regions, including dwell-time prediction, retrieval, ranking with either pointwise, contrastive pairwise, or listwise losses, distillation problems, and fine-tuning alignment of Large Language Models (LLMs).
        ]]></description>
    </item>
    <item>
        <title>Zero-Shot Open-Schema Entity Structure Discovery</title>
        <link>https://arxiv.org/abs/2506.04458</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04458v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xueqiang Xu, Jinfeng Xiao, James Barry, Mohab Elkaref, Jiaru Zou, Pengcheng Jiang, Yunyi Zhang, Max Giammona, Geeth de Mel, Jiawei Han</dc:creator>
        <description><![CDATA[
            实体结构提取是文本理解和知识图谱构建的关键任务，现有基于大语言模型的方法依赖预定义模式或标注数据，导致提取结果不完整。为此提出零样本开放模式实体结构发现方法（ZOES），该方法基于实体及其关联结构相互强化的原理，通过富集、细化和统一机制运行，无需任何模式或标注样本。实验表明，ZOES能提升大模型在三个不同领域提取更完整实体结构的能力，证明了方法的有效性和泛化性。
            arXiv:2506.04458v1 Announce Type: new 
Abstract: Entity structure extraction, which aims to extract entities and their associated attribute-value structures from text, is an essential task for text understanding and knowledge graph construction. Existing methods based on large language models (LLMs) typically rely heavily on predefined entity attribute schemas or annotated datasets, often leading to incomplete extraction results. To address these challenges, we introduce Zero-Shot Open-schema Entity Structure Discovery (ZOES), a novel approach to entity structure extraction that does not require any schema or annotated samples. ZOES operates via a principled mechanism of enrichment, refinement, and unification, based on the insight that an entity and its associated structure are mutually reinforcing. Experiments demonstrate that ZOES consistently enhances LLMs' ability to extract more complete entity structures across three different domains, showcasing both the effectiveness and generalizability of the method. These findings suggest that such an enrichment, refinement, and unification mechanism may serve as a principled approach to improving the quality of LLM-based entity structure discovery in various scenarios.
        ]]></description>
    </item>
    <item>
        <title>SQLens: An End-to-End Framework for Error Detection and Correction in Text-to-SQL</title>
        <link>https://arxiv.org/abs/2506.04494</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04494v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yue Gong, Chuan Lei, Xiao Qin, Kapil Vaidya, Balakrishnan Narayanaswamy, Tim Kraska</dc:creator>
        <description><![CDATA[
            背景：文本到SQL系统可让非技术用户与结构化数据交互，但大语言模型在该任务中常产生语义错误的查询且可靠性有限。方法：提出SQLens端到端框架，整合来自底层数据库和大语言模型的错误信号，识别SQL子句中的潜在语义错误并指导查询修正。效果：在两个公开基准测试中，SQLens在错误检测的F1值上比最佳的基于大语言模型的自我评估方法高25.78%，并将现成的文本到SQL系统的执行准确率最多提高20%。
            arXiv:2506.04494v1 Announce Type: new 
Abstract: Text-to-SQL systems translate natural language (NL) questions into SQL queries, enabling non-technical users to interact with structured data. While large language models (LLMs) have shown promising results on the text-to-SQL task, they often produce semantically incorrect yet syntactically valid queries, with limited insight into their reliability. We propose SQLens, an end-to-end framework for fine-grained detection and correction of semantic errors in LLM-generated SQL. SQLens integrates error signals from both the underlying database and the LLM to identify potential semantic errors within SQL clauses. It further leverages these signals to guide query correction. Empirical results on two public benchmarks show that SQLens outperforms the best LLM-based self-evaluation method by 25.78% in F1 for error detection, and improves execution accuracy of out-of-the-box text-to-SQL systems by up to 20%.
        ]]></description>
    </item>
    <item>
        <title>Neural MJD: Neural Non-Stationary Merton Jump Diffusion for Time Series Prediction</title>
        <link>https://arxiv.org/abs/2506.04542</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04542v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuanpei Gao, Qi Yan, Yan Leng, Renjie Liao</dc:creator>
        <description><![CDATA[
            背景：深度学习方法在时间序列预测中虽表现出色，但黑箱性质及无法显式建模潜在随机过程，限制了其对非平稳数据的泛化能力。方法：引入基于神经网络的非平稳Merton跳跃扩散（Neural MJD）模型，将预测明确为随机微分方程模拟问题，结合时变伊藤扩散与复合泊松过程；引入似然截断机制，提出带重启的欧拉 - 马尔可夫求解器。效果：实验表明Neural MJD在合成和真实数据集上均优于现有深度学习和统计学习方法。
            arXiv:2506.04542v1 Announce Type: new 
Abstract: While deep learning methods have achieved strong performance in time series prediction, their black-box nature and inability to explicitly model underlying stochastic processes often limit their generalization to non-stationary data, especially in the presence of abrupt changes. In this work, we introduce Neural MJD, a neural network based non-stationary Merton jump diffusion (MJD) model. Our model explicitly formulates forecasting as a stochastic differential equation (SDE) simulation problem, combining a time-inhomogeneous It\^o diffusion to capture non-stationary stochastic dynamics with a time-inhomogeneous compound Poisson process to model abrupt jumps. To enable tractable learning, we introduce a likelihood truncation mechanism that caps the number of jumps within small time intervals and provide a theoretical error bound for this approximation. Additionally, we propose an Euler-Maruyama with restart solver, which achieves a provably lower error bound in estimating expected states and reduced variance compared to the standard solver. Experiments on both synthetic and real-world datasets demonstrate that Neural MJD consistently outperforms state-of-the-art deep learning and statistical learning methods.
        ]]></description>
    </item>
    <item>
        <title>MuSciClaims: Multimodal Scientific Claim Verification</title>
        <link>https://arxiv.org/abs/2506.04585</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04585v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yash Kumar Lal, Manikanta Bandham, Mohammad Saqib Hasan, Apoorva Kashi, Mahnaz Koupaee, Niranjan Balasubramanian</dc:creator>
        <description><![CDATA[
            背景：评估科学主张需处理多模态数据，但缺乏直接测试主张验证能力的多模态基准。方法：引入新基准MuSciClaims及诊断任务，自动提取科学文章中支持的主张并手动扰动产生矛盾主张，设计扰动以测试特定验证能力，还引入诊断任务助于理解模型失败原因。效果：多数视觉语言模型表现较差（F1值约0.3 - 0.5），最佳模型F1值仅0.77，且模型有判断偏差，在定位证据、跨模态聚合信息等方面存在问题。
            arXiv:2506.04585v1 Announce Type: new 
Abstract: Assessing scientific claims requires identifying, extracting, and reasoning with multimodal data expressed in information-rich figures in scientific literature. Despite the large body of work in scientific QA, figure captioning, and other multimodal reasoning tasks over chart-based data, there are no readily usable multimodal benchmarks that directly test claim verification abilities. To remedy this gap, we introduce a new benchmark MuSciClaims accompanied by diagnostics tasks. We automatically extract supported claims from scientific articles, which we manually perturb to produce contradicted claims. The perturbations are designed to test for a specific set of claim verification capabilities. We also introduce a suite of diagnostic tasks that help understand model failures. Our results show most vision-language models are poor (~0.3-0.5 F1), with even the best model only achieving 0.77 F1. They are also biased towards judging claims as supported, likely misunderstanding nuanced perturbations within the claims. Our diagnostics show models are bad at localizing correct evidence within figures, struggle with aggregating information across modalities, and often fail to understand basic components of the figure.
        ]]></description>
    </item>
    <item>
        <title>Safe: Enhancing Mathematical Reasoning in Large Language Models via Retrospective Step-aware Formal Verification</title>
        <link>https://arxiv.org/abs/2506.04592</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04592v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chengwu Liu, Ye Yuan, Yichun Yin, Yan Xu, Xin Xu, Zaoyu Chen, Yasheng Wang, Lifeng Shang, Qun Liu, Ming Zhang</dc:creator>
        <description><![CDATA[
            背景：思维链提示虽能激发大语言模型推理能力，但难以检测其中的幻觉问题，现有方法效果可能受限。方法：提出回顾性、步骤感知的形式验证框架Safe，在每个推理步骤用形式化数学语言Lean 4阐述数学主张并提供形式化证明以识别幻觉。效果：在多模型和多数学数据集上评估，显著提升性能，还提供可解释和可验证的证据。此外提出含30809个形式化陈述的FormalStep作为步骤正确性定理证明的基准。
            arXiv:2506.04592v1 Announce Type: new 
Abstract: Chain-of-Thought (CoT) prompting has become the de facto method to elicit reasoning capabilities from large language models (LLMs). However, to mitigate hallucinations in CoT that are notoriously difficult to detect, current methods such as process reward models (PRMs) or self-consistency operate as opaque boxes and do not provide checkable evidence for their judgments, possibly limiting their effectiveness. To address this issue, we draw inspiration from the idea that "the gold standard for supporting a mathematical claim is to provide a proof". We propose a retrospective, step-aware formal verification framework $Safe$. Rather than assigning arbitrary scores, we strive to articulate mathematical claims in formal mathematical language Lean 4 at each reasoning step and provide formal proofs to identify hallucinations. We evaluate our framework $Safe$ across multiple language models and various mathematical datasets, demonstrating a significant performance improvement while offering interpretable and verifiable evidence. We also propose $FormalStep$ as a benchmark for step correctness theorem proving with $30,809$ formal statements. To the best of our knowledge, our work represents the first endeavor to utilize formal mathematical language Lean 4 for verifying natural language content generated by LLMs, aligning with the reason why formal mathematical languages were created in the first place: to provide a robust foundation for hallucination-prone human-written proofs.
        ]]></description>
    </item>
    <item>
        <title>Advancing Tool-Augmented Large Language Models via Meta-Verification and Reflection Learning</title>
        <link>https://arxiv.org/abs/2506.04625</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04625v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhiyuan Ma, Jiayu Liu, Xianzhen Luo, Zhenya Huang, Qingfu Zhu, Wanxiang Che</dc:creator>
        <description><![CDATA[
            背景：赋能大语言模型有效利用工具的能力对解决复杂问题至关重要，但现有模型存在工具规划调用不可靠、工具反思能力弱等局限。方法：提出Tool - MVR，引入多智能体元验证构建高质量指令数据集ToolBench - V，提出基于探索的反思学习构建反思数据集ToolBench - R，在二者上微调开源大语言模型。效果：在StableToolBench上超越ToolLLM 23.9%、GPT - 4 15.3%，减少31.4% API调用；在RefineToolBench上纠错率达58.9%，远超ToolLLM的9.1%。
            arXiv:2506.04625v1 Announce Type: new 
Abstract: Empowering large language models (LLMs) with effective tool utilization capabilities is crucial for enabling AI agents to solve complex problems. However, current models face two major limitations: (1) unreliable tool planning and invocation due to low-quality instruction datasets (e.g., widespread hallucinated API calls), and (2) weak tool reflection abilities (over 90% of errors cannot be corrected) resulting from static imitation learning. To address these critical limitations, we propose Tool-MVR, a novel Tool-Augmented LLM that achieves comprehensive System 2 reasoning through two key innovations. Specifically, we first introduce Multi-Agent Meta-Verification (MAMV), a systematic pipeline that rigorously validates APIs, queries, and reasoning trajectories to construct ToolBench-V, a new high-quality instruction dataset that addresses the limitation of unreliable tool planning and invocation. Second, we propose Exploration-based Reflection Learning (EXPLORE), which enhances tool reflection capabilities by leveraging tool feedback through a dynamic "Error -> Reflection -> Correction" learning paradigm, resulting in our reflection dataset ToolBench-R and addressing the critical weakness in tool reflection. Finally, we obtain Tool-MVR by finetuning open-source LLMs (e.g., Qwen-7B) on both ToolBench-V and ToolBench-R. Our experiments demonstrate that Tool-MVR achieves state-of-the-art performance on StableToolBench, surpassing both ToolLLM (by 23.9%) and GPT-4 (by 15.3%) while reducing API calls by 31.4%, with strong generalization capabilities across unseen tools and scenarios. Additionally, on our proposed RefineToolBench, the first benchmark specifically designed to evaluate tool reflection capabilities, Tool-MVR achieves a 58.9% error correction rate, significantly outperforming ToolLLM's 9.1%.
        ]]></description>
    </item>
    <item>
        <title>Composing Agents to Minimize Worst-case Risk</title>
        <link>https://arxiv.org/abs/2506.04632</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04632v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Guruprerana Shabadi, Rajeev Alur</dc:creator>
        <description><![CDATA[
            背景：现代智能体系统将复杂目标分解为子任务，需选择智能体组合，既要提高任务成功率又要降低风险，还需分析低概率行为。方法：将智能体工作流形式化为有向无环图（智能体图），定义最坏情况风险为损失分布的尾部分位数，引入通过联合界和动态规划近似风险值、遍历智能体图寻找近最优智能体组合的算法。效果：证明该近似对广泛的损失函数渐近近最优，在视频游戏类控制基准测试中证明算法有效。
            arXiv:2506.04632v1 Announce Type: new 
Abstract: From software development to robot control, modern agentic systems decompose complex objectives into a sequence of subtasks and choose a set of specialized AI agents to complete them. We formalize an agentic workflow as a directed acyclic graph, called an agent graph, where edges represent AI agents and paths correspond to feasible compositions of agents. When deploying these systems in the real world, we need to choose compositions of agents that not only maximize the task success, but also minimize risk where the risk captures requirements like safety, fairness, and privacy. This additionally requires carefully analyzing the low-probability (tail) behaviors of compositions of agents. In this work, we consider worst-case risk minimization over the set of feasible agent compositions. We define worst-case risk as the tail quantile -- also known as value-at-risk -- of the loss distribution of the agent composition where the loss quantifies the risk associated with agent behaviors. We introduce an efficient algorithm that traverses the agent graph and finds a near-optimal composition of agents by approximating the value-at-risk via a union bound and dynamic programming. Furthermore, we prove that the approximation is near-optimal asymptotically for a broad class of practical loss functions. To evaluate our framework, we consider a suite of video game-like control benchmarks that require composing several agents trained with reinforcement learning and demonstrate our algorithm's effectiveness in approximating the value-at-risk and identifying the optimal agent composition.
        ]]></description>
    </item>
    <item>
        <title>Truth in the Few: High-Value Data Selection for Efficient Multi-Modal Reasoning</title>
        <link>https://arxiv.org/abs/2506.04755</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04755v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Shenshen Li, Kaiyuan Deng, Lei Wang, Hao Yang, Chong Peng, Peng Yan, Fumin Shen, Heng Tao Shen, Xing Xu</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型虽在复杂推理任务取得进展，但提升推理能力需大量训练数据，导致数据冗余和高计算成本。方法：提出推理激活潜力（RAP）数据选择范式，通过因果差异估计器（CDE）和注意力置信度估计器（ACE）识别认知样本，还引入难度感知替换模块（DRM）。效果：在六个数据集实验表明，RAP方法仅用9.3%训练数据就能取得更好性能，计算成本降低超43%。
            arXiv:2506.04755v1 Announce Type: new 
Abstract: While multi-modal large language models (MLLMs) have made significant progress in complex reasoning tasks via reinforcement learning, it is commonly believed that extensive training data is necessary for improving multi-modal reasoning ability, inevitably leading to data redundancy and substantial computational costs. However, can smaller high-value datasets match or outperform full corpora for multi-modal reasoning in MLLMs? In this work, we challenge this assumption through a key observation: meaningful multi-modal reasoning is triggered by only a sparse subset of training samples, termed cognitive samples, whereas the majority contribute marginally. Building on this insight, we propose a novel data selection paradigm termed Reasoning Activation Potential (RAP), which identifies cognitive samples by estimating each sample's potential to stimulate genuine multi-modal reasoning by two complementary estimators: 1) Causal Discrepancy Estimator (CDE) based on the potential outcome model principle, eliminates samples that overly rely on language priors by comparing outputs between multi-modal and text-only inputs; 2) Attention Confidence Estimator (ACE), which exploits token-level self-attention to discard samples dominated by irrelevant but over-emphasized tokens in intermediate reasoning stages. Moreover, we introduce a Difficulty-aware Replacement Module (DRM) to substitute trivial instances with cognitively challenging ones, thereby ensuring complexity for robust multi-modal reasoning. Experiments on six datasets show that our RAP method consistently achieves superior performance using only 9.3% of the training data, while reducing computational costs by over 43%. Our code is available at https://github.com/Leo-ssl/RAP.
        ]]></description>
    </item>
    <item>
        <title>Log-Linear Attention</title>
        <link>https://arxiv.org/abs/2506.04761</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04761v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Han Guo, Songlin Yang, Tarushii Goel, Eric P. Xing, Tri Dao, Yoon Kim</dc:creator>
        <description><![CDATA[
            背景：Transformer中的注意力机制是序列建模的重要方法，但存在计算和内存复杂度高的瓶颈，线性注意力和状态空间模型虽有优势但有固定大小隐藏状态的局限性。方法：提出对数线性注意力机制，用对数增长的隐藏状态集替代固定大小隐藏状态。效果：在特定增长函数下，有类似的矩阵乘法并行形式，计算成本与序列长度呈对数线性关系，实例化的两个架构变体表现优于线性时间变体。
            arXiv:2506.04761v1 Announce Type: new 
Abstract: The attention mechanism in Transformers is an important primitive for accurate and scalable sequence modeling. Its quadratic-compute and linear-memory complexity however remain significant bottlenecks. Linear attention and state-space models enable linear-time, constant-memory sequence modeling and can moreover be trained efficiently through matmul-rich parallelization across sequence length. However, at their core these models are still RNNs, and thus their use of a fixed-size hidden state to model the context is a fundamental limitation. This paper develops log-linear attention, an attention mechanism that balances linear attention's efficiency and the expressiveness of softmax attention. Log-linear attention replaces the fixed-size hidden state with a logarithmically growing set of hidden states. We show that with a particular growth function, log-linear attention admits a similarly matmul-rich parallel form whose compute cost is log-linear in sequence length. Log-linear attention is a general framework and can be applied on top of existing linear attention variants. As case studies, we instantiate log-linear variants of two recent architectures -- Mamba-2 and Gated DeltaNet -- and find they perform well compared to their linear-time variants.
        ]]></description>
    </item>
    <item>
        <title>MMSU: A Massive Multi-task Spoken Language Understanding and Reasoning Benchmark</title>
        <link>https://arxiv.org/abs/2506.04779</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04779v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Dingdong Wang, Jincenzi Wu, Junan Li, Dongchao Yang, Xueyuan Chen, Tianhua Zhang, Helen Meng</dc:creator>
        <description><![CDATA[
            背景：语音包含丰富信息，现有多模态语音大语言模型在自然语音的细粒度感知和复杂推理能力方面有待探索。方法：推出综合基准MMSU，包含5000个精心策划的音频-问题-答案三元组，涵盖47个不同任务，还系统纳入多种语言现象。效果：通过对14个先进语音大语言模型的严格评估，发现现有模型有很大改进空间，为开发更复杂的人机语音交互系统提供了有价值的见解。
            arXiv:2506.04779v1 Announce Type: new 
Abstract: Speech inherently contains rich acoustic information that extends far beyond the textual language. In real-world spoken language understanding, effective interpretation often requires integrating semantic meaning (e.g., content), paralinguistic features (e.g., emotions, speed, pitch) and phonological characteristics (e.g., prosody, intonation, rhythm), which are embedded in speech. While recent multimodal Speech Large Language Models (SpeechLLMs) have demonstrated remarkable capabilities in processing audio information, their ability to perform fine-grained perception and complex reasoning in natural speech remains largely unexplored. To address this gap, we introduce MMSU, a comprehensive benchmark designed specifically for understanding and reasoning in spoken language. MMSU comprises 5,000 meticulously curated audio-question-answer triplets across 47 distinct tasks. To ground our benchmark in linguistic theory, we systematically incorporate a wide range of linguistic phenomena, including phonetics, prosody, rhetoric, syntactics, semantics, and paralinguistics. Through a rigorous evaluation of 14 advanced SpeechLLMs, we identify substantial room for improvement in existing models, highlighting meaningful directions for future optimization. MMSU establishes a new standard for comprehensive assessment of spoken language understanding, providing valuable insights for developing more sophisticated human-AI speech interaction systems. MMSU benchmark is available at https://huggingface.co/datasets/ddwang2000/MMSU. Evaluation Code is available at https://github.com/dingdongwang/MMSU_Bench.
        ]]></description>
    </item>
    <item>
        <title>Towards LLM-Centric Multimodal Fusion: A Survey on Integration Strategies and Techniques</title>
        <link>https://arxiv.org/abs/2506.04788</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04788v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jisu An, Junseok Lee, Jeoungeun Lee, Yongseok Son</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型（MLLMs）发展迅速，但不同模态与语言主干的连接需系统理解。方法：进行以大语言模型为中心的分析，提出基于三个关键维度的MLLM分类框架，包括模态集成的架构策略、表征学习技术分类、训练范式分析，还考察125个2021 - 2025年开发的MLLMs。效果：该分类框架为研究人员提供当前集成技术的结构化概述，有助于指导未来基于预训练基础的模型开发更稳健的多模态集成策略。
            arXiv:2506.04788v1 Announce Type: new 
Abstract: The rapid progress of Multimodal Large Language Models(MLLMs) has transformed the AI landscape. These models combine pre-trained LLMs with various modality encoders. This integration requires a systematic understanding of how different modalities connect to the language backbone. Our survey presents an LLM-centric analysis of current approaches. We examine methods for transforming and aligning diverse modal inputs into the language embedding space. This addresses a significant gap in existing literature. We propose a classification framework for MLLMs based on three key dimensions. First, we examine architectural strategies for modality integration. This includes both the specific integration mechanisms and the fusion level. Second, we categorize representation learning techniques as either joint or coordinate representations. Third, we analyze training paradigms, including training strategies and objective functions. By examining 125 MLLMs developed between 2021 and 2025, we identify emerging patterns in the field. Our taxonomy provides researchers with a structured overview of current integration techniques. These insights aim to guide the development of more robust multimodal integration strategies for future models built on pre-trained foundations.
        ]]></description>
    </item>
    <item>
        <title>Dissecting Logical Reasoning in LLMs: A Fine-Grained Evaluation and Supervision Study</title>
        <link>https://arxiv.org/abs/2506.04810</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04810v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yujun Zhou, Jiayi Ye, Zipeng Ling, Yufei Han, Yue Huang, Haomin Zhuang, Zhenwen Liang, Kehan Guo, Taicheng Guo, Xiangqi Wang, Xiangliang Zhang</dc:creator>
        <description><![CDATA[
            背景：逻辑推理是大语言模型应用的核心能力，但现有基准测试仅关注最终答案准确性，未考量推理过程。方法：提出FineLogic细粒度评估框架，从三个维度评估逻辑推理；构建四种监督风格训练大模型，研究微调时监督格式的影响。效果：自然语言监督在分布外和长上下文任务上泛化能力强，符号推理风格能促进更具结构合理性的推理链；微调主要通过逐步生成改善推理行为。该框架和分析为评估与提升大模型逻辑推理能力提供了严谨且可解释的视角。
            arXiv:2506.04810v1 Announce Type: new 
Abstract: Logical reasoning is a core capability for many applications of large language models (LLMs), yet existing benchmarks often rely solely on final-answer accuracy, failing to capture the quality and structure of the reasoning process. We propose FineLogic, a fine-grained evaluation framework that assesses logical reasoning across three dimensions: overall benchmark accuracy, stepwise soundness, and representation-level alignment. In addition, to better understand how reasoning capabilities emerge, we conduct a comprehensive study on the effects of supervision format during fine-tuning. We construct four supervision styles (one natural language and three symbolic variants) and train LLMs under each. Our findings reveal that natural language supervision yields strong generalization even on out-of-distribution and long-context tasks, while symbolic reasoning styles promote more structurally sound and atomic inference chains. Further, our representation-level probing shows that fine-tuning primarily improves reasoning behaviors through step-by-step generation, rather than enhancing shortcut prediction or internalized correctness. Together, our framework and analysis provide a more rigorous and interpretable lens for evaluating and improving logical reasoning in LLMs.
        ]]></description>
    </item>
    <item>
        <title>LogicPuzzleRL: Cultivating Robust Mathematical Reasoning in LLMs via Reinforcement Learning</title>
        <link>https://arxiv.org/abs/2506.04821</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04821v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhen Hao Wong, Jingwen Deng, Runming He, Zirong Chen, Qijie You, Hejun Dong, Hao Liang, Chengyu Shen, Bin Cui, Wentao Zhang</dc:creator>
        <description><![CDATA[
            背景：大语言模型在监督任务表现出色，但在陌生场景的结构化推理常遇困难，标准微调可能仅灌输特定领域启发式方法。方法：提出“玩中学”框架，通过强化学习在七个自定义逻辑谜题上微调大语言模型，以培养不同推理技能，用可验证奖励给予二元反馈，鼓励迭代式、假设驱动的问题解决。效果：显著提升模型在数学基准测试中的分布外性能，尤其对需多步推理的中等难度问题，促进可迁移推理能力，加强多种推理逻辑，但对机械或高度专业化任务提升有限。
            arXiv:2506.04821v1 Announce Type: new 
Abstract: Large language models (LLMs) excel at many supervised tasks but often struggle with structured reasoning in unfamiliar settings. This discrepancy suggests that standard fine-tuning pipelines may instill narrow, domain-specific heuristics rather than fostering general-purpose thinking strategies. In this work, we propose a "play to learn" framework that fine-tunes LLMs through reinforcement learning on a suite of seven custom logic puzzles, each designed to cultivate distinct reasoning skills such as constraint propagation, spatial consistency, and symbolic deduction. Using a reinforcement learning setup with verifiable rewards, models receive binary feedback based on puzzle correctness, encouraging iterative, hypothesis-driven problem solving. We demonstrate that this training approach significantly improves out-of-distribution performance on a range of mathematical benchmarks, especially for mid-difficulty problems that require multi-step reasoning. Analyses across problem categories and difficulty levels reveal that puzzle training promotes transferable reasoning routines, strengthening algebraic manipulation, geometric inference, and combinatorial logic, while offering limited gains on rote or highly specialized tasks. These findings show that reinforcement learning over logic puzzles reshapes the internal reasoning of LLMs, enabling more robust and compositional generalization without relying on task-specific symbolic tools.
        ]]></description>
    </item>
    <item>
        <title>From EHRs to Patient Pathways: Scalable Modeling of Longitudinal Health Trajectories with LLMs</title>
        <link>https://arxiv.org/abs/2506.04831</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04831v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chantal Pellegrini, Ege \"Ozsoy, David Bani-Harouni, Matthias Keicher, Nassir Navab</dc:creator>
        <description><![CDATA[
            背景：医疗系统在处理和解读大量异质患者数据以实现个性化医疗时面临挑战，现有方法存在局限性。方法：提出将不同电子健康记录（EHR）数据转化为结构化表示的患者路径建模新方法，设计了整体路径预测模型EHR2Path，还引入新的摘要机制嵌入长期时间上下文。效果：EHR2Path在下一步预测和纵向模拟中表现出色，优于竞争基线，能对患者轨迹进行详细模拟，可用于多种评估任务。
            arXiv:2506.04831v1 Announce Type: new 
Abstract: Healthcare systems face significant challenges in managing and interpreting vast, heterogeneous patient data for personalized care. Existing approaches often focus on narrow use cases with a limited feature space, overlooking the complex, longitudinal interactions needed for a holistic understanding of patient health. In this work, we propose a novel approach to patient pathway modeling by transforming diverse electronic health record (EHR) data into a structured representation and designing a holistic pathway prediction model, EHR2Path, optimized to predict future health trajectories. Further, we introduce a novel summary mechanism that embeds long-term temporal context into topic-specific summary tokens, improving performance over text-only models, while being much more token-efficient. EHR2Path demonstrates strong performance in both next time-step prediction and longitudinal simulation, outperforming competitive baselines. It enables detailed simulations of patient trajectories, inherently targeting diverse evaluation tasks, such as forecasting vital signs, lab test results, or length-of-stay, opening a path towards predictive and personalized healthcare.
        ]]></description>
    </item>
    <item>
        <title>Sparse Autoencoders, Again?</title>
        <link>https://arxiv.org/abs/2506.04859</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04859v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yin Lu, Tong He, Xuening Zhu, David Wipf</dc:creator>
        <description><![CDATA[
            背景：稀疏自编码器（SAEs）虽有广泛适用性，但多年来变化较少。传统SAEs和变分自编码器（VAE）存在不足。方法：提出一种混合替代模型，规避了之前模型的局限性，并从理论上证明该模型全局最小值能恢复跨流形结构数据。效果：在合成和真实数据集上的实证评估表明，该方法能准确估计潜在流形维度、产生更稀疏的潜在表示且不增加重构误差，能超越同等容量的SAEs、VAEs及部分扩散模型。
            arXiv:2506.04859v1 Announce Type: new 
Abstract: Is there really much more to say about sparse autoencoders (SAEs)? Autoencoders in general, and SAEs in particular, represent deep architectures that are capable of modeling low-dimensional latent structure in data. Such structure could reflect, among other things, correlation patterns in large language model activations, or complex natural image manifolds. And yet despite the wide-ranging applicability, there have been relatively few changes to SAEs beyond the original recipe from decades ago, namely, standard deep encoder/decoder layers trained with a classical/deterministic sparse regularizer applied within the latent space. One possible exception is the variational autoencoder (VAE), which adopts a stochastic encoder module capable of producing sparse representations when applied to manifold data. In this work we formalize underappreciated weaknesses with both canonical SAEs, as well as analogous VAEs applied to similar tasks, and propose a hybrid alternative model that circumvents these prior limitations. In terms of theoretical support, we prove that global minima of our proposed model recover certain forms of structured data spread across a union of manifolds. Meanwhile, empirical evaluations on synthetic and real-world datasets substantiate the efficacy of our approach in accurately estimating underlying manifold dimensions and producing sparser latent representations without compromising reconstruction error. In general, we are able to exceed the performance of equivalent-capacity SAEs and VAEs, as well as recent diffusion models where applicable, within domains such as images and language model activation patterns.
        ]]></description>
    </item>
    <item>
        <title>Verbose ListOps (VLO): Beyond Long Context -- Unmasking LLM's Reasoning Blind Spots</title>
        <link>https://arxiv.org/abs/2506.04907</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04907v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Alex Pan, Mary-Anne Williams</dc:creator>
        <description><![CDATA[
            背景：大语言模型在从文本中提取事实方面表现出色，但在嵌套叙事推理上存在困难，现有基准测试无法有效检验该能力。方法：提出Verbose ListOps基准，将ListOps计算转化为冗长连贯故事，强制模型进行内部计算和状态管理，且能分别控制叙事大小和推理难度。效果：实验表明，领先的大语言模型在该基准上，叙事长度适中（约10k标记）时性能下降，此基准有助于针对性提升推理能力。
            arXiv:2506.04907v1 Announce Type: new 
Abstract: Large Language Models (LLMs), whilst great at extracting facts from text, struggle with nested narrative reasoning. Existing long context and multi-hop QA benchmarks inadequately test this, lacking realistic distractors or failing to decouple context length from reasoning complexity, masking a fundamental LLM limitation. We introduce Verbose ListOps, a novel benchmark that programmatically transposes ListOps computations into lengthy, coherent stories. This uniquely forces internal computation and state management of nested reasoning problems by withholding intermediate results, and offers fine-grained controls for both narrative size \emph{and} reasoning difficulty. Whilst benchmarks like LongReason (2025) advance approaches for synthetically expanding the context size of multi-hop QA problems, Verbose ListOps pinpoints a specific LLM vulnerability: difficulty in state management for nested sub-reasoning amongst semantically-relevant, distracting narrative. Our experiments show that leading LLMs (e.g., OpenAI o4, Gemini 2.5 Pro) collapse in performance on Verbose ListOps at modest (~10k token) narrative lengths, despite effortlessly solving raw ListOps equations. Addressing this failure is paramount for real-world text interpretation which requires identifying key reasoning points, tracking conceptual intermediate results, and filtering irrelevant information. Verbose ListOps, and its extensible generation framework thus enables targeted reasoning enhancements beyond mere context-window expansion; a critical step to automating the world's knowledge work.
        ]]></description>
    </item>
    <item>
        <title>Agentic AI for Intent-Based Industrial Automation</title>
        <link>https://arxiv.org/abs/2506.04980</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04980v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Marcos Lima Romero, Ricardo Suyama</dc:creator>
        <description><![CDATA[
            背景：自主大语言模型赋能的智能体AI系统为工业自动化发展带来新可能。方法：提出将智能体AI与基于意图的范式相结合的概念框架，基于意图处理，让人类操作员用自然语言表达目标并分解为可执行组件，指导子智能体执行特定任务。效果：用CMAPSS数据集和谷歌智能体开发套件验证，证明在预测性维护场景中意图分解、智能体编排和自主决策的可行性，虽有数据质量等问题，但有降低技术壁垒、实现可扩展自动化的潜力。
            arXiv:2506.04980v1 Announce Type: new 
Abstract: The recent development of Agentic AI systems, empowered by autonomous large language models (LLMs) agents with planning and tool-usage capabilities, enables new possibilities for the evolution of industrial automation and reduces the complexity introduced by Industry 4.0. This work proposes a conceptual framework that integrates Agentic AI with the intent-based paradigm, originally developed in network research, to simplify human-machine interaction (HMI) and better align automation systems with the human-centric, sustainable, and resilient principles of Industry 5.0. Based on the intent-based processing, the framework allows human operators to express high-level business or operational goals in natural language, which are decomposed into actionable components. These intents are broken into expectations, conditions, targets, context, and information that guide sub-agents equipped with specialized tools to execute domain-specific tasks. A proof of concept was implemented using the CMAPSS dataset and Google Agent Developer Kit (ADK), demonstrating the feasibility of intent decomposition, agent orchestration, and autonomous decision-making in predictive maintenance scenarios. The results confirm the potential of this approach to reduce technical barriers and enable scalable, intent-driven automation, despite data quality and explainability concerns.
        ]]></description>
    </item>
    <item>
        <title>TextVidBench: A Benchmark for Long Video Scene Text Understanding</title>
        <link>https://arxiv.org/abs/2506.04983</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04983v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yangyang Zhong, Ji Qi, Yuan Yao, Pengxin Luo, Yunfeng Yan, Donglian Qi, Zhiyuan Liu, Tat-Seng Chua</dc:creator>
        <description><![CDATA[
            背景：现有短视频文本视觉问答数据集视频时长有限、评估范围窄，难以评估多模态大语言模型能力。方法：提出首个长视频文本问答基准TextVidBench，有跨领域长视频覆盖、三阶段评估框架和高质量细粒度标注；还提出通过引入IT - Rope机制和时间提示工程、采用非均匀位置编码、对视频文本数据进行轻量级微调来改进大模型的范式。效果：实验表明该基准对现有模型构成挑战，方法有助于提升长视频场景文本理解能力。
            arXiv:2506.04983v1 Announce Type: new 
Abstract: Despite recent progress on the short-video Text-Visual Question Answering (ViteVQA) task - largely driven by benchmarks such as M4-ViteVQA - existing datasets still suffer from limited video duration and narrow evaluation scopes, making it difficult to adequately assess the growing capabilities of powerful multimodal large language models (MLLMs). To address these limitations, we introduce TextVidBench, the first benchmark specifically designed for long-video text question answering (>3 minutes). TextVidBench makes three key contributions: 1) Cross-domain long-video coverage: Spanning 9 categories (e.g., news, sports, gaming), with an average video length of 2306 seconds, enabling more realistic evaluation of long-video understanding. 2) A three-stage evaluation framework: "Text Needle-in-Haystack -> Temporal Grounding -> Text Dynamics Captioning". 3) High-quality fine-grained annotations: Containing over 5,000 question-answer pairs with detailed semantic labeling. Furthermore, we propose an efficient paradigm for improving large models through: (i) introducing the IT-Rope mechanism and temporal prompt engineering to enhance temporal perception, (ii) adopting non-uniform positional encoding to better handle long video sequences, and (iii) applying lightweight fine-tuning on video-text data. Extensive experiments on multiple public datasets as well as TextVidBench demonstrate that our new benchmark presents significant challenges to existing models, while our proposed method offers valuable insights into improving long-video scene text understanding capabilities.
        ]]></description>
    </item>
    <item>
        <title>SCOP: Evaluating the Comprehension Process of Large Language Models from a Cognitive View</title>
        <link>https://arxiv.org/abs/2506.05000</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.05000v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yongjie Xiao, Hongru Liang, Peixin Qin, Yao Zhang, Wenqiang Lei</dc:creator>
        <description><![CDATA[
            背景：大语言模型虽在机器理解方面潜力巨大，但在现实场景中完全依赖它们仍有问题，且其理解过程是否与专家一致尚无合理解释。方法：提出SCOP，从认知视角审视大语言模型在理解过程中的表现，包括对理解过程五项必要技能的系统定义、构建测试数据的严格框架及用测试数据对开源和闭源大语言模型的详细分析。效果：发现大语言模型达到专家级理解过程仍有挑战，虽与专家有相似处，但可能通过有缺陷的理解过程得出正确答案，建议训练时更关注理解过程。
            arXiv:2506.05000v1 Announce Type: new 
Abstract: Despite the great potential of large language models(LLMs) in machine comprehension, it is still disturbing to fully count on them in real-world scenarios. This is probably because there is no rational explanation for whether the comprehension process of LLMs is aligned with that of experts. In this paper, we propose SCOP to carefully examine how LLMs perform during the comprehension process from a cognitive view. Specifically, it is equipped with a systematical definition of five requisite skills during the comprehension process, a strict framework to construct testing data for these skills, and a detailed analysis of advanced open-sourced and closed-sourced LLMs using the testing data. With SCOP, we find that it is still challenging for LLMs to perform an expert-level comprehension process. Even so, we notice that LLMs share some similarities with experts, e.g., performing better at comprehending local information than global information. Further analysis reveals that LLMs can be somewhat unreliable -- they might reach correct answers through flawed comprehension processes. Based on SCOP, we suggest that one direction for improving LLMs is to focus more on the comprehension process, ensuring all comprehension skills are thoroughly developed during training.
        ]]></description>
    </item>
    <item>
        <title>UnHiPPO: Uncertainty-aware Initialization for State Space Models</title>
        <link>https://arxiv.org/abs/2506.05065</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.05065v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Marten Lienen, Abdullah Saydemir, Stephan G\"unnemann</dc:creator>
        <description><![CDATA[
            背景：状态空间模型是解决序列问题的主流模型，很多依赖HiPPO框架初始化动态，但HiPPO假定数据无噪声，这在实际中常不成立。方法：将HiPPO理论扩展到有测量噪声的情况，推导出状态空间模型动态的不确定性感知初始化方法，把HiPPO解释为线性随机控制问题，重新表述问题使数据成为潜在系统的噪声输出，在不增加运行时间的情况下从数据推断潜在系统的后验。效果：实验表明该初始化方法提高了状态空间模型在训练和推理时的抗噪声能力。
            arXiv:2506.05065v1 Announce Type: new 
Abstract: State space models are emerging as a dominant model class for sequence problems with many relying on the HiPPO framework to initialize their dynamics. However, HiPPO fundamentally assumes data to be noise-free; an assumption often violated in practice. We extend the HiPPO theory with measurement noise and derive an uncertainty-aware initialization for state space model dynamics. In our analysis, we interpret HiPPO as a linear stochastic control problem where the data enters as a noise-free control signal. We then reformulate the problem so that the data become noisy outputs of a latent system and arrive at an alternative dynamics initialization that infers the posterior of this latent system from the data without increasing runtime. Our experiments show that our initialization improves the resistance of state-space models to noise both at training and inference time. Find our implementation at https://cs.cit.tum.de/daml/unhippo.
        ]]></description>
    </item>
    <item>
        <title>DiCoRe: Enhancing Zero-shot Event Detection via Divergent-Convergent LLM Reasoning</title>
        <link>https://arxiv.org/abs/2506.05128</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.05128v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tanmay Parekh, Kartik Mehta, Ninareh Mehrabi, Kai-Wei Chang, Nanyun Peng</dc:creator>
        <description><![CDATA[
            背景：零样本事件检测（ED）对专业领域的文档理解至关重要，但现有大语言模型（LLMs）在该任务中存在理解复杂事件本体、提取特定领域触发词和适当结构化等问题。方法：提出DiCoRe，一个发散 - 收敛推理框架，通过Dreamer鼓励发散推理以提高事件覆盖率，Grounder引入收敛推理，利用有限状态机引导的受限解码使预测与任务指令对齐，还有LLM - Judge验证输出。效果：在六个数据集和九个LLMs上实验，平均F1值比最佳基线高4 - 7%。
            arXiv:2506.05128v1 Announce Type: new 
Abstract: Zero-shot Event Detection (ED), the task of identifying event mentions in natural language text without any training data, is critical for document understanding in specialized domains. Understanding the complex event ontology, extracting domain-specific triggers from the passage, and structuring them appropriately overloads and limits the utility of Large Language Models (LLMs) for zero-shot ED. To this end, we propose DiCoRe, a divergent-convergent reasoning framework that decouples the task of ED using Dreamer and Grounder. Dreamer encourages divergent reasoning through open-ended event discovery, which helps to boost event coverage. Conversely, Grounder introduces convergent reasoning to align the free-form predictions with the task-specific instructions using finite-state machine guided constrained decoding. Additionally, an LLM-Judge verifies the final outputs to ensure high precision. Through extensive experiments on six datasets across five domains and nine LLMs, we demonstrate how DiCoRe consistently outperforms prior zero-shot, transfer-learning, and reasoning baselines, achieving 4-7% average F1 gains over the best baseline -- establishing DiCoRe as a strong zero-shot ED framework.
        ]]></description>
    </item>
    <item>
        <title>Knowledgeable-r1: Policy Optimization for Knowledge Exploration in Retrieval-Augmented Generation</title>
        <link>https://arxiv.org/abs/2506.05154</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.05154v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chenyu Lin, Yilin Wen, Du Su, Fei Sun, Muhan Chen, Chenfu Bao, Zhonghou Lv</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）是提升知识密集型任务性能的主流方法，但当前RAG系统过于强调检索上下文，易依赖不准确源且忽视模型固有知识。方法：提出Knowledgeable - r1，采用联合采样并在知识能力探索中定义多策略分布，以激发大语言模型对参数和上下文知识的自我整合利用。效果：显著增强了参数和上下文冲突任务及一般RAG任务的鲁棒性和推理准确性，在反事实场景中比基线高出17.07%，且在各RAG任务中均有提升。
            arXiv:2506.05154v1 Announce Type: new 
Abstract: Retrieval-augmented generation (RAG) is a mainstream method for improving performance on knowledge-intensive tasks. However,current RAG systems often place too much emphasis on retrieved contexts. This can lead to reliance on inaccurate sources and overlook the model's inherent knowledge, especially when dealing with misleading or excessive information. To resolve this imbalance, we propose Knowledgeable-r1 that using joint sampling and define multi policy distributions in knowledge capability exploration to stimulate large language models'self-integrated utilization of parametric and contextual knowledge. Experiments show that Knowledgeable-r1 significantly enhances robustness and reasoning accuracy in both parameters and contextual conflict tasks and general RAG tasks, especially outperforming baselines by 17.07% in counterfactual scenarios and demonstrating consistent gains across RAG tasks. Our code are available at https://github.com/lcy80366872/ knowledgeable-r1.
        ]]></description>
    </item>
    <item>
        <title>Counterfactual reasoning: an analysis of in-context emergence</title>
        <link>https://arxiv.org/abs/2506.05188</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.05188v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Moritz Miller, Bernhard Sch\"olkopf, Siyuan Guo</dc:creator>
        <description><![CDATA[
            背景：大规模神经语言模型在上下文学习中表现出色，而上下文反事实推理研究较少。方法：聚焦线性回归任务，该任务需噪声溯因，通过推断和复制事实观察中的上下文噪声进行准确预测。效果：表明语言模型在该受控环境下有反事实推理能力，发现自注意力、模型深度和预训练数据多样性影响Transformer性能，还证明Transformer能对序列数据进行噪声溯因，为反事实故事生成提供初步证据。
            arXiv:2506.05188v1 Announce Type: new 
Abstract: Large-scale neural language models (LMs) exhibit remarkable performance in in-context learning: the ability to learn and reason the input context on the fly without parameter update. This work studies in-context counterfactual reasoning in language models, that is, to predict the consequences of changes under hypothetical scenarios. We focus on studying a well-defined synthetic setup: a linear regression task that requires noise abduction, where accurate prediction is based on inferring and copying the contextual noise from factual observations. We show that language models are capable of counterfactual reasoning in this controlled setup and provide insights that counterfactual reasoning for a broad class of functions can be reduced to a transformation on in-context observations; we find self-attention, model depth, and data diversity in pre-training drive performance in Transformers. More interestingly, our findings extend beyond regression tasks and show that Transformers can perform noise abduction on sequential data, providing preliminary evidence on the potential for counterfactual story generation. Our code is available under https://github.com/moXmiller/counterfactual-reasoning.git .
        ]]></description>
    </item>
    <item>
        <title>Transformers Meet In-Context Learning: A Universal Approximation Theory</title>
        <link>https://arxiv.org/abs/2506.05200</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.05200v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Gen Li, Yuchen Jiao, Yu Huang, Yuting Wei, Yuxin Chen</dc:creator>
        <description><![CDATA[
            背景：现代大语言模型具备上下文学习能力，但缺乏相关理论解释。方法：开发通用逼近理论，针对任何函数类，构建无需更新权重、仅依据少量上下文示例就能进行可靠预测的Transformer。与将Transformer视为算法近似器的主流方法不同，该工作基于通用函数逼近。效果：这种方法提供的逼近保证不受被近似优化算法有效性的限制，能超越凸问题和线性函数类，揭示了Transformer可同时学习通用表征并动态适应上下文示例。
            arXiv:2506.05200v1 Announce Type: new 
Abstract: Modern large language models are capable of in-context learning, the ability to perform new tasks at inference time using only a handful of input-output examples in the prompt, without any fine-tuning or parameter updates. We develop a universal approximation theory to better understand how transformers enable in-context learning. For any class of functions (each representing a distinct task), we demonstrate how to construct a transformer that, without any further weight updates, can perform reliable prediction given only a few in-context examples. In contrast to much of the recent literature that frames transformers as algorithm approximators -- i.e., constructing transformers to emulate the iterations of optimization algorithms as a means to approximate solutions of learning problems -- our work adopts a fundamentally different approach rooted in universal function approximation. This alternative approach offers approximation guarantees that are not constrained by the effectiveness of the optimization algorithms being approximated, thereby extending far beyond convex problems and linear function classes. Our construction sheds light on how transformers can simultaneously learn general-purpose representations and adapt dynamically to in-context examples.
        ]]></description>
    </item>
    <item>
        <title>RELIC: Evaluating Compositional Instruction Following via Language Recognition</title>
        <link>https://arxiv.org/abs/2506.05205</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.05205v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jackson Petty, Michael Y. Hu, Wentao Wang, Shauli Ravfogel, William Merrill, Tal Linzen</dc:creator>
        <description><![CDATA[
            背景：大语言模型需仅依据任务说明执行任务，即指令遵循能力。方法：引入RELIC框架，用语言识别（判断字符串是否由形式语法生成）评估指令遵循能力，该任务需整合从上下文获取的大量指令，且可随模型能力提升增加复杂度。效果：能可靠预测大语言模型在该任务上的准确率，最先进的大语言模型在复杂语法和样本上表现接近随机，且任务越复杂，模型越倾向依赖浅层启发式而非复杂指令。
            arXiv:2506.05205v1 Announce Type: new 
Abstract: Large language models (LLMs) are increasingly expected to perform tasks based only on a specification of the task provided in context, without examples of inputs and outputs; this ability is referred to as instruction following. We introduce the Recognition of Languages In-Context (RELIC) framework to evaluate instruction following using language recognition: the task of determining if a string is generated by formal grammar. Unlike many standard evaluations of LLMs' ability to use their context, this task requires composing together a large number of instructions (grammar productions) retrieved from the context. Because the languages are synthetic, the task can be increased in complexity as LLMs' skills improve, and new instances can be automatically generated, mitigating data contamination. We evaluate state-of-the-art LLMs on RELIC and find that their accuracy can be reliably predicted from the complexity of the grammar and the individual example strings, and that even the most advanced LLMs currently available show near-chance performance on more complex grammars and samples, in line with theoretical expectations. We also use RELIC to diagnose how LLMs attempt to solve increasingly difficult reasoning tasks, finding that as the complexity of the language recognition task increases, models switch to relying on shallow heuristics instead of following complex instructions.
        ]]></description>
    </item>
    <item>
        <title>Mitigating Degree Bias Adaptively with Hard-to-Learn Nodes in Graph Contrastive Learning</title>
        <link>https://arxiv.org/abs/2506.05214</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.05214v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jingyu Hu, Hongbo Bo, Jun Hong, Xiaowei Liu, Weiru Liu</dc:creator>
        <description><![CDATA[
            背景：图神经网络在节点分类任务中常存在度偏差问题，现有图对比学习方法因正样本对数量有限、正负样本对权重相等，导致低度数节点信息不足且有噪声。方法：提出硬度自适应重加权（HAR）对比损失，利用节点标签增加正样本对，并根据学习难度自适应加权正负样本对，还开发了SHARP实验框架将HAR拓展到更多场景。效果：理论分析和实验验证了SHARP的有效性，四个数据集实验显示其在全局和度层面均优于基线。
            arXiv:2506.05214v1 Announce Type: new 
Abstract: Graph Neural Networks (GNNs) often suffer from degree bias in node classification tasks, where prediction performance varies across nodes with different degrees. Several approaches, which adopt Graph Contrastive Learning (GCL), have been proposed to mitigate this bias. However, the limited number of positive pairs and the equal weighting of all positives and negatives in GCL still lead to low-degree nodes acquiring insufficient and noisy information. This paper proposes the Hardness Adaptive Reweighted (HAR) contrastive loss to mitigate degree bias. It adds more positive pairs by leveraging node labels and adaptively weights positive and negative pairs based on their learning hardness. In addition, we develop an experimental framework named SHARP to extend HAR to a broader range of scenarios. Both our theoretical analysis and experiments validate the effectiveness of SHARP. The experimental results across four datasets show that SHARP achieves better performance against baselines at both global and degree levels.
        ]]></description>
    </item>
    <item>
        <title>MesaNet: Sequence Modeling by Locally Optimal Test-Time Training</title>
        <link>https://arxiv.org/abs/2506.05233</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.05233v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Johannes von Oswald, Nino Scherrer, Seijin Kobayashi, Luca Versari, Songlin Yang, Maximilian Schlegel, Kaitlin Maile, Yanick Schimpf, Oliver Sieberling, Alexander Meulemans, Rif A. Saurous, Guillaume Lajoie, Charlotte Frenkel, Razvan Pascanu, Blaise Ag\"uera y Arcas, Jo\~ao Sacramento</dc:creator>
        <description><![CDATA[
            背景：当前序列建模主要由使用softmax自注意力的因果Transformer架构主导，但推理时内存和计算开销大，虽有线性化模型如DeltaNet等，但仍有提升空间。方法：引入数值稳定、可分块并行的Mesa层，通过快速共轭梯度求解器在每个时间点优化上下文损失。效果：实验表明，该方法在语言建模中困惑度更低，下游基准任务表现更好，尤其在需要长上下文理解的任务上，但推理时需额外计算量。
            arXiv:2506.05233v1 Announce Type: new 
Abstract: Sequence modeling is currently dominated by causal transformer architectures that use softmax self-attention. Although widely adopted, transformers require scaling memory and compute linearly during inference. A recent stream of work linearized the softmax operation, resulting in powerful recurrent neural network (RNN) models with constant memory and compute costs such as DeltaNet, Mamba or xLSTM. These models can be unified by noting that their recurrent layer dynamics can all be derived from an in-context regression objective, approximately optimized through an online learning rule. Here, we join this line of work and introduce a numerically stable, chunkwise parallelizable version of the recently proposed Mesa layer (von Oswald et al., 2024), and study it in language modeling at the billion-parameter scale. This layer again stems from an in-context loss, but which is now minimized to optimality at every time point using a fast conjugate gradient solver. Through an extensive suite of experiments, we show that optimal test-time training enables reaching lower language modeling perplexity and higher downstream benchmark performance than previous RNNs, especially on tasks requiring long context understanding. This performance gain comes at the cost of additional flops spent during inference time. Our results are therefore intriguingly related to recent trends of increasing test-time compute to improve performance -- here by spending compute to solve sequential optimization problems within the neural network itself.
        ]]></description>
    </item>
    <item>
        <title>How to Unlock Time Series Editing? Diffusion-Driven Approach with Multi-Grained Control</title>
        <link>https://arxiv.org/abs/2506.05276</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.05276v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hao Yu, Chu Xin Cheng, Runlong Yu, Yuyang Ye, Shiwei Tong, Zhaofeng Liu, Defu Lian</dc:creator>
        <description><![CDATA[
            背景：时间序列生成虽有进展，但控制生成序列属性仍具挑战，现有方法难以满足时间序列编辑中对点位和片段的控制需求。方法：提出CocktailEdit框架，结合置信加权锚点控制和基于分类器的控制两种机制。效果：能在去噪推理阶段实现精确局部控制，保持时间连贯性，还可与基于扩散的时间序列模型无缝集成，大量实验证明其有效性，为时间序列生成和编辑提供灵活方案。
            arXiv:2506.05276v1 Announce Type: new 
Abstract: Recent advances in time series generation have shown promise, yet controlling properties in generated sequences remains challenging. Time Series Editing (TSE) - making precise modifications while preserving temporal coherence - consider both point-level constraints and segment-level controls that current methods struggle to provide. We introduce the CocktailEdit framework to enable simultaneous, flexible control across different types of constraints. This framework combines two key mechanisms: a confidence-weighted anchor control for point-wise constraints and a classifier-based control for managing statistical properties such as sums and averages over segments. Our methods achieve precise local control during the denoising inference stage while maintaining temporal coherence and integrating seamlessly, with any conditionally trained diffusion-based time series models. Extensive experiments across diverse datasets and models demonstrate its effectiveness. Our work bridges the gap between pure generative modeling and real-world time series editing needs, offering a flexible solution for human-in-the-loop time series generation and editing. The code and demo are provided for validation.
        ]]></description>
    </item>
    <item>
        <title>Micro-Act: Mitigate Knowledge Conflict in Question Answering via Actionable Self-Reasoning</title>
        <link>https://arxiv.org/abs/2506.05278</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.05278v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Nan Huo, Jinyang Li, Bowen Qin, Ge Qu, Xiaolong Li, Xiaodong Li, Chenhao Ma, Reynold Cheng</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）系统常面临知识冲突问题，影响问答等下游任务表现，现有方法直接对比知识源会给大语言模型带来负担。方法：提出Micro - Act框架，其具有分层动作空间，能自动感知上下文复杂度，将每个知识源分解为一系列细粒度比较，以可操作步骤呈现。效果：在五个基准数据集上实验，Micro - Act在所有5个数据集和3种冲突类型中均显著提高问答准确率，对无冲突问题也有稳健表现。
            arXiv:2506.05278v1 Announce Type: new 
Abstract: Retrieval-Augmented Generation (RAG) systems commonly suffer from Knowledge Conflicts, where retrieved external knowledge contradicts the inherent, parametric knowledge of large language models (LLMs). It adversely affects performance on downstream tasks such as question answering (QA). Existing approaches often attempt to mitigate conflicts by directly comparing two knowledge sources in a side-by-side manner, but this can overwhelm LLMs with extraneous or lengthy contexts, ultimately hindering their ability to identify and mitigate inconsistencies. To address this issue, we propose Micro-Act a framework with a hierarchical action space that automatically perceives context complexity and adaptively decomposes each knowledge source into a sequence of fine-grained comparisons. These comparisons are represented as actionable steps, enabling reasoning beyond the superficial context. Through extensive experiments on five benchmark datasets, Micro-Act consistently achieves significant increase in QA accuracy over state-of-the-art baselines across all 5 datasets and 3 conflict types, especially in temporal and semantic types where all baselines fail significantly. More importantly, Micro-Act exhibits robust performance on non-conflict questions simultaneously, highlighting its practical value in real-world RAG applications.
        ]]></description>
    </item>
    <item>
        <title>EOC-Bench: Can MLLMs Identify, Recall, and Forecast Objects in an Egocentric World?</title>
        <link>https://arxiv.org/abs/2506.05287</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.05287v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuqian Yuan, Ronghao Dang, Long Li, Wentong Li, Dian Jiao, Xin Li, Deli Zhao, Fan Wang, Wenqiao Zhang, Jun Xiao, Yueting Zhuang</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型推动了以自我为中心的视觉应用发展，但现有基准主要关注静态场景探索，忽略用户交互带来的动态变化评估。方法：引入EOC - Bench基准，有3277个精心标注的QA对，分三个时间类别，覆盖11个评估维度和3种视觉对象引用类型；开发混合格式的人工参与标注框架，设计多尺度时间准确性指标。效果：对多种MLLMs进行全面评估，为提升MLLMs的具身对象认知能力奠定基础。
            arXiv:2506.05287v1 Announce Type: new 
Abstract: The emergence of multimodal large language models (MLLMs) has driven breakthroughs in egocentric vision applications. These applications necessitate persistent, context-aware understanding of objects, as users interact with tools in dynamic and cluttered environments. However, existing embodied benchmarks primarily focus on static scene exploration, emphasizing object's appearance and spatial attributes while neglecting the assessment of dynamic changes arising from users' interactions. To address this gap, we introduce EOC-Bench, an innovative benchmark designed to systematically evaluate object-centric embodied cognition in dynamic egocentric scenarios. Specially, EOC-Bench features 3,277 meticulously annotated QA pairs categorized into three temporal categories: Past, Present, and Future, covering 11 fine-grained evaluation dimensions and 3 visual object referencing types. To ensure thorough assessment, we develop a mixed-format human-in-the-loop annotation framework with four types of questions and design a novel multi-scale temporal accuracy metric for open-ended temporal evaluation. Based on EOC-Bench, we conduct comprehensive evaluations of various proprietary, open-source, and object-level MLLMs. EOC-Bench serves as a crucial tool for advancing the embodied object cognitive capabilities of MLLMs, establishing a robust foundation for developing reliable core models for embodied systems.
        ]]></description>
    </item>
    <item>
        <title>Perceive Anything: Recognize, Explain, Caption, and Segment Anything in Images and Videos</title>
        <link>https://arxiv.org/abs/2506.05302</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.05302v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Weifeng Lin, Xinyu Wei, Ruichuan An, Tianhe Ren, Tingwei Chen, Renrui Zhang, Ziyu Guo, Wentao Zhang, Lei Zhang, Hongsheng Li</dc:creator>
        <description><![CDATA[
            背景：需要对图像和视频进行全面的区域级视觉理解。方法：提出感知一切模型（PAM），通过集成大语言模型（LLMs）扩展强大的分割模型SAM 2，引入语义感知器将视觉特征转换为多模态标记，还开发数据细化和增强管道生成高质量数据集。效果：PAM轻量高效，在多种区域理解任务中表现出色，运行速度比先前方法快1.2 - 2.4倍，且消耗更少GPU内存。
            arXiv:2506.05302v1 Announce Type: new 
Abstract: We present Perceive Anything Model (PAM), a conceptually straightforward and efficient framework for comprehensive region-level visual understanding in images and videos. Our approach extends the powerful segmentation model SAM 2 by integrating Large Language Models (LLMs), enabling simultaneous object segmentation with the generation of diverse, region-specific semantic outputs, including categories, label definition, functional explanations, and detailed captions. A key component, Semantic Perceiver, is introduced to efficiently transform SAM 2's rich visual features, which inherently carry general vision, localization, and semantic priors into multi-modal tokens for LLM comprehension. To support robust multi-granularity understanding, we also develop a dedicated data refinement and augmentation pipeline, yielding a high-quality dataset of 1.5M image and 0.6M video region-semantic annotations, including novel region-level streaming video caption data. PAM is designed for lightweightness and efficiency, while also demonstrates strong performance across a diverse range of region understanding tasks. It runs 1.2-2.4x faster and consumes less GPU memory than prior approaches, offering a practical solution for real-world applications. We believe that our effective approach will serve as a strong baseline for future research in region-level visual understanding.
        ]]></description>
    </item>
    <item>
        <title>ProRefine: Inference-time Prompt Refinement with Textual Feedback</title>
        <link>https://arxiv.org/abs/2506.05305</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.05305v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Deepak Pandita, Tharindu Cyril Weerasooriya, Ankit Parag Shah, Christopher M. Homan, Wei Wei</dc:creator>
        <description><![CDATA[
            背景：当前多个AI智能体协作完成推理或规划等复杂任务的工作流程日益普遍，但常因提示设计不佳导致错误传播和性能欠佳。方法：提出ProRefine，一种推理时提示优化方法，利用大语言模型的文本反馈，在无需额外训练或真实标签的情况下动态优化多步推理任务的提示。效果：在五个基准数学推理数据集上，显著超越零样本思维链基线3至37个百分点，还能让小模型达到大模型性能，利于高效可扩展的AI部署。
            arXiv:2506.05305v1 Announce Type: new 
Abstract: Agentic workflows, where multiple AI agents collaborate to accomplish complex tasks like reasoning or planning, are becoming increasingly prevalent. However, these workflows often suffer from error propagation and sub-optimal performance, largely due to poorly designed prompts that fail to effectively guide individual agents. This is a critical problem because it limits the reliability and scalability of these powerful systems. We introduce ProRefine, an innovative inference-time prompt optimization method that leverages textual feedback from large language models (LLMs) to address this challenge. ProRefine dynamically refines prompts for multi-step reasoning tasks without additional training or ground truth labels. Evaluated on five benchmark mathematical reasoning datasets, ProRefine significantly surpasses zero-shot Chain-of-Thought baselines by 3 to 37 percentage points. This approach not only boosts accuracy but also allows smaller models to match the performance of larger ones, highlighting its potential for efficient and scalable AI deployment, and democratizing access to high-performing AI.
        ]]></description>
    </item>
    <item>
        <title>MINT-CoT: Enabling Interleaved Visual Tokens in Mathematical Chain-of-Thought Reasoning</title>
        <link>https://arxiv.org/abs/2506.05331</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.05331v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xinyan Chen, Renrui Zhang, Dongzhi Jiang, Aojun Zhou, Shilin Yan, Weifeng Lin, Hongsheng Li</dc:creator>
        <description><![CDATA[
            思维链（CoT）虽提升了大语言模型的数学推理能力，但扩展到多模态领域仍具挑战。现有方法在解决数学问题时有依赖粗粒度图像区域等局限。本文提出MINT - CoT，通过插入令牌将相关视觉令牌自适应地融入文本推理步骤，动态选择数学图形中任意形状的视觉区域。构建含54K个数学问题的MINT - CoT数据集及数据生成管道，采用三阶段训练策略得到MINT - CoT - 7B模型。实验表明该方法有效，MINT - CoT - 7B在多个数据集上显著优于基线模型。
            arXiv:2506.05331v1 Announce Type: new 
Abstract: Chain-of-Thought (CoT) has widely enhanced mathematical reasoning in Large Language Models (LLMs), but it still remains challenging for extending it to multimodal domains. Existing works either adopt a similar textual reasoning for image input, or seek to interleave visual signals into mathematical CoT. However, they face three key limitations for math problem-solving: reliance on coarse-grained box-shaped image regions, limited perception of vision encoders on math content, and dependence on external capabilities for visual modification. In this paper, we propose MINT-CoT, introducing Mathematical INterleaved Tokens for Chain-of-Thought visual reasoning. MINT-CoT adaptively interleaves relevant visual tokens into textual reasoning steps via an Interleave Token, which dynamically selects visual regions of any shapes within math figures. To empower this capability, we construct the MINT-CoT dataset, containing 54K mathematical problems aligning each reasoning step with visual regions at the token level, accompanied by a rigorous data generation pipeline. We further present a three-stage MINT-CoT training strategy, progressively combining text-only CoT SFT, interleaved CoT SFT, and interleaved CoT RL, which derives our MINT-CoT-7B model. Extensive experiments demonstrate the effectiveness of our method for effective visual interleaved reasoning in mathematical domains, where MINT-CoT-7B outperforms the baseline model by +34.08% on MathVista, +28.78% on GeoQA, and +23.2% on MMStar, respectively. Our code and data are available at https://github.com/xinyan-cxy/MINT-CoT
        ]]></description>
    </item>
    <item>
        <title>Direct Numerical Layout Generation for 3D Indoor Scene Synthesis via Spatial Reasoning</title>
        <link>https://arxiv.org/abs/2506.05341</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.05341v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xingjian Ran, Yixuan Li, Linning Xu, Mulin Yu, Bo Dai</dc:creator>
        <description><![CDATA[
            现实的3D室内场景合成对具身AI和数字内容创作至关重要，但布局生成因数据集有限而面临挑战，现有方法存在过拟合或牺牲灵活性等问题。本文提出DirectLayout框架，利用大语言模型的空间推理能力，将生成过程分为三个阶段。采用基于3D - Front数据集的思维链激活，设计CoT - Grounded生成布局奖励，推理时通过上下文学习解决资产布局不匹配问题。实验表明，该框架在语义一致性、泛化性和物理合理性方面表现出色。
            arXiv:2506.05341v1 Announce Type: new 
Abstract: Realistic 3D indoor scene synthesis is vital for embodied AI and digital content creation. It can be naturally divided into two subtasks: object generation and layout generation. While recent generative models have significantly advanced object-level quality and controllability, layout generation remains challenging due to limited datasets. Existing methods either overfit to these datasets or rely on predefined constraints to optimize numerical layout that sacrifice flexibility. As a result, they fail to generate scenes that are both open-vocabulary and aligned with fine-grained user instructions. We introduce DirectLayout, a framework that directly generates numerical 3D layouts from text descriptions using generalizable spatial reasoning of large language models (LLMs). DirectLayout decomposes the generation into three stages: producing a Bird's-Eye View (BEV) layout, lifting it into 3D space, and refining object placements. To enable explicit spatial reasoning and help the model grasp basic principles of object placement, we employ Chain-of-Thought (CoT) Activation based on the 3D-Front dataset. Additionally, we design CoT-Grounded Generative Layout Reward to enhance generalization and spatial planning. During inference, DirectLayout addresses asset-layout mismatches via Iterative Asset-Layout Alignment through in-context learning. Extensive experiments demonstrate that DirectLayout achieves impressive semantic consistency, generalization and physical plausibility.
        ]]></description>
    </item>
    <item>
        <title>VideoMathQA: Benchmarking Mathematical Reasoning via Multimodal Understanding in Videos</title>
        <link>https://arxiv.org/abs/2506.05349</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.05349v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hanoona Rasheed, Abdelrahman Shaker, Anqi Tang, Muhammad Maaz, Ming-Hsuan Yang, Salman Khan, Fahad Khan</dc:creator>
        <description><![CDATA[
            现实世界视频场景中的数学推理与静态图像或文本中的推理挑战不同，需解读细粒度视觉信息、读取文本并整合语音线索。为此，本文引入VideoMathQA基准，涵盖10个数学领域，要求模型解读结构化视觉内容、理解指令性叙述并跨模态关联概念。该基准由专家标注，耗时超920工时。问题围绕三种推理挑战设计，含多步推理注释。此基准凸显了现有方法的局限，为模型建立了系统评估框架。
            arXiv:2506.05349v1 Announce Type: new 
Abstract: Mathematical reasoning in real-world video settings presents a fundamentally different challenge than in static images or text. It requires interpreting fine-grained visual information, accurately reading handwritten or digital text, and integrating spoken cues, often dispersed non-linearly over time. In such multimodal contexts, success hinges not just on perception, but on selectively identifying and integrating the right contextual details from a rich and noisy stream of content. To this end, we introduce VideoMathQA, a benchmark designed to evaluate whether models can perform such temporally extended cross-modal reasoning on videos. The benchmark spans 10 diverse mathematical domains, covering videos ranging from 10 seconds to over 1 hour. It requires models to interpret structured visual content, understand instructional narratives, and jointly ground concepts across visual, audio, and textual modalities. We employ graduate-level experts to ensure high quality, totaling over $920$ man-hours of annotation. To reflect real-world scenarios, questions are designed around three core reasoning challenges: direct problem solving, where answers are grounded in the presented question; conceptual transfer, which requires applying learned methods to new problems; and deep instructional comprehension, involving multi-step reasoning over extended explanations and partially worked-out solutions. Each question includes multi-step reasoning annotations, enabling fine-grained diagnosis of model capabilities. Through this benchmark, we highlight the limitations of existing approaches and establish a systematic evaluation framework for models that must reason, rather than merely perceive, across temporally extended and modality-rich mathematical problem settings. Our benchmark and evaluation code are available at: https://mbzuai-oryx.github.io/VideoMathQA
        ]]></description>
    </item>
    <item>
        <title>CMIE: Combining MLLM Insights with External Evidence for Explainable Out-of-Context Misinformation Detection</title>
        <link>https://arxiv.org/abs/2505.23449</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.23449v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Fanxiao Li, Jiaying Wu, Canyuan He, Wei Zhou</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型在检测脱离上下文的错误信息时存在难以捕捉深层关系、证据噪声影响检测精度等问题。方法：提出CMIE框架，采用共存关系生成策略和关联评分机制，识别图像与文本的潜在共存关系，有选择地利用相关证据。效果：实验结果表明，该方法优于现有方法，能有效提升错误信息检测能力。
            arXiv:2505.23449v2 Announce Type: cross 
Abstract: Multimodal large language models (MLLMs) have demonstrated impressive capabilities in visual reasoning and text generation. While previous studies have explored the application of MLLM for detecting out-of-context (OOC) misinformation, our empirical analysis reveals two persisting challenges of this paradigm. Evaluating the representative GPT-4o model on direct reasoning and evidence augmented reasoning, results indicate that MLLM struggle to capture the deeper relationships-specifically, cases in which the image and text are not directly connected but are associated through underlying semantic links. Moreover, noise in the evidence further impairs detection accuracy. To address these challenges, we propose CMIE, a novel OOC misinformation detection framework that incorporates a Coexistence Relationship Generation (CRG) strategy and an Association Scoring (AS) mechanism. CMIE identifies the underlying coexistence relationships between images and text, and selectively utilizes relevant evidence to enhance misinformation detection. Experimental results demonstrate that our approach outperforms existing methods.
        ]]></description>
    </item>
    <item>
        <title>Contextual Integrity in LLMs via Reasoning and Reinforcement Learning</title>
        <link>https://arxiv.org/abs/2506.04245</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04245v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Guangchen Lan, Huseyin A. Inan, Sahar Abdelnabi, Janardhan Kulkarni, Lukas Wutschitz, Reza Shokri, Christopher G. Brinton, Robert Sim</dc:creator>
        <description><![CDATA[
            背景：在自主代理替用户做决策的时代，确保情境完整性（CI），即执行任务时共享合适信息，成为关键问题。方法：先促使大语言模型（LLMs）在决定信息披露时明确推理CI，再开发强化学习（RL）框架，让模型具备实现CI所需的推理能力。效果：利用约700个示例的合成数据集，该方法大幅减少不适当信息披露，同时保持多模型的任务性能，且改进能迁移到如PrivacyLens等CI基准测试中。
            arXiv:2506.04245v1 Announce Type: cross 
Abstract: As the era of autonomous agents making decisions on behalf of users unfolds, ensuring contextual integrity (CI) -- what is the appropriate information to share while carrying out a certain task -- becomes a central question to the field. We posit that CI demands a form of reasoning where the agent needs to reason about the context in which it is operating. To test this, we first prompt LLMs to reason explicitly about CI when deciding what information to disclose. We then extend this approach by developing a reinforcement learning (RL) framework that further instills in models the reasoning necessary to achieve CI. Using a synthetic, automatically created, dataset of only $\sim700$ examples but with diverse contexts and information disclosure norms, we show that our method substantially reduces inappropriate information disclosure while maintaining task performance across multiple model sizes and families. Importantly, improvements transfer from this synthetic dataset to established CI benchmarks such as PrivacyLens that has human annotations and evaluates privacy leakage of AI assistants in actions and tool calls.
        ]]></description>
    </item>
    <item>
        <title>A Graph-Retrieval-Augmented Generation Framework Enhances Decision-Making in the Circular Economy</title>
        <link>https://arxiv.org/abs/2506.04252</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04252v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yang Zhao, Chengxiao Dai, Dusit Niyato, Chuan Fu Tan, Keyi Xiang, Yueyang Wang, Zhiquan Yeo, Daren Tan Zong Loong, Jonathan Low Zhaozhi, Eugene H. Z. HO</dc:creator>
        <description><![CDATA[
            背景：大语言模型用于可持续制造时，常虚构工业代码和排放因子，影响监管和投资决策。方法：提出CircuGraphRAG这一检索增强生成（RAG）框架，将大语言模型输出与循环经济领域特定知识图谱结合，该图谱连接117,380个工业和废物实体，支持结构化多跳推理，将自然语言查询转换为SPARQL并检索验证子图。效果：相比其他模型，在单跳和多跳问答中表现更优，ROUGE - L F1得分最高达1.0，还提高了效率，减少响应时间和令牌使用。
            arXiv:2506.04252v1 Announce Type: cross 
Abstract: Large language models (LLMs) hold promise for sustainable manufacturing, but often hallucinate industrial codes and emission factors, undermining regulatory and investment decisions. We introduce CircuGraphRAG, a retrieval-augmented generation (RAG) framework that grounds LLMs outputs in a domain-specific knowledge graph for the circular economy. This graph connects 117,380 industrial and waste entities with classification codes and GWP100 emission data, enabling structured multi-hop reasoning. Natural language queries are translated into SPARQL and verified subgraphs are retrieved to ensure accuracy and traceability. Compared with Standalone LLMs and Naive RAG, CircuGraphRAG achieves superior performance in single-hop and multi-hop question answering, with ROUGE-L F1 scores up to 1.0, while baseline scores below 0.08. It also improves efficiency, halving the response time and reducing token usage by 16% in representative tasks. CircuGraphRAG provides fact-checked, regulatory-ready support for circular economy planning, advancing reliable, low-carbon resource decision making.
        ]]></description>
    </item>
    <item>
        <title>SGN-CIRL: Scene Graph-based Navigation with Curriculum, Imitation, and Reinforcement Learning</title>
        <link>https://arxiv.org/abs/2506.04505</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04505v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Nikita Oskolkov, Huzhenyu Zhang, Dmitry Makarov, Dmitry Yudin, Aleksandr Panov</dc:creator>
        <description><![CDATA[
            背景：3D场景图可建模物体空间关系，助力智能体导航与目标定位。方法：本文提出SGN - CIRL框架用于无地图的基于强化学习的机器人导航，采用可学习的开放词汇3D场景图表示，还结合模仿学习和课程学习来加速与稳定强化学习算法训练，课程学习从简单到复杂构建训练过程。效果：在Isaac Sim环境实验表明，使用3D场景图进行强化学习显著提高困难导航任务成功率，代码已开源。
            arXiv:2506.04505v1 Announce Type: cross 
Abstract: The 3D scene graph models spatial relationships between objects, enabling the agent to efficiently navigate in a partially observable environment and predict the location of the target object.This paper proposes an original framework named SGN-CIRL (3D Scene Graph-Based Reinforcement Learning Navigation) for mapless reinforcement learning-based robot navigation with learnable representation of open-vocabulary 3D scene graph. To accelerate and stabilize the training of reinforcement learning-based algorithms, the framework also employs imitation learning and curriculum learning. The first one enables the agent to learn from demonstrations, while the second one structures the training process by gradually increasing task complexity from simple to more advanced scenarios. Numerical experiments conducted in the Isaac Sim environment showed that using a 3D scene graph for reinforcement learning significantly increased the success rate in difficult navigation cases. The code is open-sourced and available at: https://github.com/Xisonik/Aloha\_graph.
        ]]></description>
    </item>
    <item>
        <title>The Latent Space Hypothesis: Toward Universal Medical Representation Learning</title>
        <link>https://arxiv.org/abs/2506.04515</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04515v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Salil Patel</dc:creator>
        <description><![CDATA[
            背景：医学数据包含多种模态，虽看似不同却蕴含同一生理状态的信息。方法：提出潜在空间假说，将各观察视为统一分层流形的投影，在学习的几何表示中，健康状态、疾病进展和治疗干预分别对应点、轨迹和向量。效果：该框架能揭示子轨迹和患者特定变化方向，为个性化诊断、监测和治疗提供定量依据，虽面临一些挑战，但也有相应解决途径。
            arXiv:2506.04515v1 Announce Type: cross 
Abstract: Medical data range from genomic sequences and retinal photographs to structured laboratory results and unstructured clinical narratives. Although these modalities appear disparate, many encode convergent information about a single underlying physiological state. The Latent Space Hypothesis frames each observation as a projection of a unified, hierarchically organized manifold -- much like shadows cast by the same three-dimensional object. Within this learned geometric representation, an individual's health status occupies a point, disease progression traces a trajectory, and therapeutic intervention corresponds to a directed vector. Interpreting heterogeneous evidence in a shared space provides a principled way to re-examine eponymous conditions -- such as Parkinson's or Crohn's -- that often mask multiple pathophysiological entities and involve broader anatomical domains than once believed. By revealing sub-trajectories and patient-specific directions of change, the framework supplies a quantitative rationale for personalised diagnosis, longitudinal monitoring, and tailored treatment, moving clinical practice away from grouping by potentially misleading labels toward navigation of each person's unique trajectory. Challenges remain -- bias amplification, data scarcity for rare disorders, privacy, and the correlation-causation divide -- but scale-aware encoders, continual learning on longitudinal data streams, and perturbation-based validation offer plausible paths forward.
        ]]></description>
    </item>
    <item>
        <title>When Thinking LLMs Lie: Unveiling the Strategic Deception in Representations of Reasoning Models</title>
        <link>https://arxiv.org/abs/2506.04909</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04909v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kai Wang, Yihao Zhang, Meng Sun</dc:creator>
        <description><![CDATA[
            背景：大语言模型的诚实性是关键对齐挑战，具备思维链推理的先进系统可能会策略性欺骗人类。方法：运用表征工程，在支持思维链的大语言模型中系统地诱导、检测和控制这种欺骗行为，通过线性人工断层扫描提取“欺骗向量”，并进行激活引导。效果：检测欺骗的准确率达89%，在无明确提示下引发符合语境欺骗的成功率达40%，揭示推理模型诚实性问题并为可信AI对齐提供工具。
            arXiv:2506.04909v1 Announce Type: cross 
Abstract: The honesty of large language models (LLMs) is a critical alignment challenge, especially as advanced systems with chain-of-thought (CoT) reasoning may strategically deceive humans. Unlike traditional honesty issues on LLMs, which could be possibly explained as some kind of hallucination, those models' explicit thought paths enable us to study strategic deception--goal-driven, intentional misinformation where reasoning contradicts outputs. Using representation engineering, we systematically induce, detect, and control such deception in CoT-enabled LLMs, extracting "deception vectors" via Linear Artificial Tomography (LAT) for 89% detection accuracy. Through activation steering, we achieve a 40% success rate in eliciting context-appropriate deception without explicit prompts, unveiling the specific honesty-related issue of reasoning models and providing tools for trustworthy AI alignment.
        ]]></description>
    </item>
    <item>
        <title>LLM-First Search: Self-Guided Exploration of the Solution Space</title>
        <link>https://arxiv.org/abs/2506.05213</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.05213v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Nathan Herr, Tim Rockt\"aschel, Roberta Raileanu</dc:creator>
        <description><![CDATA[
            背景：大语言模型虽通过增加测试时计算量在推理和规划方面有显著提升，但像蒙特卡罗树搜索等方法因依赖固定探索超参数，在不同难度任务中适应性受限。方法：提出LLM-First Search (LFS)，让大语言模型通过自我引导探索自主控制搜索过程，依据内部评分机制决定搜索路径。效果：与三种经典搜索算法对比，LFS在更具挑战性任务中表现更好，计算效率更高，随模型变强扩展性更佳，且随计算预算增加表现更好。
            arXiv:2506.05213v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) have demonstrated remarkable improvements in reasoning and planning through increased test-time compute, often by framing problem-solving as a search process. While methods like Monte Carlo Tree Search (MCTS) have proven effective in some domains, their reliance on fixed exploration hyperparameters limits their adaptability across tasks of varying difficulty, rendering them impractical or expensive in certain settings. In this paper, we propose \textbf{LLM-First Search (LFS)}, a novel \textit{LLM Self-Guided Search} method that removes the need for pre-defined search strategies by empowering the LLM to autonomously control the search process via self-guided exploration. Rather than relying on external heuristics or hardcoded policies, the LLM evaluates whether to pursue the current search path or explore alternative branches based on its internal scoring mechanisms. This enables more flexible and context-sensitive reasoning without requiring manual tuning or task-specific adaptation. We evaluate LFS on Countdown and Sudoku against three classic widely-used search algorithms, Tree-of-Thoughts' Breadth First Search (ToT-BFS), Best First Search (BestFS), and MCTS, each of which have been used to achieve SotA results on a range of challenging reasoning tasks. We found that LFS (1) performs better on more challenging tasks without additional tuning, (2) is more computationally efficient compared to the other methods, especially when powered by a stronger model, (3) scales better with stronger models, due to its LLM-First design, and (4) scales better with increased compute budget. Our code is publicly available at \href{https://github.com/NathanHerr/LLM-First-Search}{LLM-First-Search}.
        ]]></description>
    </item>
    <item>
        <title>VCD: A Dataset for Visual Commonsense Discovery in Images</title>
        <link>https://arxiv.org/abs/2402.17213</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2402.17213v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiangqing Shen, Fanfan Wang, Siwei Wu, Rui Xia</dc:creator>
        <description><![CDATA[
            背景：现有常识知识库缺乏视觉表征，场景图数据集缺乏常识知识分类。方法：提出含超10万张图像和1400万对象-常识对的大规模数据集VCD，引入三级视觉常识分类法；开发生成模型VCM，结合视觉语言模型和指令微调从图像中发现视觉常识。效果：评估显示VCD质量高，能推动视觉常识理解和推理，代码将在指定网址发布。
            arXiv:2402.17213v2 Announce Type: replace 
Abstract: Visual commonsense plays a vital role in understanding and reasoning about the visual world. While commonsense knowledge bases like ConceptNet provide structured collections of general facts, they lack visually grounded representations. Scene graph datasets like Visual Genome, though rich in object-level descriptions, primarily focus on directly observable information and lack systematic categorization of commonsense knowledge. We present Visual Commonsense Dataset (VCD), a large-scale dataset containing over 100,000 images and 14 million object-commonsense pairs that bridges this gap. VCD introduces a novel three-level taxonomy for visual commonsense, integrating both Seen (directly observable) and Unseen (inferrable) commonsense across Property, Action, and Space aspects. Each commonsense is represented as a triple where the head entity is grounded to object bounding boxes in images, enabling scene-dependent and object-specific visual commonsense representation. To demonstrate VCD's utility, we develop VCM, a generative model that combines a vision-language model with instruction tuning to discover diverse visual commonsense from images. Extensive evaluations demonstrate both the high quality of VCD and its value as a resource for advancing visually grounded commonsense understanding and reasoning. Our dataset and code will be released on https://github.com/NUSTM/VCD.
        ]]></description>
    </item>
    <item>
        <title>Efficient Time Series Processing for Transformers and State-Space Models through Token Merging</title>
        <link>https://arxiv.org/abs/2405.17951</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2405.17951v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Leon G\"otz, Marcel Kollovieh, Stephan G\"unnemann, Leo Schwinn</dc:creator>
        <description><![CDATA[
            背景：处理长令牌序列计算需求大，令牌合并可提升计算机视觉架构计算效率。方法：首次在时间序列分析中对transformers和状态空间模型进行令牌合并研究，引入局部合并算法，可根据邻域大小调整计算复杂度，是首个能用于transformer解码器的因果合并方案，还能根据输入数据频谱特性预测其潜在优势。效果：显著提升效率且对精度影响小，在Chronos基础模型上加速达5400%。
            arXiv:2405.17951v3 Announce Type: replace 
Abstract: Despite recent advances in subquadratic attention mechanisms or state-space models, processing long token sequences still imposes significant computational requirements. Token merging has emerged as a solution to increase computational efficiency in computer vision architectures. In this work, we perform the first investigations of token merging in time series analysis on both transformers and state-space models. We further introduce local merging, a domain-specific token merging algorithm that selectively combines tokens within a local neighborhood, achieving two major benefits: a) Local merging can adjust its computational complexity from quadratic to linear based on the neighborhood size to effectively scale to long sequences; b) Local merging is the first causal merging scheme enabling token merging in transformer decoders. Further, we identify spectral properties of the input data that reliably predict the potential benefits of local merging without requiring evaluation on downstream tasks. Our comprehensive empirical evaluation demonstrates that local merging offers substantial efficiency gains with minimal impact on accuracy, achieving up to 5400% acceleration on the recently proposed Chronos foundation model.
        ]]></description>
    </item>
    <item>
        <title>Multi-Head RAG: Solving Multi-Aspect Problems with LLMs</title>
        <link>https://arxiv.org/abs/2406.05085</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2406.05085v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Maciej Besta, Ales Kubicek, Robert Gerstenberger, Marcin Chrapek, Roman Niggli, Patrik Okanovic, Yi Zhu, Patrick Iff, Michal Podstawski, Lucas Weitzendorf, Mingyuan Chi, Joanna Gajda, Piotr Nyczyk, J\"urgen M\"uller, Hubert Niewiadomski, Torsten Hoefler</dc:creator>
        <description><![CDATA[
            背景：现有检索增强生成（RAG）方案难以处理需获取内容差异大的多文档查询。方法：本文提出多头RAG（MRAG），利用Transformer多头注意力层而非解码器层的激活作为获取多方面文档的键，不同注意力头捕捉不同数据方面，对应激活产生的嵌入能代表数据项和查询的多方面。效果：通过评估方法、多方面数据集和实际用例证明其有效性，相比18个RAG基线有设计优势，检索成功率最高提升20%，对下游大语言模型生成有益，且可与现有RAG框架和基准无缝集成。
            arXiv:2406.05085v3 Announce Type: replace 
Abstract: Retrieval Augmented Generation (RAG) enhances the abilities of Large Language Models (LLMs) by enabling the retrieval of documents into the LLM context to provide more accurate and relevant responses. Existing RAG solutions do not focus on queries that may require fetching multiple documents with substantially different contents. Such queries occur frequently, but are challenging because the embeddings of these documents may be distant in the embedding space, making it hard to retrieve them all. This paper introduces Multi-Head RAG (MRAG), a novel scheme designed to address this gap with a simple yet powerful idea: leveraging activations of Transformer's multi-head attention layer, instead of the decoder layer, as keys for fetching multi-aspect documents. The driving observation is that different attention heads learn to capture different data aspects. Harnessing the corresponding activations results in embeddings that represent various facets of data items and queries, improving the retrieval accuracy for complex queries. We provide an evaluation methodology and metrics, multi-aspect datasets, and real-world use cases to demonstrate MRAG's effectiveness. We show MRAG's design advantages over 18 RAG baselines, empirical improvements of up to 20% in retrieval success ratios, and benefits for downstream LLM generation. MRAG can be seamlessly integrated with existing RAG frameworks and benchmarks.
        ]]></description>
    </item>
    <item>
        <title>LEMoN: Label Error Detection using Multimodal Neighbors</title>
        <link>https://arxiv.org/abs/2407.18941</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2407.18941v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Haoran Zhang, Aparna Balagopalan, Nassim Oufattole, Hyewon Jeong, Yan Wu, Jiacheng Zhu, Marzyeh Ghassemi</dc:creator>
        <description><![CDATA[
            背景：大规模图像 - 文本对数据集对视觉 - 语言模型发展很重要，但网络数据噪声大、存在大量错误标注。此前除基于图像 - 文本嵌入相似度过滤外，缺乏其他过滤方法。方法：提出LEMoN方法，利用对比预训练多模态模型潜在空间中图像 - 文本对的多模态邻域自动识别标签错误。效果：在八个数据集和十二个基线模型的评估中，LEMoN在标签错误检测上比基线模型高3%以上，用其过滤后的数据集训练，下游字幕生成性能比有噪声训练提高超2个BLEU分数。
            arXiv:2407.18941v2 Announce Type: replace 
Abstract: Large repositories of image-caption pairs are essential for the development of vision-language models. However, these datasets are often extracted from noisy data scraped from the web, and contain many mislabeled instances. In order to improve the reliability of downstream models, it is important to identify and filter images with incorrect captions. However, beyond filtering based on image-caption embedding similarity, no prior works have proposed other methods to filter noisy multimodal data, or concretely assessed the impact of noisy captioning data on downstream training. In this work, we propose, theoretically justify, and empirically validate LEMoN, a method to identify label errors in image-caption datasets. Our method leverages the multimodal neighborhood of image-caption pairs in the latent space of contrastively pretrained multimodal models to automatically identify label errors. Through empirical evaluations across eight datasets and twelve baselines, we find that LEMoN outperforms the baselines by over 3% in label error detection, and that training on datasets filtered using our method improves downstream captioning performance by more than 2 BLEU points over noisy training.
        ]]></description>
    </item>
    <item>
        <title>SPHINX: Structural Prediction using Hypergraph Inference Network</title>
        <link>https://arxiv.org/abs/2410.03208</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.03208v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Iulia Duta, Pietro Li\`o</dc:creator>
        <description><![CDATA[
            背景：高阶关系在现实系统中很重要，但标注困难，现有数据建模方法常忽略或简化高阶交互。方法：提出SPHINX模型，能从节点信号无监督推断潜在超图结构，包括软的可微聚类方法和采样算法。效果：借助k子集采样解决训练不稳定问题，可生成现代超图神经网络所需高阶结构。在轨迹预测数据集实验表明，该模型能推断可解释的潜在超图，提升最终性能。
            arXiv:2410.03208v2 Announce Type: replace 
Abstract: The importance of higher-order relations is widely recognized in a large number of real-world systems. However, annotating them is a tedious and sometimes impossible task. Consequently, current approaches for data modelling either ignore the higher-order interactions altogether or simplify them into pairwise connections. In order to facilitate higher-order processing, even when a hypergraph structure is not available, we introduce Structural Prediction using Hypergraph Inference Network (SPHINX), a model that learns to infer a latent hypergraph structure in an unsupervised way, solely from the final node-level signal. The model consists of a soft, differentiable clustering method used to sequentially predict, for each hyperedge, the probability distribution over the nodes and a sampling algorithm that converts them into an explicit hypergraph structure. We show that the recent advancement in $k$-subset sampling represents a suitable tool for producing discrete hypergraph structures, addressing some of the training instabilities exhibited by prior works. The resulting model can generate the higher-order structure necessary for any modern hypergraph neural network, facilitating the capture of higher-order interaction in domains where annotating them is difficult. Through extensive ablation studies and experiments conducted on two challenging datasets for trajectory prediction, we demonstrate that our model is capable of inferring suitable latent hypergraphs, that are interpretable and enhance the final performance.
        ]]></description>
    </item>
    <item>
        <title>TSFM-Bench: A Comprehensive and Unified Benchmarking of Foundation Models for Time Series Forecasting</title>
        <link>https://arxiv.org/abs/2410.11802</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.11802v5</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhe Li, Xiangfei Qiu, Peng Chen, Yihang Wang, Hanyin Cheng, Yang Shu, Jilin Hu, Chenjuan Guo, Aoying Zhou, Christian S. Jensen, Bin Yang</dc:creator>
        <description><![CDATA[
            时间序列预测在多领域至关重要，但现有方法存在需特定领域数据、泛化性差等问题。时间序列基础模型（TSFMs）旨在克服这些局限。本文提出基准TSFM - Bench，用于全面统一评估TSFMs，涵盖基于大语言模型和时间序列数据预训练的模型，支持多预测场景。该基准还提供标准化实验协议。通过跨多领域多样数据集的评估，识别现有TSFMs优缺点及局限，为新模型设计指明方向。
            arXiv:2410.11802v5 Announce Type: replace 
Abstract: Time Series Forecasting (TSF) is key functionality in numerous fields, such as financial investment, weather services, and energy management. Although increasingly capable TSF methods occur, many of them require domain-specific data collection and model training and do not generalize well when applied in other domains. Time Series Foundation Models (TSFMs) that are pre-trained on massive heterogeneous time series data aim to overcome these limitations. The prospects for generalizability have spurred the development of a new generation of TSFMs. This study proposes a benchmark, TSFM-Bench, to facilitate comprehensive and unified evaluation of TSFMs. TSFM-Bench covers a wide range of TSFMs, including those based on large language models and those pre-trained on time series data. TSFM-Bench supports multiple forecasting scenarios, including zero-shot, few-shot, and full-shot, enabling assessment across the full range of adaptation strategies. TSFM-Bench also provides a standardized experimental protocols for critical evaluation processes such as dataset splitting, loading, normalization, and few-shot sampling, facilitating consistency and fairness. We report on an extensive evaluation of TSFMs across a diverse range of datasets spanning multiple domains and exhibiting varied statistical characteristics. Specifically, we identify pros and cons and inherent limitations of existing TSFMs, and we propose potential directions for new model designs.
        ]]></description>
    </item>
    <item>
        <title>Context is Key: A Benchmark for Forecasting with Essential Textual Information</title>
        <link>https://arxiv.org/abs/2410.18959</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.18959v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Andrew Robert Williams, Arjun Ashok, \'Etienne Marcotte, Valentina Zantedeschi, Jithendaraa Subramanian, Roland Riachi, James Requeima, Alexandre Lacoste, Irina Rish, Nicolas Chapados, Alexandre Drouin</dc:creator>
        <description><![CDATA[
            背景：预测是各领域决策中的关键任务，历史数值数据无法提供完整背景，而自然语言能传达额外信息，但大语言模型有效整合文本信息的能力存疑。方法：引入“Context is Key”（CiK）时间序列预测基准，将数值数据与精心设计的文本背景配对，评估多种方法并提出简单有效的大语言模型提示方法。效果：该提示方法在基准测试中优于其他方法，实验凸显整合文本信息的重要性，也揭示了大语言模型的一些关键缺陷。
            arXiv:2410.18959v4 Announce Type: replace 
Abstract: Forecasting is a critical task in decision-making across numerous domains. While historical numerical data provide a start, they fail to convey the complete context for reliable and accurate predictions. Human forecasters frequently rely on additional information, such as background knowledge and constraints, which can efficiently be communicated through natural language. However, in spite of recent progress with LLM-based forecasters, their ability to effectively integrate this textual information remains an open question. To address this, we introduce "Context is Key" (CiK), a time-series forecasting benchmark that pairs numerical data with diverse types of carefully crafted textual context, requiring models to integrate both modalities; crucially, every task in CiK requires understanding textual context to be solved successfully. We evaluate a range of approaches, including statistical models, time series foundation models, and LLM-based forecasters, and propose a simple yet effective LLM prompting method that outperforms all other tested methods on our benchmark. Our experiments highlight the importance of incorporating contextual information, demonstrate surprising performance when using LLM-based forecasting models, and also reveal some of their critical shortcomings. This benchmark aims to advance multimodal forecasting by promoting models that are both accurate and accessible to decision-makers with varied technical expertise. The benchmark can be visualized at https://servicenow.github.io/context-is-key-forecasting/v0/.
        ]]></description>
    </item>
    <item>
        <title>Focus On This, Not That! Steering LLMs with Adaptive Feature Specification</title>
        <link>https://arxiv.org/abs/2410.22944</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.22944v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tom A. Lamb, Adam Davies, Alasdair Paren, Philip H. S. Torr, Francesco Pinto</dc:creator>
        <description><![CDATA[
            背景：指令调优训练大语言模型虽有成效，但模型常利用训练数据中的虚假或有偏差特征，导致行为偏差，现有推理时引导模型行为的技术多为事后处理。方法：提出聚焦指令调优（FIT），训练大语言模型聚焦特定特征并忽略其他特征来生成响应。效果：在多个基准测试中，FIT能在推理时成功引导行为，通过增强核心任务信号和弱化虚假线索提高鲁棒性，抑制人口属性减轻社会偏差，且在分布变化和面对新特征时具有泛化性。
            arXiv:2410.22944v4 Announce Type: replace 
Abstract: Despite the success of Instruction Tuning (IT) in training large language models (LLMs), such models often leverage spurious or biased features learnt from their training data and can become misaligned, leading to undesired behaviours. While existing techniques can steer model behaviour at inference-time, they are often post-hoc and do not embed steering as an intrinsic model feature. In this work, we introduce Focus Instruction Tuning (FIT), which trains LLMs to condition their responses by focusing on specific features whilst ignoring others, leading to different behaviours based on what features are specified. Across diverse benchmarks, we demonstrate that FIT: (i) successfully steers behaviour at inference time; (ii) increases robustness by amplifying core task signals and down-weighting spurious cues; (iii) mitigates social bias by suppressing demographic attributes; and (iv) generalises under distribution shifts and to previously unseen focus features. FIT therefore offers a lightweight, intrinsic mechanism for building more robust, fair, and easily controllable LLMs.
        ]]></description>
    </item>
    <item>
        <title>What Happened in LLMs Layers when Trained for Fast vs. Slow Thinking: A Gradient Perspective</title>
        <link>https://arxiv.org/abs/2410.23743</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.23743v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ming Li, Yanhong Li, Tianyi Zhou</dc:creator>
        <description><![CDATA[
            该研究背景是探究大语言模型（LLMs）后训练的差异。方法上，从梯度视角研究不同训练模式（快速与慢速思考）对LLMs各层梯度的影响，还研究梯度模式能否反映不同思考路径训练时回答的正确性，并在非推理知识学习任务上进行类似分析。结果显示，无思维链的快速思考比详细思维链的慢速思考梯度更大、层间梯度差异更大，慢速思考梯度能区分正确和无关推理路径，非推理任务中增加回答长度不会产生类似慢速思考的效果，有助于理解LLM训练。
            arXiv:2410.23743v2 Announce Type: replace 
Abstract: What makes a difference in the post-training of LLMs? We investigate the training patterns of different layers in large language models (LLMs) through the lens of the gradient. We are specifically interested in how fast vs. slow thinking affects the layer-wise gradients, given the recent popularity of training LLMs on reasoning paths such as chain-of-thoughts (CoT) and process rewards. In our study, fast thinking without CoT leads to larger gradients and larger differences of gradients across layers than slow thinking (Detailed CoT), indicating the learning stability brought by the latter. Additionally, we study whether the gradient patterns can reflect the correctness of responses when training different LLMs using slow vs. fast thinking paths. The results show that the gradients of slow thinking can distinguish correct and irrelevant reasoning paths. As a comparison, we conduct similar gradient analyses on non-reasoning knowledge learning tasks, on which, however, trivially increasing the response length does not lead to similar behaviors of slow thinking. Our study strengthens fundamental understandings of LLM training and sheds novel insights on its efficiency and stability, which pave the way towards building a generalizable System-2 agent. Our code, data, and gradient statistics can be found in: https://github.com/MingLiiii/Layer_Gradient.
        ]]></description>
    </item>
    <item>
        <title>Failure Modes of LLMs for Causal Reasoning on Narratives</title>
        <link>https://arxiv.org/abs/2410.23884</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.23884v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Khurram Yamin, Shantanu Gupta, Gaurav R. Ghosal, Zachary C. Lipton, Bryan Wilder</dc:creator>
        <description><![CDATA[
            该研究聚焦大语言模型（LLMs）因果推理能力，以从叙事中推断因果关系为代表问题。研究发现，即便最先进的语言模型在叙事呈现和参数知识方面都依赖不可靠捷径，如按事件拓扑顺序判断因果，导致非因果顺序叙事时表现不佳，且在长叙事和多事件时难以进行长期因果推理，还过度依赖参数知识。通过合成实验和真实叙事评估验证了这些失败模式。研究还发现，显式生成因果图可提升性能，而简单思维链无效，为提升LLMs因果推理能力指明方向。
            arXiv:2410.23884v3 Announce Type: replace 
Abstract: In this work, we investigate the causal reasoning abilities of large language models (LLMs) through the representative problem of inferring causal relationships from narratives. We find that even state-of-the-art language models rely on unreliable shortcuts, both in terms of the narrative presentation and their parametric knowledge. For example, LLMs tend to determine causal relationships based on the topological ordering of events (i.e., earlier events cause later ones), resulting in lower performance whenever events are not narrated in their exact causal order. Similarly, we demonstrate that LLMs struggle with long-term causal reasoning and often fail when the narratives are long and contain many events. Additionally, we show LLMs appear to rely heavily on their parametric knowledge at the expense of reasoning over the provided narrative. This degrades their abilities whenever the narrative opposes parametric knowledge. We extensively validate these failure modes through carefully controlled synthetic experiments, as well as evaluations on real-world narratives. Finally, we observe that explicitly generating a causal graph generally improves performance while naive chain-of-thought is ineffective. Collectively, our results distill precise failure modes of current state-of-the-art models and can pave the way for future techniques to enhance causal reasoning in LLMs.
        ]]></description>
    </item>
    <item>
        <title>Autoformulation of Mathematical Optimization Models Using LLMs</title>
        <link>https://arxiv.org/abs/2411.01679</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2411.01679v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Nicol\'as Astorga, Tennison Liu, Yuanzhang Xiao, Mihaela van der Schaar</dc:creator>
        <description><![CDATA[
            背景：数学优化在各领域决策中至关重要，但将现实问题转化为优化模型难度大。方法：针对自动构建优化模型的三个核心挑战，提出利用大语言模型与蒙特卡罗树搜索的方法，利用优化建模的层次结构生成并探索可能的公式；引入符号剪枝消除等效搜索路径，用大语言模型评估部分公式以引导搜索。效果：在线性和混合整数规划基准测试中，大语言模型价值估计和符号剪枝技术使性能显著提升。
            arXiv:2411.01679v2 Announce Type: replace 
Abstract: Mathematical optimization is fundamental to decision-making across diverse domains, from operations research to healthcare. Yet, translating real-world problems into optimization models remains a difficult task, often demanding specialized expertise. This paper approaches the problem of $\textit{autoformulation}$: the automated creation of solver-ready optimization models from natural language problem descriptions. We identify three core challenges of autoformulation: $\textit{(1)}$ the vast, problem-dependent hypothesis space, $\textit{(2)}$ efficient and diverse exploration of this space under uncertainty, and $\textit{(3)}$ evaluation of formulation correctness against problem description. To address these challenges, we present a novel method leveraging $\textit{Large Language Models}$ (LLMs) with $\textit{Monte-Carlo Tree Search}$, exploiting the hierarchical nature of optimization modeling to generate and systematically explore possible formulations. To enhance search efficiency, we introduce symbolic pruning to eliminate trivially equivalent search paths (branches), and employ LLM-based evaluation of partial formulations to guide search. Empirical analysis on linear and mixed-integer programming benchmarks demonstrates our method's effectiveness, with significant performance gains from both LLM-based value estimation and symbolic pruning techniques.
        ]]></description>
    </item>
    <item>
        <title>GRAF: Graph Retrieval Augmented by Facts for Romanian Legal Multi-Choice Question Answering</title>
        <link>https://arxiv.org/abs/2412.04119</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2412.04119v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Cristian-George Cr\u{a}ciun, R\u{a}zvan-Alexandru Sm\u{a}du, Dumitru-Clementin Cercel, Mihaela-Claudia Cercel</dc:creator>
        <description><![CDATA[
            背景：预训练语言模型在NLP领域表现出色，法律领域的问答任务受关注。方法：本文针对低资源语言的法律多选问答任务，引入罗马尼亚法律多选问答数据集JuRO和法律语料库CROL，构建罗马尼亚语知识图谱Law - RoG，并提出基于事实增强的图检索方法GRAF。效果：GRAF与通用的SOTA方法相比取得有竞争力的结果，多数情况下表现更优。
            arXiv:2412.04119v3 Announce Type: replace 
Abstract: Pre-trained Language Models (PLMs) have shown remarkable performances in recent years, setting a new paradigm for NLP research and industry. The legal domain has received some attention from the NLP community partly due to its textual nature. Some tasks from this domain are represented by question-answering (QA) tasks. This work explores the legal domain Multiple-Choice QA (MCQA) for a low-resource language. The contribution of this work is multi-fold. We first introduce JuRO, the first openly available Romanian legal MCQA dataset, comprising three different examinations and a number of 10,836 total questions. Along with this dataset, we introduce CROL, an organized corpus of laws that has a total of 93 distinct documents with their modifications from 763 time spans, that we leveraged in this work for Information Retrieval (IR) techniques. Moreover, we are the first to propose Law-RoG, a Knowledge Graph (KG) for the Romanian language, and this KG is derived from the aforementioned corpus. Lastly, we propose a novel approach for MCQA, Graph Retrieval Augmented by Facts (GRAF), which achieves competitive results with generally accepted SOTA methods and even exceeds them in most settings.
        ]]></description>
    </item>
    <item>
        <title>OCRBench v2: An Improved Benchmark for Evaluating Large Multimodal Models on Visual Text Localization and Reasoning</title>
        <link>https://arxiv.org/abs/2501.00321</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2501.00321v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ling Fu, Zhebin Kuang, Jiajun Song, Mingxin Huang, Biao Yang, Yuzhe Li, Linghao Zhu, Qidi Luo, Xinyu Wang, Hao Lu, Zhang Li, Guozhi Tang, Bin Shan, Chunhui Lin, Qi Liu, Binghong Wu, Hao Feng, Hao Liu, Can Huang, Jingqun Tang, Wei Chen, Lianwen Jin, Yuliang Liu, Xiang Bai</dc:creator>
        <description><![CDATA[
            背景：评估大模态模型（LMMs）的光学字符识别（OCR）能力备受关注，但现有基准对LMMs在文本定位、手写内容提取和逻辑推理等任务的能力探索不足。方法：引入OCRBench v2，其任务更全面、场景覆盖更广且有完善评估指标，还构建含1500张手动标注图像的私有测试集。效果：经测试发现多数LMMs得分低于50分，存在五类局限，且公私测试集评估趋势一致，验证了OCRBench v2的可靠性。
            arXiv:2501.00321v2 Announce Type: replace 
Abstract: Scoring the Optical Character Recognition (OCR) capabilities of Large Multimodal Models (LMMs) has witnessed growing interest. Existing benchmarks have highlighted the impressive performance of LMMs in text recognition; however, their abilities in certain challenging tasks, such as text localization, handwritten content extraction, and logical reasoning, remain underexplored. To bridge this gap, we introduce OCRBench v2, a large-scale bilingual text-centric benchmark with currently the most comprehensive set of tasks (4x more tasks than the previous multi-scene benchmark OCRBench), the widest coverage of scenarios (31 diverse scenarios), and thorough evaluation metrics, with 10,000 human-verified question-answering pairs and a high proportion of difficult samples. Moreover, we construct a private test set with 1,500 manually annotated images. The consistent evaluation trends observed across both public and private test sets validate the OCRBench v2's reliability. After carefully benchmarking state-of-the-art LMMs, we find that most LMMs score below 50 (100 in total) and suffer from five-type limitations, including less frequently encountered text recognition, fine-grained perception, layout perception, complex element parsing, and logical reasoning. The project website is at: https://99franklin.github.io/ocrbench_v2/
        ]]></description>
    </item>
    <item>
        <title>The Lessons of Developing Process Reward Models in Mathematical Reasoning</title>
        <link>https://arxiv.org/abs/2501.07301</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2501.07301v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhenru Zhang, Chujie Zheng, Yangzhen Wu, Beichen Zhang, Runji Lin, Bowen Yu, Dayiheng Liu, Jingren Zhou, Junyang Lin</dc:creator>
        <description><![CDATA[
            背景：过程奖励模型（PRMs）在大语言模型数学推理过程监督中有应用前景，但开发有效PRMs面临数据标注和评估方法的挑战。方法：通过大量实验，指出基于蒙特卡罗（MC）估计的数据合成效果差，识别出传统Best-of-N（BoN）评估策略的潜在偏差，开发了共识过滤机制，整合MC估计与大语言模型评判，并倡导综合评估框架。效果：显著提升了模型性能和数据效率，发布的新PRM超越现有开源模型。
            arXiv:2501.07301v2 Announce Type: replace 
Abstract: Process Reward Models (PRMs) emerge as a promising approach for process supervision in mathematical reasoning of Large Language Models (LLMs), which aim to identify and mitigate intermediate errors in the reasoning processes. However, the development of effective PRMs faces significant challenges, particularly in data annotation and evaluation methodologies. In this paper, through extensive experiments, we demonstrate that commonly used Monte Carlo (MC) estimation-based data synthesis for PRMs typically yields inferior performance and generalization compared to LLM-as-a-judge and human annotation methods. MC estimation relies on completion models to evaluate current-step correctness, leading to inaccurate step verification. Furthermore, we identify potential biases in conventional Best-of-N (BoN) evaluation strategies for PRMs: (1) The unreliable policy models generate responses with correct answers but flawed processes, leading to a misalignment between the evaluation criteria of BoN and the PRM objectives of process verification. (2) The tolerance of PRMs of such responses leads to inflated BoN scores. (3) Existing PRMs have a significant proportion of minimum scores concentrated on the final answer steps, revealing the shift from process to outcome-based assessment in BoN Optimized PRMs. To address these challenges, we develop a consensus filtering mechanism that effectively integrates MC estimation with LLM-as-a-judge and advocates a more comprehensive evaluation framework that combines response-level and step-level metrics. Based on the mechanisms, we significantly improve both model performance and data efficiency in the BoN evaluation and the step-wise error identification task. Finally, we release a new state-of-the-art PRM that outperforms existing open-source alternatives and provides practical guidelines for future research in building process supervision models.
        ]]></description>
    </item>
    <item>
        <title>Text-to-CAD Generation Through Infusing Visual Feedback in Large Language Models</title>
        <link>https://arxiv.org/abs/2501.19054</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2501.19054v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ruiyu Wang, Yu Yuan, Shizhao Sun, Jiang Bian</dc:creator>
        <description><![CDATA[
            创建计算机辅助设计（CAD）模型需专业知识和大量精力，文本到CAD转换可简化这一过程。以往研究用参数序列监督训练，但CAD模型具多模态性，参数序列到视觉对象渲染是多对一，顺序和视觉信号对训练都很重要。本文提出CADFusion框架，以大语言模型为骨干，交替进行顺序学习和视觉反馈两阶段训练。实验表明，该框架在定性和定量上都显著提升了性能。
            arXiv:2501.19054v3 Announce Type: replace 
Abstract: Creating Computer-Aided Design (CAD) models requires significant expertise and effort. Text-to-CAD, which converts textual descriptions into CAD parametric sequences, is crucial in streamlining this process. Recent studies have utilized ground-truth parametric sequences, known as sequential signals, as supervision to achieve this goal. However, CAD models are inherently multimodal, comprising parametric sequences and corresponding rendered visual objects. Besides,the rendering process from parametric sequences to visual objects is many-to-one. Therefore, both sequential and visual signals are critical for effective training. In this work, we introduce CADFusion, a framework that uses Large Language Models (LLMs) as the backbone and alternates between two training stages: the sequential learning (SL) stage and the visual feedback (VF) stage. In the SL stage, we train LLMs using ground-truth parametric sequences, enabling the generation of logically coherent parametric sequences. In the VF stage, we reward parametric sequences that render into visually preferred objects and penalize those that do not, allowing LLMs to learn how rendered visual objects are perceived and evaluated. These two stages alternate throughout the training, ensuring balanced learning and preserving benefits of both signals. Experiments demonstrate that CADFusion significantly improves performance, both qualitatively and quantitatively.
        ]]></description>
    </item>
    <item>
        <title>Can Large Language Models Understand Intermediate Representations in Compilers?</title>
        <link>https://arxiv.org/abs/2502.06854</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.06854v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hailong Jiang, Jianfeng Zhu, Yao Wan, Bo Fang, Hongyu Zhang, Ruoming Jin, Qiang Guan</dc:creator>
        <description><![CDATA[
            背景：中间表示（IRs）在编译器设计和程序分析中至关重要，但大语言模型（LLMs）对其理解的研究不足。方法：对GPT - 4等六种先进LLMs进行探索性实证研究，评估它们在控制流图重建等四项核心任务中的表现。效果：LLMs能解析IR语法和识别高层结构，但在指令级推理上存在困难，常见错误包括误解分支指令等。建议在结构化IR数据集上微调模型、集成控制流敏感架构以提升效果。
            arXiv:2502.06854v2 Announce Type: replace 
Abstract: Intermediate Representations (IRs) play a critical role in compiler design and program analysis, yet their comprehension by Large Language Models (LLMs) remains underexplored. In this paper, we present an explorative empirical study evaluating the capabilities of six state-of-the-art LLMs: GPT-4, GPT-3, DeepSeek, Gemma 2, Llama 3, and Code Llama, in understanding IRs. Specifically, we assess model performance across four core tasks: control flow graph reconstruction, decompilation, code summarization, and execution reasoning. While LLMs exhibit competence in parsing IR syntax and identifying high-level structures, they consistently struggle with instruction-level reasoning, especially in control flow reasoning, loop handling, and dynamic execution. Common failure modes include misinterpreting branching instructions, omitting critical operations, and relying on heuristic reasoning rather than precise instruction-level logic. Our findings highlight the need for IR-specific enhancements in LLM design. We recommend fine-tuning on structured IR datasets and integrating control-flow-sensitive architectures to improve model effectiveness. All experimental data and source code are publicly available at
        ]]></description>
    </item>
    <item>
        <title>CurvGAD: Leveraging Curvature for Enhanced Graph Anomaly Detection</title>
        <link>https://arxiv.org/abs/2502.08605</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.08605v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Karish Grover, Geoffrey J. Gordon, Christos Faloutsos</dc:creator>
        <description><![CDATA[
            背景：基于重建的图异常检测（GAD）方法忽略了复杂网络的内在曲率，仅关注结构和属性层面的异常。方法：提出CurvGAD，即混合曲率图自编码器，引入基于曲率的几何异常概念，设置两条并行管道，分别进行曲率等变几何重建和曲率不变结构与属性重建。效果：该方法细化了现有的异常分类，能识别新的曲率驱动异常，在10个真实数据集上比现有GAD方法最多提升6.5%。
            arXiv:2502.08605v2 Announce Type: replace 
Abstract: Does the intrinsic curvature of complex networks hold the key to unveiling graph anomalies that conventional approaches overlook? Reconstruction-based graph anomaly detection (GAD) methods overlook such geometric outliers, focusing only on structural and attribute-level anomalies. To this end, we propose CurvGAD - a mixed-curvature graph autoencoder that introduces the notion of curvature-based geometric anomalies. CurvGAD introduces two parallel pipelines for enhanced anomaly interpretability: (1) Curvature-equivariant geometry reconstruction, which focuses exclusively on reconstructing the edge curvatures using a mixed-curvature, Riemannian encoder and Gaussian kernel-based decoder; and (2) Curvature-invariant structure and attribute reconstruction, which decouples structural and attribute anomalies from geometric irregularities by regularizing graph curvature under discrete Ollivier-Ricci flow, thereby isolating the non-geometric anomalies. By leveraging curvature, CurvGAD refines the existing anomaly classifications and identifies new curvature-driven anomalies. Extensive experimentation over 10 real-world datasets (both homophilic and heterophilic) demonstrates an improvement of up to 6.5% over state-of-the-art GAD methods. The code is available at: https://github.com/karish-grover/curvgad.
        ]]></description>
    </item>
    <item>
        <title>Structural Alignment Improves Graph Test-Time Adaptation</title>
        <link>https://arxiv.org/abs/2502.18334</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.18334v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hans Hao-Hsun Hsu, Shikun Liu, Han Zhao, Pan Li</dc:creator>
        <description><![CDATA[
            图学习在多个领域表现出色，但在分布偏移时性能易下降，现有解决方法常需用源数据集重新训练，存在计算或隐私限制。本文提出Test-Time Structural Alignment (TSA)算法用于图测试时间自适应，在推理时对齐图结构且无需访问源数据。该算法采用三种策略：不确定性感知邻域加权、基于信噪比自适应平衡自节点和聚合邻域表示、决策边界细化。实验表明，TSA在合成和真实数据集上均优于非图TTA方法和现有GTTA基线。
            arXiv:2502.18334v3 Announce Type: replace 
Abstract: Graph-based learning excels at capturing interaction patterns in diverse domains like recommendation, fraud detection, and particle physics. However, its performance often degrades under distribution shifts, especially those altering network connectivity. Current methods to address these shifts typically require retraining with the source dataset, which is often infeasible due to computational or privacy limitations. We introduce Test-Time Structural Alignment (TSA), a novel algorithm for Graph Test-Time Adaptation (GTTA) that aligns graph structures during inference without accessing the source data. Grounded in a theoretical understanding of graph data distribution shifts, TSA employs three synergistic strategies: uncertainty-aware neighborhood weighting to accommodate neighbor label distribution shifts, adaptive balancing of self-node and aggregated neighborhood representations based on their signal-to-noise ratio, and decision boundary refinement to correct residual label and feature shifts. Extensive experiments on synthetic and real-world datasets demonstrate TSA's consistent outperformance of both non-graph TTA methods and state-of-the-art GTTA baselines.
        ]]></description>
    </item>
    <item>
        <title>On the Power of Context-Enhanced Learning in LLMs</title>
        <link>https://arxiv.org/abs/2503.01821</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.01821v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xingyu Zhu, Abhishek Panigrahi, Sanjeev Arora</dc:creator>
        <description><![CDATA[
            背景：大语言模型（LLMs）发展中需探索新学习概念。方法：提出上下文增强学习概念，在文本上进行标准基于梯度的学习，用额外数据增强上下文且不对其计算自回归梯度。效果：在简化设置中，当模型具备上下文学习（ICL）能力时，上下文增强学习比标准学习的样本效率呈指数级提升；从机制层面看，上下文增强的益处源于更准确的梯度学习信号；实验表明难以检测或恢复训练中用于上下文的学习材料，对数据安全和版权有影响。
            arXiv:2503.01821v2 Announce Type: replace 
Abstract: We formalize a new concept for LLMs, context-enhanced learning. It involves standard gradient-based learning on text except that the context is enhanced with additional data on which no auto-regressive gradients are computed. This setting is a gradient-based analog of usual in-context learning (ICL) and appears in some recent works. Using a multi-step reasoning task, we prove in a simplified setting that context-enhanced learning can be exponentially more sample-efficient than standard learning when the model is capable of ICL. At a mechanistic level, we find that the benefit of context-enhancement arises from a more accurate gradient learning signal. We also experimentally demonstrate that it appears hard to detect or recover learning materials that were used in the context during training. This may have implications for data security as well as copyright.
        ]]></description>
    </item>
    <item>
        <title>TinySQL: A Progressive Text-to-SQL Dataset for Mechanistic Interpretability Research</title>
        <link>https://arxiv.org/abs/2503.12730</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.12730v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Abir Harrasse, Philip Quirke, Clement Neo, Dhruv Nathawani, Amir Abdullah</dc:creator>
        <description><![CDATA[
            背景：机械可解释性研究在分析玩具任务简单电路与发现大模型特征之间存在差距。方法：提出文本到SQL生成作为研究任务，引入TinySQL合成数据集，训练不同参数模型搭建可解释性测试平台，应用多种互补可解释性技术识别支持SQL生成的最小电路和组件，比较不同SQL子技能电路，进行层间对数透镜分析。效果：揭示模型跨层构建SQL查询的过程，为在结构化、渐进复杂环境中探究和比较可解释性方法提供了强大框架。
            arXiv:2503.12730v2 Announce Type: replace 
Abstract: Mechanistic interpretability research faces a gap between analyzing simple circuits in toy tasks and discovering features in large models. To bridge this gap, we propose text-to-SQL generation as an ideal task to study, as it combines the formal structure of toy tasks with real-world complexity. We introduce TinySQL, a synthetic dataset, progressing from basic to advanced SQL operations, and train models ranging from 33M to 1B parameters to establish a comprehensive testbed for interpretability. We apply multiple complementary interpretability techniques, including Edge Attribution Patching and Sparse Autoencoders, to identify minimal circuits and components supporting SQL generation. We compare circuits for different SQL subskills, evaluating their minimality, reliability, and identifiability. Finally, we conduct a layerwise logit lens analysis to reveal how models compose SQL queries across layers: from intent recognition to schema resolution to structured generation. Our work provides a robust framework for probing and comparing interpretability methods in a structured, progressively complex setting.
        ]]></description>
    </item>
    <item>
        <title>Augmented Invertible Koopman Autoencoder for long-term time series forecasting</title>
        <link>https://arxiv.org/abs/2503.12930</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.12930v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Anthony Frion (Lab-STICC\_OSE, IMT Atlantique - MEE), Lucas Drumetz (IMT Atlantique - MEE, Lab-STICC\_OSE), Mauro Dalla Mura (GIPSA-SIGMAPHY), Guillaume Tochon (GIPSA-SIGMAPHY), Abdeldjalil A\"issa-El-Bey (IMT Atlantique - MEE, Lab-STICC\_COSYDE)</dc:creator>
        <description><![CDATA[
            背景：在动态模式分解及其众多扩展提出后，基于神经自编码器的Koopman算子实现被大量提出，其中可逆Koopman自编码器（IKAE）存在归一化流限制维度的问题。方法：提出用第二个非可逆编码器网络扩充潜在状态，得到新模型增强可逆Koopman自编码器（AIKAE）。效果：通过卫星图像时间序列及基于大回溯窗口观测预测的基准实验，证明了AIKAE在长期时间序列预测中的有效性。
            arXiv:2503.12930v2 Announce Type: replace 
Abstract: Following the introduction of Dynamic Mode Decomposition and its numerous extensions, many neural autoencoder-based implementations of the Koopman operator have recently been proposed. This class of methods appears to be of interest for modeling dynamical systems, either through direct long-term prediction of the evolution of the state or as a powerful embedding for downstream methods. In particular, a recent line of work has developed invertible Koopman autoencoders (IKAEs), which provide an exact reconstruction of the input state thanks to their analytically invertible encoder, based on coupling layer normalizing flow models. We identify that the conservation of the dimension imposed by the normalizing flows is a limitation for the IKAE models, and thus we propose to augment the latent state with a second, non-invertible encoder network. This results in our new model: the Augmented Invertible Koopman AutoEncoder (AIKAE). We demonstrate the relevance of the AIKAE through a series of long-term time series forecasting experiments, on satellite image time series as well as on a benchmark involving predictions based on a large lookback window of observations.
        ]]></description>
    </item>
    <item>
        <title>Intelligent4DSE: Optimizing High-Level Synthesis Design Space Exploration with Graph Neural Networks and Large Language Models</title>
        <link>https://arxiv.org/abs/2504.19649</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.19649v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Lei Xu, Shanshan Wang, Emmanuel Casseau, Chenglong Xiao</dc:creator>
        <description><![CDATA[
            背景：高级综合（HLS）设计空间探索（DSE）优化过程中，现有模型常忽视任务特性，进化算法需大量领域知识。方法：提出CoGNNs - LLMEA框架，集成具有任务自适应消息传递的图神经网络和大语言模型增强的进化算法，CoGNNs直接利用编译器前端处理后源代码生成的中间表示进行预测。效果：CoGNNs在HLS后结果质量预测中达最优，与基线模型相比，延迟平均预测误差降低2.8倍，资源利用率降低3.4倍。
            arXiv:2504.19649v2 Announce Type: replace 
Abstract: High-level synthesis (HLS) design space exploration (DSE) is an optimization process in electronic design automation (EDA) that systematically explores high-level design configurations to achieve Pareto-optimal hardware implementations balancing performance, area, and power (PPA). To optimize this process, HLS prediction tasks often employ message-passing neural networks (MPNNs), leveraging complex architectures to achieve high accuracy. These predictors serve as evaluators in the DSE process, effectively bypassing the time-consuming estimations traditionally required by HLS tools. However, existing models often prioritize structural complexity and minimization of training loss, overlooking task-specific characteristics. Additionally, while evolutionary algorithms are widely used in DSE, they typically require extensive domain-specific knowledge to design effective crossover and mutation operators. To address these limitations, we propose CoGNNs-LLMEA, a framework that integrates a graph neural network with task-adaptive message passing and a large language model-enhanced evolutionary algorithm. As a predictive model, CoGNNs directly leverages intermediate representations generated from source code after compiler front-end processing, enabling prediction of quality of results (QoR) without invoking HLS tools. Due to its strong adaptability to tasks, CoGNNs can be tuned to predict post-HLS and post-implementation outcomes, effectively bridging the gap between high-level abstractions and physical implementation characteristics. CoGNNs achieves state-of-the-art prediction accuracy in post-HLS QoR prediction, reducing mean prediction errors by 2.8$\times$ for latency and 3.4$\times$ for resource utilization compared to baseline models.
        ]]></description>
    </item>
    <item>
        <title>Optimizing Anytime Reasoning via Budget Relative Policy Optimization</title>
        <link>https://arxiv.org/abs/2505.13438</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13438v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Penghui Qi, Zichen Liu, Tianyu Pang, Chao Du, Wee Sun Lee, Min Lin</dc:creator>
        <description><![CDATA[
            提升大语言模型推理能力需扩展测试时计算量，现有强化学习方法仅在固定大令牌预算下优化最终性能，影响训练和部署效率。本文提出AnytimeReasoner框架优化随时推理性能，通过截断思考过程以适应不同令牌预算，引入可验证密集奖励，解耦优化思考和总结策略。还提出预算相对策略优化（BRPO）技术提升学习效率。数学推理任务实证表明，该方法在各预算下均优于GRPO，提高训练和令牌效率。
            arXiv:2505.13438v2 Announce Type: replace 
Abstract: Scaling test-time compute is crucial for enhancing the reasoning capabilities of large language models (LLMs). Existing approaches typically employ reinforcement learning (RL) to maximize a verifiable reward obtained at the end of reasoning traces. However, such methods optimize only the final performance under a large and fixed token budget, which hinders efficiency in both training and deployment. In this work, we present a novel framework, AnytimeReasoner, to optimize anytime reasoning performance, which aims to improve token efficiency and the flexibility of reasoning under varying token budget constraints. To achieve this, we truncate the complete thinking process to fit within sampled token budgets from a prior distribution, compelling the model to summarize the optimal answer for each truncated thinking for verification. This introduces verifiable dense rewards into the reasoning process, facilitating more effective credit assignment in RL optimization. We then optimize the thinking and summary policies in a decoupled manner to maximize the cumulative reward. Additionally, we introduce a novel variance reduction technique, Budget Relative Policy Optimization (BRPO), to enhance the robustness and efficiency of the learning process when reinforcing the thinking policy. Empirical results in mathematical reasoning tasks demonstrate that our method consistently outperforms GRPO across all thinking budgets under various prior distributions, enhancing both training and token efficiency.
        ]]></description>
    </item>
    <item>
        <title>Distilling the Implicit Multi-Branch Structure in LLMs' Reasoning via Reinforcement Learning</title>
        <link>https://arxiv.org/abs/2505.16142</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.16142v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Shicheng Xu, Liang Pang, Yunchang Zhu, Jia Gu, Zihao Wei, Jingcheng Deng, Feiyang Pan, Huawei Shen, Xueqi Cheng</dc:creator>
        <description><![CDATA[
            这篇论文聚焦于提升小语言模型推理能力。背景是当前通过监督微调（SFT）从教师模型向学生模型提炼推理路径存在局限，无法有效传递真实推理的隐含多分支结构。方法上，提出基于强化学习的蒸馏框架RLKD，利用生成式结构奖励模型（GSRM）将推理路径转化为元推理 - 求解步骤并计算奖励，结合强化学习让学生模型内化多分支结构。实验表明，在仅使用0.1%数据的纯强化学习机制下，RLKD优于标准SFT - RL管道，挖掘出比基于SFT蒸馏更大的推理潜力。
            arXiv:2505.16142v2 Announce Type: replace 
Abstract: Distilling reasoning paths from teacher to student models via supervised fine-tuning (SFT) provides a shortcut for improving the reasoning ability of smaller Large Language Models (LLMs). However, the reasoning paths generated by teacher models often reflect only surface-level traces of their underlying authentic reasoning. Insights from cognitive neuroscience suggest that authentic reasoning involves a complex interweaving between meta-reasoning (which selects appropriate sub-problems from multiple candidates) and solving (which addresses the sub-problem). This implies authentic reasoning has an implicit multi-branch structure. Supervised fine-tuning collapses this rich structure into a flat sequence of token prediction in the teacher's reasoning path, preventing effective distillation of this structure to students. To address this limitation, we propose RLKD, a reinforcement learning (RL)-based distillation framework guided by a novel Generative Structure Reward Model (GSRM). Our GSRM converts reasoning paths into multiple meta-reasoning-solving steps and computes rewards to measure structural alignment between student and teacher reasoning. RLKD combines this reward with RL, enabling student LLMs to internalize the teacher's implicit multi-branch reasoning structure rather than merely mimicking fixed output paths. Experiments show RLKD surpasses standard SFT-RL pipelines even when trained on 0.1% of data under an RL-only regime, unlocking greater student reasoning potential than SFT-based distillation.
        ]]></description>
    </item>
    <item>
        <title>WiNGPT-3.0 Technical Report</title>
        <link>https://arxiv.org/abs/2505.17387</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17387v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Boqin Zhuang, Chenxiao Song, Huitong Lu, Jiacheng Qiao, Mingqian Liu, Mingxing Yu, Ping Hong, Rui Li, Xiaoxia Song, Xiangjun Xu, Xu Chen, Yaoyao Ma, Yujie Gao</dc:creator>
        <description><![CDATA[
            背景：当前大语言模型在医学推理等方面存在局限。方法：本报告聚焦开发320亿参数的WiNGPT - 3.0，采用多阶段训练管道，包括监督微调（SFT）和强化学习（RL），利用精心策划的长思维链（CoT）数据集等。效果：特定模型变体在MedCalc得66.6分、在MedQA - USMLE得87.1分，临床推理任务分数从58.1提升到62.5，表明少量数据的强化学习可提高医学推理准确性，为临床工作流等部署可信大模型奠定基础。
            arXiv:2505.17387v2 Announce Type: replace 
Abstract: Current Large Language Models (LLMs) exhibit significant limitations, notably in structured, interpretable, and verifiable medical reasoning, alongside practical deployment challenges related to computational resources and data privacy. This report focused on the development of WiNGPT-3.0, the 32-billion parameter LLMs, engineered with the objective of enhancing its capacity for medical reasoning and exploring its potential for effective integration within healthcare IT infrastructures. The broader aim is to advance towards clinically applicable models. The approach involved a multi-stage training pipeline tailored for general, medical, and clinical reasoning. This pipeline incorporated supervised fine-tuning (SFT) and reinforcement learning (RL), leveraging curated Long Chain-of-Thought (CoT) datasets, auxiliary reward models, and an evidence-based diagnostic chain simulation. WiNGPT-3.0 demonstrated strong performance: specific model variants achieved scores of 66.6 on MedCalc and 87.1 on MedQA-USMLE. Furthermore, targeted training improved performance on a clinical reasoning task from a baseline score of 58.1 to 62.5. These findings suggest that reinforcement learning, even when applied with a limited dataset of only a few thousand examples, can enhance medical reasoning accuracy. Crucially, this demonstration of RL's efficacy with limited data and computation paves the way for more trustworthy and practically deployable LLMs within clinical workflows and health information infrastructures.
        ]]></description>
    </item>
    <item>
        <title>Supervised Graph Contrastive Learning for Gene Regulatory Network</title>
        <link>https://arxiv.org/abs/2505.17786</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.17786v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sho Oshima, Yuji Okamoto, Taisei Tosaki, Ryosuke Kojima, Yasushi Okuno</dc:creator>
        <description><![CDATA[
            背景：图表示学习能利用图数据结构获取有意义的潜在空间，但现有图对比学习（GCL）方法在应用于基因调控网络（GRNs）时忽略了如基因敲除等有生物学意义的扰动。方法：提出SupGCL，一种新的GRNs的GCL方法，直接将基因敲除实验中的生物扰动作为监督，将利用非生物扰动的现有GCL方法扩展到利用基因敲除数据的概率模型。效果：在多种癌症患者的GRN数据集上应用，SupGCL在患者风险预测等下游任务上比现有基线表现更好。
            arXiv:2505.17786v2 Announce Type: replace 
Abstract: Graph representation learning is effective for obtaining a meaningful latent space utilizing the structure of graph data and is widely applied, including biological networks. In particular, Graph Contrastive Learning (GCL) has emerged as a powerful self-supervised method that relies on applying perturbations to graphs for data augmentation. However, when applying existing GCL methods to biological networks such as Gene Regulatory Networks (GRNs), they overlooked meaningful biologically relevant perturbations, e.g., gene knockdowns. In this study, we introduce SupGCL (Supervised Graph Contrastive Learning), a novel GCL method for GRNs that directly incorporates biological perturbations derived from gene knockdown experiments as the supervision. SupGCL mathematically extends existing GCL methods that utilize non-biological perturbations to probabilistic models that introduce actual biological gene perturbation utilizing gene knockdown data. Using the GRN representation obtained by our proposed method, our aim is to improve the performance of biological downstream tasks such as patient hazard prediction and disease subtype classification (graph-level task), and gene function classification (node-level task). We applied SupGCL on real GRN datasets derived from patients with multiple types of cancer, and in all experiments SupGCL achieves better performance than state-of-the-art baselines.
        ]]></description>
    </item>
    <item>
        <title>MetaGen Blended RAG: Unlocking Zero-Shot Precision for Specialized Domain Question-Answering</title>
        <link>https://arxiv.org/abs/2505.18247</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.18247v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kunal Sawarkar, Shivam R. Solanki, Abhilasha Mangal</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）在处理特定领域企业数据集时面临困难，各领域语义差异大，微调成本高且缺乏泛化性，实现零样本精度仍是挑战。方法：提出“MetaGen Blended RAG”，通过元数据生成管道和使用密集与稀疏向量的混合查询索引来增强语义检索器。效果：在生物医学PubMedQA数据集上，检索准确率达82%，RAG准确率达77%，超越先前零样本RAG基准，还能在其他数据集上表现出色，泛化性强。
            arXiv:2505.18247v2 Announce Type: replace 
Abstract: Retrieval-Augmented Generation (RAG) struggles with domain-specific enterprise datasets, often isolated behind firewalls and rich in complex, specialized terminology unseen by LLMs during pre-training. Semantic variability across domains like medicine, networking, or law hampers RAG's context precision, while fine-tuning solutions are costly, slow, and lack generalization as new data emerges. Achieving zero-shot precision with retrievers without fine-tuning still remains a key challenge. We introduce 'MetaGen Blended RAG', a novel enterprise search approach that enhances semantic retrievers through a metadata generation pipeline and hybrid query indexes using dense and sparse vectors. By leveraging key concepts, topics, and acronyms, our method creates metadata-enriched semantic indexes and boosted hybrid queries, delivering robust, scalable performance without fine-tuning. On the biomedical PubMedQA dataset, MetaGen Blended RAG achieves 82% retrieval accuracy and 77% RAG accuracy, surpassing all prior zero-shot RAG benchmarks and even rivaling fine-tuned models on that dataset, while also excelling on datasets like SQuAD and NQ. This approach redefines enterprise search using a new approach to building semantic retrievers with unmatched generalization across specialized domains.
        ]]></description>
    </item>
    <item>
        <title>MAVL: A Multilingual Audio-Video Lyrics Dataset for Animated Song Translation</title>
        <link>https://arxiv.org/abs/2505.18614</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.18614v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Woohyun Cho, Youngmin Kim, Sunghyun Lee, Youngjae Yu</dc:creator>
        <description><![CDATA[
            背景：歌词翻译需准确语义转换并保留音乐节奏等，在动画音乐剧中还需与视听线索对齐。方法：引入多语言音频 - 视频歌词基准MAVL，这是首个用于可演唱歌词翻译的多语言、多模态基准；提出Syllable - Constrained Audio - Video LLM with Chain - of - Thought SylAVL - CoT，利用视听线索并实施音节约束。效果：实验表明SylAVL - CoT在可演唱性和上下文准确性上显著优于基于文本的模型，凸显了多模态、多语言方法的价值。
            arXiv:2505.18614v2 Announce Type: replace 
Abstract: Lyrics translation requires both accurate semantic transfer and preservation of musical rhythm, syllabic structure, and poetic style. In animated musicals, the challenge intensifies due to alignment with visual and auditory cues. We introduce Multilingual Audio-Video Lyrics Benchmark for Animated Song Translation (MAVL), the first multilingual, multimodal benchmark for singable lyrics translation. By integrating text, audio, and video, MAVL enables richer and more expressive translations than text-only approaches. Building on this, we propose Syllable-Constrained Audio-Video LLM with Chain-of-Thought SylAVL-CoT, which leverages audio-video cues and enforces syllabic constraints to produce natural-sounding lyrics. Experimental results demonstrate that SylAVL-CoT significantly outperforms text-based models in singability and contextual accuracy, emphasizing the value of multimodal, multilingual approaches for lyrics translation.
        ]]></description>
    </item>
    <item>
        <title>Deriving Strategic Market Insights with Large Language Models: A Benchmark for Forward Counterfactual Generation</title>
        <link>https://arxiv.org/abs/2505.19430</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.19430v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Keane Ong, Rui Mao, Deeksha Varshney, Paul Pu Liang, Erik Cambria, Gianmarco Mengaldo</dc:creator>
        <description><![CDATA[
            背景：反事实推理中的前向反事实推理对动态金融市场决策有重要意义，但大规模执行存在挑战，大语言模型在该应用中尚未被探索。方法：引入新基准Fin - Force，通过整理金融新闻标题并提供结构化评估，支持基于大语言模型的前向反事实生成。效果：为探索和预测未来市场发展提供可扩展的自动化解决方案，通过实验评估了现有大语言模型和反事实生成方法，分析其局限并为未来研究提供见解。
            arXiv:2505.19430v2 Announce Type: replace 
Abstract: Counterfactual reasoning typically involves considering alternatives to actual events. While often applied to understand past events, a distinct form-forward counterfactual reasoning-focuses on anticipating plausible future developments. This type of reasoning is invaluable in dynamic financial markets, where anticipating market developments can powerfully unveil potential risks and opportunities for stakeholders, guiding their decision-making. However, performing this at scale is challenging due to the cognitive demands involved, underscoring the need for automated solutions. Large Language Models (LLMs) offer promise, but remain unexplored for this application. To address this gap, we introduce a novel benchmark, Fin-Force-FINancial FORward Counterfactual Evaluation. By curating financial news headlines and providing structured evaluation, Fin-Force supports LLM based forward counterfactual generation. This paves the way for scalable and automated solutions for exploring and anticipating future market developments, thereby providing structured insights for decision-making. Through experiments on Fin-Force, we evaluate state-of-the-art LLMs and counterfactual generation methods, analyzing their limitations and proposing insights for future research.
        ]]></description>
    </item>
    <item>
        <title>DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning</title>
        <link>https://arxiv.org/abs/2505.20241</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.20241v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qi Cao, Ruiyi Wang, Ruiyi Zhang, Sai Ashish Somayajula, Pengtao Xie</dc:creator>
        <description><![CDATA[
            推理提升了大语言模型在复杂任务上的表现，过程奖励模型（PRM）能对推理步骤进行细粒度评估并引导推理。但将其拓展到多模态大语言模型面临挑战，因多模态推理任务分布偏移严重，且现有数据集质量不均衡。为此，本文提出DreamPRM，采用双层优化的领域重加权训练框架。低层优化在多数据集上微调，高层优化在元学习数据集上评估更新领域权重。实验表明，它能提升现有多模态大语言模型性能，重加权策略优于数据选择方法。
            arXiv:2505.20241v2 Announce Type: replace 
Abstract: Reasoning has improved the performance of large language models (LLMs) on complicated tasks. Central to the current reasoning studies, Process Reward Models (PRMs) offer a fine-grained evaluation of intermediate reasoning steps and guide the reasoning process. However, extending PRMs to multimodal large language models (MLLMs) introduces challenges. Since multimodal reasoning covers a wider range of tasks compared to text-only scenarios, the resulting distribution shift from the training to testing sets is more severe, leading to greater generalization difficulty. Training a reliable multimodal PRM, therefore, demands large and diverse datasets to ensure sufficient coverage. However, current multimodal reasoning datasets suffer from quality imbalance, which degrades PRM performance and highlights the need for data selection strategy. To address the issues, we introduce DreamPRM, a domain-reweighted training framework for multimodal PRMs which employs bi-level optimization. In the lower-level optimization, DreamPRM performs fine-tuning on multiple datasets with domain weights, allowing the PRM to prioritize high-quality reasoning signals and alleviating the impact of dataset quality imbalance. In the upper-level optimization, the PRM is evaluated on a separate meta-learning dataset; this feedback updates the domain weights through an aggregation loss function, thereby improving the generalization capability of trained PRM. Extensive experiments on multiple multimodal reasoning benchmarks covering both mathematical and general reasoning show that test-time scaling with DreamPRM consistently improves performance of state-of-the-art MLLMs. Further comparisons reveal that DreamPRM's domain-reweighting strategy surpasses data selection methods and yields higher accuracy gains than existing test-time scaling approaches. Codes are available at https://github.com/coder-qicao/DreamPRM.
        ]]></description>
    </item>
    <item>
        <title>Rethinking Text-based Protein Understanding: Retrieval or LLM?</title>
        <link>https://arxiv.org/abs/2505.20354</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.20354v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Juntong Wu, Zijing Liu, He Cao, Hao Li, Bin Feng, Zishan Shu, Ke Yu, Li Yuan, Yu Li</dc:creator>
        <description><![CDATA[
            近年来，蛋白质 - 文本模型在蛋白质生成和理解方面备受关注。当前方法通过持续预训练和多模态对齐将蛋白质相关知识融入大语言模型，使模型能同时理解文本描述和蛋白质序列。但现有基准存在数据泄露问题，传统指标也无法准确评估模型性能。为此，研究团队重新组织数据集，引入基于生物实体的评估框架，还提出检索增强方法。该方法在蛋白质到文本生成任务上显著优于微调的大语言模型，在免训练场景下兼具准确性和效率。
            arXiv:2505.20354v2 Announce Type: replace 
Abstract: In recent years, protein-text models have gained significant attention for their potential in protein generation and understanding. Current approaches focus on integrating protein-related knowledge into large language models through continued pretraining and multi-modal alignment, enabling simultaneous comprehension of textual descriptions and protein sequences. Through a thorough analysis of existing model architectures and text-based protein understanding benchmarks, we identify significant data leakage issues present in current benchmarks. Moreover, conventional metrics derived from natural language processing fail to accurately assess the model's performance in this domain. To address these limitations, we reorganize existing datasets and introduce a novel evaluation framework based on biological entities. Motivated by our observation, we propose a retrieval-enhanced method, which significantly outperforms fine-tuned LLMs for protein-to-text generation and shows accuracy and efficiency in training-free scenarios. Our code and data can be seen at https://github.com/IDEA-XL/RAPM.
        ]]></description>
    </item>
    <item>
        <title>Breaking the Cloak! Unveiling Chinese Cloaked Toxicity with Homophone Graph and Toxic Lexicon</title>
        <link>https://arxiv.org/abs/2505.22184</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22184v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xuchen Ma, Jianxiang Yu, Wenming Shao, Bo Pang, Xiang Li</dc:creator>
        <description><![CDATA[
            背景：社交媒体平台上有毒内容增多，部分用户用谐音伪装规避审查，现有方法多针对英文文本，中文隐匿毒性揭示问题待解。方法：提出C²TU，先基于中文同形字和毒性词典进行子串匹配识别候选有毒词，再过滤非毒性候选并纠正伪装。开发基于BERT和大语言模型（LLMs）的过滤变体，利用文本序列完整语义揭示隐匿有毒词。效果：在两个中文毒性数据集上表现优异，F1分数最高超最佳竞品71%，准确率超35%。
            arXiv:2505.22184v2 Announce Type: replace 
Abstract: Social media platforms have experienced a significant rise in toxic content, including abusive language and discriminatory remarks, presenting growing challenges for content moderation. Some users evade censorship by deliberately disguising toxic words through homophonic cloak, which necessitates the task of unveiling cloaked toxicity. Existing methods are mostly designed for English texts, while Chinese cloaked toxicity unveiling has not been solved yet. To tackle the issue, we propose C$^2$TU, a novel training-free and prompt-free method for Chinese cloaked toxic content unveiling. It first employs substring matching to identify candidate toxic words based on Chinese homo-graph and toxic lexicon. Then it filters those candidates that are non-toxic and corrects cloaks to be their corresponding toxicities. Specifically, we develop two model variants for filtering, which are based on BERT and LLMs, respectively. For LLMs, we address the auto-regressive limitation in computing word occurrence probability and utilize the full semantic contexts of a text sequence to reveal cloaked toxic words. Extensive experiments demonstrate that C$^2$TU can achieve superior performance on two Chinese toxic datasets. In particular, our method outperforms the best competitor by up to 71% on the F1 score and 35% on accuracy, respectively. Our code and data are available at https://github.com/XDxc-cuber/C2TU-Chinese-cloaked-toxicity-unveiling.
        ]]></description>
    </item>
    <item>
        <title>MMBoundary: Advancing MLLM Knowledge Boundary Awareness through Reasoning Step Confidence Calibration</title>
        <link>https://arxiv.org/abs/2505.23224</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.23224v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhitao He, Sandeep Polisetty, Zhiyuan Fan, Yuchen Huang, Shujin Wu, Yi R. Fung</dc:creator>
        <description><![CDATA[
            近年来，多模态大语言模型虽有进展，但在多模态推理上面临挑战，以往对模型置信度的估计多关注整体响应，忽略推理步骤置信度，导致幻觉问题。本文提出MMBoundary框架，通过推理步骤置信度校准提升多模态大语言模型的知识边界感知能力。方法是结合文本和跨模态自奖励信号估计推理步骤置信度，先进行监督微调，再引入强化学习阶段。实验结果显示，该框架显著优于现有方法，多模态置信度校准误差平均降低7.5%，任务性能最多提升8.3%。
            arXiv:2505.23224v2 Announce Type: replace 
Abstract: In recent years, multimodal large language models (MLLMs) have made significant progress but continue to face inherent challenges in multimodal reasoning, which requires multi-level (e.g., perception, reasoning) and multi-granular (e.g., multi-step reasoning chain) advanced inferencing. Prior work on estimating model confidence tends to focus on the overall response for training and calibration, but fails to assess confidence in each reasoning step, leading to undesirable hallucination snowballing. In this work, we present MMBoundary, a novel framework that advances the knowledge boundary awareness of MLLMs through reasoning step confidence calibration. To achieve this, we propose to incorporate complementary textual and cross-modal self-rewarding signals to estimate confidence at each step of the MLLM reasoning process. In addition to supervised fine-tuning MLLM on this set of self-rewarded confidence estimation signal for initial confidence expression warm-up, we introduce a reinforcement learning stage with multiple reward functions for further aligning model knowledge and calibrating confidence at each reasoning step, enhancing reasoning chain self-correction. Empirical results show that MMBoundary significantly outperforms existing methods across diverse domain datasets and metrics, achieving an average of 7.5% reduction in multimodal confidence calibration errors and up to 8.3% improvement in task performance.
        ]]></description>
    </item>
    <item>
        <title>MoDoMoDo: Multi-Domain Data Mixtures for Multimodal LLM Reinforcement Learning</title>
        <link>https://arxiv.org/abs/2505.24871</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.24871v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yiqing Liang, Jielin Qiu, Wenhao Ding, Zuxin Liu, James Tompkin, Mengdi Xu, Mengzhou Xia, Zhengzhong Tu, Laixi Shi, Jiacheng Zhu</dc:creator>
        <description><![CDATA[
            背景：将基于可验证奖励的强化学习（RLVR）应用于多模态大语言模型（MLLMs）有重要意义，但多数据集训练存在目标冲突问题，需优化数据集混合策略。方法：提出多模态LLM RLVR的系统后训练框架，开发多数据集后训练的多模态RLVR框架，提出从数据混合分布预测强化学习微调结果并优化最佳混合的策略。效果：多领域RLVR训练结合混合预测策略可显著提升MLLM通用推理能力，最佳混合使模型在分布外基准测试上的准确率比均匀数据混合后训练的模型平均提高5.24%，比预微调基线总共提高20.74%。
            arXiv:2505.24871v2 Announce Type: replace 
Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has recently emerged as a powerful paradigm for post-training large language models (LLMs), achieving state-of-the-art performance on tasks with structured, verifiable answers. Applying RLVR to Multimodal LLMs (MLLMs) presents significant opportunities but is complicated by the broader, heterogeneous nature of vision-language tasks that demand nuanced visual, logical, and spatial capabilities. As such, training MLLMs using RLVR on multiple datasets could be beneficial but creates challenges with conflicting objectives from interaction among diverse datasets, highlighting the need for optimal dataset mixture strategies to improve generalization and reasoning. We introduce a systematic post-training framework for Multimodal LLM RLVR, featuring a rigorous data mixture problem formulation and benchmark implementation. Specifically, (1) We developed a multimodal RLVR framework for multi-dataset post-training by curating a dataset that contains different verifiable vision-language problems and enabling multi-domain online RL learning with different verifiable rewards; (2) We proposed a data mixture strategy that learns to predict the RL fine-tuning outcome from the data mixture distribution, and consequently optimizes the best mixture. Comprehensive experiments showcase that multi-domain RLVR training, when combined with mixture prediction strategies, can significantly boost MLLM general reasoning capacities. Our best mixture improves the post-trained model's accuracy on out-of-distribution benchmarks by an average of 5.24% compared to the same model post-trained with uniform data mixture, and by a total of 20.74% compared to the pre-finetuning baseline.
        ]]></description>
    </item>
    <item>
        <title>Retrieval-Augmented Generation as Noisy In-Context Learning: A Unified Theory and Risk Bounds</title>
        <link>https://arxiv.org/abs/2506.03100</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.03100v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yang Guo, Yutian Tao, Yifei Ming, Robert D. Nowak, Yingyu Liang</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）近年在借助外部知识辅助大语言模型方面取得诸多实证成功，但理论研究较少。方法：提出上下文线性回归中RAG的首个有限样本泛化界，推导精确的偏差 - 方差权衡，将检索文本视为依赖查询的有噪声上下文示例，引入均匀和非均匀RAG噪声来建模从训练数据和外部语料库的检索。效果：分析表明RAG泛化误差存在内在上限，通过在常见问答基准上实验证明了上下文学习和RAG的样本效率。
            arXiv:2506.03100v2 Announce Type: replace 
Abstract: Retrieval-augmented generation (RAG) has seen many empirical successes in recent years by aiding the LLM with external knowledge. However, its theoretical aspect has remained mostly unexplored. In this paper, we propose the first finite-sample generalization bound for RAG in in-context linear regression and derive an exact bias-variance tradeoff. Our framework views the retrieved texts as query-dependent noisy in-context examples and recovers the classical in-context learning (ICL) and standard RAG as the limit cases. Our analysis suggests that an intrinsic ceiling on generalization error exists on RAG as opposed to the ICL. Furthermore, our framework is able to model retrieval both from the training data and from external corpora by introducing uniform and non-uniform RAG noise. In line with our theory, we show the sample efficiency of ICL and RAG empirically with experiments on common QA benchmarks, such as Natural Questions and TriviaQA.
        ]]></description>
    </item>
    <item>
        <title>Geometric Visual Fusion Graph Neural Networks for Multi-Person Human-Object Interaction Recognition in Videos</title>
        <link>https://arxiv.org/abs/2506.03440</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.03440v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tanqiu Qiao, Ruochen Li, Frederick W. B. Li, Yoshiki Kubotani, Shigeo Morishima, Hubert P. H. Shum</dc:creator>
        <description><![CDATA[
            视频中的人体与物体交互（HOI）识别需理解视觉模式和几何关系，有效融合视觉和几何多模态特征存在挑战。为此提出几何视觉融合图神经网络（GeoVis - GNN），采用双注意力特征融合与相互依赖的实体图学习，从特定实体表征逐步实现高层次交互理解。还引入并发部分交互数据集（MPHOI - 120）应对复杂场景。大量实验表明，该方法在多种HOI场景中有效，取得了最先进的性能。
            arXiv:2506.03440v2 Announce Type: replace 
Abstract: Human-Object Interaction (HOI) recognition in videos requires understanding both visual patterns and geometric relationships as they evolve over time. Visual and geometric features offer complementary strengths. Visual features capture appearance context, while geometric features provide structural patterns. Effectively fusing these multimodal features without compromising their unique characteristics remains challenging. We observe that establishing robust, entity-specific representations before modeling interactions helps preserve the strengths of each modality. Therefore, we hypothesize that a bottom-up approach is crucial for effective multimodal fusion. Following this insight, we propose the Geometric Visual Fusion Graph Neural Network (GeoVis-GNN), which uses dual-attention feature fusion combined with interdependent entity graph learning. It progressively builds from entity-specific representations toward high-level interaction understanding. To advance HOI recognition to real-world scenarios, we introduce the Concurrent Partial Interaction Dataset (MPHOI-120). It captures dynamic multi-person interactions involving concurrent actions and partial engagement. This dataset helps address challenges like complex human-object dynamics and mutual occlusions. Extensive experiments demonstrate the effectiveness of our method across various HOI scenarios. These scenarios include two-person interactions, single-person activities, bimanual manipulations, and complex concurrent partial interactions. Our method achieves state-of-the-art performance.
        ]]></description>
    </item>
    <item>
        <title>Unleashing The Power of Pre-Trained Language Models for Irregularly Sampled Time Series</title>
        <link>https://arxiv.org/abs/2408.08328</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2408.08328v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Weijia Zhang, Chenlong Yin, Hao Liu, Hui Xiong</dc:creator>
        <description><![CDATA[
            预训练语言模型在自然语言处理领域取得显著进展，相关研究多聚焦规则采样时间序列，忽略了不规则采样时间序列（ISTS）独特挑战。为此，本文率先探索预训练语言模型用于ISTS分析的潜力。先研究ISTS的不同表示方法，再提出基于预训练语言模型的统一框架ISTS - PLM，集成了时间感知和变量感知模型。大量实验表明，ISTS - PLM采用结构化且有效的序列表示，在分类、插值等多种分析任务中达最优性能。
            arXiv:2408.08328v2 Announce Type: replace-cross 
Abstract: Pre-trained Language Models (PLMs), such as ChatGPT, have significantly advanced the field of natural language processing. This progress has inspired a series of innovative studies that explore the adaptation of PLMs to time series analysis, intending to create a unified foundation model that addresses various time series analytical tasks. However, these efforts predominantly focus on Regularly Sampled Time Series (RSTS), neglecting the unique challenges posed by Irregularly Sampled Time Series (ISTS), which are characterized by uneven sampling intervals and prevalent missing data. To bridge this gap, this work takes the first step in exploring the potential of PLMs for ISTS analysis. We begin by investigating the effect of various methods for representing ISTS, aiming to maximize the efficacy of PLMs in the analysis. Furthermore, we propose a unified PLM-based framework, named ISTS-PLM, to address diverse ISTS analytical tasks. It integrates novel time-aware and variable-aware PLMs tailored to tackle the intractable intra- and inter-time series modeling in ISTS. Finally, extensive experiments on a comprehensive benchmark demonstrate that the ISTS-PLM, utilizing a structured and effective series-based representation for ISTS, consistently achieves state-of-the-art performance across various analytical tasks, such as classification, interpolation, extrapolation, few-shot and zero-shot learning scenarios, spanning scientific domains like healthcare, biomechanics, and climate science.
        ]]></description>
    </item>
    <item>
        <title>Spatial-RAG: Spatial Retrieval Augmented Generation for Real-World Spatial Reasoning Questions</title>
        <link>https://arxiv.org/abs/2502.18470</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.18470v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Dazhou Yu, Riyang Bao, Ruiyu Ning, Jinghong Peng, Gengchen Mai, Liang Zhao</dc:creator>
        <description><![CDATA[
            背景：大语言模型在空间推理方面存在挑战，难以进行空间数据检索和推理。方法：提出空间检索增强生成（Spatial - RAG）框架，将稀疏空间检索（空间数据库）和密集语义检索（基于大语言模型的相似度）集成到空间任务中，采用多目标排序策略平衡空间约束和语义相关性，利用大语言模型引导的生成器确保回答的连贯性。效果：在真实旅游数据集实验中，Spatial - RAG显著提升了空间问答能力，缩小了大语言模型与空间智能的差距。
            arXiv:2502.18470v4 Announce Type: replace-cross 
Abstract: Spatial reasoning remains a challenge for Large Language Models (LLMs), which struggle with spatial data retrieval and reasoning. We propose Spatial Retrieval-Augmented Generation (Spatial-RAG), a framework that extends RAG to spatial tasks by integrating sparse spatial retrieval (spatial databases) and dense semantic retrieval (LLM-based similarity). A multi-objective ranking strategy balances spatial constraints and semantic relevance, while an LLM-guided generator ensures coherent responses. Experiments on a real-world tourism dataset show that Spatial-RAG significantly improves spatial question answering, bridging the gap between LLMs and spatial intelligence.
        ]]></description>
    </item>
    <item>
        <title>MM-PRM: Enhancing Multimodal Mathematical Reasoning with Scalable Step-Level Supervision</title>
        <link>https://arxiv.org/abs/2505.13427</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13427v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Lingxiao Du, Fanqing Meng, Zongkai Liu, Zhixiang Zhou, Ping Luo, Qiaosheng Zhang, Wenqi Shao</dc:creator>
        <description><![CDATA[
            多模态大语言模型在视觉 - 语言理解方面进步显著，但在复杂多步推理上存在不足，缺乏对中间推理步骤的细粒度监督。为此，提出MM - PRM，在全自动可扩展框架中训练过程奖励模型。先构建基于多样数学推理数据训练的MM - Policy，再创建含10000个多模态数学问题的MM - K12数据集作为种子数据，利用基于蒙特卡罗树搜索的流程生成超700k步级注释。该模型在多个基准测试中显著提升性能，证明过程监督可增强多模态推理系统的逻辑鲁棒性。
            arXiv:2505.13427v2 Announce Type: replace-cross 
Abstract: While Multimodal Large Language Models (MLLMs) have achieved impressive progress in vision-language understanding, they still struggle with complex multi-step reasoning, often producing logically inconsistent or partially correct solutions. A key limitation lies in the lack of fine-grained supervision over intermediate reasoning steps. To address this, we propose MM-PRM, a process reward model trained within a fully automated, scalable framework. We first build MM-Policy, a strong multimodal model trained on diverse mathematical reasoning data. Then, we construct MM-K12, a curated dataset of 10,000 multimodal math problems with verifiable answers, which serves as seed data. Leveraging a Monte Carlo Tree Search (MCTS)-based pipeline, we generate over 700k step-level annotations without human labeling. The resulting PRM is used to score candidate reasoning paths in the Best-of-N inference setup and achieves significant improvements across both in-domain (MM-K12 test set) and out-of-domain (OlympiadBench, MathVista, etc.) benchmarks. Further analysis confirms the effectiveness of soft labels, smaller learning rates, and path diversity in optimizing PRM performance. MM-PRM demonstrates that process supervision is a powerful tool for enhancing the logical robustness of multimodal reasoning systems. We release all our codes and data at https://github.com/ModalMinds/MM-PRM.
        ]]></description>
    </item>
    <item>
        <title>Domain Adaptation Method and Modality Gap Impact in Audio-Text Models for Prototypical Sound Classification</title>
        <link>https://arxiv.org/abs/2506.04376</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04376v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Emiliano Acevedo, Mart\'in Rocamora, Magdalena Fuentes</dc:creator>
        <description><![CDATA[
            音频-文本模型常用于零样本环境声音分类，可减少对标注数据的需求，但在有背景声源时性能会大幅下降。研究发现，性能下降主要由背景声景的信噪比水平导致，与背景类型无关。为此，提出一种新方法，在分类过程中量化并整合背景声源的影响，无需重新训练模型就能提升性能。该领域自适应技术提高了不同背景和信噪比条件下的分类准确率，缩小音频和文本嵌入之间的模态差距也有助于提升性能，且该方法在多种原型方法中具有良好的泛化性。
            arXiv:2506.04376v1 Announce Type: new 
Abstract: Audio-text models are widely used in zero-shot environmental sound classification as they alleviate the need for annotated data. However, we show that their performance severely drops in the presence of background sound sources. Our analysis reveals that this degradation is primarily driven by SNR levels of background soundscapes, and independent of background type. To address this, we propose a novel method that quantifies and integrates the contribution of background sources into the classification process, improving performance without requiring model retraining. Our domain adaptation technique enhances accuracy across various backgrounds and SNR conditions. Moreover, we analyze the modality gap between audio and text embeddings, showing that narrowing this gap improves classification performance. The method generalizes effectively across state-of-the-art prototypical approaches, showcasing its scalability and robustness for diverse environments.
        ]]></description>
    </item>
    <item>
        <title>Benchmarking Time-localized Explanations for Audio Classification Models</title>
        <link>https://arxiv.org/abs/2506.04391</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04391v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Cecilia Bola\~nos, Leonardo Pepino, Martin Meza, Luciana Ferrer</dc:creator>
        <description><![CDATA[
            背景：现代音频处理方法大多不透明，虽有解释模型输出的方法，但评估解释质量并非易事，因多数任务缺乏明确的参考解释。方法：提出一种音频分类模型的时间局部解释基准，用目标事件的时间注释作为真实解释的替代。利用该基准系统优化并比较多种模型无关的事后解释方法。效果：在某些情况下可获得近乎完美的解释，还能揭示虚假相关性。
            arXiv:2506.04391v1 Announce Type: new 
Abstract: Most modern approaches for audio processing are opaque, in the sense that they do not provide an explanation for their decisions. For this reason, various methods have been proposed to explain the outputs generated by these models. Good explanations can result in interesting insights about the data or the model, as well as increase trust in the system. Unfortunately, evaluating the quality of explanations is far from trivial since, for most tasks, there is no clear ground truth explanation to use as reference. In this work, we propose a benchmark for time-localized explanations for audio classification models that uses time annotations of target events as a proxy for ground truth explanations. We use this benchmark to systematically optimize and compare various approaches for model-agnostic post-hoc explanation, obtaining, in some cases, close to perfect explanations. Finally, we illustrate the utility of the explanations for uncovering spurious correlations.
        ]]></description>
    </item>
    <item>
        <title>Phi-Omni-ST: A multimodal language model for direct speech-to-speech translation</title>
        <link>https://arxiv.org/abs/2506.04392</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04392v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuxuan Hu, Haibin Wu, Ruchao Fan, Xiaofei Wang, Heng Lu, Yao Qian, Jinyu Li</dc:creator>
        <description><![CDATA[
            这是一篇关于音频生成领域可处理音频的大语言模型的研究。现有语音感知语言模型理解口语后生成文本响应，但高效生成语音输出是挑战。本文基于开源Phi - 4 MM模型构建了Phi - Omni - ST多模态大模型用于直接语音到语音翻译。该模型通过音频变压器头预测音频令牌生成翻译语音，再用流式声码器合成波形。在CVSS - C数据集上实验表明，它性能超现有基线模型，扩大训练数据和模型规模后，能达到当前最优模型水平。
            arXiv:2506.04392v1 Announce Type: new 
Abstract: Speech-aware language models (LMs) have demonstrated capabilities in understanding spoken language while generating text-based responses. However, enabling them to produce speech output efficiently and effectively remains a challenge. In this paper, we present Phi-Omni-ST, a multimodal LM for direct speech-to-speech translation (ST), built on the open-source Phi-4 MM model. Phi-Omni-ST extends its predecessor by generating translated speech using an audio transformer head that predicts audio tokens with a delay relative to text tokens, followed by a streaming vocoder for waveform synthesis. Our experimental results on the CVSS-C dataset demonstrate Phi-Omni-ST's superior performance, significantly surpassing existing baseline models trained on the same dataset. Furthermore, when we scale up the training data and the model size, Phi-Omni-ST reaches on-par performance with the current SOTA model.
        ]]></description>
    </item>
    <item>
        <title>Can we reconstruct a dysarthric voice with the large speech model Parler TTS?</title>
        <link>https://arxiv.org/abs/2506.04397</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04397v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ariadna Sanchez, Simon King</dc:creator>
        <description><![CDATA[
            背景：言语障碍使患者交流困难，个性化文本转语音是有吸引力的交流辅助手段。方法：尝试用大语音模型Parler TTS进行语音重建，生成构音障碍患者患病前的近似语音。为此整理数据集并标注相关信息，对模型进行微调。效果：模型能从具有挑战性的数据分布中学习生成语音，但在控制可懂度和保持一致说话人身份方面存在困难。论文还提出了改进该类模型可控性的未来方向。
            arXiv:2506.04397v1 Announce Type: new 
Abstract: Speech disorders can make communication hard or even impossible for those who develop them. Personalised Text-to-Speech is an attractive option as a communication aid. We attempt voice reconstruction using a large speech model, with which we generate an approximation of a dysarthric speaker's voice prior to the onset of their condition. In particular, we investigate whether a state-of-the-art large speech model, Parler TTS, can generate intelligible speech while maintaining speaker identity. We curate a dataset and annotate it with relevant speaker and intelligibility information, and use this to fine-tune the model. Our results show that the model can indeed learn to generate from the distribution of this challenging data, but struggles to control intelligibility and to maintain consistent speaker identity. We propose future directions to improve controllability of this class of model, for the voice reconstruction task.
        ]]></description>
    </item>
    <item>
        <title>Bringing Interpretability to Neural Audio Codecs</title>
        <link>https://arxiv.org/abs/2506.04492</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04492v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Samir Sadok, Julien Hauret, \'Eric Bavu</dc:creator>
        <description><![CDATA[
            背景：神经音频编解码器能利用Transformer高效建模音频，但其声学单元因训练目标侧重重建性能而缺乏可解释性。方法：本文提出两步法探索编解码器令牌中语音信息的编码，分析阶段深入了解内容、身份和音高等语音属性的编码方式，合成阶段训练AnCoGen网络对编解码器进行事后解释，直接从相应令牌中提取语音属性。
            arXiv:2506.04492v1 Announce Type: new 
Abstract: The advent of neural audio codecs has increased in popularity due to their potential for efficiently modeling audio with transformers. Such advanced codecs represent audio from a highly continuous waveform to low-sampled discrete units. In contrast to semantic units, acoustic units may lack interpretability because their training objectives primarily focus on reconstruction performance. This paper proposes a two-step approach to explore the encoding of speech information within the codec tokens. The primary goal of the analysis stage is to gain deeper insight into how speech attributes such as content, identity, and pitch are encoded. The synthesis stage then trains an AnCoGen network for post-hoc explanation of codecs to extract speech attributes from the respective tokens directly.
        ]]></description>
    </item>
    <item>
        <title>French Listening Tests for the Assessment of Intelligibility, Quality, and Identity of Body-Conducted Speech Enhancement</title>
        <link>https://arxiv.org/abs/2506.04495</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04495v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Thomas Joubaud, Julien Hauret, V\'eronique Zimpfer, \'Eric Bavu</dc:creator>
        <description><![CDATA[
            背景：需评估极端带宽扩展网络（EBEN）模型在体传导传感器上的效果。方法：利用Vibravox数据集，通过法语改良押韵测试评估可懂度，用MUSHRA协议评估语音质量，以A/B识别任务评估说话人身份保留情况，涉及不同性别说话人及多种传感器。效果：EBEN能提升语音质量和可懂度，对女性说话人喉部麦克风录音的说话人识别性能有轻微下降，还发现体传导语音中短时客观可懂度与感知质量存在关联，ECAPA2 - TDNN的说话人验证与识别性能相符，且无指标能可靠预测EBEN对可懂度的影响。
            arXiv:2506.04495v1 Announce Type: new 
Abstract: This study evaluates the Extreme Bandwidth Extension Network (EBEN) model on body-conduction sensors through listening tests. Using the Vibravox dataset, we assess intelligibility with a French Modified Rhyme Test, speech quality with a MUSHRA (MUltiple Stimuli with Hidden Reference and Anchor) protocol and speaker identity preservation with an A/B identification task. The experiments involved male and female speakers recorded with a forehead accelerometer, rigid in-ear and throat microphones. The results confirm that EBEN enhances both speech quality and intelligibility. It slightly degrades speaker identification performance when applied to female speakers' throat microphone recordings. The findings also demonstrate a correlation between Short-Time Objective Intelligibility (STOI) and perceived quality in body-conducted speech, while speaker verification using ECAPA2-TDNN aligns well with identification performance. No tested metric reliably predicts EBEN's effect on intelligibility.
        ]]></description>
    </item>
    <item>
        <title>Towards Efficient Speech-Text Jointly Decoding within One Speech Language Model</title>
        <link>https://arxiv.org/abs/2506.04518</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04518v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Haibin Wu, Yuxuan Hu, Ruchao Fan, Xiaofei Wang, Kenichi Kumatani, Bo Ren, Jianwei Yu, Heng Lu, Lijuan Wang, Yao Qian, Jinyu Li</dc:creator>
        <description><![CDATA[
            背景：语音语言模型为口语对话系统提供了新方向，语音 - 文本联合解码范式对性能、效率和对齐质量至关重要。方法：系统比较了交错和并行生成等代表性联合解码策略，提出新颖的早期停止交错（ESI）模式，并整理高质量问答数据集。效果：实验表明交错方法对齐效果最佳，但推理慢；ESI模式不仅显著加速解码，性能还有所提升，整理的数据集进一步提高了语音问答性能。
            arXiv:2506.04518v1 Announce Type: new 
Abstract: Speech language models (Speech LMs) enable end-to-end speech-text modelling within a single model, offering a promising direction for spoken dialogue systems. The choice of speech-text jointly decoding paradigm plays a critical role in performance, efficiency, and alignment quality. In this work, we systematically compare representative joint speech-text decoding strategies-including the interleaved, and parallel generation paradigms-under a controlled experimental setup using the same base language model, speech tokenizer and training data. Our results show that the interleaved approach achieves the best alignment. However it suffers from slow inference due to long token sequence length. To address this, we propose a novel early-stop interleaved (ESI) pattern that not only significantly accelerates decoding but also yields slightly better performance. Additionally, we curate high-quality question answering (QA) datasets to further improve speech QA performance.
        ]]></description>
    </item>
    <item>
        <title>LLM-based phoneme-to-grapheme for phoneme-based speech recognition</title>
        <link>https://arxiv.org/abs/2506.04711</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04711v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Te Ma, Min Bi, Saierdaer Yusuyin, Hao Huang, Zhijian Ou</dc:creator>
        <description><![CDATA[
            在自动语音识别（ASR）中，基于音素的多语言预训练和跨语言微调因数据效率高且结果有竞争力而受关注，但基于加权有限状态转换器（WFST）的解码存在管道复杂、无法利用大语言模型（LLM）的局限。为此，研究人员提出基于LLM的音素到字形（LLM - P2G）解码用于基于音素的ASR，包含语音到音素（S2P）和音素到字形（P2G）。针对级联S2P和P2G存在信息损失的问题，提出两种训练策略。实验结果显示，LLM - P2G在波兰语和德语的跨语言ASR中表现优于基于WFST的系统，相对字错率分别降低3.6%和6.9%。
            arXiv:2506.04711v1 Announce Type: new 
Abstract: In automatic speech recognition (ASR), phoneme-based multilingual pre-training and crosslingual fine-tuning is attractive for its high data efficiency and competitive results compared to subword-based models. However, Weighted Finite State Transducer (WFST) based decoding is limited by its complex pipeline and inability to leverage large language models (LLMs). Therefore, we propose LLM-based phoneme-to-grapheme (LLM-P2G) decoding for phoneme-based ASR, consisting of speech-to-phoneme (S2P) and phoneme-to-grapheme (P2G). A challenge is that there seems to have information loss in cascading S2P and P2G. To address this challenge, we propose two training strategies: data augmentation with noisy phonemes (DANP), and randomized top-$K$ marginalized (TKM) training and decoding. Our experimental results show that LLM-P2G outperforms WFST-based systems in crosslingual ASR for Polish and German, by relative WER reductions of 3.6% and 6.9% respectively.
        ]]></description>
    </item>
    <item>
        <title>Improving AI-generated music with user-guided training</title>
        <link>https://arxiv.org/abs/2506.04852</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04852v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Vishwa Mohan Singh, Sai Anirudh Aryasomayajula, Ahan Chatterjee, Beste Aydemir, Rifat Mehreen Amin</dc:creator>
        <description><![CDATA[
            这是一篇关于音频生成的论文。背景是现有AI音乐生成算法多在固定数据集上训练，难以准确响应个性化用户输入。方法上，提出基于用户交互的人机计算方法，聚合和选择用户评分作为损失函数微调模型，采用遗传算法结合用户反馈提升模型性能。效果方面，通过用户评分平均提升衡量，试点测试中，第一次迭代较基线平均评分提升0.2，第二次迭代较第一次再提升0.39。
            arXiv:2506.04852v1 Announce Type: new 
Abstract: AI music generation has advanced rapidly, with models like diffusion and autoregressive algorithms enabling high-fidelity outputs. These tools can alter styles, mix instruments, or isolate them. Since sound can be visualized as spectrograms, image-generation algorithms can be applied to generate novel music. However, these algorithms are typically trained on fixed datasets, which makes it challenging for them to interpret and respond to user input accurately. This is especially problematic because music is highly subjective and requires a level of personalization that image generation does not provide. In this work, we propose a human-computation approach to gradually improve the performance of these algorithms based on user interactions. The human-computation element involves aggregating and selecting user ratings to use as the loss function for fine-tuning the model. We employ a genetic algorithm that incorporates user feedback to enhance the baseline performance of a model initially trained on a fixed dataset. The effectiveness of this approach is measured by the average increase in user ratings with each iteration. In the pilot test, the first iteration showed an average rating increase of 0.2 compared to the baseline. The second iteration further improved upon this, achieving an additional increase of 0.39 over the first iteration.
        ]]></description>
    </item>
    <item>
        <title>Survey on the Evaluation of Generative Models in Music</title>
        <link>https://arxiv.org/abs/2506.05104</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.05104v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Alexander Lerch, Claire Arthur, Nick Bryan-Kinns, Corey Ford, Qianyi Sun, Ashvala Vinay</dc:creator>
        <description><![CDATA[
            近年来，音乐生成系统研究备受关注且发展迅速，对其进行系统评估的尝试众多。本文从跨学科角度对评估系统输出和模型可用性的常见目标、方法及指标进行综述，涵盖主观与客观、定性与定量、实证与计算等方法。同时从音乐学、工程学和人机交互角度探讨这些方法的优势与挑战，有助于全面了解音乐生成模型的评估情况。
            arXiv:2506.05104v1 Announce Type: new 
Abstract: Research on generative systems in music has seen considerable attention and growth in recent years. A variety of attempts have been made to systematically evaluate such systems. We provide an interdisciplinary review of the common evaluation targets, methodologies, and metrics for the evaluation of both system output and model usability, covering subjective and objective approaches, qualitative and quantitative approaches, as well as empirical and computational methods. We discuss the advantages and challenges of such approaches from a musicological, an engineering, and an HCI perspective.
        ]]></description>
    </item>
    <item>
        <title>MMSU: A Massive Multi-task Spoken Language Understanding and Reasoning Benchmark</title>
        <link>https://arxiv.org/abs/2506.04779</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.04779v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Dingdong Wang, Jincenzi Wu, Junan Li, Dongchao Yang, Xueyuan Chen, Tianhua Zhang, Helen Meng</dc:creator>
        <description><![CDATA[
            语音包含丰富声学信息，现有多模态语音大模型在自然语音细粒度感知和复杂推理能力待探索。为此，该研究推出MMSU基准，包含47个不同任务的5000个精心策划的音频 - 问答三元组，系统纳入多种语言现象。通过对14个先进语音大模型严格评估，发现现有模型有很大改进空间，为未来优化指明方向，也为口语理解综合评估树立新标准，助力开发更先进人机语音交互系统。
            arXiv:2506.04779v1 Announce Type: cross 
Abstract: Speech inherently contains rich acoustic information that extends far beyond the textual language. In real-world spoken language understanding, effective interpretation often requires integrating semantic meaning (e.g., content), paralinguistic features (e.g., emotions, speed, pitch) and phonological characteristics (e.g., prosody, intonation, rhythm), which are embedded in speech. While recent multimodal Speech Large Language Models (SpeechLLMs) have demonstrated remarkable capabilities in processing audio information, their ability to perform fine-grained perception and complex reasoning in natural speech remains largely unexplored. To address this gap, we introduce MMSU, a comprehensive benchmark designed specifically for understanding and reasoning in spoken language. MMSU comprises 5,000 meticulously curated audio-question-answer triplets across 47 distinct tasks. To ground our benchmark in linguistic theory, we systematically incorporate a wide range of linguistic phenomena, including phonetics, prosody, rhetoric, syntactics, semantics, and paralinguistics. Through a rigorous evaluation of 14 advanced SpeechLLMs, we identify substantial room for improvement in existing models, highlighting meaningful directions for future optimization. MMSU establishes a new standard for comprehensive assessment of spoken language understanding, providing valuable insights for developing more sophisticated human-AI speech interaction systems. MMSU benchmark is available at https://huggingface.co/datasets/ddwang2000/MMSU. Evaluation Code is available at https://github.com/dingdongwang/MMSU_Bench.
        ]]></description>
    </item>
    <item>
        <title>AudioLens: A Closer Look at Auditory Attribute Perception of Large Audio-Language Models</title>
        <link>https://arxiv.org/abs/2506.05140</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.05140v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chih-Kai Yang, Neo Ho, Yi-Jyun Lee, Hung-yi Lee</dc:creator>
        <description><![CDATA[
            理解大型音频语言模型（LALMs）内部机制对解释其行为和提升性能至关重要。该论文首次深入分析LALMs如何在内部感知和识别听觉属性。通过对三个先进LALMs应用词汇投影，追踪属性信息在各层和token位置的演变。发现识别失败时属性信息随层深度下降，且早期层解析属性与更高准确率相关。此外，LALMs预测属性主要依赖查询听觉输入而非聚合隐藏状态信息。基于此发现提出增强LALMs的方法，为听觉属性处理研究和模型改进提供了思路。
            arXiv:2506.05140v1 Announce Type: cross 
Abstract: Understanding the internal mechanisms of large audio-language models (LALMs) is crucial for interpreting their behavior and improving performance. This work presents the first in-depth analysis of how LALMs internally perceive and recognize auditory attributes. By applying vocabulary projection on three state-of-the-art LALMs, we track how attribute information evolves across layers and token positions. We find that attribute information generally decreases with layer depth when recognition fails, and that resolving attributes at earlier layers correlates with better accuracy. Moreover, LALMs heavily rely on querying auditory inputs for predicting attributes instead of aggregating necessary information in hidden states at attribute-mentioning positions. Based on our findings, we demonstrate a method to enhance LALMs. Our results offer insights into auditory attribute processing, paving the way for future improvements.
        ]]></description>
    </item>
    <item>
        <title>Evaluation of LLMs in Speech is Often Flawed: Test Set Contamination in Large Language Models for Speech Recognition</title>
        <link>https://arxiv.org/abs/2505.22251</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22251v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuan Tseng, Titouan Parcollet, Rogier van Dalen, Shucong Zhang, Sourav Bhattacharya</dc:creator>
        <description><![CDATA[
            背景：近期研究认为大语言模型（LLM）能提升语音任务表现，常引用LibriSpeech和Common Voice数据集的结果。方法：发现这两个数据集的评估集大量出现在公开LLM预训练语料库中，通过对比有无数据污染训练的LLM，以及基于LLM的语音识别器。效果：受污染的LLM更易生成训练时见过的测试句子，基于受污染LLM的语音识别器错误率差异细微，但对训练时见过的转录分配更高概率，表明少量数据污染会使LLM输出有偏差。
            arXiv:2505.22251v2 Announce Type: replace 
Abstract: Recent work suggests that large language models (LLMs) can improve performance of speech tasks compared to existing systems. To support their claims, results on LibriSpeech and Common Voice are often quoted. However, this work finds that a substantial amount of the LibriSpeech and Common Voice evaluation sets appear in public LLM pretraining corpora. This calls into question the reliability of findings drawn from these two datasets. To measure contamination impact, LLMs trained with/without contamination are compared. A contaminated LLM is more likely to generate test sentences it has seen during training. Then, speech recognisers based on LLMs are compared. They show only subtle error rate differences if the LLM is contaminated, but assign significantly higher probabilities to transcriptions seen during LLM training. Results show that LLM outputs can be biased by tiny amounts of data contamination, highlighting the importance of evaluating LLM-based speech systems with held-out data.
        ]]></description>
    </item>
    <item>
        <title>DGMO: Training-Free Audio Source Separation through Diffusion-Guided Mask Optimization</title>
        <link>https://arxiv.org/abs/2506.02858</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02858v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Geonyoung Lee, Geonhee Han, Paul Hongsuck Seo</dc:creator>
        <description><![CDATA[
            这是一篇关于音频源分离的研究。背景是现有语言查询音频源分离方法依赖特定任务训练，研究探索预训练扩散模型能否不经训练进行分离。方法上，提出无需训练的框架，分析朴素适配的局限后，提出扩散引导掩码优化（DGMO），在测试时优化频谱图掩码。效果方面，有效利用预训练扩散模型进行源分离，在无特定任务监督下取得有竞争力的性能，拓展了扩散模型在音频分离上的应用。
            arXiv:2506.02858v2 Announce Type: replace 
Abstract: Language-queried Audio Source Separation (LASS) enables open-vocabulary sound separation via natural language queries. While existing methods rely on task-specific training, we explore whether pretrained diffusion models, originally designed for audio generation, can inherently perform separation without further training. In this study, we introduce a training-free framework leveraging generative priors for zero-shot LASS. Analyzing naive adaptations, we identify key limitations arising from modality-specific challenges. To address these issues, we propose Diffusion-Guided Mask Optimization (DGMO), a test-time optimization framework that refines spectrogram masks for precise, input-aligned separation. Our approach effectively repurposes pretrained diffusion models for source separation, achieving competitive performance without task-specific supervision. This work expands the application of diffusion models beyond generation, establishing a new paradigm for zero-shot audio separation. The code is available at: https://wltschmrz.github.io/DGMO/
        ]]></description>
    </item>
    <item>
        <title>MMS-LLaMA: Efficient LLM-based Audio-Visual Speech Recognition with Minimal Multimodal Speech Tokens</title>
        <link>https://arxiv.org/abs/2503.11315</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.11315v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jeong Hun Yeo, Hyeongseop Rha, Se Jin Park, Yong Man Ro</dc:creator>
        <description><![CDATA[
            背景：视听语音识别在噪声环境中结合视听信息可实现鲁棒语音识别，但基于大语言模型（LLM）的相关系统因处理的视听语音时间分辨率高，计算成本大。方法：引入高效多模态语音LLM框架，采用早期AV融合模块整合特征、音频视觉语音Q - 前馈网络动态分配令牌、结合语音速率预测器调整令牌分配。效果：在LRS3数据集上，WER为0.72%，每秒仅用3.5个令牌，较之前框架减少86%令牌使用，减少35.7%的FLOPs，提升计算效率。
            arXiv:2503.11315v2 Announce Type: replace-cross 
Abstract: Audio-Visual Speech Recognition (AVSR) achieves robust speech recognition in noisy environments by combining auditory and visual information. However, recent Large Language Model (LLM) based AVSR systems incur high computational costs due to the high temporal resolution of audio-visual speech processed by LLMs. In this work, we introduce an efficient multimodal speech LLM framework that minimizes token length while preserving essential linguistic content. Our approach employs an early AV-fusion module for streamlined feature integration, an audio-visual speech Q-Former that dynamically allocates tokens based on input duration, and a refined query allocation strategy with a speech rate predictor to adjust token allocation according to speaking speed of each audio sample. Extensive experiments on the LRS3 dataset show that our method achieves state-of-the-art performance with a WER of 0.72% while using only 3.5 tokens per second. Moreover, our approach not only reduces token usage by 86% compared to the previous multimodal speech LLM framework, but also improves computational efficiency by reducing FLOPs by 35.7%.
        ]]></description>
    </item>
    <item>
        <title>Hearing Anywhere in Any Environment</title>
        <link>https://arxiv.org/abs/2504.10746</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.10746v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiulong Liu, Anurag Kumar, Paul Calamia, Sebastia V. Amengual, Calvin Murdock, Ishwarya Ananthabhotla, Philip Robinson, Eli Shlizerman, Vamsi Krishna Ithapu, Ruohan Gao</dc:creator>
        <description><![CDATA[
            在混合现实应用中，空间环境中的逼真声学体验对实现沉浸感至关重要。但现有大多数神经方法只能用于训练的单一环境，缺乏泛化能力。为此，研究团队提出xRIR框架用于跨房间房间脉冲响应（RIR）预测，结合几何特征提取器和RIR编码器。为评估该方法，引入含260个房间超30万RIR高保真模拟的ACOUSTICROOMS数据集。实验表明该方法远超一系列基线，且在四个真实环境验证中实现从模拟到真实的迁移，体现出泛化性和数据集的逼真性。
            arXiv:2504.10746v2 Announce Type: replace-cross 
Abstract: In mixed reality applications, a realistic acoustic experience in spatial environments is as crucial as the visual experience for achieving true immersion. Despite recent advances in neural approaches for Room Impulse Response (RIR) estimation, most existing methods are limited to the single environment on which they are trained, lacking the ability to generalize to new rooms with different geometries and surface materials. We aim to develop a unified model capable of reconstructing the spatial acoustic experience of any environment with minimum additional measurements. To this end, we present xRIR, a framework for cross-room RIR prediction. The core of our generalizable approach lies in combining a geometric feature extractor, which captures spatial context from panorama depth images, with a RIR encoder that extracts detailed acoustic features from only a few reference RIR samples. To evaluate our method, we introduce ACOUSTICROOMS, a new dataset featuring high-fidelity simulation of over 300,000 RIRs from 260 rooms. Experiments show that our method strongly outperforms a series of baselines. Furthermore, we successfully perform sim-to-real transfer by evaluating our model on four real-world environments, demonstrating the generalizability of our approach and the realism of our dataset.
        ]]></description>
    </item>
    <item>
        <title>Can Masked Autoencoders Also Listen to Birds?</title>
        <link>https://arxiv.org/abs/2504.12880</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.12880v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Lukas Rauch, Ren\'e Heinrich, Ilyass Moummad, Alexis Joly, Bernhard Sick, Christoph Scholz</dc:creator>
        <description><![CDATA[
            这是一篇关于音频分类的论文。背景是通用的Masked Autoencoders（MAEs）模型在细粒度音频领域泛化能力差，如鸟类声音分类。方法上，研究人员使用与AudioSet规模相当的BirdSet数据集，系统调整预训练方案、微调方法和冻结特征利用。结果显示，提出的Bird - MAE在BirdSet多标签分类基准中取得新的最优结果，其原型探测在MAP上比线性探测最高提升37%，与微调差距平均缩小至约3.3%，在少样本基准测试中也展现出强大能力。
            arXiv:2504.12880v2 Announce Type: replace-cross 
Abstract: Masked Autoencoders (MAEs) have shown competitive results in audio classification by learning rich semantic representations through an efficient self-supervised reconstruction task. However, general-purpose models fail to generalize well when applied directly to fine-grained audio domains. Specifically, bird-sound classification requires distinguishing subtle inter-species differences and managing high intra-species acoustic variability, thereby revealing the performance limitations of general-domain Audio-MAE models. This work demonstrates that bridging this domain gap requires more than domain-specific pretraining data; adapting the entire training pipeline is crucial. We systematically revisit and adapt the pretraining recipe, fine-tuning methods, and frozen feature utilization to bird sounds using BirdSet, a large-scale bioacoustic dataset comparable to AudioSet. Our resulting Bird-MAE achieves new state-of-the-art results in BirdSet's multi-label classification benchmark. Additionally, we introduce the parameter-efficient prototypical probing, enhancing the utility of frozen MAE representations and closely approaching fine-tuning performance in low-resource settings. Bird-MAE's prototypical probes outperform linear probing by up to 37%$_\text{p}$ in MAP and narrow the gap to fine-tuning to approximately 3.3%$_\text{p}$ on average across BirdSet downstream tasks. Bird-MAE also demonstrates robust few-shot capabilities with prototypical probing in our newly established few-shot benchmark on BirdSet, highlighting the potential of tailored self-supervised learning pipelines for fine-grained audio domains.
        ]]></description>
    </item>
    <item>
        <title>MAVL: A Multilingual Audio-Video Lyrics Dataset for Animated Song Translation</title>
        <link>https://arxiv.org/abs/2505.18614</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.18614v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Woohyun Cho, Youngmin Kim, Sunghyun Lee, Youngjae Yu</dc:creator>
        <description><![CDATA[
            背景：歌词翻译需准确传递语义并保留音乐节奏等，在动画音乐剧中还需与视听线索对齐。方法：引入多语言音视频歌词基准MAVL，这是首个用于可演唱歌词翻译的多语言、多模态基准；并提出Syllable - Constrained Audio - Video LLM with Chain - of - Thought SylAVL - CoT，利用视听线索并实施音节约束。效果：实验表明SylAVL - CoT在可演唱性和上下文准确性上显著优于基于文本的模型。
            arXiv:2505.18614v2 Announce Type: replace-cross 
Abstract: Lyrics translation requires both accurate semantic transfer and preservation of musical rhythm, syllabic structure, and poetic style. In animated musicals, the challenge intensifies due to alignment with visual and auditory cues. We introduce Multilingual Audio-Video Lyrics Benchmark for Animated Song Translation (MAVL), the first multilingual, multimodal benchmark for singable lyrics translation. By integrating text, audio, and video, MAVL enables richer and more expressive translations than text-only approaches. Building on this, we propose Syllable-Constrained Audio-Video LLM with Chain-of-Thought SylAVL-CoT, which leverages audio-video cues and enforces syllabic constraints to produce natural-sounding lyrics. Experimental results demonstrate that SylAVL-CoT significantly outperforms text-based models in singability and contextual accuracy, emphasizing the value of multimodal, multilingual approaches for lyrics translation.
        ]]></description>
    </item>
    <item>
        <title>NTPP: Generative Speech Language Modeling for Dual-Channel Spoken Dialogue via Next-Token-Pair Prediction</title>
        <link>https://arxiv.org/abs/2506.00975</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.00975v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qichao Wang, Ziqiao Meng, Wenqian Cui, Yifei Zhang, Pengcheng Wu, Bingzhe Wu, Irwin King, Liang Chen, Peilin Zhao</dc:creator>
        <description><![CDATA[
            背景：受GPT - 4o启发，人们对让语音语言模型（SLMs）与人自然流畅对话兴趣渐浓，但现有方法未充分利用双通道语音数据。方法：系统探索在现代大语言模型中使用双通道语音数据，提出Next - Token - Pair Prediction（NTPP）生成建模范式，首次用仅解码器架构实现与说话者无关的双通道口语对话学习。效果：在标准基准测试中，NTPP显著提升SLMs对话能力，且推理延迟更低，适用于实时应用。
            arXiv:2506.00975v2 Announce Type: replace-cross 
Abstract: Inspired by the impressive capabilities of GPT-4o, there is growing interest in enabling speech language models (SLMs) to engage in natural, fluid spoken interactions with humans. Recent advancements have led to the development of several SLMs that demonstrate promising results in this area. However, current approaches have yet to fully exploit dual-channel speech data, which inherently captures the structure and dynamics of human conversation. In this work, we systematically explore the use of dual-channel speech data in the context of modern large language models, and introduce a novel generative modeling paradigm, Next-Token-Pair Prediction (NTPP), to enable speaker-independent dual-channel spoken dialogue learning using decoder-only architectures for the first time. We evaluate our approach on standard benchmarks, and empirical results show that our proposed method, NTPP, significantly improves the conversational abilities of SLMs in terms of turn-taking prediction, response coherence, and naturalness. Moreover, compared to existing methods, NTPP achieves substantially lower inference latency, highlighting its practical efficiency for real-time applications.
        ]]></description>
    </item>
</channel>
</rss>