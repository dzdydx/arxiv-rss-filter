<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
<channel>
    <title>arXiv Paper Filter</title>
    <link>https://github.com/None/arxiv_filter</link>
    <description>根据研究兴趣筛选的arXiv论文</description>
    <atom:link href="https://raw.githubusercontent.com/None/arxiv_filter/main/feed.xml" rel="self" type="application/rss+xml" />
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>zh-CN</language>
    <lastBuildDate>Wed, 21 May 2025 12:12:43 +0800</lastBuildDate>
    <managingEditor>None@github.com</managingEditor>
    <pubDate>Wed, 21 May 2025 12:12:43 +0800</pubDate>
    <skipDays>
        <day>Saturday</day>
        <day>Sunday</day>
    </skipDays>

    <item>
        <title>OMGPT: A Sequence Modeling Framework for Data-driven Operational Decision Making</title>
        <link>https://arxiv.org/abs/2505.13580</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13580v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hanzhao Wang, Guanting Chen, Kalyan Talluri, Xiaocheng Li</dc:creator>
        <description><![CDATA[
            背景：运筹学和管理科学中存在序列决策任务。方法：提出通用序列建模框架涵盖动态定价等任务，将其视为序列预测问题；从零构建基于Transformer的神经网络模型OMGPT进行序列建模，并从贝叶斯视角理解其工作机制。效果：与现有方法相比有范式转变，能利用大量预训练数据且不预设分析模型结构；在上述任务中表现出色。 
            arXiv:2505.13580v1 Announce Type: new 
Abstract: We build a Generative Pre-trained Transformer (GPT) model from scratch to solve sequential decision making tasks arising in contexts of operations research and management science which we call OMGPT. We first propose a general sequence modeling framework to cover several operational decision making tasks as special cases, such as dynamic pricing, inventory management, resource allocation, and queueing control. Under the framework, all these tasks can be viewed as a sequential prediction problem where the goal is to predict the optimal future action given all the historical information. Then we train a transformer-based neural network model (OMGPT) as a natural and powerful architecture for sequential modeling. This marks a paradigm shift compared to the existing methods for these OR/OM tasks in that (i) the OMGPT model can take advantage of the huge amount of pre-trained data; (ii) when tackling these problems, OMGPT does not assume any analytical model structure and enables a direct and rich mapping from the history to the future actions. Either of these two aspects, to the best of our knowledge, is not achieved by any existing method. We establish a Bayesian perspective to theoretically understand the working mechanism of the OMGPT on these tasks, which relates its performance with the pre-training task diversity and the divergence between the testing task and pre-training tasks. Numerically, we observe a surprising performance of the proposed model across all the above tasks.
        ]]></description>
    </item>
    <item>
        <title>Self-Reinforced Graph Contrastive Learning</title>
        <link>https://arxiv.org/abs/2505.13650</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13650v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chou-Ying Hsieh, Chun-Fu Jang, Cheng-En Hsieh, Qian-Hui Chen, Sy-Yen Kuo</dc:creator>
        <description><![CDATA[
            背景：图作为常见数据结构，在多领域应用广泛。图对比学习（GCL）可通过正负样本对学习图表示，但保证正样本对质量以保留图语义和结构信息是挑战。方法：提出SRGCL框架，用模型自身编码器动态评估和选择高质量正样本对，设计统一正样本对生成器和基于流形假设的选择器，采用概率机制选对。效果：在多种图分类任务实验中，SRGCL作为插件模块，性能超现有GCL方法，适应性和有效性强。
            arXiv:2505.13650v1 Announce Type: new 
Abstract: Graphs serve as versatile data structures in numerous real-world domains-including social networks, molecular biology, and knowledge graphs-by capturing intricate relational information among entities. Among graph-based learning techniques, Graph Contrastive Learning (GCL) has gained significant attention for its ability to derive robust, self-supervised graph representations through the contrasting of positive and negative sample pairs. However, a critical challenge lies in ensuring high-quality positive pairs so that the intrinsic semantic and structural properties of the original graph are preserved rather than distorted. To address this issue, we propose SRGCL (Self-Reinforced Graph Contrastive Learning), a novel framework that leverages the model's own encoder to dynamically evaluate and select high-quality positive pairs. We designed a unified positive pair generator employing multiple augmentation strategies, and a selector guided by the manifold hypothesis to maintain the underlying geometry of the latent space. By adopting a probabilistic mechanism for selecting positive pairs, SRGCL iteratively refines its assessment of pair quality as the encoder's representational power improves. Extensive experiments on diverse graph-level classification tasks demonstrate that SRGCL, as a plug-in module, consistently outperforms state-of-the-art GCL methods, underscoring its adaptability and efficacy across various domains.
        ]]></description>
    </item>
    <item>
        <title>SQLForge: Synthesizing Reliable and Diverse Data to Enhance Text-to-SQL Reasoning in LLMs</title>
        <link>https://arxiv.org/abs/2505.13725</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13725v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yu Guo, Dong Jin, Shenghao Ye, Shuangwu Chen, Jian Yang, Xiaobin Tan</dc:creator>
        <description><![CDATA[
            背景：大语言模型在文本到SQL推理任务中有潜力，但开源模型与闭源模型存在性能差距。方法：提出SQLForge方法，通过SQL语法约束和反向翻译提高数据可靠性，用模板富集和迭代探索机制提升数据多样性，基于增强数据微调多种开源模型得到SQLForge - LM。效果：在Spider和BIRD基准测试中，SQLForge - LM在开源模型里达最优，在Spider Dev上EX准确率85.7%，BIRD Dev上59.8%，大幅缩小与闭源方法的差距。
            arXiv:2505.13725v1 Announce Type: new 
Abstract: Large Language models (LLMs) have demonstrated significant potential in text-to-SQL reasoning tasks, yet a substantial performance gap persists between existing open-source models and their closed-source counterparts. In this paper, we introduce SQLForge, a novel approach for synthesizing reliable and diverse data to enhance text-to-SQL reasoning in LLMs. We improve data reliability through SQL syntax constraints and SQL-to-question reverse translation, ensuring data logic at both structural and semantic levels. We also propose an SQL template enrichment and iterative data domain exploration mechanism to boost data diversity. Building on the augmented data, we fine-tune a variety of open-source models with different architectures and parameter sizes, resulting in a family of models termed SQLForge-LM. SQLForge-LM achieves the state-of-the-art performance on the widely recognized Spider and BIRD benchmarks among the open-source models. Specifically, SQLForge-LM achieves EX accuracy of 85.7% on Spider Dev and 59.8% on BIRD Dev, significantly narrowing the performance gap with closed-source methods.
        ]]></description>
    </item>
    <item>
        <title>Beyond Semantics: The Unreasonable Effectiveness of Reasonless Intermediate Tokens</title>
        <link>https://arxiv.org/abs/2505.13775</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13775v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kaya Stechly, Karthik Valmeekam, Atharva Gundawar, Vardhan Palod, Subbarao Kambhampati</dc:creator>
        <description><![CDATA[
            背景：大型推理模型成果显著，思维链训练被认为是成功关键。方法：本文训练Transformer模型处理形式可验证的推理轨迹和解决方案，约束中间步骤和最终输出与形式求解器一致，构建形式解释器评估解决方案和中间轨迹的正确性。效果：即便基于完全正确的轨迹训练，模型得出正确解时中间轨迹仍可能无效；用不相关的噪声轨迹训练，性能与正确数据训练相当，部分情况更好，泛化性更强，挑战了思维链诱导可预测推理行为的假设。
            arXiv:2505.13775v1 Announce Type: new 
Abstract: Recent impressive results from large reasoning models have been interpreted as a triumph of Chain of Thought (CoT), and especially of the process of training on CoTs sampled from base LLMs in order to help find new reasoning patterns. In this paper, we critically examine that interpretation by investigating how the semantics of intermediate tokens-often anthropomorphized as "thoughts" or reasoning traces and which are claimed to display behaviors like backtracking, self-verification etc.-actually influence model performance. We train transformer models on formally verifiable reasoning traces and solutions, constraining both intermediate steps and final outputs to align with those of a formal solver (in our case, A* search). By constructing a formal interpreter of the semantics of our problems and intended algorithm, we systematically evaluate not only solution accuracy but also the correctness of intermediate traces, thus allowing us to evaluate whether the latter causally influences the former. We notice that, despite significant improvements on the solution-only baseline, models trained on entirely correct traces still produce invalid reasoning traces when arriving at correct solutions. To further show that trace accuracy is only loosely connected to solution accuracy, we then train models on noisy, corrupted traces which have no relation to the specific problem each is paired with, and find that not only does performance remain largely consistent with models trained on correct data, but in some cases can improve upon it and generalize more robustly on out-of-distribution tasks. These results challenge the assumption that intermediate tokens or "Chains of Thought" induce predictable reasoning behaviors and caution against anthropomorphizing such outputs or over-interpreting them (despite their mostly correct forms) as evidence of human-like or algorithmic behaviors in language models.
        ]]></description>
    </item>
    <item>
        <title>Structured Agent Distillation for Large Language Model</title>
        <link>https://arxiv.org/abs/2505.13820</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13820v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jun Liu, Zhenglun Kong, Peiyan Dong, Changdi Yang, Tianqi Li, Hao Tang, Geng Yuan, Wei Niu, Wenbin Zhang, Pu Zhao, Xue Lin, Dong Huang, Yanzhi Wang</dc:creator>
        <description><![CDATA[
            背景：大语言模型作为决策代理虽能力强，但高推理成本和大模型尺寸限制了实际应用。方法：提出结构化代理蒸馏框架，将基于大语言模型的代理压缩成小的学生模型，把轨迹划分为{[REASON]}和{[ACT]}片段，应用特定片段损失使各组件与教师行为对齐。效果：在ALFWorld、HotPotQA - ReAct和WebShop上的实验表明，该方法持续优于基于标记和模仿学习的基线，实现显著压缩且性能损失极小。
            arXiv:2505.13820v1 Announce Type: new 
Abstract: Large language models (LLMs) exhibit strong capabilities as decision-making agents by interleaving reasoning and actions, as seen in ReAct-style frameworks. Yet, their practical deployment is constrained by high inference costs and large model sizes. We propose Structured Agent Distillation, a framework that compresses large LLM-based agents into smaller student models while preserving both reasoning fidelity and action consistency. Unlike standard token-level distillation, our method segments trajectories into {[REASON]} and {[ACT]} spans, applying segment-specific losses to align each component with the teacher's behavior. This structure-aware supervision enables compact agents to better replicate the teacher's decision process. Experiments on ALFWorld, HotPotQA-ReAct, and WebShop show that our approach consistently outperforms token-level and imitation learning baselines, achieving significant compression with minimal performance drop. Scaling and ablation results further highlight the importance of span-level alignment for efficient and deployable agents.
        ]]></description>
    </item>
    <item>
        <title>Code2Logic: Game-Code-Driven Data Synthesis for Enhancing VLMs General Reasoning</title>
        <link>https://arxiv.org/abs/2505.13886</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13886v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jingqi Tong, Jixin Tang, Hangcheng Li, Yurong Mou, Ming Zhang, Jun Zhao, Yanbo Wen, Fan Song, Jiahao Zhan, Yuyang Lu, Chaoran Tao, Zhiyuan Guo, Jizhou Yu, Tianhao Cheng, Changhao Jiang, Zhen Wang, Tao Liang, Zhihui Fei, Mingyang Wan, Guojun Ma, Weifeng Ge, Guanhua Chen, Tao Gui, Xipeng Qiu, Qi Zhang, Xuanjing Huang</dc:creator>
        <description><![CDATA[
            背景：视觉语言思维链数据稀缺，高质量视觉语言推理数据标注成本高。方法：提出Code2Logic，利用大语言模型适配游戏代码，通过代码执行自动获取推理过程和结果，开发GameQA数据集用于训练和评估视觉语言模型。效果：GameQA成本低、可扩展且具有挑战性。仅在游戏数据上训练的视觉语言模型展现出跨领域泛化能力，如Qwen2.5 - VL - 7B在7个视觉语言基准测试中性能提升2.33%。
            arXiv:2505.13886v1 Announce Type: new 
Abstract: Visual-language Chain-of-Thought (CoT) data resources are relatively scarce compared to text-only counterparts, limiting the improvement of reasoning capabilities in Vision Language Models (VLMs). However, high-quality vision-language reasoning data is expensive and labor-intensive to annotate. To address this issue, we leverage a promising resource: game code, which naturally contains logical structures and state transition processes. Therefore, we propose Code2Logic, a novel game-code-driven approach for multimodal reasoning data synthesis. Our approach leverages Large Language Models (LLMs) to adapt game code, enabling automatic acquisition of reasoning processes and results through code execution. Using the Code2Logic approach, we developed the GameQA dataset to train and evaluate VLMs. GameQA is cost-effective and scalable to produce, challenging for state-of-the-art models, and diverse with 30 games and 158 tasks. Surprisingly, despite training solely on game data, VLMs demonstrated out of domain generalization, specifically Qwen2.5-VL-7B improving performance by 2.33\% across 7 diverse vision-language benchmarks. Our code and dataset are available at https://github.com/tongjingqi/Code2Logic.
        ]]></description>
    </item>
    <item>
        <title>Mapping the Minds of LLMs: A Graph-Based Analysis of Reasoning LLM</title>
        <link>https://arxiv.org/abs/2505.13890</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13890v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhen Xiong, Yujun Cai, Zhecheng Li, Yiwei Wang</dc:creator>
        <description><![CDATA[
            背景：推理大语言模型（RLMs）虽有潜力，但存在表现不稳定等问题，挑战当前认知。方法：提出基于图的分析框架，先将长思维链输出聚类为语义连贯的推理步骤，再构建有向推理图捕捉步骤间依赖关系。效果：研究发现图的结构属性与推理准确率强相关，揭示提示策略会重塑RLMs内部推理结构影响任务结果，该框架能定量评估推理质量，为提示工程和认知分析提供见解。
            arXiv:2505.13890v1 Announce Type: new 
Abstract: Recent advances in test-time scaling have enabled Large Language Models (LLMs) to display sophisticated reasoning abilities via extended Chain-of-Thought (CoT) generation. Despite their potential, these Reasoning LLMs (RLMs) often demonstrate counterintuitive and unstable behaviors, such as performance degradation under few-shot prompting, that challenge our current understanding of RLMs. In this work, we introduce a unified graph-based analytical framework for better modeling the reasoning processes of RLMs. Our method first clusters long, verbose CoT outputs into semantically coherent reasoning steps, then constructs directed reasoning graphs to capture contextual and logical dependencies among these steps. Through comprehensive analysis across models and prompting regimes, we reveal that structural properties, such as exploration density, branching, and convergence ratios, strongly correlate with reasoning accuracy. Our findings demonstrate how prompting strategies substantially reshape the internal reasoning structure of RLMs, directly affecting task outcomes. The proposed framework not only enables quantitative evaluation of reasoning quality beyond conventional metrics but also provides practical insights for prompt engineering and the cognitive analysis of LLMs. Code and resources will be released to facilitate future research in this direction.
        ]]></description>
    </item>
    <item>
        <title>InfiGFusion: Graph-on-Logits Distillation via Efficient Gromov-Wasserstein for Model Fusion</title>
        <link>https://arxiv.org/abs/2505.13893</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13893v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuanyi Wang, Zhaoyi Yan, Yiming Zhang, Qi Zhou, Yanggan Gu, Fei Wu, Hongxia Yang</dc:creator>
        <description><![CDATA[
            背景：当前大语言模型融合工作中，基于logit的融合方法忽视语义依赖，影响不同生成行为模型的对齐。方法：提出InfiGFusion，采用图蒸馏损失（GLD），保留输出的前k个logit，聚合其外积形成全局共激活图，还设计排序近似法降低复杂度。效果：实验表明，GLD提升了融合质量和稳定性，InfiGFusion在11个基准测试中超越SOTA模型和基线，在复杂推理任务中优势明显，多步算术和因果判断分别提升35.6和37.06。
            arXiv:2505.13893v1 Announce Type: new 
Abstract: Recent advances in large language models (LLMs) have intensified efforts to fuse heterogeneous open-source models into a unified system that inherits their complementary strengths. Existing logit-based fusion methods maintain inference efficiency but treat vocabulary dimensions independently, overlooking semantic dependencies encoded by cross-dimension interactions. These dependencies reflect how token types interact under a model's internal reasoning and are essential for aligning models with diverse generation behaviors. To explicitly model these dependencies, we propose \textbf{InfiGFusion}, the first structure-aware fusion framework with a novel \textit{Graph-on-Logits Distillation} (GLD) loss. Specifically, we retain the top-$k$ logits per output and aggregate their outer products across sequence positions to form a global co-activation graph, where nodes represent vocabulary channels and edges quantify their joint activations. To ensure scalability and efficiency, we design a sorting-based closed-form approximation that reduces the original $O(n^4)$ cost of Gromov-Wasserstein distance to $O(n \log n)$, with provable approximation guarantees. Experiments across multiple fusion settings show that GLD consistently improves fusion quality and stability. InfiGFusion outperforms SOTA models and fusion baselines across 11 benchmarks spanning reasoning, coding, and mathematics. It shows particular strength in complex reasoning tasks, with +35.6 improvement on Multistep Arithmetic and +37.06 on Causal Judgement over SFT, demonstrating superior multi-step and relational inference.
        ]]></description>
    </item>
    <item>
        <title>DRP: Distilled Reasoning Pruning with Skill-aware Step Decomposition for Efficient Large Reasoning Models</title>
        <link>https://arxiv.org/abs/2505.13975</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13975v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuxuan Jiang, Dawei Li, Frank Ferraro</dc:creator>
        <description><![CDATA[
            背景：大型推理模型（LRMs）通过长思维链推理在复杂推理任务中取得成功，但推理轨迹冗长导致效率低下。方法：提出蒸馏推理剪枝（DRP）混合框架，结合推理时剪枝和基于调优的蒸馏策略，用教师模型进行技能感知的步骤分解和内容剪枝，再将剪枝后的推理路径蒸馏到学生模型。效果：在多个数学推理数据集上，DRP训练的模型在不牺牲准确率的情况下大幅提高了标记效率，如GSM8K平均标记使用从917降至328，准确率从91.7%提升至94.1%，AIME标记减少43%且性能无下降。
            arXiv:2505.13975v1 Announce Type: new 
Abstract: While Large Reasoning Models (LRMs) have demonstrated success in complex reasoning tasks through long chain-of-thought (CoT) reasoning, their inference often involves excessively verbose reasoning traces, resulting in substantial inefficiency. To address this, we propose Distilled Reasoning Pruning (DRP), a hybrid framework that combines inference-time pruning with tuning-based distillation, two widely used strategies for efficient reasoning. DRP uses a teacher model to perform skill-aware step decomposition and content pruning, and then distills the pruned reasoning paths into a student model, enabling it to reason both efficiently and accurately. Across several challenging mathematical reasoning datasets, we find that models trained with DRP achieve substantial improvements in token efficiency without sacrificing accuracy. Specifically, DRP reduces average token usage on GSM8K from 917 to 328 while improving accuracy from 91.7% to 94.1%, and achieves a 43% token reduction on AIME with no performance drop. Further analysis shows that aligning the reasoning structure of training CoTs with the student's reasoning capacity is critical for effective knowledge transfer and performance gains.
        ]]></description>
    </item>
    <item>
        <title>When LLMs meet open-world graph learning: a new perspective for unlabeled data uncertainty</title>
        <link>https://arxiv.org/abs/2505.13989</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13989v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yanzhe Wen, Xunkai Li, Qi Zhang, Zhu Lei, Guang Zeng, Rong-Hua Li, Guoren Wang</dc:creator>
        <description><![CDATA[
            背景：大语言模型推动了文本属性图（TAG）学习，但现有方法在开放世界场景中处理数据不确定性不足，尤其对有限标注和未知类节点处理不佳。方法：提出基于大语言模型的Open-world Graph Assistant（OGA）框架，结合自适应标签可追溯性（融合语义和拓扑以拒绝未知类）和图标签注释器，用新注释节点更新模型。效果：综合实验证明了OGA的有效性和实用性。
            arXiv:2505.13989v1 Announce Type: new 
Abstract: Recently, large language models (LLMs) have significantly advanced text-attributed graph (TAG) learning. However, existing methods inadequately handle data uncertainty in open-world scenarios, especially concerning limited labeling and unknown-class nodes. Prior solutions typically rely on isolated semantic or structural approaches for unknown-class rejection, lacking effective annotation pipelines. To address these limitations, we propose Open-world Graph Assistant (OGA), an LLM-based framework that combines adaptive label traceability, which integrates semantics and topology for unknown-class rejection, and a graph label annotator to enable model updates using newly annotated nodes. Comprehensive experiments demonstrate OGA's effectiveness and practicality.
        ]]></description>
    </item>
    <item>
        <title>Beyond Chains: Bridging Large Language Models and Knowledge Bases in Complex Question Answering</title>
        <link>https://arxiv.org/abs/2505.14099</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14099v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yihua Zhu, Qianying Liu, Akiko Aizawa, Hidetoshi Shimodaira</dc:creator>
        <description><![CDATA[
            背景：知识库问答（KBQA）用知识库结构化知识答自然语言问题，仅大语言模型（LLM）方法有知识过时等问题，基于链的KG - RAG方法局限于简单链式问题。方法：提出PDRR四阶段框架，先预测问题类型并将问题分解为结构化三元组，再从知识库检索信息，引导LLM推理完成分解的三元组。效果：实验表明，PDRR在多种LLM骨干上始终优于现有方法，在链式和非链式复杂问题上表现出色。
            arXiv:2505.14099v1 Announce Type: new 
Abstract: Knowledge Base Question Answering (KBQA) aims to answer natural language questions using structured knowledge from KBs. While LLM-only approaches offer generalization, they suffer from outdated knowledge, hallucinations, and lack of transparency. Chain-based KG-RAG methods address these issues by incorporating external KBs, but are limited to simple chain-structured questions due to the absence of planning and logical structuring. Inspired by semantic parsing methods, we propose PDRR: a four-stage framework consisting of Predict, Decompose, Retrieve, and Reason. Our method first predicts the question type and decomposes the question into structured triples. Then retrieves relevant information from KBs and guides the LLM as an agent to reason over and complete the decomposed triples. Experimental results demonstrate that PDRR consistently outperforms existing methods across various LLM backbones and achieves superior performance on both chain-structured and non-chain complex questions.
        ]]></description>
    </item>
    <item>
        <title>MultiHal: Multilingual Dataset for Knowledge-Graph Grounded Evaluation of LLM Hallucinations</title>
        <link>https://arxiv.org/abs/2505.14101</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14101v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ernests Lavrinovics, Russa Biswas, Katja Hose, Johannes Bjerva</dc:creator>
        <description><![CDATA[
            背景：大语言模型存在忠实性和事实性局限，即幻觉问题，现有评估基准多基于英文数据集且忽略结构化事实资源。方法：提出基于知识图谱的多语言、多跳基准MultiHal用于生成文本评估，从开放领域知识图谱中挖掘140k条知识图谱路径，筛选出25.9k条高质量路径。效果：基线评估显示，在多语言和多模型中，知识图谱检索增强生成（KG - RAG）的语义相似度得分比普通问答绝对提升约0.12 - 0.36分，展示了知识图谱集成的潜力。
            arXiv:2505.14101v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have inherent limitations of faithfulness and factuality, commonly referred to as hallucinations. Several benchmarks have been developed that provide a test bed for factuality evaluation within the context of English-centric datasets, while relying on supplementary informative context like web links or text passages but ignoring the available structured factual resources. To this end, Knowledge Graphs (KGs) have been identified as a useful aid for hallucination mitigation, as they provide a structured way to represent the facts about entities and their relations with minimal linguistic overhead. We bridge the lack of KG paths and multilinguality for factual language modeling within the existing hallucination evaluation benchmarks and propose a KG-based multilingual, multihop benchmark called \textbf{MultiHal} framed for generative text evaluation. As part of our data collection pipeline, we mined 140k KG-paths from open-domain KGs, from which we pruned noisy KG-paths, curating a high-quality subset of 25.9k. Our baseline evaluation shows an absolute scale increase by approximately 0.12 to 0.36 points for the semantic similarity score in KG-RAG over vanilla QA across multiple languages and multiple models, demonstrating the potential of KG integration. We anticipate MultiHal will foster future research towards several graph-based hallucination mitigation and fact-checking tasks.
        ]]></description>
    </item>
    <item>
        <title>Self-Reasoning Language Models: Unfold Hidden Reasoning Chains with Few Reasoning Catalyst</title>
        <link>https://arxiv.org/abs/2505.14116</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14116v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hongru Wang, Deng Cai, Wanjun Zhong, Shijue Huang, Jeff Z. Pan, Zeming Liu, Kam-Fai Wong</dc:creator>
        <description><![CDATA[
            背景：推理时扩展通过增加思维链长度提升大语言模型在复杂推理任务中的表现，但长的中间推理依据难创建和获取。方法：提出自推理语言模型（SRLM），利用少量示例作为推理催化剂，让模型合成更长思维链数据并通过自训练迭代提升性能。效果：在两个骨干模型的五项推理任务中，SRLM平均绝对提升超2.5分；推理时采样次数越多提升越大，64次采样时平均绝对提升7.89分。 
            arXiv:2505.14116v1 Announce Type: new 
Abstract: Inference-time scaling has attracted much attention which significantly enhance the performance of Large Language Models (LLMs) in complex reasoning tasks by increasing the length of Chain-of-Thought. These longer intermediate reasoning rationales embody various meta-reasoning skills in human cognition, such as reflection and decomposition, being difficult to create and acquire. In this work, we introduce \textit{Self-Reasoning Language Model} (SRLM), where the model itself can synthesize longer CoT data and iteratively improve performance through self-training. By incorporating a few demonstration examples (i.e., 1,000 samples) on how to unfold hidden reasoning chains from existing responses, which act as a reasoning catalyst, we demonstrate that SRLM not only enhances the model's initial performance but also ensures more stable and consistent improvements in subsequent iterations. Our proposed SRLM achieves an average absolute improvement of more than $+2.5$ points across five reasoning tasks: MMLU, GSM8K, ARC-C, HellaSwag, and BBH on two backbone models. Moreover, it brings more improvements with more times of sampling during inference, such as absolute $+7.89$ average improvement with $64$ sampling times, revealing the in-depth, diverse and creative reasoning paths in SRLM against the strong baseline.
        ]]></description>
    </item>
    <item>
        <title>MAS-KCL: Knowledge component graph structure learning with large language model-based agentic workflow</title>
        <link>https://arxiv.org/abs/2505.14126</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14126v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuan-Hao Jiang, Kezong Tang, Zi-Wei Chen, Yuang Wei, Tian-Yi Liu, Jiayi Wu</dc:creator>
        <description><![CDATA[
            背景：知识组件（KC）图可展示教育领域中KCs间的关系与依赖，准确的KC图能助力教育者精准干预教学。方法：提出MAS - KCL算法，利用大语言模型驱动的多智能体系统自适应修改和优化KC图，还集成双向反馈机制评估边的价值、调整生成概率分布。效果：在5个合成数据集和4个真实教育数据集上实验，验证了其在学习路径识别上的有效性，有助于教师设计更完善学习计划，推动教育可持续发展。
            arXiv:2505.14126v1 Announce Type: new 
Abstract: Knowledge components (KCs) are the fundamental units of knowledge in the field of education. A KC graph illustrates the relationships and dependencies between KCs. An accurate KC graph can assist educators in identifying the root causes of learners' poor performance on specific KCs, thereby enabling targeted instructional interventions. To achieve this, we have developed a KC graph structure learning algorithm, named MAS-KCL, which employs a multi-agent system driven by large language models for adaptive modification and optimization of the KC graph. Additionally, a bidirectional feedback mechanism is integrated into the algorithm, where AI agents leverage this mechanism to assess the value of edges within the KC graph and adjust the distribution of generation probabilities for different edges, thereby accelerating the efficiency of structure learning. We applied the proposed algorithm to 5 synthetic datasets and 4 real-world educational datasets, and experimental results validate its effectiveness in learning path recognition. By accurately identifying learners' learning paths, teachers are able to design more comprehensive learning plans, enabling learners to achieve their educational goals more effectively, thus promoting the sustainable development of education.
        ]]></description>
    </item>
    <item>
        <title>Texts or Images? A Fine-grained Analysis on the Effectiveness of Input Representations and Models for Table Question Answering</title>
        <link>https://arxiv.org/abs/2505.14131</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14131v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wei Zhou, Mohsen Mesgar, Heike Adel, Annemarie Friedrich</dc:creator>
        <description><![CDATA[
            背景：在表格问答（TQA）中，表格编码为文本或图像，此前研究表明多模态大语言模型（MLLMs）处理表格图像效果与大语言模型（LLMs）处理文本相当甚至更好，但缺乏对照实验。方法：从问题复杂度和表格大小两个角度，对表格表示和模型的几种组合进行对照研究，构建新基准，系统分析七组MLLMs和LLMs；提出动态选择表格表示的方法FRES。效果：与不加区分使用两种表示相比，平均性能提升10%。
            arXiv:2505.14131v1 Announce Type: new 
Abstract: In table question answering (TQA), tables are encoded as either texts or images. Prior work suggests that passing images of tables to multi-modal large language models (MLLMs) performs comparably to or even better than using textual input with large language models (LLMs). However, the lack of controlled setups limits fine-grained distinctions between these approaches. In this paper, we conduct the first controlled study on the effectiveness of several combinations of table representations and models from two perspectives: question complexity and table size. We build a new benchmark based on existing TQA datasets. In a systematic analysis of seven pairs of MLLMs and LLMs, we find that the best combination of table representation and model varies across setups. We propose FRES, a method selecting table representations dynamically, and observe a 10% average performance improvement compared to using both representations indiscriminately.
        ]]></description>
    </item>
    <item>
        <title>Unify Graph Learning with Text: Unleashing LLM Potentials for Session Search</title>
        <link>https://arxiv.org/abs/2505.14156</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14156v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Songhao Wu, Quan Tu, Hong Liu, Jia Xu, Zhongyi Liu, Guannan Zhang, Ran Wang, Xiuying Chen, Rui Yan</dc:creator>
        <description><![CDATA[
            背景：现有会话搜索策略多侧重序列建模或仅关注结构信息，忽略语义建模。方法：提出Symbolic Graph Ranker（SGR），利用大语言模型（LLMs）结合基于文本和图的方法，先引入符号语法规则将会话图转为文本，作为LLM输入；再设计自监督符号学习任务，使LLM从粗到细捕捉拓扑信息。效果：在AOL和Tiangong - ST两个基准数据集上实验，证实该方法优越性，为传统搜索策略和现代LLMs搭建有效桥梁。
            arXiv:2505.14156v1 Announce Type: new 
Abstract: Session search involves a series of interactive queries and actions to fulfill user's complex information need. Current strategies typically prioritize sequential modeling for deep semantic understanding, overlooking the graph structure in interactions. While some approaches focus on capturing structural information, they use a generalized representation for documents, neglecting the word-level semantic modeling. In this paper, we propose Symbolic Graph Ranker (SGR), which aims to take advantage of both text-based and graph-based approaches by leveraging the power of recent Large Language Models (LLMs). Concretely, we first introduce a set of symbolic grammar rules to convert session graph into text. This allows integrating session history, interaction process, and task instruction seamlessly as inputs for the LLM. Moreover, given the natural discrepancy between LLMs pre-trained on textual corpora, and the symbolic language we produce using our graph-to-text grammar, our objective is to enhance LLMs' ability to capture graph structures within a textual format. To achieve this, we introduce a set of self-supervised symbolic learning tasks including link prediction, node content generation, and generative contrastive learning, to enable LLMs to capture the topological information from coarse-grained to fine-grained. Experiment results and comprehensive analysis on two benchmark datasets, AOL and Tiangong-ST, confirm the superiority of our approach. Our paradigm also offers a novel and effective methodology that bridges the gap between traditional search strategies and modern LLMs.
        ]]></description>
    </item>
    <item>
        <title>Nonparametric Teaching for Graph Property Learners</title>
        <link>https://arxiv.org/abs/2505.14170</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14170v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chen Zhang, Weixin Bu, Zeyi Ren, Zhengwu Liu, Yik-Chung Wu, Ngai Wong</dc:creator>
        <description><![CDATA[
            背景：图结构数据属性推断中，图属性学习器学习图到属性的隐式映射成本高。方法：提出图神经教学（GraNT）范式，从非参数教学视角重新解读学习过程，通过示例选择提供教学隐式映射的理论框架，教师选择图 - 属性对的子集促进图卷积网络（GCN）训练快速收敛。效果：显著提高图属性学习器的学习效率，图级回归、分类，节点级回归、分类的训练时间分别减少36.62%、38.19%、30.97%、47.30%，且保持泛化性能。
            arXiv:2505.14170v1 Announce Type: new 
Abstract: Inferring properties of graph-structured data, e.g., the solubility of molecules, essentially involves learning the implicit mapping from graphs to their properties. This learning process is often costly for graph property learners like Graph Convolutional Networks (GCNs). To address this, we propose a paradigm called Graph Neural Teaching (GraNT) that reinterprets the learning process through a novel nonparametric teaching perspective. Specifically, the latter offers a theoretical framework for teaching implicitly defined (i.e., nonparametric) mappings via example selection. Such an implicit mapping is realized by a dense set of graph-property pairs, with the GraNT teacher selecting a subset of them to promote faster convergence in GCN training. By analytically examining the impact of graph structure on parameter-based gradient descent during training, and recasting the evolution of GCNs--shaped by parameter updates--through functional gradient descent in nonparametric teaching, we show for the first time that teaching graph property learners (i.e., GCNs) is consistent with teaching structure-aware nonparametric learners. These new findings readily commit GraNT to enhancing learning efficiency of the graph property learner, showing significant reductions in training time for graph-level regression (-36.62%), graph-level classification (-38.19%), node-level regression (-30.97%) and node-level classification (-47.30%), all while maintaining its generalization performance.
        ]]></description>
    </item>
    <item>
        <title>Tokenization Constraints in LLMs: A Study of Symbolic and Arithmetic Reasoning Limits</title>
        <link>https://arxiv.org/abs/2505.14178</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14178v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiang Zhang, Juntai Cao, Jiaqi Wei, Yiwei Xu, Chenyu You</dc:creator>
        <description><![CDATA[
            背景：大语言模型中分词常被忽视，思维链提示虽能让模型外化中间步骤，但推理成功受分词输入结构限制。方法：理论与实证研究分词方案，尤其是基于子词的方法如何阻碍符号计算，提出“Token Awareness”概念。效果：通过算术和符号任务评估，表明分词结构显著影响推理性能，即使使用思维链也会失败，而原子对齐格式可实现强泛化，小模型在结构化推理中能超越大模型。
            arXiv:2505.14178v1 Announce Type: new 
Abstract: Tokenization is the first - and often underappreciated - layer of computation in language models. While Chain-of-Thought (CoT) prompting enables transformer models to approximate recurrent computation by externalizing intermediate steps, we show that the success of such reasoning is fundamentally bounded by the structure of tokenized inputs. This work presents a theoretical and empirical investigation into how tokenization schemes, particularly subword-based methods like byte-pair encoding (BPE), impede symbolic computation by merging or obscuring atomic reasoning units. We introduce the notion of Token Awareness to formalize how poor token granularity disrupts logical alignment and prevents models from generalizing symbolic procedures. Through systematic evaluation on arithmetic and symbolic tasks, we demonstrate that token structure dramatically affect reasoning performance, causing failure even with CoT, while atomically-aligned formats unlock strong generalization, allowing small models (e.g., GPT-4o-mini) to outperform larger systems (e.g., o1) in structured reasoning. Our findings reveal that symbolic reasoning ability in LLMs is not purely architectural, but deeply conditioned on token-level representations.
        ]]></description>
    </item>
    <item>
        <title>Enhancing Abstractive Summarization of Scientific Papers Using Structure Information</title>
        <link>https://arxiv.org/abs/2505.14179</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14179v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tong Bao, Heng Zhang, Chengzhi Zhang</dc:creator>
        <description><![CDATA[
            科学论文摘要生成一直是研究热点，但现有方法存在难以捕捉论文结构信息、识别结构信息方法缺乏鲁棒性等问题。为此，提出两阶段摘要生成框架。第一阶段，标准化章节标题构建数据集，训练分类器识别关键结构组件；第二阶段，用Longformer捕捉跨章节上下文关系生成摘要。在两个特定领域数据集上实验表明，该方法优于先进基线，能生成更全面的摘要。代码和数据集见https://github.com/tongbao96/code-for-SFR-AS 。
            arXiv:2505.14179v1 Announce Type: new 
Abstract: Abstractive summarization of scientific papers has always been a research focus, yet existing methods face two main challenges. First, most summarization models rely on Encoder-Decoder architectures that treat papers as sequences of words, thus fail to fully capture the structured information inherent in scientific papers. Second, existing research often use keyword mapping or feature engineering to identify the structural information, but these methods struggle with the structural flexibility of scientific papers and lack robustness across different disciplines. To address these challenges, we propose a two-stage abstractive summarization framework that leverages automatic recognition of structural functions within scientific papers. In the first stage, we standardize chapter titles from numerous scientific papers and construct a large-scale dataset for structural function recognition. A classifier is then trained to automatically identify the key structural components (e.g., Background, Methods, Results, Discussion), which provides a foundation for generating more balanced summaries. In the second stage, we employ Longformer to capture rich contextual relationships across sections and generating context-aware summaries. Experiments conducted on two domain-specific scientific paper summarization datasets demonstrate that our method outperforms advanced baselines, and generates more comprehensive summaries. The code and dataset can be accessed at https://github.com/tongbao96/code-for-SFR-AS.
        ]]></description>
    </item>
    <item>
        <title>ThinkSwitcher: When to Think Hard, When to Think Fast</title>
        <link>https://arxiv.org/abs/2505.14183</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14183v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Guosheng Liang, Longguang Zhong, Ziyi Yang, Xiaojun Quan</dc:creator>
        <description><![CDATA[
            背景：大型推理模型在复杂任务中依赖长思维链推理，但在简单任务中会过度思考，产生不必要计算开销。方法：提出ThinkSwitcher框架，让单一大型推理模型根据任务复杂度在短、长思维链模式间动态切换，引入轻量级切换模块，用各推理模式在不同任务上的相对表现监督训练。效果：在多个推理基准测试中，ThinkSwitcher降低20 - 30%计算成本，同时在复杂任务上保持高精度。
            arXiv:2505.14183v1 Announce Type: new 
Abstract: Large reasoning models (LRMs) excel at solving complex tasks by leveraging long chain-of-thought (CoT) reasoning. However, this often leads to overthinking on simple tasks, resulting in unnecessary computational overhead. We observe that LRMs inherently possess the capability for efficient short CoT reasoning, which can be reliably elicited through prompt design. To leverage this capability, we propose ThinkSwitcher, a framework that enables a single LRM to dynamically switch between short and long CoT modes based on task complexity. ThinkSwitcher introduces a lightweight switching module trained with supervision signals derived from the relative performance of each reasoning mode across tasks. Experiments on multiple reasoning benchmarks show that ThinkSwitcher reduces computational cost by 20-30% while maintaining high accuracy on complex tasks. This demonstrates the effectiveness of ThinkSwitcher as a scalable and efficient solution for unified LRM deployment.
        ]]></description>
    </item>
    <item>
        <title>MSDformer: Multi-scale Discrete Transformer For Time Series Generation</title>
        <link>https://arxiv.org/abs/2505.14202</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14202v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhicheng Chen, Shibo Feng, Xi Xiao, Zhong Zhang, Qing Li, Xingyu Gao, Peilin Zhao</dc:creator>
        <description><![CDATA[
            背景：现有离散令牌建模（DTM）方法在时间序列生成中存在无法捕捉多尺度时间模式和缺乏理论指导优化的问题。方法：提出多尺度离散Transformer（MSDformer），用多尺度时间序列分词器学习多尺度离散令牌表示，应用多尺度自回归令牌建模技术捕捉离散潜在空间中时间序列的多尺度模式，并用率失真定理验证方法有效性和模型合理性。效果：实验表明，MSDformer显著优于现有方法，能提升生成时间序列的质量。
            arXiv:2505.14202v1 Announce Type: new 
Abstract: Discrete Token Modeling (DTM), which employs vector quantization techniques, has demonstrated remarkable success in modeling non-natural language modalities, particularly in time series generation. While our prior work SDformer established the first DTM-based framework to achieve state-of-the-art performance in this domain, two critical limitations persist in existing DTM approaches: 1) their inability to capture multi-scale temporal patterns inherent to complex time series data, and 2) the absence of theoretical foundations to guide model optimization. To address these challenges, we proposes a novel multi-scale DTM-based time series generation method, called Multi-Scale Discrete Transformer (MSDformer). MSDformer employs a multi-scale time series tokenizer to learn discrete token representations at multiple scales, which jointly characterize the complex nature of time series data. Subsequently, MSDformer applies a multi-scale autoregressive token modeling technique to capture the multi-scale patterns of time series within the discrete latent space. Theoretically, we validate the effectiveness of the DTM method and the rationality of MSDformer through the rate-distortion theorem. Comprehensive experiments demonstrate that MSDformer significantly outperforms state-of-the-art methods. Both theoretical analysis and experimental results demonstrate that incorporating multi-scale information and modeling multi-scale patterns can substantially enhance the quality of generated time series in DTM-based approaches. The code will be released upon acceptance.
        ]]></description>
    </item>
    <item>
        <title>Automatic Dataset Generation for Knowledge Intensive Question Answering Tasks</title>
        <link>https://arxiv.org/abs/2505.14212</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14212v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sizhe Yuen, Ting Su, Ziyang Wang, Yali Du, Adam J. Sobey</dc:creator>
        <description><![CDATA[
            背景：当前问答系统在复杂推理或实时知识整合查询上表现不佳，RAG处理多源信息复杂推理和逻辑连接也面临挑战。方法：提出通过自动生成基于上下文的问答对来增强大语言模型处理知识密集型问答任务的方法，利用大模型创建微调数据，系统包含自动问答生成器和模型微调器。效果：经多种指标评估，实验显示在逻辑连贯性和事实准确性上有提升，Mistral - 7b - v0.3表现优于Llama - 3 - 8b，在多项指标上超过人工标注问答对。
            arXiv:2505.14212v1 Announce Type: new 
Abstract: A question-answering (QA) system is to search suitable answers within a knowledge base. Current QA systems struggle with queries requiring complex reasoning or real-time knowledge integration. They are often supplemented with retrieval techniques on a data source such as Retrieval-Augmented Generation (RAG). However, RAG continues to face challenges in handling complex reasoning and logical connections between multiple sources of information. A novel approach for enhancing Large Language Models (LLMs) in knowledge-intensive QA tasks is presented through the automated generation of context-based QA pairs. This methodology leverages LLMs to create fine-tuning data, reducing reliance on human labelling and improving model comprehension and reasoning capabilities. The proposed system includes an automated QA generator and a model fine-tuner, evaluated using perplexity, ROUGE, BLEU, and BERTScore. Comprehensive experiments demonstrate improvements in logical coherence and factual accuracy, with implications for developing adaptable Artificial Intelligence (AI) systems. Mistral-7b-v0.3 outperforms Llama-3-8b with BERT F1, BLEU, and ROUGE scores 0.858, 0.172, and 0.260 of for the LLM generated QA pairs compared to scores of 0.836, 0.083, and 0.139 for the human annotated QA pairs.
        ]]></description>
    </item>
    <item>
        <title>UniVG-R1: Reasoning Guided Universal Visual Grounding with Reinforcement Learning</title>
        <link>https://arxiv.org/abs/2505.14231</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14231v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sule Bai, Mingxing Li, Yong Liu, Jing Tang, Haoji Zhang, Lei Sun, Xiangxiang Chu, Yansong Tang</dc:creator>
        <description><![CDATA[
            背景：传统视觉定位方法多用于单图像简单文本参考场景，拓展到涉及隐式复杂指令的现实场景，尤其是多图像场景时，因缺乏跨多模态上下文推理能力而面临挑战。方法：提出推理引导的多模态大语言模型UniVG - R1，通过强化学习结合冷启动数据增强推理能力，构建高质量思维链定位数据集进行监督微调，执行基于规则的强化学习，还提出难度感知权重调整策略。效果：在MIG - Bench上较之前方法提升9.1%，在四个图像和视频推理定位基准上零样本性能平均提升23.4%。
            arXiv:2505.14231v1 Announce Type: new 
Abstract: Traditional visual grounding methods primarily focus on single-image scenarios with simple textual references. However, extending these methods to real-world scenarios that involve implicit and complex instructions, particularly in conjunction with multiple images, poses significant challenges, which is mainly due to the lack of advanced reasoning ability across diverse multi-modal contexts. In this work, we aim to address the more practical universal grounding task, and propose UniVG-R1, a reasoning guided multimodal large language model (MLLM) for universal visual grounding, which enhances reasoning capabilities through reinforcement learning (RL) combined with cold-start data. Specifically, we first construct a high-quality Chain-of-Thought (CoT) grounding dataset, annotated with detailed reasoning chains, to guide the model towards correct reasoning paths via supervised fine-tuning. Subsequently, we perform rule-based reinforcement learning to encourage the model to identify correct reasoning chains, thereby incentivizing its reasoning capabilities. In addition, we identify a difficulty bias arising from the prevalence of easy samples as RL training progresses, and we propose a difficulty-aware weight adjustment strategy to further strengthen the performance. Experimental results demonstrate the effectiveness of UniVG-R1, which achieves state-of-the-art performance on MIG-Bench with a 9.1% improvement over the previous method. Furthermore, our model exhibits strong generalizability, achieving an average improvement of 23.4% in zero-shot performance across four image and video reasoning grounding benchmarks. The project page can be accessed at https://amap-ml.github.io/UniVG-R1-page/.
        ]]></description>
    </item>
    <item>
        <title>Mechanistic Fine-tuning for In-context Learning</title>
        <link>https://arxiv.org/abs/2505.14233</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14233v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hakaze Cho, Peng Luo, Mariko Kato, Rin Kaenbyou, Naoya Inoue</dc:creator>
        <description><![CDATA[
            背景：上下文学习（ICL）让未在ICL风格数据上预训练的语言模型实现少样本学习，但现有端到端微调方法计算成本高。方法：提出注意力行为微调（ABFT），基于ICL内在机制研究，在注意力分数而非最终输出上构建训练目标，使注意力聚焦正确标签、减少错误标签关注。效果：在9种现代语言模型和8个数据集实验显示，ABFT在性能、鲁棒性等方面更优，数据成本仅约为先前方法的0.01%。
            arXiv:2505.14233v1 Announce Type: new 
Abstract: In-context Learning (ICL) utilizes structured demonstration-query inputs to induce few-shot learning on Language Models (LMs), which are not originally pre-trained on ICL-style data. To bridge the gap between ICL and pre-training, some approaches fine-tune LMs on large ICL-style datasets by an end-to-end paradigm with massive computational costs. To reduce such costs, in this paper, we propose Attention Behavior Fine-Tuning (ABFT), utilizing the previous findings on the inner mechanism of ICL, building training objectives on the attention scores instead of the final outputs, to force the attention scores to focus on the correct label tokens presented in the context and mitigate attention scores from the wrong label tokens. Our experiments on 9 modern LMs and 8 datasets empirically find that ABFT outperforms in performance, robustness, unbiasedness, and efficiency, with only around 0.01% data cost compared to the previous methods. Moreover, our subsequent analysis finds that the end-to-end training objective contains the ABFT objective, suggesting the implicit bias of ICL-style data to the emergence of induction heads. Our work demonstrates the possibility of controlling specific module sequences within LMs to improve their behavior, opening up the future application of mechanistic interpretability.
        ]]></description>
    </item>
    <item>
        <title>JOLT-SQL: Joint Loss Tuning of Text-to-SQL with Confusion-aware Noisy Schema Sampling</title>
        <link>https://arxiv.org/abs/2505.14305</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14305v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jinwang Song, Hongying Zan, Kunli Zhang, Lingling Mu, Yingjie Han, Haobo Hua, Min Peng</dc:creator>
        <description><![CDATA[
            背景：文本到SQL任务中，大语言模型的监督微调方法面临多阶段流程复杂、对噪声模式信息鲁棒性差等挑战。方法：提出JOLT - SQL单阶段微调框架，通过统一损失联合优化模式链接和SQL生成，采用带局部双向注意力的判别式模式链接，以及带选择性注意力的混淆感知噪声模式采样策略。效果：在Spider和BIRD基准测试中，JOLT - SQL在同规模开源模型中实现了最优执行准确率，显著提升训练和推理效率。
            arXiv:2505.14305v1 Announce Type: new 
Abstract: Text-to-SQL, which maps natural language to SQL queries, has benefited greatly from recent advances in Large Language Models (LLMs). While LLMs offer various paradigms for this task, including prompting and supervised fine-tuning (SFT), SFT approaches still face challenges such as complex multi-stage pipelines and poor robustness to noisy schema information. To address these limitations, we present JOLT-SQL, a streamlined single-stage SFT framework that jointly optimizes schema linking and SQL generation via a unified loss. JOLT-SQL employs discriminative schema linking, enhanced by local bidirectional attention, alongside a confusion-aware noisy schema sampling strategy with selective attention to improve robustness under noisy schema conditions. Experiments on the Spider and BIRD benchmarks demonstrate that JOLT-SQL achieves state-of-the-art execution accuracy among comparable-size open-source models, while significantly improving both training and inference efficiency.
        ]]></description>
    </item>
    <item>
        <title>Studying the Role of Input-Neighbor Overlap in Retrieval-Augmented Language Models Training Efficiency</title>
        <link>https://arxiv.org/abs/2505.14309</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14309v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ehsan Doostmohammadi, Marco Kuhlmann</dc:creator>
        <description><![CDATA[
            背景：检索增强语言模型性能佳且计算资源需求少，其效果依赖查询与检索上下文的重叠度，但最佳重叠度未知。方法：系统研究不同查询 - 上下文重叠水平对模型训练和推理性能的影响，通过改写查询生成合成上下文来增加重叠度。效果：超过临界阈值后，增加重叠度可显著降低测试时的困惑度、加速模型学习；刻意增加重叠度可在不影响性能的情况下提高数据效率，减少约 40% 的训练时间，且在问答任务中得到验证。
            arXiv:2505.14309v1 Announce Type: new 
Abstract: Retrieval-augmented language models have demonstrated performance comparable to much larger models while requiring fewer computational resources. The effectiveness of these models crucially depends on the overlap between query and retrieved context, but the optimal degree of this overlap remains unexplored. In this paper, we systematically investigate how varying levels of query--context overlap affect model performance during both training and inference. Our experiments reveal that increased overlap initially has minimal effect, but substantially improves test-time perplexity and accelerates model learning above a critical threshold. Building on these findings, we demonstrate that deliberately increasing overlap through synthetic context can enhance data efficiency and reduce training time by approximately 40\% without compromising performance. We specifically generate synthetic context through paraphrasing queries. We validate our perplexity-based findings on question-answering tasks, confirming that the benefits of retrieval-augmented language modeling extend to practical applications. Our results provide empirical evidence of significant optimization potential for retrieval mechanisms in language model pretraining.
        ]]></description>
    </item>
    <item>
        <title>A MIND for Reasoning: Meta-learning for In-context Deduction</title>
        <link>https://arxiv.org/abs/2505.14313</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14313v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Leonardo Bertolazzi, Manuel Vargas Guzm\'an, Raffaella Bernardi, Maciej Malicki, Jakub Szymanik</dc:creator>
        <description><![CDATA[
            背景：大语言模型在形式任务上评估时，推理泛化能力有限。方法：提出Meta - learning for In - context Deduction（MIND），一种少样本元学习微调方法，专注于从知识库中找出推导给定假设所需前提子集，使模型能有效泛化到未见知识库并系统应用推理规则。效果：MIND显著提升了15亿到70亿参数小模型的泛化能力，在小模型和低数据场景优势明显，微调后的小模型在该任务上超越GPT - 4o和o3 - mini等模型。
            arXiv:2505.14313v1 Announce Type: new 
Abstract: Large language models (LLMs) are increasingly evaluated on formal tasks, where strong reasoning abilities define the state of the art. However, their ability to generalize to out-of-distribution problems remains limited. In this paper, we investigate how LLMs can achieve a systematic understanding of deductive rules. Our focus is on the task of identifying the appropriate subset of premises within a knowledge base needed to derive a given hypothesis. To tackle this challenge, we propose Meta-learning for In-context Deduction (MIND), a novel few-shot meta-learning fine-tuning approach. The goal of MIND is to enable models to generalize more effectively to unseen knowledge bases and to systematically apply inference rules. Our results show that MIND significantly improves generalization in small LMs ranging from 1.5B to 7B parameters. The benefits are especially pronounced in smaller models and low-data settings. Remarkably, small models fine-tuned with MIND outperform state-of-the-art LLMs, such as GPT-4o and o3-mini, on this task.
        ]]></description>
    </item>
    <item>
        <title>Plane Geometry Problem Solving with Multi-modal Reasoning: A Survey</title>
        <link>https://arxiv.org/abs/2505.14340</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14340v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Seunghyuk Cho, Zhenyue Qin, Yang Liu, Youngbin Choi, Seungbeom Lee, Dongwoo Kim</dc:creator>
        <description><![CDATA[
            背景：平面几何问题求解（PGPS）作为评估大视觉语言模型多模态推理能力的基准备受关注，但缺乏对相关工作的全面综述。方法：对现有PGPS研究进行调查，将PGPS方法归类为编码器 - 解码器框架，总结对应编码器和解码器的输出格式，按架构设计对其分类分析。效果：指出未来研究的主要挑战和方向，讨论了编解码架构编码阶段的幻觉问题及当前PGPS基准的数据泄露问题。
            arXiv:2505.14340v1 Announce Type: new 
Abstract: Plane geometry problem solving (PGPS) has recently gained significant attention as a benchmark to assess the multi-modal reasoning capabilities of large vision-language models. Despite the growing interest in PGPS, the research community still lacks a comprehensive overview that systematically synthesizes recent work in PGPS. To fill this gap, we present a survey of existing PGPS studies. We first categorize PGPS methods into an encoder-decoder framework and summarize the corresponding output formats used by their encoders and decoders. Subsequently, we classify and analyze these encoders and decoders according to their architectural designs. Finally, we outline major challenges and promising directions for future research. In particular, we discuss the hallucination issues arising during the encoding phase within encoder-decoder architectures, as well as the problem of data leakage in current PGPS benchmarks.
        ]]></description>
    </item>
    <item>
        <title>AutoRev: Automatic Peer Review System for Academic Research Papers</title>
        <link>https://arxiv.org/abs/2505.14376</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14376v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Maitreya Prafulla Chitale, Ketaki Mangesh Shetye, Harshit Gupta, Manav Chaudhary, Vasudeva Varma</dc:creator>
        <description><![CDATA[
            现有微调大语言模型生成学术论文评审的方法常忽略长输入token带来的计算和性能限制。为此，本文提出自动同行评审系统AutoRev。该方法将学术文档表示为图，提取对评审有重要贡献的关键段落。这种基于图的方法在评审生成中表现有效，还可能适用于问答、摘要等下游任务。在评审生成任务中，该方法在所有评估指标上平均比SOTA基线高出58.72%。
            arXiv:2505.14376v1 Announce Type: new 
Abstract: Generating a review for an academic research paper is a complex task that requires a deep understanding of the document's content and the interdependencies between its sections. It demands not only insight into technical details but also an appreciation of the paper's overall coherence and structure. Recent methods have predominantly focused on fine-tuning large language models (LLMs) to address this challenge. However, they often overlook the computational and performance limitations imposed by long input token lengths. To address this, we introduce AutoRev, an Automatic Peer Review System for Academic Research Papers. Our novel framework represents an academic document as a graph, enabling the extraction of the most critical passages that contribute significantly to the review. This graph-based approach demonstrates effectiveness for review generation and is potentially adaptable to various downstream tasks, such as question answering, summarization, and document representation. When applied to review generation, our method outperforms SOTA baselines by an average of 58.72% across all evaluation metrics. We hope that our work will stimulate further research in applying graph-based extraction techniques to other downstream tasks in NLP. We plan to make our code public upon acceptance.
        ]]></description>
    </item>
    <item>
        <title>Log-Augmented Generation: Scaling Test-Time Reasoning with Reusable Computation</title>
        <link>https://arxiv.org/abs/2505.14398</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14398v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Peter Baile Chen, Yi Zhang, Dan Roth, Samuel Madden, Jacob Andreas, Michael Cafarella</dc:creator>
        <description><![CDATA[
            背景：大语言模型难以保留先前任务的推理并应用于新场景。方法：提出日志增强生成（LAG）框架，用键值（KV）缓存表示任务日志，编码先前任务的完整推理上下文，新任务出现时从相关日志中检索KV值增强生成，直接复用先前推理和计算。效果：在知识和推理密集型数据集实验中，显著优于不利用日志的标准智能体系统以及基于反思和KV缓存技术的现有方案。
            arXiv:2505.14398v1 Announce Type: new 
Abstract: While humans naturally learn and adapt from past experiences, large language models (LLMs) and their agentic counterparts struggle to retain reasoning from previous tasks and apply them in future contexts. To address this limitation, we propose a novel framework, log-augmented generation (LAG) that directly reuses prior computation and reasoning from past logs at test time to enhance model's ability to learn from previous tasks and perform better on new, unseen challenges, all while keeping the system efficient and scalable. Specifically, our system represents task logs using key-value (KV) caches, encoding the full reasoning context of prior tasks while storing KV caches for only a selected subset of tokens. When a new task arises, LAG retrieves the KV values from relevant logs to augment generation. Our approach differs from reflection-based memory mechanisms by directly reusing prior reasoning and computations without requiring additional steps for knowledge extraction or distillation. Our method also goes beyond existing KV caching techniques, which primarily target efficiency gains rather than improving accuracy. Experiments on knowledge- and reasoning-intensive datasets demonstrate that our method significantly outperforms standard agentic systems that do not utilize logs, as well as existing solutions based on reflection and KV cache techniques.
        ]]></description>
    </item>
    <item>
        <title>ViC-Bench: Benchmarking Visual-Interleaved Chain-of-Thought Capability in MLLMs with Free-Style Intermediate State Representations</title>
        <link>https://arxiv.org/abs/2505.14404</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14404v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xuecheng Wu, Jiaxing Liu, Danlei Huang, Xiaoyu Li, Yifan Wang, Chen Chen, Liya Ma, Xuezhi Cao, Junxiao Xue</dc:creator>
        <description><![CDATA[
            背景：当前视觉交错思维链（VI - CoT）基准为模型提供相对固定的中间视觉状态（IVS），无法评估模型内在推理能力，且未系统探索IVS对推理性能的影响因素。方法：提出ViC - Bench基准，包含四个代表性任务，有自由式IVS生成管道；提出全面评估套件和渐进三阶段策略及新指标；建立增量提示信息注入（IPII）策略。效果：对18个先进多模态大模型进行评估，揭示其VI - CoT能力，基准已在Huggingface公开。
            arXiv:2505.14404v1 Announce Type: new 
Abstract: Visual-Interleaved Chain-of-Thought (VI-CoT) enables MLLMs to continually update their understanding and decisions based on step-wise intermediate visual states (IVS), much like a human would, which demonstrates impressive success in various tasks, thereby leading to emerged advancements in related benchmarks. Despite promising progress, current benchmarks provide models with relatively fixed IVS, rather than free-style IVS, whch might forcibly distort the original thinking trajectories, failing to evaluate their intrinsic reasoning capabilities. More importantly, existing benchmarks neglect to systematically explore the impact factors that IVS would impart to untamed reasoning performance. To tackle above gaps, we introduce a specialized benchmark termed ViC-Bench, consisting of four representive tasks: maze navigation, jigsaw puzzle, embodied long-horizon planning, and complex counting, where each task has dedicated free-style IVS generation pipeline supporting function calls. To systematically examine VI-CoT capability, we propose a thorough evaluation suite incorporating a progressive three-stage strategy with targeted new metrics. Besides, we establish Incremental Prompting Information Injection (IPII) strategy to ablatively explore the prompting factors for VI-CoT. We extensively conduct evaluations for 18 advanced MLLMs, revealing key insights into their VI-CoT capability. Our proposed benchmark is publicly open at Huggingface.
        ]]></description>
    </item>
    <item>
        <title>Byte Pair Encoding for Efficient Time Series Forecasting</title>
        <link>https://arxiv.org/abs/2505.14411</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14411v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Leon G\"otz, Marcel Kollovieh, Stephan G\"unnemann, Leo Schwinn</dc:creator>
        <description><![CDATA[
            背景：现有时间序列标记化方法将固定数量样本编码为单个标记，处理简单模式时会产生过多标记和高计算开销。方法：受字节对编码启发，提出以模式为中心的时间序列标记化方案，将有潜在模式的样本合并成标记，还引入条件解码作为轻量级事后优化方法。效果：基于模式的标记化使预测性能平均提升36%，效率提升1990%，条件解码最多降低44%的均方误差。
            arXiv:2505.14411v1 Announce Type: new 
Abstract: Existing time series tokenization methods predominantly encode a constant number of samples into individual tokens. This inflexible approach can generate excessive tokens for even simple patterns like extended constant values, resulting in substantial computational overhead. Inspired by the success of byte pair encoding, we propose the first pattern-centric tokenization scheme for time series analysis. Based on a discrete vocabulary of frequent motifs, our method merges samples with underlying patterns into tokens, compressing time series adaptively. Exploiting our finite set of motifs and the continuous properties of time series, we further introduce conditional decoding as a lightweight yet powerful post-hoc optimization method, which requires no gradient computation and adds no computational overhead. On recent time series foundation models, our motif-based tokenization improves forecasting performance by 36% and boosts efficiency by 1990% on average. Conditional decoding further reduces MSE by up to 44%. In an extensive analysis, we demonstrate the adaptiveness of our tokenization to diverse temporal patterns, its generalization to unseen data, and its meaningful token representations capturing distinct time series properties, including statistical moments and trends.
        ]]></description>
    </item>
    <item>
        <title>Table Foundation Models: on knowledge pre-training for tabular learning</title>
        <link>https://arxiv.org/abs/2505.14415</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14415v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Myung Jun Kim, F\'elix Lefebvre, Ga\"etan Brison, Alexandre Perez-Lebel, Ga\"el Varoquaux</dc:creator>
        <description><![CDATA[
            背景：表格基础模型有望助力表格数据下游任务，但存在数据语义理解挑战，现有模型有计算成本高、难复用等问题。方法：提出TARTE模型，用字符串捕捉语义将表格转换为知识增强向量表示，在大型关系数据上预训练。效果：TARTE的表示能以低额外成本促进后续学习，可微调或与其他学习器结合，提升预测性能，改善预测/计算性能权衡，在特定任务或领域能生成利于进一步学习的特定表示。
            arXiv:2505.14415v1 Announce Type: new 
Abstract: Table foundation models bring high hopes to data science: pre-trained on tabular data to embark knowledge or priors, they should facilitate downstream tasks on tables. One specific challenge is that of data semantics: numerical entries take their meaning from context, e.g., column name. Pre-trained neural networks that jointly model column names and table entries have recently boosted prediction accuracy. While these models outline the promises of world knowledge to interpret table values, they lack the convenience of popular foundation models in text or vision. Indeed, they must be fine-tuned to bring benefits, come with sizeable computation costs, and cannot easily be reused or combined with other architectures. Here we introduce TARTE, a foundation model that transforms tables to knowledge-enhanced vector representations using the string to capture semantics. Pre-trained on large relational data, TARTE yields representations that facilitate subsequent learning with little additional cost. These representations can be fine-tuned or combined with other learners, giving models that push the state-of-the-art prediction performance and improve the prediction/computation performance trade-off. Specialized to a task or a domain, TARTE gives domain-specific representations that facilitate further learning. Our study demonstrates an effective approach to knowledge pre-training for tabular learning.
        ]]></description>
    </item>
    <item>
        <title>ModRWKV: Transformer Multimodality in Linear Time</title>
        <link>https://arxiv.org/abs/2505.14505</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14505v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiale Kang, Ziyin Yue, Qingyu Yin, Jiang Rui, Weile Li, Zening Lu, Zhouran Ji</dc:creator>
        <description><![CDATA[
            背景：当前多数多模态研究基于二次复杂度Transformer架构的大语言模型，线性模型如RNN虽推理成本低，但多用于文本模态。方法：提出基于RWKV7架构的解耦多模态框架ModRWKV，通过动态自适应异构模态编码器实现多源信息融合，设计极轻量级多模态模块，利用RWKV7预训练权重初始化加速训练。效果：通过大量实验确定了性能与计算效率的最优配置，对比实验表明初始化对提升模型理解多模态信号能力至关重要，证明现代RNN架构是多模态大模型的可行选择。
            arXiv:2505.14505v1 Announce Type: new 
Abstract: Currently, most multimodal studies are based on large language models (LLMs) with quadratic-complexity Transformer architectures. While linear models like RNNs enjoy low inference costs, their application has been largely limited to the text-only modality. This work explores the capabilities of modern RNN architectures in multimodal contexts. We propose ModRWKV-a decoupled multimodal framework built upon the RWKV7 architecture as its LLM backbone-which achieves multi-source information fusion through dynamically adaptable heterogeneous modality encoders. We designed the multimodal modules in ModRWKV with an extremely lightweight architecture and, through extensive experiments, identified a configuration that achieves an optimal balance between performance and computational efficiency. ModRWKV leverages the pretrained weights of the RWKV7 LLM for initialization, which significantly accelerates multimodal training. Comparative experiments with different pretrained checkpoints further demonstrate that such initialization plays a crucial role in enhancing the model's ability to understand multimodal signals. Supported by extensive experiments, we conclude that modern RNN architectures present a viable alternative to Transformers in the domain of multimodal large language models (MLLMs). Furthermore, we identify the optimal configuration of the ModRWKV architecture through systematic exploration.
        ]]></description>
    </item>
    <item>
        <title>Interpretable Dual-Stream Learning for Local Wind Hazard Prediction in Vulnerable Communities</title>
        <link>https://arxiv.org/abs/2505.14522</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14522v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mahmuda Akhter Nishu, Chenyu Huang, Milad Roohi, Xin Zhong</dc:creator>
        <description><![CDATA[
            背景：美国大平原地区风灾频发，现有预测系统难以捕捉社区特定脆弱性。方法：提出可解释的双流学习框架，通过后期融合机制将结构化数值气象数据与非结构化文本事件叙述结合，融合随机森林和基于RoBERTa的变换器。效果：实验显示，相比传统基线模型性能显著提升，基于梯度的敏感性和消融研究增强了模型决策过程的透明度和操作信任度，对支持应急准备和提升社区恢复力有实用价值。
            arXiv:2505.14522v1 Announce Type: new 
Abstract: Wind hazards such as tornadoes and straight-line winds frequently affect vulnerable communities in the Great Plains of the United States, where limited infrastructure and sparse data coverage hinder effective emergency response. Existing forecasting systems focus primarily on meteorological elements and often fail to capture community-specific vulnerabilities, limiting their utility for localized risk assessment and resilience planning. To address this gap, we propose an interpretable dual-stream learning framework that integrates structured numerical weather data with unstructured textual event narratives. Our architecture combines a Random Forest and RoBERTa-based transformer through a late fusion mechanism, enabling robust and context-aware wind hazard prediction. The system is tailored for underserved tribal communities and supports block-level risk assessment. Experimental results show significant performance gains over traditional baselines. Furthermore, gradient-based sensitivity and ablation studies provide insight into the model's decision-making process, enhancing transparency and operational trust. The findings demonstrate both predictive effectiveness and practical value in supporting emergency preparedness and advancing community resilience.
        ]]></description>
    </item>
    <item>
        <title>Exploring Graph Representations of Logical Forms for Language Modeling</title>
        <link>https://arxiv.org/abs/2505.14523</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14523v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Michael Sullivan</dc:creator>
        <description><![CDATA[
            背景：逻辑形式语言模型（LFLMs）比文本语言模型数据效率更高。方法：提出基于图的形式逻辑分布语义（GFoLDS）原型，这是一个基于逻辑形式图表示的预训练语言模型。效果：实验表明，LFLMs能利用内置基本语言知识学习更复杂模式；在下游任务中，GFoLDS远超同等数据量下预训练的文本Transformer语言模型，说明LFLMs用更少数据学习，且模型性能随参数和预训练数据增加而提升。 
            arXiv:2505.14523v1 Announce Type: new 
Abstract: We make the case for language models over logical forms (LFLMs), arguing that such models are more data-efficient than their textual counterparts. To that end, we introduce the Graph-based Formal-Logical Distributional Semantics (GFoLDS) prototype, a pretrained LM over graph representations of logical forms, as a proof-of-concept of LFLMs. Using GFoLDS, we present strong experimental evidence that LFLMs can leverage the built-in, basic linguistic knowledge inherent in such models to immediately begin learning more complex patterns. On downstream tasks, we show that GFoLDS vastly outperforms textual, transformer LMs pretrained on similar amounts of data, indicating that LFLMs can learn with substantially less data than models over plain text. Furthermore, we show that the performance of this model is likely to scale with additional parameters and pretraining data, suggesting the viability of LFLMs in real-world applications.
        ]]></description>
    </item>
    <item>
        <title>Internal Chain-of-Thought: Empirical Evidence for Layer-wise Subtask Scheduling in LLMs</title>
        <link>https://arxiv.org/abs/2505.14530</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14530v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhipeng Yang, Junzhuo Li, Siyu Xia, Xuming Hu</dc:creator>
        <description><![CDATA[
            背景：探索大语言模型执行复合任务的机制。方法：提出大语言模型存在“内部思维链”，即逐层分解和执行复合任务。在15个两步复合任务基准上，采用层上下文掩码和跨任务修补方法验证不同子任务在不同网络深度学习；用LogitLens解码隐藏状态，揭示逐层执行模式。效果：在真实世界TRACE基准上也观察到相同的逐步动态，提升了大语言模型内部规划和执行子任务能力的透明度，为指令级激活控制提供途径。
            arXiv:2505.14530v1 Announce Type: new 
Abstract: We show that large language models (LLMs) exhibit an $\textit{internal chain-of-thought}$: they sequentially decompose and execute composite tasks layer-by-layer. Two claims ground our study: (i) distinct subtasks are learned at different network depths, and (ii) these subtasks are executed sequentially across layers. On a benchmark of 15 two-step composite tasks, we employ layer-from context-masking and propose a novel cross-task patching method, confirming (i). To examine claim (ii), we apply LogitLens to decode hidden states, revealing a consistent layerwise execution pattern. We further replicate our analysis on the real-world $\text{TRACE}$ benchmark, observing the same stepwise dynamics. Together, our results enhance LLMs transparency by showing their capacity to internally plan and execute subtasks (or instructions), opening avenues for fine-grained, instruction-level activation steering.
        ]]></description>
    </item>
    <item>
        <title>Time to Embed: Unlocking Foundation Models for Time Series with Channel Descriptions</title>
        <link>https://arxiv.org/abs/2505.14543</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14543v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Utsav Dutta, Sina Khoshfetrat Pakazad, Henrik Ohlsson</dc:creator>
        <description><![CDATA[
            背景：传统时间序列模型特定于任务，依赖特定数据集训练和大量特征工程，基于Transformer的架构虽提升可扩展性，但时间序列基础模型研究不足且多局限于预测。方法：提出CHARM基础嵌入模型，融入架构创新，整合通道级文本描述且对通道顺序不变，采用联合嵌入预测架构（JEPA）训练，有新的增强方案和损失函数。效果：700万参数的模型在多样下游任务中达最优，为时间序列表征学习设新基准。
            arXiv:2505.14543v1 Announce Type: new 
Abstract: Traditional time series models are task-specific and often depend on dataset-specific training and extensive feature engineering. While Transformer-based architectures have improved scalability, foundation models, commonplace in text, vision, and audio, remain under-explored for time series and are largely restricted to forecasting. We introduce $\textbf{CHARM}$, a foundation embedding model for multivariate time series that learns shared, transferable, and domain-aware representations. To address the unique difficulties of time series foundation learning, $\textbf{CHARM}$ incorporates architectural innovations that integrate channel-level textual descriptions while remaining invariant to channel order. The model is trained using a Joint Embedding Predictive Architecture (JEPA), with novel augmentation schemes and a loss function designed to improve interpretability and training stability. Our $7$M-parameter model achieves state-of-the-art performance across diverse downstream tasks, setting a new benchmark for time series representation learning.
        ]]></description>
    </item>
    <item>
        <title>Can Pruning Improve Reasoning? Revisiting Long-CoT Compression with Capability in Mind for Better Reasoning</title>
        <link>https://arxiv.org/abs/2505.14582</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14582v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Shangziqi Zhao, Jiahao Yuan, Guisong Yang, Usman Naseem</dc:creator>
        <description><![CDATA[
            背景：长思维链（Long - CoT）推理可提高大语言模型准确性，但冗长风格不利于向小语言模型（SLM）蒸馏。方法：提出Prune - on - Logic结构感知框架，将Long - CoT转换为逻辑图，在自验证约束下选择性修剪低效用推理步骤，并分析三种修剪策略。效果：修剪验证步骤能在降低推理成本的同时持续提高准确率，优于基于token的基线方法和未压缩微调；修剪推理或全链步骤会降低性能，表明小模型受益于语义精简而非缩短的思维链。
            arXiv:2505.14582v1 Announce Type: new 
Abstract: Long chain-of-thought (Long-CoT) reasoning improves accuracy in LLMs, yet its verbose, self-reflective style often hinders effective distillation into small language models (SLMs). We revisit Long-CoT compression through the lens of capability alignment and ask: Can pruning improve reasoning? We propose Prune-on-Logic, a structure-aware framework that transforms Long-CoT into logic graphs and selectively prunes low-utility reasoning steps under self-verification constraints. Through systematic analysis across three pruning strategies -- targeting entire chains, core reasoning, and verification -- we find that pruning verification steps yields consistent accuracy gains while reducing inference cost, outperforming token-level baselines and uncompressed fine-tuning. In contrast, pruning reasoning or all-chain steps degrades performance, revealing that small models benefit not from shorter CoTs, but from semantically leaner ones. Our findings highlight pruning as a structural optimization strategy for aligning CoT reasoning with SLM capacity.
        ]]></description>
    </item>
    <item>
        <title>KERL: Knowledge-Enhanced Personalized Recipe Recommendation using Large Language Models</title>
        <link>https://arxiv.org/abs/2505.14629</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14629v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Fnu Mohbat, Mohammed J Zaki</dc:creator>
        <description><![CDATA[
            背景：虽有研究用大语言模型和知识图谱做推荐系统，但结合食物相关知识图谱与大语言模型的研究较少。方法：提出统一系统KERL，利用食物知识图谱和大语言模型，根据自然语言问题提取实体、从知识图谱检索子图并作为上下文输入大模型，以选择满足约束的食谱，还能生成烹饪步骤和营养信息。效果：构建基准数据集评估，实验表明该模型显著优于现有方法，代码和数据集已开源。
            arXiv:2505.14629v1 Announce Type: new 
Abstract: Recent advances in large language models (LLMs) and the abundance of food data have resulted in studies to improve food understanding using LLMs. Despite several recommendation systems utilizing LLMs and Knowledge Graphs (KGs), there has been limited research on integrating food related KGs with LLMs. We introduce KERL, a unified system that leverages food KGs and LLMs to provide personalized food recommendations and generates recipes with associated micro-nutritional information. Given a natural language question, KERL extracts entities, retrieves subgraphs from the KG, which are then fed into the LLM as context to select the recipes that satisfy the constraints. Next, our system generates the cooking steps and nutritional information for each recipe. To evaluate our approach, we also develop a benchmark dataset by curating recipe related questions, combined with constraints and personal preferences. Through extensive experiments, we show that our proposed KG-augmented LLM significantly outperforms existing approaches, offering a complete and coherent solution for food recommendation, recipe generation, and nutritional analysis. Our code and benchmark datasets are publicly available at https://github.com/mohbattharani/KERL.
        ]]></description>
    </item>
    <item>
        <title>Think Only When You Need with Large Hybrid-Reasoning Models</title>
        <link>https://arxiv.org/abs/2505.14631</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14631v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Lingjie Jiang, Xun Wu, Shaohan Huang, Qingxiu Dong, Zewen Chi, Li Dong, Xingxing Zhang, Tengchao Lv, Lei Cui, Furu Wei</dc:creator>
        <description><![CDATA[
            背景：现有大型推理模型虽提升推理能力，但过长思考会增加开销，简单查询时不必要。方法：提出大型混合推理模型（LHRMs），能根据用户查询上下文自适应决定是否思考，采用两阶段训练流程，先混合微调冷启动，再用混合组策略优化进行在线强化学习；还引入混合准确率指标。效果：实验表明，LHRMs能自适应处理不同难度和类型查询，推理和通用能力超现有模型，效率显著提升。
            arXiv:2505.14631v1 Announce Type: new 
Abstract: Recent Large Reasoning Models (LRMs) have shown substantially improved reasoning capabilities over traditional Large Language Models (LLMs) by incorporating extended thinking processes prior to producing final responses. However, excessively lengthy thinking introduces substantial overhead in terms of token consumption and latency, which is particularly unnecessary for simple queries. In this work, we introduce Large Hybrid-Reasoning Models (LHRMs), the first kind of model capable of adaptively determining whether to perform thinking based on the contextual information of user queries. To achieve this, we propose a two-stage training pipeline comprising Hybrid Fine-Tuning (HFT) as a cold start, followed by online reinforcement learning with the proposed Hybrid Group Policy Optimization (HGPO) to implicitly learn to select the appropriate thinking mode. Furthermore, we introduce a metric called Hybrid Accuracy to quantitatively assess the model's capability for hybrid thinking. Extensive experimental results show that LHRMs can adaptively perform hybrid thinking on queries of varying difficulty and type. It outperforms existing LRMs and LLMs in reasoning and general capabilities while significantly improving efficiency. Together, our work advocates for a reconsideration of the appropriate use of extended thinking processes and provides a solid starting point for building hybrid thinking systems.
        ]]></description>
    </item>
    <item>
        <title>VideoEval-Pro: Robust and Realistic Long Video Understanding Evaluation</title>
        <link>https://arxiv.org/abs/2505.14640</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14640v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wentao Ma, Weiming Ren, Yiming Jia, Zhuofeng Li, Ping Nie, Ge Zhang, Wenhu Chen</dc:creator>
        <description><![CDATA[
            背景：现有长视频理解（LVU）基准存在问题，如多依赖选择题致评估结果虚高，部分问题有强先验使模型不看视频也能作答，增加帧数不一定提升效果。方法：提出VideoEval - Pro，含开放式简答题，通过感知和推理任务评估片段和全视频理解。效果：评估21个模型发现，模型在开放式问题上表现比选择题下降超25%，选择题高分不意味着开放式问题高分，增加帧数对VideoEval - Pro更有益，该基准能更真实可靠地评估长视频理解能力。
            arXiv:2505.14640v1 Announce Type: new 
Abstract: Large multimodal models (LMMs) have recently emerged as a powerful tool for long video understanding (LVU), prompting the development of standardized LVU benchmarks to evaluate their performance. However, our investigation reveals a rather sober lesson for existing LVU benchmarks. First, most existing benchmarks rely heavily on multiple-choice questions (MCQs), whose evaluation results are inflated due to the possibility of guessing the correct answer; Second, a significant portion of questions in these benchmarks have strong priors to allow models to answer directly without even reading the input video. For example, Gemini-1.5-Pro can achieve over 50\% accuracy given a random frame from a long video on Video-MME. We also observe that increasing the number of frames does not necessarily lead to improvement on existing benchmarks, which is counterintuitive. As a result, the validity and robustness of current LVU benchmarks are undermined, impeding a faithful assessment of LMMs' long-video understanding capability. To tackle this problem, we propose VideoEval-Pro, a realistic LVU benchmark containing questions with open-ended short-answer, which truly require understanding the entire video. VideoEval-Pro assesses both segment-level and full-video understanding through perception and reasoning tasks. By evaluating 21 proprietary and open-source video LMMs, we conclude the following findings: (1) video LMMs show drastic performance ($>$25\%) drops on open-ended questions compared with MCQs; (2) surprisingly, higher MCQ scores do not lead to higher open-ended scores on VideoEval-Pro; (3) compared to other MCQ benchmarks, VideoEval-Pro benefits more from increasing the number of input frames. Our results show that VideoEval-Pro offers a more realistic and reliable measure of long video understanding, providing a clearer view of progress in this domain.
        ]]></description>
    </item>
    <item>
        <title>Early Diagnosis of Atrial Fibrillation Recurrence: A Large Tabular Model Approach with Structured and Unstructured Clinical Data</title>
        <link>https://arxiv.org/abs/2505.14643</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14643v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ane G. Domingo-Aldama, Marcos Merino Prado, Alain Garc\'ia Olea, Koldo Gojenola Galletebeitia, Josu Goikoetxea Salutregi, Aitziber Atutxa Salazar</dc:creator>
        <description><![CDATA[
            背景：房颤是常见心律失常，传统评分预测房颤复发准确性有限，且早期诊断依赖的电子健康记录数据有误差和信息缺失。方法：将结构化临床数据与经自然语言处理的自由文本出院报告结合生成表格数据集，以1508名有房颤发作记录患者为研究对象，用大表格模型（LTM）与传统临床评分、机器学习模型对比。效果：LTM方法预测性能最佳，超越传统评分和机器学习模型，还揭示了性别和年龄偏差中的人口统计学差异。 
            arXiv:2505.14643v1 Announce Type: new 
Abstract: BACKGROUND: Atrial fibrillation (AF), the most common arrhythmia, is linked to high morbidity and mortality. In a fast-evolving AF rhythm control treatment era, predicting AF recurrence after its onset may be crucial to achieve the optimal therapeutic approach, yet traditional scores like CHADS2-VASc, HATCH, and APPLE show limited predictive accuracy. Moreover, early diagnosis studies often rely on codified electronic health record (EHR) data, which may contain errors and missing information.
  OBJECTIVE: This study aims to predict AF recurrence between one month and two years after onset by evaluating traditional clinical scores, ML models, and our LTM approach. Moreover, another objective is to develop a methodology for integrating structured and unstructured data to enhance tabular dataset quality.
  METHODS: A tabular dataset was generated by combining structured clinical data with free-text discharge reports processed through natural language processing techniques, reducing errors and annotation effort. A total of 1,508 patients with documented AF onset were identified, and models were evaluated on a manually annotated test set. The proposed approach includes a LTM compared against traditional clinical scores and ML models.
  RESULTS: The proposed LTM approach achieved the highest predictive performance, surpassing both traditional clinical scores and ML models. Additionally, the gender and age bias analyses revealed demographic disparities.
  CONCLUSION: The integration of structured data and free-text sources resulted in a high-quality dataset. The findings emphasize the limitations of traditional clinical scores in predicting AF recurrence and highlight the potential of ML-based approaches, particularly our LTM model.
        ]]></description>
    </item>
    <item>
        <title>General-Reasoner: Advancing LLM Reasoning Across All Domains</title>
        <link>https://arxiv.org/abs/2505.14652</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14652v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xueguang Ma, Qian Liu, Dongfu Jiang, Ge Zhang, Zejun Ma, Wenhu Chen</dc:creator>
        <description><![CDATA[
            背景：当前提升大语言模型推理能力的研究多集中于数学和编程领域，限制了模型在更广泛领域的应用。方法：提出General - Reasoner训练范式，构建大规模高质量可验证答案的数据集，开发基于生成模型的答案验证器，以思维链和上下文感知能力替代传统基于规则的验证。效果：在涵盖物理、化学等领域的12个基准测试中，General - Reasoner优于现有基线方法，在保持数学推理任务有效性的同时，实现了稳健且可泛化的推理性能。
            arXiv:2505.14652v1 Announce Type: new 
Abstract: Reinforcement learning (RL) has recently demonstrated strong potential in enhancing the reasoning capabilities of large language models (LLMs). Particularly, the "Zero" reinforcement learning introduced by Deepseek-R1-Zero, enables direct RL training of base LLMs without relying on an intermediate supervised fine-tuning stage. Despite these advancements, current works for LLM reasoning mainly focus on mathematical and coding domains, largely due to data abundance and the ease of answer verification. This limits the applicability and generalization of such models to broader domains, where questions often have diverse answer representations, and data is more scarce. In this paper, we propose General-Reasoner, a novel training paradigm designed to enhance LLM reasoning capabilities across diverse domains. Our key contributions include: (1) constructing a large-scale, high-quality dataset of questions with verifiable answers curated by web crawling, covering a wide range of disciplines; and (2) developing a generative model-based answer verifier, which replaces traditional rule-based verification with the capability of chain-of-thought and context-awareness. We train a series of models and evaluate them on a wide range of datasets covering wide domains like physics, chemistry, finance, electronics etc. Our comprehensive evaluation across these 12 benchmarks (e.g. MMLU-Pro, GPQA, SuperGPQA, TheoremQA, BBEH and MATH AMC) demonstrates that General-Reasoner outperforms existing baseline methods, achieving robust and generalizable reasoning performance while maintaining superior effectiveness in mathematical reasoning tasks.
        ]]></description>
    </item>
    <item>
        <title>AKRMap: Adaptive Kernel Regression for Trustworthy Visualization of Cross-Modal Embeddings</title>
        <link>https://arxiv.org/abs/2505.14664</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14664v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yilin Ye, Junchao Huang, Xingchen Zeng, Jiazhi Xia, Wei Zeng</dc:creator>
        <description><![CDATA[
            背景：跨模态嵌入是多模态模型基础，但现有可视化方法局限于传统降维技术，未考虑多模态指标。方法：提出AKRMap，通过学习投影空间中度量格局的核回归，构建由投影后核回归损失引导的监督投影网络，采用可与投影联合优化的自适应广义核。效果：能高效生成捕捉复杂度量分布的可视化结果，支持交互特性。定量实验表明，其在生成准确可信可视化方面优于现有方法，还在文本到图像模型的跨模态嵌入可视化和比较中展现有效性。
            arXiv:2505.14664v1 Announce Type: new 
Abstract: Cross-modal embeddings form the foundation for multi-modal models. However, visualization methods for interpreting cross-modal embeddings have been primarily confined to traditional dimensionality reduction (DR) techniques like PCA and t-SNE. These DR methods primarily focus on feature distributions within a single modality, whilst failing to incorporate metrics (e.g., CLIPScore) across multiple modalities.This paper introduces AKRMap, a new DR technique designed to visualize cross-modal embeddings metric with enhanced accuracy by learning kernel regression of the metric landscape in the projection space. Specifically, AKRMap constructs a supervised projection network guided by a post-projection kernel regression loss, and employs adaptive generalized kernels that can be jointly optimized with the projection. This approach enables AKRMap to efficiently generate visualizations that capture complex metric distributions, while also supporting interactive features such as zoom and overlay for deeper exploration. Quantitative experiments demonstrate that AKRMap outperforms existing DR methods in generating more accurate and trustworthy visualizations. We further showcase the effectiveness of AKRMap in visualizing and comparing cross-modal embeddings for text-to-image models. Code and demo are available at https://github.com/yilinye/AKRMap.
        ]]></description>
    </item>
    <item>
        <title>Mind the Gap: Bridging Thought Leap for Improved Chain-of-Thought Tuning</title>
        <link>https://arxiv.org/abs/2505.14684</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14684v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Haolei Xu, Yuchen Yan, Yongliang Shen, Wenqi Zhang, Guiyang Hou, Shengpei Jiang, Kaitao Song, Weiming Lu, Jun Xiao, Yueting Zhuang</dc:creator>
        <description><![CDATA[
            背景：大语言模型通过思维链推理在数学任务上取得显著进展，但现有数学思维链数据集常因专家省略中间步骤出现思维跳跃，影响模型学习与泛化。方法：提出思维链思维跳跃弥补任务，构建基于结构化ScaleQuestMath数据集的训练集ScaleQM+，训练CoT - Bridge来弥补跳跃。效果：在数学推理基准测试中，基于弥补后数据集微调的模型表现优于原数据集，在NuminaMath上提升达5.87%，还能有效增强蒸馏数据及为强化学习提供更好起点，且对域外逻辑推理任务泛化性更好。
            arXiv:2505.14684v1 Announce Type: new 
Abstract: Large language models (LLMs) have achieved remarkable progress on mathemati-cal tasks through Chain-of-Thought (CoT) reasoning. However, existing mathematical CoT datasets often suffer from Thought Leaps due to experts omitting intermediate steps, which negatively impacts model learning and generalization. We propose the CoT Thought Leap Bridge Task, which aims to automatically detect leaps and generate missing intermediate reasoning steps to restore the completeness and coherence of CoT. To facilitate this, we constructed a specialized training dataset called ScaleQM+, based on the structured ScaleQuestMath dataset, and trained CoT-Bridge to bridge thought leaps. Through comprehensive experiments on mathematical reasoning benchmarks, we demonstrate that models fine-tuned on bridged datasets consistently outperform those trained on original datasets, with improvements of up to +5.87% on NuminaMath. Our approach effectively enhances distilled data (+3.02%) and provides better starting points for reinforcement learning (+3.1%), functioning as a plug-and-play module compatible with existing optimization techniques. Furthermore, CoT-Bridge demonstrate improved generalization to out-of-domain logical reasoning tasks, confirming that enhancing reasoning completeness yields broadly applicable benefits.
        ]]></description>
    </item>
    <item>
        <title>RTL++: Graph-enhanced LLM for RTL Code Generation</title>
        <link>https://arxiv.org/abs/2505.13479</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13479v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mohammad Akyash, Kimia Azar, Hadi Kamali</dc:creator>
        <description><![CDATA[
            随着硬件设计复杂度提升，电子设计自动化需更先进的自动化手段，传统RTL设计方法效率低且易出错，开源大模型因训练数据有限生成代码质量欠佳。本文提出RTL++方法，将RTL代码编码为文本化的控制流图和数据流图，利用代码结构的图表示增强大模型生成代码的质量。该方法增强了大模型可利用的上下文，解决了以往仅依赖代码导致的多样性不足问题。实验表明，在VerilogEval基准测试中，RTL++优于最先进的RTL生成微调模型及RTLLM1.1模型。
            arXiv:2505.13479v1 Announce Type: cross 
Abstract: As hardware design complexity escalates, there is an urgent need for advanced automation in electronic design automation (EDA). Traditional register transfer level (RTL) design methods are manual, time-consuming, and prone to errors. While commercial (instruction-tuned) large language models (LLMs) shows promising performance for automation, they pose security and privacy concerns. Open-source models offer alternatives; however, they frequently fall short in quality/correctness, largely due to limited, high-quality RTL code data essential for effective training and generalization. This paper proposes RTL++, a first-of-its-kind LLM-assisted method for RTL code generation that utilizes graph representations of code structures to enhance the quality of generated code. By encoding RTL code into a textualized control flowgraphs (CFG) and data flow graphs (DFG), RTL++ captures the inherent hierarchy, dependencies, and relationships within the code. This structured graph-based approach enhances the context available to LLMs, enabling them to better understand and generate instructions. By focusing on data generation through graph representations, RTL++ addresses the limitations of previous approaches that rely solely on code and suffer from lack of diversity. Experimental results demonstrate that RTL++ outperforms state-of-the-art models fine-tuned for RTL generation, as evaluated using the VerilogEval benchmark's Pass@1/5/10 metric, as well as the RTLLM1.1 model, which highlight the effectiveness of graph-enhanced context in advancing the capabilities of LLM-assisted RTL code generation.
        ]]></description>
    </item>
    <item>
        <title>Contrastive Cross-Course Knowledge Tracing via Concept Graph Guided Knowledge Transfer</title>
        <link>https://arxiv.org/abs/2505.13489</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13489v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wenkang Han, Wang Lin, Liya Hu, Zhenlong Dai, Yiyun Zhou, Mengze Li, Zemin Liu, Chang Yao, Jingyuan Chen</dc:creator>
        <description><![CDATA[
            背景：现有知识追踪（KT）模型多关注单课程数据，难以全面理解学习者知识状态。方法：提出对比跨课程知识追踪方法TransKT，利用概念图引导知识迁移，通过零样本大语言模型（LLM）提示构建跨课程概念图，建立课程间概念联系；采用LLM - to - LM管道整合语义特征；使用对比目标对齐单课程和跨课程知识状态。效果：显著提升用于知识迁移的图卷积网络（GCNs）性能，能更准确表示学习者整体知识状态。
            arXiv:2505.13489v1 Announce Type: cross 
Abstract: Knowledge tracing (KT) aims to predict learners' future performance based on historical learning interactions. However, existing KT models predominantly focus on data from a single course, limiting their ability to capture a comprehensive understanding of learners' knowledge states. In this paper, we propose TransKT, a contrastive cross-course knowledge tracing method that leverages concept graph guided knowledge transfer to model the relationships between learning behaviors across different courses, thereby enhancing knowledge state estimation. Specifically, TransKT constructs a cross-course concept graph by leveraging zero-shot Large Language Model (LLM) prompts to establish implicit links between related concepts across different courses. This graph serves as the foundation for knowledge transfer, enabling the model to integrate and enhance the semantic features of learners' interactions across courses. Furthermore, TransKT includes an LLM-to-LM pipeline for incorporating summarized semantic features, which significantly improves the performance of Graph Convolutional Networks (GCNs) used for knowledge transfer. Additionally, TransKT employs a contrastive objective that aligns single-course and cross-course knowledge states, thereby refining the model's ability to provide a more robust and accurate representation of learners' overall knowledge states.
        ]]></description>
    </item>
    <item>
        <title>InterFeat: An Automated Pipeline for Finding Interesting Hypotheses in Structured Biomedical Data</title>
        <link>https://arxiv.org/abs/2505.13534</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13534v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Dan Ofer, Michal Linial, Dafna Shahaf</dc:creator>
        <description><![CDATA[
            背景：在结构化生物医学数据中发现有趣现象是科学发现核心，但目前多为人工且概念不明确。方法：提出自动化发现有趣简单假设的集成管道，结合机器学习、知识图谱、文献搜索和大语言模型，将“有趣性”定义为新颖性、实用性和合理性的结合。效果：在英国生物银行的8种主要疾病上，该管道能在文献报道前数年发现风险因素，前候选中40 - 53%被验证有趣，而基于SHAP的基线仅0 - 7%，109个候选中有28%获医学专家认可。
            arXiv:2505.13534v1 Announce Type: cross 
Abstract: Finding interesting phenomena is the core of scientific discovery, but it is a manual, ill-defined concept. We present an integrative pipeline for automating the discovery of interesting simple hypotheses (feature-target relations with effect direction and a potential underlying mechanism) in structured biomedical data. The pipeline combines machine learning, knowledge graphs, literature search and Large Language Models. We formalize "interestingness" as a combination of novelty, utility and plausibility. On 8 major diseases from the UK Biobank, our pipeline consistently recovers risk factors years before their appearance in the literature. 40--53% of our top candidates were validated as interesting, compared to 0--7% for a SHAP-based baseline. Overall, 28% of 109 candidates were interesting to medical experts. The pipeline addresses the challenge of operationalizing "interestingness" scalably and for any target. We release data and code: https://github.com/LinialLab/InterFeat
        ]]></description>
    </item>
    <item>
        <title>Beyond Text: Unveiling Privacy Vulnerabilities in Multi-modal Retrieval-Augmented Generation</title>
        <link>https://arxiv.org/abs/2505.13957</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13957v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiankun Zhang, Shenglai Zeng, Jie Ren, Tianqi Zheng, Hui Liu, Xianfeng Tang, Hui Liu, Yi Chang</dc:creator>
        <description><![CDATA[
            背景：多模态检索增强生成（MRAG）系统虽能提升大语言模型能力，但引入隐私风险，且多模态数据带来独特挑战。方法：首次对视觉 - 语言和语音 - 语言模态的MRAG隐私漏洞进行系统分析，在黑盒环境下使用新颖的组合结构化提示攻击，攻击者可通过操纵查询提取隐私信息。效果：实验表明大语言模型既能直接生成类似检索内容的输出，也会间接暴露敏感信息，凸显了需开发强大隐私保护MRAG技术。
            arXiv:2505.13957v1 Announce Type: cross 
Abstract: Multimodal Retrieval-Augmented Generation (MRAG) systems enhance LMMs by integrating external multimodal databases, but introduce unexplored privacy vulnerabilities. While text-based RAG privacy risks have been studied, multimodal data presents unique challenges. We provide the first systematic analysis of MRAG privacy vulnerabilities across vision-language and speech-language modalities. Using a novel compositional structured prompt attack in a black-box setting, we demonstrate how attackers can extract private information by manipulating queries. Our experiments reveal that LMMs can both directly generate outputs resembling retrieved content and produce descriptions that indirectly expose sensitive information, highlighting the urgent need for robust privacy-preserving MRAG techniques.
        ]]></description>
    </item>
    <item>
        <title>Disentangled Multi-span Evolutionary Network against Temporal Knowledge Graph Reasoning</title>
        <link>https://arxiv.org/abs/2505.14020</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14020v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hao Dong, Ziyue Qiao, Zhiyuan Ning, Qi Hao, Yi Du, Pengyang Wang, Yuanchun Zhou</dc:creator>
        <description><![CDATA[
            背景：时序知识图谱（TKG）外推推理近年受关注，现有方法建模子图语义演化时，忽略子图内部结构交互和潜在平滑特征。方法：提出解耦多跨度演化网络（DiMNet），设计多跨度演化策略捕获局部和历史邻居特征，实现子图内部交互；设计解耦组件分离节点活跃和稳定特征，动态控制历史语义影响。效果：在四个真实TKG数据集上实验，DiMNet推理性能佳，MRR比现有最优模型提升达22.7%。
            arXiv:2505.14020v1 Announce Type: cross 
Abstract: Temporal Knowledge Graphs (TKGs), as an extension of static Knowledge Graphs (KGs), incorporate the temporal feature to express the transience of knowledge by describing when facts occur. TKG extrapolation aims to infer possible future facts based on known history, which has garnered significant attention in recent years. Some existing methods treat TKG as a sequence of independent subgraphs to model temporal evolution patterns, demonstrating impressive reasoning performance. However, they still have limitations: 1) In modeling subgraph semantic evolution, they usually neglect the internal structural interactions between subgraphs, which are actually crucial for encoding TKGs. 2) They overlook the potential smooth features that do not lead to semantic changes, which should be distinguished from the semantic evolution process. Therefore, we propose a novel Disentangled Multi-span Evolutionary Network (DiMNet) for TKG reasoning. Specifically, we design a multi-span evolution strategy that captures local neighbor features while perceiving historical neighbor semantic information, thus enabling internal interactions between subgraphs during the evolution process. To maximize the capture of semantic change patterns, we design a disentangle component that adaptively separates nodes' active and stable features, used to dynamically control the influence of historical semantics on future evolution. Extensive experiments conducted on four real-world TKG datasets show that DiMNet demonstrates substantial performance in TKG reasoning, and outperforms the state-of-the-art up to 22.7% in MRR.
        ]]></description>
    </item>
    <item>
        <title>s3: You Don't Need That Much Data to Train a Search Agent via RL</title>
        <link>https://arxiv.org/abs/2505.14146</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14146v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Pengcheng Jiang, Xueqiang Xu, Jiacheng Lin, Jinfeng Xiao, Zifeng Wang, Jimeng Sun, Jiawei Han</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）系统使大语言模型在推理时能获取外部知识，但现有方法存在忽视下游效用或使检索与生成纠缠等问题。方法：提出轻量级、模型无关的框架s3，将搜索器与生成器解耦，用超越RAG的增益奖励训练搜索器。效果：仅需2400个训练样本，就能超越用多70倍以上数据训练的基线模型，在6个通用问答和5个医学问答基准测试中，下游性能表现更优。
            arXiv:2505.14146v1 Announce Type: cross 
Abstract: Retrieval-augmented generation (RAG) systems empower large language models (LLMs) to access external knowledge during inference. Recent advances have enabled LLMs to act as search agents via reinforcement learning (RL), improving information acquisition through multi-turn interactions with retrieval engines. However, existing approaches either optimize retrieval using search-only metrics (e.g., NDCG) that ignore downstream utility or fine-tune the entire LLM to jointly reason and retrieve-entangling retrieval with generation and limiting the real search utility and compatibility with frozen or proprietary models. In this work, we propose s3, a lightweight, model-agnostic framework that decouples the searcher from the generator and trains the searcher using a Gain Beyond RAG reward: the improvement in generation accuracy over naive RAG. s3 requires only 2.4k training samples to outperform baselines trained on over 70x more data, consistently delivering stronger downstream performance across six general QA and five medical QA benchmarks.
        ]]></description>
    </item>
    <item>
        <title>Causal Cartographer: From Mapping to Reasoning Over Counterfactual Worlds</title>
        <link>https://arxiv.org/abs/2505.14396</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14396v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ga\"el Gendron, Jo\v{z}e M. Ro\v{z}anec, Michael Witbrock, Gillian Dobbie</dc:creator>
        <description><![CDATA[
            背景：现有基础模型（如大语言模型）缺乏因果推理能力，且现实应用中评估反事实情况困难。方法：提出Causal Cartographer框架，先引入图检索增强生成代理从数据中检索因果关系，构建因果知识网络；再创建受因果关系约束的反事实推理代理进行逐步因果推理。效果：该方法能提取因果知识，提升大语言模型因果推理任务的鲁棒性，同时降低推理成本和虚假相关性。
            arXiv:2505.14396v1 Announce Type: cross 
Abstract: Causal world models are systems that can answer counterfactual questions about an environment of interest, i.e. predict how it would have evolved if an arbitrary subset of events had been realized differently. It requires understanding the underlying causes behind chains of events and conducting causal inference for arbitrary unseen distributions. So far, this task eludes foundation models, notably large language models (LLMs), which do not have demonstrated causal reasoning capabilities beyond the memorization of existing causal relationships. Furthermore, evaluating counterfactuals in real-world applications is challenging since only the factual world is observed, limiting evaluation to synthetic datasets. We address these problems by explicitly extracting and modeling causal relationships and propose the Causal Cartographer framework. First, we introduce a graph retrieval-augmented generation agent tasked to retrieve causal relationships from data. This approach allows us to construct a large network of real-world causal relationships that can serve as a repository of causal knowledge and build real-world counterfactuals. In addition, we create a counterfactual reasoning agent constrained by causal relationships to perform reliable step-by-step causal inference. We show that our approach can extract causal knowledge and improve the robustness of LLMs for causal reasoning tasks while reducing inference costs and spurious correlations.
        ]]></description>
    </item>
    <item>
        <title>Towards Non-Euclidean Foundation Models: Advancing AI Beyond Euclidean Frameworks</title>
        <link>https://arxiv.org/abs/2505.14417</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14417v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Menglin Yang, Yifei Zhang, Jialin Chen, Melanie Weber, Rex Ying</dc:creator>
        <description><![CDATA[
            背景：当前基础模型和大语言模型时代，机器学习架构多基于欧几里得空间，但存在局限性。方法：非欧几里得学习渐受关注，如双曲、球面和混合曲率空间能为具有内在几何特性的数据提供更高效表示。将基础模型与非欧几何结合，可增强捕捉和建模底层结构的能力。效果：有望在搜索、推荐和内容理解等方面提升性能，该研讨会聚焦非欧基础模型与几何学习交叉领域，探索其潜力、挑战与未来方向。
            arXiv:2505.14417v1 Announce Type: cross 
Abstract: In the era of foundation models and Large Language Models (LLMs), Euclidean space is the de facto geometric setting of our machine learning architectures. However, recent literature has demonstrated that this choice comes with fundamental limitations. To that end, non-Euclidean learning is quickly gaining traction, particularly in web-related applications where complex relationships and structures are prevalent. Non-Euclidean spaces, such as hyperbolic, spherical, and mixed-curvature spaces, have been shown to provide more efficient and effective representations for data with intrinsic geometric properties, including web-related data like social network topology, query-document relationships, and user-item interactions. Integrating foundation models with non-Euclidean geometries has great potential to enhance their ability to capture and model the underlying structures, leading to better performance in search, recommendations, and content understanding. This workshop focuses on the intersection of Non-Euclidean Foundation Models and Geometric Learning (NEGEL), exploring its potential benefits, including the potential benefits for advancing web-related technologies, challenges, and future directions. Workshop page: [https://hyperboliclearning.github.io/events/www2025workshop](https://hyperboliclearning.github.io/events/www2025workshop)
        ]]></description>
    </item>
    <item>
        <title>Towards Reliable Proof Generation with LLMs: A Neuro-Symbolic Approach</title>
        <link>https://arxiv.org/abs/2505.14479</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14479v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Oren Sultan, Eitan Stern, Dafna Shahaf</dc:creator>
        <description><![CDATA[
            背景：大语言模型在数学证明生成等需严格逻辑演绎和符号推理的形式领域表现不佳。方法：提出神经符号方法，结合大语言模型生成优势与结构化组件，以几何问题为例，一是检索相似问题及其证明引导大模型，二是用形式验证器评估生成的证明并反馈以修正错误。效果：显著提升OpenAI的o1模型证明准确率，提高58%-70%，相似问题和验证器反馈均有贡献，可提升模型可靠性、准确性和一致性。
            arXiv:2505.14479v1 Announce Type: cross 
Abstract: Large language models (LLMs) struggle with formal domains that require rigorous logical deduction and symbolic reasoning, such as mathematical proof generation. We propose a neuro-symbolic approach that combines LLMs' generative strengths with structured components to overcome this challenge. As a proof-of-concept, we focus on geometry problems. Our approach is two-fold: (1) we retrieve analogous problems and use their proofs to guide the LLM, and (2) a formal verifier evaluates the generated proofs and provides feedback, helping the model fix incorrect proofs. We demonstrate that our method significantly improves proof accuracy for OpenAI's o1 model (58%-70% improvement); both analogous problems and the verifier's feedback contribute to these gains. More broadly, shifting to LLMs that generate provably correct conclusions could dramatically improve their reliability, accuracy and consistency, unlocking complex tasks and critical real-world applications that require trustworthiness.
        ]]></description>
    </item>
    <item>
        <title>Reasoning Models Better Express Their Confidence</title>
        <link>https://arxiv.org/abs/2505.14489</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14489v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Dongkeun Yoon, Seungone Kim, Sohee Yang, Sunkyoung Kim, Soyeon Kim, Yongil Kim, Eunbi Choi, Yireun Kim, Minjoon Seo</dc:creator>
        <description><![CDATA[
            背景：大语言模型难以准确表达置信度，限制了可靠性。方法：对六个推理模型在六个数据集上进行基准测试，分析推理模型在思维链推理中的慢思考行为，如探索替代方法和回溯。效果：在36种设置中的33种里，推理模型比非推理模型有更好的置信度校准；推理模型在思维链展开过程中校准度逐渐提高，去除慢思考行为会使校准度显著下降；非推理模型通过上下文学习进行慢思考也能受益。
            arXiv:2505.14489v1 Announce Type: cross 
Abstract: Despite their strengths, large language models (LLMs) often fail to communicate their confidence accurately, making it difficult to assess when they might be wrong and limiting their reliability. In this work, we demonstrate that reasoning models-LLMs that engage in extended chain-of-thought (CoT) reasoning-exhibit superior performance not only in problem-solving but also in accurately expressing their confidence. Specifically, we benchmark six reasoning models across six datasets and find that they achieve strictly better confidence calibration than their non-reasoning counterparts in 33 out of the 36 settings. Our detailed analysis reveals that these gains in calibration stem from the slow thinking behaviors of reasoning models-such as exploring alternative approaches and backtracking-which enable them to adjust their confidence dynamically throughout their CoT, making it progressively more accurate. In particular, we find that reasoning models become increasingly better calibrated as their CoT unfolds, a trend not observed in non-reasoning models. Moreover, removing slow thinking behaviors from the CoT leads to a significant drop in calibration. Lastly, we show that these gains are not exclusive to reasoning models-non-reasoning models also benefit when guided to perform slow thinking via in-context learning.
        ]]></description>
    </item>
    <item>
        <title>Two Experts Are All You Need for Steering Thinking: Reinforcing Cognitive Effort in MoE Reasoning Models Without Additional Training</title>
        <link>https://arxiv.org/abs/2505.14681</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14681v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mengru Wang, Xingyu Chen, Yue Wang, Zhiwei He, Jiahao Xu, Tian Liang, Qiuzhi Liu, Yunzhi Yao, Wenxuan Wang, Ruotian Ma, Haitao Mi, Ningyu Zhang, Zhaopeng Tu, Xiaolong Li, Dong Yu</dc:creator>
        <description><![CDATA[
            背景：大型推理模型（LRMs）中的混合专家（MoE）架构虽有推理能力，但存在过度思考和思考不足等认知效率问题。方法：提出一种名为强化认知专家（RICE）的推理时间引导方法，利用归一化点互信息（nPMI）识别专门的“认知专家”来协调元级推理操作，无需额外训练或复杂启发式方法。效果：在严格的定量和科学推理基准测试中，使用领先的基于MoE的LRMs评估，推理准确性、认知效率和跨领域泛化能力均有显著提升，且优于现有推理引导技术。 
            arXiv:2505.14681v1 Announce Type: cross 
Abstract: Mixture-of-Experts (MoE) architectures within Large Reasoning Models (LRMs) have achieved impressive reasoning capabilities by selectively activating experts to facilitate structured cognitive processes. Despite notable advances, existing reasoning models often suffer from cognitive inefficiencies like overthinking and underthinking. To address these limitations, we introduce a novel inference-time steering methodology called Reinforcing Cognitive Experts (RICE), designed to improve reasoning performance without additional training or complex heuristics. Leveraging normalized Pointwise Mutual Information (nPMI), we systematically identify specialized experts, termed ''cognitive experts'' that orchestrate meta-level reasoning operations characterized by tokens like ''''. Empirical evaluations with leading MoE-based LRMs (DeepSeek-R1 and Qwen3-235B) on rigorous quantitative and scientific reasoning benchmarks demonstrate noticeable and consistent improvements in reasoning accuracy, cognitive efficiency, and cross-domain generalization. Crucially, our lightweight approach substantially outperforms prevalent reasoning-steering techniques, such as prompt design and decoding constraints, while preserving the model's general instruction-following skills. These results highlight reinforcing cognitive experts as a promising, practical, and interpretable direction to enhance cognitive efficiency within advanced reasoning models.
        ]]></description>
    </item>
    <item>
        <title>STD-PLM: Understanding Both Spatial and Temporal Properties of Spatial-Temporal Data with PLM</title>
        <link>https://arxiv.org/abs/2407.09096</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2407.09096v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>YiHeng Huang, Xiaowei Mao, Shengnan Guo, Yubin Chen, Junfeng Shen, Tiankuo Li, Youfang Lin, Huaiyu Wan</dc:creator>
        <description><![CDATA[
            时空预测和插补对现实智能系统很重要，现有方法多针对单一任务，且零样本和少样本学习效果不佳，预训练语言模型在时空数据理解方面因对复杂关联建模不足受限。本文提出STD - PLM模型，通过显式设计的时空分词器理解时空关联，设计拓扑感知节点嵌入让模型归纳式理解数据拓扑结构，还设计沙漏注意力模块和约束损失函数提升效率。实验表明，该模型在不同数据集的预测和插补任务中表现和泛化能力强，少样本和零样本任务效果好。
            arXiv:2407.09096v4 Announce Type: replace 
Abstract: Spatial-temporal forecasting and imputation are important for real-world intelligent systems. Most existing methods are tailored for individual forecasting or imputation tasks but are not designed for both. Additionally, they are less effective for zero-shot and few-shot learning. While pre-trained language model (PLM) have exhibited strong pattern recognition and reasoning abilities across various tasks, including few-shot and zero-shot learning, their applications in spatial-temporal data understanding has been constrained by insufficient modeling of complex correlations such as the temporal correlations, spatial connectivity, non-pairwise and high-order spatial-temporal correlations within data. In this paper, we propose STD-PLM for understanding both spatial and temporal properties of \underline{S}patial-\underline{T}emporal \underline{D}ata with \underline{PLM}, which is capable of implementing both spatial-temporal forecasting and imputation tasks. STD-PLM understands spatial-temporal correlations via explicitly designed spatial and temporal tokenizers. Topology-aware node embeddings are designed for PLM to comprehend and exploit the topology structure of data in inductive manner. Furthermore, to mitigate the efficiency issues introduced by the PLM, we design a sandglass attention module (SGA) combined with a specific constrained loss function, which significantly improves the model's efficiency while ensuring performance. Extensive experiments demonstrate that STD-PLM exhibits competitive performance and generalization capabilities across the forecasting and imputation tasks on various datasets. Moreover, STD-PLM achieves promising results on both few-shot and zero-shot tasks. The code is made available at \href{https://github.com/Hyheng/STD-PLM}{https://github.com/Hyheng/STD-PLM}
        ]]></description>
    </item>
    <item>
        <title>Towards the Causal Complete Cause of Multi-Modal Representation Learning</title>
        <link>https://arxiv.org/abs/2407.14058</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2407.14058v5</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jingyao Wang, Siyu Zhao, Wenwen Qiang, Jiangmeng Li, Changwen Zheng, Fuchun Sun, Hui Xiong</dc:creator>
        <description><![CDATA[
            多模态学习旨在跨模态学习有效表征以实现准确预测。现有方法从因果角度看可能使表征包含信息不足或冗余。为此，本文提出有效表征应因果充分且必要，提出因果完全原因$C^3$概念。定义$C^3$并探讨其可识别性，引入工具变量支持识别。进行$C^3$测量即$C^3$风险评估，提出双网络估计。理论分析证实可靠性，提出$C^3$正则化方法，通过最小化$C^3$风险增强表征因果完备性，实验证明其有效。
            arXiv:2407.14058v5 Announce Type: replace 
Abstract: Multi-Modal Learning (MML) aims to learn effective representations across modalities for accurate predictions. Existing methods typically focus on modality consistency and specificity to learn effective representations. However, from a causal perspective, they may lead to representations that contain insufficient and unnecessary information. To address this, we propose that effective MML representations should be causally sufficient and necessary. Considering practical issues like spurious correlations and modality conflicts, we relax the exogeneity and monotonicity assumptions prevalent in prior works and explore the concepts specific to MML, i.e., Causal Complete Cause $C^3$. We begin by defining $C^3$, which quantifies the probability of representations being causally sufficient and necessary. We then discuss the identifiability of $C^3$ and introduce an instrumental variable to support identifying $C^3$ with non-exogeneity and non-monotonicity. Building on this, we conduct the $C^3$ measurement, i.e., \(C^3\) risk. We propose a twin network to estimate it through (i) the real-world branch: utilizing the instrumental variable for sufficiency, and (ii) the hypothetical-world branch: applying gradient-based counterfactual modeling for necessity. Theoretical analyses confirm its reliability. Based on these results, we propose $C^3$ Regularization, a plug-and-play method that enforces the causal completeness of the learned representations by minimizing $C^3$ risk. Extensive experiments demonstrate its effectiveness.
        ]]></description>
    </item>
    <item>
        <title>EvoMesh: Adaptive Physical Simulation with Hierarchical Graph Evolutions</title>
        <link>https://arxiv.org/abs/2410.03779</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.03779v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Huayu Deng, Xiangming Zhu, Yunbo Wang, Xiaokang Yang</dc:creator>
        <description><![CDATA[
            背景：图神经网络是基于网格的物理模拟的有力工具，但现有方法的图层次结构多为手动设计且固定，难以适应复杂物理系统的动态变化。方法：提出EvoMesh框架，联合学习图层次结构和物理动态，由物理输入自适应引导，引入各向异性消息传递，根据物理上下文学习节点选择概率。效果：在五个基准物理模拟数据集上的实验表明，EvoMesh大幅优于近期的固定层次消息传递网络。
            arXiv:2410.03779v2 Announce Type: replace 
Abstract: Graph neural networks have been a powerful tool for mesh-based physical simulation. To efficiently model large-scale systems, existing methods mainly employ hierarchical graph structures to capture multi-scale node relations. However, these graph hierarchies are typically manually designed and fixed, limiting their ability to adapt to the evolving dynamics of complex physical systems. We propose EvoMesh, a fully differentiable framework that jointly learns graph hierarchies and physical dynamics, adaptively guided by physical inputs. EvoMesh introduces anisotropic message passing, which enables direction-specific aggregation of dynamic features between nodes within each hierarchy, while simultaneously learning node selection probabilities for the next hierarchical level based on physical context. This design creates more flexible message shortcuts and enhances the model's capacity to capture long-range dependencies. Extensive experiments on five benchmark physical simulation datasets show that EvoMesh outperforms recent fixed-hierarchy message passing networks by large margins. Code is available at https://github.com/hbell99/EvoMesh.
        ]]></description>
    </item>
    <item>
        <title>SensorLLM: Human-Intuitive Alignment of Multivariate Sensor Data with LLMs for Activity Recognition</title>
        <link>https://arxiv.org/abs/2410.10624</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.10624v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zechen Li, Shohreh Deldari, Linyao Chen, Hao Xue, Flora D. Salim</dc:creator>
        <description><![CDATA[
            背景：大语言模型在推理和泛化方面表现出色，但处理可穿戴传感器时间序列数据时，因语义上下文有限、数值复杂和序列多变而面临挑战。方法：提出两阶段框架SensorLLM，构建问题回答数据集SensorQA监督传感器与语言的对齐阶段，引入特殊标记，使模型将传感器输入与趋势描述对齐；随后进行任务感知微调。效果：在多变量人类活动识别分类中，性能达到或超过现有最优方法，能在不同场景泛化，为时间序列分析的基础模型研究奠定基础。
            arXiv:2410.10624v3 Announce Type: replace 
Abstract: We introduce SensorLLM, a two-stage framework that enables Large Language Models (LLMs) to perform human activity recognition (HAR) from wearable sensor data. While LLMs excel at reasoning and generalization, they struggle with time-series inputs due to limited semantic context, numerical complexity, and sequence variability. To address these challenges, we construct SensorQA, a question-answering dataset of human-intuitive sensor-text pairs spanning diverse HAR scenarios. It supervises the Sensor-Language Alignment stage, where the model aligns sensor inputs with trend descriptions. Special tokens are introduced to mark channel boundaries. This alignment enables LLMs to interpret numerical patterns, channel-specific signals, and variable-length inputs--without requiring human annotation. In the subsequent Task-Aware Tuning stage, we adapt the model for multivariate HAR classification, achieving performance that matches or exceeds state-of-the-art methods. Our results show that, guided by human-intuitive alignment, SensorLLM becomes an effective sensor learner, reasoner, and classifier--generalizing across varied HAR settings and paving the way for foundation model research in time-series analysis.
        ]]></description>
    </item>
    <item>
        <title>The Mystery of the Pathological Path-star Task for Language Models</title>
        <link>https://arxiv.org/abs/2410.13779</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.13779v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Arvid Frydenlund</dc:creator>
        <description><![CDATA[
            背景：新提出的路径 - 星任务用于揭示语言模型能力局限，该任务在路径 - 星图上进行，人类能轻松完成，但语言模型表现不如随机基线。方法：作者假设问题源于教师强制和下一个标记预测范式的不足，通过在替代设置中使用教师强制证明任务可学习，指出部分问题在于表征；引入使用相同图不同目标节点结构化样本的正则化方法，还给出RASP证明。效果：该方法改善了多种模型类型的结果，且发现仅编码器模型在特定设置下能稳定解决任务。
            arXiv:2410.13779v2 Announce Type: replace 
Abstract: The recently introduced path-star task is a minimal task designed to exemplify limitations to the abilities of language models (Bachmann and Nagarajan, 2024). It involves a path-star graph where multiple arms radiate from a single starting node and each node is unique. Given the start node and a specified target node that ends an arm, the task is to generate the arm containing that target node. This is straightforward for a human but surprisingly difficult for language models, which did not outperform the random baseline. The authors hypothesized this is due to a deficiency in teacher-forcing and the next-token prediction paradigm.
  We demonstrate the task is learnable using teacher-forcing in alternative settings and that the issue is partially due to representation. We introduce a regularization method using structured samples of the same graph but with differing target nodes, improving results across a variety of model types. We provide RASP proofs showing the task is theoretically solvable. Finally, we find settings where an encoder-only model can consistently solve the task.
        ]]></description>
    </item>
    <item>
        <title>Graph Retention Networks for Dynamic Graphs</title>
        <link>https://arxiv.org/abs/2411.11259</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2411.11259v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qian Chang, Xia Li, Xiufeng Cheng</dc:creator>
        <description><![CDATA[
            背景：当前缺乏适用于动态图深度学习的统一架构。方法：提出图保留网络（GRN），将保留的核心计算方式扩展到动态图数据，形成图保留，赋予模型三种关键计算范式，实现训练并行、低成本推理和长期批量训练。效果：在基准数据集的边级预测和节点级分类任务中表现优异，与基线模型相比，训练延迟更低、GPU内存消耗更少，推理吞吐量最高提升86.7倍，有潜力成为动态图学习任务的常用架构。
            arXiv:2411.11259v2 Announce Type: replace 
Abstract: In this work, we propose Graph Retention Network as a unified architecture for deep learning on dynamic graphs. The GRN extends the core computational manner of retention to dynamic graph data as graph retention, which empowers the model with three key computational paradigms that enable training parallelism, $O(1)$ low-cost inference, and long-term batch training. This architecture achieves an optimal balance of effectiveness, efficiency, and scalability. Extensive experiments conducted on benchmark datasets present the superior performance of the GRN in both edge-level prediction and node-level classification tasks. Our architecture achieves cutting-edge results while maintaining lower training latency, reduced GPU memory consumption, and up to an 86.7x improvement in inference throughput compared to baseline models. The GRNs have demonstrated strong potential to become a widely adopted architecture for dynamic graph learning tasks. Code will be available at https://github.com/Chandler-Q/GraphRetentionNet.
        ]]></description>
    </item>
    <item>
        <title>Can LLMs be Good Graph Judge for Knowledge Graph Construction?</title>
        <link>https://arxiv.org/abs/2411.17388</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2411.17388v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Haoyu Huang, Chong Chen, Zeang Sheng, Yang Li, Wentao Zhang</dc:creator>
        <description><![CDATA[
            背景：现实中信息检索系统获取的多为非结构化数据，将自然语言句子转换为结构化知识图谱存在挑战，现有方法存在噪声、知识提取不准确、幻觉现象等问题。方法：提出GraphJudge知识图谱构建框架，设计以实体为中心的策略消除文档中的噪声信息，微调大语言模型作为图评判器提升生成知识图谱的质量。效果：在两个通用和一个特定领域的文本 - 图对数据集上实验，表现优于多种基线方法，泛化能力强。
            arXiv:2411.17388v3 Announce Type: replace 
Abstract: In real-world scenarios, most of the data obtained from the information retrieval (IR) system is unstructured. Converting natural language sentences into structured Knowledge Graphs (KGs) remains a critical challenge. We identified three limitations with respect to existing KG construction methods: (1) There could be a large amount of noise in real-world documents, which could result in extracting messy information. (2) Naive LLMs usually extract inaccurate knowledge from some domain-specific documents. (3) Hallucination phenomenon cannot be overlooked when directly using LLMs to construct KGs. In this paper, we propose \textbf{GraphJudge}, a KG construction framework to address the aforementioned challenges. In this framework, we designed an entity-centric strategy to eliminate the noise information in the documents. And we fine-tuned a LLM as a graph judge to finally enhance the quality of generated KGs. Experiments conducted on two general and one domain-specific text-graph pair datasets demonstrate state-of-the-art performance against various baseline methods with strong generalization abilities. Our code is available at \href{https://github.com/hhy-huang/GraphJudge}{https://github.com/hhy-huang/GraphJudge}.
        ]]></description>
    </item>
    <item>
        <title>A Survey of Mathematical Reasoning in the Era of Multimodal Large Language Model: Benchmark, Method & Challenges</title>
        <link>https://arxiv.org/abs/2412.11936</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2412.11936v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yibo Yan, Jiamin Su, Jianxiang He, Fangteng Fu, Xu Zheng, Yuanhuiyi Lyu, Kun Wang, Shen Wang, Qingsong Wen, Xuming Hu</dc:creator>
        <description><![CDATA[
            背景：数学推理是人类认知核心，在多领域至关重要，随着AGI发展，大语言模型与数学推理任务结合愈发重要。方法：该综述全面分析多模态大语言模型时代的数学推理，回顾2021年以来超200项研究，从基准、方法和挑战三方面分类，探讨多模态数学推理流程及相关方法。效果：指出阻碍该领域实现AGI的五大挑战，为提升多模态推理能力指明方向，为学界推进大模型处理复杂多模态推理任务提供关键资源。
            arXiv:2412.11936v3 Announce Type: replace 
Abstract: Mathematical reasoning, a core aspect of human cognition, is vital across many domains, from educational problem-solving to scientific advancements. As artificial general intelligence (AGI) progresses, integrating large language models (LLMs) with mathematical reasoning tasks is becoming increasingly significant. This survey provides the first comprehensive analysis of mathematical reasoning in the era of multimodal large language models (MLLMs). We review over 200 studies published since 2021, and examine the state-of-the-art developments in Math-LLMs, with a focus on multimodal settings. We categorize the field into three dimensions: benchmarks, methodologies, and challenges. In particular, we explore multimodal mathematical reasoning pipeline, as well as the role of (M)LLMs and the associated methodologies. Finally, we identify five major challenges hindering the realization of AGI in this domain, offering insights into the future direction for enhancing multimodal reasoning capabilities. This survey serves as a critical resource for the research community in advancing the capabilities of LLMs to tackle complex multimodal reasoning tasks.
        ]]></description>
    </item>
    <item>
        <title>TimeFilter: Patch-Specific Spatial-Temporal Graph Filtration for Time Series Forecasting</title>
        <link>https://arxiv.org/abs/2501.13041</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2501.13041v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yifan Hu, Guibin Zhang, Peiyuan Liu, Disen Lan, Naiqi Li, Dawei Cheng, Tao Dai, Shu-Tao Xia, Shirui Pan</dc:creator>
        <description><![CDATA[
            背景：现有时间序列预测方法分通道独立（CI）和通道依赖（CD）策略，前者忽略协变量关系，后者引入噪声、降低泛化，通道聚类（CC）也难以有效捕捉复杂时变交互。方法：提出基于GNN的TimeFilter框架，从输入序列构建图后，以特定块方式过滤无关相关性、保留关键相关性，实现自适应细粒度依赖建模。效果：在13个不同领域真实数据集上实验，展现了最优性能。代码见https://github.com/TROUBADOUR000/TimeFilter。
            arXiv:2501.13041v2 Announce Type: replace 
Abstract: Time series forecasting methods generally fall into two main categories: Channel Independent (CI) and Channel Dependent (CD) strategies. While CI overlooks important covariate relationships, CD captures all dependencies without distinction, introducing noise and reducing generalization. Recent advances in Channel Clustering (CC) aim to refine dependency modeling by grouping channels with similar characteristics and applying tailored modeling techniques. However, coarse-grained clustering struggles to capture complex, time-varying interactions effectively. To address these challenges, we propose TimeFilter, a GNN-based framework for adaptive and fine-grained dependency modeling. After constructing the graph from the input sequence, TimeFilter refines the learned spatial-temporal dependencies by filtering out irrelevant correlations while preserving the most critical ones in a patch-specific manner. Extensive experiments on 13 real-world datasets from diverse application domains demonstrate the state-of-the-art performance of TimeFilter. The code is available at https://github.com/TROUBADOUR000/TimeFilter.
        ]]></description>
    </item>
    <item>
        <title>When Do LLMs Help With Node Classification? A Comprehensive Analysis</title>
        <link>https://arxiv.org/abs/2502.00829</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.00829v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xixi Wu, Yifei Shen, Fangzhou Ge, Caihua Shan, Yizhu Jiao, Xiangguo Sun, Hong Cheng</dc:creator>
        <description><![CDATA[
            背景：节点分类是图分析基础任务，大语言模型（LLMs）为该任务带来新方法，但缺乏明确设计指南。方法：开发了用于基于LLMs节点分类的综合代码库和测试平台LLMNodeBed，包含多种数据集、算法等；开展超2700个模型的实验，确定影响性能的关键设置和组件。效果：得出8点见解，如半监督场景下基于LLMs方法显著优于传统方法，零样本场景下图基础模型不敌GPT - 4o等。
            arXiv:2502.00829v2 Announce Type: replace 
Abstract: Node classification is a fundamental task in graph analysis, with broad applications across various fields. Recent breakthroughs in Large Language Models (LLMs) have enabled LLM-based approaches for this task. Although many studies demonstrate the impressive performance of LLM-based methods, the lack of clear design guidelines may hinder their practical application. In this work, we aim to establish such guidelines through a fair and systematic comparison of these algorithms. As a first step, we developed LLMNodeBed, a comprehensive codebase and testbed for node classification using LLMs. It includes 10 homophilic datasets, 4 heterophilic datasets, 8 LLM-based algorithms, 8 classic baselines, and 3 learning paradigms. Subsequently, we conducted extensive experiments, training and evaluating over 2,700 models, to determine the key settings (e.g., learning paradigms and homophily) and components (e.g., model size and prompt) that affect performance. Our findings uncover 8 insights, e.g., (1) LLM-based methods can significantly outperform traditional methods in a semi-supervised setting, while the advantage is marginal in a supervised setting; (2) Graph Foundation Models can beat open-source LLMs but still fall short of strong LLMs like GPT-4o in a zero-shot setting. We hope that the release of LLMNodeBed, along with our insights, will facilitate reproducible research and inspire future studies in this field. Codes and datasets are released at \href{https://llmnodebed.github.io/}{\texttt{https://llmnodebed.github.io/}}.
        ]]></description>
    </item>
    <item>
        <title>Premise-Augmented Reasoning Chains Improve Error Identification in Math reasoning with LLMs</title>
        <link>https://arxiv.org/abs/2502.02362</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.02362v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sagnik Mukherjee, Abhinav Chinta, Takyoung Kim, Tarun Anoop Sharma, Dilek Hakkani-T\"ur</dc:creator>
        <description><![CDATA[
            背景：思维链提示虽能提升大语言模型数学推理能力，但推理链长，难以验证步骤和追踪问题。方法：提出识别各步骤前提的框架，将传统线性推理链重构为前提增强推理链（PARC），形成有向无环图。效果：通过自建数据集实验，大语言模型能可靠识别复杂推理链中的前提，开源模型前提识别召回率达90%，且PARC使推理链错误识别准确率在前提验证下绝对提升6% - 16%，为提升推理评估可靠性开辟新途径。
            arXiv:2502.02362v4 Announce Type: replace 
Abstract: Chain-of-Thought (CoT) prompting enhances mathematical reasoning in large language models (LLMs) by enabling detailed step-by-step solutions. However, due to the verbosity of LLMs, the resulting reasoning chains can be long, making it harder to verify the reasoning steps and trace issues resulting from dependencies between the steps that may be farther away in the sequence of steps. Importantly, mathematical reasoning allows each step to be derived from a small set of premises, which are a subset of the preceding steps in the reasoning chain. In this paper, we present a framework that identifies the premises for each step, to improve the evaluation of reasoning. We restructure conventional linear reasoning chains into Premise Augmented Reasoning Chains (PARC) by introducing premise links, resulting in a directed acyclic graph where the nodes are the steps and the edges are the premise links. Through experiments with a PARC-based dataset that we built, namely PERL (Premises and ERrors identification in LLMs), we demonstrate that LLMs can reliably identify premises within complex reasoning chains. In particular, even open-source LLMs achieve 90% recall in premise identification. We also show that PARC helps to identify errors in reasoning chains more reliably. The accuracy of error identification improves by 6% to 16% absolute when step-by-step verification is carried out in PARC under the premises. Our findings highlight the utility of premise-centric representations in addressing complex problem-solving tasks and open new avenues for improving the reliability of LLM-based reasoning evaluations.
        ]]></description>
    </item>
    <item>
        <title>MMUnlearner: Reformulating Multimodal Machine Unlearning in the Era of Multimodal Large Language Models</title>
        <link>https://arxiv.org/abs/2502.11051</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.11051v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiahao Huo, Yibo Yan, Xu Zheng, Yuanhuiyi Lyu, Xin Zou, Zhihua Wei, Xuming Hu</dc:creator>
        <description><![CDATA[
            背景：当前机器学习遗忘（MU）在多模态大语言模型（MLLMs）领域尚处起步阶段。方法：提出在MLLMs时代重新定义多模态MU任务，仅擦除与给定实体相关的视觉模式，同时保留语言模型主干原始参数中编码的文本知识；开发几何约束梯度上升方法MMUnlearner，在遗忘过程中用剩余概念和文本知识共同限制的权重显著性图更新MLLMs权重。效果：实验表明，MMUnlearner在各评估维度上均优于直接用梯度上升或负偏好优化微调MLLMs的基线方法。
            arXiv:2502.11051v3 Announce Type: replace 
Abstract: Recent progress in Machine Unlearning (MU) has introduced solutions for the selective removal of private or sensitive information encoded within deep neural networks. Nonetheless, MU for Multimodal Large Language Models (MLLMs) remains in its nascent phase. Therefore, we propose to reformulate the task of multimodal MU in the era of MLLMs, which aims to erase only the visual patterns associated with a given entity while preserving the corresponding textual knowledge encoded within the original parameters of the language model backbone. Furthermore, we develop a novel geometry-constrained gradient ascent method MMUnlearner. It updates the weights of MLLMs with a weight saliency map jointly restricted by the remaining concepts and textual knowledge during unlearning, thereby preserving parameters essential for non-target knowledge. Extensive experiments demonstrate that MMUnlearner surpasses baselines that finetuning MLLMs with VQA data directly through Gradient Ascent (GA) or Negative Preference Optimization (NPO), across all evaluation dimensions. Our code will be released upon acceptance.
        ]]></description>
    </item>
    <item>
        <title>FineFilter: A Fine-grained Noise Filtering Mechanism for Retrieval-Augmented Large Language Models</title>
        <link>https://arxiv.org/abs/2502.11811</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.11811v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qianchi Zhang, Hainan Zhang, Liang Pang, Ziwei Wang, Hongwei Zheng, Yongxin Tong, Zhiming Zheng</dc:creator>
        <description><![CDATA[
            背景：含噪声的检索文档会阻碍检索增强生成（RAG）发现答案线索，现有方法难以从大规模复杂文档中精准定位答案。方法：提出FineFilter，将噪声过滤视为句子级MinMax优化问题，由线索提取器、重排器和截断器组成，分别通过特定的微调目标来优化，实现细粒度噪声过滤。效果：在三个问答数据集上实验表明，FineFilter在LLaMA3和Mistral上显著提升问答性能，且在复杂推理、应对不可靠检索及场景泛化上有效。
            arXiv:2502.11811v3 Announce Type: replace 
Abstract: Retrieved documents containing noise will hinder Retrieval-Augmented Generation (RAG) from detecting answer clues, necessitating noise filtering mechanisms to enhance accuracy. Existing methods use reranking or summarization to identify the most relevant sentences, but directly and accurately locating answer clues from these large-scale and complex documents remains challenging. Unlike these document-level operations, we treat noise filtering as a sentence-level MinMax optimization problem: first identifying potential clues from multiple documents, then ranking them by relevance, and finally retaining the minimum number of clues through truncation. In this paper, we propose FineFilter, a novel fine-grained noise filtering mechanism for RAG, consisting of a clue extractor, a reranker, and a truncator. We optimize each module to tackle complex reasoning challenges: (1) The clue extractor first uses sentences containing the answer and similar ones as fine-tuning targets, aiming to extract sufficient potential clues; (2) The reranker is trained to prioritize effective clues based on the real feedback from the generation module, with clues capable of generating correct answers as positive samples and others as negative; (3) The truncator takes the minimum number of clues needed to answer the question (truncation point) as fine-tuning targets, and performs truncation on the reranked clues to achieve fine-grained noise filtering. Experiments on three QA datasets demonstrate that FineFilter significantly improves QA performance over baselines on both LLaMA3 and Mistral. Further analysis confirms its effectiveness in complex reasoning, robustness to unreliable retrieval, and generalization to different scenarios.
        ]]></description>
    </item>
    <item>
        <title>R2-KG: General-Purpose Dual-Agent Framework for Reliable Reasoning on Knowledge Graphs</title>
        <link>https://arxiv.org/abs/2502.12767</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.12767v5</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sumin Jo, Junseong Choi, Jiho Kim, Edward Choi</dc:creator>
        <description><![CDATA[
            背景：现有大语言模型与知识图谱结合的推理框架存在需重新调参、依赖高容量模型的问题。方法：提出R2 - KG双智能体框架，将推理分为证据收集的算子（低容量大模型）和最终判断的监督者（高容量大模型），还采用弃权机制。效果：在五个基准测试中，R2 - KG在准确率和可靠性上均超基线；单智能体版本用严格自一致性策略，降低推理成本、提高可靠性，但在复杂图谱中弃权率增加。
            arXiv:2502.12767v5 Announce Type: replace 
Abstract: Recent studies have combined Large Language Models (LLMs) with Knowledge Graphs (KGs) to enhance reasoning, improving inference accuracy without additional training while mitigating hallucination. However, existing frameworks still suffer two practical drawbacks: they must be re-tuned whenever the KG or reasoning task changes, and they depend on a single, high-capacity LLM for reliable (i.e., trustworthy) reasoning. To address this, we introduce R2-KG, a plug-and-play, dual-agent framework that separates reasoning into two roles: an Operator (a low-capacity LLM) that gathers evidence and a Supervisor (a high-capacity LLM) that makes final judgments. This design is cost-efficient for LLM inference while still maintaining strong reasoning accuracy. Additionally, R2-KG employs an Abstention mechanism, generating answers only when sufficient evidence is collected from KG, which significantly enhances reliability. Experiments across five diverse benchmarks show that R2-KG consistently outperforms baselines in both accuracy and reliability, regardless of the inherent capability of LLMs used as the Operator. Further experiments reveal that the single-agent version of R2-KG, equipped with a strict self-consistency strategy, achieves significantly higher-than-baseline reliability with reduced inference cost but increased abstention rate in complex KGs. Our findings establish R2-KG as a flexible and cost-effective solution for KG-based reasoning, reducing reliance on high-capacity LLMs while ensuring trustworthy inference. The code is available at https://github.com/ekrxjwh2009/R2-KG/.
        ]]></description>
    </item>
    <item>
        <title>SQLong: Enhanced NL2SQL for Longer Contexts with LLMs</title>
        <link>https://arxiv.org/abs/2502.16747</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.16747v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Dai Quoc Nguyen, Cong Duy Vu Hoang, Duy Vu, Gioacchino Tangari, Thanh Tien Vu, Don Dharmasiri, Yuan-Fang Li, Long Duong</dc:creator>
        <description><![CDATA[
            背景：开放权重的大语言模型在自然语言到SQL（NL2SQL）任务中表现出色，但处理大数据库模式时，随上下文长度增加效果下降。方法：提出SQLong数据增强框架，通过用额外的合成CREATE TABLE命令和对应数据行扩展现有数据库模式来生成增强数据集，模拟长上下文场景。效果：在Spider和BIRD数据集上实验表明，用SQLong增强数据微调的大模型显著优于用标准数据集训练的模型，能提升复杂数据库模式下的NL2SQL能力。
            arXiv:2502.16747v2 Announce Type: replace 
Abstract: Open-weight large language models (LLMs) have significantly advanced performance in the Natural Language to SQL (NL2SQL) task. However, their effectiveness diminishes when dealing with large database schemas, as the context length increases. To address this limitation, we present SQLong, a novel and efficient data augmentation framework designed to enhance LLM performance in long-context scenarios for the NL2SQL task. SQLong generates augmented datasets by extending existing database schemas with additional synthetic CREATE TABLE commands and corresponding data rows, sampled from diverse schemas in the training data. This approach effectively simulates long-context scenarios during finetuning and evaluation. Through experiments on the Spider and BIRD datasets, we demonstrate that LLMs finetuned with SQLong-augmented data significantly outperform those trained on standard datasets. These imply SQLong's practical implementation and its impact on improving NL2SQL capabilities in real-world settings with complex database schemas.
        ]]></description>
    </item>
    <item>
        <title>CODI: Compressing Chain-of-Thought into Continuous Space via Self-Distillation</title>
        <link>https://arxiv.org/abs/2502.21074</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.21074v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhenyi Shen, Hanqi Yan, Linhai Zhang, Zhanghao Hu, Yali Du, Yulan He</dc:creator>
        <description><![CDATA[
            背景：思维链推理能提升大语言模型性能，但利用潜在连续空间推理或更高效稳健，此前隐式思维链方法效果不如显式。方法：提出CODI训练框架，联合训练教师任务（显式思维链）和学生任务（隐式思维链），通过对齐指定标记的隐藏状态，将自然语言思维链压缩到连续空间。效果：在GPT - 2规模的GSM8k上，首次使隐式思维链达到显式思维链的性能，压缩率达3.1倍，准确率比此前最优方法高28.2%，且具鲁棒性、可推广性和可解释性。
            arXiv:2502.21074v2 Announce Type: replace 
Abstract: Chain-of-Thought (CoT) reasoning enhances Large Language Models (LLMs) by encouraging step-by-step reasoning in natural language. However, leveraging a latent continuous space for reasoning may offer benefits in terms of both efficiency and robustness. Prior implicit CoT methods attempt to bypass language completely by reasoning in continuous space but have consistently underperformed compared to the standard explicit CoT approach. We introduce CODI (Continuous Chain-of-Thought via Self-Distillation), a novel training framework that effectively compresses natural language CoT into continuous space. CODI jointly trains a teacher task (Explicit CoT) and a student task (Implicit CoT), distilling the reasoning ability from language into continuous space by aligning the hidden states of a designated token. Our experiments show that CODI is the first implicit CoT approach to match the performance of explicit CoT on GSM8k at the GPT-2 scale, achieving a 3.1x compression rate and outperforming the previous state-of-the-art by 28.2% in accuracy. CODI also demonstrates robustness, generalizable to complex datasets, and interpretability. These results validate that LLMs can reason effectively not only in natural language, but also in a latent continuous space.
        ]]></description>
    </item>
    <item>
        <title>Language Models, Graph Searching, and Supervision Adulteration: When More Supervision is Less and How to Make More More</title>
        <link>https://arxiv.org/abs/2503.10542</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.10542v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Arvid Frydenlund</dc:creator>
        <description><![CDATA[
            背景：在图搜索的路径星任务中，仅解码器语言模型（LM）因学习捷径吸收训练监督，难以解决此基础任务。方法：该研究分析此问题由过度监督导致，并提出一系列解决方案，以证明仅解码器LM可解决该任务。效果：研究发现任务的简单性导致其难以分解，这些解决方案有助于深入了解该问题，以及对通过下一令牌预测训练的LM的影响。 
            arXiv:2503.10542v2 Announce Type: replace 
Abstract: This work concerns the path-star task, a minimal example of searching over a graph. The graph, $G$, is star-shaped with $D$ arms radiating from a start node, $s$. A language model (LM) is given $G$, $s$, and a target node $t$, which ends one of the arms and is tasked with generating the arm containing $t$. The minimal nature of this task means only a single choice needs to be made: which of the $D$ arms contains $t$?
  Decoder-only LMs fail to solve this elementary task above $1/D$ chance due to a learned shortcut that absorbs training supervision. We show how this pathology is caused by excess supervision and we present a series of solutions demonstrating that the task is solvable via decoder-only LMs. We find that the task's minimal nature causes its difficulty, as it prevents task decomposition. Our solutions provide insight into the pathology and its implications for LMs trained via next-token prediction.
        ]]></description>
    </item>
    <item>
        <title>Open3DVQA: A Benchmark for Comprehensive Spatial Reasoning with Multimodal Large Language Model in Open Space</title>
        <link>https://arxiv.org/abs/2503.11094</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.11094v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Weichen Zhang, Zile Zhou, Zhiheng Zheng, Chen Gao, Jinqiang Cui, Yong Li, Xinlei Chen, Xiao-Ping Zhang</dc:creator>
        <description><![CDATA[
            背景：空间推理是具身智能体的基本能力，在多模态大语言模型领域备受关注。方法：提出新基准Open3DVQA，含9k个VQA样本，用半自动化工具在高保真城市模拟器中收集，从多方面评估多个SOTA多模态大模型。效果：大模型回答相对空间关系问题表现更好，以自我和以环境为中心视角的空间推理能力相近，微调大模型可显著提升不同空间推理任务性能。
            arXiv:2503.11094v2 Announce Type: replace 
Abstract: Spatial reasoning is a fundamental capability of embodied agents and has garnered widespread attention in the field of multimodal large language models (MLLMs). In this work, we propose a novel benchmark, Open3DVQA, to comprehensively evaluate the spatial reasoning capacities of current state-of-the-art (SOTA) foundation models in open 3D space. Open3DVQA consists of 9k VQA samples, collected using an efficient semi-automated tool in a high-fidelity urban simulator. We evaluate several SOTA MLLMs across various aspects of spatial reasoning, such as relative and absolute spatial relationships, situational reasoning, and object-centric spatial attributes. Our results reveal that: 1) MLLMs perform better at answering questions regarding relative spatial relationships than absolute spatial relationships, 2) MLLMs demonstrate similar spatial reasoning abilities for both egocentric and allocentric perspectives, and 3) Fine-tuning large models significantly improves their performance across different spatial reasoning tasks. We believe that our open-source data collection tools and in-depth analyses will inspire further research on MLLM spatial reasoning capabilities. The benchmark is available at https://github.com/WeichenZh/Open3DVQA.
        ]]></description>
    </item>
    <item>
        <title>Scaling Test-Time Inference with Policy-Optimized, Dynamic Retrieval-Augmented Generation via KV Caching and Decoding</title>
        <link>https://arxiv.org/abs/2504.01281</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.01281v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sakhinana Sagar Srinivas, Akash Das, Shivam Gupta, Venkataramana Runkana</dc:creator>
        <description><![CDATA[
            背景：提升检索增强生成（RAG）系统性能以应对知识密集型任务。方法：提出综合框架，集成策略优化检索增强生成（PORAG）和自适应令牌层注意力评分（ATLAS），还提出CRITIC方法压缩键值缓存，结合测试时扩展技术和优化解码策略。效果：在基准数据集实验显示，该框架减少幻觉，增强特定领域推理，相比传统RAG系统，在效率和可扩展性上有显著提升，提升了输出准确性和响应质量。
            arXiv:2504.01281v3 Announce Type: replace 
Abstract: We present a comprehensive framework for enhancing Retrieval-Augmented Generation (RAG) systems through dynamic retrieval strategies and reinforcement fine-tuning. This approach significantly improves large language models on knowledge-intensive tasks, including opendomain question answering and complex reasoning. Our framework integrates two complementary techniques: Policy-Optimized RetrievalAugmented Generation (PORAG), which optimizes the use of retrieved information, and Adaptive Token-Layer Attention Scoring (ATLAS), which dynamically determines retrieval timing and content based on contextual needs. Together, these techniques enhance both the utilization and relevance of retrieved content, improving factual accuracy and response quality. Designed as a lightweight solution compatible with any Transformer-based LLM without requiring additional training, our framework excels in knowledge-intensive tasks, boosting output accuracy in RAG settings. We further propose CRITIC, a novel method to selectively compress key-value caches by token importance, mitigating memory bottlenecks in long-context applications. The framework also incorporates test-time scaling techniques to dynamically balance reasoning depth and computational resources, alongside optimized decoding strategies for faster inference. Experiments on benchmark datasets show that our framework reduces hallucinations, strengthens domain-specific reasoning, and achieves significant efficiency and scalability gains over traditional RAG systems. This integrated approach advances the development of robust, efficient, and scalable RAG systems across diverse applications.
        ]]></description>
    </item>
    <item>
        <title>AS3D: 2D-Assisted Cross-Modal Understanding with Semantic-Spatial Scene Graphs for 3D Visual Grounding</title>
        <link>https://arxiv.org/abs/2505.04058</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.04058v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Feng Xiao, Hongbin Xu, Guocan Zhao, Wenxiong Kang</dc:creator>
        <description><![CDATA[
            背景：3D视觉定位任务中，3D与语言模态差距大，通过描述的空间关系区分相似对象是挑战，现有方法忽视被指对象感知。方法：提出2D辅助的3D视觉定位框架，构建含被指对象辨别的语义 - 空间场景图用于关系感知，采用双分支视觉编码器，用2D预训练属性引导多模态对象编码，通过图注意力进行跨模态交互。效果：在流行基准测试中表现优于现有方法，尤其在处理多个相似干扰项方面。
            arXiv:2505.04058v2 Announce Type: replace 
Abstract: 3D visual grounding aims to localize the unique target described by natural languages in 3D scenes. The significant gap between 3D and language modalities makes it a notable challenge to distinguish multiple similar objects through the described spatial relationships. Current methods attempt to achieve cross-modal understanding in complex scenes via a target-centered learning mechanism, ignoring the perception of referred objects. We propose a novel 2D-assisted 3D visual grounding framework that constructs semantic-spatial scene graphs with referred object discrimination for relationship perception. The framework incorporates a dual-branch visual encoder that utilizes 2D pre-trained attributes to guide the multi-modal object encoding. Furthermore, our cross-modal interaction module uses graph attention to facilitate relationship-oriented information fusion. The enhanced object representation and iterative relational learning enable the model to establish effective alignment between 3D vision and referential descriptions. Experimental results on the popular benchmarks demonstrate our superior performance compared to state-of-the-art methods, especially in addressing the challenges of multiple similar distractors.
        ]]></description>
    </item>
    <item>
        <title>When Thinking Fails: The Pitfalls of Reasoning for Instruction-Following in LLMs</title>
        <link>https://arxiv.org/abs/2505.11423</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.11423v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiaomin Li, Zhou Yu, Zhiwei Zhang, Xupeng Chen, Ziji Zhang, Yingying Zhuang, Narayanan Sadagopan, Anurag Beniwal</dc:creator>
        <description><![CDATA[
            背景：推理增强的大语言模型在复杂推理任务上表现出色，但显式思维链推理对指令遵循准确性的影响被忽视。方法：在两个基准上评估15个模型，通过案例研究和注意力分析找出推理的利弊，提出约束注意力指标，还引入四种策略减轻推理负面影响。效果：评估显示，选择性推理策略尤其是分类器选择性推理能大幅挽回损失的性能，该研究首次系统揭示推理在指令遵循中的问题并给出解决策略。
            arXiv:2505.11423v2 Announce Type: replace 
Abstract: Reasoning-enhanced large language models (RLLMs), whether explicitly trained for reasoning or prompted via chain-of-thought (CoT), have achieved state-of-the-art performance on many complex reasoning tasks. However, we uncover a surprising and previously overlooked phenomenon: explicit CoT reasoning can significantly degrade instruction-following accuracy. Evaluating 15 models on two benchmarks: IFEval (with simple, rule-verifiable constraints) and ComplexBench (with complex, compositional constraints), we consistently observe performance drops when CoT prompting is applied. Through large-scale case studies and an attention-based analysis, we identify common patterns where reasoning either helps (e.g., with formatting or lexical precision) or hurts (e.g., by neglecting simple constraints or introducing unnecessary content). We propose a metric, constraint attention, to quantify model focus during generation and show that CoT reasoning often diverts attention away from instruction-relevant tokens. To mitigate these effects, we introduce and evaluate four strategies: in-context learning, self-reflection, self-selective reasoning, and classifier-selective reasoning. Our results demonstrate that selective reasoning strategies, particularly classifier-selective reasoning, can substantially recover lost performance. To our knowledge, this is the first work to systematically expose reasoning-induced failures in instruction-following and offer practical mitigation strategies.
        ]]></description>
    </item>
    <item>
        <title>Multimodal Cancer Survival Analysis via Hypergraph Learning with Cross-Modality Rebalance</title>
        <link>https://arxiv.org/abs/2505.11997</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.11997v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mingcheng Qu, Guang Yang, Donglin Di, Tonghua Su, Yue Gao, Yang Song, Lei Fan</dc:creator>
        <description><![CDATA[
            背景：多模态病理 - 基因组分析在癌症生存预测中愈发重要，但现有研究忽视病理图像上下文和层次细节信息损失，且存在模态不平衡问题。方法：提出一种多模态生存预测框架，用超图学习捕获病理图像上下文和层次细节，采用模态再平衡机制和交互式对齐融合策略动态重新加权两种模态的贡献。效果：在五个TCGA数据集上的实验表明，该模型在C - Index性能上比先进方法高出超3.4%。
            arXiv:2505.11997v2 Announce Type: replace 
Abstract: Multimodal pathology-genomic analysis has become increasingly prominent in cancer survival prediction. However, existing studies mainly utilize multi-instance learning to aggregate patch-level features, neglecting the information loss of contextual and hierarchical details within pathology images. Furthermore, the disparity in data granularity and dimensionality between pathology and genomics leads to a significant modality imbalance. The high spatial resolution inherent in pathology data renders it a dominant role while overshadowing genomics in multimodal integration. In this paper, we propose a multimodal survival prediction framework that incorporates hypergraph learning to effectively capture both contextual and hierarchical details from pathology images. Moreover, it employs a modality rebalance mechanism and an interactive alignment fusion strategy to dynamically reweight the contributions of the two modalities, thereby mitigating the pathology-genomics imbalance. Quantitative and qualitative experiments are conducted on five TCGA datasets, demonstrating that our model outperforms advanced methods by over 3.4\% in C-Index performance.
        ]]></description>
    </item>
    <item>
        <title>Enhancing Channel-Independent Time Series Forecasting via Cross-Variate Patch Embedding</title>
        <link>https://arxiv.org/abs/2505.12761</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12761v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Donghwa Shin, Edwin Zhang</dc:creator>
        <description><![CDATA[
            背景：Transformer在时间序列预测中流行，但现有模型多只关注时间依赖，忽略变量间复杂关系，且全层依赖通道易过拟合。方法：提出轻量级通道依赖模块Cross-Variate Patch Embeddings（CVPE），通过修改补丁嵌入过程，在通道独立模型中注入跨变量上下文，将其集成到多模态通道独立预测模型Time - LLM中。效果：在七个真实数据集上实验表明，仅集成CVPE模块，增强后的Time - LLM性能优于原基线模型。
            arXiv:2505.12761v2 Announce Type: replace 
Abstract: Transformers have recently gained popularity in time series forecasting due to their ability to capture long-term dependencies. However, many existing models focus only on capturing temporal dependencies while omitting intricate relationships between variables. Recent models have tried tackling this by explicitly modeling both cross-time and cross-variate dependencies through a sequential or unified attention mechanism, but they are entirely channel dependent (CD) across all layers, making them potentially susceptible to overfitting. To address this, we propose Cross-Variate Patch Embeddings (CVPE), a lightweight CD module that injects cross-variate context into channel-independent (CI) models by simply modifying the patch embedding process. We achieve this by adding a learnable positional encoding and a lightweight router-attention block to the vanilla patch embedding layer. We then integrate CVPE into Time-LLM, a multimodal CI forecasting model, to demonstrate its effectiveness in capturing cross-variate dependencies and enhance the CI model's performance. Extensive experimental results on seven real-world datasets show that our enhanced Time-LLM outperforms the original baseline model simply by incorporating the CVPE module, with no other changes.
        ]]></description>
    </item>
    <item>
        <title>ReEx-SQL: Reasoning with Execution-Aware Reinforcement Learning for Text-to-SQL</title>
        <link>https://arxiv.org/abs/2505.12768</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12768v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yaxun Dai, Wenxuan Xie, Xialie Zhuang, Tianyu Yang, Yiying Yang, Haiqin Yang, Yuhang Zhao, Pingfu Chao, Wenhao Jiang</dc:creator>
        <description><![CDATA[
            在Text-to-SQL任务中，现有方法未将执行反馈融入生成过程，影响查询准确性和鲁棒性。为此提出ReEx - SQL框架，让模型在解码时与数据库交互，基于执行反馈动态调整推理。该框架引入执行感知推理范式，通过带标记的结构化提示和逐步展开策略将执行反馈融入生成各阶段，设计复合奖励函数监督策略学习，采用树型解码策略支持探索性推理。在Spider、BIRD等数据集上表现优异，超标准推理基线，且树型解码提升效率，在BIRD开发集上推理时间减少51.9%。
            arXiv:2505.12768v2 Announce Type: replace 
Abstract: In Text-to-SQL, execution feedback is essential for guiding large language models (LLMs) to reason accurately and generate reliable SQL queries. However, existing methods treat execution feedback solely as a post-hoc signal for correction or selection, failing to integrate it into the generation process. This limitation hinders their ability to address reasoning errors as they occur, ultimately reducing query accuracy and robustness. To address this issue, we propose ReEx-SQL (Reasoning with Execution-Aware Reinforcement Learning), a framework for Text-to-SQL that enables models to interact with the database during decoding and dynamically adjust their reasoning based on execution feedback. ReEx-SQL introduces an execution-aware reasoning paradigm that interleaves intermediate SQL execution into reasoning paths, facilitating context-sensitive revisions. It achieves this through structured prompts with markup tags and a stepwise rollout strategy that integrates execution feedback into each stage of generation. To supervise policy learning, we develop a composite reward function that includes an exploration reward, explicitly encouraging effective database interaction. Additionally, ReEx-SQL adopts a tree-based decoding strategy to support exploratory reasoning, enabling dynamic expansion of alternative reasoning paths. Notably, ReEx-SQL achieves 88.8% on Spider and 64.9% on BIRD at the 7B scale, surpassing the standard reasoning baseline by 2.7% and 2.6%, respectively. It also shows robustness, achieving 85.2% on Spider-Realistic with leading performance. In addition, its tree-structured decoding improves efficiency and performance over linear decoding, reducing inference time by 51.9% on the BIRD development set.
        ]]></description>
    </item>
    <item>
        <title>Rank, Chunk and Expand: Lineage-Oriented Reasoning for Taxonomy Expansion</title>
        <link>https://arxiv.org/abs/2505.13282</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13282v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sahil Mishra, Kumar Arjun, Tanmoy Chakraborty</dc:creator>
        <description><![CDATA[
            背景：分类法作为重要的层次知识图谱，在数据增长时进行扩展很关键，但现有判别和生成方法各有局限。方法：提出LORex框架，结合判别排序和生成推理进行分类法扩展，对候选术语排序分块，通过推理候选者层次结构过滤噪声、迭代优化选择。效果：在四个基准和十二个基线模型上的大量实验显示，与现有方法相比，LORex的准确率提高12%，Wu & Palmer相似度提高5%。
            arXiv:2505.13282v2 Announce Type: replace 
Abstract: Taxonomies are hierarchical knowledge graphs crucial for recommendation systems, and web applications. As data grows, expanding taxonomies is essential, but existing methods face key challenges: (1) discriminative models struggle with representation limits and generalization, while (2) generative methods either process all candidates at once, introducing noise and exceeding context limits, or discard relevant entities by selecting noisy candidates. We propose LORex ($\textbf{L}$ineage-$\textbf{O}$riented $\textbf{Re}$asoning for Taxonomy E$\textbf{x}$pansion), a plug-and-play framework that combines discriminative ranking and generative reasoning for efficient taxonomy expansion. Unlike prior methods, LORex ranks and chunks candidate terms into batches, filtering noise and iteratively refining selections by reasoning candidates' hierarchy to ensure contextual efficiency. Extensive experiments across four benchmarks and twelve baselines show that LORex improves accuracy by 12% and Wu & Palmer similarity by 5% over state-of-the-art methods.
        ]]></description>
    </item>
    <item>
        <title>MMDocIR: Benchmarking Multi-Modal Retrieval for Long Documents</title>
        <link>https://arxiv.org/abs/2501.08828</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2501.08828v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kuicai Dong, Yujing Chang, Xin Deik Goh, Dexun Li, Ruiming Tang, Yong Liu</dc:creator>
        <description><![CDATA[
            背景：多模态文档检索缺乏全面且强大的基准来评估系统性能。方法：本文引入新基准MMDocIR，包含页面级和布局级检索两个任务，数据集含专家标注的1685个问题和有引导标签的173843个问题。效果：实验表明，视觉检索器显著优于文本检索器；MMDocIR训练集有效提升多模态文档检索性能；利用VLM - 文本的文本检索器显著优于依赖OCR - 文本的检索器。
            arXiv:2501.08828v2 Announce Type: replace-cross 
Abstract: Multimodal document retrieval aims to identify and retrieve various forms of multimodal content, such as figures, tables, charts, and layout information from extensive documents. Despite its increasing popularity, there is a notable lack of a comprehensive and robust benchmark to effectively evaluate the performance of systems in such tasks. To address this gap, this work introduces a new benchmark, named MMDocIR, that encompasses two distinct tasks: page-level and layout-level retrieval. The former evaluates the performance of identifying the most relevant pages within a long document, while the later assesses the ability of detecting specific layouts, providing a more fine-grained measure than whole-page analysis. A layout refers to a variety of elements, including textual paragraphs, equations, figures, tables, or charts. The MMDocIR benchmark comprises a rich dataset featuring 1,685 questions annotated by experts and 173,843 questions with bootstrapped labels, making it a valuable resource in multimodal document retrieval for both training and evaluation. Through rigorous experiments, we demonstrate that (i) visual retrievers significantly outperform their text counterparts, (ii) MMDocIR training set effectively enhances the performance of multimodal document retrieval and (iii) text retrievers leveraging VLM-text significantly outperforms retrievers relying on OCR-text. Our dataset is available at https://mmdocrag.github.io/MMDocIR/.
        ]]></description>
    </item>
    <item>
        <title>From Words to Collisions: LLM-Guided Evaluation and Adversarial Generation of Safety-Critical Driving Scenarios</title>
        <link>https://arxiv.org/abs/2502.02145</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.02145v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuan Gao, Mattia Piccinini, Korbinian Moller, Johannes Betz</dc:creator>
        <description><![CDATA[
            背景：确保自动驾驶车辆安全需基于虚拟场景测试，现有的场景测试框架依赖手工场景作为安全指标，存在人工解释费力和可扩展性有限问题。方法：结合大语言模型与结构化场景解析及提示工程，引入笛卡尔和以自我为中心的提示策略用于场景评估，还有对抗生成模块修改风险车辆轨迹以创建关键场景。效果：经2D仿真框架和多个预训练大语言模型验证，评估模块能有效检测碰撞场景并推断安全性，生成模块能识别高风险主体并合成逼真的关键场景，减少对手工指标的依赖。
            arXiv:2502.02145v2 Announce Type: replace-cross 
Abstract: Ensuring the safety of autonomous vehicles requires virtual scenario-based testing, which depends on the robust evaluation and generation of safety-critical scenarios. So far, researchers have used scenario-based testing frameworks that rely heavily on handcrafted scenarios as safety metrics. To reduce the effort of human interpretation and overcome the limited scalability of these approaches, we combine Large Language Models (LLMs) with structured scenario parsing and prompt engineering to automatically evaluate and generate safety-critical driving scenarios. We introduce Cartesian and Ego-centric prompt strategies for scenario evaluation, and an adversarial generation module that modifies trajectories of risk-inducing vehicles (ego-attackers) to create critical scenarios. We validate our approach using a 2D simulation framework and multiple pre-trained LLMs. The results show that the evaluation module effectively detects collision scenarios and infers scenario safety. Meanwhile, the new generation module identifies high-risk agents and synthesizes realistic, safety-critical scenarios. We conclude that an LLM equipped with domain-informed prompting techniques can effectively evaluate and generate safety-critical driving scenarios, reducing dependence on handcrafted metrics. We release our open-source code and scenarios at: https://github.com/TUM-AVS/From-Words-to-Collisions.
        ]]></description>
    </item>
    <item>
        <title>SG-Reg: Generalizable and Efficient Scene Graph Registration</title>
        <link>https://arxiv.org/abs/2504.14440</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.14440v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chuhao Liu, Zhijian Qiao, Jieqi Shi, Ke Wang, Peize Liu, Shaojie Shen</dc:creator>
        <description><![CDATA[
            背景：刚性语义场景图配准在实际应用中面临经典方法依赖手工描述符、学习方法依赖真值标注的问题。方法：设计场景图网络对语义节点的多模态信息编码并融合，匹配层以粗到精方式搜索对应关系，后端用鲁棒位姿估计器确定变换；采用新的数据生成方法，利用视觉基础模型和语义映射模块重建语义场景图。效果：在双智能体SLAM基准测试中，配准成功率显著优于手工基准，与视觉回环网络相比，召回率略高，每查询帧仅需52KB通信带宽。
            arXiv:2504.14440v2 Announce Type: replace-cross 
Abstract: This paper addresses the challenges of registering two rigid semantic scene graphs, an essential capability when an autonomous agent needs to register its map against a remote agent, or against a prior map. The hand-crafted descriptors in classical semantic-aided registration, or the ground-truth annotation reliance in learning-based scene graph registration, impede their application in practical real-world environments. To address the challenges, we design a scene graph network to encode multiple modalities of semantic nodes: open-set semantic feature, local topology with spatial awareness, and shape feature. These modalities are fused to create compact semantic node features. The matching layers then search for correspondences in a coarse-to-fine manner. In the back-end, we employ a robust pose estimator to decide transformation according to the correspondences. We manage to maintain a sparse and hierarchical scene representation. Our approach demands fewer GPU resources and fewer communication bandwidth in multi-agent tasks. Moreover, we design a new data generation approach using vision foundation models and a semantic mapping module to reconstruct semantic scene graphs. It differs significantly from previous works, which rely on ground-truth semantic annotations to generate data. We validate our method in a two-agent SLAM benchmark. It significantly outperforms the hand-crafted baseline in terms of registration success rate. Compared to visual loop closure networks, our method achieves a slightly higher registration recall while requiring only 52 KB of communication bandwidth for each query frame. Code available at: \href{http://github.com/HKUST-Aerial-Robotics/SG-Reg}{http://github.com/HKUST-Aerial-Robotics/SG-Reg}.
        ]]></description>
    </item>
    <item>
        <title>VocalAgent: Large Language Models for Vocal Health Diagnostics with Safety-Aware Evaluation</title>
        <link>https://arxiv.org/abs/2505.13577</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13577v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yubin Kim, Taehan Kim, Wonjune Kang, Eugene Park, Joonsik Yoon, Dongjae Lee, Xin Liu, Daniel McDuff, Hyeonhoon Lee, Cynthia Breazeal, Hae Won Park</dc:creator>
        <description><![CDATA[
            背景：嗓音健康至关重要，但全球嗓音疾病患者难获便捷诊断治疗。方法：本文提出VocalAgent，这是一种音频大语言模型，利用在三个医院患者原位数据集上微调的Qwen - Audio - Chat，还提出包含安全评估、跨语言性能分析和模态消融研究的多方面评估框架。效果：VocalAgent在嗓音疾病分类上比现有基线模型有更高准确性，其基于大语言模型的方法为健康诊断的广泛应用提供可扩展方案。
            arXiv:2505.13577v1 Announce Type: new 
Abstract: Vocal health plays a crucial role in peoples' lives, significantly impacting their communicative abilities and interactions. However, despite the global prevalence of voice disorders, many lack access to convenient diagnosis and treatment. This paper introduces VocalAgent, an audio large language model (LLM) to address these challenges through vocal health diagnosis. We leverage Qwen-Audio-Chat fine-tuned on three datasets collected in-situ from hospital patients, and present a multifaceted evaluation framework encompassing a safety assessment to mitigate diagnostic biases, cross-lingual performance analysis, and modality ablation studies. VocalAgent demonstrates superior accuracy on voice disorder classification compared to state-of-the-art baselines. Its LLM-based method offers a scalable solution for broader adoption of health diagnostics, while underscoring the importance of ethical and technical validation.
        ]]></description>
    </item>
    <item>
        <title>Direction-Aware Neural Acoustic Fields for Few-Shot Interpolation of Ambisonic Impulse Responses</title>
        <link>https://arxiv.org/abs/2505.13617</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13617v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Christopher Ick, Gordon Wichern, Yoshiki Masuyama, Fran\c{c}ois Germain, Jonathan Le Roux</dc:creator>
        <description><![CDATA[
            背景：声场特性与声源和听者周围环境的几何和空间属性相关，此前基于神经场（NFs）的方法多关注单声道全向或最多双耳听者，无法精确捕捉单点真实声场的方向特性。方法：提出方向感知神经场（DANF），通过Ambisonic格式的房间脉冲响应（RIR）更明确地融入方向信息，还提出方向感知损失，并研究DANF以多种方式适应新房间的能力。效果：论文未提及具体定量效果。
            arXiv:2505.13617v1 Announce Type: new 
Abstract: The characteristics of a sound field are intrinsically linked to the geometric and spatial properties of the environment surrounding a sound source and a listener. The physics of sound propagation is captured in a time-domain signal known as a room impulse response (RIR). Prior work using neural fields (NFs) has allowed learning spatially-continuous representations of RIRs from finite RIR measurements. However, previous NF-based methods have focused on monaural omnidirectional or at most binaural listeners, which does not precisely capture the directional characteristics of a real sound field at a single point. We propose a direction-aware neural field (DANF) that more explicitly incorporates the directional information by Ambisonic-format RIRs. While DANF inherently captures spatial relations between sources and listeners, we further propose a direction-aware loss. In addition, we investigate the ability of DANF to adapt to new rooms in various ways including low-rank adaptation.
        ]]></description>
    </item>
    <item>
        <title>Score-Based Training for Energy-Based TTS Models</title>
        <link>https://arxiv.org/abs/2505.13771</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13771v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wanli Sun, Anton Ragni</dc:creator>
        <description><![CDATA[
            背景：噪声对比估计（NCE）是训练基于能量的模型（EBM）常用方法，但依赖噪声样本质量；切片得分匹配（SSM）受扩散模型启发，但二者都忽略对数似然函数形式，而EBM和扩散模型推理时用一阶优化。方法：提出一种新准则，学习更适合一阶方案的得分。效果：通过实验对比了这些训练EBM的方法。
            arXiv:2505.13771v1 Announce Type: new 
Abstract: Noise contrastive estimation (NCE) is a popular method for training energy-based models (EBM) with intractable normalisation terms. The key idea of NCE is to learn by comparing unnormalised log-likelihoods of the reference and noisy samples, thus avoiding explicitly computing normalisation terms. However, NCE critically relies on the quality of noisy samples. Recently, sliced score matching (SSM) has been popularised by closely related diffusion models (DM). Unlike NCE, SSM learns a gradient of log-likelihood, or score, by learning distribution of its projections on randomly chosen directions. However, both NCE and SSM disregard the form of log-likelihood function, which is problematic given that EBMs and DMs make use of first-order optimisation during inference. This paper proposes a new criterion that learns scores more suitable for first-order schemes. Experiments contrasts these approaches for training EBMs.
        ]]></description>
    </item>
    <item>
        <title>ClapFM-EVC: High-Fidelity and Flexible Emotional Voice Conversion with Dual Control from Natural Language and Speech</title>
        <link>https://arxiv.org/abs/2505.13805</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13805v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yu Pan, Yanni Hu, Yuguang Yang, Jixun Yao, Jianhao Ye, Hongbin Zhou, Lei Ma, Jianjun Zhao</dc:creator>
        <description><![CDATA[
            背景：实现高保真且能灵活、可解释控制的情感语音转换（EVC）仍具挑战。方法：提出ClapFM - EVC框架，先构建EVC - CLAP模型提取并对齐语音和文本的细粒度情感元素，再用带自适应强度门的FuEncoder融合情感特征与预训练ASR模型的语音后验图，最后用流匹配模型重构源语音的梅尔频谱图。效果：主观和客观评估验证了该框架的有效性。
            arXiv:2505.13805v1 Announce Type: new 
Abstract: Despite great advances, achieving high-fidelity emotional voice conversion (EVC) with flexible and interpretable control remains challenging. This paper introduces ClapFM-EVC, a novel EVC framework capable of generating high-quality converted speech driven by natural language prompts or reference speech with adjustable emotion intensity. We first propose EVC-CLAP, an emotional contrastive language-audio pre-training model, guided by natural language prompts and categorical labels, to extract and align fine-grained emotional elements across speech and text modalities. Then, a FuEncoder with an adaptive intensity gate is presented to seamless fuse emotional features with Phonetic PosteriorGrams from a pre-trained ASR model. To further improve emotion expressiveness and speech naturalness, we propose a flow matching model conditioned on these captured features to reconstruct Mel-spectrogram of source speech. Subjective and objective evaluations validate the effectiveness of ClapFM-EVC.
        ]]></description>
    </item>
    <item>
        <title>Improving Noise Robustness of LLM-based Zero-shot TTS via Discrete Acoustic Token Denoising</title>
        <link>https://arxiv.org/abs/2505.13830</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13830v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ye-Xin Lu, Hui-Peng Du, Fei Liu, Yang Ai, Zhen-Hua Ling</dc:creator>
        <description><![CDATA[
            背景：基于大语言模型（LLM）的零样本语音合成（TTS）方法会保留音频提示的声学环境，当提示含噪声时合成语音质量下降。方法：提出基于神经编解码器的语音去噪器，并与先进的基于LLM的TTS模型LauraTTS集成，编解码器去噪器由音频编解码器、令牌去噪器和嵌入细化器组成。效果：实验表明，提出的编解码器去噪器优于现有语音增强方法，带去噪功能的LauraTTS超越使用额外语音增强模型的方法。
            arXiv:2505.13830v1 Announce Type: new 
Abstract: Large language model (LLM) based zero-shot text-to-speech (TTS) methods tend to preserve the acoustic environment of the audio prompt, leading to degradation in synthesized speech quality when the audio prompt contains noise. In this paper, we propose a novel neural codec-based speech denoiser and integrate it with the advanced LLM-based TTS model, LauraTTS, to achieve noise-robust zero-shot TTS. The proposed codec denoiser consists of an audio codec, a token denoiser, and an embedding refiner. The token denoiser predicts the first two groups of clean acoustic tokens from the noisy ones, which can serve as the acoustic prompt for LauraTTS to synthesize high-quality personalized speech or be converted to clean speech waveforms through the embedding refiner and codec decoder. Experimental results show that our proposed codec denoiser outperforms state-of-the-art speech enhancement (SE) methods, and the proposed noise-robust LauraTTS surpasses the approach using additional SE models.
        ]]></description>
    </item>
    <item>
        <title>A Semantic Information-based Hierarchical Speech Enhancement Method Using Factorized Codec and Diffusion Model</title>
        <link>https://arxiv.org/abs/2505.13843</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13843v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yang Xiang, Canan Huang, Desheng Hu, Jingguang Tian, Xinhui Hu, Chao Zhang</dc:creator>
        <description><![CDATA[
            背景：当前多数语音增强方法直接估计时频掩码或频谱来恢复纯净语音，忽略语音信号的语义内容和声学细节等属性，在下游任务中表现不佳，且在复杂声学环境中效果下降。方法：提出基于语义信息，利用因式编解码器和扩散模型的分步因式语音增强方法，对语义和声学属性进行分层建模。效果：实验表明，该算法在语音质量上优于现有最优基线，还提升了嘈杂环境下的TTS性能。
            arXiv:2505.13843v1 Announce Type: new 
Abstract: Most current speech enhancement (SE) methods recover clean speech from noisy inputs by directly estimating time-frequency masks or spectrums. However, these approaches often neglect the distinct attributes, such as semantic content and acoustic details, inherent in speech signals, which can hinder performance in downstream tasks. Moreover, their effectiveness tends to degrade in complex acoustic environments. To overcome these challenges, we propose a novel, semantic information-based, step-by-step factorized SE method using factorized codec and diffusion model. Unlike traditional SE methods, our hierarchical modeling of semantic and acoustic attributes enables more robust clean speech recovery, particularly in challenging acoustic scenarios. Moreover, this method offers further advantages for downstream TTS tasks. Experimental results demonstrate that our algorithm not only outperforms SOTA baselines in terms of speech quality but also enhances TTS performance in noisy environments.
        ]]></description>
    </item>
    <item>
        <title>U-SAM: An audio language Model for Unified Speech, Audio, and Music Understanding</title>
        <link>https://arxiv.org/abs/2505.13880</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13880v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ziqian Wang, Xianjun Xia, Xinfa Zhu, Lei Xie</dc:creator>
        <description><![CDATA[
            现有音频模型在统一理解语音、音频事件和音乐等不同类型音频时面临挑战，且仅依赖交叉熵损失进行对齐效果不佳。为此，本文提出U - SAM，将语音、音频和音乐的专用编码器与预训练大语言模型集成，采用混合专家投影器进行任务感知特征融合，还引入语义感知对比损失模块，增强跨模态对齐。实验表明，U - SAM在多个基准测试中优于专业模型和现有音频语言模型，在未见任务上也展现出泛化能力。
            arXiv:2505.13880v1 Announce Type: new 
Abstract: The text generation paradigm for audio tasks has opened new possibilities for unified audio understanding. However, existing models face significant challenges in achieving a comprehensive understanding across diverse audio types, such as speech, general audio events, and music. Furthermore, their exclusive reliance on cross-entropy loss for alignment often falls short, as it treats all tokens equally and fails to account for redundant audio features, leading to weaker cross-modal alignment. To deal with the above challenges, this paper introduces U-SAM, an advanced audio language model that integrates specialized encoders for speech, audio, and music with a pre-trained large language model (LLM). U-SAM employs a Mixture of Experts (MoE) projector for task-aware feature fusion, dynamically routing and integrating the domain-specific encoder outputs. Additionally, U-SAM incorporates a Semantic-Aware Contrastive Loss Module, which explicitly identifies redundant audio features under language supervision and rectifies their semantic and spectral representations to enhance cross-modal alignment. Extensive experiments demonstrate that U-SAM consistently outperforms both specialized models and existing audio language models across multiple benchmarks. Moreover, it exhibits emergent capabilities on unseen tasks, showcasing its generalization potential. Code is available (https://github.com/Honee-W/U-SAM/).
        ]]></description>
    </item>
    <item>
        <title>Combining Deterministic Enhanced Conditions with Dual-Streaming Encoding for Diffusion-Based Speech Enhancement</title>
        <link>https://arxiv.org/abs/2505.13983</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13983v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hao Shi, Xugang Lu, Kazuki Shimada, Tatsuya Kawahara</dc:creator>
        <description><![CDATA[
            背景：基于扩散的语音增强模型需可靠先验知识作条件，但用噪声特征提供可靠条件有挑战，确定性方法增强的特征作条件又有信息失真问题。方法：研究不同确定性语音增强模型作扩散条件的效果，提出双流式编码修复扩散模型（DERDM - SE）利用两种条件，还提出结合粗、细粒度处理的确定性模型。效果：在CHiME4上实验表明，该模型有效利用确定性模型，取得更好语音增强评估分数，比其他基于扩散的语音增强模型性能更稳定。
            arXiv:2505.13983v1 Announce Type: new 
Abstract: Diffusion-based speech enhancement (SE) models need to incorporate correct prior knowledge as reliable conditions to generate accurate predictions. However, providing reliable conditions using noisy features is challenging. One solution is to use features enhanced by deterministic methods as conditions. However, the information distortion and loss caused by deterministic methods might affect the diffusion process. In this paper, we first investigate the effects of using different deterministic SE models as conditions for diffusion. We validate two conditions depending on whether the noisy feature was used as part of the condition: one using only the deterministic feature (deterministic-only), and the other using both deterministic and noisy features (deterministic-noisy). Preliminary investigation found that using deterministic enhanced conditions improves hearing experiences on real data, while the choice between using deterministic-only or deterministic-noisy conditions depends on the deterministic models. Based on these findings, we propose a dual-streaming encoding Repair-Diffusion Model for SE (DERDM-SE) to more effectively utilize both conditions. Moreover, we found that fine-grained deterministic models have greater potential in objective evaluation metrics, while UNet-based deterministic models provide more stable diffusion performance. Therefore, in the DERDM-SE, we propose a deterministic model that combines coarse- and fine-grained processing. Experimental results on CHiME4 show that the proposed models effectively leverage deterministic models to achieve better SE evaluation scores, along with more stable performance compared to other diffusion-based SE models.
        ]]></description>
    </item>
    <item>
        <title>SeamlessEdit: Background Noise Aware Zero-Shot Speech Editing with in-Context Enhancement</title>
        <link>https://arxiv.org/abs/2505.14066</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14066v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kuan-Yu Chen, Jeng-Lin Li, Jian-Jiun Ding</dc:creator>
        <description><![CDATA[
            背景：零样本文本转语音技术发展迅速，但现有语音编辑研究多针对干净语音场景，环境噪声会降低生成质量。方法：提出抗噪语音编辑框架SeamlessEdit，采用频带感知噪声抑制模块和内容内细化策略，能处理语音和背景噪声频带未分离的情况。效果：在多项定量和定性评估中，SeamlessEdit框架优于现有先进方法。
            arXiv:2505.14066v1 Announce Type: new 
Abstract: With the fast development of zero-shot text-to-speech technologies, it is possible to generate high-quality speech signals that are indistinguishable from the real ones. Speech editing, including speech insertion and replacement, appeals to researchers due to its potential applications. However, existing studies only considered clean speech scenarios. In real-world applications, the existence of environmental noise could significantly degrade the quality of the generation. In this study, we propose a noise-resilient speech editing framework, SeamlessEdit, for noisy speech editing. SeamlessEdit adopts a frequency-band-aware noise suppression module and an in-content refinement strategy. It can well address the scenario where the frequency bands of voice and background noise are not separated. The proposed SeamlessEdit framework outperforms state-of-the-art approaches in multiple quantitative and qualitative evaluations.
        ]]></description>
    </item>
    <item>
        <title>AudSemThinker: Enhancing Audio-Language Models through Reasoning over Semantics of Sound</title>
        <link>https://arxiv.org/abs/2505.14142</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14142v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Gijs Wijngaard, Elia Formisano, Michele Esposito, Michel Dumontier</dc:creator>
        <description><![CDATA[
            背景：音频语言模型在声音理解任务有成果，但细粒度语义推理能力有限。方法：提出AudSemThinker模型，其推理基于受人类认知启发的听觉语义框架；引入AudSem数据集，精心筛选音频样本并通过多阶段流程生成配对字幕，解决零样本评估中的数据污染问题。效果：实验表明，AudSemThinker在多种训练设置下优于现有模型，展现出强大的语义音频推理能力，且模型和数据集均已公开。
            arXiv:2505.14142v1 Announce Type: new 
Abstract: Audio-language models have shown promising results in various sound understanding tasks, yet they remain limited in their ability to reason over the fine-grained semantics of sound. In this paper, we present AudSemThinker, a model whose reasoning is structured around a framework of auditory semantics inspired by human cognition. To support this, we introduce AudSem, a novel dataset specifically curated for semantic descriptor reasoning in audio-language models. AudSem addresses the persistent challenge of data contamination in zero-shot evaluations by providing a carefully filtered collection of audio samples paired with captions generated through a robust multi-stage pipeline. Our experiments demonstrate that AudSemThinker outperforms state-of-the-art models across multiple training settings, highlighting its strength in semantic audio reasoning. Both AudSemThinker and the AudSem dataset are released publicly.
        ]]></description>
    </item>
    <item>
        <title>AquaSignal: An Integrated Framework for Robust Underwater Acoustic Analysis</title>
        <link>https://arxiv.org/abs/2505.14285</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14285v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Eirini Panteli, Paulo E. Santos, Nabil Humphrey</dc:creator>
        <description><![CDATA[
            背景：在嘈杂多变的海洋环境中，需可靠准确的水下声学信号分析方法。方法：提出AquaSignal框架，集成先进深度学习架构，用U - Net去噪，ResNet18分类已知声学事件，基于AutoEncoder模型无监督检测新异常信号。效果：在Deepship和ONC数据集上评估，信号清晰度和任务性能提升，分类准确率达71%，新奇检测准确率达91%，虽分类性能略低于部分先进模型，但因数据划分策略不同难以直接对比，在多领域实时监测有潜力。
            arXiv:2505.14285v1 Announce Type: new 
Abstract: This paper presents AquaSignal, a modular and scalable pipeline for preprocessing, denoising, classification, and novelty detection of underwater acoustic signals. Designed to operate effectively in noisy and dynamic marine environments, AquaSignal integrates state-of-the-art deep learning architectures to enhance the reliability and accuracy of acoustic signal analysis. The system is evaluated on a combined dataset from the Deepship and Ocean Networks Canada (ONC) benchmarks, providing a diverse set of real-world underwater scenarios. AquaSignal employs a U-Net architecture for denoising, a ResNet18 convolutional neural network for classifying known acoustic events, and an AutoEncoder-based model for unsupervised detection of novel or anomalous signals. To our knowledge, this is the first comprehensive study to apply and evaluate this combination of techniques on maritime vessel acoustic data. Experimental results show that AquaSignal improves signal clarity and task performance, achieving 71% classification accuracy and 91% accuracy in novelty detection. Despite slightly lower classification performance compared to some state-of-the-art models, differences in data partitioning strategies limit direct comparisons. Overall, AquaSignal demonstrates strong potential for real-time underwater acoustic monitoring in scientific, environmental, and maritime domains.
        ]]></description>
    </item>
    <item>
        <title>S2SBench: A Benchmark for Quantifying Intelligence Degradation in Speech-to-Speech Large Language Models</title>
        <link>https://arxiv.org/abs/2505.14438</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14438v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuanbo Fang, Haoze Sun, Jun Liu, Tao Zhang, Zenan Zhou, Weipeng Chen, Xiaofen Xing, Xiangmin Xu</dc:creator>
        <description><![CDATA[
            背景：端到端语音大语言模型能直接处理和生成音频令牌，但相比文本输入，其推理和生成性能常下降，即“智能退化”。方法：提出S2SBench基准，包含针对音频输入下句子续写和常识推理的诊断数据集，引入基于似然与非似然样本困惑度差异的成对评估协议来衡量相对文本输入的性能退化。效果：用其分析百川 - 音频训练过程，证明了基准的有效性，相关数据集和代码已开源。
            arXiv:2505.14438v1 Announce Type: new 
Abstract: End-to-end speech large language models ((LLMs)) extend the capabilities of text-based models to directly process and generate audio tokens. However, this often leads to a decline in reasoning and generation performance compared to text input, a phenomenon referred to as intelligence degradation. To systematically evaluate this gap, we propose S2SBench, a benchmark designed to quantify performance degradation in Speech LLMs. It includes diagnostic datasets targeting sentence continuation and commonsense reasoning under audio input. We further introduce a pairwise evaluation protocol based on perplexity differences between plausible and implausible samples to measure degradation relative to text input. We apply S2SBench to analyze the training process of Baichuan-Audio, which further demonstrates the benchmark's effectiveness. All datasets and evaluation code are available at https://github.com/undobug/S2SBench.
        ]]></description>
    </item>
    <item>
        <title>FlowTSE: Target Speaker Extraction with Flow Matching</title>
        <link>https://arxiv.org/abs/2505.14465</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14465v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Aviv Navon, Aviv Shamsian, Yael Segal-Feldman, Neta Glazer, Gil Hetz, Joseph Keshet</dc:creator>
        <description><![CDATA[
            背景：目标说话人提取（TSE）现有生成方法研究不足，且依赖复杂流程和预训练组件，计算开销大。方法：提出基于条件流匹配的FlowTSE方法，模型接收以梅尔频谱图表示的注册音频样本和混合语音信号，提取目标说话人的干净语音；针对相位重建关键任务，提出基于混合信号复STFT的新型声码器以改善相位估计。效果：在标准TSE基准测试中，FlowTSE达到或超过了强大的基线模型。
            arXiv:2505.14465v1 Announce Type: new 
Abstract: Target speaker extraction (TSE) aims to isolate a specific speaker's speech from a mixture using speaker enrollment as a reference. While most existing approaches are discriminative, recent generative methods for TSE achieve strong results. However, generative methods for TSE remain underexplored, with most existing approaches relying on complex pipelines and pretrained components, leading to computational overhead. In this work, we present FlowTSE, a simple yet effective TSE approach based on conditional flow matching. Our model receives an enrollment audio sample and a mixed speech signal, both represented as mel-spectrograms, with the objective of extracting the target speaker's clean speech. Furthermore, for tasks where phase reconstruction is crucial, we propose a novel vocoder conditioned on the complex STFT of the mixed signal, enabling improved phase estimation. Experimental results on standard TSE benchmarks show that FlowTSE matches or outperforms strong baselines.
        ]]></description>
    </item>
    <item>
        <title>PAST: Phonetic-Acoustic Speech Tokenizer</title>
        <link>https://arxiv.org/abs/2505.14470</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14470v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Nadav Har-Tuv, Or Tal, Yossi Adi</dc:creator>
        <description><![CDATA[
            背景：现有语音tokenization方法多依赖预训练自监督模型。方法：提出PAST框架，联合建模语音信息与信号重建，无需外部预训练模型，通过监督语音数据，用辅助任务将领域知识直接融入tokenization过程，还推出可流式、有因果关系的变体用于实时语音应用。效果：在语音表示和语音重建等常见评估指标上超越现有基线tokenizer，作为语音语言模型的语音表示时表现更优，代码已开源。
            arXiv:2505.14470v1 Announce Type: new 
Abstract: We present PAST, a novel end-to-end framework that jointly models phonetic information alongside signal reconstruction, eliminating the need for external pretrained models. Unlike previous approaches that rely on pretrained self-supervised models, PAST employs supervised phonetic data, directly integrating domain knowledge into the tokenization process via auxiliary tasks. Additionally, we introduce a streamable, causal variant of PAST, enabling real-time speech applications. Results demonstrate that PAST surpasses existing evaluated baseline tokenizers across common evaluation metrics, including phonetic representation and speech reconstruction. Notably, PAST also achieves superior performance when serving as a speech representation for speech language models, further highlighting its effectiveness as a foundation for spoken language generation. To foster further research, we release the full implementation. For code, model checkpoints, and samples see: https://pages.cs.huji.ac.il/adiyoss-lab/PAST
        ]]></description>
    </item>
    <item>
        <title>Teaching Audio-Aware Large Language Models What Does Not Hear: Mitigating Hallucinations through Synthesized Negative Samples</title>
        <link>https://arxiv.org/abs/2505.14518</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14518v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chun-Yi Kuan, Hung-yi Lee</dc:creator>
        <description><![CDATA[
            背景：音频感知大语言模型（ALLMs）虽能处理音频输入，但常产生不存在的声音事件幻觉，降低了其在实际应用中的可靠性。方法：提出LISTEN方法，这是一种类似对比学习的训练方法，利用骨干大语言模型合成的数据，增强ALLMs区分存在和不存在声音的能力，且无需修改大语言模型参数，通过轻量级适配器高效整合音频表示。效果：有效减轻了幻觉问题，在现有音频问答和推理基准测试中保持良好性能，且在数据和计算上更高效。
            arXiv:2505.14518v1 Announce Type: new 
Abstract: Recent advancements in audio-aware large language models (ALLMs) enable them to process and understand audio inputs. However, these models often hallucinate non-existent sound events, reducing their reliability in real-world applications. To address this, we propose LISTEN (Learning to Identify Sounds Through Extended Negative Samples), a contrastive-like training method that enhances ALLMs' ability to distinguish between present and absent sounds using synthesized data from the backbone LLM. Unlike prior approaches, our method requires no modification to LLM parameters and efficiently integrates audio representations via a lightweight adapter. Experiments show that LISTEN effectively mitigates hallucinations while maintaining impressive performance on existing audio question and reasoning benchmarks. At the same time, it is more efficient in both data and computation.
        ]]></description>
    </item>
    <item>
        <title>Representation Learning for Semantic Alignment of Language, Audio, and Visual Modalities</title>
        <link>https://arxiv.org/abs/2505.14562</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14562v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Parthasaarathy Sudarsanam, Irene Mart\'in-Morat\'o, Tuomas Virtanen</dc:creator>
        <description><![CDATA[
            背景：现有三模态（音频、视觉、文本）对齐的深度学习方法分两阶段进行，存在数据分布不匹配、对齐效果不佳的问题。方法：本文提出单阶段训练方法，利用对比学习框架，借助AVCaps数据集，联合优化所有模态的表示。效果：单阶段方法优于两阶段方法，在基于音频的视觉检索中性能提升两倍，凸显了统一多模态表示学习的优势。
            arXiv:2505.14562v1 Announce Type: new 
Abstract: This paper proposes a single-stage training approach that semantically aligns three modalities - audio, visual, and text using a contrastive learning framework. Contrastive training has gained prominence for multimodal alignment, utilizing large-scale unlabeled data to learn shared representations. Existing deep learning approach for trimodal alignment involves two-stages, that separately align visual-text and audio-text modalities. This approach suffers from mismatched data distributions, resulting in suboptimal alignment. Leveraging the AVCaps dataset, which provides audio, visual and audio-visual captions for video clips, our method jointly optimizes the representation of all the modalities using contrastive training. Our results demonstrate that the single-stage approach outperforms the two-stage method, achieving a two-fold improvement in audio based visual retrieval, highlighting the advantages of unified multimodal representation learning.
        ]]></description>
    </item>
    <item>
        <title>AdaKWS: Towards Robust Keyword Spotting with Test-Time Adaptation</title>
        <link>https://arxiv.org/abs/2505.14600</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14600v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yang Xiao, Tianyi Peng, Yanghao Zhou, Rohan Kumar Das</dc:creator>
        <description><![CDATA[
            背景：语音关键词检测在音频应用广泛，但小尺寸系统在未知环境或噪声背景下推理性能会下降。方法：提出首个用于鲁棒关键词检测的测试时自适应方法AdaKWS，先基于预测熵最小化选择可靠样本并调整每批归一化统计量来优化模型置信度，再引入伪关键词一致性识别关键可靠特征且避免过拟合噪声。效果：实验表明，AdaKWS在高斯噪声和真实场景噪声等多种条件下均优于其他方法。
            arXiv:2505.14600v1 Announce Type: new 
Abstract: Spoken keyword spotting (KWS) aims to identify keywords in audio for wide applications, especially on edge devices. Current small-footprint KWS systems focus on efficient model designs. However, their inference performance can decline in unseen environments or noisy backgrounds. Test-time adaptation (TTA) helps models adapt to test samples without needing the original training data. In this study, we present AdaKWS, the first TTA method for robust KWS to the best of our knowledge. Specifically, 1) We initially optimize the model's confidence by selecting reliable samples based on prediction entropy minimization and adjusting the normalization statistics in each batch. 2) We introduce pseudo-keyword consistency (PKC) to identify critical, reliable features without overfitting to noise. Our experiments show that AdaKWS outperforms other methods across various conditions, including Gaussian noise and real-scenario noises. The code will be released in due course.
        ]]></description>
    </item>
    <item>
        <title>Listen, Analyze, and Adapt to Learn New Attacks: An Exemplar-Free Class Incremental Learning Method for Audio Deepfake Source Tracing</title>
        <link>https://arxiv.org/abs/2505.14601</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14601v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yang Xiao, Rohan Kumar Das</dc:creator>
        <description><![CDATA[
            背景：深度伪造语音常见且难检测，音频深度伪造源追踪（ST）模型需适应学习新攻击并保留旧知识，面临灾难性遗忘问题。方法：提出分析类增量学习方法AnaST，新攻击出现时，固定特征提取器，用闭式解析解在一个周期内更新分类器。效果：实验表明该方法优于基线模型，能保证数据隐私、优化内存使用，适合在线训练。
            arXiv:2505.14601v1 Announce Type: new 
Abstract: As deepfake speech becomes common and hard to detect, it is vital to trace its source. Recent work on audio deepfake source tracing (ST) aims to find the origins of synthetic or manipulated speech. However, ST models must adapt to learn new deepfake attacks while retaining knowledge of the previous ones. A major challenge is catastrophic forgetting, where models lose the ability to recognize previously learned attacks. Some continual learning methods help with deepfake detection, but multi-class tasks such as ST introduce additional challenges as the number of classes grows. To address this, we propose an analytic class incremental learning method called AnaST. When new attacks appear, the feature extractor remains fixed, and the classifier is updated with a closed-form analytical solution in one epoch. This approach ensures data privacy, optimizes memory usage, and is suitable for online training. The experiments carried out in this work show that our method outperforms the baselines.
        ]]></description>
    </item>
    <item>
        <title>AudioJailbreak: Jailbreak Attacks against End-to-End Large Audio-Language Models</title>
        <link>https://arxiv.org/abs/2505.14103</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14103v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Guangke Chen, Fu Song, Zhe Zhao, Xiaojun Jia, Yang Liu, Yanchen Qiao, Weizhe Zhang</dc:creator>
        <description><![CDATA[
            背景：现有大音频语言模型（LALMs）越狱攻击在有效性、适用性和实用性方面欠佳，且假设攻击者能完全操控用户提示。方法：提出AudioJailbreak攻击，具有异步性、通用性、隐蔽性和空中鲁棒性等特点，还适用于无法完全操控用户提示的攻击者。效果：在多个LALMs上的大量实验证明其高效性，有助于提升LALMs的安全鲁棒性。
            arXiv:2505.14103v1 Announce Type: cross 
Abstract: Jailbreak attacks to Large audio-language models (LALMs) are studied recently, but they achieve suboptimal effectiveness, applicability, and practicability, particularly, assuming that the adversary can fully manipulate user prompts. In this work, we first conduct an extensive experiment showing that advanced text jailbreak attacks cannot be easily ported to end-to-end LALMs via text-to speech (TTS) techniques. We then propose AudioJailbreak, a novel audio jailbreak attack, featuring (1) asynchrony: the jailbreak audio does not need to align with user prompts in the time axis by crafting suffixal jailbreak audios; (2) universality: a single jailbreak perturbation is effective for different prompts by incorporating multiple prompts into perturbation generation; (3) stealthiness: the malicious intent of jailbreak audios will not raise the awareness of victims by proposing various intent concealment strategies; and (4) over-the-air robustness: the jailbreak audios remain effective when being played over the air by incorporating the reverberation distortion effect with room impulse response into the generation of the perturbations. In contrast, all prior audio jailbreak attacks cannot offer asynchrony, universality, stealthiness, or over-the-air robustness. Moreover, AudioJailbreak is also applicable to the adversary who cannot fully manipulate user prompts, thus has a much broader attack scenario. Extensive experiments with thus far the most LALMs demonstrate the high effectiveness of AudioJailbreak. We highlight that our work peeks into the security implications of audio jailbreak attacks against LALMs, and realistically fosters improving their security robustness. The implementation and audio samples are available at our website https://audiojailbreak.github.io/AudioJailbreak.
        ]]></description>
    </item>
    <item>
        <title>Universal Acoustic Adversarial Attacks for Flexible Control of Speech-LLMs</title>
        <link>https://arxiv.org/abs/2505.14286</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14286v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Rao Ma, Mengjie Qian, Vyas Raina, Mark Gales, Kate Knill</dc:creator>
        <description><![CDATA[
            背景：预训练语音编码器与大语言模型结合的语音LLM虽强大灵活，但可能更易受对抗攻击。方法：研究对语音LLM的通用声学对抗攻击，将固定的通用对抗音频片段添加到原始输入音频前，先研究使模型无输出或执行修改任务的攻击，再扩展为有选择性的攻击，仅在特定输入属性出现时激活。效果：发现Qwen2 - Audio和Granite - Speech存在关键漏洞，表明类似语音LLM可能易受通用对抗攻击，凸显需更鲁棒训练策略和更强抗攻击能力。
            arXiv:2505.14286v1 Announce Type: cross 
Abstract: The combination of pre-trained speech encoders with large language models has enabled the development of speech LLMs that can handle a wide range of spoken language processing tasks. While these models are powerful and flexible, this very flexibility may make them more vulnerable to adversarial attacks. To examine the extent of this problem, in this work we investigate universal acoustic adversarial attacks on speech LLMs. Here a fixed, universal, adversarial audio segment is prepended to the original input audio. We initially investigate attacks that cause the model to either produce no output or to perform a modified task overriding the original prompt. We then extend the nature of the attack to be selective so that it activates only when specific input attributes, such as a speaker gender or spoken language, are present. Inputs without the targeted attribute should be unaffected, allowing fine-grained control over the model outputs. Our findings reveal critical vulnerabilities in Qwen2-Audio and Granite-Speech and suggest that similar speech LLMs may be susceptible to universal adversarial attacks. This highlights the need for more robust training strategies and improved resistance to adversarial attacks.
        ]]></description>
    </item>
    <item>
        <title>Frozen Large Language Models Can Perceive Paralinguistic Aspects of Speech</title>
        <link>https://arxiv.org/abs/2410.01162</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.01162v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wonjune Kang, Junteng Jia, Chunyang Wu, Wei Zhou, Egor Lakomkin, Yashesh Gaur, Leda Sari, Suyoun Kim, Ke Li, Jay Mahadeokar, Ozlem Kalinli</dc:creator>
        <description><![CDATA[
            背景：研究大语言模型（LLM）在不微调权重情况下理解语音副语言方面的能力。方法：采用带语音编码器的端到端系统，训练编码器生成令牌嵌入，使LLM对表达性语音提示的响应与对匹配文本提示的响应一致，即使LLM权重冻结，也能让编码器捕捉并传达语言和副语言信息。效果：实验表明，与多个基线相比，该系统能对表达性语音提示生成更高质量、更具同理心的回复。
            arXiv:2410.01162v2 Announce Type: replace 
Abstract: This work studies the capabilities of a large language model (LLM) to understand paralinguistic aspects of speech without fine-tuning its weights. We utilize an end-to-end system with a speech encoder, which is trained to produce token embeddings such that the LLM's response to an expressive speech prompt is aligned with its response to a semantically matching text prompt that has also been conditioned on the user's speaking style. This framework enables the encoder to generate tokens that capture both linguistic and paralinguistic information and effectively convey them to the LLM, even when the LLM's weights remain completely frozen. To the best of our knowledge, our work is the first to explore how to induce a frozen LLM to understand more than just linguistic content from speech inputs in a general interaction setting. Experiments demonstrate that our system is able to produce higher quality and more empathetic responses to expressive speech prompts compared to several baselines.
        ]]></description>
    </item>
    <item>
        <title>F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching</title>
        <link>https://arxiv.org/abs/2410.06885</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.06885v3</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yushen Chen, Zhikang Niu, Ziyang Ma, Keqi Deng, Chunhui Wang, Jian Zhao, Kai Yu, Xie Chen</dc:creator>
        <description><![CDATA[
            背景：现有基于流匹配的端到端语音合成系统E2 TTS收敛慢、鲁棒性低。方法：提出F5 - TTS，用ConvNeXt对输入建模以优化文本表示，便于与语音对齐；提出推理时的摇摆采样策略，且该策略可用于现有基于流匹配的模型。效果：训练速度更快，推理实时因子为0.15，相比现有扩散TTS模型大幅提升。在100K小时多语言数据集训练后，具备高自然度和表现力的零样本能力、无缝代码切换能力和速度控制效率。
            arXiv:2410.06885v3 Announce Type: replace 
Abstract: This paper introduces F5-TTS, a fully non-autoregressive text-to-speech system based on flow matching with Diffusion Transformer (DiT). Without requiring complex designs such as duration model, text encoder, and phoneme alignment, the text input is simply padded with filler tokens to the same length as input speech, and then the denoising is performed for speech generation, which was originally proved feasible by E2 TTS. However, the original design of E2 TTS makes it hard to follow due to its slow convergence and low robustness. To address these issues, we first model the input with ConvNeXt to refine the text representation, making it easy to align with the speech. We further propose an inference-time Sway Sampling strategy, which significantly improves our model's performance and efficiency. This sampling strategy for flow step can be easily applied to existing flow matching based models without retraining. Our design allows faster training and achieves an inference RTF of 0.15, which is greatly improved compared to state-of-the-art diffusion-based TTS models. Trained on a public 100K hours multilingual dataset, our F5-TTS exhibits highly natural and expressive zero-shot ability, seamless code-switching capability, and speed control efficiency. We have released all codes and checkpoints to promote community development, at https://SWivid.github.io/F5-TTS/.
        ]]></description>
    </item>
    <item>
        <title>Unified Microphone Conversion: Many-to-Many Device Mapping via Feature-wise Linear Modulation</title>
        <link>https://arxiv.org/abs/2410.18322</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.18322v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Myeonghoon Ryu, Hongseok Oh, Suji Lee, Han Park</dc:creator>
        <description><![CDATA[
            背景：先前基于CycleGAN的方法虽能模拟设备特性，但每个设备对需单独模型，扩展性受限。方法：提出统一麦克风转换的生成框架，通过对频率响应数据调节生成器，经无配对训练实现多对多设备映射，利用特征线性调制集成频率响应信息，还引入合成频率响应差异。效果：实验表明，该方法在宏平均F1分数上比现有最优方法高2.6%，变异性降低0.8%。
            arXiv:2410.18322v2 Announce Type: replace 
Abstract: We present Unified Microphone Conversion, a unified generative framework designed to bolster sound event classification (SEC) systems against device variability. While our prior CycleGAN-based methods effectively simulate device characteristics, they require separate models for each device pair, limiting scalability. Our approach overcomes this constraint by conditioning the generator on frequency response data, enabling many-to-many device mappings through unpaired training. We integrate frequency-response information via Feature-wise Linear Modulation, further enhancing scalability. Additionally, incorporating synthetic frequency response differences improves the applicability of our framework for real-world application. Experimental results show that our method outperforms the state-of-the-art by 2.6% and reduces variability by 0.8% in macro-average F1 score.
        ]]></description>
    </item>
    <item>
        <title>DeepResonance: Enhancing Multimodal Music Understanding via Music-centric Multi-way Instruction Tuning</title>
        <link>https://arxiv.org/abs/2502.12623</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.12623v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhuoyuan Mao, Mengjie Zhao, Qiyu Wu, Hiromi Wakaki, Yuki Mitsufuji</dc:creator>
        <description><![CDATA[
            背景：现有音乐大语言模型多聚焦音乐与文本输入融合，未充分挖掘图像、视频等多模态数据提升音乐理解的潜力。方法：提出多模态音乐理解大语言模型DeepResonance，通过多向指令调优，利用音乐、文本、图像和视频多向对齐数据进行微调；构建三个四向训练和评估数据集，引入多采样ImageBind嵌入和预LLM融合Transformer增强模态融合。效果：在六项音乐理解任务中达到了最先进水平。
            arXiv:2502.12623v2 Announce Type: replace 
Abstract: Recent advancements in music large language models (LLMs) have significantly improved music understanding tasks, which involve the model's ability to analyze and interpret various musical elements. These improvements primarily focused on integrating both music and text inputs. However, the potential of incorporating additional modalities such as images, videos and textual music features to enhance music understanding remains unexplored. To bridge this gap, we propose DeepResonance, a multimodal music understanding LLM fine-tuned via multi-way instruction tuning with multi-way aligned music, text, image, and video data. To this end, we construct Music4way-MI2T, Music4way-MV2T, and Music4way-Any2T, three 4-way training and evaluation datasets designed to enable DeepResonance to integrate both visual and textual music feature content. We also introduce multi-sampled ImageBind embeddings and a pre-LLM fusion Transformer to enhance modality fusion prior to input into text LLMs, tailoring DeepResonance for multi-way instruction tuning. Our model achieves state-of-the-art performances across six music understanding tasks, highlighting the benefits of the auxiliary modalities and the structural superiority of DeepResonance. We plan to open-source the models and the newly constructed datasets.
        ]]></description>
    </item>
    <item>
        <title>Fast Text-to-Audio Generation with Adversarial Post-Training</title>
        <link>https://arxiv.org/abs/2505.08175</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.08175v3</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zachary Novack, Zach Evans, Zack Zukowski, Josiah Taylor, CJ Carr, Julian Parker, Adnan Al-Sinan, Gian Marco Iodice, Julian McAuley, Taylor Berg-Kirkpatrick, Jordi Pons</dc:creator>
        <description><![CDATA[
            背景：文本到音频系统推理慢，延迟难以满足创意应用需求。方法：提出对抗性相对论对比（ARC）后训练，这是首个非基于蒸馏的扩散/流模型对抗加速算法，将相对论对抗公式扩展到扩散/流后训练，并结合新颖的对比判别器目标；还对Stable Audio Open进行多项优化。效果：构建的模型能在H100上约75ms生成约12s的44.1kHz立体声音频，在移动边缘设备上约7s，是已知最快的文本到音频模型。
            arXiv:2505.08175v3 Announce Type: replace 
Abstract: Text-to-audio systems, while increasingly performant, are slow at inference time, thus making their latency unpractical for many creative applications. We present Adversarial Relativistic-Contrastive (ARC) post-training, the first adversarial acceleration algorithm for diffusion/flow models not based on distillation. While past adversarial post-training methods have struggled to compare against their expensive distillation counterparts, ARC post-training is a simple procedure that (1) extends a recent relativistic adversarial formulation to diffusion/flow post-training and (2) combines it with a novel contrastive discriminator objective to encourage better prompt adherence. We pair ARC post-training with a number optimizations to Stable Audio Open and build a model capable of generating $\approx$12s of 44.1kHz stereo audio in $\approx$75ms on an H100, and $\approx$7s on a mobile edge-device, the fastest text-to-audio model to our knowledge.
        ]]></description>
    </item>
    <item>
        <title>Universal Semantic Disentangled Privacy-preserving Speech Representation Learning</title>
        <link>https://arxiv.org/abs/2505.13085</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13085v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Biel Tura Vecino, Subhadeep Maji, Aravind Varier, Antonio Bonafonte, Ivan Valles, Michael Owen, Leif R\"adel, Grant Strimel, Seyi Feyisetan, Roberto Barra Chicote, Ariya Rastrow, Constantinos Papayiannis, Volker Leutnant, Trevor Wood</dc:creator>
        <description><![CDATA[
            背景：用人类语音录音训练大语言模型存在隐私问题。方法：提出基于通用语音编解码器（USC）的说话人隐私保护表征学习方法，将语音解耦为隐私保护的语义丰富表征和用于高保真重建的残差声学及说话人表征。效果：USC的语义表征能保留内容、韵律和情感，去除可识别的说话人属性；结合两种表征可实现最先进的语音重建；引入评估方法衡量隐私保护特性，与其他编解码器对比，证明其在隐私保护表征学习上有效。
            arXiv:2505.13085v2 Announce Type: replace 
Abstract: The use of audio recordings of human speech to train LLMs poses privacy concerns due to these models' potential to generate outputs that closely resemble artifacts in the training data. In this study, we propose a speaker privacy-preserving representation learning method through the Universal Speech Codec (USC), a computationally efficient encoder-decoder model that disentangles speech into: (i) privacy-preserving semantically rich representations, capturing content and speech paralinguistics, and (ii) residual acoustic and speaker representations that enables high-fidelity reconstruction. Extensive evaluations presented show that USC's semantic representation preserves content, prosody, and sentiment, while removing potentially identifiable speaker attributes. Combining both representations, USC achieves state-of-the-art speech reconstruction. Additionally, we introduce an evaluation methodology for measuring privacy-preserving properties, aligning with perceptual tests. We compare USC against other codecs in the literature and demonstrate its effectiveness on privacy-preserving representation learning, illustrating the trade-offs of speaker anonymization, paralinguistics retention and content preservation in the learned semantic representations. Audio samples are shared in https://www.amazon.science/usc-samples.
        ]]></description>
    </item>
</channel>
</rss>