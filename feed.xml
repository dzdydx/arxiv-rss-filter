<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
<channel>
    <title>arXiv Paper Filter</title>
    <link>https://github.com/None/arxiv_filter</link>
    <description>根据研究兴趣筛选的arXiv论文</description>
    <atom:link href="https://raw.githubusercontent.com/None/arxiv_filter/main/feed.xml" rel="self" type="application/rss+xml" />
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>zh-CN</language>
    <lastBuildDate>Thu, 17 Apr 2025 12:11:19 +0800</lastBuildDate>
    <managingEditor>None@github.com</managingEditor>
    <pubDate>Thu, 17 Apr 2025 12:11:19 +0800</pubDate>
    <skipDays>
        <day>Saturday</day>
        <day>Sunday</day>
    </skipDays>

    <item>
        <title>SFT or RL? An Early Investigation into Training R1-Like Reasoning Large Vision-Language Models</title>
        <link>https://arxiv.org/abs/2504.11468</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.11468v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hardy Chen, Haoqin Tu, Fali Wang, Hui Liu, Xianfeng Tang, Xinya Du, Yuyin Zhou, Cihang Xie</dc:creator>
        <description><![CDATA[
            背景：现有大视觉语言模型（LVLMs）训练采用监督微调（SFT）后强化学习（RL）范式，但SFT会诱导“伪推理路径”，影响后续RL。方法：引入新多模态数据集VLAA - Thinking支持LVLMs推理，对比SFT、RL及其组合，并基于GRPO和新混合奖励模块构建RL方法。效果：基于Qwen2.5VL 3B的VLAA - Thinker在4B规模LVLMs中于Open LMM推理排行榜获第一，超之前最优1.8%，为开发有推理能力的LVLMs提供见解。
            arXiv:2504.11468v1 Announce Type: new 
Abstract: This work revisits the dominant supervised fine-tuning (SFT) then reinforcement learning (RL) paradigm for training Large Vision-Language Models (LVLMs), and reveals a key finding: SFT can significantly undermine subsequent RL by inducing ``pseudo reasoning paths'' imitated from expert models. While these paths may resemble the native reasoning paths of RL models, they often involve prolonged, hesitant, less informative steps, and incorrect reasoning. To systematically study this effect, we introduce VLAA-Thinking, a new multimodal dataset designed to support reasoning in LVLMs. Constructed via a six-step pipeline involving captioning, reasoning distillation, answer rewrite and verification, VLAA-Thinking comprises high-quality, step-by-step visual reasoning traces for SFT, along with a more challenging RL split from the same data source. Using this dataset, we conduct extensive experiments comparing SFT, RL and their combinations. Results show that while SFT helps models learn reasoning formats, it often locks aligned models into imitative, rigid reasoning modes that impede further learning. In contrast, building on the Group Relative Policy Optimization (GRPO) with a novel mixed reward module integrating both perception and cognition signals, our RL approach fosters more genuine, adaptive reasoning behavior. Notably, our model VLAA-Thinker, based on Qwen2.5VL 3B, achieves top-1 performance on Open LMM Reasoning Leaderboard (https://huggingface.co/spaces/opencompass/Open_LMM_Reasoning_Leaderboard) among 4B scale LVLMs, surpassing the previous state-of-the-art by 1.8%. We hope our findings provide valuable insights in developing reasoning-capable LVLMs and can inform future research in this area.
        ]]></description>
    </item>
    <item>
        <title>SDIGLM: Leveraging Large Language Models and Multi-Modal Chain of Thought for Structural Damage Identification</title>
        <link>https://arxiv.org/abs/2504.11477</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.11477v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yunkai Zhang, Shiyin Wei, Yong Huang, Yawu Su, Shanshan Lu, Hui Li</dc:creator>
        <description><![CDATA[
            背景：现有基于计算机视觉的结构损伤识别模型在实际土木工程应用中有局限，如损伤类型识别能力有限、缺乏语言能力。方法：提出基于开源VisualGLM - 6B架构的SDIGLM，集成基于U - Net的语义分割模块生成视觉思维链，构建多轮对话微调数据集增强逻辑推理，通过提示工程形成语言思维链。效果：SDIGLM在结构损伤识别上超越通用大模型，对各类基础设施损伤识别准确率达95.24%，还能有效描述损伤特征。
            arXiv:2504.11477v1 Announce Type: new 
Abstract: Existing computer vision(CV)-based structural damage identification models demonstrate notable accuracy in categorizing and localizing damage. However, these models present several critical limitations that hinder their practical application in civil engineering(CE). Primarily, their ability to recognize damage types remains constrained, preventing comprehensive analysis of the highly varied and complex conditions encountered in real-world CE structures. Second, these models lack linguistic capabilities, rendering them unable to articulate structural damage characteristics through natural language descriptions. With the continuous advancement of artificial intelligence(AI), large multi-modal models(LMMs) have emerged as a transformative solution, enabling the unified encoding and alignment of textual and visual data. These models can autonomously generate detailed descriptive narratives of structural damage while demonstrating robust generalization across diverse scenarios and tasks. This study introduces SDIGLM, an innovative LMM for structural damage identification, developed based on the open-source VisualGLM-6B architecture. To address the challenge of adapting LMMs to the intricate and varied operating conditions in CE, this work integrates a U-Net-based semantic segmentation module to generate defect segmentation maps as visual Chain of Thought(CoT). Additionally, a multi-round dialogue fine-tuning dataset is constructed to enhance logical reasoning, complemented by a language CoT formed through prompt engineering. By leveraging this multi-modal CoT, SDIGLM surpasses general-purpose LMMs in structural damage identification, achieving an accuracy of 95.24% across various infrastructure types. Moreover, the model effectively describes damage characteristics such as hole size, crack direction, and corrosion severity.
        ]]></description>
    </item>
    <item>
        <title>Graph-Driven Multimodal Feature Learning Framework for Apparent Personality Assessment</title>
        <link>https://arxiv.org/abs/2504.11515</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.11515v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kangsheng Wang, Chengwei Ye, Huanzhen Zhang, Linuo Xu, Shuyan Liu</dc:creator>
        <description><![CDATA[
            自动预测人格特质是计算机视觉领域的难题。本文提出用于短视频人格分析的多模态特征学习框架。视觉处理上，构建面部图并设计含注意力机制的双流网络，结合GCN和CNN捕捉静态面部表情，用ResNet18和VGGFace提取帧级特征；用BiGRU和时间注意力模块提取动态时间信息。还融入VGGish和XLM - Roberta分别提取音频和文本特征。用多模态通道注意力机制融合各模态，用MLP回归模型预测。实验表明，该框架性能超现有最优方法。
            arXiv:2504.11515v1 Announce Type: new 
Abstract: Predicting personality traits automatically has become a challenging problem in computer vision. This paper introduces an innovative multimodal feature learning framework for personality analysis in short video clips. For visual processing, we construct a facial graph and design a Geo-based two-stream network incorporating an attention mechanism, leveraging both Graph Convolutional Networks (GCN) and Convolutional Neural Networks (CNN) to capture static facial expressions. Additionally, ResNet18 and VGGFace networks are employed to extract global scene and facial appearance features at the frame level. To capture dynamic temporal information, we integrate a BiGRU with a temporal attention module for extracting salient frame representations. To enhance the model's robustness, we incorporate the VGGish CNN for audio-based features and XLM-Roberta for text-based features. Finally, a multimodal channel attention mechanism is introduced to integrate different modalities, and a Multi-Layer Perceptron (MLP) regression model is used to predict personality traits. Experimental results confirm that our proposed framework surpasses existing state-of-the-art approaches in performance.
        ]]></description>
    </item>
    <item>
        <title>ReTool: Reinforcement Learning for Strategic Tool Use in LLMs</title>
        <link>https://arxiv.org/abs/2504.11536</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.11536v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiazhan Feng, Shijue Huang, Xingwei Qu, Ge Zhang, Yujia Qin, Baoquan Zhong, Chengquan Jiang, Jinxin Chi, Wanjun Zhong</dc:creator>
        <description><![CDATA[
            背景：现有基于强化学习的推理模型在文本推理表现好，但在结构化问题求解场景存在不足，而计算工具在此类场景有优势。方法：提出ReTool，通过工具集成学习增强长形式推理，具备实时代码执行动态交织、自动化强化学习范式两个关键特性，采用系统训练框架，先生成合成冷启动数据微调模型，再用强化学习迭代优化工具使用策略。效果：在AIME基准测试中，32B模型400步训练准确率达67%，扩展设置下达72.5%，优于基线和OpenAI模型。
            arXiv:2504.11536v1 Announce Type: new 
Abstract: While reasoning models (e.g., DeepSeek R1) trained with reinforcement learning (RL), excel in textual reasoning, they struggle in scenarios requiring structured problem-solving, such as geometric reasoning, concise computation, or complex equation solving-areas where computational tools like code interpreters (CI) demonstrate distinct advantages. To bridge this gap, we propose ReTool, which enhances long-form reasoning with tool-integrated learning, including two key features: (1) dynamic interleaving of real-time code execution within natural language reasoning processes, and (2) an automated RL paradigm that allows policy rollouts with multi-turn real-time code execution and teaches the model in learning when and how to invoke tools based on outcome feedback. ReTool employs a systematic training framework, beginning with synthetic cold-start data generation to produce code-augmented long-form reasoning traces for fine-tuning base models. Subsequent RL training leverages task outcomes as rewards to iteratively refine the model's tool use strategy, enabling autonomous discovery of optimal tool invocation patterns without human priors. Experiments on the challenging MATH Olympiad benchmark AIME demonstrate ReTool's superiority: Our 32B model achieves 67% accuracy with 400 training steps, outperforming text-based RL baseline (40% accuracy, 1080 steps) in efficiency and performance. Remarkably, ReTool-32B attains 72.5% accuracy in extended settings, surpassing OpenAI's o1-preview by 27.9%. Further analysis reveals emergent behaviors such as code self-correction, signaling an ''aha moment'' in which the model autonomously masters adaptive tool use. These findings highlight the promise of outcome-driven tool integration for advancing complex mathematical reasoning and offer new insights into hybrid neuro-symbolic systems.
        ]]></description>
    </item>
    <item>
        <title>H$^3$GNNs: Harmonizing Heterophily and Homophily in GNNs via Joint Structural Node Encoding and Self-Supervised Learning</title>
        <link>https://arxiv.org/abs/2504.11699</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.11699v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Rui Xue, Tianfu Wu</dc:creator>
        <description><![CDATA[
            背景：图神经网络在表示学习中难以平衡异质性和同质性，在自监督环境下挑战更大。方法：提出H³GNNs端到端自监督学习框架，一是通过加权图卷积网络将节点嵌入结合线性和非线性特征投影与K跳结构表示的统一空间，用交叉注意力机制增强对异质性和同质性的感知；二是采用师生预测架构和基于节点难度的动态掩码策略进行自监督学习。效果：在七个基准测试中有效，在四个异质性数据集上达最优，在三个同质性数据集上与现有最优方法相当。
            arXiv:2504.11699v1 Announce Type: new 
Abstract: Graph Neural Networks (GNNs) struggle to balance heterophily and homophily in representation learning, a challenge further amplified in self-supervised settings. We propose H$^3$GNNs, an end-to-end self-supervised learning framework that harmonizes both structural properties through two key innovations: (i) Joint Structural Node Encoding. We embed nodes into a unified space combining linear and non-linear feature projections with K-hop structural representations via a Weighted Graph Convolution Network(WGCN). A cross-attention mechanism enhances awareness and adaptability to heterophily and homophily. (ii) Self-Supervised Learning Using Teacher-Student Predictive Architectures with Node-Difficulty Driven Dynamic Masking Strategies. We use a teacher-student model, the student sees the masked input graph and predicts node features inferred by the teacher that sees the full input graph in the joint encoding space. To enhance learning difficulty, we introduce two novel node-predictive-difficulty-based masking strategies. Experiments on seven benchmarks (four heterophily datasets and three homophily datasets) confirm the effectiveness and efficiency of H$^3$GNNs across diverse graph types. Our H$^3$GNNs achieves overall state-of-the-art performance on the four heterophily datasets, while retaining on-par performance to previous state-of-the-art methods on the three homophily datasets.
        ]]></description>
    </item>
    <item>
        <title>Multimodal Spatio-temporal Graph Learning for Alignment-free RGBT Video Object Detection</title>
        <link>https://arxiv.org/abs/2504.11779</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.11779v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qishun Wang, Zhengzheng Tu, Chenglong Li, Bo Jiang</dc:creator>
        <description><![CDATA[
            背景：RGB-T视频目标检测可解决传统RGB检测在复杂光照下的局限，但多依赖手动对齐多模态图像对。方法：提出多模态时空图学习网络MSGNet，先设计自适应分区层实现初步不精确对齐，再引入空间稀疏图学习模块实现模态间信息交互，还引入混合结构化时间建模，包括时间稀疏图学习模块和时间星块。效果：在对齐数据集VT-VOD50和未对齐数据集UVT-VOD2024上实验，证明了方法的有效性和优越性。
            arXiv:2504.11779v1 Announce Type: new 
Abstract: RGB-Thermal Video Object Detection (RGBT VOD) can address the limitation of traditional RGB-based VOD in challenging lighting conditions, making it more practical and effective in many applications.
  However, similar to most RGBT fusion tasks, it still mainly relies on manually aligned multimodal image pairs.
  In this paper, we propose a novel Multimodal Spatio-temporal Graph learning Network (MSGNet) for alignment-free RGBT VOD problem by leveraging the robust graph representation learning model.
  Specifically, we first design an Adaptive Partitioning Layer (APL) to estimate the corresponding regions of the Thermal image within the RGB image (high-resolution), achieving a preliminary inexact alignment.
  Then, we introduce the Spatial Sparse Graph Learning Module (S-SGLM) which employs a sparse information passing mechanism on the estimated inexact alignment to achieve reliable information interaction between different modalities.
  Moreover, to fully exploit the temporal cues for RGBT VOD problem, we introduce Hybrid Structured Temporal Modeling (HSTM), which involves a Temporal Sparse Graph Learning Module (T-SGLM) and Temporal Star Block (TSB). T-SGLM aims to filter out some redundant information between adjacent frames by employing the sparse aggregation mechanism on the temporal graph. Meanwhile, TSB is dedicated to achieving the complementary learning of local spatial relationships.
  Extensive comparative experiments conducted on both the aligned dataset VT-VOD50 and the unaligned dataset UVT-VOD2024 demonstrate the effectiveness and superiority of our proposed method. Our project will be made available on our website for free public access.
        ]]></description>
    </item>
    <item>
        <title>FiSMiness: A Finite State Machine Based Paradigm for Emotional Support Conversations</title>
        <link>https://arxiv.org/abs/2504.11837</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.11837v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yue Zhao, Qingqing Gu, Xiaoyu Wang, Teng Chen, Zhonglin Jiang, Yong Chen, Luo Ji</dc:creator>
        <description><![CDATA[
            背景：情感支持对话旨在缓解个体情绪困扰，大语言模型虽有进展，但多数研究未从状态模型视角定义图，长期满意度欠佳。方法：在大语言模型上利用有限状态机，提出FiSMiness框架，使单个大语言模型在对话中自主规划，推理求助者情绪、支持策略和最终回复。效果：在情感支持对话数据集上的大量实验表明，FiSMiness优于诸多基线方法，包括直接推理、自我完善、思维链等，即便与参数量更多的方法相比也更出色。
            arXiv:2504.11837v1 Announce Type: new 
Abstract: Emotional support conversation (ESC) aims to alleviate the emotional distress of individuals through effective conversations. Although large language models (LLMs) have obtained remarkable progress on ESC, most of these studies might not define the diagram from the state model perspective, therefore providing a suboptimal solution for long-term satisfaction. To address such an issue, we leverage the Finite State Machine (FSM) on LLMs, and propose a framework called FiSMiness. Our framework allows a single LLM to bootstrap the planning during ESC, and self-reason the seeker's emotion, support strategy and the final response upon each conversational turn. Substantial experiments on ESC datasets suggest that FiSMiness outperforms many baselines, including direct inference, self-refine, chain of thought, finetuning, and external-assisted methods, even those with many more parameters.
        ]]></description>
    </item>
    <item>
        <title>HyperSAT: Unsupervised Hypergraph Neural Networks for Weighted MaxSAT Problems</title>
        <link>https://arxiv.org/abs/2504.11885</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.11885v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qiyue Chen (School of Mathematical Sciences, University of Chinese Academy of Science, Beijing, China, Zhongguancun Laboratory, Beijing, China), Shaolin Tan (Zhongguancun Laboratory, Beijing, China), Suixiang Gao (School of Mathematical Sciences, University of Chinese Academy of Science, Beijing, China, Zhongguancun Laboratory, Beijing, China), Jinhu L\"u (School of Automation Science and Electrical Engineering, Beihang University, Beijing, China, Zhongguancun Laboratory, Beijing, China)</dc:creator>
        <description><![CDATA[
            背景：图神经网络在解决布尔可满足性和最大可满足性问题上表现出色，但解决加权最大可满足性问题的方法仍待发展，挑战源于子句权重分布不均导致的非线性依赖和敏感目标函数。方法：提出HyperSAT，采用无监督超图神经网络模型，为加权最大可满足性实例构建超图表示，设计交叉注意力机制和共享表示约束损失函数。效果：在多个加权最大可满足性数据集上实验表明，HyperSAT性能优于现有方法。
            arXiv:2504.11885v1 Announce Type: new 
Abstract: Graph neural networks (GNNs) have shown promising performance in solving both Boolean satisfiability (SAT) and Maximum Satisfiability (MaxSAT) problems due to their ability to efficiently model and capture the structural dependencies between literals and clauses. However, GNN methods for solving Weighted MaxSAT problems remain underdeveloped. The challenges arise from the non-linear dependency and sensitive objective function, which are caused by the non-uniform distribution of weights across clauses. In this paper, we present HyperSAT, a novel neural approach that employs an unsupervised hypergraph neural network model to solve Weighted MaxSAT problems. We propose a hypergraph representation for Weighted MaxSAT instances and design a cross-attention mechanism along with a shared representation constraint loss function to capture the logical interactions between positive and negative literal nodes in the hypergraph. Extensive experiments on various Weighted MaxSAT datasets demonstrate that HyperSAT achieves better performance than state-of-the-art competitors.
        ]]></description>
    </item>
    <item>
        <title>CAGS: Open-Vocabulary 3D Scene Understanding with Context-Aware Gaussian Splatting</title>
        <link>https://arxiv.org/abs/2504.11893</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.11893v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wei Sun, Yanzhao Zhou, Jianbin Jiao, Yuan Li</dc:creator>
        <description><![CDATA[
            背景：开放词汇3D场景理解在机器人、增强现实等领域至关重要，但3D高斯 splatting 与开放词汇框架集成时存在跨视图粒度不一致问题，现有方法忽视空间上下文。方法：提出上下文感知高斯 splatting（CAGS）框架，构建局部图传播上下文特征，采用以掩码为中心的对比学习平滑特征，利用预计算策略降低成本。效果：在LERF - OVS和ScanNet等数据集上显著改善3D实例分割，减少碎片化错误，实现更稳健的语言引导3D场景理解。
            arXiv:2504.11893v1 Announce Type: new 
Abstract: Open-vocabulary 3D scene understanding is crucial for applications requiring natural language-driven spatial interpretation, such as robotics and augmented reality. While 3D Gaussian Splatting (3DGS) offers a powerful representation for scene reconstruction, integrating it with open-vocabulary frameworks reveals a key challenge: cross-view granularity inconsistency. This issue, stemming from 2D segmentation methods like SAM, results in inconsistent object segmentations across views (e.g., a "coffee set" segmented as a single entity in one view but as "cup + coffee + spoon" in another). Existing 3DGS-based methods often rely on isolated per-Gaussian feature learning, neglecting the spatial context needed for cohesive object reasoning, leading to fragmented representations. We propose Context-Aware Gaussian Splatting (CAGS), a novel framework that addresses this challenge by incorporating spatial context into 3DGS. CAGS constructs local graphs to propagate contextual features across Gaussians, reducing noise from inconsistent granularity, employs mask-centric contrastive learning to smooth SAM-derived features across views, and leverages a precomputation strategy to reduce computational cost by precomputing neighborhood relationships, enabling efficient training in large-scale scenes. By integrating spatial context, CAGS significantly improves 3D instance segmentation and reduces fragmentation errors on datasets like LERF-OVS and ScanNet, enabling robust language-guided 3D scene understanding.
        ]]></description>
    </item>
    <item>
        <title>Balancing Graph Embedding Smoothness in Self-Supervised Learning via Information-Theoretic Decomposition</title>
        <link>https://arxiv.org/abs/2504.12011</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.12011v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Heesoo Jung, Hogun Park</dc:creator>
        <description><![CDATA[
            背景：图自监督学习中，现有方法不确定能否有效反映图的关键属性，且在图嵌入平滑性上存在两极分化，影响下游任务表现。方法：通过信息论框架将自监督目标分解为三项，提出BSG框架，引入新损失函数平衡这三项（邻居损失、最小损失和散度损失）。效果：在多个真实数据集的节点分类和链接预测任务中，BSG始终达到了最先进的性能，超越现有方法。代码见https://github.com/steve30572/BSG。
            arXiv:2504.12011v1 Announce Type: new 
Abstract: Self-supervised learning (SSL) in graphs has garnered significant attention, particularly in employing Graph Neural Networks (GNNs) with pretext tasks initially designed for other domains, such as contrastive learning and feature reconstruction. However, it remains uncertain whether these methods effectively reflect essential graph properties, precisely representation similarity with its neighbors. We observe that existing methods position opposite ends of a spectrum driven by the graph embedding smoothness, with each end corresponding to outperformance on specific downstream tasks. Decomposing the SSL objective into three terms via an information-theoretic framework with a neighbor representation variable reveals that this polarization stems from an imbalance among the terms, which existing methods may not effectively maintain. Further insights suggest that balancing between the extremes can lead to improved performance across a wider range of downstream tasks. A framework, BSG (Balancing Smoothness in Graph SSL), introduces novel loss functions designed to supplement the representation quality in graph-based SSL by balancing the derived three terms: neighbor loss, minimal loss, and divergence loss. We present a theoretical analysis of the effects of these loss functions, highlighting their significance from both the SSL and graph smoothness perspectives. Extensive experiments on multiple real-world datasets across node classification and link prediction consistently demonstrate that BSG achieves state-of-the-art performance, outperforming existing methods. Our implementation code is available at https://github.com/steve30572/BSG.
        ]]></description>
    </item>
    <item>
        <title>From Conceptual Data Models to Multimodal Representation</title>
        <link>https://arxiv.org/abs/2504.11459</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.11459v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Peter Stockinger (PLIDAM, ESCOM)</dc:creator>
        <description><![CDATA[
            背景：探索信息设计概念，区分领域语义内容与图形表达模态。方法：强调语义建模重要性，常通过概念网络或图结构知识，考虑概念关系等；还集成词库或本体以分析复杂语料，在OKAPI环境应用模型，采用视觉叙事等创新方法。效果：强调通信系统的互操作性、灵活性和智能性，为数字数据更丰富协作使用奠定基础。
            arXiv:2504.11459v1 Announce Type: cross 
Abstract: 1) Introduction and Conceptual Framework: This document explores the concept of information design by dividing it into two major practices: defining the meaning of a corpus of textual data and its visual or multimodal representation. It draws on expertise in enriching textual corpora, particularly audiovisual ones, and transforming them into multiple narrative formats. The text highlights a crucial distinction between the semantic content of a domain and the modalities of its graphic expression, illustrating this approach with concepts rooted in structural semiotics and linguistics traditions.
  2) Modeling and Conceptual Design:  The article emphasizes the importance of semantic modeling, often achieved through conceptual networks or graphs. These tools enable the structuring of knowledge within a domain by accounting for relationships between concepts, contexts of use, and specific objectives. Stockinger also highlights the constraints and challenges involved in creating dynamic and adaptable models, integrating elements such as thesauri or interoperable ontologies to facilitate the analysis and publication of complex corpora.
  3) Applications and Multimodal Visualization:  The text concludes by examining the practical application of these models in work environments like OKAPI, developed to analyze, publish, and reuse audiovisual data. It also discusses innovative approaches such as visual storytelling and document reengineering, which involve transforming existing content into new resources tailored to various contexts. These methods emphasize interoperability, flexibility, and the intelligence of communication systems, paving the way for richer and more collaborative use of digital data. The content of this document was presented during the "Semiotics of Information Design" Day organized by Anne Beyaert-Geslin of the University of Bordeaux Montaigne (MICA laboratory) on June 21, 2018, in Bordeaux.
        ]]></description>
    </item>
    <item>
        <title>Timing Analysis Agent: Autonomous Multi-Corner Multi-Mode (MCMM) Timing Debugging with Timing Debug Relation Graph</title>
        <link>https://arxiv.org/abs/2504.11502</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.11502v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jatin Nainani, Chia-Tung Ho, Anirudh Dhurka, Haoxing Ren</dc:creator>
        <description><![CDATA[
            背景：超大规模集成电路（VLSI）时序分析中，人工调试多角多模（MCMM）时序报告面临挑战，需高效智能方法。方法：提出由多大型语言模型（LLMs）驱动的时序分析代理，采用新颖分层规划与求解流程，构建时序调试关系图（TDRG），并在其上使用代理检索增强生成（RAG）方法准确检索数据。效果：在单报告基准测试中平均通过率达98%，工业设计多报告基准测试通过率达90%，展现有效性与适应性。
            arXiv:2504.11502v1 Announce Type: cross 
Abstract: Timing analysis is an essential and demanding verification method for Very Large Scale Integrated (VLSI) circuit design and optimization. In addition, it also serves as the cornerstone of the final sign-off, determining whether the chip is ready to be sent to the semiconductor foundry for fabrication. Recently, as the technology advance relentlessly, smaller metal pitches and the increasing number of devices have led to greater challenges and longer turn-around-time for experienced human designers to debug timing issues from the Multi-Corner Multi-Mode (MCMM) timing reports. As a result, an efficient and intelligent methodology is highly necessary and essential for debugging timing issues and reduce the turnaround times. Recently, Large Language Models (LLMs) have shown great promise across various tasks in language understanding and interactive decision-making, incorporating reasoning and actions. In this work, we propose a timing analysis agent, that is empowered by multi-LLMs task solving, and incorporates a novel hierarchical planning and solving flow to automate the analysis of timing reports from commercial tool. In addition, we build a Timing Debug Relation Graph (TDRG) that connects the reports with the relationships of debug traces from experienced timing engineers. The timing analysis agent employs the novel Agentic Retrieval Augmented Generation (RAG) approach, that includes agent and coding to retrieve data accurately, on the developed TDRG. In our studies, the proposed timing analysis agent achieves an average 98% pass-rate on a single-report benchmark and a 90% pass-rate for multi-report benchmark from industrial designs, demonstrating its effectiveness and adaptability.
        ]]></description>
    </item>
    <item>
        <title>GT-SVQ: A Linear-Time Graph Transformer for Node Classification Using Spiking Vector Quantization</title>
        <link>https://arxiv.org/abs/2504.11840</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.11840v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Huizhe Zhang, Jintang Li, Yuchang Zhu, Liang Chen, Zibin Zheng</dc:creator>
        <description><![CDATA[
            背景：图变换器（GTs）在图预测任务有潜力，但二次复杂度和高能耗限制其在大规模图上的扩展性。方法：提出基于脉冲向量量化的线性时间图变换器GT - SVQ用于节点分类，它基于脉冲神经元的速率编码输出重构码本，并注入自注意力块以线性复杂度聚合全局信息，还缓解了码本崩溃问题。效果：在节点分类数据集上与其他基线对比，GT - SVQ在多数数据集上表现有竞争力，推理速度比其他GTs快达130倍。
            arXiv:2504.11840v1 Announce Type: cross 
Abstract: Graph Transformers (GTs), which simultaneously integrate message-passing and self-attention mechanisms, have achieved promising empirical results in some graph prediction tasks. Although these approaches show the potential of Transformers in capturing long-range graph topology information, issues concerning the quadratic complexity and high computing energy consumption severely limit the scalability of GTs on large-scale graphs. Recently, as brain-inspired neural networks, Spiking Neural Networks (SNNs), facilitate the development of graph representation learning methods with lower computational and storage overhead through the unique event-driven spiking neurons. Inspired by these characteristics, we propose a linear-time Graph Transformer using Spiking Vector Quantization (GT-SVQ) for node classification. GT-SVQ reconstructs codebooks based on rate coding outputs from spiking neurons, and injects the codebooks into self-attention blocks to aggregate global information in linear complexity. Besides, spiking vector quantization effectively alleviates codebook collapse and the reliance on complex machinery (distance measure, auxiliary loss, etc.) present in previous vector quantization-based graph learning methods. In experiments, we compare GT-SVQ with other state-of-the-art baselines on node classification datasets ranging from small to large. Experimental results show that GT-SVQ has achieved competitive performances on most datasets while maintaining up to 130x faster inference speed compared to other GTs.
        ]]></description>
    </item>
    <item>
        <title>Knowledge Graph Reasoning with Self-supervised Reinforcement Learning</title>
        <link>https://arxiv.org/abs/2405.13640</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2405.13640v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ying Ma, Owen Burns, Mingqiu Wang, Gang Li, Nan Du, Laurent El Shafey, Liqiang Wang, Izhak Shafran, Hagen Soltau</dc:creator>
        <description><![CDATA[
            背景：强化学习在不完整知识图谱中寻找推理路径时面临动作空间大、分布不匹配等挑战。方法：提出自监督预训练方法在强化学习训练前预热策略网络，在监督学习阶段，智能体基于策略网络选动作并从生成的标签中学习。效果：该自监督强化学习方法结合监督学习的广泛覆盖性提升了强化学习性能，在四个大型基准知识图谱数据集的Hits@k和平均倒数排名指标上达到或超过当前最优结果，且始终优于两个基线模型。
            arXiv:2405.13640v2 Announce Type: replace 
Abstract: Reinforcement learning (RL) is an effective method of finding reasoning pathways in incomplete knowledge graphs (KGs). To overcome the challenges of a large action space, a self-supervised pre-training method is proposed to warm up the policy network before the RL training stage. To alleviate the distributional mismatch issue in general self-supervised RL (SSRL), in our supervised learning (SL) stage, the agent selects actions based on the policy network and learns from generated labels; this self-generation of labels is the intuition behind the name self-supervised. With this training framework, the information density of our SL objective is increased and the agent is prevented from getting stuck with the early rewarded paths. Our self-supervised RL (SSRL) method improves the performance of RL by pairing it with the wide coverage achieved by SL during pretraining, since the breadth of the SL objective makes it infeasible to train an agent with that alone. We show that our SSRL model meets or exceeds current state-of-the-art results on all Hits@k and mean reciprocal rank (MRR) metrics on four large benchmark KG datasets. This SSRL method can be used as a plug-in for any RL architecture for a KGR task. We adopt two RL architectures, i.e., MINERVA and MultiHopKG as our baseline RL models and experimentally show that our SSRL model consistently outperforms both baselines on all of these four KG reasoning tasks. Full code for the paper available at https://github.com/owenonline/Knowledge-Graph-Reasoning-with-Self-supervised-Reinforcement-Learning.
        ]]></description>
    </item>
    <item>
        <title>Imagery as Inquiry: Exploring A Multimodal Dataset for Conversational Recommendation</title>
        <link>https://arxiv.org/abs/2405.14142</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2405.14142v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Se-eun Yoon, Hyunsik Jeon, Julian McAuley</dc:creator>
        <description><![CDATA[
            背景：现有大模型在基于图像的对话推荐任务中存在局限。方法：引入用户通过图像表达偏好的多模态数据集，支持标题生成和多项选择推荐任务，提出链图像提示法以更好利用视觉能力。效果：实验表明，基础大模型在这些任务中有局限，视觉语言模型相比仅用描述的语言模型无显著优势，而链图像提示法带来显著改进，代码和数据集已发布。
            arXiv:2405.14142v2 Announce Type: replace 
Abstract: We introduce a multimodal dataset where users express preferences through images. These images encompass a broad spectrum of visual expressions ranging from landscapes to artistic depictions. Users request recommendations for books or music that evoke similar feelings to those captured in the images, and recommendations are endorsed by the community through upvotes. This dataset supports two recommendation tasks: title generation and multiple-choice selection. Our experiments with large foundation models reveal their limitations in these tasks. Particularly, vision-language models show no significant advantage over language-only counterparts that use descriptions, which we hypothesize is due to underutilized visual capabilities. To better harness these abilities, we propose the chain-of-imagery prompting, which results in notable improvements. We release our code and datasets.
        ]]></description>
    </item>
    <item>
        <title>Multimodal Lego: Model Merging and Fine-Tuning Across Topologies and Modalities in Biomedicine</title>
        <link>https://arxiv.org/abs/2405.19950</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2405.19950v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Konstantin Hemker, Nikola Simidjievski, Mateja Jamnik</dc:creator>
        <description><![CDATA[
            背景：在生物医学中，处理不同分布和模态信息需多模态机器学习模型，但现有方法存在局限。方法：提出通用融合框架Multimodal Lego（MM - Lego），为单模态编码器引入包装器以确保模态表示形状一致，在频域学习特征以减少信号干扰实现模型合并。效果：无需微调即可与端到端融合模型竞争；可用于任何单模态编码器；经少量微调，在7个数据集中的5个超越所有基准。
            arXiv:2405.19950v2 Announce Type: replace 
Abstract: Learning holistic computational representations in physical, chemical or biological systems requires the ability to process information from different distributions and modalities within the same model. Thus, the demand for multimodal machine learning models has sharply risen for modalities that go beyond vision and language, such as sequences, graphs, time series, or tabular data. While there are many available multimodal fusion and alignment approaches, most of them require end-to-end training, scale quadratically with the number of modalities, cannot handle cases of high modality imbalance in the training set, or are highly topology-specific, making them too restrictive for many biomedical learning tasks. This paper presents Multimodal Lego (MM-Lego), a general-purpose fusion framework to turn any set of encoders into a competitive multimodal model with no or minimal fine-tuning. We achieve this by introducing a wrapper for any unimodal encoder that enforces shape consistency between modality representations. It harmonises these representations by learning features in the frequency domain to enable model merging with little signal interference. We show that MM-Lego 1) can be used as a model merging method which achieves competitive performance with end-to-end fusion models without any fine-tuning, 2) can operate on any unimodal encoder, and 3) is a model fusion method that, with minimal fine-tuning, surpasses all benchmarks in five out of seven datasets.
        ]]></description>
    </item>
    <item>
        <title>Knowledge-Driven Feature Selection and Engineering for Genotype Data with Large Language Models</title>
        <link>https://arxiv.org/abs/2410.01795</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.01795v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Joseph Lee, Shu Yang, Jae Young Baik, Xiaoxi Liu, Zhen Tan, Dawei Li, Zixuan Wen, Bojian Hou, Duy Duong-Tran, Tianlong Chen, Li Shen</dc:creator>
        <description><![CDATA[
            背景：基于少量可解释的变异特征预测具有复杂遗传基础的表型是一项挑战，传统数据驱动方法因基因型数据高维性难以分析预测。方法：提出一种知识驱动框架，开发了基于思维链和集成原理的FREEFORM，利用大语言模型的内在知识进行特征选择和工程。效果：在遗传血统和遗传性听力损失两个基因型 - 表型数据集上评估，该框架优于多种数据驱动方法，尤其在小样本情况下表现出色。
            arXiv:2410.01795v2 Announce Type: replace 
Abstract: Predicting phenotypes with complex genetic bases based on a small, interpretable set of variant features remains a challenging task. Conventionally, data-driven approaches are utilized for this task, yet the high dimensional nature of genotype data makes the analysis and prediction difficult. Motivated by the extensive knowledge encoded in pre-trained LLMs and their success in processing complex biomedical concepts, we set to examine the ability of LLMs in feature selection and engineering for tabular genotype data, with a novel knowledge-driven framework. We develop FREEFORM, Free-flow Reasoning and Ensembling for Enhanced Feature Output and Robust Modeling, designed with chain-of-thought and ensembling principles, to select and engineer features with the intrinsic knowledge of LLMs. Evaluated on two distinct genotype-phenotype datasets, genetic ancestry and hereditary hearing loss, we find this framework outperforms several data-driven methods, particularly on low-shot regimes. FREEFORM is available as open-source framework at GitHub: https://github.com/PennShenLab/FREEFORM.
        ]]></description>
    </item>
    <item>
        <title>ReGenesis: LLMs can Grow into Reasoning Generalists via Self-Improvement</title>
        <link>https://arxiv.org/abs/2410.02108</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.02108v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiangyu Peng, Congying Xia, Xinyi Yang, Caiming Xiong, Chien-Sheng Wu, Chen Xing</dc:creator>
        <description><![CDATA[
            背景：用显式推理轨迹对大语言模型（LLMs）进行后训练可提升推理能力，但获取高质量轨迹数据成本高或受许可限制，且现有自合成方法泛化性差。方法：提出ReGenesis方法，通过从抽象到具体的方式自合成推理路径作为后训练数据，将通用推理指南转化为特定任务推理路径。效果：在所有测试的领域内和领域外（OOD）设置中表现优于现有方法，6个OOD任务上，现有方法后训练后平均性能下降约4.6%，而ReGenesis提升约6.1%。
            arXiv:2410.02108v2 Announce Type: replace 
Abstract: Post-training Large Language Models (LLMs) with explicit reasoning trajectories can enhance their reasoning abilities. However, acquiring such high-quality trajectory data typically demands meticulous supervision from humans or superior models, which can be either expensive or license-constrained. In this paper, we explore how far an LLM can improve its reasoning by self-synthesizing reasoning paths as training data without any additional supervision. Existing self-synthesizing methods, such as STaR, suffer from poor generalization to out-of-domain (OOD) reasoning tasks. We hypothesize it is due to that their self-synthesized reasoning paths are too task-specific, lacking general task-agnostic reasoning guidance. To address this, we propose Reasoning Generalist via Self-Improvement (ReGenesis), a method to self-synthesize reasoning paths as post-training data by progressing from abstract to concrete. More specifically, ReGenesis self-synthesizes reasoning paths by converting general reasoning guidelines into task-specific ones, generating reasoning structures, and subsequently transforming these structures into reasoning paths, without the need for human-designed task-specific examples used in existing methods. We show that ReGenesis achieves superior performance on all in-domain and OOD settings tested compared to existing methods. For six OOD tasks specifically, while previous methods exhibited an average performance decrease of approximately 4.6% after post training, ReGenesis delivers around 6.1% performance improvement. We also conduct in-depth analysis of our framework and show ReGenesis is effective across various LLMs and design choices.
        ]]></description>
    </item>
    <item>
        <title>Bridging Stepwise Lab-Informed Pretraining and Knowledge-Guided Learning for Diagnostic Reasoning</title>
        <link>https://arxiv.org/abs/2410.19955</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.19955v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Pengfei Hu, Chang Lu, Fei Wang, Yue Ning</dc:creator>
        <description><![CDATA[
            背景：现有数据驱动的AI辅助诊断预测模型难以融入医学知识，缺乏结构化推理能力和全面覆盖性。方法：提出DuaLK双专长框架，构建编码层次和语义关系的诊断知识图谱，引入基于实验室测试信号的代理任务，引导模型进行临床一致的逐步推理。效果：在两个公共电子健康记录数据集的四个临床预测任务中，DuaLK始终优于现有基线模型，结合结构化医学知识和临床信号可实现更准确、可解释的诊断预测。
            arXiv:2410.19955v2 Announce Type: replace 
Abstract: Despite the growing use of Electronic Health Records (EHR) for AI-assisted diagnosis prediction, most data-driven models struggle to incorporate clinically meaningful medical knowledge. They often rely on limited ontologies, lacking structured reasoning capabilities and comprehensive coverage. This raises an important research question: Will medical knowledge improve predictive models to support stepwise clinical reasoning as performed by human doctors? To address this problem, we propose DuaLK, a dual-expertise framework that combines two complementary sources of information. For external knowledge, we construct a Diagnosis Knowledge Graph (KG) that encodes both hierarchical and semantic relations enriched by large language models (LLM). To align with patient data, we further introduce a lab-informed proxy task that guides the model to follow a clinically consistent, stepwise reasoning process based on lab test signals. Experimental results on two public EHR datasets demonstrate that DuaLK consistently outperforms existing baselines across four clinical prediction tasks. These findings highlight the potential of combining structured medical knowledge with individual-level clinical signals to achieve more accurate and interpretable diagnostic predictions. The source code is publicly available on https://github.com/humphreyhuu/DuaLK.
        ]]></description>
    </item>
    <item>
        <title>Document Parsing Unveiled: Techniques, Challenges, and Prospects for Structured Information Extraction</title>
        <link>https://arxiv.org/abs/2410.21169</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.21169v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qintong Zhang, Bin Wang, Victor Shea-Jay Huang, Junyuan Zhang, Zhengren Wang, Hao Liang, Conghui He, Wentao Zhang</dc:creator>
        <description><![CDATA[
            背景：将非结构化和半结构化文档转换为结构化数据对众多应用很重要，大语言模型发展下，文档解析在知识库构建和训练数据生成中不可或缺。方法：全面回顾文档解析现状，涵盖从模块化管道系统到大型视觉语言模型驱动的端到端模型等关键方法，详细研究布局检测、内容提取和多模态数据集成等核心组件。效果：指出模块化系统和视觉语言模型面临的挑战，给出未来研究方向，强调构建更多样数据集的重要性。
            arXiv:2410.21169v4 Announce Type: replace 
Abstract: Document parsing is essential for converting unstructured and semi-structured documents such as contracts, academic papers, and invoices into structured, machine-readable data. Document parsing reliable structured data from unstructured inputs, providing huge convenience for numerous applications. Especially with recent achievements in Large Language Models, document parsing plays an indispensable role in both knowledge base construction and training data generation. This survey presents a comprehensive review of the current state of document parsing, covering key methodologies, from modular pipeline systems to end-to-end models driven by large vision-language models. Core components such as layout detection, content extraction (including text, tables, and mathematical expressions), and multi-modal data integration are examined in detail. Additionally, this paper discusses the challenges faced by modular document parsing systems and vision-language models in handling complex layouts, integrating multiple modules, and recognizing high-density text. It outlines future research directions and emphasizes the importance of developing larger and more diverse datasets.
        ]]></description>
    </item>
    <item>
        <title>Kernel-Aware Graph Prompt Learning for Few-Shot Anomaly Detection</title>
        <link>https://arxiv.org/abs/2412.17619</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2412.17619v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Fenfang Tao, Guo-Sen Xie, Fang Zhao, Xiangbo Shu</dc:creator>
        <description><![CDATA[
            背景：少样本异常检测（FSAD）中，现有方法在大视觉 - 语言模型范式下用文本提示对齐视觉特征，但忽略视觉特征内在上下文信息。方法：提出核感知图提示学习框架KAG - prompt，构建核感知分层图，以不同层聚焦不同大小异常区域的特征为节点，节点关系为边，通过图上消息传递捕获跨层上下文信息；还提出基于多级信息融合的图像级评分方法。效果：在MVTecAD和VisA数据集上，KAG - prompt在图像级/像素级异常检测达SOTA。
            arXiv:2412.17619v2 Announce Type: replace 
Abstract: Few-shot anomaly detection (FSAD) aims to detect unseen anomaly regions with the guidance of very few normal support images from the same class. Existing FSAD methods usually find anomalies by directly designing complex text prompts to align them with visual features under the prevailing large vision-language model paradigm. However, these methods, almost always, neglect intrinsic contextual information in visual features, e.g., the interaction relationships between different vision layers, which is an important clue for detecting anomalies comprehensively. To this end, we propose a kernel-aware graph prompt learning framework, termed as KAG-prompt, by reasoning the cross-layer relations among visual features for FSAD. Specifically, a kernel-aware hierarchical graph is built by taking the different layer features focusing on anomalous regions of different sizes as nodes, meanwhile, the relationships between arbitrary pairs of nodes stand for the edges of the graph. By message passing over this graph, KAG-prompt can capture cross-layer contextual information, thus leading to more accurate anomaly prediction. Moreover, to integrate the information of multiple important anomaly signals in the prediction map, we propose a novel image-level scoring method based on multi-level information fusion. Extensive experiments on MVTecAD and VisA datasets show that KAG-prompt achieves state-of-the-art FSAD results for image-level/pixel-level anomaly detection. Code is available at https://github.com/CVL-hub/KAG-prompt.git.
        ]]></description>
    </item>
    <item>
        <title>MomentSeeker: A Comprehensive Benchmark and A Strong Baseline For Moment Retrieval Within Long Videos</title>
        <link>https://arxiv.org/abs/2502.12558</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.12558v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Huaying Yuan, Jian Ni, Yueze Wang, Junjie Zhou, Zhengyang Liang, Zheng Liu, Zhao Cao, Zhicheng Dou, Ji-Rong Wen</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）在长视频理解中潜力大，能助力多模态大语言模型（MLLMs）高效生成高质量答案，但缺乏全面评估长视频片段检索（LVMR）性能的基准。方法：提出MomentSeeker基准，涵盖平均超500秒长视频、多种任务类别和应用场景，评估任务经人工标注；在合成数据上微调基于MLLM的LVMR检索器。效果：微调的检索器在基准上表现良好，实验凸显LVMR挑战和现有方法局限，资源将共享推动领域研究。
            arXiv:2502.12558v3 Announce Type: replace 
Abstract: Retrieval augmented generation (RAG) holds great promise in addressing challenges associated with long video understanding. These methods retrieve useful moments from long videos for their presented tasks, thereby enabling multimodal large language models (MLLMs) to generate high-quality answers in a cost-effective way. In this work, we present MomentSeeker, a comprehensive benchmark to evaluate retrieval models' performance in handling general long-video moment retrieval (LVMR) tasks. MomentSeeker offers three key advantages. First, it incorporates long videos of over 500 seconds on average, making it the first benchmark specialized for long-video moment retrieval. Second, it covers a wide range of task categories (including Moment Search, Caption Alignment, Image-conditioned Moment Search, and Video-conditioned Moment Search) and diverse application scenarios (e.g., sports, movies, cartoons, and ego), making it a comprehensive tool for assessing retrieval models' general LVMR performance. Additionally, the evaluation tasks are carefully curated through human annotation, ensuring the reliability of assessment. We further fine-tune an MLLM-based LVMR retriever on synthetic data, which demonstrates strong performance on our benchmark. We perform extensive experiments with various popular multimodal retrievers based on our benchmark, whose results highlight the challenges of LVMR and limitations for existing methods. Our created resources will be shared with community to advance future research in this field.
        ]]></description>
    </item>
    <item>
        <title>BioMaze: Benchmarking and Enhancing Large Language Models for Biological Pathway Reasoning</title>
        <link>https://arxiv.org/abs/2502.16660</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.16660v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Haiteng Zhao, Chang Ma, Fangzhi Xu, Lingpeng Kong, Zhi-Hong Deng</dc:creator>
        <description><![CDATA[
            背景：大语言模型在生物领域应用广泛，但在复杂生物系统（如生物通路）的推理能力尚待挖掘。方法：引入含5100个复杂通路问题的BioMaze数据集，评估思维链和图增强推理等方法，发现大模型在通路推理，尤其在扰动系统中表现不佳，为此提出PathSeeker，通过基于交互子图的导航增强推理。效果：可更有效处理生物系统复杂性，以科学方式解决问题。代码和数据集见https://github.com/zhao-ht/BioMaze 。
            arXiv:2502.16660v4 Announce Type: replace 
Abstract: The applications of large language models (LLMs) in various biological domains have been explored recently, but their reasoning ability in complex biological systems, such as pathways, remains underexplored, which is crucial for predicting biological phenomena, formulating hypotheses, and designing experiments. This work explores the potential of LLMs in pathway reasoning. We introduce BioMaze, a dataset with 5.1K complex pathway problems derived from real research, covering various biological contexts including natural dynamic changes, disturbances, additional intervention conditions, and multi-scale research targets. Our evaluation of methods such as CoT and graph-augmented reasoning, shows that LLMs struggle with pathway reasoning, especially in perturbed systems. To address this, we propose PathSeeker, an LLM agent that enhances reasoning through interactive subgraph-based navigation, enabling a more effective approach to handling the complexities of biological systems in a scientifically aligned manner. The dataset and code are available at https://github.com/zhao-ht/BioMaze.
        ]]></description>
    </item>
    <item>
        <title>FourierNAT: A Fourier-Mixing-Based Non-Autoregressive Transformer for Parallel Sequence Generation</title>
        <link>https://arxiv.org/abs/2503.07630</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.07630v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Andrew Kiruluta, Eric Lundy, Andreas Lemos</dc:creator>
        <description><![CDATA[
            背景：传统非自回归Transformer（NAT）在捕获全局依赖方面存在挑战。方法：提出FourierNAT，在解码器中采用基于傅里叶的混合方式，利用离散傅里叶变换混合整个序列维度的词元嵌入，并结合学习的频域门控，使模型无需显式自回归步骤就能有效传播上下文。效果：在WMT机器翻译和CNN/DailyMail摘要等基准测试中，FourierNAT与领先的NAT基线相比取得有竞争力的结果，比自回归Transformer有显著速度优势，还能部分缓解单遍NAT生成中的连贯性差距。
            arXiv:2503.07630v2 Announce Type: replace 
Abstract: We present FourierNAT, a novel non-autoregressive Transformer (NAT) architecture that employs Fourier-based mixing in the decoder to generate output sequences in parallel. While traditional NAT approaches often face challenges with capturing global dependencies, our method leverages a discrete Fourier transform to mix token embeddings across the entire sequence dimension, coupled with learned frequency-domain gating. This allows the model to efficiently propagate context without explicit autoregressive steps. Empirically, FourierNAT achieves competitive results against leading NAT baselines on standard benchmarks like WMT machine translation and CNN/DailyMail summarization, providing significant speed advantages over autoregressive Transformers. We further demonstrate that learned frequency-domain parameters allow the model to adaptively focus on long-range or short-range dependencies, partially mitigating the well-known coherence gaps in one-pass NAT generation. Overall, FourierNAT highlights the potential of integrating spectral-domain operations to accelerate and improve parallel text generation. This approach can potentially provide great computational and time savings in inference tasks LLMs.
        ]]></description>
    </item>
    <item>
        <title>Syzygy of Thoughts: Improving LLM CoT with the Minimal Free Resolution</title>
        <link>https://arxiv.org/abs/2504.09566</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09566v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chenghao Li, Chaoning Zhang, Yi Lu, Jiaquan Zhang, Qigan Sun, Xudong Wang, Jiwei Wei, Guoqing Wang, Yang Yang, Heng Tao Shen</dc:creator>
        <description><![CDATA[
            背景：思维链（CoT）提示可提升大语言模型推理能力，但复杂任务常超出单条推理链能力。方法：受交换代数和代数几何中最小自由分解（MFR）启发，提出思维合冲（SoT）框架，引入辅助、相互关联的推理路径扩展CoT，利用MFR将复杂问题分解为逻辑完整的最小子问题。效果：在多个数据集和模型上测试，推理准确率达到或超过主流CoT标准，还提升了大语言模型推理时间的可扩展性。
            arXiv:2504.09566v2 Announce Type: replace 
Abstract: Chain-of-Thought (CoT) prompting enhances the reasoning of large language models (LLMs) by decomposing problems into sequential steps, mimicking human logic and reducing errors. However, complex tasks with vast solution spaces and vague constraints often exceed the capacity of a single reasoning chain. Inspired by Minimal Free Resolution (MFR) in commutative algebra and algebraic geometry, we propose Syzygy of Thoughts (SoT)-a novel framework that extends CoT by introducing auxiliary, interrelated reasoning paths. SoT captures deeper logical dependencies, enabling more robust and structured problem-solving. MFR decomposes a module into a sequence of free modules with minimal rank, providing a structured analytical approach to complex systems. This method introduces the concepts of "Module", "Betti numbers","Freeness", "Mapping", "Exactness" and "Minimality", enabling the systematic decomposition of the original complex problem into logically complete minimal subproblems while preserving key problem features and reducing reasoning length. We tested SoT across diverse datasets (e.g., GSM8K, MATH) and models (e.g., GPT-4o-mini, Qwen2.5), achieving inference accuracy that matches or surpasses mainstream CoTs standards. Additionally, by aligning the sampling process with algebraic constraints, our approach enhances the scalability of inference time in LLMs, ensuring both transparent reasoning and high performance. Our code will be publicly available at https://github.com/dlMARiA/Syzygy-of-thoughts.
        ]]></description>
    </item>
    <item>
        <title>Exploring the Role of Knowledge Graph-Based RAG in Japanese Medical Question Answering with Small-Scale LLMs</title>
        <link>https://arxiv.org/abs/2504.10982</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.10982v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yingjian Chen, Feiyang Li, Xingyu Song, Tianxiao Li, Issey Sukeda, Irene Li</dc:creator>
        <description><![CDATA[
            背景：大语言模型在医疗问答中表现良好，但在日语环境下，因隐私限制，商业模型难以应用，结合开源大模型与检索增强生成（RAG）的潜力待挖掘。方法：首次探索基于知识图谱（KG）的RAG框架用于日语医疗问答的小规模开源大模型。效果：实验表明，基于KG的RAG对小规模开源大模型的日语医疗问答效果提升有限，案例研究显示RAG效果对外部检索内容质量和相关性敏感。
            arXiv:2504.10982v2 Announce Type: replace 
Abstract: Large language models (LLMs) perform well in medical QA, but their effectiveness in Japanese contexts is limited due to privacy constraints that prevent the use of commercial models like GPT-4 in clinical settings. As a result, recent efforts focus on instruction-tuning open-source LLMs, though the potential of combining them with retrieval-augmented generation (RAG) remains underexplored. To bridge this gap, we are the first to explore a knowledge graph-based (KG) RAG framework for Japanese medical QA small-scale open-source LLMs. Experimental results show that KG-based RAG has only a limited impact on Japanese medical QA using small-scale open-source LLMs. Further case studies reveal that the effectiveness of the RAG is sensitive to the quality and relevance of the external retrieved content. These findings offer valuable insights into the challenges and potential of applying RAG in Japanese medical QA, while also serving as a reference for other low-resource languages.
        ]]></description>
    </item>
    <item>
        <title>Elucidating the Design Space of Multimodal Protein Language Models</title>
        <link>https://arxiv.org/abs/2504.11454</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.11454v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Cheng-Yen Hsieh, Xinyou Wang, Daiheng Zhang, Dongyu Xue, Fei Ye, Shujian Huang, Zaixiang Zheng, Quanquan Gu</dc:creator>
        <description><![CDATA[
            背景：多模态蛋白质语言模型（PLMs）整合序列和基于标记的结构信息，但将3D结构标记化会导致细粒度结构细节和相关性信息丢失。方法：系统阐明多模态PLMs的设计空间，识别出标记化损失和不准确的结构标记预测为主要瓶颈，提出改进生成建模、结构感知架构和表征学习以及数据探索等方法。效果：有效设计方法显著提高结构生成多样性，650M模型在PDB测试集上将RMSD从5.52降至2.36，优于3B基线模型，与专业折叠模型相当。
            arXiv:2504.11454v2 Announce Type: replace 
Abstract: Multimodal protein language models (PLMs) integrate sequence and token-based structural information, serving as a powerful foundation for protein modeling, generation, and design. However, the reliance on tokenizing 3D structures into discrete tokens causes substantial loss of fidelity about fine-grained structural details and correlations. In this paper, we systematically elucidate the design space of multimodal PLMs to overcome their limitations. We identify tokenization loss and inaccurate structure token predictions by the PLMs as major bottlenecks. To address these, our proposed design space covers improved generative modeling, structure-aware architectures and representation learning, and data exploration. Our advancements approach finer-grained supervision, demonstrating that token-based multimodal PLMs can achieve robust structural modeling. The effective design methods dramatically improve the structure generation diversity, and notably, folding abilities of our 650M model by reducing the RMSD from 5.52 to 2.36 on PDB testset, even outperforming 3B baselines and on par with the specialized folding models.
        ]]></description>
    </item>
    <item>
        <title>Leveraging Social Determinants of Health in Alzheimer's Research Using LLM-Augmented Literature Mining and Knowledge Graphs</title>
        <link>https://arxiv.org/abs/2410.09080</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.09080v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tianqi Shang, Shu Yang, Weiqing He, Tianhua Zhai, Dawei Li, Bojian Hou, Tianlong Chen, Jason H. Moore, Marylyn D. Ritchie, Li Shen</dc:creator>
        <description><![CDATA[
            背景：社会健康决定因素（SDoH）影响阿尔茨海默病（AD）发病风险，但相关病因机制不明，且收集信息困难。方法：提出自动化框架，利用大语言模型和自然语言处理技术从文献中挖掘SDoH知识，并与从通用知识图谱PrimeKG中提取的AD相关生物实体整合，用图神经网络进行链接预测任务。效果：该框架有望促进AD知识发现，还可推广到其他SDoH相关研究领域。代码见https://github.com/hwq0726/SDoHenPKG。
            arXiv:2410.09080v2 Announce Type: replace-cross 
Abstract: Growing evidence suggests that social determinants of health (SDoH), a set of nonmedical factors, affect individuals' risks of developing Alzheimer's disease (AD) and related dementias. Nevertheless, the etiological mechanisms underlying such relationships remain largely unclear, mainly due to difficulties in collecting relevant information. This study presents a novel, automated framework that leverages recent advancements of large language model (LLM) and natural language processing techniques to mine SDoH knowledge from extensive literature and integrate it with AD-related biological entities extracted from the general-purpose knowledge graph PrimeKG. Utilizing graph neural networks, we performed link prediction tasks to evaluate the resultant SDoH-augmented knowledge graph. Our framework shows promise for enhancing knowledge discovery in AD and can be generalized to other SDoH-related research areas, offering a new tool for exploring the impact of social determinants on health outcomes. Our code is available at: https://github.com/hwq0726/SDoHenPKG
        ]]></description>
    </item>
    <item>
        <title>Think Before Recommend: Unleashing the Latent Reasoning Power for Sequential Recommendation</title>
        <link>https://arxiv.org/abs/2503.22675</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.22675v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiakai Tang, Sunhao Dai, Teng Shi, Jun Xu, Xu Chen, Wen Chen, Wu Jian, Yuning Jiang</dc:creator>
        <description><![CDATA[
            背景：序列推荐旨在从用户历史交互中捕捉模式预测下一物品，但现有方法采用直接前向计算范式，计算深度有限，难以建模用户偏好的复杂演变。方法：提出ReaRec，首个推荐系统推理时计算框架，通过隐式多步推理增强用户表示，结合特殊推理位置嵌入解耦编码与推理空间，还引入两种轻量级推理学习方法。效果：在五个公开数据集和不同架构上实验，显著提升多个序列推荐骨干性能约30%-50%。
            arXiv:2503.22675v2 Announce Type: replace-cross 
Abstract: Sequential Recommendation (SeqRec) aims to predict the next item by capturing sequential patterns from users' historical interactions, playing a crucial role in many real-world recommender systems. However, existing approaches predominantly adopt a direct forward computation paradigm, where the final hidden state of the sequence encoder serves as the user representation. We argue that this inference paradigm, due to its limited computational depth, struggles to model the complex evolving nature of user preferences and lacks a nuanced understanding of long-tail items, leading to suboptimal performance. To address this issue, we propose \textbf{ReaRec}, the first inference-time computing framework for recommender systems, which enhances user representations through implicit multi-step reasoning. Specifically, ReaRec autoregressively feeds the sequence's last hidden state into the sequential recommender while incorporating special reasoning position embeddings to decouple the original item encoding space from the multi-step reasoning space. Moreover, we introduce two lightweight reasoning-based learning methods, Ensemble Reasoning Learning (ERL) and Progressive Reasoning Learning (PRL), to further effectively exploit ReaRec's reasoning potential. Extensive experiments on five public real-world datasets and different SeqRec architectures demonstrate the generality and effectiveness of our proposed ReaRec. Remarkably, post-hoc analyses reveal that ReaRec significantly elevates the performance ceiling of multiple sequential recommendation backbones by approximately 30\%-50\%. Thus, we believe this work can open a new and promising avenue for future research in inference-time computing for sequential recommendation.
        ]]></description>
    </item>
    <item>
        <title>Task Memory Engine (TME): A Structured Memory Framework with Graph-Aware Extensions for Multi-Step LLM Agent Tasks</title>
        <link>https://arxiv.org/abs/2504.08525</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.08525v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ye Ye</dc:creator>
        <description><![CDATA[
            背景：大语言模型用于多步任务时，现有框架难以对任务状态进行结构化理解，导致性能不稳定、易产生幻觉等问题。方法：提出任务记忆引擎（TME），用分层的任务记忆树（TMT）跟踪任务执行，每个节点存储任务步骤相关信息；引入基于活跃节点路径动态生成提示的方法。效果：通过案例研究和对比实验，TME提升了任务完成准确率，行为更具可解释性，且实现开销小，还为基于有向无环图的内存架构奠定基础。
            arXiv:2504.08525v3 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) are increasingly used as autonomous agents for multi-step tasks. However, most existing frameworks fail to maintain a structured understanding of the task state, often relying on linear prompt concatenation or shallow memory buffers. This leads to brittle performance, frequent hallucinations, and poor long-range coherence. In this work, we propose the Task Memory Engine (TME), a lightweight and structured memory module that tracks task execution using a hierarchical Task Memory Tree (TMT). Each node in the tree corresponds to a task step, storing relevant input, output, status, and sub-task relationships. We introduce a prompt synthesis method that dynamically generates LLM prompts based on the active node path, significantly improving execution consistency and contextual grounding. Through case studies and comparative experiments on multi-step agent tasks, we demonstrate that TME leads to better task completion accuracy and more interpretable behavior with minimal implementation overhead. A reference implementation of the core TME components is available at https://github.com/biubiutomato/TME-Agent, including basic examples and structured memory integration. While the current implementation uses a tree-based structure, TME is designed to be graph-aware, supporting reusable substeps, converging task paths, and shared dependencies. This lays the groundwork for future DAG-based memory architectures.
        ]]></description>
    </item>
    <item>
        <title>Understanding and Optimizing Multi-Stage AI Inference Pipelines</title>
        <link>https://arxiv.org/abs/2504.09775</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09775v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Abhimanyu Rajeshkumar Bambhaniya, Hanjiang Wu, Suvinay Subramanian, Sudarshan Srinivasan, Souvik Kundu, Amir Yazdanbakhsh, Midhilesh Elavazhagan, Madhu Kumar, Tushar Krishna</dc:creator>
        <description><![CDATA[
            背景：大语言模型发展使推理管道和硬件平台更复杂，现有模拟器难以对异构多引擎工作流建模。方法：提出HERMES模拟器，可对包括RAG、推理等多种请求阶段进行建模，支持异构客户端并发执行多模型，结合真实硬件跟踪与分析建模。效果：能捕捉内存带宽争用等关键权衡，通过案例研究探索推理阶段对端到端延迟等的影响，为系统设计人员优化软硬件协同设计提供见解。
            arXiv:2504.09775v2 Announce Type: replace-cross 
Abstract: The rapid evolution of Large Language Models (LLMs) has driven the need for increasingly sophisticated inference pipelines and hardware platforms. Modern LLM serving extends beyond traditional prefill-decode workflows, incorporating multi-stage processes such as Retrieval Augmented Generation (RAG), key-value (KV) cache retrieval, dynamic model routing, and multi step reasoning. These stages exhibit diverse computational demands, requiring distributed systems that integrate GPUs, ASICs, CPUs, and memory-centric architectures. However, existing simulators lack the fidelity to model these heterogeneous, multi-engine workflows, limiting their ability to inform architectural decisions.
  To address this gap, we introduce HERMES, a Heterogeneous Multi-stage LLM inference Execution Simulator. HERMES models diverse request stages; including RAG, KV retrieval, reasoning, prefill, and decode across complex hardware hierarchies. HERMES supports heterogeneous clients executing multiple models concurrently unlike prior frameworks while incorporating advanced batching strategies and multi-level memory hierarchies. By integrating real hardware traces with analytical modeling, HERMES captures critical trade-offs such as memory bandwidth contention, inter-cluster communication latency, and batching efficiency in hybrid CPU-accelerator deployments. Through case studies, we explore the impact of reasoning stages on end-to-end latency, optimal batching strategies for hybrid pipelines, and the architectural implications of remote KV cache retrieval. HERMES empowers system designers to navigate the evolving landscape of LLM inference, providing actionable insights into optimizing hardware-software co-design for next-generation AI workloads.
        ]]></description>
    </item>
    <item>
        <title>Voice Conversion with Diverse Intonation using Conditional Variational Auto-Encoder</title>
        <link>https://arxiv.org/abs/2504.12005</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.12005v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Soobin Suh, Dabi Ahn, Heewoong Park, Jonghun Park</dc:creator>
        <description><![CDATA[
            背景：传统语音转换模型每个源输入只能产生一种结果，无法满足说话者用不同语调表达同一脚本的需求。方法：提出一种使用条件变分自编码器（CVAE）实现多样化语调语音转换的新方法，将说话者风格特征映射到具有高斯分布的潜在空间，并用逆自回归流（IAF）使潜在空间后验更复杂。效果：转换后的语音不仅语调多样，且音质比未使用CVAE的模型更好。
            arXiv:2504.12005v1 Announce Type: new 
Abstract: Voice conversion is a task of synthesizing an utterance with target speaker's voice while maintaining linguistic information of the source utterance. While a speaker can produce varying utterances from a single script with different intonations, conventional voice conversion models were limited to producing only one result per source input. To overcome this limitation, we propose a novel approach for voice conversion with diverse intonations using conditional variational autoencoder (CVAE). Experiments have shown that the speaker's style feature can be mapped into a latent space with Gaussian distribution. We have also been able to convert voices with more diverse intonation by making the posterior of the latent space more complex with inverse autoregressive flow (IAF). As a result, the converted voice not only has a diversity of intonations, but also has better sound quality than the model without CVAE.
        ]]></description>
    </item>
    <item>
        <title>Edge Intelligence for Wildlife Conservation: Real-Time Hornbill Call Classification Using TinyML</title>
        <link>https://arxiv.org/abs/2504.12272</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.12272v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kong Ka Hing, Mehran Behjati</dc:creator>
        <description><![CDATA[
            背景：马来西亚犀鸟面临多种威胁，传统的种群监测困难且资源消耗大，TinyML的出现带来新契机。方法：利用Xeno - canto数据库音频数据，对音频预处理，用Mel - Frequency Energy提取特征，在Arduino Nano 33 BLE上部署模型，用Edge Impulse训练模型并通过实地测试验证。效果：该模型在犀鸟种类识别中达到了较高的准确率，凸显了TinyML在环境监测和生态保护中的潜力。
            arXiv:2504.12272v1 Announce Type: new 
Abstract: Hornbills, an iconic species of Malaysia's biodiversity, face threats from habi-tat loss, poaching, and environmental changes, necessitating accurate and real-time population monitoring that is traditionally challenging and re-source intensive. The emergence of Tiny Machine Learning (TinyML) offers a chance to transform wildlife monitoring by enabling efficient, real-time da-ta analysis directly on edge devices. Addressing the challenge of wildlife conservation, this research paper explores the pivotal role of machine learn-ing, specifically TinyML, in the classification and monitoring of hornbill calls in Malaysia. Leveraging audio data from the Xeno-canto database, the study aims to develop a speech recognition system capable of identifying and classifying hornbill vocalizations. The proposed methodology involves pre-processing the audio data, extracting features using Mel-Frequency Energy (MFE), and deploying the model on an Arduino Nano 33 BLE, which is adept at edge computing. The research encompasses foundational work, in-cluding a comprehensive introduction, literature review, and methodology. The model is trained using Edge Impulse and validated through real-world tests, achieving high accuracy in hornbill species identification. The project underscores the potential of TinyML for environmental monitoring and its broader application in ecological conservation efforts, contributing to both the field of TinyML and wildlife conservation.
        ]]></description>
    </item>
    <item>
        <title>Taming Data and Transformers for Audio Generation</title>
        <link>https://arxiv.org/abs/2406.19388</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2406.19388v4</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Moayed Haji-Ali, Willi Menapace, Aliaksandr Siarohin, Guha Balakrishnan, Vicente Ordonez</dc:creator>
        <description><![CDATA[
            背景：环境声音生成器的可扩展性受数据稀缺、字幕质量不足和模型架构可扩展性有限的阻碍。方法：提出高效可扩展的环境音频数据集收集管道，得到超4700万片段的AutoReCap - XL数据集；提出高质量自动音频字幕模型AutoCap，采用Q - Former模块并利用音频元数据提升字幕质量；提出基于Transformer的可扩展音频生成架构GenAu，将参数扩展到12.5亿。效果：AutoCap的CIDEr分数达83.2，较之前提升3.2%；GenAu的FAD、IS和CLAP分数分别提升4.7%、11.1%和13.5%。
            arXiv:2406.19388v4 Announce Type: replace 
Abstract: The scalability of ambient sound generators is hindered by data scarcity, insufficient caption quality, and limited scalability in model architecture. This work addresses these challenges by advancing both data and model scaling. First, we propose an efficient and scalable dataset collection pipeline tailored for ambient audio generation, resulting in AutoReCap-XL, the largest ambient audio-text dataset with over 47 million clips. To provide high-quality textual annotations, we propose AutoCap, a high-quality automatic audio captioning model. By adopting a Q-Former module and leveraging audio metadata, AutoCap substantially enhances caption quality, reaching a CIDEr score of $83.2$, a $3.2\%$ improvement over previous captioning models. Finally, we propose GenAu, a scalable transformer-based audio generation architecture that we scale up to 1.25B parameters. We demonstrate its benefits from data scaling with synthetic captions as well as model size scaling. When compared to baseline audio generators trained at similar size and data scale, GenAu obtains significant improvements of $4.7\%$ in FAD score, $11.1\%$ in IS, and $13.5\%$ in CLAP score. Our code, model checkpoints, and dataset are publicly available.
        ]]></description>
    </item>
</channel>
</rss>