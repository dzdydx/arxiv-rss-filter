<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
<channel>
    <title>arXiv Paper Filter</title>
    <link>https://github.com/None/arxiv_filter</link>
    <description>根据研究兴趣筛选的arXiv论文</description>
    <atom:link href="https://raw.githubusercontent.com/None/arxiv_filter/main/feed.xml" rel="self" type="application/rss+xml" />
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>zh-CN</language>
    <lastBuildDate>Mon, 21 Apr 2025 12:12:47 +0800</lastBuildDate>
    <managingEditor>None@github.com</managingEditor>
    <pubDate>Mon, 21 Apr 2025 12:12:47 +0800</pubDate>
    <skipDays>
        <day>Saturday</day>
        <day>Sunday</day>
    </skipDays>

    <item>
        <title>Secure Multifaceted-RAG for Enterprise: Hybrid Knowledge Retrieval with Security Filtering</title>
        <link>https://arxiv.org/abs/2504.13425</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.13425v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Grace Byun, Shinsun Lee, Nayoung Choi, Jinho Choi</dc:creator>
        <description><![CDATA[
            背景：现有检索增强生成（RAG）系统在企业环境中存在检索范围有限和数据安全风险问题。方法：提出Secure Multifaceted - RAG（SecMulti - RAG）框架，从内部文档、预生成专家知识和按需外部大模型生成知识三个来源检索，采用本地开源生成器并通过过滤机制确保安全。效果：在汽车行业报告生成任务评估中，SecMulti - RAG显著优于传统RAG，基于大模型评估的正确率、丰富度和有用性胜率达79.3% - 91.9%，人工评估达56.3% - 70.4%。
            arXiv:2504.13425v1 Announce Type: new 
Abstract: Existing Retrieval-Augmented Generation (RAG) systems face challenges in enterprise settings due to limited retrieval scope and data security risks. When relevant internal documents are unavailable, the system struggles to generate accurate and complete responses. Additionally, using closed-source Large Language Models (LLMs) raises concerns about exposing proprietary information. To address these issues, we propose the Secure Multifaceted-RAG (SecMulti-RAG) framework, which retrieves not only from internal documents but also from two supplementary sources: pre-generated expert knowledge for anticipated queries and on-demand external LLM-generated knowledge. To mitigate security risks, we adopt a local open-source generator and selectively utilize external LLMs only when prompts are deemed safe by a filtering mechanism. This approach enhances completeness, prevents data leakage, and reduces costs. In our evaluation on a report generation task in the automotive industry, SecMulti-RAG significantly outperforms traditional RAG - achieving 79.3 to 91.9 percent win rates across correctness, richness, and helpfulness in LLM-based evaluation, and 56.3 to 70.4 percent in human evaluation. This highlights SecMulti-RAG as a practical and secure solution for enterprise RAG.
        ]]></description>
    </item>
    <item>
        <title>Chain-of-Thought Textual Reasoning for Few-shot Temporal Action Localization</title>
        <link>https://arxiv.org/abs/2504.13460</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.13460v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hongwei Ji, Wulian Yun, Mengshi Qi, Huadong Ma</dc:creator>
        <description><![CDATA[
            传统时序动作定位方法依赖大量标注数据，少样本TAL虽减少依赖但现有方法多忽视文本信息。为此，提出基于思维链文本推理的少样本时序动作定位方法。设计利用文本语义信息的少样本学习框架，含语义感知的文本 - 视觉对齐模块；设计类思维链推理方法辅助动作定位。在ActivityNet1.3和THUMOS14等数据集实验，结果表明该方法在单实例和多实例场景显著优于现有方法。
            arXiv:2504.13460v1 Announce Type: new 
Abstract: Traditional temporal action localization (TAL) methods rely on large amounts of detailed annotated data, whereas few-shot TAL reduces this dependence by using only a few training samples to identify unseen action categories. However, existing few-shot TAL methods typically focus solely on video-level information, neglecting textual information, which can provide valuable semantic support for the localization task. Therefore, we propose a new few-shot temporal action localization method by Chain-of-Thought textual reasoning to improve localization performance. Specifically, we design a novel few-shot learning framework that leverages textual semantic information to enhance the model's ability to capture action commonalities and variations, which includes a semantic-aware text-visual alignment module designed to align the query and support videos at different levels. Meanwhile, to better express the temporal dependencies and causal relationships between actions at the textual level to assist action localization, we design a Chain of Thought (CoT)-like reasoning method that progressively guides the Vision Language Model (VLM) and Large Language Model (LLM) to generate CoT-like text descriptions for videos. The generated texts can capture more variance of action than visual features. We conduct extensive experiments on the publicly available ActivityNet1.3 and THUMOS14 datasets. We introduce the first dataset named Human-related Anomaly Localization and explore the application of the TAL task in human anomaly detection. The experimental results demonstrate that our proposed method significantly outperforms existing methods in single-instance and multi-instance scenarios. We will release our code, data and benchmark.
        ]]></description>
    </item>
    <item>
        <title>Prejudge-Before-Think: Enhancing Large Language Models at Test-Time by Process Prejudge Reasoning</title>
        <link>https://arxiv.org/abs/2504.13500</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.13500v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jianing Wang, Jin Jiang, Yang Liu, Mengdi Zhang, Xunliang Cai</dc:creator>
        <description><![CDATA[
            背景：提升大语言模型推理能力是重要研究方向，当前模型多依赖试错。方法：提出“过程预判”策略，定义预判节点，构建带动态树搜索策略的自动化推理框架，只需一个大语言模型完成答案判断等操作，还开发两阶段训练机制。效果：竞赛级复杂推理实验表明，该方法能让模型先预判再思考，显著提升大语言模型推理能力。代码和数据见https://github.com/wjn1996/Prejudge-Before-Think 。
            arXiv:2504.13500v1 Announce Type: new 
Abstract: In this paper, we introduce a new \emph{process prejudge} strategy in LLM reasoning to demonstrate that bootstrapping with process prejudge allows the LLM to adaptively anticipate the errors encountered when advancing the subsequent reasoning steps, similar to people sometimes pausing to think about what mistakes may occur and how to avoid them, rather than relying solely on trial and error. Specifically, we define a prejudge node in the rationale, which represents a reasoning step, with at least one step that follows the prejudge node that has no paths toward the correct answer. To synthesize the prejudge reasoning process, we present an automated reasoning framework with a dynamic tree-searching strategy. This framework requires only one LLM to perform answer judging, response critiquing, prejudge generation, and thought completion. Furthermore, we develop a two-phase training mechanism with supervised fine-tuning (SFT) and reinforcement learning (RL) to further enhance the reasoning capabilities of LLMs. Experimental results from competition-level complex reasoning demonstrate that our method can teach the model to prejudge before thinking and significantly enhance the reasoning ability of LLMs. Code and data is released at https://github.com/wjn1996/Prejudge-Before-Think.
        ]]></description>
    </item>
    <item>
        <title>Deep Learning Models Meet Financial Data Modalities</title>
        <link>https://arxiv.org/abs/2504.13521</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.13521v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kasymkhan Khubiev, Michail Semenov</dc:creator>
        <description><![CDATA[
            背景：算法交易需从多种金融数据源提取有意义信号，深度学习处理非结构化数据成果显著，但处理结构化金融数据仍是挑战。方法：该研究探索深度学习模型与金融数据模态的融合，提出将限价订单簿分析融入算法交易的新方法，开发嵌入技术，将顺序限价订单簿快照作为基于图像表示中的不同输入通道。效果：处理限价订单簿数据的方法在高频交易算法中达到了最先进水平，凸显深度学习在金融应用中的有效性。
            arXiv:2504.13521v1 Announce Type: new 
Abstract: Algorithmic trading relies on extracting meaningful signals from diverse financial data sources, including candlestick charts, order statistics on put and canceled orders, traded volume data, limit order books, and news flow. While deep learning has demonstrated remarkable success in processing unstructured data and has significantly advanced natural language processing, its application to structured financial data remains an ongoing challenge. This study investigates the integration of deep learning models with financial data modalities, aiming to enhance predictive performance in trading strategies and portfolio optimization. We present a novel approach to incorporating limit order book analysis into algorithmic trading by developing embedding techniques and treating sequential limit order book snapshots as distinct input channels in an image-based representation. Our methodology for processing limit order book data achieves state-of-the-art performance in high-frequency trading algorithms, underscoring the effectiveness of deep learning in financial applications.
        ]]></description>
    </item>
    <item>
        <title>CoT-RAG: Integrating Chain of Thought and Retrieval-Augmented Generation to Enhance Reasoning in Large Language Models</title>
        <link>https://arxiv.org/abs/2504.13534</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.13534v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Feiyang Li, Peng Fang, Zhan Shi, Arijit Khan, Fang Wang, Dan Feng, Weihao Wang, Xin Zhang, Yongjian Cui</dc:creator>
        <description><![CDATA[
            背景：思维链推理虽提升大语言模型复杂任务表现，但存在仅靠模型生成推理链可靠性低、自然语言推理链干扰推理逻辑的问题。方法：提出CoT - RAG框架，包括知识图谱驱动的思维链生成、可学习的知识案例感知RAG、伪程序提示执行。效果：在九个公开数据集上对比现有方法，准确率提升4.0% - 23.0%；在四个特定领域数据集测试中，表现出高准确率和高效执行能力，实用性和可扩展性强。
            arXiv:2504.13534v1 Announce Type: new 
Abstract: While chain-of-thought (CoT) reasoning improves the performance of large language models (LLMs) in complex tasks, it still has two main challenges: the low reliability of relying solely on LLMs to generate reasoning chains and the interference of natural language reasoning chains on the inference logic of LLMs. To address these issues, we propose CoT-RAG, a novel reasoning framework with three key designs: (i) Knowledge Graph-driven CoT Generation, featuring knowledge graphs to modulate reasoning chain generation of LLMs, thereby enhancing reasoning credibility; (ii) Learnable Knowledge Case-aware RAG, which incorporates retrieval-augmented generation (RAG) into knowledge graphs to retrieve relevant sub-cases and sub-descriptions, providing LLMs with learnable information; (iii) Pseudo-Program Prompting Execution, which encourages LLMs to execute reasoning tasks in pseudo-programs with greater logical rigor. We conduct a comprehensive evaluation on nine public datasets, covering three reasoning problems. Compared with the-state-of-the-art methods, CoT-RAG exhibits a significant accuracy improvement, ranging from 4.0% to 23.0%. Furthermore, testing on four domain-specific datasets, CoT-RAG shows remarkable accuracy and efficient execution, highlighting its strong practical applicability and scalability.
        ]]></description>
    </item>
    <item>
        <title>Compile Scene Graphs with Reinforcement Learning</title>
        <link>https://arxiv.org/abs/2504.13617</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.13617v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zuyao Chen, Jinlin Wu, Zhen Lei, Marc Pollefeys, Chang Wen Chen</dc:creator>
        <description><![CDATA[
            背景：大语言模型以预测下一令牌为训练原则，强化学习可提升其推理性能，但用大语言模型端到端提取场景图等结构化视觉表征的研究较少。方法：提出R1 - SGG，先在场景图数据集上进行监督微调（SFT），再用强化学习优化，设计以图为中心的奖励函数。效果：基于规则的强化学习显著提升场景图生成（SGG）任务的模型性能，实现零失败率，优于难以有效泛化的SFT。代码见https://github.com/gpt4vision/R1 - SGG。
            arXiv:2504.13617v1 Announce Type: new 
Abstract: Next token prediction is the fundamental principle for training large language models (LLMs), and reinforcement learning (RL) further enhances their reasoning performance. As an effective way to model language, image, video, and other modalities, the use of LLMs for end-to-end extraction of structured visual representations, such as scene graphs, remains underexplored. It requires the model to accurately produce a set of objects and relationship triplets, rather than generating text token by token. To achieve this, we introduce R1-SGG, a multimodal LLM (M-LLM) initially trained via supervised fine-tuning (SFT) on the scene graph dataset and subsequently refined using reinforcement learning to enhance its ability to generate scene graphs in an end-to-end manner. The SFT follows a conventional prompt-response paradigm, while RL requires the design of effective reward signals. Given the structured nature of scene graphs, we design a graph-centric reward function that integrates node-level rewards, edge-level rewards, and a format consistency reward. Our experiments demonstrate that rule-based RL substantially enhances model performance in the SGG task, achieving a zero failure rate--unlike supervised fine-tuning (SFT), which struggles to generalize effectively. Our code is available at https://github.com/gpt4vision/R1-SGG.
        ]]></description>
    </item>
    <item>
        <title>Thought Manipulation: External Thought Can Be Efficient for Large Reasoning Models</title>
        <link>https://arxiv.org/abs/2504.13626</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.13626v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yule Liu, Jingyi Zheng, Zhen Sun, Zifan Peng, Wenhan Dong, Zeyang Sha, Shiwen Cui, Weiqiang Wang, Xinlei He</dc:creator>
        <description><![CDATA[
            背景：大型推理模型（LRMs）存在“过度思考”问题，现有缓解方法需额外数据、非常规训练设置等。方法：通过实证分析发现将小模型生成的外部思维链置于特定标记间可操纵模型减少思考步骤，提出简单高效的ThoughtMani流程，使LRMs绕过不必要的中间步骤。效果：在LiveBench/Code数据集上应用于QwQ - 32B时，保持原性能，输出令牌数约减少30%，提升安全对齐度约10%。
            arXiv:2504.13626v1 Announce Type: new 
Abstract: Recent advancements in large reasoning models (LRMs) have demonstrated the effectiveness of scaling test-time computation to enhance reasoning capabilities in multiple tasks. However, LRMs typically suffer from "overthinking" problems, where models generate significantly redundant reasoning steps while bringing limited performance gains. Existing work relies on fine-tuning to mitigate overthinking, which requires additional data, unconventional training setups, risky safety misalignment, and poor generalization.
  Through empirical analysis, we reveal an important characteristic of LRM behaviors that placing external CoTs generated by smaller models between the thinking token ($\texttt{}$ and $\texttt{)}$ can effectively manipulate the model to generate fewer thoughts. Building on these insights, we propose a simple yet efficient pipeline, ThoughtMani, to enable LRMs to bypass unnecessary intermediate steps and reduce computational costs significantly. We conduct extensive experiments to validate the utility and efficiency of ThoughtMani. For instance, when applied to QwQ-32B on the LiveBench/Code dataset, ThoughtMani keeps the original performance and reduces output token counts by approximately 30%, with little overhead from the CoT generator. Furthermore, we find that ThoughtMani enhances safety alignment by an average of 10%. Since model vendors typically serve models of different sizes simultaneously, ThoughtMani provides an effective way to construct more efficient and accessible LRMs for real-world applications.
        ]]></description>
    </item>
    <item>
        <title>Multi-Type Context-Aware Conversational Recommender Systems via Mixture-of-Experts</title>
        <link>https://arxiv.org/abs/2504.13655</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.13655v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jie Zou, Cheng Lin, Weikang Guo, Zheng Wang, Jiwei Wei, Yang Yang, Hengtao Shen</dc:creator>
        <description><![CDATA[
            背景：对话推荐系统对话上下文信息有限，现有方法融合不同类型上下文信息存在挑战。方法：提出多类型上下文感知对话推荐系统MCCRS，通过专家混合体有效融合多类型上下文信息，结合结构化知识图谱和非结构化对话历史、商品评论，由多个专家分别处理特定领域信息，再由ChairBot协调生成最终结果。效果：实验表明，MCCRS比现有基线方法性能显著提高。
            arXiv:2504.13655v1 Announce Type: new 
Abstract: Conversational recommender systems enable natural language conversations and thus lead to a more engaging and effective recommendation scenario. As the conversations for recommender systems usually contain limited contextual information, many existing conversational recommender systems incorporate external sources to enrich the contextual information. However, how to combine different types of contextual information is still a challenge. In this paper, we propose a multi-type context-aware conversational recommender system, called MCCRS, effectively fusing multi-type contextual information via mixture-of-experts to improve conversational recommender systems. MCCRS incorporates both structured information and unstructured information, including the structured knowledge graph, unstructured conversation history, and unstructured item reviews. It consists of several experts, with each expert specialized in a particular domain (i.e., one specific contextual information). Multiple experts are then coordinated by a ChairBot to generate the final results. Our proposed MCCRS model takes advantage of different contextual information and the specialization of different experts followed by a ChairBot breaks the model bottleneck on a single contextual information. Experimental results demonstrate that our proposed MCCRS method achieves significantly higher performance compared to existing baselines.
        ]]></description>
    </item>
    <item>
        <title>SysCaps: Language Interfaces for Simulation Surrogates of Complex Systems</title>
        <link>https://arxiv.org/abs/2405.19653</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2405.19653v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Patrick Emami, Zhaonan Li, Saumya Sinha, Truc Nguyen</dc:creator>
        <description><![CDATA[
            背景：传统数值方法模拟复杂能源系统成本高，需用代理模型预测其行为。方法：引入语言描述“系统说明”（SysCaps）与代理模型交互，提出轻量级多模态文本和时间序列回归模型及训练流程，用大语言模型从模拟元数据合成高质量说明。效果：在建筑和风力发电场两个真实模拟器实验中，SysCaps增强的代理模型在未见过系统上比传统方法精度更高，还具备新泛化能力，如处理同一测试系统的语义相关描述。
            arXiv:2405.19653v4 Announce Type: replace 
Abstract: Surrogate models are used to predict the behavior of complex energy systems that are too expensive to simulate with traditional numerical methods. Our work introduces the use of language descriptions, which we call ``system captions'' or SysCaps, to interface with such surrogates. We argue that interacting with surrogates through text, particularly natural language, makes these models more accessible for both experts and non-experts. We introduce a lightweight multimodal text and timeseries regression model and a training pipeline that uses large language models (LLMs) to synthesize high-quality captions from simulation metadata. Our experiments on two real-world simulators of buildings and wind farms show that our SysCaps-augmented surrogates have better accuracy on held-out systems than traditional methods while enjoying new generalization abilities, such as handling semantically related descriptions of the same test system. Additional experiments also highlight the potential of SysCaps to unlock language-driven design space exploration and to regularize training through prompt augmentation.
        ]]></description>
    </item>
    <item>
        <title>Large Language Models are Good Multi-lingual Learners : When LLMs Meet Cross-lingual Prompts</title>
        <link>https://arxiv.org/abs/2409.11056</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2409.11056v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Teng Wang, Zhenqi He, Wing-Yin Yu, Xiaojin Fu, Xiongwei Han</dc:creator>
        <description><![CDATA[
            背景：大语言模型在长复杂语境中遵循规则生成数据时存在困难。方法：提出多语言提示策略MLPrompt，将模型难遵循的易错规则自动翻译成另一种语言以吸引更多注意力，还引入结合MLPrompt和自动检查机制的框架用于结构化数据生成。效果：在公共数据集多任务实验中，MLPrompt优于思维链等先进提示方法，通过文本到混合整数规划实例和文本到SQL的案例，展示了其对结构化数据合成的生成能力。
            arXiv:2409.11056v2 Announce Type: replace 
Abstract: With the advent of Large Language Models (LLMs), generating rule-based data for real-world applications has become more accessible. Due to the inherent ambiguity of natural language and the complexity of rule sets, especially in long contexts, LLMs often struggle to follow all specified rules, frequently omitting at least one. To enhance the reasoning and understanding of LLMs on long and complex contexts, we propose a novel prompting strategy Multi-Lingual Prompt, namely MLPrompt, which automatically translates the error-prone rule that an LLM struggles to follow into another language, thus drawing greater attention to it. Experimental results on public datasets across various tasks have shown MLPrompt can outperform state-of-the-art prompting methods such as Chain of Thought, Tree of Thought, and Self-Consistency. Additionally, we introduce a framework integrating MLPrompt with an auto-checking mechanism for structured data generation, with a specific case study in text-to-MIP instances. Further, we extend the proposed framework for text-to-SQL to demonstrate its generation ability towards structured data synthesis.
        ]]></description>
    </item>
    <item>
        <title>A-MEM: Agentic Memory for LLM Agents</title>
        <link>https://arxiv.org/abs/2502.12110</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.12110v5</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wujiang Xu, Kai Mei, Hang Gao, Juntao Tan, Zujie Liang, Yongfeng Zhang</dc:creator>
        <description><![CDATA[
            背景：大语言模型（LLM）智能体执行复杂任务需记忆系统，但现有系统缺乏复杂记忆组织且适应性有限。方法：提出一种新的智能记忆系统，借鉴Zettelkasten方法，通过动态索引和链接创建互联知识网络，添加新记忆时生成含多种结构化属性的笔记，分析历史记忆建立关联，实现记忆进化。效果：在六个基础模型上的实验显示，较现有SOTA基线有显著提升。
            arXiv:2502.12110v5 Announce Type: replace 
Abstract: While large language model (LLM) agents can effectively use external tools for complex real-world tasks, they require memory systems to leverage historical experiences. Current memory systems enable basic storage and retrieval but lack sophisticated memory organization, despite recent attempts to incorporate graph databases. Moreover, these systems' fixed operations and structures limit their adaptability across diverse tasks. To address this limitation, this paper proposes a novel agentic memory system for LLM agents that can dynamically organize memories in an agentic way. Following the basic principles of the Zettelkasten method, we designed our memory system to create interconnected knowledge networks through dynamic indexing and linking. When a new memory is added, we generate a comprehensive note containing multiple structured attributes, including contextual descriptions, keywords, and tags. The system then analyzes historical memories to identify relevant connections, establishing links where meaningful similarities exist. Additionally, this process enables memory evolution - as new memories are integrated, they can trigger updates to the contextual representations and attributes of existing historical memories, allowing the memory network to continuously refine its understanding. Our approach combines the structured organization principles of Zettelkasten with the flexibility of agent-driven decision making, allowing for more adaptive and context-aware memory management. Empirical experiments on six foundation models show superior improvement against existing SOTA baselines. The source code for evaluating performance is available at https://github.com/WujiangXu/AgenticMemory, while the source code of agentic memory system is available at https://github.com/agiresearch/A-mem.
        ]]></description>
    </item>
    <item>
        <title>Project Alexandria: Towards Freeing Scientific Knowledge from Copyright Burdens via LLMs</title>
        <link>https://arxiv.org/abs/2502.19413</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.19413v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Christoph Schuhmann, Gollam Rabby, Ameya Prabhu, Tawsif Ahmed, Andreas Hochlehnert, Huu Nguyen, Nick Akinci, Ludwig Schmidt, Robert Kaczmarczyk, S\"oren Auer, Jenia Jitsev, Matthias Bethge</dc:creator>
        <description><![CDATA[
            背景：付费墙、许可和版权规则限制科学知识传播与复用，现有文本嵌入等方法有缺陷。方法：提出用大语言模型将学术文档转换为知识单元，以结构化数据捕获实体、属性和关系，不包含风格内容。效果：基于德美法律分析，知识单元为分享受版权保护的研究文本知识提供法律框架；跨四个研究领域，通过对原版权文本事实的多项选择题测试，保留约95%事实知识，还开源转换工具。
            arXiv:2502.19413v2 Announce Type: replace 
Abstract: Paywalls, licenses and copyright rules often restrict the broad dissemination and reuse of scientific knowledge. We take the position that it is both legally and technically feasible to extract the scientific knowledge in scholarly texts. Current methods, like text embeddings, fail to reliably preserve factual content, and simple paraphrasing may not be legally sound. We propose a new idea for the community to adopt: convert scholarly documents into knowledge preserving, but style agnostic representations we term Knowledge Units using LLMs. These units use structured data capturing entities, attributes and relationships without stylistic content. We provide evidence that Knowledge Units (1) form a legally defensible framework for sharing knowledge from copyrighted research texts, based on legal analyses of German copyright law and U.S. Fair Use doctrine, and (2) preserve most (~95\%) factual knowledge from original text, measured by MCQ performance on facts from the original copyrighted text across four research domains. Freeing scientific knowledge from copyright promises transformative benefits for scientific research and education by allowing language models to reuse important facts from copyrighted text. To support this, we share open-source tools for converting research documents into Knowledge Units. Overall, our work posits the feasibility of democratizing access to scientific knowledge while respecting copyright.
        ]]></description>
    </item>
    <item>
        <title>ReaRAG: Knowledge-guided Reasoning Enhances Factuality of Large Reasoning Models with Iterative Retrieval Augmented Generation</title>
        <link>https://arxiv.org/abs/2503.21729</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.21729v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhicheng Lee, Shulin Cao, Jinxin Liu, Jiajie Zhang, Weichuan Liu, Xiaoyin Che, Lei Hou, Juanzi Li</dc:creator>
        <description><![CDATA[
            大推理模型（LRMs）推理能力强，但主要依赖参数知识，事实准确性受限。现有基于强化学习的LRMs虽有检索能力，但存在过度思考和推理缺乏鲁棒性问题。为此提出ReaRAG，包含推理链长度有上限的数据构建框架。先利用LRM生成思考内容，从预定义动作空间选动作，搜索动作会在RAG引擎查询，结果作为观测指导后续推理，直至选择结束动作。该方法在多跳问答上优于现有基线，还能识别错误、优化推理路径，增强了LRMs事实性和RAG推理能力。
            arXiv:2503.21729v2 Announce Type: replace 
Abstract: Large Reasoning Models (LRMs) exhibit remarkable reasoning abilities but rely primarily on parametric knowledge, limiting factual accuracy. While recent works equip reinforcement learning (RL)-based LRMs with retrieval capabilities, they suffer from overthinking and lack robustness in reasoning, reducing their effectiveness in question answering (QA) tasks. To address this, we propose ReaRAG, a factuality-enhanced reasoning model that explores diverse queries without excessive iterations. Our solution includes a novel data construction framework with an upper bound on the reasoning chain length. Specifically, we first leverage an LRM to generate deliberate thinking, then select an action from a predefined action space (Search and Finish). For Search action, a query is executed against the RAG engine, where the result is returned as observation to guide reasoning steps later. This process iterates until a Finish action is chosen. Benefiting from ReaRAG's strong reasoning capabilities, our approach outperforms existing baselines on multi-hop QA. Further analysis highlights its strong reflective ability to recognize errors and refine its reasoning trajectory. Our study enhances LRMs' factuality while effectively integrating robust reasoning for Retrieval-Augmented Generation (RAG).
        ]]></description>
    </item>
    <item>
        <title>Multimodal machine learning with large language embedding model for polymer property prediction</title>
        <link>https://arxiv.org/abs/2503.22962</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.22962v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tianren Zhang, Dai-Bei Yang</dc:creator>
        <description><![CDATA[
            背景：当代大语言模型在材料科学等领域展现强大能力，为利用其领域知识，需解决聚合物性质预测问题。方法：提出多模态架构PolyLLMem，融合Llama 3生成的文本嵌入和Uni - Mol的分子结构嵌入，在预测任务中加入低秩自适应层，基于有限聚合物数据集优化嵌入。效果：该模型能在训练数据稀缺情况下准确预测多种聚合物性质，性能与基于图和基于Transformer的模型相当，部分情况更优，证明了多模态融合在克服数据稀缺和加速材料发现上的有效性。
            arXiv:2503.22962v2 Announce Type: replace 
Abstract: Contemporary large language models (LLMs), such as GPT-4 and Llama, have harnessed extensive computational power and diverse text corpora to achieve remarkable proficiency in interpreting and generating domain-specific content, including materials science. To leverage the domain knowledge embedded within these models, we propose a simple yet effective multimodal architecture, PolyLLMem, which integrates text embeddings generated by Llama 3 with molecular structure embeddings derived from Uni-Mol, for polymer properties prediction tasks. In our model, Low-rank adaptation (LoRA) layers were also incorporated during the property prediction tasks to refine the embeddings based on our limited polymer dataset, thereby enhancing their chemical relevance for polymer SMILES representation. This balanced fusion of fine-tuned textual and structural information enables PolyLLMem to accurately predict a variety of polymer properties despite the scarcity of training data. Its performance is comparable to, and in some cases exceeds, that of graph-based models, as well as transformer-based models that typically require pretraining on millions of polymer samples. These findings demonstrate that LLM, such as Llama, can effectively capture chemical information encoded in polymer PSMILES, and underscore the efficacy of multimodal fusion of LLM embeddings and molecular structure embeddings in overcoming data scarcity and accelerating the discovery of advanced polymeric materials.
        ]]></description>
    </item>
    <item>
        <title>Diffusion Transformers for Tabular Data Time Series Generation</title>
        <link>https://arxiv.org/abs/2504.07566</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.07566v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Fabrizio Garuti, Enver Sangineto, Simone Luetto, Lorenzo Forni, Rita Cucchiara</dc:creator>
        <description><![CDATA[
            背景：表格数据生成受关注，但生成表格数据时间序列因需同时解决数据异构性和序列长度可变等问题，仍是待探索领域。方法：提出基于扩散变压器（DiTs）的表格数据序列生成方法，借鉴其在图像和视频生成中的成功经验，扩展该框架以处理异构数据和可变长度序列。效果：在六个数据集上的大量实验表明，该方法大幅超越先前工作。 
            arXiv:2504.07566v2 Announce Type: replace 
Abstract: Tabular data generation has recently attracted a growing interest due to its different application scenarios. However, generating time series of tabular data, where each element of the series depends on the others, remains a largely unexplored domain. This gap is probably due to the difficulty of jointly solving different problems, the main of which are the heterogeneity of tabular data (a problem common to non-time-dependent approaches) and the variable length of a time series. In this paper, we propose a Diffusion Transformers (DiTs) based approach for tabular data series generation. Inspired by the recent success of DiTs in image and video generation, we extend this framework to deal with heterogeneous data and variable-length sequences. Using extensive experiments on six datasets, we show that the proposed approach outperforms previous work by a large margin.
        ]]></description>
    </item>
    <item>
        <title>ProteinGPT: Multimodal LLM for Protein Property Prediction and Structure Understanding</title>
        <link>https://arxiv.org/abs/2408.11363</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2408.11363v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yijia Xiao, Edward Sun, Yiqiao Jin, Qifan Wang, Wei Wang</dc:creator>
        <description><![CDATA[
            传统蛋白质研究分析结构和功能复杂耗时。为此提出ProteinGPT，这是用于蛋白质的多模态大模型。方法上，它集成蛋白质序列和结构编码器与线性投影层，确保精确表示适配，利用大语言模型生成准确响应。构建含132,092个蛋白质的大规模数据集，用GPT - 4o优化指令微调。实验表明，它能有效回答蛋白质相关问题，在语义和词汇指标上表现出色，显著优于基线模型和通用大模型。
            arXiv:2408.11363v2 Announce Type: replace-cross 
Abstract: Understanding biological processes, drug development, and biotechnological advancements requires a detailed analysis of protein structures and functions, a task that is inherently complex and time-consuming in traditional protein research. To streamline this process, we introduce ProteinGPT, a state-of-the-art multimodal large language model for proteins that enables users to upload protein sequences and/or structures for comprehensive analysis and responsive inquiries. ProteinGPT integrates protein sequence and structure encoders with linear projection layers to ensure precise representation adaptation and leverages a large language model (LLM) to generate accurate, contextually relevant responses. To train ProteinGPT, we constructed a large-scale dataset of 132,092 proteins, each annotated with 20-30 property tags and 5-10 QA pairs per protein, and optimized the instruction-tuning process using GPT-4o. Experiments demonstrate that ProteinGPT effectively generates informative responses to protein-related questions, achieving high performance on both semantic and lexical metrics and significantly outperforming baseline models and general-purpose LLMs in understanding and responding to protein-related queries. Our code and data are available at https://github.com/ProteinGPT/ProteinGPT.
        ]]></description>
    </item>
    <item>
        <title>Large Language Model-Based Knowledge Graph System Construction for Sustainable Development Goals: An AI-Based Speculative Design Perspective</title>
        <link>https://arxiv.org/abs/2504.12309</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.12309v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yi-De Lin, Guan-Ze Liao</dc:creator>
        <description><![CDATA[
            背景：2030年临近，可持续发展目标（SDGs）进展滞后，需创新加速策略。方法：该研究利用官方SDG文本、关键词数据集和TED演讲转录，采用AI推测设计、大语言模型和检索增强生成技术，构建知识图谱系统分析SDG相互联系、发现新目标并在线可视化。效果：热图分析显示目标10和16关联强、目标6覆盖少；知识图谱中模拟对话揭示新中心节点；提出6个围绕公平、恢复力和技术驱动包容的潜在新目标，为政策制定者提供新见解。
            arXiv:2504.12309v2 Announce Type: replace-cross 
Abstract: From 2000 to 2015, the UN's Millennium Development Goals guided global priorities. The subsequent Sustainable Development Goals (SDGs) adopted a more dynamic approach, with annual indicator updates. As 2030 nears and progress lags, innovative acceleration strategies are critical. This study develops an AI-powered knowledge graph system to analyze SDG interconnections, discover potential new goals, and visualize them online. Using official SDG texts, Elsevier's keyword dataset, and 1,127 TED Talk transcripts (2020.01-2024.04), a pilot on 269 talks from 2023 applies AI-speculative design, large language models, and retrieval-augmented generation. Key findings include: (1) Heatmap analysis reveals strong associations between Goal 10 and Goal 16, and minimal coverage of Goal 6. (2) In the knowledge graph, simulated dialogue over time reveals new central nodes, showing how richer data supports divergent thinking and goal clarity. (3) Six potential new goals are proposed, centered on equity, resilience, and technology-driven inclusion. This speculative-AI framework offers fresh insights for policymakers and lays groundwork for future multimodal and cross-system SDG applications.
        ]]></description>
    </item>
    <item>
        <title>Towards Cardiac MRI Foundation Models: Comprehensive Visual-Tabular Representations for Whole-Heart Assessment and Beyond</title>
        <link>https://arxiv.org/abs/2504.13037</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.13037v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yundi Zhang, Paul Hager, Che Liu, Suprosanna Shit, Chen Chen, Daniel Rueckert, Jiazhen Pan</dc:creator>
        <description><![CDATA[
            背景：心脏磁共振成像（CMR）评估心脏健康时未考虑患者层面健康因素，现有多模态方法存在局限。方法：提出ViTa模型，利用42000名英国生物银行参与者数据，整合3D+T电影堆栈成像数据与详细表格化患者层面因素，学习共享潜在表征。效果：支持多种下游任务，能全面表征心脏并精准解读个体疾病风险，超越传统特定任务模型，有望提升心脏分析临床实用性和可扩展性。
            arXiv:2504.13037v2 Announce Type: replace-cross 
Abstract: Cardiac magnetic resonance imaging is the gold standard for non-invasive cardiac assessment, offering rich spatio-temporal views of the cardiac anatomy and physiology. Patient-level health factors, such as demographics, metabolic, and lifestyle, are known to substantially influence cardiovascular health and disease risk, yet remain uncaptured by CMR alone. To holistically understand cardiac health and to enable the best possible interpretation of an individual's disease risk, CMR and patient-level factors must be jointly exploited within an integrated framework. Recent multi-modal approaches have begun to bridge this gap, yet they often rely on limited spatio-temporal data and focus on isolated clinical tasks, thereby hindering the development of a comprehensive representation for cardiac health evaluation. To overcome these limitations, we introduce ViTa, a step toward foundation models that delivers a comprehensive representation of the heart and a precise interpretation of individual disease risk. Leveraging data from 42,000 UK Biobank participants, ViTa integrates 3D+T cine stacks from short-axis and long-axis views, enabling a complete capture of the cardiac cycle. These imaging data are then fused with detailed tabular patient-level factors, enabling context-aware insights. This multi-modal paradigm supports a wide spectrum of downstream tasks, including cardiac phenotype and physiological feature prediction, segmentation, and classification of cardiac and metabolic diseases within a single unified framework. By learning a shared latent representation that bridges rich imaging features and patient context, ViTa moves beyond traditional, task-specific models toward a universal, patient-specific understanding of cardiac health, highlighting its potential to advance clinical utility and scalability in cardiac analysis.
        ]]></description>
    </item>
    <item>
        <title>MusFlow: Multimodal Music Generation via Conditional Flow Matching</title>
        <link>https://arxiv.org/abs/2504.13535</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.13535v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiahao Song, Yuzhao Wang</dc:creator>
        <description><![CDATA[
            背景：音乐生成虽能依据文本描述创作音乐，但普通用户缺乏专业知识和时间写准确提示词，限制了实际应用。方法：提出MusFlow模型，用多个多层感知器将多模态条件信息对齐到音频的CLAP嵌入空间，通过条件流匹配在预训练VAE潜在空间中重构压缩的梅尔频谱图；构建新的多模态音乐数据集MMusSet。效果：实验表明，无论输入是单模态还是多模态，MusFlow都能生成高质量音乐片段。
            arXiv:2504.13535v1 Announce Type: new 
Abstract: Music generation aims to create music segments that align with human aesthetics based on diverse conditional information. Despite advancements in generating music from specific textual descriptions (e.g., style, genre, instruments), the practical application is still hindered by ordinary users' limited expertise or time to write accurate prompts. To bridge this application gap, this paper introduces MusFlow, a novel multimodal music generation model using Conditional Flow Matching. We employ multiple Multi-Layer Perceptrons (MLPs) to align multimodal conditional information into the audio's CLAP embedding space. Conditional flow matching is trained to reconstruct the compressed Mel-spectrogram in the pretrained VAE latent space guided by aligned feature embedding. MusFlow can generate music from images, story texts, and music captions. To collect data for model training, inspired by multi-agent collaboration, we construct an intelligent data annotation workflow centered around a fine-tuned Qwen2-VL model. Using this workflow, we build a new multimodal music dataset, MMusSet, with each sample containing a quadruple of image, story text, music caption, and music piece. We conduct four sets of experiments: image-to-music, story-to-music, caption-to-music, and multimodal music generation. Experimental results demonstrate that MusFlow can generate high-quality music pieces whether the input conditions are unimodal or multimodal. We hope this work can advance the application of music generation in multimedia field, making music creation more accessible. Our generated samples, code and dataset are available at musflow.github.io.
        ]]></description>
    </item>
    <item>
        <title>Collective Learning Mechanism based Optimal Transport Generative Adversarial Network for Non-parallel Voice Conversion</title>
        <link>https://arxiv.org/abs/2504.13791</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.13791v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sandipan Dhar, Md. Tousin Akhter, Nanda Dulal Jana, Swagatam Das</dc:creator>
        <description><![CDATA[
            背景：生成对抗网络（GAN）在语音合成领域取得进展，但基于GAN的语音转换（VC）模型生成语音自然度与真实语音有差距，单生成器单判别器学习方式优化目标数据分布效果不佳。方法：提出基于集体学习机制的最优传输GAN（CLOT - GAN）模型，结合多个判别器（DCNN、ViT和conformer），通过集体学习机制理解频谱图共振峰分布，引入最优传输（OT）损失缩小源数据与目标数据分布差距。效果：在VCC 2018等数据集上实验表明，CLOT - GAN - VC模型在主客观评估中优于现有VC模型。
            arXiv:2504.13791v1 Announce Type: new 
Abstract: After demonstrating significant success in image synthesis, Generative Adversarial Network (GAN) models have likewise made significant progress in the field of speech synthesis, leveraging their capacity to adapt the precise distribution of target data through adversarial learning processes. Notably, in the realm of State-Of-The-Art (SOTA) GAN-based Voice Conversion (VC) models, there exists a substantial disparity in naturalness between real and GAN-generated speech samples. Furthermore, while many GAN models currently operate on a single generator discriminator learning approach, optimizing target data distribution is more effectively achievable through a single generator multi-discriminator learning scheme. Hence, this study introduces a novel GAN model named Collective Learning Mechanism-based Optimal Transport GAN (CLOT-GAN) model, incorporating multiple discriminators, including the Deep Convolutional Neural Network (DCNN) model, Vision Transformer (ViT), and conformer. The objective of integrating various discriminators lies in their ability to comprehend the formant distribution of mel-spectrograms, facilitated by a collective learning mechanism. Simultaneously, the inclusion of Optimal Transport (OT) loss aims to precisely bridge the gap between the source and target data distribution, employing the principles of OT theory. The experimental validation on VCC 2018, VCTK, and CMU-Arctic datasets confirms that the CLOT-GAN-VC model outperforms existing VC models in objective and subjective assessments.
        ]]></description>
    </item>
    <item>
        <title>EmoVoice: LLM-based Emotional Text-To-Speech Model with Freestyle Text Prompting</title>
        <link>https://arxiv.org/abs/2504.12867</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.12867v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Mon, 21 Apr 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Guanrou Yang, Chen Yang, Qian Chen, Ziyang Ma, Wenxi Chen, Wen Wang, Tianrui Wang, Yifan Yang, Zhikang Niu, Wenrui Liu, Fan Yu, Zhihao Du, Zhifu Gao, ShiLiang Zhang, Xie Chen</dc:creator>
        <description><![CDATA[
            背景：文本转语音（TTS）模型虽有进展，但在控制生成语音情感表达方面仍面临挑战。方法：提出EmoVoice模型，利用大语言模型（LLMs）实现细粒度自由式自然语言情感控制，采用音素增强变体设计使模型并行输出音素和音频令牌；引入高质量英语情感数据集EmoVoice - DB。效果：仅用合成训练数据就在英语EmoVoice - DB测试集上，用内部数据在中文Secap测试集上达到了先进水平，还对现有情感评估指标进行了研究。
            arXiv:2504.12867v2 Announce Type: replace 
Abstract: Human speech goes beyond the mere transfer of information; it is a profound exchange of emotions and a connection between individuals. While Text-to-Speech (TTS) models have made huge progress, they still face challenges in controlling the emotional expression in the generated speech. In this work, we propose EmoVoice, a novel emotion-controllable TTS model that exploits large language models (LLMs) to enable fine-grained freestyle natural language emotion control, and a phoneme boost variant design that makes the model output phoneme tokens and audio tokens in parallel to enhance content consistency, inspired by chain-of-thought (CoT) and chain-of-modality (CoM) techniques. Besides, we introduce EmoVoice-DB, a high-quality 40-hour English emotion dataset featuring expressive speech and fine-grained emotion labels with natural language descriptions. EmoVoice achieves state-of-the-art performance on the English EmoVoice-DB test set using only synthetic training data, and on the Chinese Secap test set using our in-house data. We further investigate the reliability of existing emotion evaluation metrics and their alignment with human perceptual preferences, and explore using SOTA multimodal LLMs GPT-4o-audio and Gemini to assess emotional speech. Demo samples are available at https://anonymous.4open.science/r/EmoVoice-DF55. Dataset, code, and checkpoints will be released.
        ]]></description>
    </item>
</channel>
</rss>