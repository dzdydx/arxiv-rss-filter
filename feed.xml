<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
<channel>
    <title>arXiv Paper Filter</title>
    <link>https://github.com/None/arxiv_filter</link>
    <description>根据研究兴趣筛选的arXiv论文</description>
    <atom:link href="https://raw.githubusercontent.com/None/arxiv_filter/main/feed.xml" rel="self" type="application/rss+xml" />
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>zh-CN</language>
    <lastBuildDate>Tue, 20 May 2025 12:15:57 +0800</lastBuildDate>
    <managingEditor>None@github.com</managingEditor>
    <pubDate>Tue, 20 May 2025 12:15:57 +0800</pubDate>
    <skipDays>
        <day>Saturday</day>
        <day>Sunday</day>
    </skipDays>

    <item>
        <title>MedGUIDE: Benchmarking Clinical Decision-Making in Large Language Models</title>
        <link>https://arxiv.org/abs/2505.11613</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.11613v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiaomin Li, Mingye Gao, Yuexing Hao, Taoran Li, Guangya Wan, Zihan Wang, Yijun Wang</dc:creator>
        <description><![CDATA[
            背景：临床指南多为决策树结构，大语言模型能否可靠遵循此类结构化协议尚不明确。方法：提出MedGUIDE基准，基于55个NCCN决策树构建，用大模型生成临床场景创建选择题，经两阶段筛选得7747个高质量样本，评估25个大模型，还测试通过上下文纳入指南或继续预训练提升性能。效果：发现即使特定领域大模型在需遵循结构化指南任务上表现欠佳，凸显MedGUIDE评估大模型在临床环境安全性的重要性。
            arXiv:2505.11613v1 Announce Type: new 
Abstract: Clinical guidelines, typically structured as decision trees, are central to evidence-based medical practice and critical for ensuring safe and accurate diagnostic decision-making. However, it remains unclear whether Large Language Models (LLMs) can reliably follow such structured protocols. In this work, we introduce MedGUIDE, a new benchmark for evaluating LLMs on their ability to make guideline-consistent clinical decisions. MedGUIDE is constructed from 55 curated NCCN decision trees across 17 cancer types and uses clinical scenarios generated by LLMs to create a large pool of multiple-choice diagnostic questions. We apply a two-stage quality selection process, combining expert-labeled reward models and LLM-as-a-judge ensembles across ten clinical and linguistic criteria, to select 7,747 high-quality samples. We evaluate 25 LLMs spanning general-purpose, open-source, and medically specialized models, and find that even domain-specific LLMs often underperform on tasks requiring structured guideline adherence. We also test whether performance can be improved via in-context guideline inclusion or continued pretraining. Our findings underscore the importance of MedGUIDE in assessing whether LLMs can operate safely within the procedural frameworks expected in real-world clinical settings.
        ]]></description>
    </item>
    <item>
        <title>Nearest Neighbor Multivariate Time Series Forecasting</title>
        <link>https://arxiv.org/abs/2505.11625</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.11625v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Huiliang Zhang, Ping Nie, Lijun Sun, Benoit Boulet</dc:creator>
        <description><![CDATA[
            背景：多元时间序列（MTS）预测应用广泛，现有时空图神经网络（STGNNs）因计算复杂度只能用有限长度输入数据，且缺乏识别相似模式能力。方法：提出简单有效的k近邻MTS预测（kNN - MTS）框架，通过近邻检索机制预测，还设计了混合时空编码器（HSTEncoder）。效果：实验显示，kNN - MTS在多个真实数据集上显著提升预测性能，兼具可解释性和高效性，有更好应用前景。
            arXiv:2505.11625v1 Announce Type: new 
Abstract: Multivariate time series (MTS) forecasting has a wide range of applications in both industry and academia. Recently, spatial-temporal graph neural networks (STGNNs) have gained popularity as MTS forecasting methods. However, current STGNNs can only use the finite length of MTS input data due to the computational complexity. Moreover, they lack the ability to identify similar patterns throughout the entire dataset and struggle with data that exhibit sparsely and discontinuously distributed correlations among variables over an extensive historical period, resulting in only marginal improvements. In this article, we introduce a simple yet effective k-nearest neighbor MTS forecasting ( kNN-MTS) framework, which forecasts with a nearest neighbor retrieval mechanism over a large datastore of cached series, using representations from the MTS model for similarity search. This approach requires no additional training and scales to give the MTS model direct access to the whole dataset at test time, resulting in a highly expressive model that consistently improves performance, and has the ability to extract sparse distributed but similar patterns spanning over multivariables from the entire dataset. Furthermore, a hybrid spatial-temporal encoder (HSTEncoder) is designed for kNN-MTS which can capture both long-term temporal and short-term spatial-temporal dependencies and is shown to provide accurate representation for kNN-MTSfor better forecasting. Experimental results on several real-world datasets show a significant improvement in the forecasting performance of kNN-MTS. The quantitative analysis also illustrates the interpretability and efficiency of kNN-MTS, showing better application prospects and opening up a new path for efficiently using the large dataset in MTS models.
        ]]></description>
    </item>
    <item>
        <title>THELMA: Task Based Holistic Evaluation of Large Language Model Applications-RAG Question Answering</title>
        <link>https://arxiv.org/abs/2505.11626</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.11626v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Udita Patel, Rutu Mulkar, Jay Roberts, Cibi Chakravarthy Senthilkumar, Sujay Gandhi, Xiaofei Zheng, Naumaan Nayyar, Rafael Castrillo</dc:creator>
        <description><![CDATA[
            背景：现有缺乏无参考的RAG问答应用评估框架。方法：提出THELMA框架，包含六个相互依赖的指标，可在无需标注源或参考回复的情况下，对基于RAG的问答应用进行整体、细粒度评估，还能帮助开发者和应用所有者评估、监控和改进端到端的RAG问答管道。效果：可通过分析指标间的相互作用，识别问答应用中需改进的特定RAG组件。
            arXiv:2505.11626v1 Announce Type: new 
Abstract: We propose THELMA (Task Based Holistic Evaluation of Large Language Model Applications), a reference free framework for RAG (Retrieval Augmented generation) based question answering (QA) applications. THELMA consist of six interdependent metrics specifically designed for holistic, fine grained evaluation of RAG QA applications. THELMA framework helps developers and application owners evaluate, monitor and improve end to end RAG QA pipelines without requiring labelled sources or reference responses.We also present our findings on the interplay of the proposed THELMA metrics, which can be interpreted to identify the specific RAG component needing improvement in QA applications.
        ]]></description>
    </item>
    <item>
        <title>Ambiguity Resolution in Text-to-Structured Data Mapping</title>
        <link>https://arxiv.org/abs/2505.11679</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.11679v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhibo Hu, Chen Wang, Yanfeng Shu, Hye-Young Paik, Liming Zhu</dc:creator>
        <description><![CDATA[
            背景：自然语言的歧义性是大语言模型实现准确文本到结构化数据映射的重大障碍，影响相关任务表现。方法：该论文采取不同策略，刻画歧义文本在潜在空间的表征差异，利用该差异在映射到结构化数据前识别歧义；设计新的距离度量方法，通过稀疏自编码器下各概念梯度值积分的路径核计算；基于缺失概念预测提出新框架。效果：有望提升大语言模型在歧义代理工具调用任务上的表现。
            arXiv:2505.11679v1 Announce Type: new 
Abstract: Ambiguity in natural language is a significant obstacle for achieving accurate text to structured data mapping through large language models (LLMs), which affects the performance of tasks such as mapping text to agentic tool calling and text-to-SQL queries. Existing methods of ambiguity handling either exploit ReACT framework to produce the correct mapping through trial and error, or supervised fine tuning to guide models to produce a biased mapping to improve certain tasks. In this paper, we adopt a different approach that characterizes the representation difference of ambiguous text in the latent space and leverage the difference to identify ambiguity before mapping them to structured data. To detect ambiguity of a sentence, we focused on the relationship between ambiguous questions and their interpretations and what cause the LLM ignore multiple interpretations. Different to the distance calculated by dense embedding vectors, we utilize the observation that ambiguity is caused by concept missing in latent space of LLM to design a new distance measurement, computed through the path kernel by the integral of gradient values for each concepts from sparse-autoencoder (SAE) under each state. We identify patterns to distinguish ambiguous questions with this measurement. Based on our observation, We propose a new framework to improve the performance of LLMs on ambiguous agentic tool calling through missing concepts prediction.
        ]]></description>
    </item>
    <item>
        <title>Disambiguating Reference in Visually Grounded Dialogues through Joint Modeling of Textual and Multimodal Semantic Structures</title>
        <link>https://arxiv.org/abs/2505.11726</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.11726v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Shun Inadumi, Nobuhiro Ueda, Koichiro Yoshino</dc:creator>
        <description><![CDATA[
            背景：多模态指称消解需理解提及内容与现实对象语义关系，实际应用中需整合文本和多模态指称消解处理对话歧义。方法：提出统一文本和多模态指称消解的框架，将提及嵌入映射到对象嵌入并基于相似度选择。效果：实验表明学习文本指称消解对多模态指称消解有积极影响，带共指消解的模型在代词短语定位上优于MDETR和GLIP，定性分析显示纳入文本指称关系可降低视觉对话歧义。
            arXiv:2505.11726v1 Announce Type: new 
Abstract: Multimodal reference resolution, including phrase grounding, aims to understand the semantic relations between mentions and real-world objects. Phrase grounding between images and their captions is a well-established task. In contrast, for real-world applications, it is essential to integrate textual and multimodal reference resolution to unravel the reference relations within dialogue, especially in handling ambiguities caused by pronouns and ellipses. This paper presents a framework that unifies textual and multimodal reference resolution by mapping mention embeddings to object embeddings and selecting mentions or objects based on their similarity. Our experiments show that learning textual reference resolution, such as coreference resolution and predicate-argument structure analysis, positively affects performance in multimodal reference resolution. In particular, our model with coreference resolution performs better in pronoun phrase grounding than representative models for this task, MDETR and GLIP. Our qualitative analysis demonstrates that incorporating textual reference relations strengthens the confidence scores between mentions, including pronouns and predicates, and objects, which can reduce the ambiguities that arise in visually grounded dialogues.
        ]]></description>
    </item>
    <item>
        <title>BELLE: A Bi-Level Multi-Agent Reasoning Framework for Multi-Hop Question Answering</title>
        <link>https://arxiv.org/abs/2505.11811</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.11811v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Taolin Zhang, Dongyang Li, Qizhou Chen, Chengyu Wang, Xiaofeng He</dc:creator>
        <description><![CDATA[
            多跳问答需找相关段落并逐步推理解答复杂问题。以往研究未区分问题类型。本文深入分析多跳问答基准，将问题分为四类，评估五种前沿方法，发现不同问题对不同方法敏感度不同。为此提出BELLE框架，聚焦问题类型与方法对应关系，将各方法视为‘算子’。框架分两级，一级多智能体辩论获执行方案，二级用快慢辩论者监控观点变化。实验表明，BELLE在多数据集上显著优于基线，在复杂场景成本效益更高。
            arXiv:2505.11811v1 Announce Type: new 
Abstract: Multi-hop question answering (QA) involves finding multiple relevant passages and performing step-by-step reasoning to answer complex questions. Previous works on multi-hop QA employ specific methods from different modeling perspectives based on large language models (LLMs), regardless of the question types. In this paper, we first conduct an in-depth analysis of public multi-hop QA benchmarks, dividing the questions into four types and evaluating five types of cutting-edge methods for multi-hop QA: Chain-of-Thought (CoT), Single-step, Iterative-step, Sub-step, and Adaptive-step. We find that different types of multi-hop questions have varying degrees of sensitivity to different types of methods. Thus, we propose a Bi-levEL muLti-agEnt reasoning (BELLE) framework to address multi-hop QA by specifically focusing on the correspondence between question types and methods, where each type of method is regarded as an ''operator'' by prompting LLMs differently. The first level of BELLE includes multiple agents that debate to obtain an executive plan of combined ''operators'' to address the multi-hop QA task comprehensively. During the debate, in addition to the basic roles of affirmative debater, negative debater, and judge, at the second level, we further leverage fast and slow debaters to monitor whether changes in viewpoints are reasonable. Extensive experiments demonstrate that BELLE significantly outperforms strong baselines in various datasets. Additionally, the model consumption of BELLE is higher cost-effectiveness than that of single models in more complex multi-hop QA scenarios.
        ]]></description>
    </item>
    <item>
        <title>Reinforcing Multi-Turn Reasoning in LLM Agents via Turn-Level Credit Assignment</title>
        <link>https://arxiv.org/abs/2505.11821</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.11821v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Siliang Zeng, Quan Wei, William Brown, Oana Frunza, Yuriy Nevmyvaka, Mingyi Hong</dc:creator>
        <description><![CDATA[
            背景：现有方法在多轮推理任务中对多决策步骤进行回合级功劳分配时存在困难，限制了大语言模型（LLM）智能体的多轮推理能力。方法：引入细粒度回合级优势估计策略，使多轮智能体交互中功劳分配更精确，且该策略可融入多种强化学习算法。效果：在多轮推理和基于搜索的工具使用任务实验中，该方法工具执行成功率达100%，精确答案匹配准确率达50%，显著优于仅20 - 30%匹配准确率且无法调用工具的基线方法。
            arXiv:2505.11821v1 Announce Type: new 
Abstract: This paper investigates approaches to enhance the reasoning capabilities of Large Language Model (LLM) agents using Reinforcement Learning (RL). Specifically, we focus on multi-turn tool-use scenarios, which can be naturally modeled as Markov Decision Processes (MDPs). While existing approaches often train multi-turn LLM agents with trajectory-level advantage estimation in bandit settings, they struggle with turn-level credit assignment across multiple decision steps, limiting their performance on multi-turn reasoning tasks. To address this, we introduce a fine-grained turn-level advantage estimation strategy to enable more precise credit assignment in multi-turn agent interactions. The strategy is general and can be incorporated into various RL algorithms such as Group Relative Preference Optimization (GRPO). Our experimental evaluation on multi-turn reasoning and search-based tool-use tasks with GRPO implementations highlights the effectiveness of the MDP framework and the turn-level credit assignment in advancing the multi-turn reasoning capabilities of LLM agents in complex decision-making settings. Our method achieves 100% success in tool execution and 50% accuracy in exact answer matching, significantly outperforming baselines, which fail to invoke tools and achieve only 20-30% exact match accuracy.
        ]]></description>
    </item>
    <item>
        <title>Search-Based Correction of Reasoning Chains for Language Models</title>
        <link>https://arxiv.org/abs/2505.11824</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.11824v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Minsu Kim, Jean-Pierre Falet, Oliver E. Richardson, Xiaoyin Chen, Moksh Jain, Sungjin Ahn, Sungsoo Ahn, Yoshua Bengio</dc:creator>
        <description><![CDATA[
            背景：思维链推理提升了语言模型能力与透明度，但推理链存在不准确陈述影响性能和可信度。方法：提出自校正框架，为思维链各推理步骤添加表示真实性的潜变量，引入离散搜索算法Search Corrector探索扩展空间，利用语言模型联合似然作为代理奖励进行推理，还可基于此为真实性提供伪标签对Amortized Corrector进行微调。效果：Search Corrector能可靠识别基准测试错误，Amortized Corrector零样本准确率相当，最终答案准确率最高提升25%。
            arXiv:2505.11824v1 Announce Type: new 
Abstract: Chain-of-Thought (CoT) reasoning has advanced the capabilities and transparency of language models (LMs); however, reasoning chains can contain inaccurate statements that reduce performance and trustworthiness. To address this, we introduce a new self-correction framework that augments each reasoning step in a CoT with a latent variable indicating its veracity, enabling modeling of all possible truth assignments rather than assuming correctness throughout. To efficiently explore this expanded space, we introduce Search Corrector, a discrete search algorithm over boolean-valued veracity assignments. It efficiently performs otherwise intractable inference in the posterior distribution over veracity assignments by leveraging the LM's joint likelihood over veracity and the final answer as a proxy reward. This efficient inference-time correction method facilitates supervised fine-tuning of an Amortized Corrector by providing pseudo-labels for veracity. The Amortized Corrector generalizes self-correction, enabling accurate zero-shot veracity inference in novel contexts. Empirical results demonstrate that Search Corrector reliably identifies errors in logical (ProntoQA) and mathematical reasoning (GSM8K) benchmarks. The Amortized Corrector achieves comparable zero-shot accuracy and improves final answer accuracy by up to 25%.
        ]]></description>
    </item>
    <item>
        <title>CoT-Vid: Dynamic Chain-of-Thought Routing with Self Verification for Training-Free Video Reasoning</title>
        <link>https://arxiv.org/abs/2505.11830</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.11830v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hongbo Jin, Ruyang Liu, Wenhao Zhang, Guibo Luo, Ge Li</dc:creator>
        <description><![CDATA[
            背景：随着深度思考模型和思维链技术出现，System2推理发展迅速，但复杂视频推理研究存在不足。方法：提出CoT - Vid，一种无训练的视频推理范式，有动态推理路径路由、问题解耦策略和视频自一致性验证三个主要组件，还提出视频问题分类新标准。效果：在多个基准测试中表现出色，在Egochema上比基础模型性能提升9.3%，在VideoEspresso上提升5.6%，可与甚至超越GPT - 4V等大模型。
            arXiv:2505.11830v1 Announce Type: new 
Abstract: System2 reasoning is developing rapidly these days with the emergence of Deep- Thinking Models and chain-of-thought technology, which has become a centralized discussion point in the AI community. However, there is a relative gap in the research on complex video reasoning at present. In this work, we propose CoT-Vid, a novel training-free paradigm for the video domain with a multistage complex reasoning design. Distinguishing from existing video LLMs, which rely heavily on perceptual abilities, it achieved surprising performance gain with explicit reasoning mechanism. The paradigm consists of three main components: dynamic inference path routing, problem decoupling strategy, and video self-consistency verification. In addition, we propose a new standard for categorization of video questions. CoT- Vid showed outstanding results on a wide range of benchmarks, and outperforms its base model by 9.3% on Egochema and 5.6% on VideoEspresso, rivalling or even surpassing larger and proprietary models, such as GPT-4V, GPT-4o and Gemini-1.5-flash. Our codebase will be publicly available soon.
        ]]></description>
    </item>
    <item>
        <title>MedSG-Bench: A Benchmark for Medical Image Sequences Grounding</title>
        <link>https://arxiv.org/abs/2505.11852</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.11852v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jingkun Yue, Siqi Zhang, Zinan Jia, Huihuan Xu, Zongbo Han, Xiaohong Liu, Guangyu Wang</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型在医学影像领域的视觉定位中，现有基准主要关注单图像场景，缺乏对图像序列的考量。方法：提出首个医学图像序列定位基准MedSG - Bench，包含八大VQA式任务、两种定位范式，涵盖76个公开数据集等，还构建了大规模指令调优数据集MedSG - 188K并开发模型MedSeq - Grounder。效果：测试发现通用及医学专用MLLMs在医学序列定位任务中存在明显局限，新基准等资源有助于推动该领域研究。
            arXiv:2505.11852v1 Announce Type: new 
Abstract: Visual grounding is essential for precise perception and reasoning in multimodal large language models (MLLMs), especially in medical imaging domains. While existing medical visual grounding benchmarks primarily focus on single-image scenarios, real-world clinical applications often involve sequential images, where accurate lesion localization across different modalities and temporal tracking of disease progression (e.g., pre- vs. post-treatment comparison) require fine-grained cross-image semantic alignment and context-aware reasoning. To remedy the underrepresentation of image sequences in existing medical visual grounding benchmarks, we propose MedSG-Bench, the first benchmark tailored for Medical Image Sequences Grounding. It comprises eight VQA-style tasks, formulated into two paradigms of the grounding tasks, including 1) Image Difference Grounding, which focuses on detecting change regions across images, and 2) Image Consistency Grounding, which emphasizes detection of consistent or shared semantics across sequential images. MedSG-Bench covers 76 public datasets, 10 medical imaging modalities, and a wide spectrum of anatomical structures and diseases, totaling 9,630 question-answer pairs. We benchmark both general-purpose MLLMs (e.g., Qwen2.5-VL) and medical-domain specialized MLLMs (e.g., HuatuoGPT-vision), observing that even the advanced models exhibit substantial limitations in medical sequential grounding tasks. To advance this field, we construct MedSG-188K, a large-scale instruction-tuning dataset tailored for sequential visual grounding, and further develop MedSeq-Grounder, an MLLM designed to facilitate future research on fine-grained understanding across medical sequential images. The benchmark, dataset, and model are available at https://huggingface.co/MedSG-Bench
        ]]></description>
    </item>
    <item>
        <title>AdaptMol: Adaptive Fusion from Sequence String to Topological Structure for Few-shot Drug Discovery</title>
        <link>https://arxiv.org/abs/2505.11878</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.11878v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yifan Dai (College of Computer Science and Electronic Engineering, Hunan University), Xuanbai Ren (College of Computer Science and Electronic Engineering, Hunan University), Tengfei Ma (College of Computer Science and Electronic Engineering, Hunan University), Qipeng Yan (School of Biomedical Science, Hunan University), Yiping Liu (College of Computer Science and Electronic Engineering, Hunan University), Yuansheng Liu (College of Computer Science and Electronic Engineering, Hunan University), Xiangxiang Zeng (College of Computer Science and Electronic Engineering, Hunan University)</dc:creator>
        <description><![CDATA[
            背景：准确的分子属性预测是现代药物开发关键步骤，但实验验证数据稀缺，少样本学习场景下分子表示质量影响模型性能上限。方法：提出AdaptMol，一个集成自适应多模态融合的原型网络，采用双级注意力机制动态融合SMILES序列和分子图两种模态的全局与局部分子特征。效果：在三个常用基准数据集的5样本和10样本设置下实验表明，AdaptMol多数情况达最优性能，证明多模态自适应融合能有效表示分子。 
            arXiv:2505.11878v1 Announce Type: new 
Abstract: Accurate molecular property prediction (MPP) is a critical step in modern drug development. However, the scarcity of experimental validation data poses a significant challenge to AI-driven research paradigms. Under few-shot learning scenarios, the quality of molecular representations directly dictates the theoretical upper limit of model performance. We present AdaptMol, a prototypical network integrating Adaptive multimodal fusion for Molecular representation. This framework employs a dual-level attention mechanism to dynamically integrate global and local molecular features derived from two modalities: SMILES sequences and molecular graphs. (1) At the local level, structural features such as atomic interactions and substructures are extracted from molecular graphs, emphasizing fine-grained topological information; (2) At the global level, the SMILES sequence provides a holistic representation of the molecule. To validate the necessity of multimodal adaptive fusion, we propose an interpretable approach based on identifying molecular active substructures to demonstrate that multimodal adaptive fusion can efficiently represent molecules. Extensive experiments on three commonly used benchmarks under 5-shot and 10-shot settings demonstrate that AdaptMol achieves state-of-the-art performance in most cases. The rationale-extracted method guides the fusion of two modalities and highlights the importance of both modalities.
        ]]></description>
    </item>
    <item>
        <title>Mobile-Bench-v2: A More Realistic and Comprehensive Benchmark for VLM-based Mobile Agents</title>
        <link>https://arxiv.org/abs/2505.11891</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.11891v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Weikai Xu, Zhizheng Jiang, Yuxuan Liu, Wei Liu, Jian Luan, Yuanchun Li, Yunxin Liu, Bin Wang, Bo An</dc:creator>
        <description><![CDATA[
            背景：基于视觉语言模型（VLM）的移动代理可与智能手机GUI和XML结构化文本交互，但现有在线和离线基准测试分别存在获取稳定奖励信号难、单路径评估与GUI任务多解特性不符等问题。方法：采用基于插槽的指令生成方法构建更真实全面的基准测试Mobile - Bench - v2，含多种任务划分。效果：用多个代理框架和移动代理进行评估，代码和数据已公开。
            arXiv:2505.11891v1 Announce Type: new 
Abstract: VLM-based mobile agents are increasingly popular due to their capabilities to interact with smartphone GUIs and XML-structured texts and to complete daily tasks. However, existing online benchmarks struggle with obtaining stable reward signals due to dynamic environmental changes. Offline benchmarks evaluate the agents through single-path trajectories, which stands in contrast to the inherently multi-solution characteristics of GUI tasks. Additionally, both types of benchmarks fail to assess whether mobile agents can handle noise or engage in proactive interactions due to a lack of noisy apps or overly full instructions during the evaluation process. To address these limitations, we use a slot-based instruction generation method to construct a more realistic and comprehensive benchmark named Mobile-Bench-v2. Mobile-Bench-v2 includes a common task split, with offline multi-path evaluation to assess the agent's ability to obtain step rewards during task execution. It contains a noisy split based on pop-ups and ads apps, and a contaminated split named AITZ-Noise to formulate a real noisy environment. Furthermore, an ambiguous instruction split with preset Q\&amp;A interactions is released to evaluate the agent's proactive interaction capabilities. We conduct evaluations on these splits using the single-agent framework AppAgent-v1, the multi-agent framework Mobile-Agent-v2, as well as other mobile agents such as UI-Tars and OS-Atlas. Code and data are available at https://huggingface.co/datasets/xwk123/MobileBench-v2.
        ]]></description>
    </item>
    <item>
        <title>AdaCoT: Pareto-Optimal Adaptive Chain-of-Thought Triggering via Reinforcement Learning</title>
        <link>https://arxiv.org/abs/2505.11896</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.11896v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chenwei Lou, Zewei Sun, Xinnian Liang, Meng Qu, Wei Shen, Wenqi Wang, Yuntao Li, Qingping Yang, Shuangzhi Wu</dc:creator>
        <description><![CDATA[
            大语言模型在复杂推理任务上存在挑战，思维链提示虽能增强推理，但会带来高计算成本和低效率问题。为此，本文提出AdaCoT框架，将自适应推理构建为帕累托优化问题，用基于近端策略优化的强化学习方法动态控制思维链触发决策边界。还提出选择性损失掩码来保证训练稳定。实验表明，AdaCoT能在不影响复杂任务表现的同时，大幅减少简单查询的思维链使用，如在测试集上使触发率降至3.18%，平均响应令牌减少69.06%。
            arXiv:2505.11896v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities but often face challenges with tasks requiring sophisticated reasoning. While Chain-of-Thought (CoT) prompting significantly enhances reasoning, it indiscriminately generates lengthy reasoning steps for all queries, leading to substantial computational costs and inefficiency, especially for simpler inputs. To address this critical issue, we introduce AdaCoT (Adaptive Chain-of-Thought), a novel framework enabling LLMs to adaptively decide when to invoke CoT. AdaCoT framed adaptive reasoning as a Pareto optimization problem that seeks to balance model performance with the costs associated with CoT invocation (both frequency and computational overhead). We propose a reinforcement learning (RL) based method, specifically utilizing Proximal Policy Optimization (PPO), to dynamically control the CoT triggering decision boundary by adjusting penalty coefficients, thereby allowing the model to determine CoT necessity based on implicit query complexity. A key technical contribution is Selective Loss Masking (SLM), designed to counteract decision boundary collapse during multi-stage RL training, ensuring robust and stable adaptive triggering. Experimental results demonstrate that AdaCoT successfully navigates the Pareto frontier, achieving substantial reductions in CoT usage for queries not requiring elaborate reasoning. For instance, on our production traffic testset, AdaCoT reduced CoT triggering rates to as low as 3.18\% and decreased average response tokens by 69.06%, while maintaining high performance on complex tasks.
        ]]></description>
    </item>
    <item>
        <title>Recursive Question Understanding for Complex Question Answering over Heterogeneous Personal Data</title>
        <link>https://arxiv.org/abs/2505.11900</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.11900v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Philipp Christmann, Gerhard Weikum</dc:creator>
        <description><![CDATA[
            背景：问答系统处理文本和表格等混合源数据时，常将内容语言化并用语言模型编码，个人信息这类异构数据的问答存在方便获取且数据留存在用户设备的挑战。方法：提出ReQAP方法，通过递归分解为给定问题创建可执行的操作符树，操作符能无缝集成结构化和非结构化源。效果：执行操作符树可得到可追溯答案，还发布了PerQA基准，涵盖多种现实用户需求。
            arXiv:2505.11900v1 Announce Type: new 
Abstract: Question answering over mixed sources, like text and tables, has been advanced by verbalizing all contents and encoding it with a language model. A prominent case of such heterogeneous data is personal information: user devices log vast amounts of data every day, such as calendar entries, workout statistics, shopping records, streaming history, and more. Information needs range from simple look-ups to queries of analytical nature. The challenge is to provide humans with convenient access with small footprint, so that all personal data stays on the user devices. We present ReQAP, a novel method that creates an executable operator tree for a given question, via recursive decomposition. Operators are designed to enable seamless integration of structured and unstructured sources, and the execution of the operator tree yields a traceable answer. We further release the PerQA benchmark, with persona-based data and questions, covering a diverse spectrum of realistic user needs.
        ]]></description>
    </item>
    <item>
        <title>Dynamic Perturbed Adaptive Method for Infinite Task-Conflicting Time Series</title>
        <link>https://arxiv.org/abs/2505.11902</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.11902v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiang You, Xiaozhen Wang, Arben Cela</dc:creator>
        <description><![CDATA[
            背景：时间序列任务中同一输入可能有不同输出，挑战模型泛化与适应性，现有静态模型在频繁任务切换场景表现不佳。方法：提出基于主干 - 分支架构的动态扰动自适应方法，主干缓慢进化捕捉长期结构，分支模块为每个任务重新初始化和更新，无需明确任务标签实现持续测试时适应和跨任务迁移。效果：理论证明该架构比静态模型和LoRA有更高函数表达能力，实验显示其在复杂冲突任务环境中显著优于基线模型，具备快速适应和渐进学习能力。
            arXiv:2505.11902v1 Announce Type: new 
Abstract: We formulate time series tasks as input-output mappings under varying objectives, where the same input may yield different outputs. This challenges a model's generalization and adaptability. To study this, we construct a synthetic dataset with numerous conflicting subtasks to evaluate adaptation under frequent task shifts. Existing static models consistently fail in such settings. We propose a dynamic perturbed adaptive method based on a trunk-branch architecture, where the trunk evolves slowly to capture long-term structure, and branch modules are re-initialized and updated for each task. This enables continual test-time adaptation and cross-task transfer without relying on explicit task labels. Theoretically, we show that this architecture has strictly higher functional expressivity than static models and LoRA. We also establish exponential convergence of branch adaptation under the Polyak-Lojasiewicz condition. Experiments demonstrate that our method significantly outperforms competitive baselines in complex and conflicting task environments, exhibiting fast adaptation and progressive learning capabilities.
        ]]></description>
    </item>
    <item>
        <title>Are Multimodal Large Language Models Ready for Omnidirectional Spatial Reasoning?</title>
        <link>https://arxiv.org/abs/2505.11907</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.11907v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zihao Dongfang, Xu Zheng, Ziqiao Weng, Yuanhuiyi Lyu, Danda Pani Paudel, Luc Van Gool, Kailun Yang, Xuming Hu</dc:creator>
        <description><![CDATA[
            背景：360度相机的全向视野在多领域有应用，但多模态大语言模型（MLLMs）在全向空间推理方面研究较少。方法：提出首个相关基准OSR - Bench，含超15.3万个基于全景室内场景地图的问答对，覆盖多种推理类型；采用负采样策略评估幻觉和接地鲁棒性，设计两阶段评估框架。效果：对8个先进MLLMs零样本评估，结果显示当前模型在全景空间推理有困难，表明需更多感知接地的MLLMs。
            arXiv:2505.11907v1 Announce Type: new 
Abstract: The 180x360 omnidirectional field of view captured by 360-degree cameras enables their use in a wide range of applications such as embodied AI and virtual reality. Although recent advances in multimodal large language models (MLLMs) have shown promise in visual-spatial reasoning, most studies focus on standard pinhole-view images, leaving omnidirectional perception largely unexplored. In this paper, we ask: Are MLLMs ready for omnidirectional spatial reasoning? To investigate this, we introduce OSR-Bench, the first benchmark specifically designed for this setting. OSR-Bench includes over 153,000 diverse question-answer pairs grounded in high-fidelity panoramic indoor scene maps. It covers key reasoning types including object counting, relative distance, and direction. We also propose a negative sampling strategy that inserts non-existent objects into prompts to evaluate hallucination and grounding robustness. For fine-grained analysis, we design a two-stage evaluation framework assessing both cognitive map generation and QA accuracy using rotation-invariant matching and a combination of rule-based and LLM-based metrics. We evaluate eight state-of-the-art MLLMs, including GPT-4o, Gemini 1.5 Pro, and leading open-source models under zero-shot settings. Results show that current models struggle with spatial reasoning in panoramic contexts, highlighting the need for more perceptually grounded MLLMs. OSR-Bench and code will be released at: https://huggingface.co/datasets/UUUserna/OSR-Bench
        ]]></description>
    </item>
    <item>
        <title>ELITE: Embedding-Less retrieval with Iterative Text Exploration</title>
        <link>https://arxiv.org/abs/2505.11908</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.11908v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhangyu Wang, Siyuan Gao, Rong Zhou, Hao Wang, Li Ning</dc:creator>
        <description><![CDATA[
            背景：大语言模型在处理文档级或多轮任务时因长上下文保留能力有限而受限，现有检索增强生成（RAG）系统存在内容与问题意图不匹配、计算和存储开销大等问题。方法：提出无嵌入检索框架，利用大语言模型的逻辑推理能力，通过基于新重要性度量的迭代搜索空间细化进行检索，且无需显式构建图来扩展检索结果。效果：在长上下文问答基准测试中，该方法优于强基线，同时将存储和运行时间降低一个数量级以上。
            arXiv:2505.11908v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have achieved impressive progress in natural language processing, but their limited ability to retain long-term context constrains performance on document-level or multi-turn tasks. Retrieval-Augmented Generation (RAG) mitigates this by retrieving relevant information from an external corpus. However, existing RAG systems often rely on embedding-based retrieval trained on corpus-level semantic similarity, which can lead to retrieving content that is semantically similar in form but misaligned with the question's true intent. Furthermore, recent RAG variants construct graph- or hierarchy-based structures to improve retrieval accuracy, resulting in significant computation and storage overhead. In this paper, we propose an embedding-free retrieval framework. Our method leverages the logical inferencing ability of LLMs in retrieval using iterative search space refinement guided by our novel importance measure and extend our retrieval results with logically related information without explicit graph construction. Experiments on long-context QA benchmarks, including NovelQA and Marathon, show that our approach outperforms strong baselines while reducing storage and runtime by over an order of magnitude.
        ]]></description>
    </item>
    <item>
        <title>The Logical Expressiveness of Temporal GNNs via Two-Dimensional Product Logics</title>
        <link>https://arxiv.org/abs/2505.11930</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.11930v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Marco S\"alzer, Przemys{\l}aw Andrzej Wa{\l}\k{e}ga, Martin Lange</dc:creator>
        <description><![CDATA[
            背景：随着基础架构能力被深入理解，结合多架构范式的模型受关注，其中GNN的时间扩展模型因整合空间和时间维度，分析难度大。方法：将时间GNN与二维乘积逻辑联系起来，研究其逻辑表征。效果：发现时间GNN表达能力取决于图和时间组件的组合方式，递归应用静态GNN的时间GNN可捕获特定乘积逻辑中所有可定义属性，而部分架构只能表达该逻辑的受限片段，得到了时间GNN的逻辑表征和相对表达能力结果。
            arXiv:2505.11930v1 Announce Type: new 
Abstract: In recent years, the expressive power of various neural architectures -- including graph neural networks (GNNs), transformers, and recurrent neural networks -- has been characterised using tools from logic and formal language theory. As the capabilities of basic architectures are becoming well understood, increasing attention is turning to models that combine multiple architectural paradigms. Among them particularly important, and challenging to analyse, are temporal extensions of GNNs, which integrate both spatial (graph-structure) and temporal (evolution over time) dimensions. In this paper, we initiate the study of logical characterisation of temporal GNNs by connecting them to two-dimensional product logics. We show that the expressive power of temporal GNNs depends on how graph and temporal components are combined. In particular, temporal GNNs that apply static GNNs recursively over time can capture all properties definable in the product logic of (past) propositional temporal logic PTL and the modal logic K. In contrast, architectures such as graph-and-time TGNNs and global TGNNs can only express restricted fragments of this logic, where the interaction between temporal and spatial operators is syntactically constrained. These results yield the first logical characterisations of temporal GNNs and establish new relative expressiveness results for temporal GNNs.
        ]]></description>
    </item>
    <item>
        <title>Neuro-Symbolic Query Compiler</title>
        <link>https://arxiv.org/abs/2505.11932</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.11932v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuyao Zhang, Zhicheng Dou, Xiaoxi Li, Jiajie Jin, Yongkang Wu, Zhonghua Li, Qi Ye, Ji-Rong Wen</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）系统精准识别搜索意图颇具挑战，尤其是在资源受限及处理复杂嵌套结构查询时。方法：提出神经符号框架QCompiler，受语言语法规则和编译器设计启发，设计最小且充分的巴科斯-诺尔范式语法形式化复杂查询，包含查询表达式翻译器、词法语法解析器和递归下降处理器将查询编译为抽象语法树。效果：保证子查询原子性，能更精准检索文档和生成回复，显著提升RAG系统处理复杂查询能力。
            arXiv:2505.11932v1 Announce Type: new 
Abstract: Precise recognition of search intent in Retrieval-Augmented Generation (RAG) systems remains a challenging goal, especially under resource constraints and for complex queries with nested structures and dependencies. This paper presents QCompiler, a neuro-symbolic framework inspired by linguistic grammar rules and compiler design, to bridge this gap. It theoretically designs a minimal yet sufficient Backus-Naur Form (BNF) grammar $G[q]$ to formalize complex queries. Unlike previous methods, this grammar maintains completeness while minimizing redundancy. Based on this, QCompiler includes a Query Expression Translator, a Lexical Syntax Parser, and a Recursive Descent Processor to compile queries into Abstract Syntax Trees (ASTs) for execution. The atomicity of the sub-queries in the leaf nodes ensures more precise document retrieval and response generation, significantly improving the RAG system's ability to address complex queries.
        ]]></description>
    </item>
    <item>
        <title>ChartEdit: How Far Are MLLMs From Automating Chart Analysis? Evaluating MLLMs' Capability via Chart Editing</title>
        <link>https://arxiv.org/abs/2505.11935</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.11935v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xuanle Zhao, Xuexin Liu, Haoyue Yang, Xianzhen Luo, Fanhu Zeng, Jianling Li, Qi Shi, Chi Chen</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型（MLLMs）在图表编辑任务上挑战大，当前缺乏全面评估框架。方法：提出新的高质量图表编辑基准ChartEdit，包含1405条编辑指令用于233个真实图表，每条指令 - 图表实例都经人工标注验证；用其对10个主流MLLMs进行代码和图表层面实验评估。效果：大规模模型生成代码产出的图像与参考图像部分匹配，但按指令精确编辑能力有限，SOTA模型得分仅59.96，小规模模型表现更差，该领域有待进一步发展。
            arXiv:2505.11935v1 Announce Type: new 
Abstract: Although multimodal large language models (MLLMs) show promise in generating chart rendering code, chart editing presents a greater challenge. This difficulty stems from its nature as a labor-intensive task for humans that also demands MLLMs to integrate chart understanding, complex reasoning, and precise intent interpretation. While many MLLMs claim such editing capabilities, current assessments typically rely on limited case studies rather than robust evaluation methodologies, highlighting the urgent need for a comprehensive evaluation framework. In this work, we propose ChartEdit, a new high-quality benchmark designed for chart editing tasks. This benchmark comprises $1,405$ diverse editing instructions applied to $233$ real-world charts, with each instruction-chart instance having been manually annotated and validated for accuracy. Utilizing ChartEdit, we evaluate the performance of 10 mainstream MLLMs across two types of experiments, assessing them at both the code and chart levels. The results suggest that large-scale models can generate code to produce images that partially match the reference images. However, their ability to generate accurate edits according to the instructions remains limited. The state-of-the-art (SOTA) model achieves a score of only $59.96$, highlighting significant challenges in precise modification. In contrast, small-scale models, including chart-domain models, struggle both with following editing instructions and generating overall chart images, underscoring the need for further development in this area. Code is available at https://github.com/xxlllz/ChartEdit.
        ]]></description>
    </item>
    <item>
        <title>Unveiling Knowledge Utilization Mechanisms in LLM-based Retrieval-Augmented Generation</title>
        <link>https://arxiv.org/abs/2505.11995</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.11995v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuhao Wang, Ruiyang Ren, Yucheng Wang, Wayne Xin Zhao, Jing Liu, Hua Wu, Haifeng Wang</dc:creator>
        <description><![CDATA[
            背景：大语言模型（LLMs）的参数知识有局限，检索增强生成（RAG）虽能扩大知识范围，但基于LLM的RAG潜在知识利用机制待探索。方法：宏观上用知识流分析，微观上研究各模块功能；将知识利用过程分解为四个阶段，引入知识激活概率熵（KAPE）识别神经元。效果：通过选择性停用神经元可改变LLM对知识源的依赖，明确多头注意力和多层感知机层在知识形成中的互补作用，为提升RAG可靠性和可解释性奠定基础。
            arXiv:2505.11995v1 Announce Type: new 
Abstract: Considering the inherent limitations of parametric knowledge in large language models (LLMs), retrieval-augmented generation (RAG) is widely employed to expand their knowledge scope. Since RAG has shown promise in knowledge-intensive tasks like open-domain question answering, its broader application to complex tasks and intelligent assistants has further advanced its utility. Despite this progress, the underlying knowledge utilization mechanisms of LLM-based RAG remain underexplored. In this paper, we present a systematic investigation of the intrinsic mechanisms by which LLMs integrate internal (parametric) and external (retrieved) knowledge in RAG scenarios. Specially, we employ knowledge stream analysis at the macroscopic level, and investigate the function of individual modules at the microscopic level. Drawing on knowledge streaming analyses, we decompose the knowledge utilization process into four distinct stages within LLM layers: knowledge refinement, knowledge elicitation, knowledge expression, and knowledge contestation. We further demonstrate that the relevance of passages guides the streaming of knowledge through these stages. At the module level, we introduce a new method, knowledge activation probability entropy (KAPE) for neuron identification associated with either internal or external knowledge. By selectively deactivating these neurons, we achieve targeted shifts in the LLM's reliance on one knowledge source over the other. Moreover, we discern complementary roles for multi-head attention and multi-layer perceptron layers during knowledge formation. These insights offer a foundation for improving interpretability and reliability in retrieval-augmented LLMs, paving the way for more robust and transparent generative solutions in knowledge-intensive domains.
        ]]></description>
    </item>
    <item>
        <title>Multimodal Cancer Survival Analysis via Hypergraph Learning with Cross-Modality Rebalance</title>
        <link>https://arxiv.org/abs/2505.11997</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.11997v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mingcheng Qu, Guang Yang,  Donglin, Tonghua Su, Yue Gao, Yang Song, Lei Fan</dc:creator>
        <description><![CDATA[
            背景：多模态病理 - 基因组分析在癌症生存预测中愈发重要，但现有研究忽略病理图像上下文和层次细节信息损失，且存在模态不平衡问题。方法：提出多模态生存预测框架，用超图学习捕捉病理图像细节，采用模态再平衡机制和交互式对齐融合策略动态调整两模态贡献。效果：在五个TCGA数据集上实验，模型C - Index性能比先进方法高超3.4%。
            arXiv:2505.11997v1 Announce Type: new 
Abstract: Multimodal pathology-genomic analysis has become increasingly prominent in cancer survival prediction. However, existing studies mainly utilize multi-instance learning to aggregate patch-level features, neglecting the information loss of contextual and hierarchical details within pathology images. Furthermore, the disparity in data granularity and dimensionality between pathology and genomics leads to a significant modality imbalance. The high spatial resolution inherent in pathology data renders it a dominant role while overshadowing genomics in multimodal integration. In this paper, we propose a multimodal survival prediction framework that incorporates hypergraph learning to effectively capture both contextual and hierarchical details from pathology images. Moreover, it employs a modality rebalance mechanism and an interactive alignment fusion strategy to dynamically reweight the contributions of the two modalities, thereby mitigating the pathology-genomics imbalance. Quantitative and qualitative experiments are conducted on five TCGA datasets, demonstrating that our model outperforms advanced methods by over 3.4\% in C-Index performance.
        ]]></description>
    </item>
    <item>
        <title>Relation-Aware Graph Foundation Model</title>
        <link>https://arxiv.org/abs/2505.12027</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12027v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jianxiang Yu, Jiapeng Zhu, Hao Qian, Ziqi Liu, Zhiqiang Zhang, Xiang Li</dc:creator>
        <description><![CDATA[
            背景：大语言模型在NLP任务表现出色，图基础模型是图学习的有前景方向，但图缺乏明确泛化单元，设计有效预训练策略有挑战。方法：提出REEF框架，以关系令牌为基本单元，构建关系词汇表存储图关系信息，引入超网络生成图神经网络参数，设计超网络构建特定数据集投影器并引入特征偏差，采用数据增强和混合数据集预训练策略。效果：在预训练和迁移学习任务上显著优于现有方法。
            arXiv:2505.12027v1 Announce Type: new 
Abstract: In recent years, large language models (LLMs) have demonstrated remarkable generalization capabilities across various natural language processing (NLP) tasks. Similarly, graph foundation models (GFMs) have emerged as a promising direction in graph learning, aiming to generalize across diverse datasets through large-scale pre-training. However, unlike language models that rely on explicit token representations, graphs lack a well-defined unit for generalization, making it challenging to design effective pre-training strategies. In this work, we propose REEF, a novel framework that leverages relation tokens as the basic units for GFMs. Inspired by the token vocabulary in LLMs, we construct a relation vocabulary of relation tokens to store relational information within graphs. To accommodate diverse relations, we introduce two hypernetworks that adaptively generate the parameters of aggregators and classifiers in graph neural networks based on relation tokens. In addition, we design another hypernetwork to construct dataset-specific projectors and incorporate a dataset-level feature bias into the initial node representations, enhancing flexibility across different datasets with the same relation. Further, we adopt graph data augmentation and a mixed-dataset pre-training strategy, allowing REEF to capture relational diversity more effectively and exhibit strong generalization capabilities. Extensive experiments show that REEF significantly outperforms existing methods on both pre-training and transfer learning tasks, underscoring its potential as a powerful foundation model for graph-based applications.
        ]]></description>
    </item>
    <item>
        <title>Attribution Projection Calculus: A Novel Framework for Causal Inference in Bayesian Networks</title>
        <link>https://arxiv.org/abs/2505.12094</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12094v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>M Ruhul Amin</dc:creator>
        <description><![CDATA[
            背景：需确定结构化贝叶斯网络中的因果关系。方法：提出归因投影演算（AP - Calculus）框架，研究特定网络架构，证明每个标签对应一个去混杂中间节点，形式化中间节点双重性质，建立分离函数。效果：该网络架构在因果推理上优于其他结构；AP - Calculus为分析特征 - 标签归因等提供数学基础，理论验证显示其在很多实际应用中可涵盖传统do - calculus，为监督学习因果推理提供更直接方法。
            arXiv:2505.12094v1 Announce Type: new 
Abstract: This paper introduces Attribution Projection Calculus (AP-Calculus), a novel mathematical framework for determining causal relationships in structured Bayesian networks. We investigate a specific network architecture with source nodes connected to destination nodes through intermediate nodes, where each input maps to a single label with maximum marginal probability. We prove that for each label, exactly one intermediate node acts as a deconfounder while others serve as confounders, enabling optimal attribution of features to their corresponding labels. The framework formalizes the dual nature of intermediate nodes as both confounders and deconfounders depending on the context, and establishes separation functions that maximize distinctions between intermediate representations. We demonstrate that the proposed network architecture is optimal for causal inference compared to alternative structures, including those based on Pearl's causal framework. AP-Calculus provides a comprehensive mathematical foundation for analyzing feature-label attributions, managing spurious correlations, quantifying information gain, ensuring fairness, and evaluating uncertainty in prediction models, including large language models. Theoretical verification shows that AP-Calculus not only extends but can also subsume traditional do-calculus for many practical applications, offering a more direct approach to causal inference in supervised learning contexts.
        ]]></description>
    </item>
    <item>
        <title>TinyRS-R1: Compact Multimodal Language Model for Remote Sensing</title>
        <link>https://arxiv.org/abs/2505.12099</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12099v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Aybora Koksal, A. Aydin Alatan</dc:creator>
        <description><![CDATA[
            背景：遥感应用常运行于无法承载70亿参数多模态语言模型的边缘硬件上。方法：本文推出20亿参数的多模态小语言模型TinyRS及推理增强变体TinyRS - R1，基于Qwen2 - VL - 2B，经四阶段训练，包括卫星图像预训练、视觉指令示例指令调优、推理数据集思维链标注微调及组相对策略优化对齐。效果：TinyRS - R1在多项任务中达或超70亿参数模型表现，仅需三分之一内存和延迟，思维链推理利于空间定位和场景理解，非推理的TinyRS在低延迟问答任务中表现出色。
            arXiv:2505.12099v1 Announce Type: new 
Abstract: Remote-sensing applications often run on edge hardware that cannot host today's 7B-parameter multimodal language models. This paper introduces TinyRS, the first 2B-parameter multimodal small language model (MSLM) optimized for remote sensing tasks, and TinyRS-R1, its reasoning-augmented variant. Built upon Qwen2-VL-2B, TinyRS is trained through a four-stage pipeline: pre-training on million satellite images, instruction tuning on visual instruction examples, fine-tuning with Chain-of-Thought (CoT) annotations from the proposed reasoning dataset, and alignment via Group Relative Policy Optimization (GRPO). TinyRS-R1 achieves or surpasses the performance of recent 7B-parameter remote sensing models across classification, VQA, visual grounding, and open-ended question answering-while requiring just one-third of the memory and latency. Our analysis shows that CoT reasoning substantially benefits spatial grounding and scene understanding, while the non-reasoning TinyRS excels in concise, latency-sensitive VQA tasks. TinyRS-R1 represents the first domain-specialized MSLM with GRPO-aligned CoT reasoning for general-purpose remote sensing.
        ]]></description>
    </item>
    <item>
        <title>Understanding the Capabilities of Molecular Graph Neural Networks in Materials Science Through Multimodal Learning and Physical Context Encoding</title>
        <link>https://arxiv.org/abs/2505.12137</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12137v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Can Polat, Hasan Kurban, Erchin Serpedin, Mustafa Kurban</dc:creator>
        <description><![CDATA[
            背景：分子图神经网络（GNNs）常仅关注基于XYZ的几何表示，忽略了公共数据库中的化学背景信息。方法：提出一种多模态框架，将分子图与IUPAC名称、分子式等文本描述符相结合，通过门控融合机制平衡几何和文本特征。效果：在基准数据集实验显示，添加文本数据对某些电子属性有显著提升，但对其他属性提升有限，且不同GNN架构表现模式相似，表明学习到的表示相近。
            arXiv:2505.12137v1 Announce Type: new 
Abstract: Molecular graph neural networks (GNNs) often focus exclusively on XYZ-based geometric representations and thus overlook valuable chemical context available in public databases like PubChem. This work introduces a multimodal framework that integrates textual descriptors, such as IUPAC names, molecular formulas, physicochemical properties, and synonyms, alongside molecular graphs. A gated fusion mechanism balances geometric and textual features, allowing models to exploit complementary information. Experiments on benchmark datasets indicate that adding textual data yields notable improvements for certain electronic properties, while gains remain limited for others. Furthermore, the GNN architectures display similar performance patterns (improving and deteriorating on analogous targets), suggesting they learn comparable representations rather than distinctly different physical insights.
        ]]></description>
    </item>
    <item>
        <title>Reasoning Large Language Model Errors Arise from Hallucinating Critical Problem Features</title>
        <link>https://arxiv.org/abs/2505.12151</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12151v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Alex Heyman, Joel Zylberberg</dc:creator>
        <description><![CDATA[
            背景：大语言模型通过思维链策略在推理任务上取得进展，但“推理大语言模型”（RLLMs）仍有不足，了解其失败原因很重要。方法：对o1 - mini等多个模型在图着色这一约束满足逻辑问题上进行测试，通过错误率比较和思维链/解释文本分析。效果：发现RLLMs易虚构提示中未指定的图边，该现象在不同复杂度和语义框架中存在，是多数模型错误答案的重要原因。研究指出RLLMs在问题特征表征上有问题，并给出改进建议。
            arXiv:2505.12151v1 Announce Type: new 
Abstract: Large language models have recently made great strides in reasoning task performance through chain-of-thought (CoT) strategies trained via reinforcement learning; however, these "reasoning large language models" (RLLMs) remain imperfect reasoners, and understanding the frequencies and causes of their failure modes is important for both users and developers. We test o1-mini, o3-mini, DeepSeek-R1, Claude 3.7 Sonnet, Gemini 2.5 Pro Preview, and Grok 3 Mini Beta on graph coloring as a variable-complexity constraint-satisfaction logic problem, and find evidence from both error rate comparisons and CoT/explanation text analysis that RLLMs are prone to hallucinate edges not specified in the prompt's description of the graph. This phenomenon persists across multiple problem complexity levels and semantic frames, and it appears to account for a significant fraction of the incorrect answers from every tested model, and the vast majority of them for some models. Our results indicate that RLLMs may possess broader issues with misrepresentation of problem specifics, and we offer suggestions for design choices to mitigate this weakness.
        ]]></description>
    </item>
    <item>
        <title>From Shots to Stories: LLM-Assisted Video Editing with Unified Language Representations</title>
        <link>https://arxiv.org/abs/2505.12237</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12237v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuzhi Li, Haojun Xu, Fang Tian</dc:creator>
        <description><![CDATA[
            背景：大语言模型和视觉 - 语言模型在视频理解中有出色表现，但在视频编辑应用待挖掘。方法：引入中间表示L - Storyboard，将离散视频片段转为适合大模型处理的结构化语言描述；划分视频编辑任务为收敛和发散任务，聚焦三个核心任务；针对发散任务输出不稳定，提出StoryFlow策略，将多路径推理转为收敛选择机制。效果：L - Storyboard加强视觉与语言映射，提升编辑任务可解释性和隐私保护；StoryFlow增强镜头排序逻辑一致性和输出稳定性。
            arXiv:2505.12237v1 Announce Type: new 
Abstract: Large Language Models (LLMs) and Vision-Language Models (VLMs) have demonstrated remarkable reasoning and generalization capabilities in video understanding; however, their application in video editing remains largely underexplored. This paper presents the first systematic study of LLMs in the context of video editing. To bridge the gap between visual information and language-based reasoning, we introduce L-Storyboard, an intermediate representation that transforms discrete video shots into structured language descriptions suitable for LLM processing. We categorize video editing tasks into Convergent Tasks and Divergent Tasks, focusing on three core tasks: Shot Attributes Classification, Next Shot Selection, and Shot Sequence Ordering. To address the inherent instability of divergent task outputs, we propose the StoryFlow strategy, which converts the divergent multi-path reasoning process into a convergent selection mechanism, effectively enhancing task accuracy and logical coherence. Experimental results demonstrate that L-Storyboard facilitates a more robust mapping between visual information and language descriptions, significantly improving the interpretability and privacy protection of video editing tasks. Furthermore, StoryFlow enhances the logical consistency and output stability in Shot Sequence Ordering, underscoring the substantial potential of LLMs in intelligent video editing.
        ]]></description>
    </item>
    <item>
        <title>MMS-VPR: Multimodal Street-Level Visual Place Recognition Dataset and Benchmark</title>
        <link>https://arxiv.org/abs/2505.12254</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12254v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yiwei Ou, Xiaobin Ren, Ronggui Sun, Guansong Gao, Ziyi Jiang, Kaiqi Zhao, Manfredo Manfredini</dc:creator>
        <description><![CDATA[
            背景：现有视觉场所识别数据集多依赖车载图像，缺乏多模态多样性，且对复杂街道场景覆盖不足。方法：提出大规模多模态数据集MMS - VPR，含78,575张标注图像和2,512个视频片段，形成有125条边、81个节点和1个子图的空间图，并定义两个子集。效果：用传统VPR模型、图神经网络和多模态基线进行的大量基准测试表明，利用多模态和结构线索可大幅提升性能，该数据集有助于多领域交叉研究。
            arXiv:2505.12254v1 Announce Type: new 
Abstract: Existing visual place recognition (VPR) datasets predominantly rely on vehicle-mounted imagery, lack multimodal diversity and underrepresent dense, mixed-use street-level spaces, especially in non-Western urban contexts. To address these gaps, we introduce MMS-VPR, a large-scale multimodal dataset for street-level place recognition in complex, pedestrian-only environments. The dataset comprises 78,575 annotated images and 2,512 video clips captured across 207 locations in a ~70,800 $\mathrm{m}^2$ open-air commercial district in Chengdu, China. Each image is labeled with precise GPS coordinates, timestamp, and textual metadata, and covers varied lighting conditions, viewpoints, and timeframes. MMS-VPR follows a systematic and replicable data collection protocol with minimal device requirements, lowering the barrier for scalable dataset creation. Importantly, the dataset forms an inherent spatial graph with 125 edges, 81 nodes, and 1 subgraph, enabling structure-aware place recognition. We further define two application-specific subsets -- Dataset_Edges and Dataset_Points -- to support fine-grained and graph-based evaluation tasks. Extensive benchmarks using conventional VPR models, graph neural networks, and multimodal baselines show substantial improvements when leveraging multimodal and structural cues. MMS-VPR facilitates future research at the intersection of computer vision, geospatial understanding, and multimodal reasoning. The dataset is publicly available at https://huggingface.co/datasets/Yiwei-Ou/MMS-VPR.
        ]]></description>
    </item>
    <item>
        <title>Pre-trained Prompt-driven Community Search</title>
        <link>https://arxiv.org/abs/2505.12304</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12304v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Li Ni, Hengkai Xu, Lin Mu, Yiwen Zhang, Wenjian Luo</dc:creator>
        <description><![CDATA[
            背景：现有半监督社区检测算法不适用于给定节点的社区搜索。方法：首次将“预训练 - 提示”范式用于半监督社区搜索，提出PPCS模型，包含节点编码、样本生成和提示驱动微调三个组件。节点编码用图神经网络学习节点局部结构模式；样本生成组件为给定节点确定初始社区并选择相似已知社区作训练样本；提示驱动微调组件用样本引导最终社区预测。效果：在五个真实数据集上，PPCS优于基线算法，搜索效率更高，消融实验验证各组件有效。
            arXiv:2505.12304v1 Announce Type: new 
Abstract: The "pre-train, prompt" paradigm is widely adopted in various graph-based tasks and has shown promising performance in community detection. Most existing semi-supervised community detection algorithms detect communities based on known ones, and the detected communities typically do not contain the given query node. Therefore, they are not suitable for searching the community of a given node. Motivated by this, we adopt this paradigm into the semi-supervised community search for the first time and propose Pre-trained Prompt-driven Community Search (PPCS), a novel model designed to enhance search accuracy and efficiency. PPCS consists of three main components: node encoding, sample generation, and prompt-driven fine-tuning. Specifically, the node encoding component employs graph neural networks to learn local structural patterns of nodes in a graph, thereby obtaining representations for nodes and communities. Next, the sample generation component identifies an initial community for a given node and selects known communities that are structurally similar to the initial one as training samples. Finally, the prompt-driven fine-tuning component leverages these samples as prompts to guide the final community prediction. Experimental results on five real-world datasets demonstrate that PPCS performs better than baseline algorithms. It also achieves higher community search efficiency than semi-supervised community search baseline methods, with ablation studies verifying the effectiveness of each component of PPCS.
        ]]></description>
    </item>
    <item>
        <title>LogicOCR: Do Your Large Multimodal Models Excel at Logical Reasoning on Text-Rich Images?</title>
        <link>https://arxiv.org/abs/2505.12307</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12307v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Maoyuan Ye, Jing Zhang, Juhua Liu, Bo Du, Dacheng Tao</dc:creator>
        <description><![CDATA[
            背景：大多模态模型（LMMs）虽提升了推理和OCR能力，但在富文本图像复杂逻辑推理任务上表现待研究。方法：提出LogicOCR基准，含1100道选择题，从公务员考试文本语料构建，用自动化流程转化为多模态样本，设计提示模板生成图像并人工验证；在思维链和直接回答设置下评估多种LMMs。效果：多维度分析揭示关键见解，LMMs在多模态推理上仍落后于纯文本输入，未完全融合视觉阅读与推理。
            arXiv:2505.12307v1 Announce Type: new 
Abstract: Recent advances in Large Multimodal Models (LMMs) have significantly improved their reasoning and Optical Character Recognition (OCR) capabilities. However, their performance on complex logical reasoning tasks involving text-rich images remains underexplored. To bridge this gap, we introduce LogicOCR, a benchmark comprising 1,100 multiple-choice questions designed to evaluate LMMs' logical reasoning abilities on text-rich images, while minimizing reliance on domain-specific knowledge (e.g., mathematics). We construct LogicOCR by curating a text corpus from the Chinese National Civil Servant Examination and develop a scalable, automated pipeline to convert it into multimodal samples. First, we design prompt templates to steer GPT-Image-1 to generate images with diverse backgrounds, interleaved text-illustration layouts, and varied fonts, ensuring contextual relevance and visual realism. Then, the generated images are manually verified, with low-quality examples discarded. We evaluate a range of representative open-source and proprietary LMMs under both Chain-of-Thought (CoT) and direct-answer settings. Our multi-dimensional analysis reveals key insights, such as the impact of test-time scaling, input modality differences, and sensitivity to visual-text orientation. Notably, LMMs still lag in multimodal reasoning compared to text-only inputs, indicating that they have not fully bridged visual reading with reasoning. We hope LogicOCR will serve as a valuable resource for advancing multimodal reasoning research. The dataset is available at https://github.com/MiliLab/LogicOCR.
        ]]></description>
    </item>
    <item>
        <title>Model alignment using inter-modal bridges</title>
        <link>https://arxiv.org/abs/2505.12322</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12322v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ali Gholamzadeh, Noor Sajid</dc:creator>
        <description><![CDATA[
            背景：基础模型在语言和视觉等多模态上表现出色，但不同模态内部表征对齐困难，限制了跨模态模型复用，现有方法需大量配对数据或局限特定领域。方法：提出通过条件流匹配进行模型对齐的半监督方法，在两种设置下学习不同模态潜在空间的条件流。效果：在MNIST、ImageNet等数据集的目标识别和图像生成任务中，尤其在标记训练数据稀缺（<20%）时，该方法能达到端到端训练模型的下游任务性能，提供了数据高效的跨模态模型对齐方案。
            arXiv:2505.12322v1 Announce Type: new 
Abstract: Foundation models have demonstrated remarkable performance across modalities such as language and vision. However, model reuse across distinct modalities (e.g., text and vision) remains limited due to the difficulty of aligning internal representations. Existing methods require extensive paired training data or are constrained to specific domains. We introduce a semi-supervised approach for model alignment via conditional flow matching. The conditional flow between latent spaces of different modalities (e.g., text-to-image or biological-to-artificial neuronal activity) can be learned in two settings: ($1$) solving a (balanced or unbalanced) optimal transport problem with an inter-space bridge cost, and ($2$) performing memory-efficient alignment using labelled exemplars. Despite being constrained by the original models' capacity, our method--under both settings--matches downstream task performance of end-to-end trained models on object recognition and image generation tasks across MNIST, ImageNet, and \cite{majaj2015simple} datasets, particularly when labelled training data is scarce ($<20\%$). Our method provides a data-efficient solution for inter-modal model alignment with minimal supervision.
        ]]></description>
    </item>
    <item>
        <title>GraphFLEx: Structure Learning Framework for Large Expanding Graphs</title>
        <link>https://arxiv.org/abs/2505.12323</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12323v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mohit Kataria, Nikita Malik, Sandeep Kumar,  Jayadeva</dc:creator>
        <description><![CDATA[
            背景：图结构学习是基于图的机器学习核心问题，但现有方法不适用于大规模动态图，新节点到来时需重新学习结构，计算和内存成本高。方法：提出GraphFLEx框架，结合聚类和粗化技术将边形成限制在结构相关的节点子集，减少搜索空间，支持48种灵活配置。效果：在26个数据集和多种图神经网络架构上实验表明，GraphFLEx实现了最先进性能，可扩展性显著提升。
            arXiv:2505.12323v1 Announce Type: new 
Abstract: Graph structure learning is a core problem in graph-based machine learning, essential for uncovering latent relationships and ensuring model interpretability. However, most existing approaches are ill-suited for large-scale and dynamically evolving graphs, as they often require complete re-learning of the structure upon the arrival of new nodes and incur substantial computational and memory costs. In this work, we propose GraphFLEx: a unified and scalable framework for Graph Structure Learning in Large and Expanding Graphs. GraphFLEx mitigates the scalability bottlenecks by restricting edge formation to structurally relevant subsets of nodes identified through a combination of clustering and coarsening techniques. This dramatically reduces the search space and enables efficient, incremental graph updates. The framework supports 48 flexible configurations by integrating diverse choices of learning paradigms, coarsening strategies, and clustering methods, making it adaptable to a wide range of graph settings and learning objectives. Extensive experiments across 26 diverse datasets and Graph Neural Network architectures demonstrate that GraphFLEx achieves state-of-the-art performance with significantly improved scalability.
        ]]></description>
    </item>
    <item>
        <title>LLMSR@XLLM25: An Empirical Study of LLM for Structural Reasoning</title>
        <link>https://arxiv.org/abs/2505.12328</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12328v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xinye Li, Mingqi Wan, Dianbo Sui</dc:creator>
        <description><![CDATA[
            背景：LLMSR@XLLM25共享任务评估大语言模型生成细粒度、可控且可解释推理过程的能力。方法：团队仅利用现成的Meta - Llama - 3 - 8B - Instruct，设计了简洁的少样本多轮提示，先列举条件，再引导模型标注、引用和评判推理步骤，并用基于正则表达式的轻量级后处理器规范结果。效果：未进行微调、外部检索或集成，该方法总体排名第5，宏观F1分数与更复杂、高资源消耗的流程相当。
            arXiv:2505.12328v1 Announce Type: new 
Abstract: We present Team asdfo123's submission to the LLMSR@XLLM25 shared task, which evaluates large language models on producing fine-grained, controllable, and interpretable reasoning processes. Systems must extract all problem conditions, decompose a chain of thought into statement-evidence pairs, and verify the logical validity of each pair. Leveraging only the off-the-shelf Meta-Llama-3-8B-Instruct, we craft a concise few-shot, multi-turn prompt that first enumerates all conditions and then guides the model to label, cite, and adjudicate every reasoning step. A lightweight post-processor based on regular expressions normalises spans and enforces the official JSON schema. Without fine-tuning, external retrieval, or ensembling, our method ranks 5th overall, achieving macro F1 scores on par with substantially more complex and resource-consuming pipelines. We conclude by analysing the strengths and limitations of our approach and outlining directions for future research in structural reasoning with LLMs. Our code is available at https://github.com/asdfo123/LLMSR-asdfo123.
        ]]></description>
    </item>
    <item>
        <title>UniEdit: A Unified Knowledge Editing Benchmark for Large Language Models</title>
        <link>https://arxiv.org/abs/2505.12345</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12345v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qizhou Chen, Dakan Wang, Taolin Zhang, Zaoming Yan, Chengsong You, Chengyu Wang, Xiaofeng He</dc:creator>
        <description><![CDATA[
            背景：当前多数大语言模型编辑数据集局限于狭窄知识领域，编辑评估范围有限。方法：提出统一基准UniEdit，从25个常见领域选实体构建编辑样本，用开放知识图谱的三元组知识确保覆盖度；设计NMCS算法采样子图以评估编辑影响；用专有大模型将子图转为自然语言文本。效果：统计分析证实了UniEdit的规模、全面性和多样性，多模型实验分析了编辑表现，为后续研究提供见解。
            arXiv:2505.12345v1 Announce Type: new 
Abstract: Model editing aims to enhance the accuracy and reliability of large language models (LLMs) by efficiently adjusting their internal parameters. Currently, most LLM editing datasets are confined to narrow knowledge domains and cover a limited range of editing evaluation. They often overlook the broad scope of editing demands and the diversity of ripple effects resulting from edits. In this context, we introduce UniEdit, a unified benchmark for LLM editing grounded in open-domain knowledge. First, we construct editing samples by selecting entities from 25 common domains across five major categories, utilizing the extensive triple knowledge available in open-domain knowledge graphs to ensure comprehensive coverage of the knowledge domains. To address the issues of generality and locality in editing, we design an Neighborhood Multi-hop Chain Sampling (NMCS) algorithm to sample subgraphs based on a given knowledge piece to entail comprehensive ripple effects to evaluate. Finally, we employ proprietary LLMs to convert the sampled knowledge subgraphs into natural language text, guaranteeing grammatical accuracy and syntactical diversity. Extensive statistical analysis confirms the scale, comprehensiveness, and diversity of our UniEdit benchmark. We conduct comprehensive experiments across multiple LLMs and editors, analyzing their performance to highlight strengths and weaknesses in editing across open knowledge domains and various evaluation criteria, thereby offering valuable insights for future research endeavors.
        ]]></description>
    </item>
    <item>
        <title>Graph-Reward-SQL: Execution-Free Reinforcement Learning for Text-to-SQL via Graph Matching and Stepwise Reward</title>
        <link>https://arxiv.org/abs/2505.12380</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12380v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Han Weng, Boyi Liu, Yuanfeng Song, Dun Zeng, Yingxiang Yang, Yi Zhan, Longjie Cui, Xiaoming Yin, Yang Sun</dc:creator>
        <description><![CDATA[
            背景：强化学习用于提升大语言模型在文本到SQL任务的性能，但现有方法存在执行延迟高或GPU内存开销大的问题。方法：提出Graph - Reward - SQL框架，采用GMNScore结果奖励模型，利用SQL图表示提供准确奖励信号，减少推理时间和内存使用；引入StepRTM逐步奖励模型，对公共表表达式子查询进行中间监督。效果：在Spider和BIRD等基准测试中，该方法始终优于现有奖励模型。
            arXiv:2505.12380v1 Announce Type: new 
Abstract: Reinforcement learning (RL) has been widely adopted to enhance the performance of large language models (LLMs) on Text-to-SQL tasks. However, existing methods often rely on execution-based or LLM-based Bradley-Terry reward models. The former suffers from high execution latency caused by repeated database calls, whereas the latter imposes substantial GPU memory overhead, both of which significantly hinder the efficiency and scalability of RL pipelines. To this end, we propose a novel Text-to-SQL RL fine-tuning framework named Graph-Reward-SQL, which employs the GMNScore outcome reward model. We leverage SQL graph representations to provide accurate reward signals while significantly reducing inference time and GPU memory usage. Building on this foundation, we further introduce StepRTM, a stepwise reward model that provides intermediate supervision over Common Table Expression (CTE) subqueries. This encourages both functional correctness and structural clarity of SQL. Extensive comparative and ablation experiments on standard benchmarks, including Spider and BIRD, demonstrate that our method consistently outperforms existing reward models.
        ]]></description>
    </item>
    <item>
        <title>Table-R1: Region-based Reinforcement Learning for Table Understanding</title>
        <link>https://arxiv.org/abs/2505.12415</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12415v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhenhe Wu, Jian Yang, Jiaheng Liu, Xianjie Wu, Changzai Pan, Jie Zhang, Yu Zhao, Shuangyong Song, Yongxiang Li, Zhoujun Li</dc:creator>
        <description><![CDATA[
            背景：表格的行列结构给语言模型理解带来挑战，大语言模型虽在表格推理有潜力，但优化表格问答性能待探索。方法：提出基于区域的Table - R1强化学习方法，通过Region - Enhanced Supervised Fine - Tuning引导模型在生成答案前识别相关表格区域，采用Table - Aware Group Relative Policy Optimization引入混合奖励系统平衡区域准确性和答案正确性。效果：在三个基准数据集上，Table - R1使多个基础模型平均性能提升14.36分，TARPO比GRPO减少67.5%的响应令牌消耗。
            arXiv:2505.12415v1 Announce Type: new 
Abstract: Tables present unique challenges for language models due to their structured row-column interactions, necessitating specialized approaches for effective comprehension. While large language models (LLMs) have demonstrated potential in table reasoning through prompting and techniques like chain-of-thought (CoT) and program-of-thought (PoT), optimizing their performance for table question answering remains underexplored. In this paper, we introduce region-based Table-R1, a novel reinforcement learning approach that enhances LLM table understanding by integrating region evidence into reasoning steps. Our method employs Region-Enhanced Supervised Fine-Tuning (RE-SFT) to guide models in identifying relevant table regions before generating answers, incorporating textual, symbolic, and program-based reasoning. Additionally, Table-Aware Group Relative Policy Optimization (TARPO) introduces a mixed reward system to dynamically balance region accuracy and answer correctness, with decaying region rewards and consistency penalties to align reasoning steps. Experiments show that Table-R1 achieves an average performance improvement of 14.36 points across multiple base models on three benchmark datasets, even outperforming baseline models with ten times the parameters, while TARPO reduces response token consumption by 67.5% compared to GRPO, significantly advancing LLM capabilities in efficient tabular reasoning.
        ]]></description>
    </item>
    <item>
        <title>Observe-R1: Unlocking Reasoning Abilities of MLLMs with Dynamic Progressive Reinforcement Learning</title>
        <link>https://arxiv.org/abs/2505.12432</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12432v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zirun Guo, Minjie Hong, Tao Jin</dc:creator>
        <description><![CDATA[
            背景：强化学习改善大语言模型推理能力有前景，但适配多模态数据和格式的挑战待探索。方法：提出Observe - R1框架，借鉴人类学习规律提出渐进学习范式，构建NeuraLadder数据集用于训练；引入多模态格式约束，实现奖励系统和动态加权机制。效果：在NeuraLadder数据集20k样本上实验，Observe - R1在推理和通用基准上优于一系列更大推理模型，推理链更清晰简洁，消融实验验证策略有效。
            arXiv:2505.12432v1 Announce Type: new 
Abstract: Reinforcement Learning (RL) has shown promise in improving the reasoning abilities of Large Language Models (LLMs). However, the specific challenges of adapting RL to multimodal data and formats remain relatively unexplored. In this work, we present Observe-R1, a novel framework aimed at enhancing the reasoning capabilities of multimodal large language models (MLLMs). We draw inspirations from human learning progression--from simple to complex and easy to difficult, and propose a gradual learning paradigm for MLLMs. To this end, we construct the NeuraLadder dataset, which is organized and sampled according to the difficulty and complexity of data samples for RL training. To tackle multimodal tasks, we introduce a multimodal format constraint that encourages careful observation of images, resulting in enhanced visual abilities and clearer and more structured responses. Additionally, we implement a bonus reward system that favors concise, correct answers within a length constraint, alongside a dynamic weighting mechanism that prioritizes uncertain and medium-difficulty problems, ensuring that more informative samples have a greater impact on training. Our experiments with the Qwen2.5-VL-3B and Qwen2.5-VL-7B models on 20k samples from the NeuraLadder dataset show that Observe-R1 outperforms a series of larger reasoning models on both reasoning and general benchmarks, achieving superior clarity and conciseness in reasoning chains. Ablation studies validate the effectiveness of our strategies, highlighting the robustness and generalization of our approach. The dataset and code will be released at https://github.com/zrguo/Observe-R1.
        ]]></description>
    </item>
    <item>
        <title>VideoRFT: Incentivizing Video Reasoning Capability in MLLMs via Reinforced Fine-Tuning</title>
        <link>https://arxiv.org/abs/2505.12434</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12434v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qi Wang, Yanrui Yu, Ye Yuan, Rui Mao, Tianfei Zhou</dc:creator>
        <description><![CDATA[
            背景：强化微调在大语言模型推理能力提升上有成效，但视频推理因视频数据复杂结构仍是挑战。方法：提出VideoRFT，先以思维链标注进行监督微调，再用强化学习提升泛化；构建自动思维链整理流程，生成两个新数据集；引入语义一致性奖励促进文本推理与视觉证据对齐。效果：在六个视频推理基准测试中达到了最先进水平。
            arXiv:2505.12434v1 Announce Type: new 
Abstract: Reinforcement fine-tuning (RFT) has shown great promise in achieving humanlevel reasoning capabilities of Large Language Models (LLMs), and has recently been extended to MLLMs. Nevertheless, reasoning about videos, which is a fundamental aspect of human intelligence, remains a persistent challenge due to the complex logic, temporal and causal structures inherent in video data. To fill this gap, we propose VIDEORFT, a novel approach that extends the RFT paradigm to cultivate human-like video reasoning capabilities in MLLMs. VIDEORFT follows the standard two-stage scheme in RFT: supervised fine-tuning (SFT) with chain-of-thought (CoT) annotations, followed by reinforcement learning (RL) to improve generalization. A central challenge to achieve this in the video domain lies in the scarcity of large-scale, high-quality video CoT datasets. We address this by building a fully automatic CoT curation pipeline. First, we devise a cognitioninspired prompting strategy to elicit a reasoning LLM to generate preliminary CoTs based solely on rich, structured, and literal representations of video content. Subsequently, these CoTs are revised by a visual-language model conditioned on the actual video, ensuring visual consistency and reducing visual hallucinations. This pipeline results in two new datasets - VideoRFT-CoT-102K for SFT and VideoRFT-RL-310K for RL. To further strength the RL phase, we introduce a novel semantic-consistency reward that explicitly promotes the alignment between textual reasoning with visual evidence. This reward encourages the model to produce coherent, context-aware reasoning outputs grounded in visual input. Extensive experiments show that VIDEORFT achieves state-of-the-art performance on six video reasoning benchmarks.
        ]]></description>
    </item>
    <item>
        <title>Addressing the Scarcity of Benchmarks for Graph XAI</title>
        <link>https://arxiv.org/abs/2505.12437</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12437v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Michele Fontanesi, Alessio Micheli, Marco Podda, Domenico Tortorella</dc:creator>
        <description><![CDATA[
            背景：图神经网络虽适用于结构化数据学习，但决策过程不透明，图分类中可解释人工智能技术可解决此问题，不过该领域因缺乏含真实子图基元的基准数据集阻碍发展。方法：提出从真实数据集自动构建图分类可解释人工智能基准的通用方法，提供15个现成基准及生成超2000个基准的代码。效果：以这些基准评估了一些流行图解释器的有效性。
            arXiv:2505.12437v1 Announce Type: new 
Abstract: While Graph Neural Networks (GNNs) have become the de facto model for learning from structured data, their decisional process remains opaque to the end user, undermining their deployment in safety-critical applications. In the case of graph classification, Explainable Artificial Intelligence (XAI) techniques address this major issue by identifying sub-graph motifs that explain predictions. However, advancements in this field are hindered by a chronic scarcity of benchmark datasets with known ground-truth motifs to assess the explanations' quality. Current graph XAI benchmarks are limited to synthetic data or a handful of real-world tasks hand-curated by domain experts. In this paper, we propose a general method to automate the construction of XAI benchmarks for graph classification from real-world datasets. We provide both 15 ready-made benchmarks, as well as the code to generate more than 2000 additional XAI benchmarks with our method. As a use case, we employ our benchmarks to assess the effectiveness of some popular graph explainers.
        ]]></description>
    </item>
    <item>
        <title>Learning to Play Like Humans: A Framework for LLM Adaptation in Interactive Fiction Games</title>
        <link>https://arxiv.org/abs/2505.12439</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12439v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jinming Zhang, Yunfei Long</dc:creator>
        <description><![CDATA[
            背景：交互式小说游戏中，现有方法重特定任务表现，轻对叙事背景和游戏逻辑的类人理解。方法：提出类人学习游玩（LPLH）框架，整合结构化地图构建、动作学习和反馈驱动的经验分析三个关键组件，使基于大语言模型的智能体行为与叙事意图和常识约束对齐。效果：超越纯探索策略，实现更具可解释性的类人表现，将交互式小说游戏挑战转化为学习问题，为复杂文本环境中的游戏玩法提供新路径。
            arXiv:2505.12439v1 Announce Type: new 
Abstract: Interactive Fiction games (IF games) are where players interact through natural language commands. While recent advances in Artificial Intelligence agents have reignited interest in IF games as a domain for studying decision-making, existing approaches prioritize task-specific performance metrics over human-like comprehension of narrative context and gameplay logic. This work presents a cognitively inspired framework that guides Large Language Models (LLMs) to learn and play IF games systematically. Our proposed **L**earning to **P**lay **L**ike **H**umans (LPLH) framework integrates three key components: (1) structured map building to capture spatial and narrative relationships, (2) action learning to identify context-appropriate commands, and (3) feedback-driven experience analysis to refine decision-making over time. By aligning LLMs-based agents' behavior with narrative intent and commonsense constraints, LPLH moves beyond purely exploratory strategies to deliver more interpretable, human-like performance. Crucially, this approach draws on cognitive science principles to more closely simulate how human players read, interpret, and respond within narrative worlds. As a result, LPLH reframes the IF games challenge as a learning problem for LLMs-based agents, offering a new path toward robust, context-aware gameplay in complex text-based environments.
        ]]></description>
    </item>
    <item>
        <title>Enhancing Large Language Models with Reward-guided Tree Search for Knowledge Graph Question and Answering</title>
        <link>https://arxiv.org/abs/2505.12476</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12476v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiao Long, Liansheng Zhuang, Chen Shen, Shaotian Yan, Yifei Li, Shafei Wang</dc:creator>
        <description><![CDATA[
            背景：现有基于大语言模型的知识图谱问答（KGQA）方法遵循GraphRAG范式，存在忽视历史推理路径、检索不准确等问题。方法：提出无训练框架RTSoG，将原问题分解为子问题处理复杂语义，引入奖励模型引导的SC - MCTS迭代检索加权推理路径作为上下文知识，按权重堆叠生成最终答案。效果：在四个数据集上实验有效，在GrailQA和WebQSP上比现有最优方法分别提升8.7%和7.0%。
            arXiv:2505.12476v1 Announce Type: new 
Abstract: Recently, large language models (LLMs) have demonstrated impressive performance in Knowledge Graph Question Answering (KGQA) tasks, which aim to find answers based on knowledge graphs (KGs) for natural language questions. Existing LLMs-based KGQA methods typically follow the Graph Retrieval-Augmented Generation (GraphRAG) paradigm, which first retrieves reasoning paths from the large KGs, and then generates the answers based on them. However, these methods emphasize the exploration of new optimal reasoning paths in KGs while ignoring the exploitation of historical reasoning paths, which may lead to sub-optimal reasoning paths. Additionally, the complex semantics contained in questions may lead to the retrieval of inaccurate reasoning paths. To address these issues, this paper proposes a novel and training-free framework for KGQA tasks called Reward-guided Tree Search on Graph (RTSoG). RTSoG decomposes an original question into a series of simpler and well-defined sub-questions to handle the complex semantics. Then, a Self-Critic Monte Carlo Tree Search (SC-MCTS) guided by a reward model is introduced to iteratively retrieve weighted reasoning paths as contextual knowledge. Finally, it stacks the weighted reasoning paths according to their weights to generate the final answers. Extensive experiments on four datasets demonstrate the effectiveness of RTSoG. Notably, it achieves 8.7\% and 7.0\% performance improvement over the state-of-the-art method on the GrailQA and the WebQSP respectively.
        ]]></description>
    </item>
    <item>
        <title>KG-QAGen: A Knowledge-Graph-Based Framework for Systematic Question Generation and Long-Context LLM Evaluation</title>
        <link>https://arxiv.org/abs/2505.12495</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12495v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Nikita Tatarinov, Vidhyakshaya Kannan, Haricharana Srinivasa, Arnav Raj, Harpreet Singh Anand, Varun Singh, Aditya Luthra, Ravij Lade, Agam Shah, Sudheer Chava</dc:creator>
        <description><![CDATA[
            背景：现代语言模型上下文长度增加，现有基准测试缺乏系统改变问题复杂度的方法来评估模型长文本信息处理能力。方法：提出KG - QAGen框架，利用金融协议的结构化表示，从多跳检索、集合操作和答案多样性三个维度提取不同复杂度的问答对。效果：构建了含20139个问答对的数据集，评估13个大模型，发现即使表现最佳的模型在集合比较和多跳逻辑推理上也存在困难，分析揭示了语义误解和处理隐含关系能力不足等问题。
            arXiv:2505.12495v1 Announce Type: new 
Abstract: The increasing context length of modern language models has created a need for evaluating their ability to retrieve and process information across extensive documents. While existing benchmarks test long-context capabilities, they often lack a structured way to systematically vary question complexity. We introduce KG-QAGen (Knowledge-Graph-based Question-Answer Generation), a framework that (1) extracts QA pairs at multiple complexity levels (2) by leveraging structured representations of financial agreements (3) along three key dimensions -- multi-hop retrieval, set operations, and answer plurality -- enabling fine-grained assessment of model performance across controlled difficulty levels. Using this framework, we construct a dataset of 20,139 QA pairs (the largest number among the long-context benchmarks) and open-source a part of it. We evaluate 13 proprietary and open-source LLMs and observe that even the best-performing models are struggling with set-based comparisons and multi-hop logical inference. Our analysis reveals systematic failure modes tied to semantic misinterpretation and inability to handle implicit relations.
        ]]></description>
    </item>
    <item>
        <title>Reasoning by Superposition: A Theoretical Perspective on Chain of Continuous Thought</title>
        <link>https://arxiv.org/abs/2505.12514</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12514v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hanlin Zhu, Shibo Hao, Zhiting Hu, Jiantao Jiao, Stuart Russell, Yuandong Tian</dc:creator>
        <description><![CDATA[
            背景：大语言模型通过思维链技术在推理问题上表现出色，但连续思维链在图推理任务中优于离散思维链缺乏理论解释。方法：证明具有D步连续思维链的两层Transformer能解决有向图可达性问题，连续思维向量是同时编码多个搜索前沿的叠加态。效果：离散思维链需$O(n^2)$解码步骤，而连续思维链仅需D步（D为图直径且$D < n$），实验验证理论构建与训练结果相符，且训练中自动出现多搜索前沿叠加态编码。
            arXiv:2505.12514v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have demonstrated remarkable performance in many applications, including challenging reasoning problems via chain-of-thoughts (CoTs) techniques that generate ``thinking tokens'' before answering the questions. While existing theoretical works demonstrate that CoTs with discrete tokens boost the capability of LLMs, recent work on continuous CoTs lacks a theoretical understanding of why it outperforms discrete counterparts in various reasoning tasks such as directed graph reachability, a fundamental graph reasoning problem that includes many practical domain applications as special cases. In this paper, we prove that a two-layer transformer with $D$ steps of continuous CoTs can solve the directed graph reachability problem, where $D$ is the diameter of the graph, while the best known result of constant-depth transformers with discrete CoTs requires $O(n^2)$ decoding steps where $n$ is the number of vertices ($D<n$). In our construction, each continuous thought vector is a superposition state that encodes multiple search frontiers simultaneously (i.e., parallel breadth-first search (BFS)), while discrete CoTs must choose a single path sampled from the superposition state, which leads to sequential search that requires many more steps and may be trapped into local solutions. We also performed extensive experiments to verify that our theoretical construction aligns well with the empirical solution obtained via training dynamics. Notably, encoding of multiple search frontiers as a superposition state automatically emerges in training continuous CoTs, without explicit supervision to guide the model to explore multiple paths simultaneously.
        ]]></description>
    </item>
    <item>
        <title>Never Skip a Batch: Continuous Training of Temporal GNNs via Adaptive Pseudo-Supervision</title>
        <link>https://arxiv.org/abs/2505.12526</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12526v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Alexander Panyshev, Dmitry Vinichenko, Oleg Travkin, Roman Alferov, Alexey Zaytsev</dc:creator>
        <description><![CDATA[
            背景：时态图网络（TGNs）虽准确，但动态图中不规则监督信号导致梯度更新稀疏，训练效率低。方法：理论证明将历史节点交互聚合为伪标签可降低梯度方差、加速收敛，提出历史平均标签（HAL）方法，用历史标签分布生成的伪目标动态丰富训练批次，将闲置计算转化为有效学习步骤。效果：在时态图基准（TGB）实验中，HAL可将TGNv2训练速度提升达15倍，且性能有竞争力，为时态图学习中标签稀疏问题提供有效解决方案。
            arXiv:2505.12526v1 Announce Type: new 
Abstract: Temporal Graph Networks (TGNs), while being accurate, face significant training inefficiencies due to irregular supervision signals in dynamic graphs, which induce sparse gradient updates. We first theoretically establish that aggregating historical node interactions into pseudo-labels reduces gradient variance, accelerating convergence. Building on this analysis, we propose History-Averaged Labels (HAL), a method that dynamically enriches training batches with pseudo-targets derived from historical label distributions. HAL ensures continuous parameter updates without architectural modifications by converting idle computation into productive learning steps. Experiments on the Temporal Graph Benchmark (TGB) validate our findings and an assumption about slow change of user preferences: HAL accelerates TGNv2 training by up to 15x while maintaining competitive performance. Thus, this work offers an efficient, lightweight, architecture-agnostic, and theoretically motivated solution to label sparsity in temporal graph learning.
        ]]></description>
    </item>
    <item>
        <title>Towards Reliable and Interpretable Traffic Crash Pattern Prediction and Safety Interventions Using Customized Large Language Models</title>
        <link>https://arxiv.org/abs/2505.12545</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12545v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yang Zhao (Frank), Pu Wang (Frank), Yibo Zhao (Frank), Hongru Du (Frank),  Hao (Frank),  Yang</dc:creator>
        <description><![CDATA[
            背景：现有方法难以解读交通事故数据复杂关系，无法捕捉丰富语义和关联，限制了识别关键风险因素的能力。方法：提出TrafficSafe框架，将大语言模型用于重构事故预测和特征归因，收集多模态事故数据集并文本化，定制微调大语言模型，还引入TrafficSafe Attribution进行特征归因。效果：TrafficSafe大语言模型F1分数较基线平均提升42%，能识别出酒驾是严重事故主因，还可指导数据收集以提升性能。
            arXiv:2505.12545v1 Announce Type: new 
Abstract: Predicting crash events is crucial for understanding crash distributions and their contributing factors, thereby enabling the design of proactive traffic safety policy interventions. However, existing methods struggle to interpret the complex interplay among various sources of traffic crash data, including numeric characteristics, textual reports, crash imagery, environmental conditions, and driver behavior records. As a result, they often fail to capture the rich semantic information and intricate interrelationships embedded in these diverse data sources, limiting their ability to identify critical crash risk factors. In this research, we propose TrafficSafe, a framework that adapts LLMs to reframe crash prediction and feature attribution as text-based reasoning. A multi-modal crash dataset including 58,903 real-world reports together with belonged infrastructure, environmental, driver, and vehicle information is collected and textualized into TrafficSafe Event Dataset. By customizing and fine-tuning LLMs on this dataset, the TrafficSafe LLM achieves a 42% average improvement in F1-score over baselines. To interpret these predictions and uncover contributing factors, we introduce TrafficSafe Attribution, a sentence-level feature attribution framework enabling conditional risk analysis. Findings show that alcohol-impaired driving is the leading factor in severe crashes, with aggressive and impairment-related behaviors having nearly twice the contribution for severe crashes compared to other driver behaviors. Furthermore, TrafficSafe Attribution highlights pivotal features during model training, guiding strategic crash data collection for iterative performance improvements. The proposed TrafficSafe offers a transformative leap in traffic safety research, providing a blueprint for translating advanced AI technologies into responsible, actionable, and life-saving outcomes.
        ]]></description>
    </item>
    <item>
        <title>Know3-RAG: A Knowledge-aware RAG Framework with Adaptive Retrieval, Generation, and Filtering</title>
        <link>https://arxiv.org/abs/2505.12662</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12662v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xukai Liu, Ye Liu, Shiwen Wu, Yanghai Zhang, Yihao Yuan, Kai Zhang, Qi Liu</dc:creator>
        <description><![CDATA[
            背景：大语言模型在自然语言生成中进步显著，但易产生幻觉内容，现有RAG系统存在外部知识监督有限和参考不准确等问题。方法：提出Know3 - RAG框架，利用知识图谱的结构化知识指导RAG的检索、生成和过滤阶段，引入知识感知自适应检索模块、知识增强参考生成策略和知识驱动参考过滤机制。效果：在多个开放领域问答基准测试中，该框架优于基线模型，显著减少幻觉内容，提高答案可靠性。
            arXiv:2505.12662v1 Announce Type: new 
Abstract: Recent advances in large language models (LLMs) have led to impressive progress in natural language generation, yet their tendency to produce hallucinated or unsubstantiated content remains a critical concern. To improve factual reliability, Retrieval-Augmented Generation (RAG) integrates external knowledge during inference. However, existing RAG systems face two major limitations: (1) unreliable adaptive control due to limited external knowledge supervision, and (2) hallucinations caused by inaccurate or irrelevant references. To address these issues, we propose Know3-RAG, a knowledge-aware RAG framework that leverages structured knowledge from knowledge graphs (KGs) to guide three core stages of the RAG process, including retrieval, generation, and filtering. Specifically, we introduce a knowledge-aware adaptive retrieval module that employs KG embedding to assess the confidence of the generated answer and determine retrieval necessity, a knowledge-enhanced reference generation strategy that enriches queries with KG-derived entities to improve generated reference relevance, and a knowledge-driven reference filtering mechanism that ensures semantic alignment and factual accuracy of references. Experiments on multiple open-domain QA benchmarks demonstrate that Know3-RAG consistently outperforms strong baselines, significantly reducing hallucinations and enhancing answer reliability.
        ]]></description>
    </item>
    <item>
        <title>Towards Effective Federated Graph Foundation Model via Mitigating Knowledge Entanglement</title>
        <link>https://arxiv.org/abs/2505.12684</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12684v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yinlin Zhu, Xunkai Li, Jishuo Jia, Miao Hu, Di Wu, Meikang Qiu</dc:creator>
        <description><![CDATA[
            背景：图机器学习发展至以数据为中心的范式，联邦图学习（FGL）存在数据和任务异质性挑战，图基础模型（GFM）通常单机训练，二者互补。方法：提出FedGFM+框架，含两个核心模块，AncDAI是基于全局锚点的域感知初始化策略，AdaDPP是局部自适应域敏感提示池。效果：在8个跨多领域和任务的基准测试中评估，优于20个来自监督学习、FGL和联邦GFM变体的基线模型。
            arXiv:2505.12684v1 Announce Type: new 
Abstract: Recent advances in graph machine learning have shifted to data-centric paradigms, driven by two emerging fields: (1) Federated graph learning (FGL) enables multi-client collaboration but faces challenges from data and task heterogeneity, limiting its practicality; (2) Graph foundation models (GFM) offer strong domain generalization but are usually trained on single machines, missing out on cross-silo data and resources.
  These paradigms are complementary, and their integration brings notable benefits. Motivated by this, we propose FedGFM, a novel decentralized GFM training paradigm. However, a key challenge is knowledge entanglement, where multi-domain knowledge merges into indistinguishable representations, hindering downstream adaptation.
  To address this, we present FedGFM+, an enhanced framework with two core modules to reduce knowledge entanglement: (1) AncDAI: A global anchor-based domain-aware initialization strategy. Before pre-training, each client encodes its local graph into domain-specific prototypes that serve as semantic anchors. Synthetic embeddings around these anchors initialize the global model. We theoretically prove these prototypes are distinguishable across domains, providing a strong inductive bias to disentangle domain-specific knowledge. (2) AdaDPP: A local adaptive domain-sensitive prompt pool. Each client learns a lightweight graph prompt capturing domain semantics during pre-training. During fine-tuning, prompts from all clients form a pool from which the GFM selects relevant prompts to augment target graph attributes, improving downstream adaptation.
  FedGFM+ is evaluated on 8 diverse benchmarks across multiple domains and tasks, outperforming 20 baselines from supervised learning, FGL, and federated GFM variants.
        ]]></description>
    </item>
    <item>
        <title>TACOcc:Target-Adaptive Cross-Modal Fusion with Volume Rendering for 3D Semantic Occupancy</title>
        <link>https://arxiv.org/abs/2505.12693</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12693v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Luyao Lei, Shuo Xu, Yifan Bai, Xing Wei</dc:creator>
        <description><![CDATA[
            多模态3D占用预测受融合效果不佳限制，原因包括固定融合策略导致的几何语义不匹配、稀疏嘈杂标注造成的表面细节丢失。为此提出目标尺度自适应的双向对称检索机制，根据目标大小调整邻域，实现准确的跨模态特征对齐；针对表面细节丢失，引入基于3D高斯溅射的改进体渲染管道，以融合特征渲染图像，施加光度一致性监督。提出自适应多模态融合框架TACOcc，经nuScenes和SemanticKITTI基准测试验证了有效性。
            arXiv:2505.12693v1 Announce Type: new 
Abstract: The performance of multi-modal 3D occupancy prediction is limited by ineffective fusion, mainly due to geometry-semantics mismatch from fixed fusion strategies and surface detail loss caused by sparse, noisy annotations. The mismatch stems from the heterogeneous scale and distribution of point cloud and image features, leading to biased matching under fixed neighborhood fusion. To address this, we propose a target-scale adaptive, bidirectional symmetric retrieval mechanism. It expands the neighborhood for large targets to enhance context awareness and shrinks it for small ones to improve efficiency and suppress noise, enabling accurate cross-modal feature alignment. This mechanism explicitly establishes spatial correspondences and improves fusion accuracy. For surface detail loss, sparse labels provide limited supervision, resulting in poor predictions for small objects. We introduce an improved volume rendering pipeline based on 3D Gaussian Splatting, which takes fused features as input to render images, applies photometric consistency supervision, and jointly optimizes 2D-3D consistency. This enhances surface detail reconstruction while suppressing noise propagation. In summary, we propose TACOcc, an adaptive multi-modal fusion framework for 3D semantic occupancy prediction, enhanced by volume rendering supervision. Experiments on the nuScenes and SemanticKITTI benchmarks validate its effectiveness.
        ]]></description>
    </item>
    <item>
        <title>SpatialLLM: From Multi-modality Data to Urban Spatial Intelligence</title>
        <link>https://arxiv.org/abs/2505.12703</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12703v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiabin Chen, Haiping Wang, Jinpeng Li, Yuan Liu, Zhen Dong, Bisheng Yang</dc:creator>
        <description><![CDATA[
            背景：现有方法处理复杂城市场景空间智能任务需地理分析工具或领域专业知识。方法：提出SpatialLLM，它是统一语言模型，能直接处理多种空间智能任务，核心是从原始空间数据构建详细结构化场景描述，以提示预训练大语言模型进行场景分析。效果：大量实验表明，经此设计，预训练大语言模型能准确感知空间分布信息，实现零样本执行城市规划、生态分析等高级空间智能任务。
            arXiv:2505.12703v1 Announce Type: new 
Abstract: We propose SpatialLLM, a novel approach advancing spatial intelligence tasks in complex urban scenes. Unlike previous methods requiring geographic analysis tools or domain expertise, SpatialLLM is a unified language model directly addressing various spatial intelligence tasks without any training, fine-tuning, or expert intervention. The core of SpatialLLM lies in constructing detailed and structured scene descriptions from raw spatial data to prompt pre-trained LLMs for scene-based analysis. Extensive experiments show that, with our designs, pretrained LLMs can accurately perceive spatial distribution information and enable zero-shot execution of advanced spatial intelligence tasks, including urban planning, ecological analysis, traffic management, etc. We argue that multi-field knowledge, context length, and reasoning ability are key factors influencing LLM performances in urban analysis. We hope that SpatialLLM will provide a novel viable perspective for urban intelligent analysis and management. The code and dataset are available at https://github.com/WHU-USI3DV/SpatialLLM.
        ]]></description>
    </item>
    <item>
        <title>ToTRL: Unlock LLM Tree-of-Thoughts Reasoning Potential through Puzzles Solving</title>
        <link>https://arxiv.org/abs/2505.12717</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12717v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Haoyuan Wu, Xueyi Chen, Rui Ming, Jilong Gao, Shoubo Hu, Zhuolun He, Bei Yu</dc:creator>
        <description><![CDATA[
            背景：大语言模型虽有推理能力，但长思维链推理存在输出冗长、推理不系统等局限，树状思维（ToT）是更优方法。方法：提出基于规则奖励的树状思维强化学习（ToTRL）框架，引导大模型在顺序思维链策略基础上发展并行ToT策略，在训练中让大模型玩解谜游戏培养ToT推理能力。效果：经ToTRL训练的ToTQwen3 - 8B模型在复杂推理任务中性能和推理效率显著提升。
            arXiv:2505.12717v1 Announce Type: new 
Abstract: Large language models (LLMs) demonstrate significant reasoning capabilities, particularly through long chain-of-thought (CoT) processes, which can be elicited by reinforcement learning (RL). However, prolonged CoT reasoning presents limitations, primarily verbose outputs due to excessive introspection. The reasoning process in these LLMs often appears to follow a trial-and-error methodology rather than a systematic, logical deduction. In contrast, tree-of-thoughts (ToT) offers a conceptually more advanced approach by modeling reasoning as an exploration within a tree structure. This reasoning structure facilitates the parallel generation and evaluation of multiple reasoning branches, allowing for the active identification, assessment, and pruning of unproductive paths. This process can potentially lead to improved performance and reduced token costs. Building upon the long CoT capability of LLMs, we introduce tree-of-thoughts RL (ToTRL), a novel on-policy RL framework with a rule-based reward. ToTRL is designed to guide LLMs in developing the parallel ToT strategy based on the sequential CoT strategy. Furthermore, we employ LLMs as players in a puzzle game during the ToTRL training process. Solving puzzle games inherently necessitates exploring interdependent choices and managing multiple constraints, which requires the construction and exploration of a thought tree, providing challenging tasks for cultivating the ToT reasoning capability. Our empirical evaluations demonstrate that our ToTQwen3-8B model, trained with our ToTRL, achieves significant improvement in performance and reasoning efficiency on complex reasoning tasks.
        ]]></description>
    </item>
    <item>
        <title>Enhancing Channel-Independent Time-Series Forecasting via Cross-Variate Patch Embedding</title>
        <link>https://arxiv.org/abs/2505.12761</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12761v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Donghwa Shin, Edwin Zhang</dc:creator>
        <description><![CDATA[
            背景：Transformer在时间序列预测中流行，但现有模型多只关注时间依赖，忽略变量间复杂关系，且全层依赖通道，易过拟合。方法：提出轻量级通道依赖模块Cross-Variate Patch Embeddings（CVPE），通过修改补丁嵌入过程将跨变量上下文注入通道独立模型，在普通补丁嵌入层添加可学习位置编码和轻量级路由注意力块，并将其集成到多模态通道独立预测模型Time-LLM中。效果：在七个真实数据集上，集成CVPE的Time-LLM优于原基线模型。
            arXiv:2505.12761v1 Announce Type: new 
Abstract: Transformers have recently gained popularity in time series forecasting due to their ability to capture long-term dependencies. However, many existing models focus only on capturing temporal dependencies while omitting intricate relationships between variables. Recent models have tried tackling this by explicitly modeling both cross-time and cross-variate dependencies through a sequential or unified attention mechanism, but they are entirely channel dependent (CD) across all layers, making them potentially susceptible to overfitting. To address this, we propose Cross-Variate Patch Embeddings (CVPE), a lightweight CD module that injects cross-variate context into channel-independent (CI) models by simply modifying the patch embedding process. We achieve this by adding a learnable positional encoding and a lightweight router-attention block to the vanilla patch embedding layer. We then integrate CVPE into Time-LLM, a multimodal CI forecasting model, to demonstrate its effectiveness in capturing cross-variate dependencies and enhance the CI model's performance. Extensive experimental results on seven real-world datasets show that our enhanced Time-LLM outperforms the original baseline model simply by incorporating the CVPE module, with no other changes.
        ]]></description>
    </item>
    <item>
        <title>ReEx-SQL: Reasoning with Execution-Aware Reinforcement Learning for Text-to-SQL</title>
        <link>https://arxiv.org/abs/2505.12768</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12768v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yaxun Dai (Soochow University), Wenxuan Xie (South China University of Technology), Xialie Zhuang (University of Chinese Academy of Sciences), Tianyu Yang (Alibaba DAMO Academy), Yiying Yang (Guangdong Laboratory of Artificial Intelligence and Digital Economy), Haiqin Yang (International Digital Economy Academy), Yuhang Zhao (Guangdong Laboratory of Artificial Intelligence and Digital Economy), Pingfu Chao (Soochow University), Wenhao Jiang (Guangdong Laboratory of Artificial Intelligence and Digital Economy)</dc:creator>
        <description><![CDATA[
            在文本到SQL任务中，现有方法将执行反馈仅作为事后修正信号，未融入生成过程，影响查询准确性和鲁棒性。为此提出ReEx - SQL框架，让模型在解码时与数据库交互，基于执行反馈动态调整推理。该框架采用执行感知推理范式，通过带标记的结构化提示和逐步展开策略，将执行反馈融入生成各阶段。还开发复合奖励函数监督策略学习，采用树型解码策略支持探索性推理。在Spider、BIRD等数据集上效果显著，超越基线，且推理时间减少51.9%。
            arXiv:2505.12768v1 Announce Type: new 
Abstract: In Text-to-SQL, execution feedback is essential for guiding large language models (LLMs) to reason accurately and generate reliable SQL queries. However, existing methods treat execution feedback solely as a post-hoc signal for correction or selection, failing to integrate it into the generation process. This limitation hinders their ability to address reasoning errors as they occur, ultimately reducing query accuracy and robustness. To address this issue, we propose ReEx-SQL (Reasoning with Execution-Aware Reinforcement Learning), a framework for Text-to-SQL that enables models to interact with the database during decoding and dynamically adjust their reasoning based on execution feedback. ReEx-SQL introduces an execution-aware reasoning paradigm that interleaves intermediate SQL execution into reasoning paths, facilitating context-sensitive revisions. It achieves this through structured prompts with markup tags and a stepwise rollout strategy that integrates execution feedback into each stage of generation. To supervise policy learning, we develop a composite reward function that includes an exploration reward, explicitly encouraging effective database interaction. Additionally, ReEx-SQL adopts a tree-based decoding strategy to support exploratory reasoning, enabling dynamic expansion of alternative reasoning paths. Notably, ReEx-SQL achieves 88.8% on Spider and 64.9% on BIRD at the 7B scale, surpassing the standard reasoning baseline by 2.7% and 2.6%, respectively. It also shows robustness, achieving 85.2% on Spider-Realistic with leading performance. In addition, its tree-structured decoding improves efficiency and performance over linear decoding, reducing inference time by 51.9% on the BIRD development set.
        ]]></description>
    </item>
    <item>
        <title>FlightGPT: Towards Generalizable and Interpretable UAV Vision-and-Language Navigation with Vision-Language Models</title>
        <link>https://arxiv.org/abs/2505.12835</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12835v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hengxing Cai, Jinhan Dong, Jingjun Tan, Jingcheng Deng, Sihang Li, Zhifeng Gao, Haidong Wang, Zicheng Su, Agachai Sumalee, Renxin Zhong</dc:creator>
        <description><![CDATA[
            背景：无人机视觉语言导航（VLN）应用广泛，但现有方法存在多模态融合不足、泛化性弱和可解释性差等问题。方法：提出FlightGPT框架，采用两阶段训练策略，先进行监督微调提升初始化和结构化推理能力，再用组相对策略优化算法增强泛化和适应性，还引入基于思维链的推理机制提高决策可解释性。效果：在CityNav数据集上表现出色，在所有场景达到最优，在未见环境中成功率比最强基线高9.22%。
            arXiv:2505.12835v1 Announce Type: new 
Abstract: Unmanned Aerial Vehicle (UAV) Vision-and-Language Navigation (VLN) is vital for applications such as disaster response, logistics delivery, and urban inspection. However, existing methods often struggle with insufficient multimodal fusion, weak generalization, and poor interpretability. To address these challenges, we propose FlightGPT, a novel UAV VLN framework built upon Vision-Language Models (VLMs) with powerful multimodal perception capabilities. We design a two-stage training pipeline: first, Supervised Fine-Tuning (SFT) using high-quality demonstrations to improve initialization and structured reasoning; then, Group Relative Policy Optimization (GRPO) algorithm, guided by a composite reward that considers goal accuracy, reasoning quality, and format compliance, to enhance generalization and adaptability. Furthermore, FlightGPT introduces a Chain-of-Thought (CoT)-based reasoning mechanism to improve decision interpretability. Extensive experiments on the city-scale dataset CityNav demonstrate that FlightGPT achieves state-of-the-art performance across all scenarios, with a 9.22\% higher success rate than the strongest baseline in unseen environments. Our implementation is publicly available.
        ]]></description>
    </item>
    <item>
        <title>The Hidden Structure -- Improving Legal Document Understanding Through Explicit Text Formatting</title>
        <link>https://arxiv.org/abs/2505.12837</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12837v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Christian Braun, Alexander Lilienbeck, Daniel Mentjukov</dc:creator>
        <description><![CDATA[
            背景：法律合同的结构对人类理解至关重要，但对大语言模型处理的影响研究不足。方法：用CUAD节选进行法律问答任务，对比GPT - 4o和GPT - 4.1在不同输入格式下的精确匹配准确率，还评估了提示工程的影响。效果：GPT - 4o对输入结构变化较稳健但整体性能欠佳；GPT - 4.1性能敏感，结构良好的输入使精确匹配准确率提高约20个百分点，优化系统提示再提升约10 - 13个百分点，Markdown格式下整体精确匹配准确率达79%。
            arXiv:2505.12837v1 Announce Type: new 
Abstract: Legal contracts possess an inherent, semantically vital structure (e.g., sections, clauses) that is crucial for human comprehension but whose impact on LLM processing remains under-explored. This paper investigates the effects of explicit input text structure and prompt engineering on the performance of GPT-4o and GPT-4.1 on a legal question-answering task using an excerpt of the CUAD. We compare model exact-match accuracy across various input formats: well-structured plain-text (human-generated from CUAD), plain-text cleaned of line breaks, extracted plain-text from Azure OCR, plain-text extracted by GPT-4o Vision, and extracted (and interpreted) Markdown (MD) from GPT-4o Vision. To give an indication of the impact of possible prompt engineering, we assess the impact of shifting task instructions to the system prompt and explicitly informing the model about the structured nature of the input. Our findings reveal that GPT-4o demonstrates considerable robustness to variations in input structure, but lacks in overall performance. Conversely, GPT-4.1's performance is markedly sensitive; poorly structured inputs yield suboptimal results (but identical with GPT-4o), while well-structured formats (original CUAD text, GPT-4o Vision text and GPT-4o MD) improve exact-match accuracy by ~20 percentage points. Optimizing the system prompt to include task details and an advisory about structured input further elevates GPT-4.1's accuracy by an additional ~10-13 percentage points, with Markdown ultimately achieving the highest performance under these conditions (79 percentage points overall exact-match accuracy). This research empirically demonstrates that while newer models exhibit greater resilience, careful input structuring and strategic prompt design remain critical for optimizing the performance of LLMs, and can significantly affect outcomes in high-stakes legal applications.
        ]]></description>
    </item>
    <item>
        <title>GAP: Graph-Assisted Prompts for Dialogue-based Medication Recommendation</title>
        <link>https://arxiv.org/abs/2505.12888</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12888v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jialun Zhong, Yanzeng Li, Sen Hu, Yang Zhang, Teng Xu, Lei Zou</dc:creator>
        <description><![CDATA[
            在医疗领域，基于对话的药物推荐对医疗对话系统的准确性和安全性至关重要。大语言模型虽可提供医疗建议，但多轮对话中会忽略细粒度信息、缺乏领域知识时会生成非事实回复。为此，提出Graph - Assisted Prompts（GAP）框架。该框架从对话中提取医疗概念和状态构建以患者为中心的图，结合外部医疗知识图谱生成查询和提示，从多源检索信息。实验表明，相比强基线模型，GAP在药物推荐数据集及动态诊断访谈场景中表现出色。
            arXiv:2505.12888v1 Announce Type: new 
Abstract: Medication recommendations have become an important task in the healthcare domain, especially in measuring the accuracy and safety of medical dialogue systems (MDS). Different from the recommendation task based on electronic health records (EHRs), dialogue-based medication recommendations require research on the interaction details between patients and doctors, which is crucial but may not exist in EHRs. Recent advancements in large language models (LLM) have extended the medical dialogue domain. These LLMs can interpret patients' intent and provide medical suggestions including medication recommendations, but some challenges are still worth attention. During a multi-turn dialogue, LLMs may ignore the fine-grained medical information or connections across the dialogue turns, which is vital for providing accurate suggestions. Besides, LLMs may generate non-factual responses when there is a lack of domain-specific knowledge, which is more risky in the medical domain. To address these challenges, we propose a \textbf{G}raph-\textbf{A}ssisted \textbf{P}rompts (\textbf{GAP}) framework for dialogue-based medication recommendation. It extracts medical concepts and corresponding states from dialogue to construct an explicitly patient-centric graph, which can describe the neglected but important information. Further, combined with external medical knowledge graphs, GAP can generate abundant queries and prompts, thus retrieving information from multiple sources to reduce the non-factual responses. We evaluate GAP on a dialogue-based medication recommendation dataset and further explore its potential in a more difficult scenario, dynamically diagnostic interviewing. Extensive experiments demonstrate its competitive performance when compared with strong baselines.
        ]]></description>
    </item>
    <item>
        <title>ORQA: A Benchmark and Foundation Model for Holistic Operating Room Modeling</title>
        <link>https://arxiv.org/abs/2505.12890</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12890v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ege \"Ozsoy, Chantal Pellegrini, David Bani-Harouni, Kun Yuan, Matthias Keicher, Nassir Navab</dc:creator>
        <description><![CDATA[
            背景：手术的复杂性要求计算系统对手术室有全面理解，以往工作多为单任务且缺乏泛化性。方法：提出ORQA基准和基础多模态模型，将四个公开手术室数据集统一为综合基准，多模态大模型融合视觉、听觉和结构化数据进行手术室整体建模，还提出渐进式知识蒸馏范式生成不同性能需求的模型。效果：ORQA在提出的基准上表现出色，具备零样本泛化能力，推动了多模态手术智能发展。
            arXiv:2505.12890v1 Announce Type: new 
Abstract: The real-world complexity of surgeries necessitates surgeons to have deep and holistic comprehension to ensure precision, safety, and effective interventions. Computational systems are required to have a similar level of comprehension within the operating room. Prior works, limited to single-task efforts like phase recognition or scene graph generation, lack scope and generalizability. In this work, we introduce ORQA, a novel OR question answering benchmark and foundational multimodal model to advance OR intelligence. By unifying all four public OR datasets into a comprehensive benchmark, we enable our approach to concurrently address a diverse range of OR challenges. The proposed multimodal large language model fuses diverse OR signals such as visual, auditory, and structured data, for a holistic modeling of the OR. Finally, we propose a novel, progressive knowledge distillation paradigm, to generate a family of models optimized for different speed and memory requirements. We show the strong performance of ORQA on our proposed benchmark, and its zero-shot generalization, paving the way for scalable, unified OR modeling and significantly advancing multimodal surgical intelligence. We will release our code and data upon acceptance.
        ]]></description>
    </item>
    <item>
        <title>On the Thinking-Language Modeling Gap in Large Language Models</title>
        <link>https://arxiv.org/abs/2505.12896</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12896v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chenxi Liu, Yongqiang Chen, Tongliang Liu, James Cheng, Bo Han, Kun Zhang</dc:creator>
        <description><![CDATA[
            背景：人类通过思维语言进行系统2推理，虽大语言模型可被激发系统2推理能力，但语言建模和思维建模存在显著差距，语言偏差会误导模型。方法：提出名为思维语言（LoT）的提示技术，指导大语言模型调整相关信息表达的顺序和标记。效果：该简单策略显著减少了大语言模型中的语言建模偏差，提升了其在多种推理任务上的表现。
            arXiv:2505.12896v1 Announce Type: new 
Abstract: System 2 reasoning is one of the defining characteristics of intelligence, which requires slow and logical thinking. Human conducts System 2 reasoning via the language of thoughts that organizes the reasoning process as a causal sequence of mental language, or thoughts. Recently, it has been observed that System 2 reasoning can be elicited from Large Language Models (LLMs) pre-trained on large-scale natural languages. However, in this work, we show that there is a significant gap between the modeling of languages and thoughts. As language is primarily a tool for humans to share knowledge and thinking, modeling human language can easily absorb language biases into LLMs deviated from the chain of thoughts in minds. Furthermore, we show that the biases will mislead the eliciting of "thoughts" in LLMs to focus only on a biased part of the premise. To this end, we propose a new prompt technique termed Language-of-Thoughts (LoT) to demonstrate and alleviate this gap. Instead of directly eliciting the chain of thoughts from partial information, LoT instructs LLMs to adjust the order and token used for the expressions of all the relevant information. We show that the simple strategy significantly reduces the language modeling biases in LLMs and improves the performance of LLMs across a variety of reasoning tasks.
        ]]></description>
    </item>
    <item>
        <title>SourceDetMamba: A Graph-aware State Space Model for Source Detection in Sequential Hypergraphs</title>
        <link>https://arxiv.org/abs/2505.12910</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12910v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Le Cheng, Peican Zhu, Yangming Guo, Chao Gao, Zhen Wang, Keke Tang</dc:creator>
        <description><![CDATA[
            背景：图上的源检测在识别谣言源头方面很有效，但很多基于机器学习的方法难以捕捉谣言传播的内在动态。方法：提出SourceDetMamba，利用状态空间模型Mamba的全局建模和计算效率优势，先用超图建模社交网络高阶交互，将传播过程的时间网络快照逆序输入Mamba推断传播动态，还提出图感知状态更新机制。效果：在八个数据集上的评估表明，SourceDetMamba始终优于现有方法。
            arXiv:2505.12910v1 Announce Type: new 
Abstract: Source detection on graphs has demonstrated high efficacy in identifying rumor origins. Despite advances in machine learning-based methods, many fail to capture intrinsic dynamics of rumor propagation. In this work, we present SourceDetMamba: A Graph-aware State Space Model for Source Detection in Sequential Hypergraphs, which harnesses the recent success of the state space model Mamba, known for its superior global modeling capabilities and computational efficiency, to address this challenge. Specifically, we first employ hypergraphs to model high-order interactions within social networks. Subsequently, temporal network snapshots generated during the propagation process are sequentially fed in reverse order into Mamba to infer underlying propagation dynamics. Finally, to empower the sequential model to effectively capture propagation patterns while integrating structural information, we propose a novel graph-aware state update mechanism, wherein the state of each node is propagated and refined by both temporal dependencies and topological context. Extensive evaluations on eight datasets demonstrate that SourceDetMamba consistently outperforms state-of-the-art approaches.
        ]]></description>
    </item>
    <item>
        <title>DGRO: Enhancing LLM Reasoning via Exploration-Exploitation Control and Reward Variance Management</title>
        <link>https://arxiv.org/abs/2505.12951</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12951v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xuerui Su, Liya Guo, Yue Wang, Yi Zhu, Zhiming Ma, Zun Wang, Yuting Liu</dc:creator>
        <description><![CDATA[
            背景：当前大语言模型推理多依赖手工规则奖励函数，强化学习中探索与利用的权衡及手动设计奖励函数的影响研究不足。方法：提出解耦组奖励优化算法（DGRO），将传统正则化系数解耦为两个独立超参数，精准控制探索与利用平衡，还考虑奖励方差对模型的影响。效果：在Logic数据集上平均准确率达96.9%，在多个数学基准测试中展现出良好泛化性。
            arXiv:2505.12951v1 Announce Type: new 
Abstract: Inference scaling further accelerates Large Language Models (LLMs) toward Artificial General Intelligence (AGI), with large-scale Reinforcement Learning (RL) to unleash long Chain-of-Thought reasoning. Most contemporary reasoning approaches usually rely on handcrafted rule-based reward functions. However, the tarde-offs of exploration and exploitation in RL algorithms involves multiple complex considerations, and the theoretical and empirical impacts of manually designed reward functions remain insufficiently explored. In this paper, we propose Decoupled Group Reward Optimization (DGRO), a general RL algorithm for LLM reasoning. On the one hand, DGRO decouples the traditional regularization coefficient into two independent hyperparameters: one scales the policy gradient term, and the other regulates the distance from the sampling policy. This decoupling not only enables precise control over balancing exploration and exploitation, but also can be seamlessly extended to Online Policy Mirror Descent (OPMD) algorithms in Kimi k1.5 and Direct Reward Optimization. On the other hand, we observe that reward variance significantly affects both convergence speed and final model performance. We conduct both theoretical analysis and extensive empirical validation to assess DGRO, including a detailed ablation study that investigates its performance and optimization dynamics. Experimental results show that DGRO achieves state-of-the-art performance on the Logic dataset with an average accuracy of 96.9\%, and demonstrates strong generalization across mathematical benchmarks.
        ]]></description>
    </item>
    <item>
        <title>Fractured Chain-of-Thought Reasoning</title>
        <link>https://arxiv.org/abs/2505.12992</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12992v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Baohao Liao, Hanze Dong, Yuhui Xu, Doyen Sahoo, Christof Monz, Junnan Li, Caiming Xiong</dc:creator>
        <description><![CDATA[
            背景：推理时间缩放技术和思维链（CoT）提示虽提升大语言模型推理能力，但CoT成本高，限制其在低延迟场景应用。方法：提出截断CoT，提前停止推理直接生成答案，还引入Fractured Sampling，从推理轨迹数量、每条轨迹最终解数量、推理轨迹截断深度三方面插值采样。效果：在五个推理基准和不同模型规模实验中，该方法实现了更好的准确率 - 成本权衡，Pass@k与令牌预算呈对数线性缩放增益。
            arXiv:2505.12992v1 Announce Type: new 
Abstract: Inference-time scaling techniques have significantly bolstered the reasoning capabilities of large language models (LLMs) by harnessing additional computational effort at inference without retraining. Similarly, Chain-of-Thought (CoT) prompting and its extension, Long CoT, improve accuracy by generating rich intermediate reasoning trajectories, but these approaches incur substantial token costs that impede their deployment in latency-sensitive settings. In this work, we first show that truncated CoT, which stops reasoning before completion and directly generates the final answer, often matches full CoT sampling while using dramatically fewer tokens. Building on this insight, we introduce Fractured Sampling, a unified inference-time strategy that interpolates between full CoT and solution-only sampling along three orthogonal axes: (1) the number of reasoning trajectories, (2) the number of final solutions per trajectory, and (3) the depth at which reasoning traces are truncated. Through extensive experiments on five diverse reasoning benchmarks and several model scales, we demonstrate that Fractured Sampling consistently achieves superior accuracy-cost trade-offs, yielding steep log-linear scaling gains in Pass@k versus token budget. Our analysis reveals how to allocate computation across these dimensions to maximize performance, paving the way for more efficient and scalable LLM reasoning.
        ]]></description>
    </item>
    <item>
        <title>Evaluating the Performance of RAG Methods for Conversational AI in the Airport Domain</title>
        <link>https://arxiv.org/abs/2505.13006</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13006v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuyang Li, Philip J. M. Kerbusch, Raimon H. R. Pruim, Tobias K\"afer</dc:creator>
        <description><![CDATA[
            背景：机场为提高自动化程度，需实现员工与航班信息系统的交流。方法：构建三种检索增强生成（RAG）方法，即传统RAG、SQL RAG和基于知识图谱的RAG（Graph RAG）。效果：实验显示，传统RAG用BM25 + GPT - 4准确率达84.84%，但有幻觉问题；SQL RAG和Graph RAG准确率分别为80.85%和91.49%，幻觉显著减少，且Graph RAG处理推理问题更有效，推荐后两者用于机场环境。 
            arXiv:2505.13006v1 Announce Type: new 
Abstract: Airports from the top 20 in terms of annual passengers are highly dynamic environments with thousands of flights daily, and they aim to increase the degree of automation. To contribute to this, we implemented a Conversational AI system that enables staff in an airport to communicate with flight information systems. This system not only answers standard airport queries but also resolves airport terminology, jargon, abbreviations, and dynamic questions involving reasoning. In this paper, we built three different Retrieval-Augmented Generation (RAG) methods, including traditional RAG, SQL RAG, and Knowledge Graph-based RAG (Graph RAG). Experiments showed that traditional RAG achieved 84.84% accuracy using BM25 + GPT-4 but occasionally produced hallucinations, which is risky to airport safety. In contrast, SQL RAG and Graph RAG achieved 80.85% and 91.49% accuracy respectively, with significantly fewer hallucinations. Moreover, Graph RAG was especially effective for questions that involved reasoning. Based on our observations, we thus recommend SQL RAG and Graph RAG are better for airport environments, due to fewer hallucinations and the ability to handle dynamic questions.
        ]]></description>
    </item>
    <item>
        <title>Unpacking Positional Encoding in Transformers: A Spectral Analysis of Content-Position Coupling</title>
        <link>https://arxiv.org/abs/2505.13027</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13027v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zihan Gu, Han Zhang, Ruoyu Chen, Yue Hu, Hua Zhang</dc:creator>
        <description><![CDATA[
            背景：位置编码（PE）对Transformer建模序列结构至关重要，但不同PE方案耦合内容与位置信息的机制及对模型动态的影响缺乏理论研究。方法：提出统一框架，通过注意力对数生成的Toeplitz矩阵的谱特性分析PE，构建合成任务评估多种PE方法。效果：理论表明乘法内容 - 位置耦合能提升优化稳定性和效率，实验显示RoPE在位置敏感任务上表现佳，还发现修改PE耦合方式可缓解集中问题，为有效PE设计提供原则。
            arXiv:2505.13027v1 Announce Type: new 
Abstract: Positional encoding (PE) is essential for enabling Transformers to model sequential structure. However, the mechanisms by which different PE schemes couple token content and positional information-and how these mechanisms influence model dynamics-remain theoretically underexplored. In this work, we present a unified framework that analyzes PE through the spectral properties of Toeplitz and related matrices derived from attention logits. We show that multiplicative content-position coupling-exemplified by Rotary Positional Encoding (RoPE) via a Hadamard product with a Toeplitz matrix-induces spectral contraction, which theoretically improves optimization stability and efficiency. Guided by this theory, we construct synthetic tasks that contrast content-position dependent and content-position independent settings, and evaluate a range of PE methods. Our experiments reveal strong alignment with theory: RoPE consistently outperforms other methods on position-sensitive tasks and induces "single-head deposit" patterns in early layers, indicating localized positional processing. Further analyses show that modifying the method and timing of PE coupling, such as MLA in Deepseek-V3, can effectively mitigate this concentration. These results establish explicit content-relative mixing with relative-position Toeplitz signals as a key principle for effective PE design and provide new insight into how positional structure is integrated in Transformer architectures.
        ]]></description>
    </item>
    <item>
        <title>Advancing Sequential Numerical Prediction in Autoregressive Models</title>
        <link>https://arxiv.org/abs/2505.13077</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13077v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiang Fei, Jinghui Lu, Qi Sun, Hao Feng, Yanjie Wang, Wei Shi, An-Lan Wang, Jingqun Tang, Can Huang</dc:creator>
        <description><![CDATA[
            背景：自回归模型是序列生成任务的常用选择，但标准方法将数字视为独立标记，忽略了数值序列的连贯结构。方法：本文提出数值标记完整性损失（NTIL），从标记层面扩展推土机距离以保留数值的顺序关系，从序列层面惩罚预测序列与实际序列的整体差异，且能与大语言模型/多模态大模型有效集成。效果：大量实验表明，NTIL显著提升了数值预测性能。 
            arXiv:2505.13077v1 Announce Type: new 
Abstract: Autoregressive models have become the de facto choice for sequence generation tasks, but standard approaches treat digits as independent tokens and apply cross-entropy loss, overlooking the coherent structure of numerical sequences. This paper introduces Numerical Token Integrity Loss (NTIL) to address this gap. NTIL operates at two levels: (1) token-level, where it extends the Earth Mover's Distance (EMD) to preserve ordinal relationships between numerical values, and (2) sequence-level, where it penalizes the overall discrepancy between the predicted and actual sequences. This dual approach improves numerical prediction and integrates effectively with LLMs/MLLMs. Extensive experiments show significant performance improvements with NTIL.
        ]]></description>
    </item>
    <item>
        <title>Walking the Tightrope: Disentangling Beneficial and Detrimental Drifts in Non-Stationary Custom-Tuning</title>
        <link>https://arxiv.org/abs/2505.13081</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13081v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiaoyu Yang, Jie Lu, En Yu</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型非平稳强化微调中，思维链推理存在有害概念漂移，导致预测偏差。方法：将思维链自回归标记流形式化为非平稳分布，建立概念漂移理论与强化微调的联系，提出反事实感知强化微调方法，通过概念图赋能的大语言模型专家生成反事实推理轨迹，实现反事实偏好优化。效果：在非平稳环境尤其医疗领域实现稳定强化微调，实验表明在鲁棒性、泛化性和协调性上表现出色，还贡献了含320,416条推理轨迹的数据集。
            arXiv:2505.13081v1 Announce Type: new 
Abstract: This paper uncovers a critical yet overlooked phenomenon in multi-modal large language models (MLLMs): detrimental concept drift within chain-of-thought (CoT) reasoning during non-stationary reinforcement fine-tuning (RFT), where reasoning token distributions evolve unpredictably, thereby introducing significant biases in final predictions. To address this, we are pioneers in establishing the theoretical bridge between concept drift theory and RFT processes by formalizing CoT's autoregressive token streams as non-stationary distributions undergoing arbitrary temporal shifts. Leveraging this framework, we propose a novel counterfact-aware RFT that systematically decouples beneficial distribution adaptation from harmful concept drift through concept graph-empowered LLM experts generating counterfactual reasoning trajectories. Our solution, Counterfactual Preference Optimization (CPO), enables stable RFT in non-stationary environments, particularly within the medical domain, through custom-tuning of counterfactual-aware preference alignment. Extensive experiments demonstrate our superior performance of robustness, generalization and coordination within RFT. Besides, we also contributed a large-scale dataset CXR-CounterFact (CCF), comprising 320,416 meticulously curated counterfactual reasoning trajectories derived from MIMIC-CXR. Our code and data are public.
        ]]></description>
    </item>
    <item>
        <title>Lightweight Transformer via Unrolling of Mixed Graph Algorithms for Traffic Forecast</title>
        <link>https://arxiv.org/abs/2505.13102</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13102v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ji Qi, Tam Thuc Do, Mingxiao Liu, Zhuoshi Pan, Yuzhe Li, Gene Cheung, H. Vicky Zhao</dc:creator>
        <description><![CDATA[
            背景：交通预测需同时考虑时空维度。方法：将基于混合图的优化算法展开为轻量级、可解释的类Transformer神经网络，构建地理空间相关的无向图和时间序列相关的有向图，设计新的变分项量化和促进信号平滑，基于交替方向乘子法构建迭代算法并展开为前馈网络进行参数学习，插入类似自注意力机制的图学习模块。效果：所提展开网络在交通预测中与现有最优方案性能相当，且大幅减少参数数量。
            arXiv:2505.13102v1 Announce Type: new 
Abstract: To forecast traffic with both spatial and temporal dimensions, we unroll a mixed-graph-based optimization algorithm into a lightweight and interpretable transformer-like neural net. Specifically, we construct two graphs: an undirected graph $\mathcal{G}^u$ capturing spatial correlations across geography, and a directed graph $\mathcal{G}^d$ capturing sequential relationships over time. We formulate a prediction problem for the future samples of signal $\mathbf{x}$, assuming it is "smooth" with respect to both $\mathcal{G}^u$ and $\mathcal{G}^d$, where we design new $\ell_2$ and $\ell_1$-norm variational terms to quantify and promote signal smoothness (low-frequency reconstruction) on a directed graph. We construct an iterative algorithm based on alternating direction method of multipliers (ADMM), and unroll it into a feed-forward network for data-driven parameter learning. We insert graph learning modules for $\mathcal{G}^u$ and $\mathcal{G}^d$, which are akin to the self-attention mechanism in classical transformers. Experiments show that our unrolled networks achieve competitive traffic forecast performance as state-of-the-art prediction schemes, while reducing parameter counts drastically. Our code is available in https://github.com/SingularityUndefined/Unrolling-GSP-STForecast.
        ]]></description>
    </item>
    <item>
        <title>Effective and Transparent RAG: Adaptive-Reward Reinforcement Learning for Decision Traceability</title>
        <link>https://arxiv.org/abs/2505.13258</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13258v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jingyi Ren, Yekun Xu, Xiaolong Wang, Weitao Li, Weizhi Ma, Yang Liu</dc:creator>
        <description><![CDATA[
            检索增强生成（RAG）提升了大语言模型在知识密集领域的表现，但存在有效性和透明度问题。为解决这些问题，研究提出ARENA框架，通过强化学习和自定义奖励训练。该框架基于结构化生成和自适应奖励计算，使模型能识别关键证据、进行结构化推理并生成可解释决策轨迹的答案。在Qwen2.5 - 7B - Instruct和Llama3.1 - 8B - Instruct上实验，相比多种RAG基线模型，在多跳问答数据集上提升10 - 30%，与SOTA商业大模型相当，且无需额外训练即可适配新数据集。
            arXiv:2505.13258v1 Announce Type: new 
Abstract: Retrieval-Augmented Generation (RAG) has significantly improved the performance of large language models (LLMs) on knowledge-intensive domains. However, although RAG achieved successes across distinct domains, there are still some unsolved challenges: 1) Effectiveness. Existing research mainly focuses on developing more powerful RAG retrievers, but how to enhance the generator's (LLM's) ability to utilize the retrieved information for reasoning and generation? 2) Transparency. Most RAG methods ignore which retrieved content actually contributes to the reasoning process, resulting in a lack of interpretability and visibility. To address this, we propose ARENA (Adaptive-Rewarded Evidence Navigation Agent), a transparent RAG generator framework trained via reinforcement learning (RL) with our proposed rewards. Based on the structured generation and adaptive reward calculation, our RL-based training enables the model to identify key evidence, perform structured reasoning, and generate answers with interpretable decision traces. Applied to Qwen2.5-7B-Instruct and Llama3.1-8B-Instruct, abundant experiments with various RAG baselines demonstrate that our model achieves 10-30% improvements on all multi-hop QA datasets, which is comparable with the SOTA Commercially-developed LLMs (e.g., OpenAI-o1, DeepSeek-R1). Further analyses show that ARENA has strong flexibility to be adopted on new datasets without extra training. Our models and codes are publicly released.
        ]]></description>
    </item>
    <item>
        <title>CSC-SQL: Corrective Self-Consistency in Text-to-SQL via Reinforcement Learning</title>
        <link>https://arxiv.org/abs/2505.13271</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13271v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Lei Sheng, Shuai-Shuai Xu</dc:creator>
        <description><![CDATA[
            背景：大语言模型在将自然语言问题转换为SQL查询上有较强能力，但自一致性和自纠错等测试时扩展技术存在局限。方法：提出CSC - SQL，集成自一致性和自纠错，从并行采样中选两个最常出现的输出送入合并修正模型进行修正，用GRPO算法通过强化学习微调SQL生成和修正模型。效果：实验证明有效且具泛化性，在BIRD开发集上，3B模型执行准确率达65.28%，7B模型达69.19%。
            arXiv:2505.13271v1 Announce Type: new 
Abstract: Large language models (LLMs) have demonstrated strong capabilities in translating natural language questions about relational databases into SQL queries. In particular, test-time scaling techniques such as Self-Consistency and Self-Correction can enhance SQL generation accuracy by increasing computational effort during inference. However, these methods have notable limitations: Self-Consistency may select suboptimal outputs despite majority votes, while Self-Correction typically addresses only syntactic errors. To leverage the strengths of both approaches, we propose CSC-SQL, a novel method that integrates Self-Consistency and Self-Correction. CSC-SQL selects the two most frequently occurring outputs from parallel sampling and feeds them into a merge revision model for correction. Additionally, we employ the Group Relative Policy Optimization (GRPO) algorithm to fine-tune both the SQL generation and revision models via reinforcement learning, significantly enhancing output quality. Experimental results confirm the effectiveness and generalizability of CSC-SQL. On the BIRD development set, our 3B model achieves 65.28% execution accuracy, while the 7B model achieves 69.19%. The code will be open sourced at https://github.com/CycloneBoy/csc_sql.
        ]]></description>
    </item>
    <item>
        <title>$\textit{Rank, Chunk and Expand}$: Lineage-Oriented Reasoning for Taxonomy Expansion</title>
        <link>https://arxiv.org/abs/2505.13282</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13282v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sahil Mishra, Kumar Arjun, Tanmoy Chakraborty</dc:creator>
        <description><![CDATA[
            背景：分类法作为层次化知识图谱，对推荐系统和网络应用至关重要，随数据增长，扩展分类法很必要，但现有方法存在问题。方法：提出LORex框架，结合判别式排序和生成式推理进行分类法扩展，将候选术语排序并分块，通过推理候选者层次结构过滤噪声、迭代优化选择。效果：在四个基准和十二个基线模型上实验表明，与现有方法相比，LORex的准确率提高12%，Wu & Palmer相似度提高5%。
            arXiv:2505.13282v1 Announce Type: new 
Abstract: Taxonomies are hierarchical knowledge graphs crucial for recommendation systems, and web applications. As data grows, expanding taxonomies is essential, but existing methods face key challenges: (1) discriminative models struggle with representation limits and generalization, while (2) generative methods either process all candidates at once, introducing noise and exceeding context limits, or discard relevant entities by selecting noisy candidates. We propose LORex ($\textbf{L}$ineage-$\textbf{O}$riented $\textbf{Re}$asoning for Taxonomy E$\textbf{x}$pansion), a plug-and-play framework that combines discriminative ranking and generative reasoning for efficient taxonomy expansion. Unlike prior methods, LORex ranks and chunks candidate terms into batches, filtering noise and iteratively refining selections by reasoning candidates' hierarchy to ensure contextual efficiency. Extensive experiments across four benchmarks and twelve baselines show that LORex improves accuracy by 12% and Wu & Palmer similarity by 5% over state-of-the-art methods.
        ]]></description>
    </item>
    <item>
        <title>RBF++: Quantifying and Optimizing Reasoning Boundaries across Measurable and Unmeasurable Capabilities for Chain-of-Thought Reasoning</title>
        <link>https://arxiv.org/abs/2505.13307</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13307v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qiguang Chen, Libo Qin, Jinhao Liu, Yue Liao, Jiaqi Wang, Jingxuan Zhou, Wanxiang Che</dc:creator>
        <description><![CDATA[
            思维链（CoT）推理能提升大语言模型处理复杂任务的能力，但在实际应用中有两大挑战：一是缺乏评估和优化可测量CoT能力边界的量化指标与操作指南；二是缺少评估不可测量CoT能力边界的方法。为此，研究团队提出Reasoning Boundary Framework++（RBF++）。对于可测量边界，定义推理边界（RB）并提出组合定律；对于不可测量边界，引入常数假设和推理边界划分机制。实验涉及38个模型、13个任务，验证了框架在跨模态场景的可行性。
            arXiv:2505.13307v1 Announce Type: new 
Abstract: Chain-of-Thought (CoT) reasoning has proven effective in enhancing large language models (LLMs) on complex tasks, spurring research into its underlying mechanisms. However, two primary challenges remain for real-world applications: (1) the lack of quantitative metrics and actionable guidelines for evaluating and optimizing measurable boundaries of CoT capability, and (2) the absence of methods to assess boundaries of unmeasurable CoT capability, such as multimodal perception. To address these gaps, we introduce the Reasoning Boundary Framework++ (RBF++). To tackle the first challenge, we define the reasoning boundary (RB) as the maximum limit of CoT performance. We also propose a combination law for RBs, enabling quantitative analysis and offering actionable guidance across various CoT tasks. For the second challenge, particularly in multimodal scenarios, we introduce a constant assumption, which replaces unmeasurable RBs with scenario-specific constants. Additionally, we propose the reasoning boundary division mechanism, which divides unmeasurable RBs into two sub-boundaries, facilitating the quantification and optimization of both unmeasurable domain knowledge and multimodal perception capabilities. Extensive experiments involving 38 models across 13 tasks validate the feasibility of our framework in cross-modal settings. Additionally, we evaluate 10 CoT strategies, offer insights into optimization and decay from two complementary perspectives, and expand evaluation benchmarks for measuring RBs in LLM reasoning. We hope this work advances the understanding of RBs and optimization strategies in LLMs. Code and data are available at https://github.com/LightChen233/reasoning-boundary.
        ]]></description>
    </item>
    <item>
        <title>Seek in the Dark: Reasoning via Test-Time Instance-Level Policy Gradient in Latent Space</title>
        <link>https://arxiv.org/abs/2505.13308</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13308v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hengli Li, Chenxi Li, Tong Wu, Xuekai Zhu, Yuxuan Wang, Zhaoxin Yu, Eric Hanchen Jiang, Song-Chun Zhu, Zixia Jia, Ying Nian Wu, Zilong Zheng</dc:creator>
        <description><![CDATA[
            大语言模型在追求通用人工智能时，推理能力仍是一大挑战，训练算法存在如灾难性遗忘等问题，新训练数据也有限。本文提出LatentSeek框架，在模型潜在空间通过测试时实例级自适应（TTIA）增强大语言模型推理能力，利用策略梯度在自生成奖励信号引导下迭代更新潜在表征。在多个推理基准测试中，该方法始终优于思维链提示和基于微调的方法，对平均复杂度问题通常迭代几次就能收敛，是提升大语言模型推理能力的轻量级有效方案。
            arXiv:2505.13308v1 Announce Type: new 
Abstract: Reasoning ability, a core component of human intelligence, continues to pose a significant challenge for Large Language Models (LLMs) in the pursuit of AGI. Although model performance has improved under the training scaling law, significant challenges remain, particularly with respect to training algorithms, such as catastrophic forgetting, and the limited availability of novel training data. As an alternative, test-time scaling enhances reasoning performance by increasing test-time computation without parameter updating. Unlike prior methods in this paradigm focused on token space, we propose leveraging latent space for more effective reasoning and better adherence to the test-time scaling law. We introduce LatentSeek, a novel framework that enhances LLM reasoning through Test-Time Instance-level Adaptation (TTIA) within the model's latent space. Specifically, LatentSeek leverages policy gradient to iteratively update latent representations, guided by self-generated reward signals. LatentSeek is evaluated on a range of reasoning benchmarks, including GSM8K, MATH-500, and AIME2024, across multiple LLM architectures. Results show that LatentSeek consistently outperforms strong baselines, such as Chain-of-Thought prompting and fine-tuning-based methods. Furthermore, our analysis demonstrates that LatentSeek is highly efficient, typically converging within a few iterations for problems of average complexity, while also benefiting from additional iterations, thereby highlighting the potential of test-time scaling in the latent space. These findings position LatentSeek as a lightweight, scalable, and effective solution for enhancing the reasoning capabilities of LLMs.
        ]]></description>
    </item>
    <item>
        <title>VesselGPT: Autoregressive Modeling of Vascular Geometry</title>
        <link>https://arxiv.org/abs/2505.13318</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13318v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Paula Feldman, Martin Sinnona, Viviana Siless, Claudio Delrieux, Emmanuel Iarussi</dc:creator>
        <description><![CDATA[
            背景：解剖树在临床诊断和治疗规划中至关重要，但复杂多样的几何形状使其准确表示成为挑战。方法：受大语言模型进展启发，提出自回归方法合成解剖树，先通过VQ - VAE架构将血管结构嵌入离散词汇表，再用GPT - 2模型自回归建模其生成。效果：有效捕捉复杂几何和分支模式，实现逼真血管树合成，能以紧凑离散表示实现高保真树重建，B样条表示保留关键形态细节。
            arXiv:2505.13318v1 Announce Type: new 
Abstract: Anatomical trees are critical for clinical diagnosis and treatment planning, yet their complex and diverse geometry make accurate representation a significant challenge. Motivated by the latest advances in large language models, we introduce an autoregressive method for synthesizing anatomical trees. Our approach first embeds vessel structures into a learned discrete vocabulary using a VQ-VAE architecture, then models their generation autoregressively with a GPT-2 model. This method effectively captures intricate geometries and branching patterns, enabling realistic vascular tree synthesis. Comprehensive qualitative and quantitative evaluations reveal that our technique achieves high-fidelity tree reconstruction with compact discrete representations. Moreover, our B-spline representation of vessel cross-sections preserves critical morphological details that are often overlooked in previous' methods parameterizations. To the best of our knowledge, this work is the first to generate blood vessels in an autoregressive manner. Code, data, and trained models will be made available.
        ]]></description>
    </item>
    <item>
        <title>Thinking Short and Right Over Thinking Long: Serving LLM Reasoning Efficiently and Accurately</title>
        <link>https://arxiv.org/abs/2505.13326</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13326v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuhang Wang, Youhe Jiang, Bin Cui, Fangcheng Fu</dc:creator>
        <description><![CDATA[
            背景：大语言模型（LLMs）通过思维链推理及探索更多推理分支可提升能力，但二者结合会因过度思考和高内存消耗降低系统效率。方法：提出SART服务框架，采用基于经验观察和理论分析的带早停冗余采样方法获取短思维响应，动态修剪低质量分支以减少内存消耗。效果：实验表明，SART提高了LLM推理准确性和服务效率，在达到相同准确率时，效率比现有方法最高提升28.2倍，平均提升15.7倍。
            arXiv:2505.13326v1 Announce Type: new 
Abstract: Recent advances in test-time scaling suggest that Large Language Models (LLMs) can gain better capabilities by generating Chain-of-Thought reasoning (analogous to human thinking) to respond a given request, and meanwhile exploring more reasoning branches (i.e., generating multiple responses and ensembling them) can improve the final output quality. However, when incorporating the two scaling dimensions, we find that the system efficiency is dampened significantly for two reasons. Firstly, the time cost to generate the final output increases substantially as many reasoning branches would be trapped in the over-thinking dilemma, producing excessively long responses. Secondly, generating multiple reasoning branches for each request increases memory consumption, which is unsuitable for LLM serving since we can only batch a limited number of requests to process simultaneously. To address this, we present SART, a serving framework for efficient and accurate LLM reasoning. The essential idea is to manage the thinking to be short and right, rather than long. For one thing, we devise a redundant sampling with early stopping approach based on empirical observations and theoretic analysis, which increases the likelihood of obtaining short-thinking responses when sampling reasoning branches. For another, we propose to dynamically prune low-quality branches so that only right-thinking branches are maintained, reducing the memory consumption and allowing us to batch more requests. Experimental results demonstrate that SART not only improves the accuracy of LLM reasoning but also enhances the serving efficiency, outperforming existing methods by up to 28.2 times and on average 15.7 times in terms of efficiency when achieving the same level of accuracy.
        ]]></description>
    </item>
    <item>
        <title>Thinkless: LLM Learns When to Think</title>
        <link>https://arxiv.org/abs/2505.13379</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13379v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Gongfan Fang, Xinyin Ma, Xinchao Wang</dc:creator>
        <description><![CDATA[
            背景：具备思维链推理能力的推理语言模型在复杂逻辑推理任务表现出色，但对所有查询都进行详尽推理会导致计算效率低。方法：提出Thinkless框架，让大语言模型根据任务复杂度和自身能力自适应选择短、长形式推理，采用强化学习范式训练，使用两个控制令牌，核心是DeGRPO算法，将混合推理学习目标分解为控制令牌损失和响应损失。效果：在多个基准测试中，能减少50% - 90%长链思维使用，显著提升推理语言模型效率。
            arXiv:2505.13379v1 Announce Type: new 
Abstract: Reasoning Language Models, capable of extended chain-of-thought reasoning, have demonstrated remarkable performance on tasks requiring complex logical inference. However, applying elaborate reasoning for all queries often results in substantial computational inefficiencies, particularly when many problems admit straightforward solutions. This motivates an open question: Can LLMs learn when to think? To answer this, we propose Thinkless, a learnable framework that empowers an LLM to adaptively select between short-form and long-form reasoning, based on both task complexity and the model's ability. Thinkless is trained under a reinforcement learning paradigm and employs two control tokens,  for concise responses and  for detailed reasoning. At the core of our method is a Decoupled Group Relative Policy Optimization (DeGRPO) algorithm, which decomposes the learning objective of hybrid reasoning into two components: (1) a control token loss that governs the selection of the reasoning mode, and (2) a response loss that improves the accuracy of the generated answers. This decoupled formulation enables fine-grained control over the contributions of each objective, stabilizing training and effectively preventing collapse observed in vanilla GRPO. Empirically, on several benchmarks such as Minerva Algebra, MATH-500, and GSM8K, Thinkless is able to reduce the usage of long-chain thinking by 50% - 90%, significantly improving the efficiency of Reasoning Language Models. The code is available at https://github.com/VainF/Thinkless
        ]]></description>
    </item>
    <item>
        <title>MR. Judge: Multimodal Reasoner as a Judge</title>
        <link>https://arxiv.org/abs/2505.13403</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13403v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Renjie Pi, Felix Bai, Qibin Chen, Simon Wang, Jiulong Shan, Kieran Liu, Meng Cao</dc:creator>
        <description><![CDATA[
            背景：用大语言模型和多模态大语言模型作为评估裁判在RLHF和推理时扩展中是有效方法。方法：提出MR. Judge范式，将判断过程构建为受推理启发的多项选择题，先进行多方面推理再选最佳回复；针对缺乏带评分回复的问题，提出反向回复候选合成和基于文本的推理提取策略。效果：实验表明该范式在多任务有效，MR. Judge - 7B在VL - RewardBench上超GPT - 4o 9.9%，推理时扩展在MM - Vet上性能提升达7.7%。
            arXiv:2505.13403v1 Announce Type: new 
Abstract: The paradigm of using Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) as evaluative judges has emerged as an effective approach in RLHF and inference-time scaling. In this work, we propose Multimodal Reasoner as a Judge (MR. Judge), a paradigm for empowering general-purpose MLLMs judges with strong reasoning capabilities. Instead of directly assigning scores for each response, we formulate the judgement process as a reasoning-inspired multiple-choice problem. Specifically, the judge model first conducts deliberate reasoning covering different aspects of the responses and eventually selects the best response from them. This reasoning process not only improves the interpretibility of the judgement, but also greatly enhances the performance of MLLM judges. To cope with the lack of questions with scored responses, we propose the following strategy to achieve automatic annotation: 1) Reverse Response Candidates Synthesis: starting from a supervised fine-tuning (SFT) dataset, we treat the original response as the best candidate and prompt the MLLM to generate plausible but flawed negative candidates. 2) Text-based reasoning extraction: we carefully design a data synthesis pipeline for distilling the reasoning capability from a text-based reasoning model, which is adopted to enable the MLLM judges to regain complex reasoning ability via warm up supervised fine-tuning. Experiments demonstrate that our MR. Judge is effective across a wide range of tasks. Specifically, our MR. Judge-7B surpasses GPT-4o by 9.9% on VL-RewardBench, and improves performance on MM-Vet during inference-time scaling by up to 7.7%.
        ]]></description>
    </item>
    <item>
        <title>Make Still Further Progress: Chain of Thoughts for Tabular Data Leaderboard</title>
        <link>https://arxiv.org/abs/2505.13421</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13421v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Si-Yang Liu, Qile Zhou, Han-Jia Ye</dc:creator>
        <description><![CDATA[
            背景：表格数据是机器学习常用格式，表格模型性能因数据集特征分布和任务特性差异大，传统聚合策略缺乏实例级适应性。方法：提出基于大语言模型的上下文集成框架，利用最近邻和外部模型预测为测试实例构建上下文，引入Chain of Tabular Thoughts提示策略，引导大模型多步、可解释推理。效果：实验表明，该方法在多种表格数据集上优于调优基线和标准集成技术。
            arXiv:2505.13421v1 Announce Type: new 
Abstract: Tabular data, a fundamental data format in machine learning, is predominantly utilized in competitions and real-world applications. The performance of tabular models--such as gradient boosted decision trees and neural networks--can vary significantly across datasets due to differences in feature distributions and task characteristics. Achieving top performance on each dataset often requires specialized expert knowledge. To address this variability, practitioners often aggregate the predictions of multiple models. However, conventional aggregation strategies typically rely on static combination rules and lack instance-level adaptability. In this work, we propose an in-context ensemble framework for tabular prediction that leverages large language models (LLMs) to perform dynamic, instance-specific integration of external model predictions. Without access to raw tabular features or semantic information, our method constructs a context around each test instance using its nearest neighbors and the predictions from a pool of external models. Within this enriched context, we introduce Chain of Tabular Thoughts (CoT$^2$), a prompting strategy that guides LLMs through multi-step, interpretable reasoning, making still further progress toward expert-level decision-making. Experimental results show that our method outperforms well-tuned baselines and standard ensemble techniques across a wide range of tabular datasets.
        ]]></description>
    </item>
    <item>
        <title>Optimizing Anytime Reasoning via Budget Relative Policy Optimization</title>
        <link>https://arxiv.org/abs/2505.13438</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13438v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Penghui Qi, Zichen Liu, Tianyu Pang, Chao Du, Wee Sun Lee, Min Lin</dc:creator>
        <description><![CDATA[
            提升大语言模型推理能力需扩展测试时计算量。现有强化学习方法仅在固定大令牌预算下优化最终性能，影响训练和部署效率。本文提出AnytimeReasoner框架，通过从先验分布采样令牌预算截断思考过程，引入可验证密集奖励，解耦优化思考和总结策略。还提出BRPO技术增强学习过程稳健性和效率。数学推理任务实证表明，该方法在各先验分布和思考预算下均优于GRPO，提升训练和令牌效率。
            arXiv:2505.13438v1 Announce Type: new 
Abstract: Scaling test-time compute is crucial for enhancing the reasoning capabilities of large language models (LLMs). Existing approaches typically employ reinforcement learning (RL) to maximize a verifiable reward obtained at the end of reasoning traces. However, such methods optimize only the final performance under a large and fixed token budget, which hinders efficiency in both training and deployment. In this work, we present a novel framework, AnytimeReasoner, to optimize anytime reasoning performance, which aims to improve token efficiency and the flexibility of reasoning under varying token budget constraints. To achieve this, we truncate the complete thinking process to fit within sampled token budgets from a prior distribution, compelling the model to summarize the optimal answer for each truncated thinking for verification. This introduces verifiable dense rewards into the reasoning process, facilitating more effective credit assignment in RL optimization. We then optimize the thinking and summary policies in a decoupled manner to maximize the cumulative reward. Additionally, we introduce a novel variance reduction technique, Budget Relative Policy Optimization (BRPO), to enhance the robustness and efficiency of the learning process when reinforcing the thinking policy. Empirical results in mathematical reasoning tasks demonstrate that our method consistently outperforms GRPO across all thinking budgets under various prior distributions, enhancing both training and token efficiency.
        ]]></description>
    </item>
    <item>
        <title>TARGET: Benchmarking Table Retrieval for Generative Tasks</title>
        <link>https://arxiv.org/abs/2505.11545</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.11545v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xingyu Ji, Parker Glenn, Aditya G. Parameswaran, Madelon Hulsebos</dc:creator>
        <description><![CDATA[
            背景：结构化数据丰富且价值高，检索增强生成在结构化数据交互中有重要作用，但如何为分析查询或任务检索合适表格是关键问题。方法：提出用于评估生成任务中表格检索的基准TARGET，分析不同检索器的检索性能及其对下游任务的影响。效果：基于密集嵌入的检索器远超BM25基线，且不同数据集和任务的检索性能差异大，还揭示了检索器对各种元数据的敏感性。
            arXiv:2505.11545v1 Announce Type: cross 
Abstract: The data landscape is rich with structured data, often of high value to organizations, driving important applications in data analysis and machine learning. Recent progress in representation learning and generative models for such data has led to the development of natural language interfaces to structured data, including those leveraging text-to-SQL. Contextualizing interactions, either through conversational interfaces or agentic components, in structured data through retrieval-augmented generation can provide substantial benefits in the form of freshness, accuracy, and comprehensiveness of answers. The key question is: how do we retrieve the right table(s) for the analytical query or task at hand? To this end, we introduce TARGET: a benchmark for evaluating TAble Retrieval for GEnerative Tasks. With TARGET we analyze the retrieval performance of different retrievers in isolation, as well as their impact on downstream tasks. We find that dense embedding-based retrievers far outperform a BM25 baseline which is less effective than it is for retrieval over unstructured text. We also surface the sensitivity of retrievers across various metadata (e.g., missing table titles), and demonstrate a stark variation of retrieval performance across datasets and tasks. TARGET is available at https://target-benchmark.github.io.
        ]]></description>
    </item>
    <item>
        <title>Foundation Models for AI-Enabled Biological Design</title>
        <link>https://arxiv.org/abs/2505.11610</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.11610v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Asher Moldwin, Amarda Shehu</dc:creator>
        <description><![CDATA[
            背景：当前AI助力生物设计领域发展迅速，需对相关基础模型进行梳理。方法：本文对用于生物设计的基础模型进行调研，探讨现有模型和方法的分类，聚焦生物应用中适配这些模型的挑战与解决方案，如生物序列建模架构、生成可控性和多模态集成。效果：总结了该领域的开放性问题和未来方向，为提升生物序列生成质量给出具体下一步建议。
            arXiv:2505.11610v1 Announce Type: cross 
Abstract: This paper surveys foundation models for AI-enabled biological design, focusing on recent developments in applying large-scale, self-supervised models to tasks such as protein engineering, small molecule design, and genomic sequence design. Though this domain is evolving rapidly, this survey presents and discusses a taxonomy of current models and methods. The focus is on challenges and solutions in adapting these models for biological applications, including biological sequence modeling architectures, controllability in generation, and multi-modal integration. The survey concludes with a discussion of open problems and future directions, offering concrete next-steps to improve the quality of biological sequence generation.
        ]]></description>
    </item>
    <item>
        <title>Benchmarking Spatiotemporal Reasoning in LLMs and Reasoning Models: Capabilities and Challenges</title>
        <link>https://arxiv.org/abs/2505.11618</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.11618v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Pengrui Quan, Brian Wang, Kang Yang, Liying Han, Mani Srivastava</dc:creator>
        <description><![CDATA[
            时空推理在网络物理系统中至关重要，但大语言模型和大推理模型对复杂时空信号的推理能力尚待探索。本文提出分层时空推理基准STARK，从状态估计、状态时空推理、结合背景知识推理三个复杂度层次评估模型。研究整理26个时空任务共14552个挑战，评估3个大推理模型和8个大语言模型。结果显示，大语言模型在几何推理任务中表现有限，大推理模型在各难度任务中表现稳健，o3模型在所有任务中领先，在需世界知识的推理任务中，两者性能差距缩小。
            arXiv:2505.11618v1 Announce Type: cross 
Abstract: Spatiotemporal reasoning plays a key role in Cyber-Physical Systems (CPS). Despite advances in Large Language Models (LLMs) and Large Reasoning Models (LRMs), their capacity to reason about complex spatiotemporal signals remains underexplored. This paper proposes a hierarchical SpatioTemporal reAsoning benchmaRK, STARK, to systematically evaluate LLMs across three levels of reasoning complexity: state estimation (e.g., predicting field variables, localizing and tracking events in space and time), spatiotemporal reasoning over states (e.g., inferring spatial-temporal relationships), and world-knowledge-aware reasoning that integrates contextual and domain knowledge (e.g., intent prediction, landmark-aware navigation). We curate 26 distinct spatiotemporal tasks with diverse sensor modalities, comprising 14,552 challenges where models answer directly or by Python Code Interpreter. Evaluating 3 LRMs and 8 LLMs, we find LLMs achieve limited success in tasks requiring geometric reasoning (e.g., multilateration or triangulation), particularly as complexity increases. Surprisingly, LRMs show robust performance across tasks with various levels of difficulty, often competing or surpassing traditional first-principle-based methods. Our results show that in reasoning tasks requiring world knowledge, the performance gap between LLMs and LRMs narrows, with some LLMs even surpassing LRMs. However, the LRM o3 model continues to achieve leading performance across all evaluated tasks, a result attributed primarily to the larger size of the reasoning models. STARK motivates future innovations in model architectures and reasoning paradigms for intelligent CPS by providing a structured framework to identify limitations in the spatiotemporal reasoning of LLMs and LRMs.
        ]]></description>
    </item>
    <item>
        <title>LLM-BABYBENCH: Understanding and Evaluating Grounded Planning and Reasoning in LLMs</title>
        <link>https://arxiv.org/abs/2505.12135</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12135v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Omar Choukrani, Idriss Malek, Daniil Orel, Zhuohan Xie, Zangir Iklassov, Martin Tak\'a\v{c}, Salem Lahlou</dc:creator>
        <description><![CDATA[
            背景：评估大语言模型（LLMs）在交互式环境约束下的规划和推理能力，对开发智能AI代理至关重要。方法：提出LLM - BabyBench基准套件，基于文本版BabyAI网格世界，评估LLMs在环境状态后果预测、生成行动序列以达成目标、分解高级指令为子目标序列三方面的能力，从专家代理中提取结构化信息生成对应数据集，并提供评估工具和指标。效果：初始基线结果显示这些推理任务颇具挑战，相关资源已公开。 
            arXiv:2505.12135v1 Announce Type: cross 
Abstract: Assessing the capacity of Large Language Models (LLMs) to plan and reason within the constraints of interactive environments is crucial for developing capable AI agents. We introduce $\textbf{LLM-BabyBench}$, a new benchmark suite designed specifically for this purpose. Built upon a textual adaptation of the procedurally generated BabyAI grid world, this suite evaluates LLMs on three fundamental aspects of grounded intelligence: (1) predicting the consequences of actions on the environment state ($\textbf{Predict}$ task), (2) generating sequences of low-level actions to achieve specified objectives ($\textbf{Plan}$ task), and (3) decomposing high-level instructions into coherent subgoal sequences ($\textbf{Decompose}$ task). We detail the methodology for generating the three corresponding datasets ($\texttt{LLM-BabyBench-Predict}$, $\texttt{-Plan}$, $\texttt{-Decompose}$) by extracting structured information from an expert agent operating within the text-based environment. Furthermore, we provide a standardized evaluation harness and metrics, including environment interaction for validating generated plans, to facilitate reproducible assessment of diverse LLMs. Initial baseline results highlight the challenges posed by these grounded reasoning tasks. The benchmark suite, datasets, data generation code, and evaluation code are made publicly available ($\href{https://github.com/choukrani/llm-babybench}{\text{GitHub}}$, $\href{https://huggingface.co/datasets/salem-mbzuai/LLM-BabyBench}{\text{HuggingFace}}$).
        ]]></description>
    </item>
    <item>
        <title>WaLRUS: Wavelets for Long-range Representation Using SSMs</title>
        <link>https://arxiv.org/abs/2505.12161</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12161v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hossein Babaei, Mel White, Sina Alemohammad, Richard G. Baraniuk</dc:creator>
        <description><![CDATA[
            背景：状态空间模型（SSMs）是处理序列数据长距离依赖的有力工具，但现有HiPPO方法依赖特定基的闭式解，存在局限性，SaFARi框架虽进行了推广，但仍有改进空间。方法：提出WaLRUS，它是基于Daubechies小波构建的SaFARi新实现。效果：摘要未提及具体定量效果，但表明该方法是在现有基础上针对序列数据处理的进一步探索，有望提升对序列数据的建模能力。
            arXiv:2505.12161v1 Announce Type: cross 
Abstract: State-Space Models (SSMs) have proven to be powerful tools for modeling long-range dependencies in sequential data. While the recent method known as HiPPO has demonstrated strong performance, and formed the basis for machine learning models S4 and Mamba, it remains limited by its reliance on closed-form solutions for a few specific, well-behaved bases. The SaFARi framework generalized this approach, enabling the construction of SSMs from arbitrary frames, including non-orthogonal and redundant ones, thus allowing an infinite diversity of possible "species" within the SSM family. In this paper, we introduce WaLRUS (Wavelets for Long-range Representation Using SSMs), a new implementation of SaFARi built from Daubechies wavelets.
        ]]></description>
    </item>
    <item>
        <title>Enhancing Knowledge Graph Completion with GNN Distillation and Probabilistic Interaction Modeling</title>
        <link>https://arxiv.org/abs/2505.12272</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12272v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Lingzhi Wang, Pengcheng Huang, Haotian Li, Yuliang Wei, Guodong Xin, Rui Zhang, Donglin Zhang, Zhenzhou Ji, Wei Wang</dc:creator>
        <description><![CDATA[
            背景：知识图谱（KGs）多不完整，知识图谱补全（KGC）现有方法存在深度图神经网络（GNNs）过平滑、基于嵌入的模型无法捕捉抽象关系特征的问题。方法：提出统一框架，结合GNN蒸馏和抽象概率交互建模（APIM），GNN蒸馏用迭代消息 - 特征过滤减轻过平滑，APIM通过概率签名和转移矩阵学习结构化抽象交互模式。效果：在WN18RR和FB15K - 237数据集上评估，较基线模型有显著性能提升。
            arXiv:2505.12272v1 Announce Type: cross 
Abstract: Knowledge graphs (KGs) serve as fundamental structures for organizing interconnected data across diverse domains. However, most KGs remain incomplete, limiting their effectiveness in downstream applications. Knowledge graph completion (KGC) aims to address this issue by inferring missing links, but existing methods face critical challenges: deep graph neural networks (GNNs) suffer from over-smoothing, while embedding-based models fail to capture abstract relational features. This study aims to overcome these limitations by proposing a unified framework that integrates GNN distillation and abstract probabilistic interaction modeling (APIM). GNN distillation approach introduces an iterative message-feature filtering process to mitigate over-smoothing, preserving the discriminative power of node representations. APIM module complements this by learning structured, abstract interaction patterns through probabilistic signatures and transition matrices, allowing for a richer, more flexible representation of entity and relation interactions. We apply these methods to GNN-based models and the APIM to embedding-based KGC models, conducting extensive evaluations on the widely used WN18RR and FB15K-237 datasets. Our results demonstrate significant performance gains over baseline models, showcasing the effectiveness of the proposed techniques. The findings highlight the importance of both controlling information propagation and leveraging structured probabilistic modeling, offering new avenues for advancing knowledge graph completion. And our codes are available at https://anonymous.4open.science/r/APIM_and_GNN-Distillation-461C.
        ]]></description>
    </item>
    <item>
        <title>MPRM: A Markov Path-based Rule Miner for Efficient and Interpretable Knowledge Graph Reasoning</title>
        <link>https://arxiv.org/abs/2505.12329</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12329v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mingyang Li, Song Wang, Ning Cai</dc:creator>
        <description><![CDATA[
            背景：知识图谱规则挖掘可实现可解释的链接预测，但基于深度学习的方法在处理大规模知识图谱时面临内存和时间挑战，传统方法受限于置信度指标，计算成本高。方法：提出MPRM方法，将基于规则的推理建模为马尔可夫链，使用从聚合路径概率导出的高效置信度指标。效果：在多个数据集上的实验表明，MPRM能高效挖掘超百万事实的知识图谱，在单CPU上22秒内采样不到1%的事实，保持可解释性，推理准确率比基线提升达11%。
            arXiv:2505.12329v1 Announce Type: cross 
Abstract: Rule mining in knowledge graphs enables interpretable link prediction. However, deep learning-based rule mining methods face significant memory and time challenges for large-scale knowledge graphs, whereas traditional approaches, limited by rigid confidence metrics, incur high computational costs despite sampling techniques. To address these challenges, we propose MPRM, a novel rule mining method that models rule-based inference as a Markov chain and uses an efficient confidence metric derived from aggregated path probabilities, significantly lowering computational demands. Experiments on multiple datasets show that MPRM efficiently mines knowledge graphs with over a million facts, sampling less than 1% of facts on a single CPU in 22 seconds, while preserving interpretability and boosting inference accuracy by up to 11% over baselines.
        ]]></description>
    </item>
    <item>
        <title>Fully Geometric Multi-Hop Reasoning on Knowledge Graphs with Transitive Relations</title>
        <link>https://arxiv.org/abs/2505.12369</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12369v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Fernando Zhapa-Camacho, Robert Hoehndorf</dc:creator>
        <description><![CDATA[
            背景：几何嵌入方法用于知识图谱多跳推理，可将实体和逻辑操作分别映射到几何区域和变换，但现有方法仅利用实体几何构建，用神经组件学习逻辑操作。方法：提出GeometrE，无需学习逻辑操作，实现全几何可解释性，还引入传递损失函数以保留逻辑规则。效果：实验表明，GeometrE在标准基准数据集上优于当前最先进方法。
            arXiv:2505.12369v1 Announce Type: cross 
Abstract: Geometric embedding methods have shown to be useful for multi-hop reasoning on knowledge graphs by mapping entities and logical operations to geometric regions and geometric transformations, respectively. Geometric embeddings provide direct interpretability framework for queries. However, current methods have only leveraged the geometric construction of entities, failing to map logical operations to geometric transformations and, instead, using neural components to learn these operations. We introduce GeometrE, a geometric embedding method for multi-hop reasoning, which does not require learning the logical operations and enables full geometric interpretability. Additionally, unlike previous methods, we introduce a transitive loss function and show that it can preserve the logical rule $\forall a,b,c: r(a,b) \land r(b,c) \to r(a,c)$. Our experiments show that GeometrE outperforms current state-of-the-art methods on standard benchmark datasets.
        ]]></description>
    </item>
    <item>
        <title>AdaToken-3D: Dynamic Spatial Gating for Efficient 3D Large Multimodal-Models Reasoning</title>
        <link>https://arxiv.org/abs/2505.12782</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12782v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kai Zhang, Xingyu Chen, Xiaofeng Zhang</dc:creator>
        <description><![CDATA[
            大多模态模型在3D场景理解中很关键，但当前3D大多模态模型在多模态推理时存在计算开销大、信息冗余等低效问题。为此提出AdaToken - 3D自适应空间令牌优化框架，通过空间贡献分析动态修剪冗余令牌，利用注意力模式挖掘量化令牌级信息流以适配不同架构。在LLaVA - 3D上实验表明，该方法推理速度提升21%，FLOPs减少63%，且保持任务准确率。研究还揭示超60%空间令牌对最终预测贡献极小，为高效3D多模态学习奠定理论基础。
            arXiv:2505.12782v1 Announce Type: cross 
Abstract: Large Multimodal Models (LMMs) have become a pivotal research focus in deep learning, demonstrating remarkable capabilities in 3D scene understanding. However, current 3D LMMs employing thousands of spatial tokens for multimodal reasoning suffer from critical inefficiencies: excessive computational overhead and redundant information flows. Unlike 2D VLMs processing single images, 3D LMMs exhibit inherent architectural redundancy due to the heterogeneous mechanisms between spatial tokens and visual tokens. To address this challenge, we propose AdaToken-3D, an adaptive spatial token optimization framework that dynamically prunes redundant tokens through spatial contribution analysis. Our method automatically tailors pruning strategies to different 3D LMM architectures by quantifying token-level information flows via attention pattern mining. Extensive experiments on LLaVA-3D (a 7B parameter 3D-LMM) demonstrate that AdaToken-3D achieves 21\% faster inference speed and 63\% FLOPs reduction while maintaining original task accuracy. Beyond efficiency gains, this work systematically investigates redundancy patterns in multimodal spatial information flows through quantitative token interaction analysis. Our findings reveal that over 60\% of spatial tokens contribute minimally ($<$5\%) to the final predictions, establishing theoretical foundations for efficient 3D multimodal learning.
        ]]></description>
    </item>
    <item>
        <title>LLM-KG-Bench 3.0: A Compass for SemanticTechnology Capabilities in the Ocean of LLMs</title>
        <link>https://arxiv.org/abs/2505.13098</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13098v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Lars-Peter Meyer, Johannes Frey, Desiree Heim, Felix Brei, Claus Stadler, Kurt Junghanns, Michael Martin</dc:creator>
        <description><![CDATA[
            背景：当前大语言模型（LLMs）应用广泛，但在支持知识图谱（KGs）方面的能力待评估。方法：推出LLM - KG - Bench 3.0框架，包含可扩展的自动化评估任务集，更新了任务API，修订任务，通过vllm库扩展对多种开放模型的支持。效果：使用超30种当代开放和专有LLMs生成综合数据集，能创建展示模型处理RDF和SPARQL能力的示例模型卡，还可对比模型在Turtle和JSON - LD RDF序列化任务上的表现。
            arXiv:2505.13098v1 Announce Type: cross 
Abstract: Current Large Language Models (LLMs) can assist developing program code beside many other things, but can they support working with Knowledge Graphs (KGs) as well? Which LLM is offering the best capabilities in the field of Semantic Web and Knowledge Graph Engineering (KGE)? Is this possible to determine without checking many answers manually? The LLM-KG-Bench framework in Version 3.0 is designed to answer these questions. It consists of an extensible set of tasks for automated evaluation of LLM answers and covers different aspects of working with semantic technologies. In this paper the LLM-KG-Bench framework is presented in Version 3 along with a dataset of prompts, answers and evaluations generated with it and several state-of-the-art LLMs. Significant enhancements have been made to the framework since its initial release, including an updated task API that offers greater flexibility in handling evaluation tasks, revised tasks, and extended support for various open models through the vllm library, among other improvements. A comprehensive dataset has been generated using more than 30 contemporary open and proprietary LLMs, enabling the creation of exemplary model cards that demonstrate the models' capabilities in working with RDF and SPARQL, as well as comparing their performance on Turtle and JSON-LD RDF serialization tasks.
        ]]></description>
    </item>
    <item>
        <title>CoT-Kinetics: A Theoretical Modeling Assessing LRM Reasoning Process</title>
        <link>https://arxiv.org/abs/2505.13408</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13408v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jinhe Bi, Danqi Yan, Yifan Wang, Wenke Huang, Haokun Chen, Guancheng Wan, Mang Ye, Xun Xiao, Hinrich Schuetze, Volker Tresp, Yunpu Ma</dc:creator>
        <description><![CDATA[
            背景：大型推理模型（LRMs）通过学习推理提升了大语言模型的推理能力，但判断其输出答案质量不易，现有方法考虑推理部分评估整体答案的能力仍欠佳。方法：受经典力学启发，提出建立CoT - Kinetics能量方程，将LRM内部transformer层调节的token状态转换过程类比为机械场中的粒子动力学。效果：该方程能为推理阶段的合理性赋予标量分数，可准确衡量LRM整体输出质量，而非简单的正误判断。
            arXiv:2505.13408v1 Announce Type: cross 
Abstract: Recent Large Reasoning Models significantly improve the reasoning ability of Large Language Models by learning to reason, exhibiting the promising performance in solving complex tasks. LRMs solve tasks that require complex reasoning by explicitly generating reasoning trajectories together with answers. Nevertheless, judging the quality of such an output answer is not easy because only considering the correctness of the answer is not enough and the soundness of the reasoning trajectory part matters as well. Logically, if the soundness of the reasoning part is poor, even if the answer is correct, the confidence of the derived answer should be low. Existing methods did consider jointly assessing the overall output answer by taking into account the reasoning part, however, their capability is still not satisfactory as the causal relationship of the reasoning to the concluded answer cannot properly reflected. In this paper, inspired by classical mechanics, we present a novel approach towards establishing a CoT-Kinetics energy equation. Specifically, our CoT-Kinetics energy equation formulates the token state transformation process, which is regulated by LRM internal transformer layers, as like a particle kinetics dynamics governed in a mechanical field. Our CoT-Kinetics energy assigns a scalar score to evaluate specifically the soundness of the reasoning phase, telling how confident the derived answer could be given the evaluated reasoning. As such, the LRM's overall output quality can be accurately measured, rather than a coarse judgment (e.g., correct or incorrect) anymore.
        ]]></description>
    </item>
    <item>
        <title>MM-PRM: Enhancing Multimodal Mathematical Reasoning with Scalable Step-Level Supervision</title>
        <link>https://arxiv.org/abs/2505.13427</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13427v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Lingxiao Du, Fanqing Meng, Zongkai Liu, Zhixiang Zhou, Ping Luo, Qiaosheng Zhang, Wenqi Shao</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型在视觉 - 语言理解上有进展，但在复杂多步推理上表现不佳，缺乏对中间推理步骤的细粒度监督。方法：提出MM - PRM，先构建基于多样数学推理数据训练的MM - Policy，再构建含10000个多模态数学问题的MM - K12数据集作为种子数据，利用基于蒙特卡罗树搜索的流程生成超70万个无人工标注的步骤级注释。效果：在内外数据集基准测试中显著提升，证明过程监督能增强多模态推理系统逻辑鲁棒性。
            arXiv:2505.13427v1 Announce Type: cross 
Abstract: While Multimodal Large Language Models (MLLMs) have achieved impressive progress in vision-language understanding, they still struggle with complex multi-step reasoning, often producing logically inconsistent or partially correct solutions. A key limitation lies in the lack of fine-grained supervision over intermediate reasoning steps. To address this, we propose MM-PRM, a process reward model trained within a fully automated, scalable framework. We first build MM-Policy, a strong multimodal model trained on diverse mathematical reasoning data. Then, we construct MM-K12, a curated dataset of 10,000 multimodal math problems with verifiable answers, which serves as seed data. Leveraging a Monte Carlo Tree Search (MCTS)-based pipeline, we generate over 700k step-level annotations without human labeling. The resulting PRM is used to score candidate reasoning paths in the Best-of-N inference setup and achieves significant improvements across both in-domain (MM-K12 test set) and out-of-domain (OlympiadBench, MathVista, etc.) benchmarks. Further analysis confirms the effectiveness of soft labels, smaller learning rates, and path diversity in optimizing PRM performance. MM-PRM demonstrates that process supervision is a powerful tool for enhancing the logical robustness of multimodal reasoning systems. We release all our codes and data at https://github.com/ModalMinds/MM-PRM.
        ]]></description>
    </item>
    <item>
        <title>Physics of Language Models: Part 1, Learning Hierarchical Language Structures</title>
        <link>https://arxiv.org/abs/2305.13673</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2305.13673v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zeyuan Allen-Zhu, Yuanzhi Li</dc:creator>
        <description><![CDATA[
            背景：基于Transformer的语言模型有效但复杂，理解其内部工作和推理机制是挑战，此前研究多关注简单任务。方法：引入能产生分层规则的合成上下文无关文法（CFG），研究模型对其递归语言结构的推理能力，还探究模型内部状态。效果：如GPT等生成模型能准确学习和推理CFG定义的层次结构并生成句子，模型隐藏状态能精确捕捉CFG结构，注意力模式类似动态规划算法信息传递。此外还得出多个推论。
            arXiv:2305.13673v4 Announce Type: replace 
Abstract: Transformer-based language models are effective but complex, and understanding their inner workings and reasoning mechanisms is a significant challenge. Previous research has primarily explored how these models handle simple tasks like name copying or selection, and we extend this by investigating how these models perform recursive language structure reasoning defined by context-free grammars (CFGs). We introduce a family of synthetic CFGs that produce hierarchical rules, capable of generating lengthy sentences (e.g., hundreds of tokens) that are locally ambiguous and require dynamic programming to parse. Despite this complexity, we demonstrate that generative models like GPT can accurately learn and reason over CFG-defined hierarchies and generate sentences based on it. We explore the model's internals, revealing that its hidden states precisely capture the structure of CFGs, and its attention patterns resemble the information passing in a dynamic programming algorithm.
  This paper also presents several corollaries, including showing why absolute positional embeddings is inferior to relative and rotary embeddings; uniform attention alone is surprisingly effective (motivating our follow-up work on Canon layers); encoder-only models (e.g., BERT, DeBERTa) struggle with deep structure reasoning on CFGs compared to autoregressive models (e.g., GPT); and injecting structural or syntactic noise into pretraining data markedly improves robustness to corrupted language prompts.
        ]]></description>
    </item>
    <item>
        <title>Streaming Sequence Transduction through Dynamic Compression</title>
        <link>https://arxiv.org/abs/2402.01172</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2402.01172v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Weiting Tan, Yunmo Chen, Tongfei Chen, Guanghui Qin, Haoran Xu, Heidi C. Zhang, Benjamin Van Durme, Philipp Koehn</dc:creator>
        <description><![CDATA[
            背景：需要高效的流式序列到序列转换模型。方法：提出基于Transformer的STAR模型，它能动态分割输入流以创建压缩的锚表示。效果：在自动语音识别中实现近无损压缩（12倍），性能超越现有方法；在同步语音转文本任务中，展现出更优的分割能力和延迟 - 质量权衡，优化了延迟、内存占用和质量。
            arXiv:2402.01172v2 Announce Type: replace 
Abstract: We introduce STAR (Stream Transduction with Anchor Representations), a novel Transformer-based model designed for efficient sequence-to-sequence transduction over streams. STAR dynamically segments input streams to create compressed anchor representations, achieving nearly lossless compression (12x) in Automatic Speech Recognition (ASR) and outperforming existing methods. Moreover, STAR demonstrates superior segmentation and latency-quality trade-offs in simultaneous speech-to-text tasks, optimizing latency, memory footprint, and quality.
        ]]></description>
    </item>
    <item>
        <title>Can We Verify Step by Step for Incorrect Answer Detection?</title>
        <link>https://arxiv.org/abs/2402.10528</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2402.10528v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xin Xu, Shizhe Diao, Can Yang, Yang Wang</dc:creator>
        <description><![CDATA[
            背景：思维链提示提升大语言模型推理能力，此前研究多关注提升任务表现及评估推理链质量，而能否通过审查推理链预测模型输出准确性尚待研究。方法：引入基准R2PE探索推理链与多领域推理任务表现的关系，提出过程可辨别性分数（PDS）框架充分利用多推理链信息。效果：在R2PE的45个子集中，F1分数平均提高5.1%，AUC - PR提高2.97%，还提升了开放领域问答的准确性。
            arXiv:2402.10528v4 Announce Type: replace 
Abstract: Chain-of-Thought (CoT) prompting has marked a significant advancement in enhancing the reasoning capabilities of large language models (LLMs). Previous studies have developed various extensions of CoT, which focus primarily on enhancing end-task performance. In addition, there has been research on assessing the quality of reasoning chains in CoT. This raises an intriguing question: Is it possible to predict the accuracy of LLM outputs by scrutinizing the reasoning chains they generate? To answer this research question, we introduce a benchmark, R2PE, designed specifically to explore the relationship between reasoning chains and performance in various reasoning tasks spanning five different domains. This benchmark aims to measure the falsehood of the final output of LLMs based on the reasoning steps. To make full use of information in multiple reasoning chains, we propose the process discernibility score (PDS) framework that beats the answer-checking baseline by a large margin. Concretely, this resulted in an average of $5.1\%$ increase in the F1 score and $2.97\%$ improvement in AUC-PR across all 45 subsets within R2PE. We further demonstrate our PDS's efficacy in advancing open-domain QA accuracy.
        ]]></description>
    </item>
    <item>
        <title>RS-Agent: Automating Remote Sensing Tasks through Intelligent Agent</title>
        <link>https://arxiv.org/abs/2406.07089</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2406.07089v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wenjia Xu, Zijian Yu, Boyang Mu, Zhiwei Wei, Yuanben Zhang, Guangzuo Li, Mugen Peng</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型在遥感应用中受限于基础任务，应对复杂场景存在挑战。方法：提出RS - Agent，集成中央控制器、动态工具包、解决方案空间和知识空间四个组件，引入任务感知检索和DualRAG机制。效果：在9个数据集和18个遥感任务的实验中，显著优于现有多模态大模型，任务规划准确率超95%，在场景分类、目标计数等任务中表现出色。
            arXiv:2406.07089v2 Announce Type: replace 
Abstract: The unprecedented advancements in Multimodal Large Language Models (MLLMs) have demonstrated strong potential in interacting with humans through both language and visual inputs to perform downstream tasks such as visual question answering and scene understanding. However, these models are constrained to basic instruction-following or descriptive tasks, facing challenges in complex real-world remote sensing applications that require specialized tools and knowledge. To address these limitations, we propose RS-Agent, an AI agent designed to interact with human users and autonomously leverage specialized models to address the demands of real-world remote sensing applications. RS-Agent integrates four key components: a Central Controller based on large language models, a dynamic toolkit for tool execution, a Solution Space for task-specific expert guidance, and a Knowledge Space for domain-level reasoning, enabling it to interpret user queries and orchestrate tools for accurate remote sensing task. We introduce two novel mechanisms: Task-Aware Retrieval, which improves tool selection accuracy through expert-guided planning, and DualRAG, a retrieval-augmented generation method that enhances knowledge relevance through weighted, dual-path retrieval. RS-Agent supports flexible integration of new tools and is compatible with both open-source and proprietary LLMs. Extensive experiments across 9 datasets and 18 remote sensing tasks demonstrate that RS-Agent significantly outperforms state-of-the-art MLLMs, achieving over 95% task planning accuracy and delivering superior performance in tasks such as scene classification, object counting, and remote sensing visual question answering. Our work presents RS-Agent as a robust and extensible framework for advancing intelligent automation in remote sensing analysis.
        ]]></description>
    </item>
    <item>
        <title>A Bounding Box is Worth One Token: Interleaving Layout and Text in a Large Language Model for Document Understanding</title>
        <link>https://arxiv.org/abs/2407.01976</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2407.01976v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jinghui Lu, Haiyang Yu, Yanjie Wang, Yongjie Ye, Jingqun Tang, Ziwei Yang, Binghong Wu, Qi Liu, Hao Feng, Han Wang, Hao Liu, Can Huang</dc:creator>
        <description><![CDATA[
            背景：现有将空间布局与文本结合的大语言模型用于文档理解任务有局限，如产生过长文本序列或未充分利用自回归特性。方法：提出用于文档理解的LayTextLLM，将每个边界框投影为单个嵌入并与文本交错，避免长序列问题并利用自回归特性。效果：不仅简化布局和文本数据交互，还在关键信息提取（KIE）和视觉问答（VQA）任务中表现更优，较之前基于OCR的SOTA模型，KIE任务提升15.2%，VQA任务提升10.7%。
            arXiv:2407.01976v3 Announce Type: replace 
Abstract: Recently, many studies have demonstrated that exclusively incorporating OCR-derived text and spatial layouts with large language models (LLMs) can be highly effective for document understanding tasks. However, existing methods that integrate spatial layouts with text have limitations, such as producing overly long text sequences or failing to fully leverage the autoregressive traits of LLMs. In this work, we introduce Interleaving Layout and Text in a Large Language Model (LayTextLLM)} for document understanding. LayTextLLM projects each bounding box to a single embedding and interleaves it with text, efficiently avoiding long sequence issues while leveraging autoregressive traits of LLMs. LayTextLLM not only streamlines the interaction of layout and textual data but also shows enhanced performance in KIE and VQA. Comprehensive benchmark evaluations reveal significant improvements of LayTextLLM, with a 15.2% increase on KIE tasks and 10.7% on VQA tasks compared to previous SOTA OCR-based LLMs. All resources are available at https://github.com/LayTextLLM/LayTextLLM.
        ]]></description>
    </item>
    <item>
        <title>ClinicRealm: Re-evaluating Large Language Models with Conventional Machine Learning for Non-Generative Clinical Prediction Tasks</title>
        <link>https://arxiv.org/abs/2407.18525</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2407.18525v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yinghao Zhu, Junyi Gao, Zixiang Wang, Weibin Liao, Xiaochen Zheng, Lifang Liang, Miguel O. Bernabeu, Yasha Wang, Lequan Yu, Chengwei Pan, Ewen M. Harrison, Liantao Ma</dc:creator>
        <description><![CDATA[
            背景：大语言模型在医学领域应用渐多，但在非生成式临床预测任务中的效用评估不足。方法：ClinicRealm研究在非结构化临床笔记和结构化电子健康记录（EHR）上对9个基于GPT的大语言模型、5个基于BERT的模型和7种传统方法进行基准测试。效果：零样本设置下，领先的大语言模型在临床笔记预测中优于微调的BERT模型；在结构化EHR上，数据稀缺时先进大语言模型常超传统模型，部分开源大语言模型表现不逊于专有模型，凸显其在临床预测中的强大能力。 
            arXiv:2407.18525v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) are increasingly deployed in medicine. However, their utility in non-generative clinical prediction, often presumed inferior to specialized models, remains under-evaluated, leading to ongoing debate within the field and potential for misuse, misunderstanding, or over-reliance due to a lack of systematic benchmarking. Our ClinicRealm study addresses this by benchmarking 9 GPT-based LLMs, 5 BERT-based models, and 7 traditional methods on unstructured clinical notes and structured Electronic Health Records (EHR). Key findings reveal a significant shift: for clinical note predictions, leading LLMs (e.g., DeepSeek R1/V3, GPT o3-mini-high) in zero-shot settings now decisively outperform finetuned BERT models. On structured EHRs, while specialized models excel with ample data, advanced LLMs (e.g., GPT-4o, DeepSeek R1/V3) show potent zero-shot capabilities, often surpassing conventional models in data-scarce settings. Notably, leading open-source LLMs can match or exceed proprietary counterparts. These results establish modern LLMs as powerful non-generative clinical prediction tools, particularly with unstructured text and offering data-efficient structured data options, thus necessitating a re-evaluation of model selection strategies. This research should serve as an important insight for medical informaticists, AI developers, and clinical researchers, potentially prompting a reassessment of current assumptions and inspiring new approaches to LLM application in predictive healthcare.
        ]]></description>
    </item>
    <item>
        <title>SWIFT:A Scalable lightWeight Infrastructure for Fine-Tuning</title>
        <link>https://arxiv.org/abs/2408.05517</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2408.05517v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuze Zhao, Jintao Huang, Jinghan Hu, Xingjun Wang, Yunlin Mao, Daoze Zhang, Hong Zhang, Zeyinzi Jiang, Zhikai Wu, Baole Ai, Ang Wang, Wenmeng Zhou, Yingda Chen</dc:creator>
        <description><![CDATA[
            背景：大语言模型和多模态大语言模型发展迅速，基于Transformer架构的模型训练和轻量级微调尤为重要。方法：开发了可定制的一站式大模型基础设施SWIFT，支持超300个大语言模型和50多个多模态大语言模型，集成微调、推理、评估和模型量化等功能。效果：在特定微调中，相比基线模型，Act.EM指标提升5.2%-21.8%，幻觉减少1.6%-14.1%，平均性能提升8%-17%。
            arXiv:2408.05517v4 Announce Type: replace 
Abstract: Recent development in Large Language Models (LLMs) and Multi-modal Large Language Models (MLLMs) have leverage Attention-based Transformer architectures and achieved superior performance and generalization capabilities. They have since covered extensive areas of traditional learning tasks. For instance, text-based tasks such as text-classification and sequence-labeling, as well as multi-modal tasks like Visual Question Answering (VQA) and Optical Character Recognition (OCR), which were previously addressed using different models, can now be tackled based on one foundation model. Consequently, the training and lightweight fine-tuning of LLMs and MLLMs, especially those based on Transformer architecture, has become particularly important. In recognition of these overwhelming needs, we develop SWIFT, a customizable one-stop infrastructure for large models. With support of over $300+$ LLMs and $50+$ MLLMs, SWIFT stands as the open-source framework that provide the most comprehensive support for fine-tuning large models. In particular, it is the first training framework that provides systematic support for MLLMs. In addition to the core functionalities of fine-tuning, SWIFT also integrates post-training processes such as inference, evaluation, and model quantization, to facilitate fast adoptions of large models in various application scenarios. With a systematic integration of various training techniques, SWIFT offers helpful utilities such as benchmark comparisons among different training techniques for large models. For fine-tuning models specialized in agent framework, we show that notable improvements on the ToolBench leader-board can be achieved by training with customized dataset on SWIFT, with an increase of 5.2%-21.8% in the Act.EM metric over various baseline models, a reduction in hallucination by 1.6%-14.1%, and an average performance improvement of 8%-17%.
        ]]></description>
    </item>
    <item>
        <title>LLMs are not Zero-Shot Reasoners for Biomedical Information Extraction</title>
        <link>https://arxiv.org/abs/2408.12249</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2408.12249v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Aishik Nagar, Viktor Schlegel, Thanh-Tung Nguyen, Hao Li, Yuping Wu, Kuluhan Binici, Stefan Winkler</dc:creator>
        <description><![CDATA[
            背景：大语言模型在医疗问答、文档总结等任务表现良好，但在生物医学结构化信息提取任务中的表现尚不明确。方法：系统评估多种开源大模型在医学分类和命名实体识别任务中的性能，采用标准提示、思维链、基于自我一致性的推理及结合PubMed和维基百科语料的检索增强生成等方法。效果：结果显示标准提示在两项任务中始终优于更复杂的技术，表明当前思维链、自我一致性和检索增强生成在生物医学领域应用存在局限，需更有效整合外部知识和推理机制。 
            arXiv:2408.12249v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) are increasingly adopted for applications in healthcare, reaching the performance of domain experts on tasks such as question answering and document summarisation. Despite their success on these tasks, it is unclear how well LLMs perform on tasks that are traditionally pursued in the biomedical domain, such as structured information extraction. To bridge this gap, in this paper, we systematically benchmark LLM performance in Medical Classification and Named Entity Recognition (NER) tasks. We aim to disentangle the contribution of different factors to the performance, particularly the impact of LLMs' task knowledge and reasoning capabilities, their (parametric) domain knowledge, and addition of external knowledge. To this end, we evaluate various open LLMs - including BioMistral and Llama-2 models - on a diverse set of biomedical datasets, using standard prompting, Chain of-Thought (CoT) and Self Consistency based reasoning as well as Retrieval-Augmented Generation (RAG) with PubMed and Wikipedia corpora. Counter intuitively, our results reveal that standard prompting consistently outperforms more complex techniques across both tasks, laying bare the limitations in the current application of CoT, self-consistency and RAG in the biomedical domain. Our findings suggest that advanced prompting methods developed for knowledge- or reasoning-intensive tasks, such as CoT or RAG, are not easily portable to biomedical tasks where precise structured outputs are required. This highlights the need for more effective integration of external knowledge and reasoning mechanisms in LLMs to enhance their performance in real-world biomedical applications.
        ]]></description>
    </item>
    <item>
        <title>Repurposing Foundation Model for Generalizable Medical Time Series Classification</title>
        <link>https://arxiv.org/abs/2410.03794</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.03794v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Nan Huang, Haishuai Wang, Zihuai He, Marinka Zitnik, Xiang Zhang</dc:creator>
        <description><![CDATA[
            背景：医学时间序列（MedTS）分类因数据集间和数据集中的异质性，在实际部署中泛化性差。方法：提出FORMED框架，将预训练在通用时间序列上的骨干基础模型用于MedTS分类，结合骨干模型与新型分类器，包含任务特定通道嵌入和标签查询、共享解码注意力层，通过轻量级标签查询训练实现对未见数据集的无缝适应。效果：在5个不同MedTS数据集上评估，相比基线，F1分数最高提升35%，在多种配置和任务中泛化性佳。
            arXiv:2410.03794v2 Announce Type: replace 
Abstract: Medical time series (MedTS) classification suffers from poor generalizability in real-world deployment due to inter- and intra-dataset heterogeneity, such as varying numbers of channels, signal lengths, task definitions, and patient characteristics. To address this, we propose FORMED, a novel framework for repurposing a backbone foundation model, pre-trained on generic time series, to enable highly generalizable MedTS classification on unseen datasets. FORMED combines the backbone with a novel classifier comprising two components: (1) task-specific channel embeddings and label queries, dynamically sized to match any number of channels and target classes, and (2) a shared decoding attention layer, jointly trained across datasets to capture medical domain knowledge through task-agnostic feature-query interactions. After repurposing, FORMED achieves seamless adaptation to unseen MedTS datasets through lightweight label query training (0.1% of parameters), eliminating the need for full fine-tuning or architectural redesign. We evaluate FORMED on 5 diverse MedTS datasets, benchmarking against 11 Task-Specific Models (TSM) and 4 Task-Specific Adaptation (TSA) methods. Our results demonstrate FORMED's dominant performance, achieving up to 35% absolute improvement in F1-score (on ADFTD dataset) over specialized baselines. Further analysis reveals consistent generalization across varying channel configurations, time series lengths, and clinical tasks, which are key challenges in real-world deployment. By decoupling domain-invariant representation learning from task-specific adaptation, FORMED establishes a scalable and resource-efficient paradigm for foundation model repurposing in healthcare. This approach prioritizes clinical adaptability over rigid task-centric design, offering a practical pathway for real-world implementation.
        ]]></description>
    </item>
    <item>
        <title>Intention Knowledge Graph Construction for User Intention Relation Modeling</title>
        <link>https://arxiv.org/abs/2412.11500</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2412.11500v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiaxin Bai, Zhaobo Wang, Junfei Cheng, Dan Yu, Zerui Huang, Weiqi Wang, Xin Liu, Chen Luo, Yanming Zhu, Bo Li, Yangqiu Song</dc:creator>
        <description><![CDATA[
            背景：在线平台理解用户意图颇具挑战，现有意图知识图谱研究常忽视意图间连接。方法：本文提出自动生成意图知识图谱的框架，以捕捉用户意图间的联系，利用Amazon m2数据集构建了含3.51亿条边的意图图。效果：该图具有高合理性和可接受性，模型能有效预测新会话意图、提升产品推荐效果，优于此前的先进方法，展现了该方法的实用性。
            arXiv:2412.11500v2 Announce Type: replace 
Abstract: Understanding user intentions is challenging for online platforms. Recent work on intention knowledge graphs addresses this but often lacks focus on connecting intentions, which is crucial for modeling user behavior and predicting future actions. This paper introduces a framework to automatically generate an intention knowledge graph, capturing connections between user intentions. Using the Amazon m2 dataset, we construct an intention graph with 351 million edges, demonstrating high plausibility and acceptance. Our model effectively predicts new session intentions and enhances product recommendations, outperforming previous state-of-the-art methods and showcasing the approach's practical utility.
        ]]></description>
    </item>
    <item>
        <title>ATLAS: Autoformalizing Theorems through Lifting, Augmentation, and Synthesis of Data</title>
        <link>https://arxiv.org/abs/2502.05567</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.05567v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiaoyang Liu, Kangjie Bao, Jiashuo Zhang, Yunqi Liu, Yuntian Liu, Yu Chen, Yang Jiao, Tao Luo</dc:creator>
        <description><![CDATA[
            背景：大语言模型推动自动形式化取得进展，但缺乏自然语言数学内容与机器可验证形式语言的平行语料限制了其进一步发展。方法：提出ATLAS数据生成框架，从概念库出发，结合专家迭代和知识蒸馏加速学生模型改进，引入利用形式语言结构特征的增强策略。效果：运行10次迭代构建含11.7万条定理陈述的数据集，开发的ATLAS Translator在各基准测试中显著优于其他模型（$p<0.05$），达到新的最优水平。
            arXiv:2502.05567v2 Announce Type: replace 
Abstract: Autoformalization, the automatic translation of mathematical content from natural language into machine-verifiable formal languages, has seen significant progress driven by advances in large language models (LLMs). Nonetheless, a primary barrier to further improvements is the limited availability of parallel corpora that map informal mathematical text to its formal counterpart. To address this limitation, we propose ATLAS (Autoformalizing Theorems through Lifting, Augmentation, and Synthesis of Data), a novel data generation framework designed to produce large-scale, high-quality parallel corpora of theorem statements. Distinct from prior approaches, ATLAS begins with a concept repository, accelerates the improvement of student model through expert iteration combined with knowledge distillation, and introduces two novel augmentation strategies that exploit the structural characteristics of formal languages. With the proposed ATLAS running for 10 iterations, we construct an undergraduate-level dataset comprising 117k theorem statements and develop ATLAS Translator, which demonstrates statistically significant improvements over both the HERALD Translator and the Kimina-Autoformalizer across all benchmarks ($p<0.05$, two-sided t-test), achieving a new state of the art. The datasets, model, and code will be released to the public soon.
        ]]></description>
    </item>
    <item>
        <title>RAS: Retrieval-And-Structuring for Knowledge-Intensive LLM Generation</title>
        <link>https://arxiv.org/abs/2502.10996</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.10996v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Pengcheng Jiang, Lang Cao, Ruike Zhu, Minhao Jiang, Yunyi Zhang, Jimeng Sun, Jiawei Han</dc:creator>
        <description><![CDATA[
            背景：大语言模型在知识密集型任务中表现出色，但因检索上下文非结构化，多步推理能力受限，现有检索增强生成方法缺乏对检索段落的明确组织。方法：提出Retrieval-And-Structuring（RAS）框架，通过迭代检索和结构化知识构建动态构建特定查询的知识图，将目标检索规划与增量图构建相结合。效果：在七个知识密集型基准测试中，RAS始终优于强基线，使用开源和专有大语言模型时分别最多提升6.4%和7.0%。
            arXiv:2502.10996v2 Announce Type: replace 
Abstract: Large language models (LLMs) have achieved impressive performance on knowledge-intensive tasks, yet they often struggle with multi-step reasoning due to the unstructured nature of retrieved context. While retrieval-augmented generation (RAG) methods provide external information, the lack of explicit organization among retrieved passages limits their effectiveness, leading to brittle reasoning pathways. Recent interpretability studies highlighting the importance of structured intermediate reasoning further align with this perspective. We propose Retrieval-And-Structuring (RAS), a framework that dynamically constructs query-specific knowledge graphs through iterative retrieval and structured knowledge building. RAS interleaves targeted retrieval planning with incremental graph construction, enabling models to assemble and reason over evolving knowledge structures tailored to each query. On seven knowledge-intensive benchmarks, RAS consistently outperforms strong baselines, achieving up to 6.4% and 7.0% gains with open-source and proprietary LLMs, respectively. Our results demonstrate that dynamic, query-specific knowledge structuring offers a robust path to improving reasoning accuracy and robustness in language model generation. Our data and code can be found at https://github.com/pat-jj/RAS.
        ]]></description>
    </item>
    <item>
        <title>Beyond Pairwise: Global Zero-shot Temporal Graph Generation</title>
        <link>https://arxiv.org/abs/2502.11114</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.11114v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Alon Eirew, Kfir Bar, Ido Dagan</dc:creator>
        <description><![CDATA[
            背景：时间关系抽取（TRE）是自然语言处理的基础任务，大语言模型在TRE中的应用有限，现有方法多为成对分类，存在计算低效和全局一致性不足问题。方法：提出一种零样本TRE方法，一步生成文档完整时间图，再进行时间约束优化；引入新数据集OmniTemp。效果：实验表明该方法优于现有零样本方法，与有监督TRE模型相比也有竞争力。
            arXiv:2502.11114v2 Announce Type: replace 
Abstract: Temporal relation extraction (TRE) is a fundamental task in natural language processing (NLP) that involves identifying the temporal relationships between events in a document. Despite the advances in large language models (LLMs), their application to TRE remains limited. Most existing approaches rely on pairwise classification, where event pairs are classified in isolation, leading to computational inefficiency and a lack of global consistency in the resulting temporal graph. In this work, we propose a novel zero-shot method for TRE that generates a document's complete temporal graph in a single step, followed by temporal constraint optimization to refine predictions and enforce temporal consistency across relations. Additionally, we introduce OmniTemp, a new dataset with complete annotations for all pairs of targeted events within a document. Through experiments and analyses, we demonstrate that our method outperforms existing zero-shot approaches and offers a competitive alternative to supervised TRE models.
        ]]></description>
    </item>
    <item>
        <title>From the New World of Word Embeddings: A Comparative Study of Small-World Lexico-Semantic Networks in LLMs</title>
        <link>https://arxiv.org/abs/2502.11380</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.11380v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhu Liu, Ying Liu, KangYang Luo, Cunliang Kong, Maosong Sun</dc:creator>
        <description><![CDATA[
            背景：传统词汇语义网络用基于编码器模型或静态向量的嵌入构建，基于仅解码器大语言模型（LLMs）的嵌入研究不足。方法：从不同参数规模LLMs的输入嵌入构建词汇语义网络，对比分析其全局和局部结构。效果：这些网络有小世界特性，即高聚类和短路径长度；更大的LLMs产生更复杂网络，小世界效应弱、路径更长，反映出更丰富语义结构和关系，还通过多方面分析验证了方法。 
            arXiv:2502.11380v2 Announce Type: replace 
Abstract: Lexico-semantic networks represent words as nodes and their semantic relatedness as edges. While such networks are traditionally constructed using embeddings from encoder-based models or static vectors, embeddings from decoder-only large language models (LLMs) remain underexplored. Unlike encoder models, LLMs are trained with a next-token prediction objective, which does not directly encode the meaning of the current token. In this paper, we construct lexico-semantic networks from the input embeddings of LLMs with varying parameter scales and conduct a comparative analysis of their global and local structures. Our results show that these networks exhibit small-world properties, characterized by high clustering and short path lengths. Moreover, larger LLMs yield more intricate networks with less small-world effects and longer paths, reflecting richer semantic structures and relations. We further validate our approach through analyses of common conceptual pairs, structured lexical relations derived from WordNet, and a cross-lingual semantic network for qualitative words.
        ]]></description>
    </item>
    <item>
        <title>FANformer: Improving Large Language Models Through Effective Periodicity Modeling</title>
        <link>https://arxiv.org/abs/2502.21309</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.21309v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yihong Dong, Ge Li, Xue Jiang, Yongding Tao, Kechi Zhang, Hao Zhu, Huanyu Liu, Jiazheng Ding, Jia Li, Jinliang Deng, Hong Mei</dc:creator>
        <description><![CDATA[
            背景：周期性是人类学习范式中结构化知识获取和认知的基础，但Transformer中周期性建模的缺陷影响基于其构建的大语言模型学习效率和原理建立。方法：提出FANformer，将傅里叶分析网络融入注意力机制，修改特征投影过程实现高效周期性建模。效果：语言建模实验显示，扩大模型规模和训练令牌时FANformer学习效率超Transformer；预训练的FANformer - 1B在下游任务表现优于参数或训练令牌相近的开源模型，推理能力也更强。
            arXiv:2502.21309v2 Announce Type: replace 
Abstract: Periodicity, as one of the most important basic characteristics, lays the foundation for facilitating structured knowledge acquisition and systematic cognitive processes within human learning paradigms. However, the potential flaws of periodicity modeling in Transformer affect the learning efficiency and establishment of underlying principles from data for large language models (LLMs) built upon it. In this paper, we demonstrate that integrating effective periodicity modeling can improve the learning efficiency and performance of LLMs. We introduce FANformer, which adapts Fourier Analysis Network (FAN) into attention mechanism to achieve efficient periodicity modeling, by modifying the feature projection process of attention mechanism. Extensive experimental results on language modeling show that FANformer consistently outperforms Transformer when scaling up model size and training tokens, underscoring its superior learning efficiency. Our pretrained FANformer-1B exhibits marked improvements on downstream tasks compared to open-source LLMs with similar model parameters or training tokens. Moreover, we reveal that FANformer exhibits superior ability to learn and apply rules for reasoning compared to Transformer. The results position FANformer as an effective and promising architecture for advancing LLMs.
        ]]></description>
    </item>
    <item>
        <title>SCoRE: Benchmarking Long-Chain Reasoning in Commonsense Scenarios</title>
        <link>https://arxiv.org/abs/2503.06218</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.06218v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Weidong Zhan, Yue Wang, Nan Hu, Liming Xiao, Jingyuan Ma, Yuhang Qin, Zheng Li, Yixin Yang, Sirui Deng, Jinkun Ding, Wenhan Ma, Rui Li, Weilin Luo, Qun Liu, Zhifang Sui</dc:creator>
        <description><![CDATA[
            背景：长链推理是大语言模型面临的关键挑战，现有基准存在覆盖范围窄、推理路径短等局限。方法：提出SCoRE基准，从实体、关系和逻辑规则的场景模式合成多跳问题，包含10万道中英双语选择题，推理链2 - 11跳，有细粒度知识标签等。效果：在o3 - mini和Deepseek R1等模型上评估，最佳模型准确率仅69.78%，难题集仅47.91%，该基准可评估诊断模型长链推理能力。
            arXiv:2503.06218v2 Announce Type: replace 
Abstract: Currently, long-chain reasoning remains a key challenge for large language models (LLMs) because natural texts lack sufficient explicit reasoning data. However, existing benchmarks suffer from limitations such as narrow coverage, short reasoning paths, or high construction costs. We introduce SCoRE (Scenario-based Commonsense Reasoning Evaluation), a benchmark that synthesizes multi-hop questions from scenario schemas of entities, relations, and logical rules to assess long-chain commonsense reasoning. SCoRE contains 100k bilingual (Chinese-English) multiple-choice questions whose reasoning chains span 2-11 hops and are grouped into various difficulty levels. Each question is accompanied by fine-grained knowledge labels, explicit reasoning chains, and difficulty levels for diagnostic evaluation. Evaluation results on cutting-edge LLMs such as o3-mini and Deepseek R1 shows that even the best model attains only 69.78% accuracy on SCoRE (even only 47.91% on the hard set), with errors often stemming from rare knowledge, logical inconsistency, and over-interpretation of simple questions. SCoRE offers a scalable, extensible framework for evaluating and diagnosing the long-chain commonsense reasoning abilities of LLMs and guiding future advances in model design and training.
        ]]></description>
    </item>
    <item>
        <title>Unifying Text Semantics and Graph Structures for Temporal Text-attributed Graphs with Large Language Models</title>
        <link>https://arxiv.org/abs/2503.14411</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.14411v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Siwei Zhang, Yun Xiong, Yateng Tang, Xi Chen, Zian Jia, Zehao Gu, Jiarong Xu, Jiawei Zhang</dc:creator>
        <description><![CDATA[
            背景：现实中的时态图常有丰富文本信息，但现有时态图神经网络（TGNNs）静态嵌入文本且侧重结构信息，忽略文本语义的时态演变及语义与结构的相互作用。方法：提出CROSS框架，将时态文本属性图（TTAGs）建模分为时态语义提取和语义 - 结构信息统一两阶段，用大语言模型动态提取文本时态语义，生成统一语义和结构的表征。效果：在四个公开数据集和一个工业数据集上取得最优结果，时态链接预测平均MRR绝对增益24.7%，工业应用节点分类AUC增益3.7%。
            arXiv:2503.14411v2 Announce Type: replace 
Abstract: Temporal graph neural networks (TGNNs) have shown remarkable performance in temporal graph modeling. However, real-world temporal graphs often possess rich textual information, giving rise to temporal text-attributed graphs (TTAGs). Such combination of dynamic text semantics and evolving graph structures introduces heightened complexity. Existing TGNNs embed texts statically and rely heavily on encoding mechanisms that biasedly prioritize structural information, overlooking the temporal evolution of text semantics and the essential interplay between semantics and structures for synergistic reinforcement. To tackle these issues, we present \textbf{CROSS}, a flexible framework that seamlessly extends existing TGNNs for TTAG modeling. CROSS is designed by decomposing the TTAG modeling process into two phases: (i) temporal semantics extraction; and (ii) semantic-structural information unification. The key idea is to advance the large language models (LLMs) to dynamically extract the temporal semantics in text space and then generate cohesive representations unifying both semantics and structures. Specifically, we propose a Temporal Semantics Extractor in the CROSS framework, which empowers LLMs to offer the temporal semantic understanding of node's evolving contexts of textual neighborhoods, facilitating semantic dynamics. Subsequently, we introduce the Semantic-structural Co-encoder, which collaborates with the above Extractor for synthesizing illuminating representations by jointly considering both semantic and structural information while encouraging their mutual reinforcement. Extensive experiments show that CROSS achieves state-of-the-art results on four public datasets and one industrial dataset, with 24.7% absolute MRR gain on average in temporal link prediction and 3.7% AUC gain in node classification of industrial application.
        ]]></description>
    </item>
    <item>
        <title>Continual Multimodal Contrastive Learning</title>
        <link>https://arxiv.org/abs/2503.14963</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.14963v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiaohao Liu, Xiaobo Xia, See-Kiong Ng, Tat-Seng Chua</dc:creator>
        <description><![CDATA[
            背景：多模态对比学习（MCL）在对齐不同模态和生成联合空间的多模态表征方面取得进展，但多模态数据通常非一次性收集，从头训练计算成本高。方法：定义持续多模态对比学习（CMCL）问题，通过稳定性和可塑性两个原则构建CMCL，理论推导基于优化的方法，将更新梯度从两侧投影到子空间以避免干扰先前知识。效果：在多个数据集上实验，与先进持续学习基线对比，结果证明了方法的有效性。
            arXiv:2503.14963v2 Announce Type: replace 
Abstract: Multimodal contrastive learning (MCL) advances in aligning different modalities and generating multimodal representations in a joint space. By leveraging contrastive learning across diverse modalities, large-scale multimodal data enhances representational quality. However, a critical yet often overlooked challenge remains: multimodal data is rarely collected in a single process, and training from scratch is computationally expensive. Instead, emergent multimodal data can be used to optimize existing models gradually, \textit{i.e.}, models are trained on a sequence of modality pair data. We define this problem as Continual Multimodal Contrastive Learning (CMCL), an underexplored yet crucial research direction at the intersection of multimodal and continual learning. In this paper, we formulate CMCL through two specialized principles of stability and plasticity. We theoretically derive a novel optimization-based method, which projects updated gradients from dual sides onto subspaces where any gradient is prevented from interfering with the previously learned knowledge. Two upper bounds provide theoretical insights on both stability and plasticity in our solution. Beyond our theoretical contributions, we conduct experiments on multiple datasets by comparing our method against advanced continual learning baselines. The empirical results further support our claims and demonstrate the efficacy of our method. The code will be publicly available.
        ]]></description>
    </item>
    <item>
        <title>ReaRAG: Knowledge-guided Reasoning Enhances Factuality of Large Reasoning Models with Iterative Retrieval Augmented Generation</title>
        <link>https://arxiv.org/abs/2503.21729</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.21729v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhicheng Lee, Shulin Cao, Jinxin Liu, Jiajie Zhang, Weichuan Liu, Xiaoyin Che, Lei Hou, Juanzi Li</dc:creator>
        <description><![CDATA[
            背景：大型推理模型（LRMs）推理能力强，但主要依赖参数知识，事实准确性受限，现有基于强化学习的LRMs有过度思考和推理缺乏鲁棒性问题。方法：提出ReaRAG模型，有推理链长度上限的数据构建框架，先利用LRM生成思考，从预定义动作空间选动作，搜索动作会在RAG引擎执行查询，结果作为观察指导后续推理，直至选择结束动作。效果：在多跳问答任务上优于现有基线，有较强反思纠错能力，增强了LRMs事实性和推理能力。
            arXiv:2503.21729v3 Announce Type: replace 
Abstract: Large Reasoning Models (LRMs) exhibit remarkable reasoning abilities but rely primarily on parametric knowledge, limiting factual accuracy. While recent works equip reinforcement learning (RL)-based LRMs with retrieval capabilities, they suffer from overthinking and lack robustness in reasoning, reducing their effectiveness in question answering (QA) tasks. To address this, we propose ReaRAG, a factuality-enhanced reasoning model that explores diverse queries without excessive iterations. Our solution includes a novel data construction framework with an upper bound on the reasoning chain length. Specifically, we first leverage an LRM to generate deliberate thinking, then select an action from a predefined action space (Search and Finish). For Search action, a query is executed against the RAG engine, where the result is returned as observation to guide reasoning steps later. This process iterates until a Finish action is chosen. Benefiting from ReaRAG's strong reasoning capabilities, our approach outperforms existing baselines on multi-hop QA. Further analysis highlights its strong reflective ability to recognize errors and refine its reasoning trajectory. Our study enhances LRMs' factuality while effectively integrating robust reasoning for Retrieval-Augmented Generation (RAG).
        ]]></description>
    </item>
    <item>
        <title>RARE: Retrieval-Augmented Reasoning Modeling</title>
        <link>https://arxiv.org/abs/2503.23513</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.23513v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhengren Wang, Jiayang Yu, Dongsheng Ma, Zhe Chen, Yu Wang, Zhiyu Li, Feiyu Xiong, Yanfeng Wang, Weinan E, Linpeng Tang, Wentao Zhang</dc:creator>
        <description><![CDATA[
            背景：特定领域智能要求专业知识和复杂推理，大语言模型存在知识幻觉和推理能力不足问题。方法：提出检索增强推理建模（RARE）范式，将知识存储与推理优化分离，把领域知识外置到可检索源，训练时内化特定领域推理模式，通过向训练提示注入检索知识并使用掩码损失，将学习目标转变为情境化推理。效果：轻量级RARE训练模型（如Llama - 3.1 - 8B）可达最优性能，准确率比检索增强的GPT - 4和DeepSeek - R1高约20%。
            arXiv:2503.23513v2 Announce Type: replace 
Abstract: Domain-specific intelligence demands specialized knowledge and sophisticated reasoning for problem-solving, posing significant challenges for large language models (LLMs) that struggle with knowledge hallucination and inadequate reasoning capabilities under constrained parameter budgets. Inspired by Bloom's Taxonomy in educational theory, we propose Retrieval-Augmented Reasoning Modeling (RARE), a novel paradigm that decouples knowledge storage from reasoning optimization. RARE externalizes domain knowledge to retrievable sources and internalizes domain-specific reasoning patterns during training. Specifically, by injecting retrieved knowledge into training prompts with masked losses, RARE transforms learning objectives from rote memorization to contextualized reasoning. It enables models to bypass parameter-intensive memorization and prioritize the development of higher-order cognitive processes. Extensive experiments demonstrate that lightweight RARE-trained models (e.g., Llama-3.1-8B) could achieve state-of-the-art performance, surpassing retrieval-augmented GPT-4 and DeepSeek-R1 up to approximately 20\% accuracy. RARE establishes a paradigm shift where maintainable external knowledge bases synergize with compact, reasoning-optimized models, collectively driving more scalable domain-specific intelligence.
        ]]></description>
    </item>
    <item>
        <title>Effectively Controlling Reasoning Models through Thinking Intervention</title>
        <link>https://arxiv.org/abs/2503.24370</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.24370v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tong Wu, Chong Xiang, Jiachen T. Wang, G. Edward Suh, Prateek Mittal</dc:creator>
        <description><![CDATA[
            背景：推理增强的大语言模型在生成最终答案前显式生成中间推理步骤，有助于复杂问题求解，且为更细粒度控制模型行为提供了机会。方法：提出思维干预范式，通过策略性插入或修改特定思维标记来显式引导大语言模型的内部推理过程。效果：在多种任务中提升了推理模型能力，相比基线提示方法表现更优，如在指令遵循场景中准确率最多提高6.7%，指令层次推理提升15.4%，使用开源模型时对不安全提示的拒绝率提高40.0%。
            arXiv:2503.24370v2 Announce Type: replace 
Abstract: Reasoning-enhanced large language models (LLMs) explicitly generate intermediate reasoning steps prior to generating final answers, helping the model excel in complex problem-solving. In this paper, we demonstrate that this emerging generation framework offers a unique opportunity for more fine-grained control over model behavior. We propose Thinking Intervention, a novel paradigm designed to explicitly guide the internal reasoning processes of LLMs by strategically inserting or revising specific thinking tokens. We find that the Thinking Intervention paradigm enhances the capabilities of reasoning models across a wide range of tasks, including instruction following on IFEval, instruction hierarchy on SEP, and safety alignment on XSTest and SorryBench. Our results demonstrate that Thinking Intervention significantly outperforms baseline prompting approaches, achieving up to 6.7% accuracy gains in instruction-following scenarios, 15.4% improvements in reasoning about instruction hierarchies, and a 40.0% increase in refusal rates for unsafe prompts using open-source DeepSeek R1 models. Overall, our work opens a promising new research avenue for controlling reasoning LLMs.
        ]]></description>
    </item>
    <item>
        <title>SpecReason: Fast and Accurate Inference-Time Compute via Speculative Reasoning</title>
        <link>https://arxiv.org/abs/2504.07891</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.07891v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Rui Pan, Yinwei Dai, Zhihao Zhang, Gabriele Oliaro, Zhihao Jia, Ravi Netravali</dc:creator>
        <description><![CDATA[
            背景：大推理模型生成思维链虽提升复杂任务准确率，但因推理序列长和自回归解码导致推理延迟高。方法：提出SpecReason系统，用轻量级模型推测执行简单中间推理步骤，仅用高成本基础模型评估和修正推测输出。效果：在多种推理基准测试中，较普通大推理模型推理加速1.4 - 3.0倍，准确率提升0.4 - 9.0%；与无SpecReason的推测解码结合，额外降低8.8 - 58.0%的延迟。
            arXiv:2504.07891v2 Announce Type: replace 
Abstract: Recent advances in inference-time compute have significantly improved performance on complex tasks by generating long chains of thought (CoTs) using Large Reasoning Models (LRMs). However, this improved accuracy comes at the cost of high inference latency due to the length of generated reasoning sequences and the autoregressive nature of decoding. Our key insight in tackling these overheads is that LRM inference, and the reasoning that it embeds, is highly tolerant of approximations: complex tasks are typically broken down into simpler steps, each of which brings utility based on the semantic insight it provides for downstream steps rather than the exact tokens it generates. Accordingly, we introduce SpecReason, a system that automatically accelerates LRM inference by using a lightweight model to (speculatively) carry out simpler intermediate reasoning steps and reserving the costly base model only to assess (and potentially correct) the speculated outputs. Importantly, SpecReason's focus on exploiting the semantic flexibility of thinking tokens in preserving final-answer accuracy is complementary to prior speculation techniques, most notably speculative decoding, which demands token-level equivalence at each step. Across a variety of reasoning benchmarks, SpecReason achieves $1.4-3.0\times$ speedup over vanilla LRM inference while improving accuracy by $0.4-9.0\%$. Compared to speculative decoding without SpecReason, their combination yields an additional $8.8-58.0\%$ latency reduction. We open-source SpecReason at https://github.com/ruipeterpan/specreason.
        ]]></description>
    </item>
    <item>
        <title>TAMP: Token-Adaptive Layerwise Pruning in Multimodal Large Language Models</title>
        <link>https://arxiv.org/abs/2504.09897</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.09897v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jaewoo Lee, Keyang Xuan, Chanakya Ekbote, Sandeep Polisetty, Yi R. Fung, Paul Pu Liang</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型（MLLMs）功能强大但模型规模大，现有后训练剪枝方法用于MLLMs效果有限，因未考虑其跨层和模态的独特token属性。方法：提出TAMP剪枝框架，含多样性感知稀疏性（基于多模态输出token多样性调整每层稀疏率）和自适应多模态输入激活（用注意力分数识别代表性输入token指导非结构化权重剪枝）。效果：在LLaVA - NeXT和VideoLLaMA2上验证，各组件在多模态评估基准上显著优于现有剪枝技术。
            arXiv:2504.09897v3 Announce Type: replace 
Abstract: Multimodal Large Language Models (MLLMs) have shown remarkable versatility in understanding diverse multimodal data and tasks. However, these capabilities come with an increased model scale. While post-training pruning reduces model size in unimodal models, its application to MLLMs often yields limited success. Our analysis discovers that conventional methods fail to account for the unique token attributes across layers and modalities inherent to MLLMs. Inspired by this observation, we propose TAMP, a simple yet effective pruning framework tailored for MLLMs, featuring two key components: (1) Diversity-Aware Sparsity, which adjusts sparsity ratio per layer based on diversities among multimodal output tokens, preserving more parameters in high-diversity layers; and (2) Adaptive Multimodal Input Activation, which identifies representative multimodal input tokens using attention scores to guide unstructured weight pruning. We validate our method on two state-of-the-art MLLMs: LLaVA-NeXT, designed for vision-language tasks, and VideoLLaMA2, capable of processing audio, visual, and language modalities. Empirical experiments across various multimodal evaluation benchmarks demonstrate that each component of our approach substantially outperforms existing pruning techniques.
        ]]></description>
    </item>
    <item>
        <title>DioR: Adaptive Cognitive Detection and Contextual Retrieval Optimization for Dynamic Retrieval-Augmented Generation</title>
        <link>https://arxiv.org/abs/2504.10198</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.10198v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hanghui Guo, Jia Zhu, Shimin Di, Weijie Shi, Zhangze Chen, Jiajie Xu</dc:creator>
        <description><![CDATA[
            背景：动态检索增强生成（RAG）可减少大语言模型生成时的幻觉，但现有方法在控制检索触发机制和审查检索内容方面存在局限。方法：提出创新动态RAG方法DioR，包含自适应认知检测和上下文检索优化两部分，用于确定大模型何时需要检索及检索什么内容。效果：实验表明，DioR在所有任务上表现出色，证明了该方法的有效性。
            arXiv:2504.10198v2 Announce Type: replace 
Abstract: Dynamic Retrieval-augmented Generation (RAG) has shown great success in mitigating hallucinations in large language models (LLMs) during generation. However, existing dynamic RAG methods face significant limitations in two key aspects: 1) Lack of an effective mechanism to control retrieval triggers, and 2) Lack of effective scrutiny of retrieval content. To address these limitations, we propose an innovative dynamic RAG method, DioR (Adaptive Cognitive Detection and Contextual Retrieval Optimization), which consists of two main components: adaptive cognitive detection and contextual retrieval optimization, specifically designed to determine when retrieval is needed and what to retrieve for LLMs is useful. Experimental results demonstrate that DioR achieves superior performance on all tasks, demonstrating the effectiveness of our work.
        ]]></description>
    </item>
    <item>
        <title>GraphOmni: A Comprehensive and Extendable Benchmark Framework for Large Language Models on Graph-theoretic Tasks</title>
        <link>https://arxiv.org/abs/2504.12764</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.12764v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hao Xu, Xiangru Jian, Xinjian Zhao, Wei Pang, Chao Zhang, Suyuchen Wang, Qixin Zhang, Zhengyuan Dong, Joao Monteiro, Bang Liu, Qiuzhuang Sun, Tianshu Yu</dc:creator>
        <description><![CDATA[
            背景：当前缺乏全面评估大语言模型在图论任务推理能力的基准。方法：提出GraphOmni基准，涵盖多种图类型、序列化格式和提示方案，还提出受强化学习启发的框架来自适应选择影响推理能力的最优因素。效果：实验表明Claude - 3.5和o4 - mini等模型表现较好，但仍有提升空间，不同因素组合使模型性能有差异，开源和闭源模型受序列化及提示策略影响不同，该基准为图推理研究提供基础。
            arXiv:2504.12764v2 Announce Type: replace 
Abstract: This paper introduces GraphOmni, a comprehensive benchmark designed to evaluate the reasoning capabilities of LLMs on graph-theoretic tasks articulated in natural language. GraphOmni encompasses diverse graph types, serialization formats, and prompting schemes, significantly exceeding prior efforts in both scope and depth. Through extensive systematic evaluation, we identify critical interactions among these dimensions, demonstrating their substantial impact on model performance. Our experiments reveal that state-of-the-art models like Claude-3.5 and o4-mini consistently outperform other models, yet even these leading models exhibit substantial room for improvement. Performance variability is evident depending on the specific combinations of factors we considered, underscoring the necessity of comprehensive evaluations across these interconnected dimensions. Additionally, we observe distinct impacts of serialization and prompting strategies between open-source and closed-source models, encouraging the development of tailored approaches. Motivated by the findings, we also propose a reinforcement learning-inspired framework that adaptively selects the optimal factors influencing LLM reasoning capabilities. This flexible and extendable benchmark not only deepens our understanding of LLM performance on structured tasks but also provides a robust foundation for advancing research in LLM-based graph reasoning.
        ]]></description>
    </item>
    <item>
        <title>CoT-RAG: Integrating Chain of Thought and Retrieval-Augmented Generation to Enhance Reasoning in Large Language Models</title>
        <link>https://arxiv.org/abs/2504.13534</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.13534v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Feiyang Li, Peng Fang, Zhan Shi, Arijit Khan, Fang Wang, Dan Feng, Weihao Wang, Xin Zhang, Yongjian Cui</dc:creator>
        <description><![CDATA[
            背景：思维链推理能提升大语言模型在复杂任务上的表现，但存在仅依赖模型生成推理链不可靠、自然语言推理步骤干扰模型推理逻辑的问题。方法：提出CoT - RAG框架，包含知识图谱驱动的思维链生成、可学习的知识案例感知RAG、伪程序提示执行三个关键设计。效果：在九个公共数据集的三项推理任务上，相比现有方法准确率提升4.0% - 44.3%；在四个特定领域数据集测试中，展现出高准确率和高效执行能力。
            arXiv:2504.13534v2 Announce Type: replace 
Abstract: Chain-of-thought (CoT) reasoning boosts large language models' (LLMs) performance on complex tasks but faces two key limitations: a lack of reliability when solely relying on LLM-generated reasoning chains and interference from natural language reasoning steps with the models' inference process, also known as the inference logic of LLMs. To address these issues, we propose CoT-RAG, a novel reasoning framework with three key designs: (i) Knowledge Graph-driven CoT Generation,featuring knowledge graphs to modulate reasoning chain generation of LLMs, thereby enhancing reasoning credibility; (ii) Learnable Knowledge Case-aware RAG, which incorporates retrieval-augmented generation (RAG) into knowledge graphs to retrieve relevant sub-cases and sub-descriptions, providing LLMs with learnable information; (iii) Pseudo-Program Prompting Execution, which promotes greater logical rigor by guiding LLMs to execute reasoning tasks as pseudo-programs. Evaluations on nine public datasets spanning three reasoning tasks reveal significant accuracy gains--ranging from 4.0% to 44.3%--over state-of-the-art methods. Furthermore, tests on four domain-specific datasets demonstrate exceptional accuracy and efficient execution, underscoring its practical applicability and scalability.
        ]]></description>
    </item>
    <item>
        <title>Dynamic Early Exit in Reasoning Models</title>
        <link>https://arxiv.org/abs/2504.15895</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.15895v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chenxu Yang, Qingyi Si, Yongjie Duan, Zheliang Zhu, Chenyu Zhu, Qiaowei Li, Zheng Lin, Li Cao, Weiping Wang</dc:creator>
        <description><![CDATA[
            背景：大型推理语言模型依赖测试时扩展长思维链来解决复杂任务，但长思维链过度思考会降低解题效率，且可能因推理步骤冗余导致精度损失。方法：提出一种简单有效的方法，让大语言模型在生成时通过早期退出自截断思维链序列，在潜在推理过渡点监测模型行为，当模型对试验答案有高置信度时动态终止下一推理链生成。效果：在10个推理基准测试中，该方法对11种前沿推理大模型有效，平均将思维链序列长度减少19.1% - 80.1%，精度提升0.3% - 5.0%。
            arXiv:2504.15895v2 Announce Type: replace 
Abstract: Recent advances in large reasoning language models (LRLMs) rely on test-time scaling, which extends long chain-of-thought (CoT) generation to solve complex tasks. However, overthinking in long CoT not only slows down the efficiency of problem solving, but also risks accuracy loss due to the extremely detailed or redundant reasoning steps. We propose a simple yet effective method that allows LLMs to self-truncate CoT sequences by early exit during generation. Instead of relying on fixed heuristics, the proposed method monitors model behavior at potential reasoning transition points (e.g.,"Wait" tokens) and dynamically terminates the next reasoning chain's generation when the model exhibits high confidence in a trial answer. Our method requires no additional training and can be seamlessly integrated into existing o1-like reasoning LLMs. Experiments on 10 reasoning benchmarks (e.g., GSM8K, MATH-500, AMC, GPQA, AIME and LiveCodeBench) show that the proposed method is consistently effective on 11 cutting-edge reasoning LLMs of varying series and sizes, reducing the length of CoT sequences by an average of 19.1% to 80.1% while improving accuracy by 0.3% to 5.0%.
        ]]></description>
    </item>
    <item>
        <title>Process Reward Models That Think</title>
        <link>https://arxiv.org/abs/2504.16828</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.16828v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Muhammad Khalifa, Rishabh Agarwal, Lajanugen Logeswaran, Jaekyeom Kim, Hao Peng, Moontae Lee, Honglak Lee, Lu Wang</dc:creator>
        <description><![CDATA[
            背景：逐步验证器（PRMs）是测试时扩展的关键，但训练成本高。方法：提出ThinkPRM，一种长思维链验证器，通过生成验证思维链来验证解决方案的每一步，在比判别式PRMs所需少几个数量级的过程标签上微调。效果：在多个具有挑战性的基准测试中表现出色，仅使用PRM800K中1%的过程标签就超越了LLM-as-a-Judge和判别式验证器；在域外评估中，比在完整PRM800K上训练的判别式验证器分别高出8%和4.5%；在相同令牌预算下，在ProcessBench子集上比LLM-as-a-Judge高出7.2%。
            arXiv:2504.16828v2 Announce Type: replace 
Abstract: Step-by-step verifiers -- also known as process reward models (PRMs) -- are a key ingredient for test-time scaling. PRMs require step-level supervision, making them expensive to train. This work aims to build data-efficient PRMs as verbalized step-wise reward models that verify every step in the solution by generating a verification chain-of-thought (CoT). We propose ThinkPRM, a long CoT verifier fine-tuned on orders of magnitude fewer process labels than those required by discriminative PRMs. Our approach capitalizes on the inherent reasoning abilities of long CoT models, and outperforms LLM-as-a-Judge and discriminative verifiers -- using only 1% of the process labels in PRM800K -- across several challenging benchmarks. Specifically, ThinkPRM beats the baselines on ProcessBench, MATH-500, and AIME '24 under best-of-N selection and reward-guided search. In an out-of-domain evaluation on a subset of GPQA-Diamond and LiveCodeBench, our PRM surpasses discriminative verifiers trained on the full PRM800K by 8% and 4.5%, respectively. Lastly, under the same token budget, ThinkPRM scales up verification compute more effectively compared to LLM-as-a-Judge, outperforming it by 7.2% on a subset of ProcessBench. Our work highlights the value of generative, long CoT PRMs that can scale test-time compute for verification while requiring minimal supervision for training. Our code, data, and models will be released at https://github.com/mukhal/thinkprm.
        ]]></description>
    </item>
    <item>
        <title>SPC: Evolving Self-Play Critic via Adversarial Games for LLM Reasoning</title>
        <link>https://arxiv.org/abs/2504.19162</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.19162v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiaqi Chen, Bang Zhang, Ruotian Ma, Peisong Wang, Xiaodan Liang, Zhaopeng Tu, Xiaolong Li, Kwan-Yee K. Wong</dc:creator>
        <description><![CDATA[
            背景：评估大语言模型逐步推理的可靠性颇具挑战，获取高质量步骤级监督困难且成本高。方法：提出Self - Play Critic（SPC）方法，通过对抗自博弈让评判模型评估推理步骤，无需手动步骤级标注。将基础模型的两个副本微调为“狡猾生成器”和“评判器”进行对抗博弈，依据博弈结果用强化学习迭代改进。效果：在三个推理过程基准测试中，SPC逐步提升错误检测能力，如在ProcessBench上准确率从70.8%提升到77.7%，还显著提高大模型数学推理性能。
            arXiv:2504.19162v2 Announce Type: replace 
Abstract: Evaluating the step-by-step reliability of large language model (LLM) reasoning, such as Chain-of-Thought, remains challenging due to the difficulty and cost of obtaining high-quality step-level supervision. In this paper, we introduce Self-Play Critic (SPC), a novel approach where a critic model evolves its ability to assess reasoning steps through adversarial self-play games, eliminating the need for manual step-level annotation. SPC involves fine-tuning two copies of a base model to play two roles, namely a "sneaky generator" that deliberately produces erroneous steps designed to be difficult to detect, and a "critic" that analyzes the correctness of reasoning steps. These two models engage in an adversarial game in which the generator aims to fool the critic, while the critic model seeks to identify the generator's errors. Using reinforcement learning based on the game outcomes, the models iteratively improve; the winner of each confrontation receives a positive reward and the loser receives a negative reward, driving continuous self-evolution. Experiments on three reasoning process benchmarks (ProcessBench, PRM800K, DeltaBench) demonstrate that our SPC progressively enhances its error detection capabilities (e.g., accuracy increases from 70.8% to 77.7% on ProcessBench) and surpasses strong baselines, including distilled R1 model. Furthermore, SPC can guide the test-time search of diverse LLMs and significantly improve their mathematical reasoning performance on MATH500 and AIME2024, surpassing those guided by state-of-the-art process reward models.
        ]]></description>
    </item>
    <item>
        <title>UniversalRAG: Retrieval-Augmented Generation over Corpora of Diverse Modalities and Granularities</title>
        <link>https://arxiv.org/abs/2504.20734</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.20734v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Woongyeong Yeo, Kangsan Kim, Soyeong Jeong, Jinheon Baek, Sung Ju Hwang</dc:creator>
        <description><![CDATA[
            背景：现有检索增强生成（RAG）多局限于文本语料，即便拓展到其他模态也多针对单一模态语料，难以满足现实中多样的知识需求。方法：提出UniversalRAG框架，采用模态感知路由机制动态识别合适的特定模态语料库并检索，还将各模态组织成多粒度层次以适配查询。效果：在8个跨模态基准测试中验证，优于多种特定模态和统一基线模型。
            arXiv:2504.20734v2 Announce Type: replace 
Abstract: Retrieval-Augmented Generation (RAG) has shown substantial promise in improving factual accuracy by grounding model responses with external knowledge relevant to queries. However, most existing RAG approaches are limited to a text-only corpus, and while recent efforts have extended RAG to other modalities such as images and videos, they typically operate over a single modality-specific corpus. In contrast, real-world queries vary widely in the type of knowledge they require, which a single type of knowledge source cannot address. To address this, we introduce UniversalRAG, a novel RAG framework designed to retrieve and integrate knowledge from heterogeneous sources with diverse modalities and granularities. Specifically, motivated by the observation that forcing all modalities into a unified representation space derived from a single aggregated corpus causes a modality gap, where the retrieval tends to favor items from the same modality as the query, we propose a modality-aware routing mechanism that dynamically identifies the most appropriate modality-specific corpus and performs targeted retrieval within it. Also, beyond modality, we organize each modality into multiple granularity levels, enabling fine-tuned retrieval tailored to the complexity and scope of the query. We validate UniversalRAG on 8 benchmarks spanning multiple modalities, showing its superiority over various modality-specific and unified baselines.
        ]]></description>
    </item>
    <item>
        <title>GLIP-OOD: Zero-Shot Graph OOD Detection with Graph Foundation Model</title>
        <link>https://arxiv.org/abs/2504.21186</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.21186v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Haoyan Xu, Zhengtao Yao, Xuzhi Zhang, Ziyi Wang, Langzhou He, Yushun Dong, Philip S. Yu, Mengyuan Li, Yue Zhao</dc:creator>
        <description><![CDATA[
            背景：图结构数据的零样本分布外（OOD）检测因复杂关系结构和缺乏强大预训练模型而未充分研究。方法：利用图基础模型（GFM）实现零样本图OOD检测，在无OOD标签名时，引入GLIP - OOD框架用大语言模型从无标签数据生成伪OOD标签。效果：仅用类别标签名，GFM就能有效进行OOD检测，常超依赖大量标注节点数据的“有监督”方法；GLIP - OOD在四个基准文本属性图数据集上表现与最先进有监督方法相当。
            arXiv:2504.21186v2 Announce Type: replace 
Abstract: Out-of-distribution (OOD) detection is critical for ensuring the safety and reliability of machine learning systems, particularly in dynamic and open-world environments. In the vision and text domains, zero-shot OOD detection - which requires no training on in-distribution (ID) data - has advanced significantly through the use of large-scale pretrained models, such as vision-language models (VLMs) and large language models (LLMs). However, zero-shot OOD detection in graph-structured data remains largely unexplored, primarily due to the challenges posed by complex relational structures and the absence of powerful, large-scale pretrained models for graphs. In this work, we take the first step toward enabling zero-shot graph OOD detection by leveraging a graph foundation model (GFM). Our experiments show that, when provided only with class label names for both ID and OOD categories, the GFM can effectively perform OOD detection - often surpassing existing "supervised" OOD detection methods that rely on extensive labeled node data. We further address the practical scenario in which OOD label names are not available in real-world settings by introducing GLIP-OOD, a framework that uses LLMs to generate semantically informative pseudo-OOD labels from unlabeled data. These generated OOD labels allow the GFM to better separate ID and OOD classes, facilitating more precise OOD detection - all without any labeled nodes (only ID label names). To our knowledge, this is the first approach to achieve node-level graph OOD detection in a fully zero-shot setting, and it attains performance comparable to state-of-the-art supervised methods on four benchmark text-attributed graph datasets.
        ]]></description>
    </item>
    <item>
        <title>Graph Synthetic Out-of-Distribution Exposure with Large Language Models</title>
        <link>https://arxiv.org/abs/2504.21198</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.21198v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Haoyan Xu, Zhengtao Yao, Ziyi Wang, Zhan Cheng, Xiyang Hu, Mengyuan Li, Yue Zhao</dc:creator>
        <description><![CDATA[
            图的分布外（OOD）检测对确保开放世界和安全敏感应用中模型的鲁棒性至关重要。现有方法多在分布内（ID）数据上训练分类器，再用事后评分检测OOD实例，虽OOD暴露可提升检测效果，但现有图方法常需真实OOD节点，不切实际且成本高。本文提出GOE - LLM框架，利用大语言模型（LLM）在无真实OOD节点情况下实现文本属性图的OOD暴露。该框架有两条流水线，识别伪OOD节点和生成合成OOD节点。实验显示，GOE - LLM大幅超越无OOD暴露的方法，OOD检测的AUROC提升达23.5%，与依赖真实OOD标签的方法性能相当。
            arXiv:2504.21198v2 Announce Type: replace 
Abstract: Out-of-distribution (OOD) detection in graphs is critical for ensuring model robustness in open-world and safety-sensitive applications. Existing graph OOD detection approaches typically train an in-distribution (ID) classifier on ID data alone, then apply post-hoc scoring to detect OOD instances. While OOD exposure - adding auxiliary OOD samples during training - can improve detection, current graph-based methods often assume access to real OOD nodes, which is often impractical or costly. In this paper, we present GOE-LLM, a framework that leverages Large Language Models (LLMs) to achieve OOD exposure on text-attributed graphs without using any real OOD nodes. GOE-LLM introduces two pipelines: (1) identifying pseudo-OOD nodes from the initially unlabeled graph using zero-shot LLM annotations, and (2) generating semantically informative synthetic OOD nodes via LLM-prompted text generation. These pseudo-OOD nodes are then used to regularize ID classifier training and enhance OOD detection awareness. Empirical results on multiple benchmarks show that GOE-LLM substantially outperforms state-of-the-art methods without OOD exposure, achieving up to a 23.5% improvement in AUROC for OOD detection, and attains performance on par with those relying on real OOD labels for exposure.
        ]]></description>
    </item>
    <item>
        <title>Self-Generated In-Context Examples Improve LLM Agents for Sequential Decision-Making Tasks</title>
        <link>https://arxiv.org/abs/2505.00234</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.00234v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Vishnu Sarukkai, Zhiqiang Xie, Kayvon Fatahalian</dc:creator>
        <description><![CDATA[
            背景：提升大语言模型（LLM）在序列决策任务中的表现，通常需大量特定任务知识工程。方法：提出让代理自动从自身成功经验中学习的方法，构建并完善自生成轨迹数据库，作为未来任务的上下文示例，还采用基于种群训练的数据库级筛选和基于经验效用的示例级筛选。效果：在三个基准测试中，简单积累成功轨迹就能大幅提升性能，经改进后在ALFWorld上成功率达93%，超越使用更强LLM和手工组件的方法。 
            arXiv:2505.00234v3 Announce Type: replace 
Abstract: Improving Large Language Model (LLM) agents for sequential decision-making tasks typically requires extensive task-specific knowledge engineering--custom prompts, curated examples, and specialized observation/action spaces. We investigate a different approach where agents automatically improve by learning from their own successful experiences without human intervention. Our method constructs and refines a database of self-generated trajectories that serve as in-context examples for future tasks. Even naive accumulation of successful trajectories yields substantial performance gains across three diverse benchmarks: ALFWorld (73% to 89%), Wordcraft (55% to 64%), and InterCode-SQL (75% to 79%). These improvements exceed those achieved by upgrading from gpt-4o-mini to gpt-4o and match the performance of allowing multiple attempts per task. We further enhance this approach with two innovations: database-level curation using population-based training to propagate high-performing example collections, and exemplar-level curation that selectively retains trajectories based on their empirical utility as in-context examples. With these enhancements, our method achieves 93% success on ALFWorld--surpassing approaches that use more powerful LLMs and hand-crafted components. Our trajectory bootstrapping technique demonstrates that agents can autonomously improve through experience, offering a scalable alternative to labor-intensive knowledge engineering.
        ]]></description>
    </item>
    <item>
        <title>Synthesize-on-Graph: Knowledgeable Synthetic Data Generation for Continue Pre-training of Large Language Models</title>
        <link>https://arxiv.org/abs/2505.00979</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.00979v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xuhui Jiang, Shengjie Ma, Chengjin Xu, Cehao Yang, Liyu Zhang, Jian Guo</dc:creator>
        <description><![CDATA[
            大语言模型学习小而专业的语料时数据效率低，现有合成数据生成方法忽视跨文档知识关联。为此提出Synthetic-on-Graph（SoG）框架，通过从原语料中提取实体和概念构建上下文图，采用图游走策略进行知识关联采样，还集成思维链和对比澄清合成以提升数据质量。实验表明，SoG在多跳文档问答数据集上优于现有最优方法，在阅读理解任务数据集上表现相当，展现出更好的泛化能力。
            arXiv:2505.00979v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have achieved remarkable success but remain data-inefficient, especially when learning from small, specialized corpora with limited and proprietary data. Existing synthetic data generation methods for continue pre-training focus on intra-document content and overlook cross-document knowledge associations, limiting content diversity and depth. We propose Synthetic-on-Graph (SoG), a synthetic data generation framework that incorporates cross-document knowledge associations for efficient corpus expansion. SoG constructs a context graph by extracting entities and concepts from the original corpus, representing cross-document associations, and employing a graph walk strategy for knowledge-associated sampling. This enhances synthetic data diversity and coherence, enabling models to learn complex knowledge structures and handle rare knowledge. To further improve synthetic data quality, we integrate Chain-of-Thought (CoT) and Contrastive Clarifying (CC) synthetic, enhancing reasoning processes and discriminative power. Experiments show that SoG outperforms the state-of-the-art (SOTA) method in a multi-hop document Q&amp;A dataset while performing comparably to the SOTA method on the reading comprehension task datasets, which also underscores the better generalization capability of SoG. Our work advances synthetic data generation and provides practical solutions for efficient knowledge acquisition in LLMs, especially in domains with limited data availability.
        ]]></description>
    </item>
    <item>
        <title>ReGraP-LLaVA: Reasoning enabled Graph-based Personalized Large Language and Vision Assistant</title>
        <link>https://arxiv.org/abs/2505.03654</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.03654v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yifan Xiang, Zhenxi Zhang, Bin Li, Yixuan Weng, Shoujun Zhou, Yangfan He, Keqin Li</dc:creator>
        <description><![CDATA[
            背景：现有个性化多模态大语言模型在挖掘对象关系和推理方面存在局限，如训练数据缺乏可学习对象关系的多对象集，模型忽视概念间关系且实验聚焦单概念。方法：提出含120组个性化知识的数据集ReGraP，包含图像、知识图谱（KGs）和思维链（CoT）问答对；提出MLLM模型ReGraP - LLaVA，用KGs和CoT问答对训练，设计软硬图提示法对齐KGs与语义空间；建立ReGraP基准评估模型能力。效果：该模型能学习个性化知识并进行关系推理，优于对比方法。
            arXiv:2505.03654v2 Announce Type: replace 
Abstract: Recent advances in personalized MLLMs enable effective capture of user-specific concepts, supporting both recognition of personalized concepts and contextual captioning. However, humans typically explore and reason over relations among objects and individuals, transcending surface-level information to achieve more personalized and contextual understanding. To this end, existing methods may face three main limitations: Their training data lacks multi-object sets in which relations among objects are learnable. Building on the limited training data, their models overlook the relations between different personalized concepts and fail to reason over them. Their experiments mainly focus on a single personalized concept, where evaluations are limited to recognition and captioning tasks. To address the limitations, we present a new dataset named ReGraP, consisting of 120 sets of personalized knowledge. Each set includes images, KGs, and CoT QA pairs derived from the KGs, enabling more structured and sophisticated reasoning pathways. We propose ReGraP-LLaVA, an MLLM trained with the corresponding KGs and CoT QA pairs, where soft and hard graph prompting methods are designed to align KGs within the model's semantic space. We establish the ReGraP Benchmark, which contains diverse task types: multiple-choice, fill-in-the-blank, True/False, and descriptive questions in both open- and closed-ended settings. The proposed benchmark is designed to evaluate the relational reasoning and knowledge-connection capability of personalized MLLMs. We conduct experiments on the proposed ReGraP-LLaVA and other competitive MLLMs. Results show that the proposed model not only learns personalized knowledge but also performs relational reasoning in responses, achieving the SoTA performance compared with the competitive methods. All the codes and datasets are released at: https://github.com/xyfyyds/ReGraP.
        ]]></description>
    </item>
    <item>
        <title>Reward-SQL: Boosting Text-to-SQL via Stepwise Reasoning and Process-Supervised Rewards</title>
        <link>https://arxiv.org/abs/2505.04671</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.04671v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuxin Zhang, Meihao Fan, Ju Fan, Mingyang Yi, Yuyu Luo, Jian Tan, Guoliang Li</dc:creator>
        <description><![CDATA[
            背景：大语言模型虽提升了文本到 SQL 任务表现，但引入外部过程奖励模型（PRMs）可能扭曲推理轨迹。方法：提出 Reward - SQL 框架，遵循“冷启动，后 PRM 监督”范式，先训练模型用公共表表达式将 SQL 查询分解为结构化逐步推理链，再研究四种整合 PRMs 的策略，发现结合在线训练信号与 PRM 引导推理效果最佳。效果：在 BIRD 基准上，使 PRM 监督的模型性能提升 13.1%，基于 Qwen2.5 - Coder - 7B - Instruct 的策略模型在开发集上准确率达 68.9%，优于同规模基线方法。
            arXiv:2505.04671v2 Announce Type: replace 
Abstract: Recent advances in large language models (LLMs) have significantly improved performance on the Text-to-SQL task by leveraging their powerful reasoning capabilities. To enhance accuracy during the reasoning process, external Process Reward Models (PRMs) can be introduced during training and inference to provide fine-grained supervision. However, if misused, PRMs may distort the reasoning trajectory and lead to suboptimal or incorrect SQL generation. To address this challenge, we propose Reward-SQL, a framework that systematically explores how to incorporate PRMs into the Text-to-SQL reasoning process effectively. Our approach follows a "cold start, then PRM supervision" paradigm. Specifically, we first train the model to decompose SQL queries into structured stepwise reasoning chains using common table expressions (Chain-of-CTEs), establishing a strong and interpretable reasoning baseline. Then, we investigate four strategies for integrating PRMs, and find that combining PRM as an online training signal (e.g.,GRPO) with PRM-guided inference (e.g., best-of-N sampling) yields the best results. Empirically, on the BIRD benchmark, Reward-SQL enables models supervised by PRM (7B) to achieve a 13.1% performance gain across various guidance strategies. Notably, our GRPO-aligned policy model based on Qwen2.5-Coder-7B-Instruct achieves 68.9% accuracy on the BIRD development set, outperforming all baseline methods under the same model size. These results demonstrate the effectiveness of Reward-SQL in leveraging reward-based supervision for Text-to-SQL reasoning.
        ]]></description>
    </item>
    <item>
        <title>Learn to Think: Bootstrapping LLM Reasoning Capability Through Graph Representation Learning</title>
        <link>https://arxiv.org/abs/2505.06321</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.06321v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hang Gao, Chenhao Zhang, Tie Wang, Junsuo Zhao, Fengge Wu, Changwen Zheng, Huaping Liu</dc:creator>
        <description><![CDATA[
            背景：大语言模型虽成功，但训练成本高、解决复杂推理问题能力有限，现有结构化范式扩展推理能力的方法灵活性和泛化性不足。方法：提出新框架，将问题推理过程建模为图，用基于大语言模型的图学习引导推理步骤自适应生成，引入图神经网络模块对推理过程进行表征学习以实时调整模型和提示。效果：实验表明，该方法无需额外训练和特定任务提示设计，显著提升多任务推理性能。代码见https://github.com/zch65458525/L2T 。
            arXiv:2505.06321v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have achieved remarkable success across various domains. However, they still face significant challenges, including high computational costs for training and limitations in solving complex reasoning problems. Although existing methods have extended the reasoning capabilities of LLMs through structured paradigms, these approaches often rely on task-specific prompts and predefined reasoning processes, which constrain their flexibility and generalizability. To address these limitations, we propose a novel framework that leverages graph learning to enable more flexible and adaptive reasoning capabilities for LLMs. Specifically, this approach models the reasoning process of a problem as a graph and employs LLM-based graph learning to guide the adaptive generation of each reasoning step. To further enhance the adaptability of the model, we introduce a Graph Neural Network (GNN) module to perform representation learning on the generated reasoning process, enabling real-time adjustments to both the model and the prompt. Experimental results demonstrate that this method significantly improves reasoning performance across multiple tasks without requiring additional training or task-specific prompt design. Code can be found in https://github.com/zch65458525/L2T.
        ]]></description>
    </item>
    <item>
        <title>Accelerating Chain-of-Thought Reasoning: When Goal-Gradient Importance Meets Dynamic Skipping</title>
        <link>https://arxiv.org/abs/2505.08392</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.08392v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ren Zhuang, Ben Wang, Shuifa Sun</dc:creator>
        <description><![CDATA[
            大语言模型利用思维链（CoT）提示处理复杂任务，但推理轨迹冗长低效，现有CoT压缩技术存在局限。为此提出Adaptive GoGI - Skip框架，通过监督微调学习动态CoT压缩。该框架有两项创新：一是Goal - Gradient Importance（GoGI）指标，通过测量中间表征对最终答案损失的梯度影响识别关键标记；二是Adaptive Dynamic Skipping（ADS）机制，根据模型不确定性动态调节压缩率。该方法在多个推理基准测试中展现出强泛化性，平均减少超45%的CoT标记数，推理速度提升1.6 - 2.0倍，且保持高推理准确率。
            arXiv:2505.08392v2 Announce Type: replace 
Abstract: Large Language Models leverage Chain-of-Thought (CoT) prompting for complex tasks, but their reasoning traces are often excessively verbose and inefficient, leading to significant computational costs and latency. Current CoT compression techniques typically rely on generic importance metrics and static compression rates, which may inadvertently remove functionally critical tokens or fail to adapt to varying reasoning complexity. To overcome these limitations, we propose Adaptive GoGI-Skip, a novel framework learning dynamic CoT compression via supervised fine-tuning. This approach introduces two synergistic innovations: (1) Goal-Gradient Importance (GoGI), a novel metric accurately identifying functionally relevant tokens by measuring the gradient influence of their intermediate representations on the final answer loss, and (2) Adaptive Dynamic Skipping (ADS), a mechanism dynamically regulating the compression rate based on runtime model uncertainty while ensuring local coherence through an adaptive N-token constraint. To our knowledge, this is the first work unifying a goal-oriented, gradient-based importance metric with dynamic, uncertainty-aware skipping for CoT compression. Trained on compressed MATH data, Adaptive GoGI-Skip demonstrates strong cross-domain generalization across diverse reasoning benchmarks including AIME, GPQA, and GSM8K. It achieves substantial efficiency gains - reducing CoT token counts by over 45% on average and delivering 1.6-2.0 times inference speedups - while maintaining high reasoning accuracy. Notably, it significantly outperforms existing baselines by preserving accuracy even at high effective compression rates, advancing the state of the art in the CoT reasoning efficiency-accuracy trade-off.
        ]]></description>
    </item>
    <item>
        <title>Learning to Think: Information-Theoretic Reinforcement Fine-Tuning for LLMs</title>
        <link>https://arxiv.org/abs/2505.10425</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.10425v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jingyao Wang, Wenwen Qiang, Zeen Song, Changwen Zheng, Hui Xiong</dc:creator>
        <description><![CDATA[
            背景：现有大语言模型推理方法未兼顾推理效果与计算效率，常产生过长推理链、浪费token。方法：提出Learning to Think（L2T）信息论强化微调框架，将查询 - 响应交互视为多阶段分层会话，提出通用密集过程奖励，基于PAC - Bayes边界和Fisher信息矩阵快速估计奖励，通过强化学习优化模型。效果：理论分析表明可降低计算复杂度且估计精度高，实验结果显示在不同推理基准和基础模型上，能提升推理效果和效率。
            arXiv:2505.10425v2 Announce Type: replace 
Abstract: Large language models (LLMs) excel at complex tasks thanks to advances in reasoning abilities. However, existing methods overlook the trade-off between reasoning effectiveness and computational efficiency, often encouraging unnecessarily long reasoning chains and wasting tokens. To address this, we propose Learning to Think (L2T), an information-theoretic reinforcement fine-tuning framework for LLMs to make the models achieve optimal reasoning with fewer tokens. Specifically, L2T treats each query-response interaction as a hierarchical session of multiple episodes and proposes a universal dense process reward, i.e., quantifies the episode-wise information gain in parameters, requiring no extra annotations or task-specific evaluators. We propose a method to quickly estimate this reward based on PAC-Bayes bounds and the Fisher information matrix. Theoretical analyses show that it significantly reduces computational complexity with high estimation accuracy. By immediately rewarding each episode's contribution and penalizing excessive updates, L2T optimizes the model via reinforcement learning to maximize the use of each episode and achieve effective updates. Empirical results on various reasoning benchmarks and base models demonstrate the advantage of L2T across different tasks, boosting both reasoning effectiveness and efficiency.
        ]]></description>
    </item>
    <item>
        <title>SubGCache: Accelerating Graph-based RAG with Subgraph-level KV Cache</title>
        <link>https://arxiv.org/abs/2505.10951</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.10951v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qiuyu Zhu, Liang Zhang, Qianxiong Xu, Cheng Long, Jie Zhang</dc:creator>
        <description><![CDATA[
            背景：基于图的检索增强生成（RAG）可让大语言模型通过图检索结合结构化知识，但不同查询可能检索到相似子图。方法：提出SubGCache，基于子图嵌入对查询聚类，为每个簇构建代表性子图并预计算其键值（KV）缓存，查询复用缓存避免重复计算。效果：在两个新数据集上实验表明，SubGCache能持续降低推理延迟，生成质量相当甚至更好，首词生成时间最多减少6.68倍。
            arXiv:2505.10951v2 Announce Type: replace 
Abstract: Graph-based retrieval-augmented generation (RAG) enables large language models (LLMs) to incorporate structured knowledge via graph retrieval as contextual input, enhancing more accurate and context-aware reasoning. We observe that for different queries, it could retrieve similar subgraphs as prompts, and thus we propose SubGCache, which aims to reduce inference latency by reusing computation across queries with similar structural prompts (i.e., subgraphs). Specifically, SubGCache clusters queries based on subgraph embeddings, constructs a representative subgraph for each cluster, and pre-computes the key-value (KV) cache of the representative subgraph. For each query with its retrieved subgraph within a cluster, it reuses the pre-computed KV cache of the representative subgraph of the cluster without computing the KV tensors again for saving computation. Experiments on two new datasets across multiple LLM backbones and graph-based RAG frameworks demonstrate that SubGCache consistently reduces inference latency with comparable and even improved generation quality, achieving up to 6.68$\times$ reduction in time-to-first-token (TTFT).
        ]]></description>
    </item>
    <item>
        <title>OntoURL: A Benchmark for Evaluating Large Language Models on Symbolic Ontological Understanding, Reasoning and Learning</title>
        <link>https://arxiv.org/abs/2505.11031</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.11031v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiao Zhang, Huiyuan Lai, Qianru Meng, Johan Bos</dc:creator>
        <description><![CDATA[
            背景：大语言模型在自然语言处理任务表现出色，但处理结构化符号知识的能力待探索。方法：提出大语言模型本体能力分类法，引入OntoURL基准，基于分类法从理解、推理和学习三个维度，通过15个任务共58981个问题（源自8个领域40个本体）评估大语言模型处理本体的能力。效果：对20个开源大语言模型实验显示，不同模型、任务和领域表现差异大，当前模型理解本体知识较熟练，但推理和学习任务能力弱。
            arXiv:2505.11031v2 Announce Type: replace 
Abstract: Large language models (LLMs) have demonstrated remarkable capabilities across a range of natural language processing tasks, yet their ability to process structured symbolic knowledge remains underexplored. To address this gap, we propose a taxonomy of LLMs' ontological capabilities and introduce OntoURL, the first comprehensive benchmark designed to systematically evaluate LLMs' proficiency in handling ontologies -- formal, symbolic representations of domain knowledge through concepts, relationships, and instances. Based on the proposed taxonomy, OntoURL systematically assesses three dimensions: understanding, reasoning, and learning through 15 distinct tasks comprising 58,981 questions derived from 40 ontologies across 8 domains. Experiments with 20 open-source LLMs reveal significant performance differences across models, tasks, and domains, with current LLMs showing proficiency in understanding ontological knowledge but substantial weaknesses in reasoning and learning tasks. These findings highlight fundamental limitations in LLMs' capability to process symbolic knowledge and establish OntoURL as a critical benchmark for advancing the integration of LLMs with formal knowledge representations.
        ]]></description>
    </item>
    <item>
        <title>Task Facet Learning: A Structured Approach to Prompt Optimization</title>
        <link>https://arxiv.org/abs/2406.10504</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2406.10504v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Gurusha Juneja, Gautam Jajoo, Nagarajan Natarajan, Hua Li, Jian Jiao, Amit Sharma</dc:creator>
        <description><![CDATA[
            背景：现有基于迭代编辑或自动选择上下文示例的提示优化算法，能否涵盖解决复杂任务所需的多方面信息尚不明确。方法：将提示优化视为从训练示例中学习任务多方面信息，利用问题结构将提示拆分为松散耦合的语义部分。提出UniPrompt算法，先对输入空间聚类，再用反馈机制建议添加、编辑或删除部分。效果：在多数据集和实际任务中，该算法生成的提示准确率高于人工调整及现有方法，还能生成现有方法无法生成的复杂长提示。
            arXiv:2406.10504v2 Announce Type: replace-cross 
Abstract: Given a task in the form of a basic description and its training examples, prompt optimization is the problem of synthesizing the given information into a text prompt for a large language model. Humans solve this problem by also considering the different facets that define a task (e.g., counter-examples, explanations, analogies) and including them in the prompt. However, it is unclear whether existing algorithmic approaches, based on iteratively editing a given prompt or automatically selecting a few in-context examples, can cover the multiple facets required to solve a complex task. In this work, we view prompt optimization as that of learning multiple facets of a task from a set of training examples. We exploit structure in the prompt optimization problem and break down a prompt into loosely coupled semantic sections. The proposed algorithm, UniPrompt, (1) clusters the input space and uses clustered batches so that each batch likely corresponds to a different facet of the task, and (2) utilizes a feedback mechanism to propose adding, editing or deleting a section, which in turn is aggregated over a batch to capture generalizable facets. Empirical evaluation on multiple datasets and a real-world task shows that prompts generated using \shortname{} obtain higher accuracy than human-tuned prompts and those from state-of-the-art methods. In particular, our algorithm can generate long, complex prompts that existing methods are unable to generate. Code for UniPrompt is available at https://aka.ms/uniprompt.
        ]]></description>
    </item>
    <item>
        <title>Decoding Time Series with LLMs: A Multi-Agent Framework for Cross-Domain Annotation</title>
        <link>https://arxiv.org/abs/2410.17462</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.17462v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Minhua Lin, Zhengzhang Chen, Yanchi Liu, Xujiang Zhao, Zongyu Wu, Junxiang Wang, Xiang Zhang, Suhang Wang, Haifeng Chen</dc:creator>
        <description><![CDATA[
            背景：时间序列数据广泛存在于各领域，高质量标注对理解数据和下游任务至关重要，但获取困难。方法：提出多智能体系统TESSA，包含通用标注智能体和特定领域标注智能体，通用智能体利用多源领域特征生成通用标注，特定领域智能体借助目标领域有限标注生成针对性标注。效果：在多个合成和真实数据集上实验表明，TESSA能有效生成高质量标注，优于现有方法。
            arXiv:2410.17462v3 Announce Type: replace-cross 
Abstract: Time series data is ubiquitous across various domains, including manufacturing, finance, and healthcare. High-quality annotations are essential for effectively understanding time series and facilitating downstream tasks; however, obtaining such annotations is challenging, particularly in mission-critical domains. In this paper, we propose TESSA, a multi-agent system designed to automatically generate both general and domain-specific annotations for time series data. TESSA introduces two agents: a general annotation agent and a domain-specific annotation agent. The general agent captures common patterns and knowledge across multiple source domains, leveraging both time-series-wise and text-wise features to generate general annotations. Meanwhile, the domain-specific agent utilizes limited annotations from the target domain to learn domain-specific terminology and generate targeted annotations. Extensive experiments on multiple synthetic and real-world datasets demonstrate that TESSA effectively generates high-quality annotations, outperforming existing methods.
        ]]></description>
    </item>
    <item>
        <title>Table-Critic: A Multi-Agent Framework for Collaborative Criticism and Refinement in Table Reasoning</title>
        <link>https://arxiv.org/abs/2502.11799</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.11799v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Peiying Yu, Guoxin Chen, Jingjing Wang</dc:creator>
        <description><![CDATA[
            背景：大语言模型在表格推理任务中表现不佳，尤其难以在多步推理中保持一致性，现有方法缺乏识别和纠正中间推理步骤错误的有效机制。方法：提出Table - Critic多智能体框架，包含判断、批评、改进和提炼四种智能体，还引入自进化模板树积累批评知识。效果：实验表明，该框架较现有方法有显著提升，在保持计算效率和低解决方案退化率的同时，实现了更高的准确率和纠错率。
            arXiv:2502.11799v2 Announce Type: replace-cross 
Abstract: Despite the remarkable capabilities of large language models (LLMs) in various reasoning tasks, they still struggle with table reasoning tasks, particularly in maintaining consistency throughout multi-step reasoning processes. While existing approaches have explored various decomposition strategies, they often lack effective mechanisms to identify and correct errors in intermediate reasoning steps, leading to cascading error propagation. To address these issues, we propose Table-Critic, a novel multi-agent framework that facilitates collaborative criticism and iterative refinement of the reasoning process until convergence to correct solutions. Our framework consists of four specialized agents: a Judge for error identification, a Critic for comprehensive critiques, a Refiner for process improvement, and a Curator for pattern distillation. To effectively deal with diverse and unpredictable error types, we introduce a self-evolving template tree that systematically accumulates critique knowledge through experience-driven learning and guides future reflections. Extensive experiments have demonstrated that Table-Critic achieves substantial improvements over existing methods, achieving superior accuracy and error correction rates while maintaining computational efficiency and lower solution degradation rate.
        ]]></description>
    </item>
    <item>
        <title>A Pilot Empirical Study on When and How to Use Knowledge Graphs as Retrieval Augmented Generation</title>
        <link>https://arxiv.org/abs/2502.20854</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.20854v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xujie Yuan, Yongxu Liu, Shimin Di, Shiwen Wu, Libin Zheng, Rui Meng, Lei Chen, Xiaofang Zhou, Jian Yin</dc:creator>
        <description><![CDATA[
            背景：将知识图谱（KGs）集成到检索增强生成（RAG）框架中备受关注，但缺乏对新兴KG - RAG方法的系统理解和对比分析。方法：本文分析KG - RAG在不同技术配置和应用场景下的表现，绘制其思维导图、总结常用流程，对6种KG - RAG方法在9个不同领域和场景的数据集上进行复现和评估，分析9种KG - RAG配置与17种大语言模型结合的影响，还尝试将元认知与KG - RAG结合。效果：强调了合适应用条件和KG - RAG组件最优配置的关键作用。
            arXiv:2502.20854v3 Announce Type: replace-cross 
Abstract: The integration of Knowledge Graphs (KGs) into the Retrieval Augmented Generation (RAG) framework has attracted significant interest, with early studies showing promise in mitigating hallucinations and improving model accuracy. However, a systematic understanding and comparative analysis of the rapidly emerging KG-RAG methods are still lacking. This paper seeks to lay the foundation for systematically answering the question of when and how to use KG-RAG by analyzing their performance in various application scenarios associated with different technical configurations. After outlining the mind map using KG-RAG framework and summarizing its popular pipeline, we conduct a pilot empirical study of KG-RAG works to reimplement and evaluate 6 KG-RAG methods across 9 datasets in diverse domains and scenarios, analyzing the impact of 9 KG-RAG configurations in combination with 17 LLMs, and combining Metacognition with KG-RAG as a pilot attempt. Our results underscore the critical role of appropriate application conditions and optimal configurations of KG-RAG components.
        ]]></description>
    </item>
    <item>
        <title>GNN-ACLP: Graph Neural Networks based Analog Circuit Link Prediction</title>
        <link>https://arxiv.org/abs/2504.10240</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.10240v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Guanyuan Pan, Tiansheng Zhou, Bingtao Ma, Yaqi Wang, Jianxiang Zhao, Zhi Li, Yugui Lin, Pietro Lio, Shuai Wang</dc:creator>
        <description><![CDATA[
            在模拟电路设计自动化中，电路链接预测至关重要，但现有方法存在拓扑模式利用不足、数据稀缺和格式适应性有限等问题。为此提出GNN - ACLP框架，一是引入SEAL框架实现端口级电路链接预测；二是用大语言模型的检索增强生成（RAG）技术开发网表格式转换工具Netlist Babel Fish；三是构建含775个注释电路的SpiceNetlist数据集。实验结果显示，在数据集内评估中，SpiceNetlist等数据集准确率分别提升16.08%、11.38%和16.01%，跨数据集评估准确率保持在92.05% - 99.07%，特征迁移能力强。
            arXiv:2504.10240v2 Announce Type: replace-cross 
Abstract: Circuit link prediction identifying missing component connections from incomplete netlists is crucial in automating analog circuit design. However, existing methods face three main challenges: 1) Insufficient use of topological patterns in circuit graphs reduces prediction accuracy; 2) Data scarcity due to the complexity of annotations hinders model generalization; 3) Limited adaptability to various netlist formats. We propose GNN-ACLP, a Graph Neural Networks (GNNs) based framework featuring three innovations to tackle these challenges. First, we introduce the SEAL (Subgraphs, Embeddings, and Attributes for Link Prediction) framework and achieve port-level accuracy in circuit link prediction. Second, we propose Netlist Babel Fish, a netlist format conversion tool leveraging retrieval-augmented generation (RAG) with a large language model (LLM) to enhance the compatibility of netlist formats. Finally, we construct SpiceNetlist, a comprehensive dataset that contains 775 annotated circuits across 10 different component classes. Experimental results achieve accuracy improvements of 16.08% on SpiceNetlist, 11.38% on Image2Net, and 16.01% on Masala-CHAI in intra-dataset evaluation, while maintaining accuracy from 92.05% to 99.07% in cross-dataset evaluation, exhibiting robust feature transfer capabilities.
        ]]></description>
    </item>
    <item>
        <title>AlignRAG: Leveraging Critique Learning for Evidence-Sensitive Retrieval-Augmented Reasoning</title>
        <link>https://arxiv.org/abs/2504.14858</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.14858v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiaqi Wei, Hao Zhou, Xiang Zhang, Di Zhang, Zijie Qiu, Wei Wei, Jinzhe Li, Wanli Ouyang, Siqi Sun</dc:creator>
        <description><![CDATA[
            背景：检索增强生成（RAG）虽广泛应用，但标准RAG管道常无法保证模型推理与检索证据一致，存在推理不一致问题。方法：提出AlignRAG框架，采用基于批判驱动对齐的迭代方法，核心是对比批判合成机制，训练检索增强的批判语言模型（CLM），通过自监督或外部引导获取监督信号。效果：8B参数的CLM在域外任务上比Self - Refine基线性能提升12.1%，比标准72B参数CLM高2.2%，还能作为即插即用模块提升RAG系统可靠性和鲁棒性。
            arXiv:2504.14858v2 Announce Type: replace-cross 
Abstract: Retrieval-augmented generation (RAG) has become a widely adopted paradigm for enabling knowledge-grounded large language models (LLMs). However, standard RAG pipelines often fail to ensure that model reasoning remains consistent with the evidence retrieved, leading to factual inconsistencies or unsupported conclusions. In this work, we reinterpret RAG as Retrieval-Augmented Reasoning and identify a central but underexplored problem: \textit{Reasoning Misalignment}-the divergence between an LLM's internal reasoning trajectory and the evidential constraints provided by retrieval. To address this issue, we propose \textsc{AlignRAG}, a novel iterative framework grounded in Critique-Driven Alignment (CDA). At the heart of \textsc{AlignRAG} lies a \textit{contrastive critique synthesis} mechanism that generates retrieval-sensitive critiques while mitigating self-bias. This mechanism trains a dedicated retrieval-augmented \textit{Critic Language Model (CLM)} using labeled critiques that distinguish between evidence-aligned and misaligned reasoning. Alignment signals for supervision are obtained through self-supervised or externally guided labeling strategies. The resulting CLM is explicitly optimized for evidence sensitivity, enabling it to detect and revise reasoning errors during inference without relying solely on self-generated feedback. Empirical evaluations show that our 8B-parameter CLM improves performance over the Self-Refine baseline by 12.1\% on out-of-domain tasks and outperforms a standard 72B-parameter CLM by 2.2\%, while remaining compatible with existing RAG architectures as a plug-and-play module. Overall, AlignRAG offers a principled solution for aligning model reasoning with retrieved evidence, substantially improving the factual reliability and robustness of RAG systems.
        ]]></description>
    </item>
    <item>
        <title>BrainPrompt: Multi-Level Brain Prompt Enhancement for Neurological Condition Identification</title>
        <link>https://arxiv.org/abs/2504.16096</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.16096v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiaxing Xu, Kai He, Yue Tang, Wei Li, Mengcheng Lan, Xia Dong, Yiping Ke, Mengling Feng</dc:creator>
        <description><![CDATA[
            背景：神经疾病早期诊断困难，现有脑网络分析方法多基于成像数据的图模型，忽略非成像因素，限制了模型性能和可解释性。方法：提出BrainPrompt框架，将大语言模型与知识驱动提示结合，增强图神经网络，整合ROI、受试者、疾病三个层面的提示，利用多模态信息。效果：在两个静息态功能磁共振成像数据集上优于现有方法，生物标志物研究表明能提取与神经科学领域知识一致的信息。代码：https://github.com/AngusMonroe/BrainPrompt
            arXiv:2504.16096v2 Announce Type: replace-cross 
Abstract: Neurological conditions, such as Alzheimer's Disease, are challenging to diagnose, particularly in the early stages where symptoms closely resemble healthy controls. Existing brain network analysis methods primarily focus on graph-based models that rely solely on imaging data, which may overlook important non-imaging factors and limit the model's predictive power and interpretability. In this paper, we present BrainPrompt, an innovative framework that enhances Graph Neural Networks (GNNs) by integrating Large Language Models (LLMs) with knowledge-driven prompts, enabling more effective capture of complex, non-imaging information and external knowledge for neurological disease identification. BrainPrompt integrates three types of knowledge-driven prompts: (1) ROI-level prompts to encode the identity and function of each brain region, (2) subject-level prompts that incorporate demographic information, and (3) disease-level prompts to capture the temporal progression of disease. By leveraging these multi-level prompts, BrainPrompt effectively harnesses knowledge-enhanced multi-modal information from LLMs, enhancing the model's capability to predict neurological disease stages and meanwhile offers more interpretable results. We evaluate BrainPrompt on two resting-state functional Magnetic Resonance Imaging (fMRI) datasets from neurological disorders, showing its superiority over state-of-the-art methods. Additionally, a biomarker study demonstrates the framework's ability to extract valuable and interpretable information aligned with domain knowledge in neuroscience. The code is available at https://github.com/AngusMonroe/BrainPrompt
        ]]></description>
    </item>
    <item>
        <title>S-GRPO: Early Exit via Reinforcement Learning in Reasoning Models</title>
        <link>https://arxiv.org/abs/2505.07686</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.07686v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Muzhi Dai, Chenxu Yang, Qingyi Si</dc:creator>
        <description><![CDATA[
            背景：大语言模型中测试时缩放受关注，推理模型虽增强推理能力但在思维链生成中存在过度冗余问题。方法：提出Serial - Group Decaying - Reward Policy Optimization（S - GRPO）强化学习范式，只采样一条推理路径并串行选择退出点，对正确答案按退出位置递减奖励。效果：与Qwen3和Deepseek - distill等模型兼容，在多个基准测试中，能使序列长度减少35.4% - 61.1%，同时准确率提升0.72% - 6.08%。
            arXiv:2505.07686v2 Announce Type: replace-cross 
Abstract: As Test-Time Scaling emerges as an active research focus in the large language model community, advanced post-training methods increasingly emphasize extending chain-of-thought (CoT) generation length, thereby enhancing reasoning capabilities to approach Deepseek R1-like reasoning models. However, recent studies reveal that reasoning models (even Qwen3) consistently exhibit excessive thought redundancy in CoT generation. This overthinking issue arises from the inherent limitations of conventional outcome-reward reinforcement learning, which systematically overlooks the regulation of intermediate reasoning processes. This paper introduces Serial-Group Decaying-Reward Policy Optimization (S-GRPO), a novel reinforcement learning paradigm that enables models to implicitly evaluate the sufficiency of intermediate reasoning steps, thereby facilitating early exit in CoT generation. Unlike GRPO, which samples multiple possible reasoning paths in parallel (parallel group), S-GRPO only samples one reasoning path and serially selects multiple temporal positions from the path to exit thinking and directly generate answers (serial group). For correct answers within a serial group, rewards gradually decrease based on the exit positions along the reasoning path from front to back. This design encourages the model to produce more accurate and concise thoughts, while also incentivizing early thinking termination when appropriate. Empirical evaluations demonstrate that S-GRPO is compatible with state-of-the-art reasoning models, including Qwen3 and Deepseek-distill. Across diverse benchmarks such as GSM8K, AIME 2024, AMC 2023, MATH-500, and GPQA Diamond, S-GRPO achieves a substantial reduction in sequence length (35.4% - 61.1%) while simultaneously improving accuracy (absolute 0.72% - 6.08%).
        ]]></description>
    </item>
    <item>
        <title>Lost in Transmission: When and Why LLMs Fail to Reason Globally</title>
        <link>https://arxiv.org/abs/2505.08140</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.08140v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tobias Schnabel, Kiran Tomlinson, Adith Swaminathan, Jennifer Neville</dc:creator>
        <description><![CDATA[
            背景：基于Transformer的大语言模型在对大量输入进行复杂推理的任务上存在困难。方法：引入有界注意力前缀预言机（BAPO）模型，该框架模拟大语言模型内部通信机制注意力头的带宽限制，指出图可达性等推理问题为BAPO困难问题。实验发现GPT - 4o、Claude和Gemini能解决BAPO简单任务，难以解决BAPO困难任务。还证明思维链可将BAPO困难问题转化为简单问题。效果：为大语言模型的推理失败提供合理解释并指明改进方向。
            arXiv:2505.08140v2 Announce Type: replace-cross 
Abstract: Despite their many successes, transformer-based large language models (LLMs) continue to struggle with tasks that require complex reasoning over large parts of their input. We argue that these failures arise due to capacity limits on the accurate flow of information within LLMs. To formalize this issue, we introduce the bounded attention prefix oracle (BAPO) model, a new computational framework that models bandwidth constraints on attention heads, the mechanism for internal communication in LLMs. We show that several important reasoning problems like graph reachability require high communication bandwidth for BAPOs to solve; we call these problems BAPO-hard. Our experiments corroborate our theoretical predictions: GPT-4o, Claude, and Gemini succeed on BAPO-easy tasks and fail even on relatively small BAPO-hard tasks. BAPOs also reveal another benefit of chain of thought (CoT): we prove that breaking down a task using CoT can turn any BAPO-hard problem into a BAPO-easy one. Our results offer principled explanations for key LLM failures and suggest directions for architectures and inference methods that mitigate bandwidth limits.
        ]]></description>
    </item>
    <item>
        <title>Exploring the Potential of SSL Models for Sound Event Detection</title>
        <link>https://arxiv.org/abs/2505.11889</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.11889v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hanfang Cui, Longfei Song, Li Li, Dongxing Xu, Yanhua Long</dc:creator>
        <description><![CDATA[
            背景：自监督学习（SSL）模型对声音事件检测（SED）有强大表征能力，但协同潜力待挖掘。方法：系统评估先进SSL模型，提出结合异质SSL表征的框架，有三种融合策略；还引入归一化声音事件边界框（nSEBBs）自适应后处理方法。效果：在DCASE 2023任务4挑战中，双模态融合有互补性能提升，CRNN+BEATs单模型效果最佳；nSEBBs使独立SSL模型的PSDS1最多提升4%，为SED系统设计提供指导。
            arXiv:2505.11889v1 Announce Type: new 
Abstract: Self-supervised learning (SSL) models offer powerful representations for sound event detection (SED), yet their synergistic potential remains underexplored. This study systematically evaluates state-of-the-art SSL models to guide optimal model selection and integration for SED. We propose a framework that combines heterogeneous SSL representations (e.g., BEATs, HuBERT, WavLM) through three fusion strategies: individual SSL embedding integration, dual-modal fusion, and full aggregation. Experiments on the DCASE 2023 Task 4 Challenge reveal that dual-modal fusion (e.g., CRNN+BEATs+WavLM) achieves complementary performance gains, while CRNN+BEATs alone delivers the best results among individual SSL models. We further introduce normalized sound event bounding boxes (nSEBBs), an adaptive post-processing method that dynamically adjusts event boundary predictions, improving PSDS1 by up to 4% for standalone SSL models. These findings highlight the compatibility and complementarity of SSL architectures, providing guidance for task-specific fusion and robust SED system design.
        ]]></description>
    </item>
    <item>
        <title>Shallow Flow Matching for Coarse-to-Fine Text-to-Speech Synthesis</title>
        <link>https://arxiv.org/abs/2505.12226</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12226v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Dong Yang, Yiyi Cai, Yuki Saito, Lixu Wang, Hiroshi Saruwatari</dc:creator>
        <description><![CDATA[
            背景：旨在提升基于流匹配（FM）的文本到语音（TTS）模型性能。方法：提出浅流匹配（SFM）机制，在粗到精生成范式下，利用粗输出表示构建FM路径中间状态，训练时用正交投影法确定状态时间位置，采用单段分段流构建策略，推理从中间状态开始，将SFM以轻量级头部集成到多个TTS模型。效果：实验表明，SFM在主客观评估中提升合成语音自然度，使用自适应步长ODE求解器时显著减少推理时间。
            arXiv:2505.12226v1 Announce Type: new 
Abstract: We propose a shallow flow matching (SFM) mechanism to enhance flow matching (FM)-based text-to-speech (TTS) models within a coarse-to-fine generation paradigm. SFM constructs intermediate states along the FM paths using coarse output representations. During training, we introduce an orthogonal projection method to adaptively determine the temporal position of these states, and apply a principled construction strategy based on a single-segment piecewise flow. The SFM inference starts from the intermediate state rather than pure noise and focuses computation on the latter stages of the FM paths. We integrate SFM into multiple TTS models with a lightweight SFM head. Experiments show that SFM consistently improves the naturalness of synthesized speech in both objective and subjective evaluations, while significantly reducing inference when using adaptive-step ODE solvers. Demo and codes are available at https://ydqmkkx.github.io/SFMDemo/.
        ]]></description>
    </item>
    <item>
        <title>VoiceCloak: A Multi-Dimensional Defense Framework against Unauthorized Diffusion-based Voice Cloning</title>
        <link>https://arxiv.org/abs/2505.12332</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12332v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qianyue Hu, Junyan Wu, Wei Lu, Xiangyang Luo</dc:creator>
        <description><![CDATA[
            背景：扩散模型在语音克隆中取得成功，但增加了恶意滥用风险，现有传统语音克隆防御方法与扩散模型不兼容。方法：提出多维主动防御框架VoiceCloak，分析扩散模型漏洞，通过向参考音频引入对抗性扰动来破坏克隆过程，如扭曲说话人身份表征、破坏条件引导过程、放大分数幅度、进行噪声引导的语义破坏。效果：大量实验表明，该框架在抵御基于扩散的非授权语音克隆方面有出色的防御成功率。
            arXiv:2505.12332v1 Announce Type: new 
Abstract: Diffusion Models (DMs) have achieved remarkable success in realistic voice cloning (VC), while they also increase the risk of malicious misuse. Existing proactive defenses designed for traditional VC models aim to disrupt the forgery process, but they have been proven incompatible with DMs due to the intricate generative mechanisms of diffusion. To bridge this gap, we introduce VoiceCloak, a multi-dimensional proactive defense framework with the goal of obfuscating speaker identity and degrading perceptual quality in potential unauthorized VC. To achieve these goals, we conduct a focused analysis to identify specific vulnerabilities within DMs, allowing VoiceCloak to disrupt the cloning process by introducing adversarial perturbations into the reference audio. Specifically, to obfuscate speaker identity, VoiceCloak first targets speaker identity by distorting representation learning embeddings to maximize identity variation, which is guided by auditory perception principles. Additionally, VoiceCloak disrupts crucial conditional guidance processes, particularly attention context, thereby preventing the alignment of vocal characteristics that are essential for achieving convincing cloning. Then, to address the second objective, VoiceCloak introduces score magnitude amplification to actively steer the reverse trajectory away from the generation of high-quality speech. Noise-guided semantic corruption is further employed to disrupt structural speech semantics captured by DMs, degrading output quality. Extensive experiments highlight VoiceCloak's outstanding defense success rate against unauthorized diffusion-based voice cloning. Audio samples of VoiceCloak are available at https://voice-cloak.github.io/VoiceCloak/.
        ]]></description>
    </item>
    <item>
        <title>Chain-Talker: Chain Understanding and Rendering for Empathetic Conversational Speech Synthesis</title>
        <link>https://arxiv.org/abs/2505.12597</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12597v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yifan Hu, Rui Liu, Yi Ren, Xiang Yin, Haizhou Li</dc:creator>
        <description><![CDATA[
            对话语音合成旨在使合成语音契合交互的情感和风格语境以实现共情。当前生成式模型因情感感知不足和离散语音编码冗余，存在可解释性局限。为此提出Chain - Talker三阶段框架，模仿人类认知：情感理解从对话历史获取上下文感知的情感描述符；语义理解通过序列化预测生成紧凑语义代码；共情渲染结合两者合成富有表现力的语音。还开发CSS - EmCap辅助情感建模。实验表明，该模型在三个基准数据集上比现有方法生成的语音更具表现力和共情力。
            arXiv:2505.12597v1 Announce Type: new 
Abstract: Conversational Speech Synthesis (CSS) aims to align synthesized speech with the emotional and stylistic context of user-agent interactions to achieve empathy. Current generative CSS models face interpretability limitations due to insufficient emotional perception and redundant discrete speech coding. To address the above issues, we present Chain-Talker, a three-stage framework mimicking human cognition: Emotion Understanding derives context-aware emotion descriptors from dialogue history; Semantic Understanding generates compact semantic codes via serialized prediction; and Empathetic Rendering synthesizes expressive speech by integrating both components. To support emotion modeling, we develop CSS-EmCap, an LLM-driven automated pipeline for generating precise conversational speech emotion captions. Experiments on three benchmark datasets demonstrate that Chain-Talker produces more expressive and empathetic speech than existing methods, with CSS-EmCap contributing to reliable emotion modeling. The code and demos are available at: https://github.com/AI-S2-Lab/Chain-Talker.
        ]]></description>
    </item>
    <item>
        <title>OZSpeech: One-step Zero-shot Speech Synthesis with Learned-Prior-Conditioned Flow Matching</title>
        <link>https://arxiv.org/abs/2505.12800</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12800v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hieu-Nghia Huynh-Nguyen, Ngoc Son Nguyen, Huynh Nguyen Dang, Thieu Vo, Truong-Son Hy, Van Nguyen</dc:creator>
        <description><![CDATA[
            近年来，文本转语音（TTS）系统取得显著进展，但以往基于Flow Matching框架的方法存在忽视语音属性、计算成本高的问题。为此，本文提出OZSpeech，它是首个探索最优传输条件流匹配的TTS方法，采用单步采样和学习先验作为条件，忽略先前状态并减少采样步骤。该方法对令牌格式的语音解耦和分解组件进行操作，能精确建模语音属性。实验表明，在内容准确性、自然度、韵律生成和说话人风格保留方面，该方法优于现有方法。
            arXiv:2505.12800v1 Announce Type: new 
Abstract: Text-to-speech (TTS) systems have seen significant advancements in recent years, driven by improvements in deep learning and neural network architectures. Viewing the output speech as a data distribution, previous approaches often employ traditional speech representations, such as waveforms or spectrograms, within the Flow Matching framework. However, these methods have limitations, including overlooking various speech attributes and incurring high computational costs due to additional constraints introduced during training. To address these challenges, we introduce OZSpeech, the first TTS method to explore optimal transport conditional flow matching with one-step sampling and a learned prior as the condition, effectively disregarding preceding states and reducing the number of sampling steps. Our approach operates on disentangled, factorized components of speech in token format, enabling accurate modeling of each speech attribute, which enhances the TTS system's ability to precisely clone the prompt speech. Experimental results show that our method achieves promising performance over existing methods in content accuracy, naturalness, prosody generation, and speaker style preservation. Audio samples are available at our demo page https://ozspeech.github.io/OZSpeech_Web/.
        ]]></description>
    </item>
    <item>
        <title>Unified Cross-modal Translation of Score Images, Symbolic Music, and Performance Audio</title>
        <link>https://arxiv.org/abs/2505.12863</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12863v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jongmin Jung, Dongmin Kim, Sihun Lee, Seola Cho, Hyungjoon Soh, Irmak Bukey, Chris Donahue, Dasaem Jeong</dc:creator>
        <description><![CDATA[
            音乐存在多种模态，以往多模态翻译工作多针对单个任务训练专门模型。本文提出统一方法，同时在多个翻译任务上训练通用模型。关键在于新的大规模数据集和各模态的tokenization。新数据集含超1300小时配对音频 - 乐谱图像数据；统一tokenization框架将各模态离散为token序列。实验表明，统一多任务模型在多方面优于单任务基线，如光学音乐识别符号错误率从24.58%降至13.67%，还实现了首个成功的乐谱图像条件音频生成。
            arXiv:2505.12863v1 Announce Type: new 
Abstract: Music exists in various modalities, such as score images, symbolic scores, MIDI, and audio. Translations between each modality are established as core tasks of music information retrieval, such as automatic music transcription (audio-to-MIDI) and optical music recognition (score image to symbolic score). However, most past work on multimodal translation trains specialized models on individual translation tasks. In this paper, we propose a unified approach, where we train a general-purpose model on many translation tasks simultaneously. Two key factors make this unified approach viable: a new large-scale dataset and the tokenization of each modality. Firstly, we propose a new dataset that consists of more than 1,300 hours of paired audio-score image data collected from YouTube videos, which is an order of magnitude larger than any existing music modal translation datasets. Secondly, our unified tokenization framework discretizes score images, audio, MIDI, and MusicXML into a sequence of tokens, enabling a single encoder-decoder Transformer to tackle multiple cross-modal translation as one coherent sequence-to-sequence task. Experimental results confirm that our unified multitask model improves upon single-task baselines in several key areas, notably reducing the symbol error rate for optical music recognition from 24.58% to a state-of-the-art 13.67%, while similarly substantial improvements are observed across the other translation tasks. Notably, our approach achieves the first successful score-image-conditioned audio generation, marking a significant breakthrough in cross-modal music generation.
        ]]></description>
    </item>
    <item>
        <title>The Computation of Generalized Embeddings for Underwater Acoustic Target Recognition using Contrastive Learning</title>
        <link>https://arxiv.org/abs/2505.12904</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12904v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hilde I. Hummel, Arwin Gansekoele, Sandjai Bhulai, Rob van der Mei</dc:creator>
        <description><![CDATA[
            背景：海洋环境噪声污染威胁海洋健康，需监测水下噪声，但现有机器学习自动声音分类方法多为有监督学习，需要大量高质量标注数据，而公开的多为低质量无标注数据。方法：采用无监督对比学习方法，用基于Conformer的编码器，通过方差 - 不变性 - 协方差正则化损失函数在低质量无标注数据上优化，并转换到标注数据。效果：在识别船舶类型和海洋哺乳动物发声的分类任务中，该方法能生成鲁棒且通用的嵌入，显示了无监督方法用于水下声学自动分析任务的潜力。
            arXiv:2505.12904v1 Announce Type: new 
Abstract: The increasing level of sound pollution in marine environments poses an increased threat to ocean health, making it crucial to monitor underwater noise. By monitoring this noise, the sources responsible for this pollution can be mapped. Monitoring is performed by passively listening to these sounds. This generates a large amount of data records, capturing a mix of sound sources such as ship activities and marine mammal vocalizations. Although machine learning offers a promising solution for automatic sound classification, current state-of-the-art methods implement supervised learning. This requires a large amount of high-quality labeled data that is not publicly available. In contrast, a massive amount of lower-quality unlabeled data is publicly available, offering the opportunity to explore unsupervised learning techniques. This research explores this possibility by implementing an unsupervised Contrastive Learning approach. Here, a Conformer-based encoder is optimized by the so-called Variance-Invariance-Covariance Regularization loss function on these lower-quality unlabeled data and the translation to the labeled data is made. Through classification tasks involving recognizing ship types and marine mammal vocalizations, our method demonstrates to produce robust and generalized embeddings. This shows to potential of unsupervised methods for various automatic underwater acoustic analysis tasks.
        ]]></description>
    </item>
    <item>
        <title>Personalized Fine-Tuning with Controllable Synthetic Speech from LLM-Generated Transcripts for Dysarthric Speech Recognition</title>
        <link>https://arxiv.org/abs/2505.12991</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12991v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Dominik Wagner, Ilja Baumann, Natalie Engert, Seanie Lee, Elmar N\"oth, Korbinian Riedhammer, Tobias Bocklet</dc:creator>
        <description><![CDATA[
            背景：为解决构音障碍语音识别问题参与相关挑战。方法：将参数高效微调与潜在音频表示相结合改进编解码器自动语音识别系统；微调Parler - TTS生成合成训练数据，用大语言模型生成提示得到符合语料库的目标转录；用x - 向量进行个性化处理，使用AdaLoRA适配器，还结合基于wav2vec 2.0的音频表示。效果：个性化处理降低了字错误率；AdaLoRA适配器相对全量微调、标准低秩适配分别降低约23%、22%的字错误率；结合音频表示再降约5%；合成构音障碍语音训练比单独个性化微调最多提升约7%。
            arXiv:2505.12991v1 Announce Type: new 
Abstract: In this work, we present our submission to the Speech Accessibility Project challenge for dysarthric speech recognition. We integrate parameter-efficient fine-tuning with latent audio representations to improve an encoder-decoder ASR system. Synthetic training data is generated by fine-tuning Parler-TTS to mimic dysarthric speech, using LLM-generated prompts for corpus-consistent target transcripts. Personalization with x-vectors consistently reduces word error rates (WERs) over non-personalized fine-tuning. AdaLoRA adapters outperform full fine-tuning and standard low-rank adaptation, achieving relative WER reductions of ~23% and ~22%, respectively. Further improvements (~5% WER reduction) come from incorporating wav2vec 2.0-based audio representations. Training with synthetic dysarthric speech yields up to ~7% relative WER improvement over personalized fine-tuning alone.
        ]]></description>
    </item>
    <item>
        <title>Codec-Based Deepfake Source Tracing via Neural Audio Codec Taxonomy</title>
        <link>https://arxiv.org/abs/2505.12994</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12994v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xuanjun Chen, I-Ming Lin, Lin Zhang, Jiawei Du, Haibin Wu, Hung-yi Lee, Jyh-Shing Roger Jang</dc:creator>
        <description><![CDATA[
            背景：基于神经音频编解码器的语音生成模型产生了逼真的音频深度伪造，现有反伪造研究多关注音频真伪验证，鲜少追踪生成这些深度伪造的系统。方法：提出通过神经音频编解码器分类对基于编解码器的深度伪造语音进行源追踪，剖析神经音频编解码器来追踪语音生成系统。效果：在CodecFake+数据集上的实验结果初步证明了深度伪造语音源追踪的可行性，同时也指出了一些有待进一步研究的挑战。
            arXiv:2505.12994v1 Announce Type: new 
Abstract: Recent advances in neural audio codec-based speech generation (CoSG) models have produced remarkably realistic audio deepfakes. We refer to deepfake speech generated by CoSG systems as codec-based deepfake, or CodecFake. Although existing anti-spoofing research on CodecFake predominantly focuses on verifying the authenticity of audio samples, almost no attention was given to tracing the CoSG used in generating these deepfakes. In CodecFake generation, processes such as speech-to-unit encoding, discrete unit modeling, and unit-to-speech decoding are fundamentally based on neural audio codecs. Motivated by this, we introduce source tracing for CodecFake via neural audio codec taxonomy, which dissects neural audio codecs to trace CoSG. Our experimental results on the CodecFake+ dataset provide promising initial evidence for the feasibility of CodecFake source tracing while also highlighting several challenges that warrant further investigation.
        ]]></description>
    </item>
    <item>
        <title>DualCodec: A Low-Frame-Rate, Semantically-Enhanced Neural Audio Codec for Speech Generation</title>
        <link>https://arxiv.org/abs/2505.13000</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13000v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiaqi Li, Xiaolong Lin, Zhekai Li, Shixi Huang, Yuancheng Wang, Chaoren Wang, Zhenpeng Zhan, Zhizheng Wu</dc:creator>
        <description><![CDATA[
            背景：神经音频编解码器是基于语言模型的语音生成的基础，但帧率和音频质量通常存在权衡。方法：提出DualCodec，一种双流编码方法，在端到端编解码器框架中集成自监督学习（SSL）和波形表示，增强第一层编解码器的语义信息。效果：能使编解码器系统在低帧率下保持高音频质量，提高语音生成效率。实验表明，相比Mimi Codec等先进编解码器系统，DualCodec更有效。
            arXiv:2505.13000v1 Announce Type: new 
Abstract: Neural audio codecs form the foundational building blocks for language model (LM)-based speech generation. Typically, there is a trade-off between frame rate and audio quality. This study introduces a low-frame-rate, semantically enhanced codec model. Existing approaches distill semantically rich self-supervised (SSL) representations into the first-layer codec tokens. This work proposes DualCodec, a dual-stream encoding approach that integrates SSL and waveform representations within an end-to-end codec framework. In this setting, DualCodec enhances the semantic information in the first-layer codec and enables the codec system to maintain high audio quality while operating at a low frame rate. Note that a low-frame-rate codec improves the efficiency of speech generation. Experimental results on audio codec and speech generation tasks confirm the effectiveness of the proposed DualCodec compared to state-of-the-art codec systems, such as Mimi Codec, SpeechTokenizer, DAC, and Encodec. Demos and codes are available at: https://dualcodec.github.io
        ]]></description>
    </item>
    <item>
        <title>Optimal Scalogram for Computational Complexity Reduction in Acoustic Recognition Using Deep Learning</title>
        <link>https://arxiv.org/abs/2505.13017</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13017v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Dang Thoai Phan, Tuan Anh Huynh, Van Tuan Pham, Cao Minh Tran, Van Thuan Mai, Ngoc Quy Tran</dc:creator>
        <description><![CDATA[
            背景：连续小波变换（CWT）是用卷积神经网络进行声学识别特征提取的有效工具，但计算成本高，使研究者倾向选择短时傅里叶变换等方法。方法：本文提出通过优化小波核长度和输出尺度图的跳数来降低CWT计算复杂度。效果：实验表明，该方法能显著降低计算成本，同时在声学识别任务中让训练模型保持良好性能。
            arXiv:2505.13017v1 Announce Type: new 
Abstract: The Continuous Wavelet Transform (CWT) is an effective tool for feature extraction in acoustic recognition using Convolutional Neural Networks (CNNs), particularly when applied to non-stationary audio. However, its high computational cost poses a significant challenge, often leading researchers to prefer alternative methods such as the Short-Time Fourier Transform (STFT). To address this issue, this paper proposes a method to reduce the computational complexity of CWT by optimizing the length of the wavelet kernel and the hop size of the output scalogram. Experimental results demonstrate that the proposed approach significantly reduces computational cost while maintaining the robust performance of the trained model in acoustic recognition tasks.
        ]]></description>
    </item>
    <item>
        <title>MDDM: A Multi-view Discriminative Enhanced Diffusion-based Model for Speech Enhancement</title>
        <link>https://arxiv.org/abs/2505.13029</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13029v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Nan Xu, Zhaolong Huang, Xiaonan Zhi</dc:creator>
        <description><![CDATA[
            背景：深度学习发展使语音增强在语音质量上有很大优化，但以往方法侧重判别监督学习或生成建模，易引入语音失真或计算成本高。方法：提出多视图判别增强扩散模型MDDM，将时间、频率和噪声三个域的特征作为判别预测网络输入生成初步频谱图，再经推理采样步骤转换为干净语音。效果：因判别输出和干净目标分布有交集，较少采样步骤就能取得与其他基于扩散方法相当的性能，在公开和真实数据集上主客观指标均验证了有效性。
            arXiv:2505.13029v1 Announce Type: new 
Abstract: With the development of deep learning, speech enhancement has been greatly optimized in terms of speech quality. Previous methods typically focus on the discriminative supervised learning or generative modeling, which tends to introduce speech distortions or high computational cost. In this paper, we propose MDDM, a Multi-view Discriminative enhanced Diffusion-based Model. Specifically, we take the features of three domains (time, frequency and noise) as inputs of a discriminative prediction network, generating the preliminary spectrogram. Then, the discriminative output can be converted to clean speech by several inference sampling steps. Due to the intersection of the distributions between discriminative output and clean target, the smaller sampling steps can achieve the competitive performance compared to other diffusion-based methods. Experiments conducted on a public dataset and a realworld dataset validate the effectiveness of MDDM, either on subjective or objective metric.
        ]]></description>
    </item>
    <item>
        <title>MMAR: A Challenging Benchmark for Deep Reasoning in Speech, Audio, Music, and Their Mix</title>
        <link>https://arxiv.org/abs/2505.13032</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13032v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ziyang Ma, Yinghao Ma, Yanqiao Zhu, Chen Yang, Yi-Wen Chao, Ruiyang Xu, Wenxi Chen, Yuanzhe Chen, Zhuo Chen, Jian Cong, Kai Li, Keliang Li, Siyou Li, Xinfeng Li, Xiquan Li, Zheng Lian, Yuzhe Liang, Minghao Liu, Zhikang Niu, Tianrui Wang, Yuping Wang, Yuxuan Wang, Yihao Wu, Guanrou Yang, Jianwei Yu, Ruibin Yuan, Zhisheng Zheng, Ziya Zhou, Haina Zhu, Wei Xue, Emmanouil Benetos, Kai Yu, Eng-Siong Chng, Xie Chen</dc:creator>
        <description><![CDATA[
            背景：现有基准多局限于特定音频领域，缺乏能评估音频语言模型深度推理能力的多学科任务基准。方法：提出新基准MMAR，包含1000个精心挑选的音频问答三元组，问题按四层推理层次分类，还标注思维链理由。对多种模型进行评估。效果：模型在MMAR上的表现凸显其挑战性，分析揭示当前模型在理解和推理能力上的关键局限，有望推动该领域发展。
            arXiv:2505.13032v1 Announce Type: new 
Abstract: We introduce MMAR, a new benchmark designed to evaluate the deep reasoning capabilities of Audio-Language Models (ALMs) across massive multi-disciplinary tasks. MMAR comprises 1,000 meticulously curated audio-question-answer triplets, collected from real-world internet videos and refined through iterative error corrections and quality checks to ensure high quality. Unlike existing benchmarks that are limited to specific domains of sound, music, or speech, MMAR extends them to a broad spectrum of real-world audio scenarios, including mixed-modality combinations of sound, music, and speech. Each question in MMAR is hierarchically categorized across four reasoning layers: Signal, Perception, Semantic, and Cultural, with additional sub-categories within each layer to reflect task diversity and complexity. To further foster research in this area, we annotate every question with a Chain-of-Thought (CoT) rationale to promote future advancements in audio reasoning. Each item in the benchmark demands multi-step deep reasoning beyond surface-level understanding. Moreover, a part of the questions requires graduate-level perceptual and domain-specific knowledge, elevating the benchmark's difficulty and depth. We evaluate MMAR using a broad set of models, including Large Audio-Language Models (LALMs), Large Audio Reasoning Models (LARMs), Omni Language Models (OLMs), Large Language Models (LLMs), and Large Reasoning Models (LRMs), with audio caption inputs. The performance of these models on MMAR highlights the benchmark's challenging nature, and our analysis further reveals critical limitations of understanding and reasoning capabilities among current models. We hope MMAR will serve as a catalyst for future advances in this important but little-explored area.
        ]]></description>
    </item>
    <item>
        <title>MultiActor-Audiobook: Zero-Shot Audiobook Generation with Faces and Voices of Multiple Speakers</title>
        <link>https://arxiv.org/abs/2505.13082</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13082v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kyeongman Park, Seongho Joo, Kyomin Jung</dc:creator>
        <description><![CDATA[
            背景：以往有声书系统存在需手动配置韵律、语调单调或训练成本高等问题。方法：提出MultiActor - Audiobook零样本有声书生成方法，引入多模态说话人角色生成（MSP）和基于大语言模型的脚本指令生成（LSI）两个新流程。效果：无需额外训练，能生成韵律一致、更具情感表达的有声书。通过人工和多模态大语言模型评估，与商业产品对比取得有竞争力的结果，消融实验也证明了MSP和LSI的有效性。
            arXiv:2505.13082v1 Announce Type: new 
Abstract: We introduce MultiActor-Audiobook, a zero-shot approach for generating audiobooks that automatically produces consistent, expressive, and speaker-appropriate prosody, including intonation and emotion. Previous audiobook systems have several limitations: they require users to manually configure the speaker's prosody, read each sentence with a monotonic tone compared to voice actors, or rely on costly training. However, our MultiActor-Audiobook addresses these issues by introducing two novel processes: (1) MSP (**Multimodal Speaker Persona Generation**) and (2) LSI (**LLM-based Script Instruction Generation**). With these two processes, MultiActor-Audiobook can generate more emotionally expressive audiobooks with a consistent speaker prosody without additional training. We compare our system with commercial products, through human and MLLM evaluations, achieving competitive results. Furthermore, we demonstrate the effectiveness of MSP and LSI through ablation studies.
        ]]></description>
    </item>
    <item>
        <title>Universal Semantic Disentangled Privacy-preserving Speech Representation Learning</title>
        <link>https://arxiv.org/abs/2505.13085</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13085v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Biel Tura Vecino, Subhadeep Maji, Aravind Varier, Antonio Bonafonte, Ivan Valles, Michael Owen, Leif Radel, Grant Strimmel, Seyi Feyisetan, Roberto Barra Chicote, Ariya Rastrow, Constantinos Papayiannis, Volker Leutnant, Trevor Wood</dc:creator>
        <description><![CDATA[
            背景：使用人类语音录音训练大语言模型存在隐私问题。方法：提出通过通用语音编解码器（USC）进行说话人隐私保护表征学习的方法，将语音解缠为隐私保护的语义丰富表征和用于高保真重建的残余声学及说话人表征。效果：USC的语义表征能保留内容、韵律和情感，去除可识别的说话人属性，结合两种表征可实现先进的语音重建，还引入评估方法，对比显示其在隐私保护表征学习上有效。
            arXiv:2505.13085v1 Announce Type: new 
Abstract: The use of audio recordings of human speech to train LLMs poses privacy concerns due to these models' potential to generate outputs that closely resemble artifacts in the training data. In this study, we propose a speaker privacy-preserving representation learning method through the Universal Speech Codec (USC), a computationally efficient encoder-decoder model that disentangles speech into: $\textit{(i)}$ privacy-preserving semantically rich representations, capturing content and speech paralinguistics, and $\textit{(ii)}$ residual acoustic and speaker representations that enables high-fidelity reconstruction. Extensive evaluations presented show that USC's semantic representation preserves content, prosody, and sentiment, while removing potentially identifiable speaker attributes. Combining both representations, USC achieves state-of-the-art speech reconstruction. Additionally, we introduce an evaluation methodology for measuring privacy-preserving properties, aligning with perceptual tests. We compare USC against other codecs in the literature and demonstrate its effectiveness on privacy-preserving representation learning, illustrating the trade-offs of speaker anonymization, paralinguistics retention and content preservation in the learned semantic representations. Audio samples are shared in $\href{https://www.amazon.science/usc-samples}{https://www.amazon.science/usc-samples}$.
        ]]></description>
    </item>
    <item>
        <title>SAKURA: On the Multi-hop Reasoning of Large Audio-Language Models Based on Speech and Audio Information</title>
        <link>https://arxiv.org/abs/2505.13237</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13237v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chih-Kai Yang, Neo Ho, Yen-Ting Piao, Hung-yi Lee</dc:creator>
        <description><![CDATA[
            背景：大型音频语言模型（LALMs）在语音和音频处理任务上表现受广泛研究，但推理能力，尤其是多跳推理能力缺乏系统评估，现有基准忽视这方面。方法：引入基准SAKURA，用于评估LALMs基于语音和音频信息的多跳推理能力。效果：结果显示，即便LALMs能正确提取相关信息，也难以整合语音/音频表征进行多跳推理，揭示了LALMs在多模态推理中的根本挑战和关键局限。
            arXiv:2505.13237v1 Announce Type: new 
Abstract: Large audio-language models (LALMs) extend the large language models with multimodal understanding in speech, audio, etc. While their performances on speech and audio-processing tasks are extensively studied, their reasoning abilities remain underexplored. Particularly, their multi-hop reasoning, the ability to recall and integrate multiple facts, lacks systematic evaluation. Existing benchmarks focus on general speech and audio-processing tasks, conversational abilities, and fairness but overlook this aspect. To bridge this gap, we introduce SAKURA, a benchmark assessing LALMs' multi-hop reasoning based on speech and audio information. Results show that LALMs struggle to integrate speech/audio representations for multi-hop reasoning, even when they extract the relevant information correctly, highlighting a fundamental challenge in multimodal reasoning. Our findings expose a critical limitation in LALMs, offering insights and resources for future research.
        ]]></description>
    </item>
    <item>
        <title>Distilling a speech and music encoder with task arithmetic</title>
        <link>https://arxiv.org/abs/2505.13270</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13270v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Fabian Ritter-Gutierrez, Yi-Cheng Lin, Jui-Chiang Wei, Jeremy H. M Wong, Eng Siong Chng, Nancy F. Chen, Hung-yi Lee</dc:creator>
        <description><![CDATA[
            背景：现有语音和音乐自监督学习模型分开处理二者，限制统一音频理解能力，直接训练通用模型计算成本高。方法：提出学习蒸馏任务向量，再线性插值形成统一的语音 + 音乐模型，可通过调整权重灵活强调不同领域，且训练更简单。效果：在语音和音乐基准测试中，该方法比集成蒸馏有更优的整体表现。
            arXiv:2505.13270v1 Announce Type: new 
Abstract: Despite the progress in self-supervised learning (SSL) for speech and music, existing models treat these domains separately, limiting their capacity for unified audio understanding. A unified model is desirable for applications that require general representations, e.g. audio large language models. Nonetheless, directly training a general model for speech and music is computationally expensive. Knowledge Distillation of teacher ensembles may be a natural solution, but we posit that decoupling the distillation of the speech and music SSL models allows for more flexibility. Thus, we propose to learn distilled task vectors and then linearly interpolate them to form a unified speech+music model. This strategy enables flexible domain emphasis through adjustable weights and is also simpler to train. Experiments on speech and music benchmarks demonstrate that our method yields superior overall performance compared to ensemble distillation.
        ]]></description>
    </item>
    <item>
        <title>Learning to Highlight Audio by Watching Movies</title>
        <link>https://arxiv.org/abs/2505.12154</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.12154v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chao Huang, Ruohan Gao, J. M. F. Tsang, Jan Kurcius, Cagdas Bilen, Chenliang Xu, Anurag Kumar, Sanjeel Parekh</dc:creator>
        <description><![CDATA[
            背景：视频内容创作和消费增加，但音频元素处理进展不如视觉，导致视听显著度脱节。方法：提出视觉引导的声学突出任务，用基于Transformer的多模态框架解决，引入“泥泞混音”数据集，开发伪数据生成过程模拟真实场景。效果：在定量和主观评估中均优于多个基线，还系统研究了不同上下文引导和数据集难度的影响。
            arXiv:2505.12154v1 Announce Type: cross 
Abstract: Recent years have seen a significant increase in video content creation and consumption. Crafting engaging content requires the careful curation of both visual and audio elements. While visual cue curation, through techniques like optimal viewpoint selection or post-editing, has been central to media production, its natural counterpart, audio, has not undergone equivalent advancements. This often results in a disconnect between visual and acoustic saliency. To bridge this gap, we introduce a novel task: visually-guided acoustic highlighting, which aims to transform audio to deliver appropriate highlighting effects guided by the accompanying video, ultimately creating a more harmonious audio-visual experience. We propose a flexible, transformer-based multimodal framework to solve this task. To train our model, we also introduce a new dataset -- the muddy mix dataset, leveraging the meticulous audio and video crafting found in movies, which provides a form of free supervision. We develop a pseudo-data generation process to simulate poorly mixed audio, mimicking real-world scenarios through a three-step process -- separation, adjustment, and remixing. Our approach consistently outperforms several baselines in both quantitative and subjective evaluation. We also systematically study the impact of different types of contextual guidance and difficulty levels of the dataset. Our project page is here: https://wikichao.github.io/VisAH/.
        ]]></description>
    </item>
    <item>
        <title>Hearing from Silence: Reasoning Audio Descriptions from Silent Videos via Vision-Language Model</title>
        <link>https://arxiv.org/abs/2505.13062</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13062v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yong Ren, Chenxing Li, Le Xu, Hao Gu, Duzhen Zhang, Yujie Chen, Manjie Xu, Ruibo Fu, Shan Yang, Dong Yu</dc:creator>
        <description><![CDATA[
            背景：人类能从无声视频中推断声音，但多模态大语言模型在不接触目标模态时能否进行模态不匹配推理尚待研究，现有VT2A方法难以在推理时获取音频描述。方法：提出从无声视频推理音频描述任务（SVAD），构建CoT - AudioCaps数据集，采用基于思维链的监督微调策略。效果：在SVAD和后续VT2A任务实验中，显著提升VLMs在SVAD中的模态不匹配推理能力，有效解决VT2A推理时获取音频描述的难题。
            arXiv:2505.13062v1 Announce Type: cross 
Abstract: Humans can intuitively infer sounds from silent videos, but whether multimodal large language models can perform modal-mismatch reasoning without accessing target modalities remains relatively unexplored. Current text-assisted-video-to-audio (VT2A) methods excel in video foley tasks but struggle to acquire audio descriptions during inference. We introduce the task of Reasoning Audio Descriptions from Silent Videos (SVAD) to address this challenge and investigate vision-language models' (VLMs) capabilities on this task. To further enhance the VLMs' reasoning capacity for the SVAD task, we construct a CoT-AudioCaps dataset and propose a Chain-of-Thought-based supervised fine-tuning strategy. Experiments on SVAD and subsequent VT2A tasks demonstrate our method's effectiveness in two key aspects: significantly improving VLMs' modal-mismatch reasoning for SVAD and effectively addressing the challenge of acquiring audio descriptions during VT2A inference.
        ]]></description>
    </item>
    <item>
        <title>Benchmarking and Confidence Evaluation of LALMs For Temporal Reasoning</title>
        <link>https://arxiv.org/abs/2505.13115</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13115v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Debarpan Bhattacharya, Apoorva Kulkarni, Sriram Ganapathy</dc:creator>
        <description><![CDATA[
            背景：文本大语言模型成功促使多模态领域关注结合音频等模态实现多模态能力，大音频语言模型（LALMs）需在推理任务上评估。方法：提出名为TREA的数据集用于音频时间推理评估，对开源LALMs进行基准测试，并提出不确定性度量指标，计算模型对输入语义相同扰动的不变性。效果：开源LALMs在TREA数据集任务上表现落后于人类，且分析表明准确率和不确定性指标不一定相关，凸显高风险应用中全面评估LALMs的必要性。
            arXiv:2505.13115v1 Announce Type: cross 
Abstract: The popular success of text-based large language models (LLM) has streamlined the attention of the multimodal community to combine other modalities like vision and audio along with text to achieve similar multimodal capabilities. In this quest, large audio language models (LALMs) have to be evaluated on reasoning related tasks which are different from traditional classification or generation tasks. Towards this goal, we propose a novel dataset called temporal reasoning evaluation of audio (TREA).
  We benchmark open-source LALMs and observe that they are consistently behind human capabilities on the tasks in the TREA dataset. While evaluating LALMs, we also propose an uncertainty metric, which computes the invariance of the model to semantically identical perturbations of the input. Our analysis shows that the accuracy and uncertainty metrics are not necessarily correlated and thus, points to a need for wholesome evaluation of LALMs for high-stakes applications.
        ]]></description>
    </item>
    <item>
        <title>Efficient Speech Language Modeling via Energy Distance in Continuous Latent Space</title>
        <link>https://arxiv.org/abs/2505.13181</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13181v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhengrui Ma, Yang Feng, Chenze Shao, Fandong Meng, Jie Zhou, Min Zhang</dc:creator>
        <description><![CDATA[
            背景：现有语音语言模型存在依赖残差向量量化导致离散化误差、架构复杂等问题。方法：提出SLED方法，将语音波形编码为连续潜在表示序列，使用能量距离目标进行自回归建模，通过对比模拟和目标样本衡量分布差距，避免依赖残差向量量化。效果：简化了建模流程，保留语音信息丰富度并维持推理效率，在零样本和流式语音合成中表现良好，展现了在通用语音语言模型中的应用潜力。
            arXiv:2505.13181v1 Announce Type: cross 
Abstract: We introduce SLED, an alternative approach to speech language modeling by encoding speech waveforms into sequences of continuous latent representations and modeling them autoregressively using an energy distance objective. The energy distance offers an analytical measure of the distributional gap by contrasting simulated and target samples, enabling efficient training to capture the underlying continuous autoregressive distribution. By bypassing reliance on residual vector quantization, SLED avoids discretization errors and eliminates the need for the complicated hierarchical architectures common in existing speech language models. It simplifies the overall modeling pipeline while preserving the richness of speech information and maintaining inference efficiency. Empirical results demonstrate that SLED achieves strong performance in both zero-shot and streaming speech synthesis, showing its potential for broader applications in general-purpose speech language models.
        ]]></description>
    </item>
    <item>
        <title>Contextual Paralinguistic Data Creation for Multi-Modal Speech-LLM: Data Condensation and Spoken QA Generation</title>
        <link>https://arxiv.org/abs/2505.13338</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.13338v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qiongqiong Wang, Hardik B. Sailor, Tianchi Liu, Ai Ti Aw</dc:creator>
        <description><![CDATA[
            背景：当前语音大语言模型在上下文推理和副语言理解方面能力有限，原因是缺乏涵盖这两方面的问答数据集。方法：提出从自然语音数据生成数据集的框架，集成上下文推理与副语言信息，包括基于伪副语言标签的数据浓缩和基于大语言模型的上下文副语言问答生成。效果：在该框架生成的数据集上对Qwen2 - Audio - 7B - Instruct模型评估，与人工生成的问答数据集评估结果强相关，还揭示了模型在处理共情推理任务上的局限。
            arXiv:2505.13338v1 Announce Type: cross 
Abstract: Current speech-LLMs exhibit limited capability in contextual reasoning alongside paralinguistic understanding, primarily due to the lack of Question-Answer (QA) datasets that cover both aspects. We propose a novel framework for dataset generation from in-the-wild speech data, that integrates contextual reasoning with paralinguistic information. It consists of a pseudo paralinguistic label-based data condensation of in-the-wild speech and LLM-based Contextual Paralinguistic QA (CPQA) generation. The effectiveness is validated by a strong correlation in evaluations of the Qwen2-Audio-7B-Instruct model on a dataset created by our framework and human-generated CPQA dataset. The results also reveal the speech-LLM's limitations in handling empathetic reasoning tasks, highlighting the need for such datasets and more robust models. The proposed framework is first of its kind and has potential in training more robust speech-LLMs with paralinguistic reasoning capabilities.
        ]]></description>
    </item>
    <item>
        <title>BAT: Learning to Reason about Spatial Sounds with Large Language Models</title>
        <link>https://arxiv.org/abs/2402.01591</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2402.01591v3</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhisheng Zheng, Puyuan Peng, Ziyang Ma, Xie Chen, Eunsol Choi, David Harwath</dc:creator>
        <description><![CDATA[
            背景：空间声音推理是人类基本技能，现有野外空间声音数据集缺乏。方法：提出BAT，结合双耳声学场景分析模型的空间声音感知能力与大语言模型（LLM）的自然语言推理能力；用AudioSet和SoundSpaces 2.0合成双耳音频数据集，开发基于空间声音的问答数据集SpatialSoundQA；声学前端编码器采用新型空间音频编码器Spatial - AST，并与LLaMA - 2 7B模型集成。效果：Spatial - AST在声音事件检测等任务表现良好，BAT在空间声音感知和推理上性能优越。
            arXiv:2402.01591v3 Announce Type: replace 
Abstract: Spatial sound reasoning is a fundamental human skill, enabling us to navigate and interpret our surroundings based on sound. In this paper we present BAT, which combines the spatial sound perception ability of a binaural acoustic scene analysis model with the natural language reasoning capabilities of a large language model (LLM) to replicate this innate ability. To address the lack of existing datasets of in-the-wild spatial sounds, we synthesized a binaural audio dataset using AudioSet and SoundSpaces 2.0. Next, we developed SpatialSoundQA, a spatial sound-based question-answering dataset, offering a range of QA tasks that train BAT in various aspects of spatial sound perception and reasoning. The acoustic front end encoder of BAT is a novel spatial audio encoder named Spatial Audio Spectrogram Transformer, or Spatial-AST, which by itself achieves strong performance across sound event detection, spatial localization, and distance estimation. By integrating Spatial-AST with LLaMA-2 7B model, BAT transcends standard Sound Event Localization and Detection (SELD) tasks, enabling the model to reason about the relationships between the sounds in its environment. Our experiments demonstrate BAT's superior performance on both spatial sound perception and reasoning, showcasing the immense potential of LLMs in navigating and interpreting complex spatial audio environments.
        ]]></description>
    </item>
    <item>
        <title>Audio xLSTMs: Learning Self-Supervised Audio Representations with xLSTMs</title>
        <link>https://arxiv.org/abs/2408.16568</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2408.16568v3</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sarthak Yadav, Sergios Theodoridis, Zheng-Hua Tan</dc:creator>
        <description><![CDATA[
            背景：尽管Transformer是主流架构，但循环神经网络方法重获关注，xLSTM架构复兴了原始LSTM，不过其在自监督通用音频表征学习方面的可行性未被评估。方法：提出Audio xLSTM（AxLSTM），在自监督环境下从掩码频谱图块中学习音频表征。效果：在AudioSet数据集上预训练后，AxLSTM模型在十个不同下游任务中相对性能比自监督音频频谱图Transformer（SSAST）基线最高提升25%，且参数最多减少45%。
            arXiv:2408.16568v3 Announce Type: replace 
Abstract: While the transformer has emerged as the eminent neural architecture, several independent lines of research have emerged to address its limitations. Recurrent neural approaches have observed a lot of renewed interest, including the extended long short-term memory (xLSTM) architecture, which reinvigorates the original LSTM. However, while xLSTMs have shown competitive performance compared to the transformer, their viability for learning self-supervised general-purpose audio representations has not been evaluated. This work proposes Audio xLSTM (AxLSTM), an approach for learning audio representations from masked spectrogram patches in a self-supervised setting. Pretrained on the AudioSet dataset, the proposed AxLSTM models outperform comparable self-supervised audio spectrogram transformer (SSAST) baselines by up to 25% in relative performance across a set of ten diverse downstream tasks while having up to 45% fewer parameters.
        ]]></description>
    </item>
    <item>
        <title>ArrayDPS: Unsupervised Blind Speech Separation with a Diffusion Prior</title>
        <link>https://arxiv.org/abs/2505.05657</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.05657v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhongweiyang Xu, Xulin Fan, Zhong-Qiu Wang, Xilin Jiang, Romit Roy Choudhury</dc:creator>
        <description><![CDATA[
            盲语音分离（BSS）旨在从麦克风阵列录制的音频混合信号中分离出多个语音源，但该问题是盲逆问题，极具挑战。为此，本文提出ArrayDPS，以无监督、与阵列无关的生成方式解决BSS问题。其核心基于扩散后验采样（DPS），需通过制定单独的优化问题来近似似然。该优化解可近似房间声学和麦克风间的相对传递函数，结合扩散先验，经采样过程分离语音源。实验表明，ArrayDPS在SDR上优于所有无监督基线方法，与有监督方法相当。
            arXiv:2505.05657v2 Announce Type: replace 
Abstract: Blind Speech Separation (BSS) aims to separate multiple speech sources from audio mixtures recorded by a microphone array. The problem is challenging because it is a blind inverse problem, i.e., the microphone array geometry, the room impulse response (RIR), and the speech sources, are all unknown. We propose ArrayDPS to solve the BSS problem in an unsupervised, array-agnostic, and generative manner. The core idea builds on diffusion posterior sampling (DPS), but unlike DPS where the likelihood is tractable, ArrayDPS must approximate the likelihood by formulating a separate optimization problem. The solution to the optimization approximates room acoustics and the relative transfer functions between microphones. These approximations, along with the diffusion priors, iterate through the ArrayDPS sampling process and ultimately yield separated voice sources. We only need a simple single-speaker speech diffusion model as a prior along with the mixtures recorded at the microphones; no microphone array information is necessary. Evaluation results show that ArrayDPS outperforms all baseline unsupervised methods while being comparable to supervised methods in terms of SDR. Audio demos are provided at: https://arraydps.github.io/ArrayDPSDemo/.
        ]]></description>
    </item>
    <item>
        <title>EMelodyGen: Emotion-Conditioned Melody Generation in ABC Notation with the Musical Feature Template</title>
        <link>https://arxiv.org/abs/2309.13259</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2309.13259v3</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Monan Zhou, Xiaobing Li, Feng Yu, Wei Li</dc:creator>
        <description><![CDATA[
            背景：结构化且有情感标注的乐谱稀缺。方法：从小规模情感符号音乐数据集和音乐心理学结论中得出音乐特征与情感标签的统计关联，设计控制情感旋律生成的模板；用模板为大型结构化乐谱集标注粗略情感标签，转为ABC记谱法，通过数据增强减少标签不平衡，得到Rough4Q数据集。效果：在Rough4Q上预训练的系统骨干音乐解析率达99%，模板生成的旋律在盲听测试中情感表达一致率达91%。
            arXiv:2309.13259v3 Announce Type: replace-cross 
Abstract: The EMelodyGen system focuses on emotional melody generation in ABC notation controlled by the musical feature template. Owing to the scarcity of well-structured and emotionally labeled sheet music, we designed a template for controlling emotional melody generation by statistical correlations between musical features and emotion labels derived from small-scale emotional symbolic music datasets and music psychology conclusions. We then automatically annotated a large, well-structured sheet music collection with rough emotional labels by the template, converted them into ABC notation, and reduced label imbalance by data augmentation, resulting in a dataset named Rough4Q. Our system backbone pre-trained on Rough4Q can achieve up to 99% music21 parsing rate and melodies generated by our template can lead to a 91% alignment on emotional expressions in blind listening tests. Ablation studies further validated the effectiveness of the feature controls in the template. Available code and demos are at https://github.com/monetjoe/EMelodyGen.
        ]]></description>
    </item>
    <item>
        <title>SSR: Alignment-Aware Modality Connector for Speech Language Models</title>
        <link>https://arxiv.org/abs/2410.00168</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.00168v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Weiting Tan, Hirofumi Inaguma, Ning Dong, Paden Tomasello, Xutai Ma</dc:creator>
        <description><![CDATA[
            背景：将语音融入预训练语言模型时，存在长语音编码效率低和预训练文本模态灾难性遗忘问题。方法：提出SSR-Connector，利用语音-文本对齐对语音特征进行分段和压缩，使其与文本嵌入粒度匹配；引入包含蒸馏和微调阶段的两阶段训练流程，缓解灾难性遗忘。效果：优于现有语音-文本模态融合机制，在语音理解任务上表现更好，如StoryCloze准确率提升10%、Speech - MMLU提升20%，且保留了预训练文本能力。
            arXiv:2410.00168v2 Announce Type: replace-cross 
Abstract: Fusing speech into pre-trained language model (SpeechLM) usually suffers from inefficient encoding of long-form speech and catastrophic forgetting of pre-trained text modality. We propose SSR-Connector (Segmented Speech Representation Connector) for better modality fusion. Leveraging speech-text alignments, our approach segments and compresses speech features to match the granularity of text embeddings. Additionally, we introduce a two-stage training pipeline that includes the distillation and fine-tuning phases to mitigate catastrophic forgetting. SSR-Connector outperforms existing mechanism for speech-text modality fusion, consistently achieving better speech understanding (e.g., +10 accuracy on StoryCloze and +20 on Speech-MMLU) while preserving pre-trained text ability.
        ]]></description>
    </item>
</channel>
</rss>