<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
<channel>
    <title>arXiv Paper Filter</title>
    <link>https://github.com/None/arxiv_filter</link>
    <description>根据研究兴趣筛选的arXiv论文</description>
    <atom:link href="https://raw.githubusercontent.com/None/arxiv_filter/main/feed.xml" rel="self" type="application/rss+xml" />
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>zh-CN</language>
    <lastBuildDate>Tue, 10 Jun 2025 12:22:47 +0800</lastBuildDate>
    <managingEditor>None@github.com</managingEditor>
    <pubDate>Tue, 10 Jun 2025 12:22:47 +0800</pubDate>
    <skipDays>
        <day>Saturday</day>
        <day>Sunday</day>
    </skipDays>

    <item>
        <title>Dynamic Graph CNN with Jacobi Kolmogorov-Arnold Networks for 3D Classification of Point Sets</title>
        <link>https://arxiv.org/abs/2506.06296</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06296v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hanaa El Afia, Said Ohamouddou, Raddouane Chiheb, Abdellatif El Afia</dc:creator>
        <description><![CDATA[
            背景：需要有效方法对三维点云进行分类。方法：提出Jacobi - KAN - DGCNN框架，将动态图卷积神经网络（DGCNN）与雅可比柯尔莫哥洛夫 - 阿诺德网络（KAN）结合，在简化的DGCNN架构中用自适应单变量多项式展开代替多层感知器（MLP）层。效果：在ModelNet40数据集对比实验中，采用雅可比多项式的KAN层在准确性和收敛速度上优于传统基于线性层的DGCNN基线，且保持参数效率，还发现高多项式次数不一定提升性能。
            arXiv:2506.06296v1 Announce Type: new 
Abstract: We introduce Jacobi-KAN-DGCNN, a framework that integrates Dynamic Graph Convolutional Neural Network (DGCNN) with Jacobi Kolmogorov-Arnold Networks (KAN) for the classification of three-dimensional point clouds. This method replaces Multi-Layer Perceptron (MLP) layers with adaptable univariate polynomial expansions within a streamlined DGCNN architecture, circumventing deep levels for both MLP and KAN to facilitate a layer-by-layer comparison. In comparative experiments on the ModelNet40 dataset, KAN layers employing Jacobi polynomials outperform the traditional linear layer-based DGCNN baseline in terms of accuracy and convergence speed, while maintaining parameter efficiency. Our results demonstrate that higher polynomial degrees do not automatically improve performance, highlighting the need for further theoretical and empirical investigation to fully understand the interactions between polynomial bases, degrees, and the mechanisms of graph-based learning.
        ]]></description>
    </item>
    <item>
        <title>How Significant Are the Real Performance Gains? An Unbiased Evaluation Framework for GraphRAG</title>
        <link>https://arxiv.org/abs/2506.06331</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06331v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qiming Zeng, Xiao Yan, Hao Luo, Yuhao Lin, Yuxiang Wang, Fangcheng Fu, Bo Du, Quanqing Xu, Jiawei Jiang</dc:creator>
        <description><![CDATA[
            背景：基于图的检索增强生成（GraphRAG）可增强大语言模型生成优质答案的能力，但当前的答案评估框架存在无关问题和评估偏差两个关键缺陷。方法：提出无偏评估框架，用图文本接地问题生成更相关问题，采用无偏评估程序消除基于大语言模型答案评估的偏差。效果：应用该框架评估3种代表性GraphRAG方法，发现其性能提升比之前报道的更为温和，呼吁开展科学评估为GraphRAG研究奠定基础。
            arXiv:2506.06331v1 Announce Type: new 
Abstract: By retrieving contexts from knowledge graphs, graph-based retrieval-augmented generation (GraphRAG) enhances large language models (LLMs) to generate quality answers for user questions. Many GraphRAG methods have been proposed and reported inspiring performance in answer quality. However, we observe that the current answer evaluation framework for GraphRAG has two critical flaws, i.e., unrelated questions and evaluation biases, which may lead to biased or even wrong conclusions on performance. To tackle the two flaws, we propose an unbiased evaluation framework that uses graph-text-grounded question generation to produce questions that are more related to the underlying dataset and an unbiased evaluation procedure to eliminate the biases in LLM-based answer assessment. We apply our unbiased framework to evaluate 3 representative GraphRAG methods and find that their performance gains are much more moderate than reported previously. Although our evaluation framework may still have flaws, it calls for scientific evaluations to lay solid foundations for GraphRAG research.
        ]]></description>
    </item>
    <item>
        <title>Relationship Detection on Tabular Data Using Statistical Analysis and Large Language Models</title>
        <link>https://arxiv.org/abs/2506.06371</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06371v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Panagiotis Koletsis, Christos Panagiotopoulos, Georgios Th. Papadopoulos, Vasilis Efthymiou</dc:creator>
        <description><![CDATA[
            近年来，表格解释任务因重要性及新技术和基准的引入取得显著进展。本文提出一种混合方法检测无标签表格数据列间关系，以知识图谱为参考。该方法利用大语言模型，结合统计分析缩小潜在知识图谱关系的搜索空间，主要模块有定义域和值域约束检测、关系共现分析。在SemTab挑战的两个基准数据集上实验，评估各模块影响及不同大语言模型在不同量化水平的效果，还测试不同提示技术。该方法在github公开，在数据集上与现有方法相比有竞争力。
            arXiv:2506.06371v1 Announce Type: new 
Abstract: Over the past few years, table interpretation tasks have made significant progress due to their importance and the introduction of new technologies and benchmarks in the field. This work experiments with a hybrid approach for detecting relationships among columns of unlabeled tabular data, using a Knowledge Graph (KG) as a reference point, a task known as CPA. This approach leverages large language models (LLMs) while employing statistical analysis to reduce the search space of potential KG relations. The main modules of this approach for reducing the search space are domain and range constraints detection, as well as relation co-appearance analysis. The experimental evaluation on two benchmark datasets provided by the SemTab challenge assesses the influence of each module and the effectiveness of different state-of-the-art LLMs at various levels of quantization. The experiments were performed, as well as at different prompting techniques. The proposed methodology, which is publicly available on github, proved to be competitive with state-of-the-art approaches on these datasets.
        ]]></description>
    </item>
    <item>
        <title>Natural Language Interaction with Databases on Edge Devices in the Internet of Battlefield Things</title>
        <link>https://arxiv.org/abs/2506.06396</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06396v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Christopher D. Molek, Roberto Fronteddu, K. Brent Venable, Niranjan Suri</dc:creator>
        <description><![CDATA[
            随着战场物联网（IoBT）发展，需将设备数据处理成可用信息以提升态势感知。本文提出用自然语言处理查询数据库并返回自然语言响应的工作流，利用适合边缘设备的大语言模型（LLM）和适合动态连接网络的图形数据库。架构用LLM将自然语言问题映射为Cypher查询并总结输出。在相关数据库评估多个中型LLM，发现Llama 3.1（80亿参数）表现最佳，两步法使准确率提升19.4%，为边缘设备部署LLM与数据库自然交互奠定基础。
            arXiv:2506.06396v1 Announce Type: new 
Abstract: The expansion of the Internet of Things (IoT) in the battlefield, Internet of Battlefield Things (IoBT), gives rise to new opportunities for enhancing situational awareness. To increase the potential of IoBT for situational awareness in critical decision making, the data from these devices must be processed into consumer-ready information objects, and made available to consumers on demand. To address this challenge we propose a workflow that makes use of natural language processing (NLP) to query a database technology and return a response in natural language. Our solution utilizes Large Language Models (LLMs) that are sized for edge devices to perform NLP as well as graphical databases which are well suited for dynamic connected networks which are pervasive in the IoBT. Our architecture employs LLMs for both mapping questions in natural language to Cypher database queries as well as to summarize the database output back to the user in natural language. We evaluate several medium sized LLMs for both of these tasks on a database representing publicly available data from the US Army's Multipurpose Sensing Area (MSA) at the Jornada Range in Las Cruces, NM. We observe that Llama 3.1 (8 billion parameters) outperforms the other models across all the considered metrics. Most importantly, we note that, unlike current methods, our two step approach allows the relaxation of the Exact Match (EM) requirement of the produced Cypher queries with ground truth code and, in this way, it achieves a 19.4% increase in accuracy. Our workflow lays the ground work for deploying LLMs on edge devices to enable natural language interactions with databases containing information objects for critical decision making.
        ]]></description>
    </item>
    <item>
        <title>Direct Behavior Optimization: Unlocking the Potential of Lightweight LLMs</title>
        <link>https://arxiv.org/abs/2506.06401</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06401v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hongming Yang, Shi Lin, Jun Shao, Changting Lin, Donghai Zhu, Meng Han, Qinglei Kong</dc:creator>
        <description><![CDATA[
            背景：轻量级大语言模型（LwLLMs）虽有资源效率等优势，但推理能力有限，现有提示优化方法对其效果不佳。方法：引入源于思维链（CoT）提示技术的直接行为优化范式DeBoP，用无梯度蒙特卡罗树搜索将复杂提示优化转化为离散、可量化执行序列的优化。效果：在七个具有挑战性的任务中评估，DeBoP在多数任务上显著优于近期提示优化方法，优化后的LwLLMs在多数任务上超越GPT - 3.5，且比其他自动提示优化方法减少约60%的计算时间。
            arXiv:2506.06401v1 Announce Type: new 
Abstract: Lightweight Large Language Models (LwLLMs) are reduced-parameter, optimized models designed to run efficiently on consumer-grade hardware, offering significant advantages in resource efficiency, cost-effectiveness, and data privacy. However, these models often struggle with limited inference and reasoning capabilities, which restrict their performance on complex tasks and limit their practical applicability. Moreover, existing prompt optimization methods typically rely on extensive manual effort or the meta-cognitive abilities of state-of-the-art LLMs, making them less effective for LwLLMs. To address these challenges, we introduce DeBoP, a new Direct Behavior Optimization Paradigm, original from the Chain-of-Thought (CoT) prompting technique. Unlike CoT Prompting, DeBoP is an automatic optimization method, which focuses on the optimization directly on the behavior of LwLLMs. In particular, DeBoP transforms the optimization of complex prompts into the optimization of discrete, quantifiable execution sequences using a gradient-free Monte Carlo Tree Search. We evaluate DeBoP on seven challenging tasks where state-of-the-art LLMs excel but LwLLMs generally underperform. Experimental results demonstrate that DeBoP significantly outperforms recent prompt optimization methods on most tasks. In particular, DeBoP-optimized LwLLMs surpass GPT-3.5 on most tasks while reducing computational time by approximately 60% compared to other automatic prompt optimization methods.
        ]]></description>
    </item>
    <item>
        <title>SMAR: Soft Modality-Aware Routing Strategy for MoE-based Multimodal Large Language Models Preserving Language Capabilities</title>
        <link>https://arxiv.org/abs/2506.06406</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06406v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Guoyang Xia, Yifeng Ding, Fengfa Li, Lei Ren, Chen Wei, Fangxiang Feng, Xiaojie Wang</dc:creator>
        <description><![CDATA[
            背景：混合专家（MoE）架构在扩展大语言模型时备受关注，然而现有构建多模态MoE模型的方法存在训练成本高或语言能力退化等问题。方法：提出软模态感知路由（SMAR）正则化技术，利用Kullback Leibler散度控制跨模态的路由概率分布，在不修改模型架构且不过度依赖文本数据的情况下促进专家专业化。效果：视觉指令调优实验显示，SMAR仅用2.5%纯文本就能保持86.6%的语言能力，优于基线并保持了较强的多模态性能。
            arXiv:2506.06406v1 Announce Type: new 
Abstract: Mixture of Experts (MoE) architectures have become a key approach for scaling large language models, with growing interest in extending them to multimodal tasks. Existing methods to build multimodal MoE models either incur high training costs or suffer from degraded language capabilities when adapting pretrained models. To address this, we propose Soft ModalityAware Routing (SMAR), a novel regularization technique that uses Kullback Leibler divergence to control routing probability distributions across modalities, encouraging expert specialization without modifying model architecture or heavily relying on textual data. Experiments on visual instruction tuning show that SMAR preserves language ability at 86.6% retention with only 2.5% pure text, outperforming baselines while maintaining strong multimodal performance. Our approach offers a practical and efficient solution to balance modality differentiation and language capabilities in multimodal MoE models.
        ]]></description>
    </item>
    <item>
        <title>LETS Forecast: Learning Embedology for Time Series Forecasting</title>
        <link>https://arxiv.org/abs/2506.06454</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06454v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Abrar Majeedi, Viswanatha Reddy Gajjala, Satya Sai Srinath Namburi GNVV, Nada Magdi Elkordi, Yin Li</dc:creator>
        <description><![CDATA[
            现实世界的时间序列常受复杂非线性动力学支配，理解其潜在动力学对精准预测未来至关重要。现有深度学习方法大多未明确建模动力学。为此，本文提出DeepEDM框架，将非线性动力系统建模与深度神经网络相结合。该框架受经验动态建模启发，基于Takens定理，从延迟嵌入中学习潜在空间，用核回归近似潜在动力学。实验表明，DeepEDM对输入噪声有鲁棒性，在预测精度上超越了现有最优方法。
            arXiv:2506.06454v1 Announce Type: new 
Abstract: Real-world time series are often governed by complex nonlinear dynamics. Understanding these underlying dynamics is crucial for precise future prediction. While deep learning has achieved major success in time series forecasting, many existing approaches do not explicitly model the dynamics. To bridge this gap, we introduce DeepEDM, a framework that integrates nonlinear dynamical systems modeling with deep neural networks. Inspired by empirical dynamic modeling (EDM) and rooted in Takens' theorem, DeepEDM presents a novel deep model that learns a latent space from time-delayed embeddings, and employs kernel regression to approximate the underlying dynamics, while leveraging efficient implementation of softmax attention and allowing for accurate prediction of future time steps. To evaluate our method, we conduct comprehensive experiments on synthetic data of nonlinear dynamical systems as well as real-world time series across domains. Our results show that DeepEDM is robust to input noise, and outperforms state-of-the-art methods in forecasting accuracy. Our code is available at: https://abrarmajeedi.github.io/deep_edm.
        ]]></description>
    </item>
    <item>
        <title>Graph Persistence goes Spectral</title>
        <link>https://arxiv.org/abs/2506.06571</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06571v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mattie Ji, Amauri H. Souza, Vikas Garg</dc:creator>
        <description><![CDATA[
            背景：包含复杂拓扑信息可提升消息传递图神经网络的表达能力，现有持久同调（PH）方法虽有改进但仍无法捕捉基本图结构信息。方法：提出SpectRe，一种将谱信息集成到PH图中的新拓扑描述符，并引入全局和局部稳定性概念分析现有描述符。效果：SpectRe比现有图描述符更具表达性且局部稳定，在合成和真实数据集实验中证明其有效性及提升图模型相关学习任务能力的潜力。
            arXiv:2506.06571v1 Announce Type: new 
Abstract: Including intricate topological information (e.g., cycles) provably enhances the expressivity of message-passing graph neural networks (GNNs) beyond the Weisfeiler-Leman (WL) hierarchy. Consequently, Persistent Homology (PH) methods are increasingly employed for graph representation learning. In this context, recent works have proposed decorating classical PH diagrams with vertex and edge features for improved expressivity. However, due to their dependence on features, these methods still fail to capture basic graph structural information. In this paper, we propose SpectRe -- a new topological descriptor for graphs that integrates spectral information into PH diagrams. Notably, SpectRe is strictly more expressive than existing descriptors on graphs. We also introduce notions of global and local stability to analyze existing descriptors and establish that SpectRe is locally stable. Finally, experiments on synthetic and real-world datasets demonstrate the effectiveness of SpectRe and its potential to enhance the capabilities of graph models in relevant learning tasks.
        ]]></description>
    </item>
    <item>
        <title>RARL: Improving Medical VLM Reasoning and Generalization with Reinforcement Learning and LoRA under Data and Hardware Constraints</title>
        <link>https://arxiv.org/abs/2506.06600</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06600v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tan-Hanh Pham, Chris Ngo</dc:creator>
        <description><![CDATA[
            背景：当前医学视觉语言模型（VLMs）在泛化性、透明度和计算效率上存在局限，阻碍其在资源受限场景部署。方法：提出推理感知强化学习框架RARL，用低秩自适应和自定义奖励函数微调轻量级基础模型Qwen2 - VL - 2B - Instruct，在单GPU上训练，用大语言模型作为评判框架评估。效果：RARL显著提升医学图像分析和临床推理性能，在推理任务上比监督微调高约7.78%，泛化性能提升约27%，比传统强化学习微调高约4%。
            arXiv:2506.06600v1 Announce Type: new 
Abstract: The growing integration of vision-language models (VLMs) in medical applications offers promising support for diagnostic reasoning. However, current medical VLMs often face limitations in generalization, transparency, and computational efficiency-barriers that hinder deployment in real-world, resource-constrained settings. To address these challenges, we propose a Reasoning-Aware Reinforcement Learning framework, \textbf{RARL}, that enhances the reasoning capabilities of medical VLMs while remaining efficient and adaptable to low-resource environments. Our approach fine-tunes a lightweight base model, Qwen2-VL-2B-Instruct, using Low-Rank Adaptation and custom reward functions that jointly consider diagnostic accuracy and reasoning quality. Training is performed on a single NVIDIA A100-PCIE-40GB GPU, demonstrating the feasibility of deploying such models in constrained environments. We evaluate the model using an LLM-as-judge framework that scores both correctness and explanation quality. Experimental results show that RARL significantly improves VLM performance in medical image analysis and clinical reasoning, outperforming supervised fine-tuning on reasoning-focused tasks by approximately 7.78%, while requiring fewer computational resources. Additionally, we demonstrate the generalization capabilities of our approach on unseen datasets, achieving around 27% improved performance compared to supervised fine-tuning and about 4% over traditional RL fine-tuning. Our experiments also illustrate that diversity prompting during training and reasoning prompting during inference are crucial for enhancing VLM performance. Our findings highlight the potential of reasoning-guided learning and reasoning prompting to steer medical VLMs toward more transparent, accurate, and resource-efficient clinical decision-making. Code and data are publicly available.
        ]]></description>
    </item>
    <item>
        <title>Curriculum Reinforcement Learning from Easy to Hard Tasks Improves LLM Reasoning</title>
        <link>https://arxiv.org/abs/2506.06632</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06632v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Shubham Parashar, Shurui Gui, Xiner Li, Hongyi Ling, Sushil Vemuri, Blake Olson, Eric Li, Yu Zhang, James Caverlee, Dileep Kalathil, Shuiwang Ji</dc:creator>
        <description><![CDATA[
            背景：现有研究表明单独用强化学习（RL）提升大语言模型在困难任务上的推理能力效果不佳。方法：受课程学习启发，提出从易到难安排任务的E2H Reasoner方法，让模型逐步建立推理技能，且通过合理调度逐渐减少简单任务以防止过拟合。效果：理论上证明了收敛性，推导了有限样本复杂度边界；实验显示该方法显著提升了15亿到30亿参数小模型的推理能力，凸显有效性。
            arXiv:2506.06632v1 Announce Type: new 
Abstract: We aim to improve the reasoning capabilities of language models via reinforcement learning (RL). Recent RL post-trained models like DeepSeek-R1 have demonstrated reasoning abilities on mathematical and coding tasks. However, prior studies suggest that using RL alone to improve reasoning on inherently difficult tasks is less effective. Here, we draw inspiration from curriculum learning and propose to schedule tasks from easy to hard (E2H), allowing LLMs to build reasoning skills gradually. Our method is termed E2H Reasoner. Empirically, we observe that, although easy tasks are important initially, fading them out through appropriate scheduling is essential in preventing overfitting. Theoretically, we establish convergence guarantees for E2H Reasoner within an approximate policy iteration framework. We derive finite-sample complexity bounds and show that when tasks are appropriately decomposed and conditioned, learning through curriculum stages requires fewer total samples than direct learning. Experiments across multiple domains show that E2H Reasoner significantly improves the reasoning ability of small LLMs (1.5B to 3B), which otherwise struggle when trained with vanilla RL alone, highlighting the effectiveness of our method.
        ]]></description>
    </item>
    <item>
        <title>SAFER: A Calibrated Risk-Aware Multimodal Recommendation Model for Dynamic Treatment Regimes</title>
        <link>https://arxiv.org/abs/2506.06649</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06649v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yishan Shen, Yuyang Ye, Hui Xiong, Yong Chen</dc:creator>
        <description><![CDATA[
            背景：动态治疗方案（DTRs）对精准医疗很关键，但存在不安全治疗风险，现有方法多依赖临床医生标准且主要用结构化电子病历数据，未挖掘临床笔记价值。方法：提出SAFER，一个整合结构化电子病历和临床笔记的框架，假设死亡患者最优治疗方案模糊以处理标签不确定性，还用共形预测提供统计保证。效果：在两个脓毒症公开数据集实验显示，SAFER在多个推荐指标和反事实死亡率上超现有基线，能提供可靠保证。
            arXiv:2506.06649v1 Announce Type: new 
Abstract: Dynamic treatment regimes (DTRs) are critical to precision medicine, optimizing long-term outcomes through personalized, real-time decision-making in evolving clinical contexts, but require careful supervision for unsafe treatment risks. Existing efforts rely primarily on clinician-prescribed gold standards despite the absence of a known optimal strategy, and predominantly using structured EHR data without extracting valuable insights from clinical notes, limiting their reliability for treatment recommendations. In this work, we introduce SAFER, a calibrated risk-aware tabular-language recommendation framework for DTR that integrates both structured EHR and clinical notes, enabling them to learn from each other, and addresses inherent label uncertainty by assuming ambiguous optimal treatment solution for deceased patients. Moreover, SAFER employs conformal prediction to provide statistical guarantees, ensuring safe treatment recommendations while filtering out uncertain predictions. Experiments on two publicly available sepsis datasets demonstrate that SAFER outperforms state-of-the-art baselines across multiple recommendation metrics and counterfactual mortality rate, while offering robust formal assurances. These findings underscore SAFER potential as a trustworthy and theoretically grounded solution for high-stakes DTR applications.
        ]]></description>
    </item>
    <item>
        <title>Learning Robust Heterogeneous Graph Representations via Contrastive-Reconstruction under Sparse Semantics</title>
        <link>https://arxiv.org/abs/2506.06682</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06682v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Di Lin, Wanjing Ren, Xuanbin Li, Rui Zhang</dc:creator>
        <description><![CDATA[
            背景：在图自监督学习中，掩码自编码器（MAE）和对比学习（CL）各有优势但面临挑战，混合框架设计共享编码器困难，CL在语义稀疏场景有问题。方法：提出用于异构图的双通道自监督学习框架HetCRF，采用两阶段聚合策略适应嵌入语义，增强编码器输出构建视图，提出两种正样本增强策略平衡梯度。效果：在四个异构图数据集的节点分类实验中，HetCRF优于现有基线，在Aminer和Freebase数据集40%标签率下，Macro - F1分数分别提升2.75%和2.2%。
            arXiv:2506.06682v1 Announce Type: new 
Abstract: In graph self-supervised learning, masked autoencoders (MAE) and contrastive learning (CL) are two prominent paradigms. MAE focuses on reconstructing masked elements, while CL maximizes similarity between augmented graph views. Recent studies highlight their complementarity: MAE excels at local feature capture, and CL at global information extraction. Hybrid frameworks for homogeneous graphs have been proposed, but face challenges in designing shared encoders to meet the semantic requirements of both tasks. In semantically sparse scenarios, CL struggles with view construction, and gradient imbalance between positive and negative samples persists. This paper introduces HetCRF, a novel dual-channel self-supervised learning framework for heterogeneous graphs. HetCRF uses a two-stage aggregation strategy to adapt embedding semantics, making it compatible with both MAE and CL. To address semantic sparsity, it enhances encoder output for view construction instead of relying on raw features, improving efficiency. Two positive sample augmentation strategies are also proposed to balance gradient contributions. Node classification experiments on four real-world heterogeneous graph datasets demonstrate that HetCRF outperforms state-of-the-art baselines. On datasets with missing node features, such as Aminer and Freebase, at a 40% label rate in node classification, HetCRF improves the Macro-F1 score by 2.75% and 2.2% respectively compared to the second-best baseline, validating its effectiveness and superiority.
        ]]></description>
    </item>
    <item>
        <title>MarginSel : Max-Margin Demonstration Selection for LLMs</title>
        <link>https://arxiv.org/abs/2506.06699</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06699v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Rajeev Bhatt Ambati, James Lester, Shashank Srivastava, Snigdha Chaturvedi</dc:creator>
        <description><![CDATA[
            背景：大语言模型（LLMs）通过上下文学习（ICL）进行少样本学习效果出色，但ICL的有效性常受示范示例选择和排序的影响。方法：提出MarginSel，一种两步法，为ICL提示选择难的示范示例，并适应每个测试实例。效果：在分类任务中，与随机选择示例相比，F1分数有2 - 7%的绝对提升，且能有效增加难示例的边界，使决策边界向有利方向移动。
            arXiv:2506.06699v1 Announce Type: new 
Abstract: Large Language Models (LLMs) excel at few-shot learning via in-context learning (ICL). However, the effectiveness of ICL is often sensitive to the selection and ordering of demonstration examples. To address this, we present MarginSel: Max-Margin Demonstration Selection for LLMs, a two-step method that selects hard demonstration examples for the ICL prompt, adapting to each test instance. Our approach achieves 2-7% absolute improvement in F1-score across classification tasks, compared to a random selection of examples. We also provide theoretical insights and empirical evidence showing that MarginSel induces max-margin behavior in LLMs by effectively increasing the margin for hard examples, analogous to support vectors, thereby shifting the decision boundary in a beneficial direction.
        ]]></description>
    </item>
    <item>
        <title>Dynamic and Parametric Retrieval-Augmented Generation</title>
        <link>https://arxiv.org/abs/2506.06704</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06704v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Weihang Su, Qingyao Ai, Jingtao Zhan, Qian Dong, Yiqun Liu</dc:creator>
        <description><![CDATA[
            检索增强生成（RAG）是为大语言模型赋予外部知识的基础范式，但传统RAG系统采用静态检索生成流程和上下文知识注入，在复杂任务中表现欠佳。为此，研究聚焦于动态RAG和参数化RAG两个新兴领域。动态RAG在模型生成时自适应确定检索内容和时机，参数化RAG将知识注入从输入层转为参数层以提升效率。该研究全面介绍了这两个领域进展，为RAG研究提供理论和实践参考。
            arXiv:2506.06704v1 Announce Type: new 
Abstract: Retrieval-Augmented Generation (RAG) has become a foundational paradigm for equipping large language models (LLMs) with external knowledge, playing a critical role in information retrieval and knowledge-intensive applications. However, conventional RAG systems typically adopt a static retrieve-then-generate pipeline and rely on in-context knowledge injection, which can be suboptimal for complex tasks that require multihop reasoning, adaptive information access, and deeper integration of external knowledge. Motivated by these limitations, the research community has moved beyond static retrieval and in-context knowledge injection. Among the emerging directions, this tutorial delves into two rapidly growing and complementary research areas on RAG: Dynamic RAG and Parametric RAG. Dynamic RAG adaptively determines when and what to retrieve during the LLM's generation process, enabling real-time adaptation to the LLM's evolving information needs. Parametric RAG rethinks how retrieved knowledge should be injected into LLMs, transitioning from input-level to parameter-level knowledge injection for enhanced efficiency and effectiveness. This tutorial offers a comprehensive overview of recent advances in these emerging research areas. It also shares theoretical foundations and practical insights to support and inspire further research in RAG.
        ]]></description>
    </item>
    <item>
        <title>A Survey of Retentive Network</title>
        <link>https://arxiv.org/abs/2506.06708</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06708v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Haiqi Yang, Zhiyuan Li, Yi Chang, Yuan Wu</dc:creator>
        <description><![CDATA[
            背景：Transformer处理长序列时存在高内存成本和可扩展性有限的问题，而目前缺少对Retentive Network（RetNet）的全面综述。方法：本文首次详细综述RetNet架构、关键创新及多样应用，还探讨其面临的主要挑战并提出未来研究方向。效果：RetNet引入保留机制统一递归和注意力的优势，能实现线性时间推理、高效建模长上下文，在自然语言处理、语音识别和时间序列分析等领域表现出色。
            arXiv:2506.06708v1 Announce Type: new 
Abstract: Retentive Network (RetNet) represents a significant advancement in neural network architecture, offering an efficient alternative to the Transformer. While Transformers rely on self-attention to model dependencies, they suffer from high memory costs and limited scalability when handling long sequences due to their quadratic complexity. To mitigate these limitations, RetNet introduces a retention mechanism that unifies the inductive bias of recurrence with the global dependency modeling of attention. This mechanism enables linear-time inference, facilitates efficient modeling of extended contexts, and remains compatible with fully parallelizable training pipelines. RetNet has garnered significant research interest due to its consistently demonstrated cross-domain effectiveness, achieving robust performance across machine learning paradigms including natural language processing, speech recognition, and time-series analysis. However, a comprehensive review of RetNet is still missing from the current literature. This paper aims to fill that gap by offering the first detailed survey of the RetNet architecture, its key innovations, and its diverse applications. We also explore the main challenges associated with RetNet and propose future research directions to support its continued advancement in both academic research and practical deployment.
        ]]></description>
    </item>
    <item>
        <title>Neighborhood Overlap-Aware High-Order Graph Neural Network for Dynamic Graph Learning</title>
        <link>https://arxiv.org/abs/2506.06728</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06728v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ling Wang</dc:creator>
        <description><![CDATA[
            动态图学习旨在学习信息丰富且随时间演变的节点嵌入以支持下游任务，其面临的挑战是有效建模动态图拓扑的时间动态和结构依赖关系。现有动态图神经网络常忽略复杂结构模式。为此，研究人员提出邻域重叠感知高阶图神经网络（NO - HGNN），一是基于邻域重叠程度计算相关分数，二是将相关性嵌入高阶图神经网络的消息传递过程。在两个真实动态图上的实验表明，NO - HGNN显著提高了链接预测的准确性，优于多个先进方法。
            arXiv:2506.06728v1 Announce Type: new 
Abstract: Dynamic graph learning (DGL) aims to learn informative and temporally-evolving node embeddings to support downstream tasks such as link prediction. A fundamental challenge in DGL lies in effectively modeling both the temporal dynamics and structural dependencies of evolving graph topologies. Recent advances in Dynamic Graph Neural Networks (DGNNs) have obtained remarkable success by leveraging message-passing mechanisms to capture pairwise node interactions. However, these approaches often overlook more complex structural patterns, particularly neighborhood overlap, which can play a critical role in characterizing node interactions. To overcome this limitation, we introduce the Neighborhood Overlap-Aware High-Order Graph Neural Network (NO-HGNN), which is built upon two key innovations: (a) computing a correlation score based on the extent of neighborhood overlap to better capture complex node interactions; and (b) embedding this correlation directly into the message-passing process of high-order graph neural networks in the DGL. Experiments on two real-world dynamic graphs show that NO-HGNN achieves notable improvements in link prediction accuracy, outperforming several state-of-the-art approaches.
        ]]></description>
    </item>
    <item>
        <title>Mitigating Object Hallucination via Robust Local Perception Search</title>
        <link>https://arxiv.org/abs/2506.06729</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06729v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zixian Gao, Chao Yang, Zhanhui Zhou, Xing Xu, Chaochao Lu</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型虽能有效整合视觉与语言，但存在输出与图像内容不符的幻觉现象。方法：引入局部感知搜索（LPS）这一简单且无需训练的推理解码方法，利用局部视觉先验信息作为价值函数来纠正解码过程。效果：LPS是可插拔方法，能适配多种模型。在常用幻觉基准和噪声数据上的大量实验表明，相比基线，LPS显著降低了幻觉发生率，在噪声环境下表现尤为出色。
            arXiv:2506.06729v1 Announce Type: new 
Abstract: Recent advancements in Multimodal Large Language Models (MLLMs) have enabled them to effectively integrate vision and language, addressing a variety of downstream tasks. However, despite their significant success, these models still exhibit hallucination phenomena, where the outputs appear plausible but do not align with the content of the images. To mitigate this issue, we introduce Local Perception Search (LPS), a decoding method during inference that is both simple and training-free, yet effectively suppresses hallucinations. This method leverages local visual prior information as a value function to correct the decoding process. Additionally, we observe that the impact of the local visual prior on model performance is more pronounced in scenarios with high levels of image noise. Notably, LPS is a plug-and-play approach that is compatible with various models. Extensive experiments on widely used hallucination benchmarks and noisy data demonstrate that LPS significantly reduces the incidence of hallucinations compared to the baseline, showing exceptional performance, particularly in noisy settings.
        ]]></description>
    </item>
    <item>
        <title>C-PATH: Conversational Patient Assistance and Triage in Healthcare System</title>
        <link>https://arxiv.org/abs/2506.06737</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06737v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qi Shi, Qiwei Han, Cl\'audia Soares</dc:creator>
        <description><![CDATA[
            背景：医疗系统复杂，患者寻求及时合适医疗帮助存在障碍。方法：本文介绍基于大语言模型的对话式AI系统C - PATH，利用多阶段管道在医学知识、对话数据和临床总结上微调，构建基于GPT的数据增强框架，将DDXPlus中的结构化临床知识转化为通俗易懂对话，还实施对话历史管理策略。效果：GPTScore评估显示其在清晰度、信息量和推荐准确性等维度表现出色，在GPT改写的对话数据集上显著优于特定领域基线。
            arXiv:2506.06737v1 Announce Type: new 
Abstract: Navigating healthcare systems can be complex and overwhelming, creating barriers for patients seeking timely and appropriate medical attention. In this paper, we introduce C-PATH (Conversational Patient Assistance and Triage in Healthcare), a novel conversational AI system powered by large language models (LLMs) designed to assist patients in recognizing symptoms and recommending appropriate medical departments through natural, multi-turn dialogues. C-PATH is fine-tuned on medical knowledge, dialogue data, and clinical summaries using a multi-stage pipeline built on the LLaMA3 architecture. A core contribution of this work is a GPT-based data augmentation framework that transforms structured clinical knowledge from DDXPlus into lay-person-friendly conversations, allowing alignment with patient communication norms. We also implement a scalable conversation history management strategy to ensure long-range coherence. Evaluation with GPTScore demonstrates strong performance across dimensions such as clarity, informativeness, and recommendation accuracy. Quantitative benchmarks show that C-PATH achieves superior performance in GPT-rewritten conversational datasets, significantly outperforming domain-specific baselines. C-PATH represents a step forward in the development of user-centric, accessible, and accurate AI tools for digital health assistance and triage.
        ]]></description>
    </item>
    <item>
        <title>Caterpillar GNN: Replacing Message Passing with Efficient Aggregation</title>
        <link>https://arxiv.org/abs/2506.06784</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06784v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Marek \v{C}ern\'y</dc:creator>
        <description><![CDATA[
            背景：当前消息传递图神经网络在图学习中占主导地位，通常追求最大表达能力。方法：本文引入“高效聚合”机制，牺牲部分表达能力以获得更强且更结构化的聚合能力，提出“Caterpillar GNN”，用广义“毛毛虫图”层次结构中的同态计数严格刻画中间步骤的表达能力。效果：该模型能成功处理专门为挑战经典消息传递图神经网络而设计的合成图级任务，在真实数据集上，预测性能相当，还显著减少计算图隐藏层的节点数量。
            arXiv:2506.06784v1 Announce Type: new 
Abstract: Message-passing graph neural networks (MPGNNs) dominate modern graph learning, typically prioritizing maximal expressive power. In contrast, we introduce an \emph{efficient aggregation} mechanism, deliberately trading off some expressivity for stronger and more structured aggregation capabilities. Our approach allows seamless scaling between classical message-passing and simpler methods based on colored or plain walks. We rigorously characterize the expressive power at each intermediate step using homomorphism counts from a hierarchy of generalized \emph{caterpillar graphs}. Based on this foundation, we propose the \emph{Caterpillar GNN}, whose robust graph-level aggregation enables it to successfully tackle synthetic graph-level task specifically designed to be challenging for classical MPGNNs. Moreover, we demonstrate that, on real-world datasets, the Caterpillar GNN achieves comparable predictive performance while significantly reducing the number of nodes in the hidden layers of the computational graph.
        ]]></description>
    </item>
    <item>
        <title>IMPA-HGAE:Intra-Meta-Path Augmented Heterogeneous Graph Autoencoder</title>
        <link>https://arxiv.org/abs/2506.06809</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06809v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Di Lin, Wanjing Ren, Xuanbin Li, Rui Zhang</dc:creator>
        <description><![CDATA[
            背景：自监督学习方法因泛化能力强、标注成本低被广泛应用于下游任务，但现有异质图自监督学习模型在转换异质图为同质图训练时，未充分利用元路径上的异质节点信息。方法：提出IMPA - HGAE框架，充分利用元路径上的内部节点信息增强目标节点嵌入，还引入创新的掩码策略。效果：实验表明IMPA - HGAE在异质数据集上表现优异，该研究为复杂图场景下的表征学习提供了思路。
            arXiv:2506.06809v1 Announce Type: new 
Abstract: Self-supervised learning (SSL) methods have been increasingly applied to diverse downstream tasks due to their superior generalization capabilities and low annotation costs. However, most existing heterogeneous graph SSL models convert heterogeneous graphs into homogeneous ones via meta-paths for training, which only leverage information from nodes at both ends of meta-paths while underutilizing the heterogeneous node information along the meta-paths. To address this limitation, this paper proposes a novel framework named IMPA-HGAE to enhance target node embeddings by fully exploiting internal node information along meta-paths. Experimental results validate that IMPA-HGAE achieves superior performance on heterogeneous datasets. Furthermore, this paper introduce innovative masking strategies to strengthen the representational capacity of generative SSL models on heterogeneous graph data. Additionally, this paper discuss the interpretability of the proposed method and potential future directions for generative self-supervised learning in heterogeneous graphs. This work provides insights into leveraging meta-path-guided structural semantics for robust representation learning in complex graph scenarios.
        ]]></description>
    </item>
    <item>
        <title>Harnessing Vision-Language Models for Time Series Anomaly Detection</title>
        <link>https://arxiv.org/abs/2506.06836</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06836v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zelin He, Sarah Alnegheimish, Matthew Reimherr</dc:creator>
        <description><![CDATA[
            时间序列异常检测在多领域至关重要，以往方法缺乏视觉 - 时间推理能力。为填补此空白，本文探索基于视觉语言模型（VLMs）的解决方案。提出两阶段方法，一是基于轻量级预训练视觉编码器的ViT4TS，利用二维时间序列表示定位候选异常；二是基于VLM的VLM4TS，整合全局时间上下文和VLM推理能力，在ViT4TS提供的候选异常上优化检测。结果显示，VLM4TS在多数情况下超越基线，F1 - max分数比最佳基线提高24.6%，还优于现有基于语言模型的方法，令牌使用效率平均高36倍。
            arXiv:2506.06836v1 Announce Type: new 
Abstract: Time-series anomaly detection (TSAD) has played a vital role in a variety of fields, including healthcare, finance, and industrial monitoring. Prior methods, which mainly focus on training domain-specific models on numerical data, lack the visual-temporal reasoning capacity that human experts have to identify contextual anomalies. To fill this gap, we explore a solution based on vision language models (VLMs). Recent studies have shown the ability of VLMs for visual reasoning tasks, yet their direct application to time series has fallen short on both accuracy and efficiency. To harness the power of VLMs for TSAD, we propose a two-stage solution, with (1) ViT4TS, a vision-screening stage built on a relatively lightweight pretrained vision encoder, which leverages 2-D time-series representations to accurately localize candidate anomalies; (2) VLM4TS, a VLM-based stage that integrates global temporal context and VLM reasoning capacity to refine the detection upon the candidates provided by ViT4TS. We show that without any time-series training, VLM4TS outperforms time-series pretrained and from-scratch baselines in most cases, yielding a 24.6 percent improvement in F1-max score over the best baseline. Moreover, VLM4TS also consistently outperforms existing language-model-based TSAD methods and is on average 36 times more efficient in token usage.
        ]]></description>
    </item>
    <item>
        <title>Vision-EKIPL: External Knowledge-Infused Policy Learning for Visual Reasoning</title>
        <link>https://arxiv.org/abs/2506.06856</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06856v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chaoyang Wang, Zeyu Zhang, Haiyun Jiang</dc:creator>
        <description><![CDATA[
            背景：视觉推理对理解复杂多模态数据和发展通用人工智能至关重要，现有强化学习微调方法存在局限。方法：提出Vision - EKIPL框架，在强化学习训练过程中引入外部辅助模型生成的高质量动作，引导策略模型优化。效果：显著扩大模型探索空间，有效提升推理边界，加速训练收敛。在Reason - RFT - CoT基准测试中，相比现有最优方法性能提升达5%，能显著增强多模态大语言模型的视觉推理能力。
            arXiv:2506.06856v1 Announce Type: new 
Abstract: Visual reasoning is crucial for understanding complex multimodal data and advancing Artificial General Intelligence. Existing methods enhance the reasoning capability of Multimodal Large Language Models (MLLMs) through Reinforcement Learning (RL) fine-tuning (e.g., GRPO). However, current RL approaches sample action groups solely from the policy model itself, which limits the upper boundary of the model's reasoning capability and leads to inefficient training. To address these limitations, this paper proposes a novel RL framework called \textbf{Vision-EKIPL}. The core of this framework lies in introducing high-quality actions generated by external auxiliary models during the RL training process to guide the optimization of the policy model. The policy learning with knowledge infusion from external models significantly expands the model's exploration space, effectively improves the reasoning boundary, and substantially accelerates training convergence speed and efficiency. Experimental results demonstrate that our proposed Vision-EKIPL achieved up to a 5\% performance improvement on the Reason-RFT-CoT Benchmark compared to the state-of-the-art (SOTA). It reveals that Vision-EKIPL can overcome the limitations of traditional RL methods, significantly enhance the visual reasoning performance of MLLMs, and provide a new effective paradigm for research in this field.
        ]]></description>
    </item>
    <item>
        <title>Basis Transformers for Multi-Task Tabular Regression</title>
        <link>https://arxiv.org/abs/2506.06926</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06926v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wei Min Loh, Jiaqi Shang, Pascal Poupart</dc:creator>
        <description><![CDATA[
            背景：处理表格数据存在挑战，现有技术难以同时解决表格数据的关键问题。方法：提出一种名为“基础变压器”的新型架构，该架构能尊重表格数据的固有不变性，包括层次结构和数值表示。效果：在多任务表格回归基准测试中，中位数 $R^2$ 得分提高了 0.338，在 OpenML - CTR23 基准的 34 个任务中标准差最低，且模型参数比最佳基线少五倍，即使随机初始化权重也能超越预训练大语言模型基线。
            arXiv:2506.06926v1 Announce Type: new 
Abstract: Dealing with tabular data is challenging due to partial information, noise, and heterogeneous structure. Existing techniques often struggle to simultaneously address key aspects of tabular data such as textual information, a variable number of columns, and unseen data without metadata besides column names. We propose a novel architecture, \textit{basis transformers}, specifically designed to tackle these challenges while respecting inherent invariances in tabular data, including hierarchical structure and the representation of numeric values. We evaluate our design on a multi-task tabular regression benchmark, achieving an improvement of 0.338 in the median $R^2$ score and the lowest standard deviation across 34 tasks from the OpenML-CTR23 benchmark. Furthermore, our model has five times fewer parameters than the best-performing baseline and surpasses pretrained large language model baselines -- even when initialized from randomized weights.
        ]]></description>
    </item>
    <item>
        <title>How Important are Videos for Training Video LLMs?</title>
        <link>https://arxiv.org/abs/2506.06928</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06928v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>George Lydakis, Alexander Hermans, Ali Athar, Daan de Geus, Bastian Leibe</dc:creator>
        <description><![CDATA[
            背景：视频大语言模型（LLMs）研究进展迅速，通常用预训练文本LLM初始化并在图像和视频字幕数据集上微调。方法：研究发现图像训练后的视频LLMs就有一定时间推理能力，视频特定训练提升小，还介绍了涉及带注释图像序列和针对时间能力问题的微调方案。效果：基于图像训练的两个用LongVU算法训练的LLMs在时间推理基准TVBench上表现显著高于随机水平，微调方案的时间推理性能接近甚至偶尔高于视频训练的LLMs。
            arXiv:2506.06928v1 Announce Type: new 
Abstract: Research into Video Large Language Models (LLMs) has progressed rapidly, with numerous models and benchmarks emerging in just a few years. Typically, these models are initialized with a pretrained text-only LLM and finetuned on both image- and video-caption datasets. In this paper, we present findings indicating that Video LLMs are more capable of temporal reasoning after image-only training than one would assume, and that improvements from video-specific training are surprisingly small. Specifically, we show that image-trained versions of two LLMs trained with the recent LongVU algorithm perform significantly above chance level on TVBench, a temporal reasoning benchmark. Additionally, we introduce a simple finetuning scheme involving sequences of annotated images and questions targeting temporal capabilities. This baseline results in temporal reasoning performance close to, and occasionally higher than, what is achieved by video-trained LLMs. This suggests suboptimal utilization of rich temporal features found in real video by current models. Our analysis motivates further research into the mechanisms that allow image-trained LLMs to perform temporal reasoning, as well as into the bottlenecks that render current video training schemes inefficient.
        ]]></description>
    </item>
    <item>
        <title>LaTtE-Flow: Layerwise Timestep-Expert Flow-based Transformer</title>
        <link>https://arxiv.org/abs/2506.06952</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06952v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ying Shen, Zhiyang Xu, Jiuhai Chen, Shizhe Diao, Jiaxin Zhang, Yuguang Yao, Joy Rimchala, Ismini Lourentzou, Lifu Huang</dc:creator>
        <description><![CDATA[
            背景：现有统一图像理解与生成的多模态基础模型需大量预训练，性能有限且图像生成速度慢。方法：提出基于分层时间步专家流的Transformer（LaTtE - Flow），依托预训练视觉语言模型，用分层时间步专家流架构实现高效图像生成，将流匹配过程分布在不同Transformer层组，还提出时间步条件残差注意力机制。效果：在多模态理解任务中表现出色，图像生成质量有竞争力，推理速度比近期统一多模态模型快约6倍。
            arXiv:2506.06952v1 Announce Type: new 
Abstract: Recent advances in multimodal foundation models unifying image understanding and generation have opened exciting avenues for tackling a wide range of vision-language tasks within a single framework. Despite progress, existing unified models typically require extensive pretraining and struggle to achieve the same level of performance compared to models dedicated to each task. Additionally, many of these models suffer from slow image generation speeds, limiting their practical deployment in real-time or resource-constrained settings. In this work, we propose Layerwise Timestep-Expert Flow-based Transformer (LaTtE-Flow), a novel and efficient architecture that unifies image understanding and generation within a single multimodal model. LaTtE-Flow builds upon powerful pretrained Vision-Language Models (VLMs) to inherit strong multimodal understanding capabilities, and extends them with a novel Layerwise Timestep Experts flow-based architecture for efficient image generation. LaTtE-Flow distributes the flow-matching process across specialized groups of Transformer layers, each responsible for a distinct subset of timesteps. This design significantly improves sampling efficiency by activating only a small subset of layers at each sampling timestep. To further enhance performance, we propose a Timestep-Conditioned Residual Attention mechanism for efficient information reuse across layers. Experiments demonstrate that LaTtE-Flow achieves strong performance on multimodal understanding tasks, while achieving competitive image generation quality with around 6x faster inference speed compared to recent unified multimodal models.
        ]]></description>
    </item>
    <item>
        <title>Break-The-Chain: Reasoning Failures in LLMs via Adversarial Prompting in Code Generation</title>
        <link>https://arxiv.org/abs/2506.06971</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06971v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jaechul Roh, Varun Gandhi, Shivani Anilkumar, Arin Garg</dc:creator>
        <description><![CDATA[
            背景：大语言模型在复杂推理任务中取得成功，但核心问题是其是否真正推理。方法：系统研究推理大语言模型的鲁棒性，引入一系列语义忠实但对抗性结构的提示扰动，对700个来自LeetCode风格问题的代码生成进行评估，应用多种变换。效果：部分修改严重降低性能，准确率最多下降42.1%，部分却使准确率最多提高35.3%，揭示了当前推理系统的脆弱性和不可预测性。
            arXiv:2506.06971v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have achieved remarkable success in tasks requiring complex reasoning, such as code generation, mathematical problem solving, and algorithmic synthesis -- especially when aided by reasoning tokens and Chain-of-Thought prompting. Yet, a core question remains: do these models truly reason, or do they merely exploit shallow statistical patterns? In this paper, we systematically investigate the robustness of reasoning LLMs by introducing a suite of semantically faithful yet adversarially structured prompt perturbations. Our evaluation -- spanning 700 perturbed code generations derived from LeetCode-style problems -- applies transformations such as storytelling reframing, irrelevant constraint injection, example reordering, and numeric perturbation. We observe that while certain modifications severely degrade performance (with accuracy drops up to -42.1%), others surprisingly improve model accuracy by up to 35.3%, suggesting sensitivity not only to semantics but also to surface-level prompt dynamics. These findings expose the fragility and unpredictability of current reasoning systems, underscoring the need for more principles approaches to reasoning alignments and prompting robustness. We release our perturbation datasets and evaluation framework to promote further research in trustworthy and resilient LLM reasoning.
        ]]></description>
    </item>
    <item>
        <title>Atomic Reasoning for Scientific Table Claim Verification</title>
        <link>https://arxiv.org/abs/2506.06972</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06972v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuji Zhang, Qingyun Wang, Cheng Qian, Jiateng Liu, Chenkai Sun, Denghui Zhang, Tarek Abdelzaher, Chengxiang Zhai, Preslav Nakov, Heng Ji</dc:creator>
        <description><![CDATA[
            背景：科学文本因技术语言和复杂数据易传播错误信息，现有表格声明验证模型在细粒度推理上存在不足。方法：受认知负荷理论启发，提出开发模块化、可复用的推理组件（原子技能）以降低认知负荷，引入技能链模式动态组合技能。效果：创建跨领域基准SciAtomicBench进行评估，仅用350个微调示例训练的原子推理模型，优于GPT - 4o的思维链方法，用更少训练数据取得了最优结果。
            arXiv:2506.06972v1 Announce Type: new 
Abstract: Scientific texts often convey authority due to their technical language and complex data. However, this complexity can sometimes lead to the spread of misinformation. Non-experts are particularly susceptible to misleading claims based on scientific tables due to their high information density and perceived credibility. Existing table claim verification models, including state-of-the-art large language models (LLMs), often struggle with precise fine-grained reasoning, resulting in errors and a lack of precision in verifying scientific claims. Inspired by Cognitive Load Theory, we propose that enhancing a model's ability to interpret table-based claims involves reducing cognitive load by developing modular, reusable reasoning components (i.e., atomic skills). We introduce a skill-chaining schema that dynamically composes these skills to facilitate more accurate and generalizable reasoning with a reduced cognitive load. To evaluate this, we create SciAtomicBench, a cross-domain benchmark with fine-grained reasoning annotations. With only 350 fine-tuning examples, our model trained by atomic reasoning outperforms GPT-4o's chain-of-thought method, achieving state-of-the-art results with far less training data.
        ]]></description>
    </item>
    <item>
        <title>Chain of Methodologies: Scaling Test Time Computation without Training</title>
        <link>https://arxiv.org/abs/2506.06982</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06982v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Cong Liu, Jie Wu, Weigang Wu, Xu Chen, Liang Lin, Wei-Shi Zheng</dc:creator>
        <description><![CDATA[
            背景：大语言模型因训练数据缺乏深度见解，处理复杂推理任务时存在困难。方法：本文提出方法链（CoM）这一创新提示框架，通过整合人类方法学见解增强结构化思维，利用高级大语言模型的元认知能力，无需显式微调，通过用户定义的方法激活系统推理。效果：实验表明，CoM超越了对比基线，显示出无训练提示方法作为复杂推理任务解决方案的潜力，有助于缩小与人类水平推理的差距。
            arXiv:2506.06982v1 Announce Type: new 
Abstract: Large Language Models (LLMs) often struggle with complex reasoning tasks due to insufficient in-depth insights in their training data, which are typically absent in publicly available documents. This paper introduces the Chain of Methodologies (CoM), an innovative and intuitive prompting framework that enhances structured thinking by integrating human methodological insights, enabling LLMs to tackle complex tasks with extended reasoning. CoM leverages the metacognitive abilities of advanced LLMs, activating systematic reasoning throught user-defined methodologies without explicit fine-tuning. Experiments show that CoM surpasses competitive baselines, demonstrating the potential of training-free prompting methods as robust solutions for complex reasoning tasks and bridging the gap toward human-level reasoning through human-like methodological insights.
        ]]></description>
    </item>
    <item>
        <title>What makes Reasoning Models Different? Follow the Reasoning Leader for Efficient Decoding</title>
        <link>https://arxiv.org/abs/2506.06998</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06998v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ming Li, Zhengyuan Yang, Xiyao Wang, Dianqi Li, Kevin Lin, Tianyi Zhou, Lijuan Wang</dc:creator>
        <description><![CDATA[
            背景：大推理模型（LRMs）通过发出长思维链实现强推理性能，但存在推理冗长、过思考等问题。方法：系统分析推理和非推理模型的标记级不对齐现象，基于局部不对齐减少现象，提出FoReaL - Decoding协作式快慢思考解码方法，用引导模型引导句子开头，草稿模型完成后续。效果：在四个数学推理基准测试中，该方法理论FLOPs减少30% - 50%，CoT长度最多缩减40%，同时保留86% - 100%的模型性能。
            arXiv:2506.06998v1 Announce Type: new 
Abstract: Large reasoning models (LRMs) achieve strong reasoning performance by emitting long chains of thought. Yet, these verbose traces slow down inference and often drift into unnecessary detail, known as the overthinking phenomenon. To better understand LRMs' behavior, we systematically analyze the token-level misalignment between reasoning and non-reasoning models. While it is expected that their primary difference lies in the stylistic "thinking cues", LRMs uniquely exhibit two pivotal, previously under-explored phenomena: a Global Misalignment Rebound, where their divergence from non-reasoning models persists or even grows as response length increases, and more critically, a Local Misalignment Diminish, where the misalignment concentrates at the "thinking cues" each sentence starts with but rapidly declines in the remaining of the sentence. Motivated by the Local Misalignment Diminish, we propose FoReaL-Decoding, a collaborative fast-slow thinking decoding method for cost-quality trade-off. In FoReaL-Decoding, a Leading model leads the first few tokens for each sentence, and then a weaker draft model completes the following tokens to the end of each sentence. FoReaL-Decoding adopts a stochastic gate to smoothly interpolate between the small and the large model. On four popular math-reasoning benchmarks (AIME24, GPQA-Diamond, MATH500, AMC23), FoReaL-Decoding reduces theoretical FLOPs by 30 to 50% and trims CoT length by up to 40%, while preserving 86 to 100% of model performance. These results establish FoReaL-Decoding as a simple, plug-and-play route to controllable cost-quality trade-offs in reasoning-centric tasks.
        ]]></description>
    </item>
    <item>
        <title>KG2QA: Knowledge Graph-enhanced Retrieval-Augmented Generation for Communication Standards Question Answering</title>
        <link>https://arxiv.org/abs/2506.07037</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07037v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhongze Luo, Weixuan Wan, Qizhi Zheng, Yanhong Bai, Jingyun Sun, Jian Wang, Dan Wang</dc:creator>
        <description><![CDATA[
            背景：通信领域标准类型多，传统咨询模式周期长、依赖专家，难以满足技术发展需求。方法：结合大语言模型微调与知识图谱构建，实现通信标准智能咨询问答系统，在通信标准问答数据集上进行LoRA调优，构建通信标准领域知识图谱。效果：Qwen2.5 - 7B - Instruct在测试集表现出色，BLEU - 4等指标显著提升，知识图谱查询准确率较好，RAG框架使模型平均得分提高2.26%，且在交互和后端访问方面效果佳。
            arXiv:2506.07037v1 Announce Type: new 
Abstract: There are many types of standards in the field of communication. The traditional consulting model has a long cycle and relies on the knowledge and experience of experts, making it difficult to meet the rapidly developing technological demands. This paper combines the fine-tuning of large language models with the construction of knowledge graphs to implement an intelligent consultation and question-answering system for communication standards. The experimental results show that after LoRA tuning on the constructed dataset of 6,587 questions and answers in the field of communication standards, Qwen2.5-7B-Instruct demonstrates outstanding professional capabilities in the field of communication standards on the test set. BLEU-4 rose from 18.8564 to 66.8993, and evaluation indicators such as ROUGE also increased significantly, outperforming the fine-tuning effect of the comparison model Llama-3-8B-Instruct. Based on the ontology framework containing 6 entity attributes and 10 relation attributes, a knowledge graph of the communication standard domain containing 13,906 entities and 13,524 relations was constructed, showing a relatively good query accuracy rate. The intelligent consultation and question-answering system enables the fine-tuned model on the server side to access the locally constructed knowledge graph and conduct graphical retrieval of key information first, which is conducive to improving the question-answering effect. The evaluation using DeepSeek as the Judge on the test set shows that our RAG framework enables the fine-tuned model to improve the scores at all five angles, with an average score increase of 2.26%. And combined with web services and API interfaces, it has achieved very good results in terms of interaction experience and back-end access, and has very good practical application value.
        ]]></description>
    </item>
    <item>
        <title>Reasoning with RAGged events: RAG-Enhanced Event Knowledge Base Construction and reasoning with proof-assistants</title>
        <link>https://arxiv.org/abs/2506.07042</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07042v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Stergios Chatzikyriakidis</dc:creator>
        <description><![CDATA[
            从叙述文本中手动构建历史事件的结构化计算表示成本高，且RDF/OWL推理器在深层时空和语义分析上受限。本文用多个大语言模型（GPT - 4、Claude、Llama 3.2）结合纯基础生成、知识图谱增强和RAG三种策略开发自动历史事件提取模型。实验表明，不同策略在不同性能维度有优化效果，RAG增强能提高精度。还开发自动化翻译流程，将提取的RDF表示转换为Coq证明助手规范，实现高阶推理，验证了RAG发现的事件类型的合理性。
            arXiv:2506.07042v1 Announce Type: new 
Abstract: Extracting structured computational representations of historical events from narrative text remains computationally expensive when constructed manually. While RDF/OWL reasoners enable graph-based reasoning, they are limited to fragments of first-order logic, preventing deeper temporal and semantic analysis. This paper addresses both challenges by developing automatic historical event extraction models using multiple LLMs (GPT-4, Claude, Llama 3.2) with three enhancement strategies: pure base generation, knowledge graph enhancement, and Retrieval-Augmented Generation (RAG). We conducted comprehensive evaluations using historical texts from Thucydides. Our findings reveal that enhancement strategies optimize different performance dimensions rather than providing universal improvements. For coverage and historical breadth, base generation achieves optimal performance with Claude and GPT-4 extracting comprehensive events. However, for precision, RAG enhancement improves coordinate accuracy and metadata completeness. Model architecture fundamentally determines enhancement sensitivity: larger models demonstrate robust baseline performance with incremental RAG improvements, while Llama 3.2 shows extreme variance from competitive performance to complete failure. We then developed an automated translation pipeline converting extracted RDF representations into Coq proof assistant specifications, enabling higher-order reasoning beyond RDF capabilities including multi-step causal verification, temporal arithmetic with BC dates, and formal proofs about historical causation. The Coq formalization validates that RAG-discovered event types represent legitimate domain-specific semantic structures rather than ontological violations.
        ]]></description>
    </item>
    <item>
        <title>Lingshu: A Generalist Foundation Model for Unified Multimodal Medical Understanding and Reasoning</title>
        <link>https://arxiv.org/abs/2506.07044</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07044v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>LASA Team, Weiwen Xu, Hou Pong Chan, Long Li, Mahani Aljunied, Ruifeng Yuan, Jianyu Wang, Chenghao Xiao, Guizhen Chen, Chaoqun Liu, Zhaodonghui Li, Yu Sun, Junao Shen, Chaojun Wang, Jie Tan, Deli Zhao, Tingyang Xu, Hao Zhang, Yu Rong</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型在医学应用中效果有限，现有医学模型存在知识覆盖不足、易产生幻觉、缺乏复杂场景推理能力等问题。方法：提出全面的数据整理程序，构建富含医学知识的多模态数据集，在此基础上推出医学专用模型Lingshu，进行多阶段训练，并探索用强化学习提升其推理能力，还开发统一评估框架。效果：Lingshu在多模态问答等三项医学任务中多数表现优于现有开源多模态模型。
            arXiv:2506.07044v1 Announce Type: new 
Abstract: Multimodal Large Language Models (MLLMs) have demonstrated impressive capabilities in understanding common visual elements, largely due to their large-scale datasets and advanced training strategies. However, their effectiveness in medical applications remains limited due to the inherent discrepancies between data and tasks in medical scenarios and those in the general domain. Concretely, existing medical MLLMs face the following critical limitations: (1) limited coverage of medical knowledge beyond imaging, (2) heightened susceptibility to hallucinations due to suboptimal data curation processes, (3) lack of reasoning capabilities tailored for complex medical scenarios. To address these challenges, we first propose a comprehensive data curation procedure that (1) efficiently acquires rich medical knowledge data not only from medical imaging but also from extensive medical texts and general-domain data; and (2) synthesizes accurate medical captions, visual question answering (VQA), and reasoning samples. As a result, we build a multimodal dataset enriched with extensive medical knowledge. Building on the curated data, we introduce our medical-specialized MLLM: Lingshu. Lingshu undergoes multi-stage training to embed medical expertise and enhance its task-solving capabilities progressively. Besides, we preliminarily explore the potential of applying reinforcement learning with verifiable rewards paradigm to enhance Lingshu's medical reasoning ability. Additionally, we develop MedEvalKit, a unified evaluation framework that consolidates leading multimodal and textual medical benchmarks for standardized, fair, and efficient model assessment. We evaluate the performance of Lingshu on three fundamental medical tasks, multimodal QA, text-based QA, and medical report generation. The results show that Lingshu consistently outperforms the existing open-source multimodal models on most tasks ...
        ]]></description>
    </item>
    <item>
        <title>Com$^2$: A Causal-Guided Benchmark for Exploring Complex Commonsense Reasoning in Large Language Models</title>
        <link>https://arxiv.org/abs/2506.07064</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07064v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kai Xiong, Xiao Ding, Yixin Cao, Yuxiong Yan, Li Du, Yufei Zhang, Jinglong Gao, Jiaqian Liu, Bing Qin, Ting Liu</dc:creator>
        <description><![CDATA[
            背景：大语言模型虽掌握简单常识知识，但在复杂隐式常识推理上表现不佳，且相关研究较少。方法：提出聚焦复杂常识推理的基准Com$^2$，引入因果事件图作为结构化复杂常识，用因果理论修改图以获不同场景，让大语言模型依据修改后图的逻辑关系合成示例，还用侦探故事构建更具挑战性子集。效果：实验表明大语言模型在推理深度和广度上有困难，后训练和慢思考可缓解，代码和数据已开源。
            arXiv:2506.07064v1 Announce Type: new 
Abstract: Large language models (LLMs) have mastered abundant simple and explicit commonsense knowledge through pre-training, enabling them to achieve human-like performance in simple commonsense reasoning. Nevertheless, LLMs struggle to reason with complex and implicit commonsense knowledge that is derived from simple ones (such as understanding the long-term effects of certain events), an aspect humans tend to focus on more. Existing works focus on complex tasks like math and code, while complex commonsense reasoning remains underexplored due to its uncertainty and lack of structure. To fill this gap and align with real-world concerns, we propose a benchmark Com$^2$ focusing on complex commonsense reasoning. We first incorporate causal event graphs to serve as structured complex commonsense. Then we adopt causal theory~(e.g., intervention) to modify the causal event graphs and obtain different scenarios that meet human concerns. Finally, an LLM is employed to synthesize examples with slow thinking, which is guided by the logical relationships in the modified causal graphs. Furthermore, we use detective stories to construct a more challenging subset. Experiments show that LLMs struggle in reasoning depth and breadth, while post-training and slow thinking can alleviate this. The code and data are available at https://github.com/Waste-Wood/Com2.
        ]]></description>
    </item>
    <item>
        <title>How Far Are We from Optimal Reasoning Efficiency?</title>
        <link>https://arxiv.org/abs/2506.07104</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07104v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiaxuan Gao, Shu Yan, Qixin Tan, Lu Yang, Shusheng Xu, Wei Fu, Zhiyu Mei, Kaifeng Lyu, Yi Wu</dc:creator>
        <description><![CDATA[
            背景：大推理模型（LRMs）通过思维链推理有强大解题能力，但推理过程冗长冗余，现有微调方法难以评估效率提升。方法：引入推理效率前沿，提出推理效率差距（REG）指标，还提出REO - RL强化学习算法以缩小效率差距。效果：REG能有效衡量准确率与长度的权衡，REO - RL在所有评估的LRMs中使REG降低超50，在16K令牌预算下匹配Qwen3 - 4B/8B效率前沿且准确率损失极小。
            arXiv:2506.07104v1 Announce Type: new 
Abstract: Large Reasoning Models (LRMs) demonstrate remarkable problem-solving capabilities through extended Chain-of-Thought (CoT) reasoning but often produce excessively verbose and redundant reasoning traces. This inefficiency incurs high inference costs and limits practical deployment. While existing fine-tuning methods aim to improve reasoning efficiency, assessing their efficiency gains remains challenging due to inconsistent evaluations. In this work, we introduce the reasoning efficiency frontiers, empirical upper bounds derived from fine-tuning base LRMs across diverse approaches and training configurations. Based on these frontiers, we propose the Reasoning Efficiency Gap (REG), a unified metric quantifying deviations of any fine-tuned LRMs from these frontiers. Systematic evaluation on challenging mathematical benchmarks reveals significant gaps in current methods: they either sacrifice accuracy for short length or still remain inefficient under tight token budgets. To reduce the efficiency gap, we propose REO-RL, a class of Reinforcement Learning algorithms that minimizes REG by targeting a sparse set of token budgets. Leveraging numerical integration over strategically selected budgets, REO-RL approximates the full efficiency objective with low error using a small set of token budgets. Through systematic benchmarking, we demonstrate that our efficiency metric, REG, effectively captures the accuracy-length trade-off, with low-REG methods reducing length while maintaining accuracy. Our approach, REO-RL, consistently reduces REG by >=50 across all evaluated LRMs and matching Qwen3-4B/8B efficiency frontiers under a 16K token budget with minimal accuracy loss. Ablation studies confirm the effectiveness of our exponential token budget strategy. Finally, our findings highlight that fine-tuning LRMs to perfectly align with the efficiency frontiers remains an open challenge.
        ]]></description>
    </item>
    <item>
        <title>Theorem-of-Thought: A Multi-Agent Framework for Abductive, Deductive, and Inductive Reasoning in Language Models</title>
        <link>https://arxiv.org/abs/2506.07106</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07106v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Samir Abdaljalil, Hasan Kurban, Khalid Qaraqe, Erchin Serpedin</dc:creator>
        <description><![CDATA[
            背景：大语言模型在自然语言推理任务中表现出色，但推理过程脆弱且难以解释，现有提示技术缺乏逻辑结构和内部一致性评估机制。方法：提出定理思维（ToTh）框架，将推理建模为三个模拟不同推理模式的并行智能体协作，生成推理轨迹并构建形式推理图，用自然语言推理引导的贝叶斯信念传播评估一致性。效果：在符号和数值推理基准测试中，ToTh始终优于其他方法，能产生可解释且逻辑合理的推理链。
            arXiv:2506.07106v1 Announce Type: new 
Abstract: Large language models (LLMs) have shown strong performance across natural language reasoning tasks, yet their reasoning processes remain brittle and difficult to interpret. Prompting techniques like Chain-of-Thought (CoT) enhance reliability by eliciting intermediate reasoning steps or aggregating multiple outputs. However, they lack mechanisms for enforcing logical structure and assessing internal coherence. We introduce Theorem-of-Thought (ToTh), a novel framework that models reasoning as collaboration among three parallel agents, each simulating a distinct mode of inference: abductive, deductive, and inductive. Each agent produces a reasoning trace, which is structured into a formal reasoning graph. To evaluate consistency, we apply Bayesian belief propagation guided by natural language inference (NLI), assigning confidence scores to each step. The most coherent graph is selected to derive the final answer. Experiments on symbolic (WebOfLies) and numerical (MultiArith) reasoning benchmarks show that ToTh consistently outperforms CoT, Self-Consistency, and CoT-Decoding across multiple LLMs, while producing interpretable and logically grounded reasoning chains. Our findings suggest a promising direction for building more robust and cognitively inspired LLM reasoning. The implementation is available at https://github.com/KurbanIntelligenceLab/theorem-of-thought.
        ]]></description>
    </item>
    <item>
        <title>Prompting Science Report 2: The Decreasing Value of Chain of Thought in Prompting</title>
        <link>https://arxiv.org/abs/2506.07142</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07142v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Lennart Meincke, Ethan Mollick, Lilach Mollick, Dan Shapiro</dc:creator>
        <description><![CDATA[
            背景：思维链（CoT）提示是提升大语言模型推理能力的常用方法。方法：该报告通过严格测试，研究CoT提示在不同类型任务和模型中的效果。效果：对于非推理模型，CoT能小幅提升平均性能，但会增加答案的变异性，还会增加成本和时间；许多新模型即使未被要求也会进行一定的CoT推理，此时CoT提示作用不大；对于有显式推理能力的模型，CoT提示对答案准确性提升有限，却显著增加生成响应的时间和所需令牌数。 
            arXiv:2506.07142v1 Announce Type: new 
Abstract: This is the second in a series of short reports that seek to help business, education, and policy leaders understand the technical details of working with AI through rigorous testing. In this report, we investigate Chain-of-Thought (CoT) prompting, a technique that encourages a large language model (LLM) to "think step by step" (Wei et al., 2022). CoT is a widely adopted method for improving reasoning tasks, however, our findings reveal a more nuanced picture of its effectiveness. We demonstrate two things:
  - The effectiveness of Chain-of-Thought prompting can vary greatly depending on the type of task and model. For non-reasoning models, CoT generally improves average performance by a small amount, particularly if the model does not inherently engage in step-by-step processing by default. However, CoT can introduce more variability in answers, sometimes triggering occasional errors in questions the model would otherwise get right. We also found that many recent models perform some form of CoT reasoning even if not asked; for these models, a request to perform CoT had little impact. Performing CoT generally requires far more tokens (increasing cost and time) than direct answers.
  - For models designed with explicit reasoning capabilities, CoT prompting often results in only marginal, if any, gains in answer accuracy. However, it significantly increases the time and tokens needed to generate a response.
        ]]></description>
    </item>
    <item>
        <title>GeometryZero: Improving Geometry Solving for LLM with Group Contrastive Policy Optimization</title>
        <link>https://arxiv.org/abs/2506.07160</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07160v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yikun Wang, Yibin Wang, Dianyi Wang, Zimian Peng, Qipeng Guo, Dacheng Tao, Jiaqi Wang</dc:creator>
        <description><![CDATA[
            背景：大语言模型在数学推理领域有进展，但几何问题求解仍具挑战，现有方法存在性能不佳或计算成本高的问题。方法：提出Group Contrastive Policy Optimization（GCPO）强化学习框架，包括基于上下文效用提供奖励信号的Group Contrastive Masking和促进更长推理链的长度奖励，基于此开发GeometryZero几何推理模型。效果：在多个几何基准测试中，GeometryZero模型平均比基线提升4.29%。
            arXiv:2506.07160v1 Announce Type: new 
Abstract: Recent advances in large language models (LLMs) have demonstrated remarkable capabilities across diverse domains, particularly in mathematical reasoning, amid which geometry problem solving remains a challenging area where auxiliary construction plays a enssential role. Existing approaches either achieve suboptimal performance or rely on massive LLMs (e.g., GPT-4o), incurring massive computational costs. We posit that reinforcement learning with verifiable reward (e.g., GRPO) offers a promising direction for training smaller models that effectively combine auxiliary construction with robust geometric reasoning. However, directly applying GRPO to geometric reasoning presents fundamental limitations due to its dependence on unconditional rewards, which leads to indiscriminate and counterproductive auxiliary constructions. To address these challenges, we propose Group Contrastive Policy Optimization (GCPO), a novel reinforcement learning framework featuring two key innovations: (1) Group Contrastive Masking, which adaptively provides positive or negative reward signals for auxiliary construction based on contextual utility, and a (2) length reward that promotes longer reasoning chains. Building on GCPO, we develop GeometryZero, a family of affordable-size geometric reasoning models that judiciously determine when to employ auxiliary construction. Our extensive empirical evaluation across popular geometric benchmarks (Geometry3K, MathVista) demonstrates that GeometryZero models consistently outperform baselines (e.g. GRPO), achieving an average improvement of 4.29% across all benchmarks.
        ]]></description>
    </item>
    <item>
        <title>Efficient Text-Attributed Graph Learning through Selective Annotation and Graph Alignment</title>
        <link>https://arxiv.org/abs/2506.07168</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07168v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Huanyi Xie, Lijie Hu, Lu Yu, Tianhao Huang, Longfei Li, Meng Li, Jun Zhou, Huan Wang, Di Wang</dc:creator>
        <description><![CDATA[
            在文本属性图（TAGs）领域，传统图神经网络因节点复杂文本信息而表现不佳，现有利用大语言模型（LLMs）的方法需大量注释或微调，耗时且成本高。为此，研究人员提出高效框架GAGA。该框架仅对代表性节点和边注释以降低时间和成本，构建注释图捕捉拓扑关系，还采用两级对齐模块将注释图与TAG有效集成。实验表明，GAGA只需注释1%的数据，分类准确率就与或超现有最优方法，效率高。
            arXiv:2506.07168v1 Announce Type: new 
Abstract: In the realm of Text-attributed Graphs (TAGs), traditional graph neural networks (GNNs) often fall short due to the complex textual information associated with each node. Recent methods have improved node representations by leveraging large language models (LLMs) to enhance node text features, but these approaches typically require extensive annotations or fine-tuning across all nodes, which is both time-consuming and costly. To overcome these challenges, we introduce GAGA, an efficient framework for TAG representation learning. GAGA reduces annotation time and cost by focusing on annotating only representative nodes and edges. It constructs an annotation graph that captures the topological relationships among these annotations. Furthermore, GAGA employs a two-level alignment module to effectively integrate the annotation graph with the TAG, aligning their underlying structures. Experiments show that GAGA achieves classification accuracies on par with or surpassing state-of-the-art methods while requiring only 1% of the data to be annotated, demonstrating its high efficiency.
        ]]></description>
    </item>
    <item>
        <title>Regularized Adaptive Graph Learning for Large-Scale Traffic Forecasting</title>
        <link>https://arxiv.org/abs/2506.07179</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07179v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kaiqi Wu, Weiyang Kong, Sen Zhang, Yubao Liu, Zitong Chen</dc:creator>
        <description><![CDATA[
            背景：交通预测是时空预测中的关键任务，现有自适应图学习方法存在忽略节点嵌入正则化或图卷积操作可扩展性差等问题。方法：提出正则化自适应图学习（RAGL）模型，引入正则化自适应图学习框架，通过残差差分机制协同随机共享嵌入（SSE）和自适应图卷积；开发高效余弦算子（ECO）以确保在大型道路网络上的可扩展性。效果：在四个大规模真实交通数据集上，RAGL预测精度超现有方法，计算效率有竞争力。
            arXiv:2506.07179v1 Announce Type: new 
Abstract: Traffic prediction is a critical task in spatial-temporal forecasting with broad applications in travel planning and urban management. Adaptive graph convolution networks have emerged as mainstream solutions due to their ability to learn node embeddings in a data-driven manner and capture complex latent dependencies. However, existing adaptive graph learning methods for traffic forecasting often either ignore the regularization of node embeddings, which account for a significant proportion of model parameters, or face scalability issues from expensive graph convolution operations. To address these challenges, we propose a Regularized Adaptive Graph Learning (RAGL) model. First, we introduce a regularized adaptive graph learning framework that synergizes Stochastic Shared Embedding (SSE) and adaptive graph convolution via a residual difference mechanism, achieving both embedding regularization and noise suppression. Second, to ensure scalability on large road networks, we develop the Efficient Cosine Operator (ECO), which performs graph convolution based on the cosine similarity of regularized embeddings with linear time complexity. Extensive experiments on four large-scale real-world traffic datasets show that RAGL consistently outperforms state-of-the-art methods in terms of prediction accuracy and exhibits competitive computational efficiency.
        ]]></description>
    </item>
    <item>
        <title>Learning based on neurovectors for tabular data: a new neural network approach</title>
        <link>https://arxiv.org/abs/2506.07185</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07185v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>J. C. Husillos, A. Gallego, A. Roma, A. Troncoso</dc:creator>
        <description><![CDATA[
            背景：传统人工神经网络依靠反向传播调整权重，存在一定局限性。方法：提出基于神经向量的新型学习方法，通过相互连接的节点和向量关系构建信息，在向量空间中构建数据来编码信息，以能量传播驱动学习过程，用神经向量生成动态知识表示。效果：提高了预测模型的可解释性和效率，在分类和回归任务中，与标准机器学习和深度学习模型对比，神经向量取得了有竞争力的准确率。
            arXiv:2506.07185v1 Announce Type: new 
Abstract: In this paper, we present a novel learning approach based on Neurovectors, an innovative paradigm that structures information through interconnected nodes and vector relationships for tabular data processing. Unlike traditional artificial neural networks that rely on weight adjustment through backpropagation, Neurovectors encode information by structuring data in vector spaces where energy propagation, rather than traditional weight updates, drives the learning process, enabling a more adaptable and explainable learning process. Our method generates dynamic representations of knowledge through neurovectors, thereby improving both the interpretability and efficiency of the predictive model. Experimental results using datasets from well-established repositories such as the UCI machine learning repository and Kaggle are reported both for classification and regression. To evaluate its performance, we compare our approach with standard machine learning and deep learning models, showing that Neurovectors achieve competitive accuracy.
        ]]></description>
    </item>
    <item>
        <title>SAP-Bench: Benchmarking Multimodal Large Language Models in Surgical Action Planning</title>
        <link>https://arxiv.org/abs/2506.07196</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07196v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mengya Xu, Zhongzhen Huang, Dillan Imans, Yiru Ye, Xiaofan Zhang, Qi Dou</dc:creator>
        <description><![CDATA[
            背景：有效评估对推动多模态大语言模型（MLLM）研究进步至关重要，现有基准难以充分评估手术动作规划（SAP）任务所需能力。方法：引入SAP - Bench大规模高质量数据集，源自胆囊切除术，有时间关联的手术动作注释；提出MLLM - SAP框架，利用MLLM结合自然语言指令和手术领域知识生成动作建议。效果：评估7种先进MLLM，揭示其在预测下一动作性能上存在关键差距。
            arXiv:2506.07196v1 Announce Type: new 
Abstract: Effective evaluation is critical for driving advancements in MLLM research. The surgical action planning (SAP) task, which aims to generate future action sequences from visual inputs, demands precise and sophisticated analytical capabilities. Unlike mathematical reasoning, surgical decision-making operates in life-critical domains and requires meticulous, verifiable processes to ensure reliability and patient safety. This task demands the ability to distinguish between atomic visual actions and coordinate complex, long-horizon procedures, capabilities that are inadequately evaluated by current benchmarks. To address this gap, we introduce SAP-Bench, a large-scale, high-quality dataset designed to enable multimodal large language models (MLLMs) to perform interpretable surgical action planning. Our SAP-Bench benchmark, derived from the cholecystectomy procedures context with the mean duration of 1137.5s, and introduces temporally-grounded surgical action annotations, comprising the 1,226 clinically validated action clips (mean duration: 68.7s) capturing five fundamental surgical actions across 74 procedures. The dataset provides 1,152 strategically sampled current frames, each paired with the corresponding next action as multimodal analysis anchors. We propose the MLLM-SAP framework that leverages MLLMs to generate next action recommendations from the current surgical scene and natural language instructions, enhanced with injected surgical domain knowledge. To assess our dataset's effectiveness and the broader capabilities of current models, we evaluate seven state-of-the-art MLLMs (e.g., OpenAI-o1, GPT-4o, QwenVL2.5-72B, Claude-3.5-Sonnet, GeminiPro2.5, Step-1o, and GLM-4v) and reveal critical gaps in next action prediction performance.
        ]]></description>
    </item>
    <item>
        <title>GGBall: Graph Generative Model on Poincar\'e Ball</title>
        <link>https://arxiv.org/abs/2506.07198</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07198v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tianci Bu, Chuanrui Wang, Hao Ma, Haoren Zheng, Xin Lu, Tailin Wu</dc:creator>
        <description><![CDATA[
            由于欧几里得几何在捕捉指数复杂性方面的局限，生成具有层次结构的图仍是一项基础挑战。本文提出了一种新的双曲图生成框架GGBall，它将几何归纳偏置与现代生成范式相结合。该框架结合了双曲向量量化自编码器和通过闭式测地线定义的黎曼流匹配先验，还开发了一套完全在流形内操作的双曲GNN和Transformer层。实验表明，与现有基线相比，该模型在Community - Small和Ego - Small上分别将度MMD降低了75%和40%以上，能更好地保留拓扑层次结构。
            arXiv:2506.07198v1 Announce Type: new 
Abstract: Generating graphs with hierarchical structures remains a fundamental challenge due to the limitations of Euclidean geometry in capturing exponential complexity. Here we introduce \textbf{GGBall}, a novel hyperbolic framework for graph generation that integrates geometric inductive biases with modern generative paradigms. GGBall combines a Hyperbolic Vector-Quantized Autoencoder (HVQVAE) with a Riemannian flow matching prior defined via closed-form geodesics. This design enables flow-based priors to model complex latent distributions, while vector quantization helps preserve the curvature-aware structure of the hyperbolic space. We further develop a suite of hyperbolic GNN and Transformer layers that operate entirely within the manifold, ensuring stability and scalability. Empirically, our model reduces degree MMD by over 75\% on Community-Small and over 40\% on Ego-Small compared to state-of-the-art baselines, demonstrating an improved ability to preserve topological hierarchies. These results highlight the potential of hyperbolic geometry as a powerful foundation for the generative modeling of complex, structured, and hierarchical data domains. Our code is available at \href{https://github.com/AI4Science-WestlakeU/GGBall}{here}.
        ]]></description>
    </item>
    <item>
        <title>Backdoor Attack on Vision Language Models with Stealthy Semantic Manipulation</title>
        <link>https://arxiv.org/abs/2506.07214</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07214v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhiyuan Zhong, Zhen Sun, Yepang Liu, Xinlei He, Guanhong Tao</dc:creator>
        <description><![CDATA[
            背景：视觉语言模型（VLMs）虽性能出色，但易受后门攻击，此前攻击多依赖单模态触发器，未充分探索跨模态融合特性。方法：提出BadSem数据投毒攻击，利用跨模态语义不匹配作为隐式触发器，通过故意错配图像 - 文本对注入后门，还构建了用于语义操纵的数据集SIMBad。效果：在四个常用VLMs上平均攻击成功率超98%，泛化性好且能跨投毒模态转移，同时发现现有两种防御策略无法缓解语义后门攻击。
            arXiv:2506.07214v1 Announce Type: new 
Abstract: Vision Language Models (VLMs) have shown remarkable performance, but are also vulnerable to backdoor attacks whereby the adversary can manipulate the model's outputs through hidden triggers. Prior attacks primarily rely on single-modality triggers, leaving the crucial cross-modal fusion nature of VLMs largely unexplored. Unlike prior work, we identify a novel attack surface that leverages cross-modal semantic mismatches as implicit triggers. Based on this insight, we propose BadSem (Backdoor Attack with Semantic Manipulation), a data poisoning attack that injects stealthy backdoors by deliberately misaligning image-text pairs during training. To perform the attack, we construct SIMBad, a dataset tailored for semantic manipulation involving color and object attributes. Extensive experiments across four widely used VLMs show that BadSem achieves over 98% average ASR, generalizes well to out-of-distribution datasets, and can transfer across poisoning modalities. Our detailed analysis using attention visualization shows that backdoored models focus on semantically sensitive regions under mismatched conditions while maintaining normal behavior on clean inputs. To mitigate the attack, we try two defense strategies based on system prompt and supervised fine-tuning but find that both of them fail to mitigate the semantic backdoor. Our findings highlight the urgent need to address semantic vulnerabilities in VLMs for their safer deployment.
        ]]></description>
    </item>
    <item>
        <title>Multi-Step Visual Reasoning with Visual Tokens Scaling and Verification</title>
        <link>https://arxiv.org/abs/2506.07235</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07235v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tianyi Bai, Zengjie Hu, Fupeng Sun, Jiantao Qiu, Yizhen Jiang, Guangxin He, Bohan Zeng, Conghui He, Binhang Yuan, Wentao Zhang</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型虽有显著能力，但大多采用静态推理范式，限制了迭代理解与适应上下文的能力，与人的动态感知形成对比。方法：引入推理时视觉标记缩放的新框架，将问题建模为马尔可夫决策过程，包含提出视觉动作的推理器和通过多步直接偏好优化训练的验证器，还提供新数据集VTS。效果：在各种视觉推理基准测试中显著优于现有方法，不仅提高准确性，还使推理过程更具可解释性和依据。
            arXiv:2506.07235v1 Announce Type: new 
Abstract: Multi-modal large language models (MLLMs) have achieved remarkable capabilities by integrating visual perception with language understanding, enabling applications such as image-grounded dialogue, visual question answering, and scientific analysis. However, most MLLMs adopt a static inference paradigm, encoding the entire image into fixed visual tokens upfront, which limits their ability to iteratively refine understanding or adapt to context during inference. This contrasts sharply with human perception, which is dynamic, selective, and feedback-driven. In this work, we introduce a novel framework for inference-time visual token scaling that enables MLLMs to perform iterative, verifier-guided reasoning over visual content. We formulate the problem as a Markov Decision Process, involving a reasoner that proposes visual actions and a verifier, which is trained via multi-step Direct Preference Optimization (DPO), that evaluates these actions and determines when reasoning should terminate. To support this, we present a new dataset, VTS, comprising supervised reasoning trajectories (VTS-SFT) and preference-labeled reasoning comparisons (VTS-DPO). Our method significantly outperforms existing approaches across diverse visual reasoning benchmarks, offering not only improved accuracy but also more interpretable and grounded reasoning processes. These results demonstrate the promise of dynamic inference mechanisms for enabling fine-grained, context-aware visual reasoning in next-generation MLLMs.
        ]]></description>
    </item>
    <item>
        <title>Overclocking LLM Reasoning: Monitoring and Controlling Thinking Path Lengths in LLMs</title>
        <link>https://arxiv.org/abs/2506.07240</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07240v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Roy Eisenstadt, Itamar Zimerman, Lior Wolf</dc:creator>
        <description><![CDATA[
            背景：显式结构化推理技术将模型内部“思考”与最终响应分离，但思考阶段长度影响答案质量，过短无法捕捉任务复杂性，过长会过度思考。方法：探索大语言模型在显式思考过程中理解和调节推理长度的机制，展示模型通过推理过程编码进度，引入交互式进度条可视化，在推理时操纵内部进度编码以减少不必要步骤。效果：该“超频”方法减轻了过度思考，提高了答案准确率，降低了推理延迟。
            arXiv:2506.07240v1 Announce Type: new 
Abstract: Recently, techniques such as explicit structured reasoning have demonstrated strong test-time scaling behavior by enforcing a separation between the model's internal "thinking" process and the final response. A key factor influencing answer quality in this setting is the length of the thinking stage. When the reasoning is too short, the model may fail to capture the complexity of the task. Conversely, when it is too long, the model may overthink, leading to unnecessary computation and degraded performance. This paper explores and exploits the underlying mechanisms by which LLMs understand and regulate the length of their reasoning during explicit thought processes. First, we show that LLMs encode their progress through the reasoning process and introduce an interactive progress bar visualization, which is then used to reveal insights on the model's planning dynamics. Second, we manipulate the internal progress encoding during inference to reduce unnecessary steps and generate a more concise and decisive chain of thoughts. Our empirical results demonstrate that this "overclocking" method mitigates overthinking, improves answer accuracy, and reduces inference latency. Our code is publicly available.
        ]]></description>
    </item>
    <item>
        <title>SDE-SQL: Enhancing Text-to-SQL Generation in Large Language Models via Self-Driven Exploration with SQL Probes</title>
        <link>https://arxiv.org/abs/2506.07245</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07245v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wenxuan Xie, Yaxun Dai, Wenhao Jiang</dc:creator>
        <description><![CDATA[
            背景：现有大语言模型在文本到SQL任务中依赖静态数据库信息，限制了对数据库内容的理解。方法：提出SDE - SQL框架，让大模型在推理时通过生成和执行SQL探针进行数据库的自驱动探索，主动获取信息并迭代更新对数据的理解，且能在零样本设置下运行。效果：在BIRD基准测试中，相比原始Qwen2.5 - 72B - Instruct，执行准确率相对提升8.02%；经有监督微调后，还能额外提升0.52%。
            arXiv:2506.07245v1 Announce Type: new 
Abstract: Recent advancements in large language models (LLMs) have significantly improved performance on the Text-to-SQL task. However, prior approaches typically rely on static, pre-processed database information provided at inference time, which limits the model's ability to fully understand the database contents. Without dynamic interaction, LLMs are constrained to fixed, human-provided context and cannot autonomously explore the underlying data. To address this limitation, we propose SDE-SQL, a framework that enables large language models to perform self-driven exploration of databases during inference. This is accomplished by generating and executing SQL probes, which allow the model to actively retrieve information from the database and iteratively update its understanding of the data. Unlike prior methods, SDE-SQL operates in a zero-shot setting, without relying on any question-SQL pairs as in-context demonstrations. When evaluated on the BIRD benchmark with Qwen2.5-72B-Instruct, SDE-SQL achieves an 8.02% relative improvement in execution accuracy over the vanilla Qwen2.5-72B-Instruct baseline, establishing a new state-of-the-art among methods based on open-source models without supervised fine-tuning (SFT) or model ensembling. Moreover, with SFT, the performance of SDE-SQL can be further enhanced, yielding an additional 0.52% improvement.
        ]]></description>
    </item>
    <item>
        <title>From Generation to Generalization: Emergent Few-Shot Learning in Video Diffusion Models</title>
        <link>https://arxiv.org/abs/2506.07280</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07280v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Pablo Acuaviva, Aram Davtyan, Mariam Hassan, Sebastian Stapf, Ahmad Rahimi, Alexandre Alahi, Paolo Favaro</dc:creator>
        <description><![CDATA[
            背景：视频扩散模型（VDMs）是强大的生成工具，其潜力远超视频生成，训练动态促使其内化结构化表征和对视觉世界的隐式理解。方法：引入少样本微调框架，将任务转化为视觉过渡，在短输入输出序列上训练LoRA权重且不改变冻结VDM的生成接口。效果：模型在从低级视觉到高级推理等多样任务中展现出强泛化能力，VDMs有望成为未来视觉基础模型的骨干。
            arXiv:2506.07280v1 Announce Type: new 
Abstract: Video Diffusion Models (VDMs) have emerged as powerful generative tools, capable of synthesizing high-quality spatiotemporal content. Yet, their potential goes far beyond mere video generation. We argue that the training dynamics of VDMs, driven by the need to model coherent sequences, naturally pushes them to internalize structured representations and an implicit understanding of the visual world. To probe the extent of this internal knowledge, we introduce a few-shot fine-tuning framework that repurposes VDMs for new tasks using only a handful of examples. Our method transforms each task into a visual transition, enabling the training of LoRA weights on short input-output sequences without altering the generative interface of a frozen VDM. Despite minimal supervision, the model exhibits strong generalization across diverse tasks, from low-level vision (for example, segmentation and pose estimation) to high-level reasoning (for example, on ARC-AGI). These results reframe VDMs as more than generative engines. They are adaptable visual learners with the potential to serve as the backbone for future foundation models in vision.
        ]]></description>
    </item>
    <item>
        <title>EviNet: Evidential Reasoning Network for Resilient Graph Learning in the Open and Noisy Environments</title>
        <link>https://arxiv.org/abs/2506.07288</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07288v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Weijie Guan, Haohui Wang, Jian Kang, Lihui Liu, Dawei Zhou</dc:creator>
        <description><![CDATA[
            背景：图学习对很多现实任务至关重要，但常基于封闭世界假设开展研究，在开放和嘈杂环境中有效进行图学习面临挑战，如误分类检测和分布外检测。方法：本文提出证据推理网络（EVINET），在主观逻辑框架内集成Beta嵌入，包含用于误分类检测的不一致性推理和用于分布外检测的空洞性推理两个关键模块。效果：大量实验表明，EVINET在多项指标上优于现有方法，为开放世界图学习奠定基础。
            arXiv:2506.07288v1 Announce Type: new 
Abstract: Graph learning has been crucial to many real-world tasks, but they are often studied with a closed-world assumption, with all possible labels of data known a priori. To enable effective graph learning in an open and noisy environment, it is critical to inform the model users when the model makes a wrong prediction to in-distribution data of a known class, i.e., misclassification detection or when the model encounters out-of-distribution from novel classes, i.e., out-of-distribution detection. This paper introduces Evidential Reasoning Network (EVINET), a framework that addresses these two challenges by integrating Beta embedding within a subjective logic framework. EVINET includes two key modules: Dissonance Reasoning for misclassification detection and Vacuity Reasoning for out-of-distribution detection. Extensive experiments demonstrate that EVINET outperforms state-of-the-art methods across multiple metrics in the tasks of in-distribution classification, misclassification detection, and out-of-distribution detection. EVINET demonstrates the necessity of uncertainty estimation and logical reasoning for misclassification detection and out-of-distribution detection and paves the way for open-world graph learning. Our code and data are available at https://github.com/SSSKJ/EviNET.
        ]]></description>
    </item>
    <item>
        <title>Pre-trained Large Language Models Learn Hidden Markov Models In-context</title>
        <link>https://arxiv.org/abs/2506.07298</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07298v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yijia Dai, Zhaolin Gao, Yahya Satter, Sarah Dean, Jennifer J. Sun</dc:creator>
        <description><![CDATA[
            背景：隐马尔可夫模型（HMMs）是建模序列数据的基础工具，但拟合真实数据存在计算挑战。方法：研究表明预训练大语言模型（LLMs）可通过上下文学习（ICL）有效建模HMMs生成的数据。效果：在多种合成HMMs上，LLMs的预测准确率接近理论最优；在真实动物决策任务中，ICL与人类专家设计的模型表现相当，这一进展加深了对LLMs中上下文学习的理解。
            arXiv:2506.07298v1 Announce Type: new 
Abstract: Hidden Markov Models (HMMs) are foundational tools for modeling sequential data with latent Markovian structure, yet fitting them to real-world data remains computationally challenging. In this work, we show that pre-trained large language models (LLMs) can effectively model data generated by HMMs via in-context learning (ICL)$\unicode{x2013}$their ability to infer patterns from examples within a prompt. On a diverse set of synthetic HMMs, LLMs achieve predictive accuracy approaching the theoretical optimum. We uncover novel scaling trends influenced by HMM properties, and offer theoretical conjectures for these empirical observations. We also provide practical guidelines for scientists on using ICL as a diagnostic tool for complex data. On real-world animal decision-making tasks, ICL achieves competitive performance with models designed by human experts. To our knowledge, this is the first demonstration that ICL can learn and predict HMM-generated sequences$\unicode{x2013}$an advance that deepens our understanding of in-context learning in LLMs and establishes its potential as a powerful tool for uncovering hidden structure in complex scientific data.
        ]]></description>
    </item>
    <item>
        <title>Graph-KV: Breaking Sequence via Injecting Structural Biases into Large Language Models</title>
        <link>https://arxiv.org/abs/2506.07334</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07334v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Haoyu Wang, Peihao Wang, Mufei Li, Shikun Liu, Siqi Miao, Zhangyang Wang, Pan Li</dc:creator>
        <description><![CDATA[
            现代大语言模型需将输入序列化为扁平序列，这阻碍其利用结构归纳偏差，尤其在RAG和图结构数据推理任务中。为此提出Graph - KV方法，它利用文本段的KV缓存作为浓缩表示，通过结构归纳偏差控制交互，使‘目标’段仅关注指定‘源’段的KV缓存，形成图结构块掩码，还通过分配位置编码减少偏差和窗口消耗。在三类场景评估中，Graph - KV有效降低位置偏差、利用结构归纳偏差，大幅超越基线方法。
            arXiv:2506.07334v1 Announce Type: new 
Abstract: Modern large language models (LLMs) are inherently auto-regressive, requiring input to be serialized into flat sequences regardless of their structural dependencies. This serialization hinders the model's ability to leverage structural inductive biases, especially in tasks such as retrieval-augmented generation (RAG) and reasoning on data with native graph structures, where inter-segment dependencies are crucial. We introduce Graph-KV with the potential to overcome this limitation. Graph-KV leverages the KV-cache of text segments as condensed representations and governs their interaction through structural inductive biases. In this framework, 'target' segments selectively attend only to the KV-caches of their designated 'source' segments, rather than all preceding segments in a serialized sequence. This approach induces a graph-structured block mask, sparsifying attention and enabling a message-passing-like step within the LLM. Furthermore, strategically allocated positional encodings for source and target segments reduce positional bias and context window consumption. We evaluate Graph-KV across three scenarios: (1) seven RAG benchmarks spanning direct inference, multi-hop reasoning, and long-document understanding; (2) Arxiv-QA, a novel academic paper QA task with full-text scientific papers structured as citation ego-graphs; and (3) paper topic classification within a citation network. By effectively reducing positional bias and harnessing structural inductive biases, Graph-KV substantially outperforms baselines, including standard costly sequential encoding, across various settings. Code and the Graph-KV data are publicly available.
        ]]></description>
    </item>
    <item>
        <title>Improving LLM Reasoning through Interpretable Role-Playing Steering</title>
        <link>https://arxiv.org/abs/2506.07335</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07335v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Anyi Wang, Dong Shu, Yifan Wang, Yunpu Ma, Mengnan Du</dc:creator>
        <description><![CDATA[
            背景：角色扮演是提升大语言模型推理能力的有效技术，但现有方法依赖提示工程，缺乏稳定性和可解释性。方法：本文提出Sparse Autoencoder Role - Playing Steering（SRPS）框架，从角色扮演提示中提取潜在表征，基于激活模式选择相关特征，构建可控制强度的转向向量注入模型残差流。效果：在多个推理基准测试和不同模型规模上表现出性能提升，如在零样本思维链设置中，Llama3.1 - 8B在CSQA上准确率从31.86%提升到39.80%，Gemma2 - 9B在SVAMP上从37.50%提升到45.10%。
            arXiv:2506.07335v1 Announce Type: new 
Abstract: Role-playing has emerged as an effective technique for enhancing the reasoning capabilities of large language models (LLMs). However, existing methods primarily rely on prompt engineering, which often lacks stability and interpretability. In this paper, we introduce Sparse Autoencoder Role-Playing Steering (SRPS), a novel framework that identifies and manipulates internal model features associated with role-playing behavior. Our approach extracts latent representations from role-play prompts, selects the most relevant features based on activation patterns, and constructs a steering vector that can be injected into the model's residual stream with controllable intensity. Our method enables fine-grained control over role-specific behavior and offers insights into how role information influences internal model activations. Extensive experiments across various reasoning benchmarks and model sizes demonstrate consistent performance gains. Notably, in the zero-shot chain-of-thought (CoT) setting, the accuracy of Llama3.1-8B on CSQA improves from 31.86% to 39.80%, while Gemma2-9B on SVAMP increases from 37.50% to 45.10%. These results highlight the potential of SRPS to enhance reasoning ability in LLMs, providing better interpretability and stability compared to traditional prompt-based role-playing.
        ]]></description>
    </item>
    <item>
        <title>MrM: Black-Box Membership Inference Attacks against Multimodal RAG Systems</title>
        <link>https://arxiv.org/abs/2506.07399</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07399v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Peiru Yang, Jinhua Yin, Haoran Zheng, Xueying Bai, Huili Wang, Yufei Sun, Xintian Li, Shangguang Wang, Yongfeng Huang, Tao Qi</dc:creator>
        <description><![CDATA[
            背景：多模态检索增强生成（RAG）系统在多模态任务中广泛应用，但存在隐私风险，现有针对RAG系统的成员推理攻击（MIAs）多聚焦文本模态，视觉模态研究较少。方法：提出首个针对多模态RAG系统的黑盒MIA框架MrM，利用多目标数据扰动框架，采用对象感知数据扰动和反事实信息掩码选择策略，通过建模查询试验进行统计成员推理。效果：在两个视觉数据集和八个主流模型上表现出色，在样本和集合层面评估中性能强，且在自适应防御下保持稳健。
            arXiv:2506.07399v1 Announce Type: new 
Abstract: Multimodal retrieval-augmented generation (RAG) systems enhance large vision-language models by integrating cross-modal knowledge, enabling their increasing adoption across real-world multimodal tasks. These knowledge databases may contain sensitive information that requires privacy protection. However, multimodal RAG systems inherently grant external users indirect access to such data, making them potentially vulnerable to privacy attacks, particularly membership inference attacks (MIAs). % Existing MIA methods targeting RAG systems predominantly focus on the textual modality, while the visual modality remains relatively underexplored. To bridge this gap, we propose MrM, the first black-box MIA framework targeted at multimodal RAG systems. It utilizes a multi-object data perturbation framework constrained by counterfactual attacks, which can concurrently induce the RAG systems to retrieve the target data and generate information that leaks the membership information. Our method first employs an object-aware data perturbation method to constrain the perturbation to key semantics and ensure successful retrieval. Building on this, we design a counterfact-informed mask selection strategy to prioritize the most informative masked regions, aiming to eliminate the interference of model self-knowledge and amplify attack efficacy. Finally, we perform statistical membership inference by modeling query trials to extract features that reflect the reconstruction of masked semantics from response patterns. Experiments on two visual datasets and eight mainstream commercial visual-language models (e.g., GPT-4o, Gemini-2) demonstrate that MrM achieves consistently strong performance across both sample-level and set-level evaluations, and remains robust under adaptive defenses.
        ]]></description>
    </item>
    <item>
        <title>InverseScope: Scalable Activation Inversion for Interpreting Large Language Models</title>
        <link>https://arxiv.org/abs/2506.07406</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07406v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yifan Luo, Zhennan Zhou, Bin Dong</dc:creator>
        <description><![CDATA[
            理解大语言模型的内部表征是可解释性研究的核心挑战，现有特征可解释性方法的假设在实践中未必成立。为此，本文提出InversScope框架，该框架假设少且可扩展，通过输入反演来解释神经激活。给定目标激活，定义能产生相似激活的输入分布并分析以推断编码特征。为解决高维空间采样低效问题，提出新的条件生成架构，相比以往方法显著提高采样效率。还引入定量评估协议，用特征一致性率测试可解释性假设，能对真实大语言模型内部表征进行系统定量分析。
            arXiv:2506.07406v1 Announce Type: new 
Abstract: Understanding the internal representations of large language models (LLMs) is a central challenge in interpretability research. Existing feature interpretability methods often rely on strong assumptions about the structure of representations that may not hold in practice. In this work, we introduce InverseScope, an assumption-light and scalable framework for interpreting neural activations via input inversion. Given a target activation, we define a distribution over inputs that generate similar activations and analyze this distribution to infer the encoded features. To address the inefficiency of sampling in high-dimensional spaces, we propose a novel conditional generation architecture that significantly improves sample efficiency compared to previous methods. We further introduce a quantitative evaluation protocol that tests interpretability hypotheses using feature consistency rate computed over the sampled inputs. InverseScope scales inversion-based interpretability methods to larger models and practical tasks, enabling systematic and quantitative analysis of internal representations in real-world LLMs.
        ]]></description>
    </item>
    <item>
        <title>Fast Geometric Embedding for Node Influence Maximization</title>
        <link>https://arxiv.org/abs/2506.07435</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07435v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Alexander Kolpakov, Igor Rivin</dc:creator>
        <description><![CDATA[
            背景：在大规模图上计算经典中心性度量（如介数和接近度）计算成本高。方法：引入一种高效的力布局算法，将图嵌入低维空间，用原点的径向距离作为各种中心性度量的代理。效果：在多个图族上评估该方法，证明其与度、PageRank和基于路径的中心性有很强的相关性，还能找到网络中高影响力的节点，为标准贪心算法提供了快速且可扩展的替代方案。
            arXiv:2506.07435v1 Announce Type: new 
Abstract: Computing classical centrality measures such as betweenness and closeness is computationally expensive on large-scale graphs. In this work, we introduce an efficient force layout algorithm that embeds a graph into a low-dimensional space, where the radial distance from the origin serves as a proxy for various centrality measures. We evaluate our method on multiple graph families and demonstrate strong correlations with degree, PageRank, and paths-based centralities. As an application, it turns out that the proposed embedding allows to find high-influence nodes in a network, and provides a fast and scalable alternative to the standard greedy algorithm.
        ]]></description>
    </item>
    <item>
        <title>Prompt to Protection: A Comparative Study of Multimodal LLMs in Construction Hazard Recognition</title>
        <link>https://arxiv.org/abs/2506.07436</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07436v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Nishi Chaudhary, S M Jamil Uddin, Sathvik Sharath Chandra, Anto Ovid, Alex Albert</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型为施工现场视觉危险识别带来新机遇，但不同模型在建筑领域安全关键视觉任务中的表现研究较少。方法：对Claude - 3 Opus等五个先进大语言模型，采用零样本、少样本和思维链三种提示策略，测试其从真实建筑图像中识别潜在危险的能力，并用量化指标分析。效果：思维链提示策略显著提升性能，GPT - 4.5和GPT - o3在多数情况下表现更优，提示设计对提高准确性和一致性至关重要。
            arXiv:2506.07436v1 Announce Type: new 
Abstract: The recent emergence of multimodal large language models (LLMs) has introduced new opportunities for improving visual hazard recognition on construction sites. Unlike traditional computer vision models that rely on domain-specific training and extensive datasets, modern LLMs can interpret and describe complex visual scenes using simple natural language prompts. However, despite growing interest in their applications, there has been limited investigation into how different LLMs perform in safety-critical visual tasks within the construction domain. To address this gap, this study conducts a comparative evaluation of five state-of-the-art LLMs: Claude-3 Opus, GPT-4.5, GPT-4o, GPT-o3, and Gemini 2.0 Pro, to assess their ability to identify potential hazards from real-world construction images. Each model was tested under three prompting strategies: zero-shot, few-shot, and chain-of-thought (CoT). Zero-shot prompting involved minimal instruction, few-shot incorporated basic safety context and a hazard source mnemonic, and CoT provided step-by-step reasoning examples to scaffold model thinking. Quantitative analysis was performed using precision, recall, and F1-score metrics across all conditions. Results reveal that prompting strategy significantly influenced performance, with CoT prompting consistently producing higher accuracy across models. Additionally, LLM performance varied under different conditions, with GPT-4.5 and GPT-o3 outperforming others in most settings. The findings also demonstrate the critical role of prompt design in enhancing the accuracy and consistency of multimodal LLMs for construction safety applications. This study offers actionable insights into the integration of prompt engineering and LLMs for practical hazard recognition, contributing to the development of more reliable AI-assisted safety systems.
        ]]></description>
    </item>
    <item>
        <title>GLOS: Sign Language Generation with Temporally Aligned Gloss-Level Conditioning</title>
        <link>https://arxiv.org/abs/2506.07460</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07460v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Taeryung Lee, Hyeongjin Nam, Gyeongsik Moon, Kyoung Mu Lee</dc:creator>
        <description><![CDATA[
            背景：手语生成（SLG）虽有进展，但现有方法存在词汇顺序错误和语义准确性低的问题，原因在于句子级条件无法捕捉手语的时间结构和词级语义。方法：提出GLOS框架，采用与动作序列时间对齐的词素级条件，使模型能获取时间结构和词级语义；引入条件融合模块TAC，将词级语义和时间结构传递到对应动作时间步。效果：生成的手语词汇顺序正确、语义准确性高，在CSL - Daily和Phoenix - 2014T上优于先前方法。
            arXiv:2506.07460v1 Announce Type: new 
Abstract: Sign language generation (SLG), or text-to-sign generation, bridges the gap between signers and non-signers. Despite recent progress in SLG, existing methods still often suffer from incorrect lexical ordering and low semantic accuracy. This is primarily due to sentence-level condition, which encodes the entire sentence of the input text into a single feature vector as a condition for SLG. This approach fails to capture the temporal structure of sign language and lacks the granularity of word-level semantics, often leading to disordered sign sequences and ambiguous motions. To overcome these limitations, we propose GLOS, a sign language generation framework with temporally aligned gloss-level conditioning. First, we employ gloss-level conditions, which we define as sequences of gloss embeddings temporally aligned with the motion sequence. This enables the model to access both the temporal structure of sign language and word-level semantics at each timestep. As a result, this allows for fine-grained control of signs and better preservation of lexical order. Second, we introduce a condition fusion module, temporal alignment conditioning (TAC), to efficiently deliver the word-level semantic and temporal structure provided by the gloss-level condition to the corresponding motion timesteps. Our method, which is composed of gloss-level conditions and TAC, generates signs with correct lexical order and high semantic accuracy, outperforming prior methods on CSL-Daily and Phoenix-2014T.
        ]]></description>
    </item>
    <item>
        <title>CCI4.0: A Bilingual Pretraining Dataset for Enhancing Reasoning in Large Language Models</title>
        <link>https://arxiv.org/abs/2506.07463</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07463v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Guang Liu, Liangdong Wang, Jijie Li, Yang Yu, Yao Xu, Jiabei Chen, Yu Bai, Feng Liao, Yonghua Lin</dc:creator>
        <description><![CDATA[
            背景：现有数据质量标准动态变化，需大量专家经验和人力处理。方法：引入大规模双语预训练数据集CCI4.0，包含CCI4.0 - M2 - Base和CCI4.0 - M2 - CoT两个子数据集，提出基于模型的新数据质量验证流程，提取45亿条思维链模板。效果：预训练的大语言模型能获得更干净可靠的训练信号，在下游任务尤其是数学和代码反思任务中有持续提升，还降低了幻觉可能性。
            arXiv:2506.07463v1 Announce Type: new 
Abstract: We introduce CCI4.0, a large-scale bilingual pre-training dataset engineered for superior data quality and diverse human-like reasoning trajectory. CCI4.0 occupies roughly $35$ TB of disk space and comprises two sub-datasets: CCI4.0-M2-Base and CCI4.0-M2-CoT. CCI4.0-M2-Base combines a $5.2$ TB carefully curated Chinese web corpus, a $22.5$ TB English subset from Nemotron-CC, and diverse sources from math, wiki, arxiv, and code. Although these data are mostly sourced from well-processed datasets, the quality standards of various domains are dynamic and require extensive expert experience and labor to process. So, we propose a novel pipeline justifying data quality mainly based on models through two-stage deduplication, multiclassifier quality scoring, and domain-aware fluency filtering. We extract $4.5$ billion pieces of CoT(Chain-of-Thought) templates, named CCI4.0-M2-CoT. Differing from the distillation of CoT from larger models, our proposed staged CoT extraction exemplifies diverse reasoning patterns and significantly decreases the possibility of hallucination. Empirical evaluations demonstrate that LLMs pre-trained in CCI4.0 benefit from cleaner, more reliable training signals, yielding consistent improvements in downstream tasks, especially in math and code reflection tasks. Our results underscore the critical role of rigorous data curation and human thinking templates in advancing LLM performance, shedding some light on automatically processing pretraining corpora.
        ]]></description>
    </item>
    <item>
        <title>DeepVideo-R1: Video Reinforcement Fine-Tuning via Difficulty-aware Regressive GRPO</title>
        <link>https://arxiv.org/abs/2506.07464</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07464v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jinyoung Park, Jeehye Na, Jinyoung Kim, Hyunwoo J. Kim</dc:creator>
        <description><![CDATA[
            背景：基于强化学习的训练后处理可提升大语言模型推理能力，Group Relative Policy Optimization（GRPO）效果显著，但在视频大语言模型中的应用研究较少，且存在依赖保障措施和优势消失问题。方法：提出DeepVideo - R1，采用Reg - GRPO将GRPO目标转化为回归任务，直接预测优势值，还设计难度感知数据增强策略。效果：综合实验表明，DeepVideo - R1在多个视频推理基准测试中显著提升视频推理性能。
            arXiv:2506.07464v1 Announce Type: new 
Abstract: Recent works have demonstrated the effectiveness of reinforcement learning (RL)-based post-training in enhancing the reasoning capabilities of large language models (LLMs). In particular, Group Relative Policy Optimization (GRPO) has shown impressive success by employing a PPO-style reinforcement algorithm with group-based normalized rewards. However, the application of GRPO to Video Large Language Models (Video LLMs) has been less studied. In this paper, we explore GRPO for video LLMs and identify two primary issues that impede its effective learning: (1) reliance on safeguards, and (2) the vanishing advantage problem. To mitigate these challenges, we propose DeepVideo-R1, a video large language model trained with our proposed Reg-GRPO (Regressive GRPO) and difficulty-aware data augmentation strategy. Reg-GRPO reformulates the GRPO objective as a regression task, directly predicting the advantage in GRPO. This design eliminates the need for safeguards like clipping and min functions, thereby facilitating more direct policy guidance by aligning the model with the advantage values. We also design the difficulty-aware data augmentation strategy that dynamically augments training samples at solvable difficulty levels, fostering diverse and informative reward signals. Our comprehensive experiments show that DeepVideo-R1 significantly improves video reasoning performance across multiple video reasoning benchmarks.
        ]]></description>
    </item>
    <item>
        <title>A Hybrid GA LLM Framework for Structured Task Optimization</title>
        <link>https://arxiv.org/abs/2506.07483</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07483v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Berry Feng, Jonas Lin, Patrick Lau</dc:creator>
        <description><![CDATA[
            背景：为处理严格约束下的结构化生成任务，提出结合遗传算法与大语言模型的GA LLM混合框架。方法：将输出视为基因，由语言模型引导选择、交叉和变异等进化操作迭代优化方案，语言模型提供领域知识和创新变化，遗传算法确保结构完整和全局优化。效果：在行程规划、学术大纲拟定和商业报告等任务中表现出色，能稳定输出结构良好且满足要求的结果，相比单用语言模型，约束满足度和方案质量更高，且模块化设计易适配新任务。
            arXiv:2506.07483v1 Announce Type: new 
Abstract: GA LLM is a hybrid framework that combines Genetic Algorithms with Large Language Models to handle structured generation tasks under strict constraints. Each output, such as a plan or report, is treated as a gene, and evolutionary operations like selection, crossover, and mutation are guided by the language model to iteratively improve solutions. The language model provides domain knowledge and creative variation, while the genetic algorithm ensures structural integrity and global optimization. GA LLM has proven effective in tasks such as itinerary planning, academic outlining, and business reporting, consistently producing well structured and requirement satisfying results. Its modular design also makes it easy to adapt to new tasks. Compared to using a language model alone, GA LLM achieves better constraint satisfaction and higher quality solutions by combining the strengths of both components.
        ]]></description>
    </item>
    <item>
        <title>SpatialLM: Training Large Language Models for Structured Indoor Modeling</title>
        <link>https://arxiv.org/abs/2506.07491</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07491v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yongsen Mao, Junhao Zhong, Chuan Fang, Jia Zheng, Rui Tang, Hao Zhu, Ping Tan, Zihan Zhou</dc:creator>
        <description><![CDATA[
            背景：现有方法多采用特定任务网络设计处理3D点云数据。方法：提出SpatialLM大语言模型，遵循标准多模态大语言模型架构，直接从开源大语言模型微调。收集含12328个室内场景（54778个房间）点云及3D标注的大规模高质量合成数据集，研究多种建模和训练决策。效果：在公共基准测试中，布局估计达最优，3D目标检测结果有竞争力，为增强大语言模型空间理解能力提供可行路径。
            arXiv:2506.07491v1 Announce Type: new 
Abstract: SpatialLM is a large language model designed to process 3D point cloud data and generate structured 3D scene understanding outputs. These outputs include architectural elements like walls, doors, windows, and oriented object boxes with their semantic categories. Unlike previous methods which exploit task-specific network designs, our model adheres to the standard multimodal LLM architecture and is fine-tuned directly from open-source LLMs.
  To train SpatialLM, we collect a large-scale, high-quality synthetic dataset consisting of the point clouds of 12,328 indoor scenes (54,778 rooms) with ground-truth 3D annotations, and conduct a careful study on various modeling and training decisions. On public benchmarks, our model gives state-of-the-art performance in layout estimation and competitive results in 3D object detection. With that, we show a feasible path for enhancing the spatial understanding capabilities of modern LLMs for applications in augmented reality, embodied robotics, and more.
        ]]></description>
    </item>
    <item>
        <title>Genesis: Multimodal Driving Scene Generation with Spatio-Temporal and Cross-Modal Consistency</title>
        <link>https://arxiv.org/abs/2506.07497</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07497v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiangyu Guo, Zhanqian Wu, Kaixin Xiong, Ziyang Xu, Lijun Zhou, Gangwei Xu, Shaoqing Xu, Haiyang Sun, Bing Wang, Guang Chen, Hangjun Ye, Wenyu Liu, Xinggang Wang</dc:creator>
        <description><![CDATA[
            本文背景是需要实现多模态驾驶场景生成的时空和跨模态一致性。方法上，提出Genesis统一框架，采用两阶段架构，将基于DiT的视频扩散模型与3D-VAE编码集成，BEV感知的LiDAR生成器结合NeRF渲染和自适应采样，通过共享潜空间耦合两种模态，并引入基于视觉语言模型的DataCrafter模块提供语义监督。效果上，在nuScenes基准测试中取得了领先成绩（FVD 16.95，FID 4.24，Chamfer 0.611），并有益于下游任务。
            arXiv:2506.07497v1 Announce Type: new 
Abstract: We present Genesis, a unified framework for joint generation of multi-view driving videos and LiDAR sequences with spatio-temporal and cross-modal consistency. Genesis employs a two-stage architecture that integrates a DiT-based video diffusion model with 3D-VAE encoding, and a BEV-aware LiDAR generator with NeRF-based rendering and adaptive sampling. Both modalities are directly coupled through a shared latent space, enabling coherent evolution across visual and geometric domains. To guide the generation with structured semantics, we introduce DataCrafter, a captioning module built on vision-language models that provides scene-level and instance-level supervision. Extensive experiments on the nuScenes benchmark demonstrate that Genesis achieves state-of-the-art performance across video and LiDAR metrics (FVD 16.95, FID 4.24, Chamfer 0.611), and benefits downstream tasks including segmentation and 3D detection, validating the semantic fidelity and practical utility of the generated data.
        ]]></description>
    </item>
    <item>
        <title>Graph-of-Causal Evolution: Challenging Chain-of-Model for Reasoning</title>
        <link>https://arxiv.org/abs/2506.07501</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07501v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Libo Wang</dc:creator>
        <description><![CDATA[
            背景：模型链（CoM）中各子链仅依赖前一子链信息，因果掩码阻断多级子链间全局上下文流动，可能丢失长程依赖。方法：提出因果演化图（GoCE），将隐式标记表示映射为可微稀疏因果邻接矩阵，用因果掩码注意力和因果混合专家网络贯穿各层计算，结合干预一致性损失测试和自演化门实现因果结构学习与架构自适应更新的动态平衡。效果：在多个公开数据集上评估，证明GoCE增强了捕捉长程因果依赖和自演化能力，超越CoM。
            arXiv:2506.07501v1 Announce Type: new 
Abstract: In view of the problem that each subchain in the chain-of-model (CoM) relies only on the information of the previous subchain and may lose long-range dependencies due to the causal mask blocking the global context flow between multi-level subchains, this work proposes a graph of causal evolution (GoCE). Its core principle is to map the implicit token representation into a differentiable and sparse causal adjacency matrix, then permeate causal constraints through each layer of calculation using causal-masked attention and causal-MoE. By combining intervention consistency loss test and self-evolution gate, the dynamic balance between causal structure learning and adaptive updating of transformer architecture is realized. The researcher built experimental environments in sandboxes built with Claude Sonnet 4, o4-mini-high, and DeepSeek R1 respectively with the transformer variant architecture introduced in GoCE. It is evaluated on publicly available datasets including CLUTRR, CLADDER, EX-FEVER, and CausalQA and compared with the baseline LLMs. The finding proves that GoCE strengthens the transformer's ability to capture long-range causal dependencies, while the ability to self-evolve is improved. It not only surpasses the design of CoM in terms of design principles, but also provides experience for future research on causal learning and continuous adaptive improvement.
        ]]></description>
    </item>
    <item>
        <title>Towards Large Language Models with Self-Consistent Natural Language Explanations</title>
        <link>https://arxiv.org/abs/2506.07523</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07523v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sahar Admoni, Ofra Amir, Assaf Hallak, Yftah Ziser</dc:creator>
        <description><![CDATA[
            背景：大语言模型（LLMs）的事后解释常歪曲真实决策过程，且因估算特征重要性成本高，缺乏系统解决方案。方法：引入事后自一致性库（PSCB），提出更有效的替代指标，并通过直接偏好优化（DPO）微调LLMs。效果：该方法使解释与决策相关特征的对齐显著改善，即使在领域转移情况下也有效，为构建更可信、自一致的LLMs提供了可扩展路径。
            arXiv:2506.07523v1 Announce Type: new 
Abstract: Large language models (LLMs) seem to offer an easy path to interpretability: just ask them to explain their decisions. Yet, studies show that these post-hoc explanations often misrepresent the true decision process, as revealed by mismatches in feature importance. Despite growing evidence of this inconsistency, no systematic solutions have emerged, partly due to the high cost of estimating feature importance, which limits evaluations to small datasets. To address this, we introduce the Post-hoc Self-Consistency Bank (PSCB) - a large-scale benchmark of decisions spanning diverse tasks and models, each paired with LLM-generated explanations and corresponding feature importance scores. Analysis of PSCB reveals that self-consistency scores barely differ between correct and incorrect predictions. We also show that the standard metric fails to meaningfully distinguish between explanations. To overcome this limitation, we propose an alternative metric that more effectively captures variation in explanation quality. We use it to fine-tune LLMs via Direct Preference Optimization (DPO), leading to significantly better alignment between explanations and decision-relevant features, even under domain shift. Our findings point to a scalable path toward more trustworthy, self-consistent LLMs.
        ]]></description>
    </item>
    <item>
        <title>SELT: Self-Evaluation Tree Search for LLMs with Task Decomposition</title>
        <link>https://arxiv.org/abs/2506.07557</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07557v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mengsong Wu, Di Zhang, Yuqiang Li, Dongzhan Zhou, Wenliang Chen</dc:creator>
        <description><![CDATA[
            大语言模型在复杂推理任务中表现欠佳。本文提出SELT框架，利用改进的蒙特卡罗树搜索，不依赖外部奖励模型来增强大语言模型推理能力。通过重新定义上置信界评分，将推理过程分解为原子子任务并结合语义聚类，有效平衡探索与利用，减少冗余推理路径、缓解幻觉问题。在MMLU和Seal - Tools等基准测试中，相比基线方法，SELT显著提升了答案准确率和推理鲁棒性，且无需特定任务微调，泛化性强。
            arXiv:2506.07557v1 Announce Type: new 
Abstract: While Large Language Models (LLMs) have achieved remarkable success in a wide range of applications, their performance often degrades in complex reasoning tasks. In this work, we introduce SELT (Self-Evaluation LLM Tree Search), a novel framework that leverages a modified Monte Carlo Tree Search (MCTS) to enhance LLM reasoning without relying on external reward models. By redefining the Upper Confidence Bound scoring to align with intrinsic self-evaluation capabilities of LLMs and decomposing the inference process into atomic subtasks augmented with semantic clustering at each node, SELT effectively balances exploration and exploitation, reduces redundant reasoning paths, and mitigates hallucination. We validate our approach on challenging benchmarks, including the knowledge-based MMLU and the Tool Learning dataset Seal-Tools, where SELT achieves significant improvements in answer accuracy and reasoning robustness compared to baseline methods. Notably, our framework operates without task-specific fine-tuning, demonstrating strong generalizability across diverse reasoning tasks. Relevant results and code are available at https://github.com/fairyshine/SELT .
        ]]></description>
    </item>
    <item>
        <title>MIRA: Medical Time Series Foundation Model for Real-World Health Data</title>
        <link>https://arxiv.org/abs/2506.07584</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07584v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hao Li, Bowen Deng, Chang Xu, Zhiyuan Feng, Viktor Schlegel, Yu-Hao Huang, Yizheng Sun, Jingyuan Sun, Kailai Yang, Yiyao Yu, Jiang Bian</dc:creator>
        <description><![CDATA[
            背景：现有通用时间序列基础模型难以处理医疗时间序列数据，因其存在间隔不规则、采样率异质和频繁缺失值等挑战。方法：提出专门用于医疗时间序列预测的统一基础模型MIRA，它结合连续时间旋转位置编码、特定频率的专家混合层和基于神经常微分方程的连续动态外推块。效果：在包含超4540亿时间点的大规模多样医疗语料上预训练，与其他零样本和微调基线相比，在分布外和分布内场景中预测误差平均分别降低10%和7%，还建立了多下游临床任务综合基准。
            arXiv:2506.07584v1 Announce Type: new 
Abstract: A unified foundation model for medical time series -- pretrained on open access and ethics board-approved medical corpora -- offers the potential to reduce annotation burdens, minimize model customization, and enable robust transfer across clinical institutions, modalities, and tasks, particularly in data-scarce or privacy-constrained environments. However, existing generalist time series foundation models struggle to handle medical time series data due to their inherent challenges, including irregular intervals, heterogeneous sampling rates, and frequent missing values. To address these challenges, we introduce MIRA, a unified foundation model specifically designed for medical time series forecasting. MIRA incorporates a Continuous-Time Rotary Positional Encoding that enables fine-grained modeling of variable time intervals, a frequency-specific mixture-of-experts layer that routes computation across latent frequency regimes to further promote temporal specialization, and a Continuous Dynamics Extrapolation Block based on Neural ODE that models the continuous trajectory of latent states, enabling accurate forecasting at arbitrary target timestamps. Pretrained on a large-scale and diverse medical corpus comprising over 454 billion time points collect from publicly available datasets, MIRA achieves reductions in forecasting errors by an average of 10% and 7% in out-of-distribution and in-distribution scenarios, respectively, when compared to other zero-shot and fine-tuned baselines. We also introduce a comprehensive benchmark spanning multiple downstream clinical tasks, establishing a foundation for future research in medical time series modeling.
        ]]></description>
    </item>
    <item>
        <title>SceneRAG: Scene-level Retrieval-Augmented Generation for Video Understanding</title>
        <link>https://arxiv.org/abs/2506.07600</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07600v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Nianbo Zeng, Haowen Hou, Fei Richard Yu, Si Shi, Ying Tiffany He</dc:creator>
        <description><![CDATA[
            背景：当前视频理解的检索增强生成（RAG）方法在处理长视频时，因视频数据规模大、复杂度高，常破坏上下文信息连续性且无法捕捉真实场景边界。方法：提出SceneRAG框架，利用大语言模型结合ASR转录和时间元数据将视频分割为连贯场景，通过轻量级启发式和迭代校正优化边界，为每个场景融合视觉和文本信息提取实体关系并动态构建知识图。效果：在LongerVideos基准测试中，显著优于先前基线，生成任务胜率达72.5%。
            arXiv:2506.07600v1 Announce Type: new 
Abstract: Despite recent advances in retrieval-augmented generation (RAG) for video understanding, effectively understanding long-form video content remains underexplored due to the vast scale and high complexity of video data. Current RAG approaches typically segment videos into fixed-length chunks, which often disrupts the continuity of contextual information and fails to capture authentic scene boundaries. Inspired by the human ability to naturally organize continuous experiences into coherent scenes, we present SceneRAG, a unified framework that leverages large language models to segment videos into narrative-consistent scenes by processing ASR transcripts alongside temporal metadata. SceneRAG further sharpens these initial boundaries through lightweight heuristics and iterative correction. For each scene, the framework fuses information from both visual and textual modalities to extract entity relations and dynamically builds a knowledge graph, enabling robust multi-hop retrieval and generation that account for long-range dependencies. Experiments on the LongerVideos benchmark, featuring over 134 hours of diverse content, confirm that SceneRAG substantially outperforms prior baselines, achieving a win rate of up to 72.5 percent on generation tasks.
        ]]></description>
    </item>
    <item>
        <title>Synthetic Visual Genome</title>
        <link>https://arxiv.org/abs/2506.07643</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07643v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jae Sung Park, Zixian Ma, Linjie Li, Chenhao Zheng, Cheng-Yu Hsieh, Ximing Lu, Khyathi Chandu, Quan Kong, Norimasa Kobori, Ali Farhadi, Yejin Choi, Ranjay Krishna</dc:creator>
        <description><![CDATA[
            视觉关系推理是人类认知的基础，但多模态语言模型在关系精确推理和生成上仍有挑战。为此，本文引入ROBIN，通过精心注释关系进行指令调优，能大规模构建高质量密集场景图。为训练ROBIN，创建了合成场景图数据集SVG；还提出SG - EDIT自蒸馏框架以生成更准确丰富的场景图。实验表明，ROBIN - 3B模型虽训练实例少，但在关系理解基准测试中超越类似规模及部分更大模型，在指代表达理解任务中得分88.9，优于此前最佳的87.4。
            arXiv:2506.07643v1 Announce Type: new 
Abstract: Reasoning over visual relationships-spatial, functional, interactional, social, etc.-is considered to be a fundamental component of human cognition. Yet, despite the major advances in visual comprehension in multimodal language models (MLMs), precise reasoning over relationships and their generations remains a challenge. We introduce ROBIN: an MLM instruction-tuned with densely annotated relationships capable of constructing high-quality dense scene graphs at scale. To train ROBIN, we curate SVG, a synthetic scene graph dataset by completing the missing relations of selected objects in existing scene graphs using a teacher MLM and a carefully designed filtering process to ensure high-quality. To generate more accurate and rich scene graphs at scale for any image, we introduce SG-EDIT: a self-distillation framework where GPT-4o further refines ROBIN's predicted scene graphs by removing unlikely relations and/or suggesting relevant ones. In total, our dataset contains 146K images and 5.6M relationships for 2.6M objects. Results show that our ROBIN-3B model, despite being trained on less than 3 million instances, outperforms similar-size models trained on over 300 million instances on relationship understanding benchmarks, and even surpasses larger models up to 13B parameters. Notably, it achieves state-of-the-art performance in referring expression comprehension with a score of 88.9, surpassing the previous best of 87.4. Our results suggest that training on the refined scene graph data is crucial to maintaining high performance across diverse visual reasoning task.
        ]]></description>
    </item>
    <item>
        <title>Synthesis by Design: Controlled Data Generation via Structural Guidance</title>
        <link>https://arxiv.org/abs/2506.07664</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07664v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Lei Xu, Sirui Chen, Yuxuan Huang, Chaochao Lu</dc:creator>
        <description><![CDATA[
            背景：数学推理对大语言模型（LLMs）而言颇具挑战，现有通过问题改写合成数据集的方法存在生成质量和问题复杂度等问题。方法：从数学推理中提取生成的解题代码的结构信息，用结构化解决方案指导数据生成。效果：应用于MATH和GSM8K，生成39K个带标记中间步骤的问题及6.1K个更高难度问题的基准。实验表明推理长度增加时模型性能下降，在一系列LLMs上的微调实验验证了数据集的有效性。
            arXiv:2506.07664v1 Announce Type: new 
Abstract: Mathematical reasoning remains challenging for LLMs due to complex logic and the need for precise computation. Existing methods enhance LLM reasoning by synthesizing datasets through problem rephrasing, but face issues with generation quality and problem complexity. To address this, we propose to extract structural information with generated problem-solving code from mathematical reasoning and guide data generation with structured solutions. Applied to MATH and GSM8K, our approach produces 39K problems with labeled intermediate steps and a 6.1K-problem benchmark of higher difficulty. Results on our benchmark show that model performance declines as reasoning length increases. Additionally, we conducted fine-tuning experiments using the proposed training data on a range of LLMs, and the results validate the effectiveness of our dataset. We hope the proposed method and dataset will contribute to future research in enhancing LLM reasoning capabilities.
        ]]></description>
    </item>
    <item>
        <title>Through the Valley: Path to Effective Long CoT Training for Small Language Models</title>
        <link>https://arxiv.org/abs/2506.07712</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07712v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Renjie Luo, Jiaxi Li, Chen Huang, Wei Lu</dc:creator>
        <description><![CDATA[
            长思维链（CoT）监督是提升语言模型推理能力的常用策略，但大模型适用，小模型却存在问题。研究发现小语言模型（参数<=3B）在有限长CoT数据上训练会出现“长CoT退化”现象，在Qwen2.5、LLaMA3和Gemma3系列实验显示该现象普遍存在。如仅用8k长CoT示例训练，模型性能最多下降75%，部分极小模型用220k示例训练也难恢复原有性能。原因是错误累积，长回复虽提升多步推理能力但增加错误风险。研究还指出该现象影响下游强化学习，可通过充分监督微调缓解，为构建有效小推理模型提供指导。
            arXiv:2506.07712v1 Announce Type: new 
Abstract: Long chain-of-thought (CoT) supervision has become a common strategy to enhance reasoning in language models. While effective for large models, we identify a phenomenon we call Long CoT Degradation, in which small language models (SLMs; <=3B parameters) trained on limited long CoT data experience significant performance deterioration. Through extensive experiments on the Qwen2.5, LLaMA3 and Gemma3 families, we demonstrate that this degradation is widespread across SLMs. In some settings, models trained on only 8k long CoT examples lose up to 75% of their original performance before fine-tuning. Strikingly, we further observe that for some particularly small models, even training on 220k long CoT examples fails to recover or surpass their original performance prior to fine-tuning. Our analysis attributes this effect to error accumulation: while longer responses increase the capacity for multi-step reasoning, they also amplify the risk of compounding mistakes. Furthermore, we find that Long CoT Degradation may negatively impacts downstream reinforcement learning (RL), although this can be alleviated by sufficiently scaled supervised fine-tuning (SFT). Our findings challenge common assumptions about the benefits of long CoT training for SLMs and offer practical guidance for building more effective small-scale reasoning models.
        ]]></description>
    </item>
    <item>
        <title>Language Embedding Meets Dynamic Graph: A New Exploration for Neural Architecture Representation Learning</title>
        <link>https://arxiv.org/abs/2506.07735</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07735v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Haizhao Jing, Haokui Zhang, Zhenhao Shang, Rong Xiao, Peng Wang, Yanning Zhang</dc:creator>
        <description><![CDATA[
            这是一篇关于神经架构表示学习的论文。背景是现有基于图神经网络与Transformer集成的方法存在忽略硬件属性信息、依赖静态邻接矩阵等局限。方法上，提出LeDG - Former框架，结合基于语言的语义嵌入和动态图表示学习，将神经架构和硬件平台规格投影到统一语义空间，用动态图Transformer建模神经架构。效果上，在NNLQP基准上超越先前方法，在NAS - Bench - 101和NAS - Bench - 201数据集上表现优越，还实现跨硬件延迟预测。
            arXiv:2506.07735v1 Announce Type: new 
Abstract: Neural Architecture Representation Learning aims to transform network models into feature representations for predicting network attributes, playing a crucial role in deploying and designing networks for real-world applications. Recently, inspired by the success of transformers, transformer-based models integrated with Graph Neural Networks (GNNs) have achieved significant progress in representation learning. However, current methods still have some limitations. First, existing methods overlook hardware attribute information, which conflicts with the current trend of diversified deep learning hardware and limits the practical applicability of models. Second, current encoding approaches rely on static adjacency matrices to represent topological structures, failing to capture the structural differences between computational nodes, which ultimately compromises encoding effectiveness. In this paper, we introduce LeDG-Former, an innovative framework that addresses these limitations through the synergistic integration of language-based semantic embedding and dynamic graph representation learning. Specifically, inspired by large language models (LLMs), we propose a language embedding framework where both neural architectures and hardware platform specifications are projected into a unified semantic space through tokenization and LLM processing, enabling zero-shot prediction across different hardware platforms for the first time. Then, we propose a dynamic graph-based transformer for modeling neural architectures, resulting in improved neural architecture modeling performance. On the NNLQP benchmark, LeDG-Former surpasses previous methods, establishing a new SOTA while demonstrating the first successful cross-hardware latency prediction capability. Furthermore, our framework achieves superior performance on the cell-structured NAS-Bench-101 and NAS-Bench-201 datasets.
        ]]></description>
    </item>
    <item>
        <title>Graph-Assisted Stitching for Offline Hierarchical Reinforcement Learning</title>
        <link>https://arxiv.org/abs/2506.07744</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07744v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Seungho Baek, Taegeon Park, Jongchan Park, Seungjun Oh, Yusung Kim</dc:creator>
        <description><![CDATA[
            背景：现有离线分层强化学习方法依赖高层策略学习生成子目标序列，任务视野增加时效率降低，且缺乏跨轨迹拼接有用状态转换的有效策略。方法：提出图辅助拼接（GAS）框架，将子目标选择视为图搜索问题，把状态嵌入时间距离表示（TDR）空间，聚类相似状态到统一图节点，用最短路径算法选子目标序列，低层策略学习到达子目标，还引入时间效率（TE）指标提高图质量。效果：在多项任务中表现优于现有方法，在最关键任务中得分88.3，远超之前的1.0。
            arXiv:2506.07744v1 Announce Type: new 
Abstract: Existing offline hierarchical reinforcement learning methods rely on high-level policy learning to generate subgoal sequences. However, their efficiency degrades as task horizons increase, and they lack effective strategies for stitching useful state transitions across different trajectories. We propose Graph-Assisted Stitching (GAS), a novel framework that formulates subgoal selection as a graph search problem rather than learning an explicit high-level policy. By embedding states into a Temporal Distance Representation (TDR) space, GAS clusters semantically similar states from different trajectories into unified graph nodes, enabling efficient transition stitching. A shortest-path algorithm is then applied to select subgoal sequences within the graph, while a low-level policy learns to reach the subgoals. To improve graph quality, we introduce the Temporal Efficiency (TE) metric, which filters out noisy or inefficient transition states, significantly enhancing task performance. GAS outperforms prior offline HRL methods across locomotion, navigation, and manipulation tasks. Notably, in the most stitching-critical task, it achieves a score of 88.3, dramatically surpassing the previous state-of-the-art score of 1.0. Our source code is available at: https://github.com/qortmdgh4141/GAS.
        ]]></description>
    </item>
    <item>
        <title>Re-ranking Reasoning Context with Tree Search Makes Large Vision-Language Models Stronger</title>
        <link>https://arxiv.org/abs/2506.07785</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07785v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qi Yang, Chenghao Zhang, Lubin Fan, Kun Ding, Jieping Ye, Shiming Xiang</dc:creator>
        <description><![CDATA[
            这是一篇关于多模态大模型的论文。背景是现有大视觉语言模型在视觉问答任务中存在推理示例知识稀缺、检索知识响应不稳定等问题。方法是提出了名为RCTS的多模态RAG框架，通过构建富含推理上下文的知识库和树搜索重排序方法来增强模型，还引入自洽评估机制、提出蒙特卡罗树搜索启发式奖励法。效果是在多个视觉问答数据集上取得了最先进的性能，显著优于上下文学习和普通RAG方法。
            arXiv:2506.07785v1 Announce Type: new 
Abstract: Recent advancements in Large Vision Language Models (LVLMs) have significantly improved performance in Visual Question Answering (VQA) tasks through multimodal Retrieval-Augmented Generation (RAG). However, existing methods still face challenges, such as the scarcity of knowledge with reasoning examples and erratic responses from retrieved knowledge. To address these issues, in this study, we propose a multimodal RAG framework, termed RCTS, which enhances LVLMs by constructing a Reasoning Context-enriched knowledge base and a Tree Search re-ranking method. Specifically, we introduce a self-consistent evaluation mechanism to enrich the knowledge base with intrinsic reasoning patterns. We further propose a Monte Carlo Tree Search with Heuristic Rewards (MCTS-HR) to prioritize the most relevant examples. This ensures that LVLMs can leverage high-quality contextual reasoning for better and more consistent responses. Extensive experiments demonstrate that our framework achieves state-of-the-art performance on multiple VQA datasets, significantly outperforming In-Context Learning (ICL) and Vanilla-RAG methods. It highlights the effectiveness of our knowledge base and re-ranking method in improving LVLMs. Our code is available at https://github.com/yannqi/RCTS-RAG.
        ]]></description>
    </item>
    <item>
        <title>WebUIBench: A Comprehensive Benchmark for Evaluating Multimodal Large Language Models in WebUI-to-Code</title>
        <link>https://arxiv.org/abs/2506.07818</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07818v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhiyu Lin, Zhengda Zhou, Zhiyuan Zhao, Tianrui Wan, Yilun Ma, Junyu Gao, Xuelong Li</dc:creator>
        <description><![CDATA[
            背景：随着生成式AI技术发展，多模态大语言模型有潜力进行复杂网页应用开发，但现有基准通常只关注网页生成结果，缺乏对模型子能力的评估。方法：受软件工程原理启发，提出WebUIBench基准，从WebUI感知、HTML编程等四个关键领域评估多模态大语言模型，其包含21K高质量问答对，来自超0.7K真实网站。效果：对29个主流多模态大语言模型的评估揭示了模型在开发过程中的技能特点和多种弱点。
            arXiv:2506.07818v1 Announce Type: new 
Abstract: With the rapid advancement of Generative AI technology, Multimodal Large Language Models(MLLMs) have the potential to act as AI software engineers capable of executing complex web application development. Considering that the model requires a confluence of multidimensional sub-capabilities to address the challenges of various development phases, constructing a multi-view evaluation framework is crucial for accurately guiding the enhancement of development efficiency. However, existing benchmarks usually fail to provide an assessment of sub-capabilities and focus solely on webpage generation outcomes. In this work, we draw inspiration from the principles of software engineering and further propose WebUIBench, a benchmark systematically designed to evaluate MLLMs in four key areas: WebUI Perception, HTML Programming,WebUI-HTML Understanding, and WebUI-to-Code. WebUIBench comprises 21K high-quality question-answer pairs derived from over 0.7K real-world websites. The extensive evaluation of 29 mainstream MLLMs uncovers the skill characteristics and various weakness that models encountered during the development process.
        ]]></description>
    </item>
    <item>
        <title>Learning to Focus: Causal Attention Distillation via Gradient-Guided Token Pruning</title>
        <link>https://arxiv.org/abs/2506.07851</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07851v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yiju Guo, Wenkai Yang, Zexu Sun, Ning Ding, Zhiyuan Liu, Yankai Lin</dc:creator>
        <description><![CDATA[
            背景：大语言模型在长文本推理和生成时难以关注关键信息，训练数据中的虚假关联会阻碍模型推断真实因果关系，导致推理冗余、结果错误等问题。方法：提出两阶段框架Learning to Focus (LeaF)，第一阶段基于梯度与高级教师对比，根据训练语料因果关系识别混淆标记；第二阶段在蒸馏时修剪这些标记。效果：在数学推理和代码生成基准测试中有绝对提升，有效抑制对混淆标记的关注，得到更具解释性和可靠性的推理模型。
            arXiv:2506.07851v1 Announce Type: new 
Abstract: Large language models (LLMs) have demonstrated significant improvements in contextual understanding. However, their ability to attend to truly critical information during long-context reasoning and generation still falls behind the pace. Specifically, our preliminary experiments reveal that certain distracting patterns can misdirect the model's attention during inference, and removing these patterns substantially improves reasoning accuracy and generation quality. We attribute this phenomenon to spurious correlations in the training data, which obstruct the model's capacity to infer authentic causal instruction-response relationships. This phenomenon may induce redundant reasoning processes, potentially resulting in significant inference overhead and, more critically, the generation of erroneous or suboptimal responses. To mitigate this, we introduce a two-stage framework called Learning to Focus (LeaF) leveraging intervention-based inference to disentangle confounding factors. In the first stage, LeaF employs gradient-based comparisons with an advanced teacher to automatically identify confounding tokens based on causal relationships in the training corpus. Then, in the second stage, it prunes these tokens during distillation to enact intervention, aligning the student's attention with the teacher's focus distribution on truly critical context tokens. Experimental results demonstrate that LeaF not only achieves an absolute improvement in various mathematical reasoning and code generation benchmarks but also effectively suppresses attention to confounding tokens during inference, yielding a more interpretable and reliable reasoning model.
        ]]></description>
    </item>
    <item>
        <title>Diffuse Everything: Multimodal Diffusion Models on Arbitrary State Spaces</title>
        <link>https://arxiv.org/abs/2506.07903</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07903v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kevin Rojas, Yuchen Zhu, Sichen Zhu, Felix X. -F. Ye, Molei Tao</dc:creator>
        <description><![CDATA[
            背景：扩散模型在单模态数据生成任务中表现出色，但多模态数据联合生成尚处早期探索阶段，现有方法依赖外部预处理协议，对编解码器准确性要求高，不适用于数据有限的应用。方法：提出在任意状态空间构建多模态扩散模型的新框架，为各模态引入创新的解耦噪声调度。效果：能在单个模型中同时实现无条件和模态条件生成，在文本图像生成和混合类型表格数据合成中取得有竞争力的性能。
            arXiv:2506.07903v1 Announce Type: new 
Abstract: Diffusion models have demonstrated remarkable performance in generating unimodal data across various tasks, including image, video, and text generation. On the contrary, the joint generation of multimodal data through diffusion models is still in the early stages of exploration. Existing approaches heavily rely on external preprocessing protocols, such as tokenizers and variational autoencoders, to harmonize varied data representations into a unified, unimodal format. This process heavily demands the high accuracy of encoders and decoders, which can be problematic for applications with limited data. To lift this restriction, we propose a novel framework for building multimodal diffusion models on arbitrary state spaces, enabling native generation of coupled data across different modalities. By introducing an innovative decoupled noise schedule for each modality, we enable both unconditional and modality-conditioned generation within a single model simultaneously. We empirically validate our approach for text-image generation and mixed-type tabular data synthesis, demonstrating that it achieves competitive performance.
        ]]></description>
    </item>
    <item>
        <title>Uncovering the Functional Roles of Nonlinearity in Memory</title>
        <link>https://arxiv.org/abs/2506.07919</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07919v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Manuel Brenner, Georgia Koppe</dc:creator>
        <description><![CDATA[
            记忆和长时程时间处理是自然语言处理等序列建模任务的核心需求。以往认为非线性循环对这些机制很关键，但近期研究表明线性动态也常能满足需求。该研究超越性能比较，系统剖析循环网络中非线性的功能作用。借助几乎线性循环神经网络（AL - RNNs）作为建模工具和探测手段，在一系列经典序列建模任务和实际刺激选择任务中发现，最小非线性不仅足够且常是最优的，模型比全非线性或线性模型更简单、稳健和可解释。研究为选择性引入非线性提供了理论框架，连接了动力系统理论与循环神经网络长时记忆和结构化计算的功能需求。
            arXiv:2506.07919v1 Announce Type: new 
Abstract: Memory and long-range temporal processing are core requirements for sequence modeling tasks across natural language processing, time-series forecasting, speech recognition, and control. While nonlinear recurrence has long been viewed as essential for enabling such mechanisms, recent work suggests that linear dynamics may often suffice. In this study, we go beyond performance comparisons to systematically dissect the functional role of nonlinearity in recurrent networks--identifying both when it is computationally necessary, and what mechanisms it enables. We use Almost Linear Recurrent Neural Networks (AL-RNNs), which allow fine-grained control over nonlinearity, as both a flexible modeling tool and a probe into the internal mechanisms of memory. Across a range of classic sequence modeling tasks and a real-world stimulus selection task, we find that minimal nonlinearity is not only sufficient but often optimal, yielding models that are simpler, more robust, and more interpretable than their fully nonlinear or linear counterparts. Our results provide a principled framework for selectively introducing nonlinearity, bridging dynamical systems theory with the functional demands of long-range memory and structured computation in recurrent neural networks, with implications for both artificial and biological neural systems.
        ]]></description>
    </item>
    <item>
        <title>W4S4: WaLRUS Meets S4 for Long-Range Sequence Modeling</title>
        <link>https://arxiv.org/abs/2506.07920</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07920v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hossein Babaei, Mel White, Richard G. Baraniuk</dc:creator>
        <description><![CDATA[
            背景：状态空间模型（SSMs）是序列建模的有力组件，但效果依赖状态矩阵的选择和初始化。方法：基于SaFARi框架和现有的WaLRUS SSMs，引入新变体W4S4，这是由冗余小波框架构建的新型SSMs，其能稳定对角化且支持快速核计算。效果：WaLRUS在长时信息保留上显著优于基于HiPPO的SSMs，在延迟重建、分类基准和长序列建模等任务中均有持续改进，为下一代深度SSM模型提供了可扩展且通用的基础。
            arXiv:2506.07920v1 Announce Type: new 
Abstract: State Space Models (SSMs) have emerged as powerful components for sequence modeling, enabling efficient handling of long-range dependencies via linear recurrence and convolutional computation. However, their effectiveness depends heavily on the choice and initialization of the state matrix. In this work, we build on the SaFARi framework and existing WaLRUS SSMs to introduce a new variant, W4S4 (WaLRUS for S4), a new class of SSMs constructed from redundant wavelet frames. WaLRUS admits a stable diagonalization and supports fast kernel computation without requiring low-rank approximations, making it both theoretically grounded and computationally efficient. We show that WaLRUS retains information over long horizons significantly better than HiPPO-based SSMs, both in isolation and when integrated into deep architectures such as S4. Our experiments demonstrate consistent improvements across delay reconstruction tasks, classification benchmarks, and long-range sequence modeling, confirming that high-quality, structured initialization enabled by wavelet-based state dynamic offers substantial advantages over existing alternatives. WaLRUS provides a scalable and versatile foundation for the next generation of deep SSM-based models.
        ]]></description>
    </item>
    <item>
        <title>Mimicking or Reasoning: Rethinking Multi-Modal In-Context Learning in Vision-Language Models</title>
        <link>https://arxiv.org/abs/2506.07936</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07936v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chengyue Huang, Yuchen Zhu, Sichen Zhu, Jingyun Xiao, Moises Andrade, Shivang Chopra, Zsolt Kira</dc:creator>
        <description><![CDATA[
            背景：视觉语言模型（VLMs）被认为具有上下文学习（ICL）能力，但研究表明其常依赖浅层启发式方法而非真正理解任务。方法：在分布偏移情况下评估VLMs，提出新的带推理的多模态上下文学习（MM - ICL）管道，为每个示例添加生成的推理依据。效果：对不同规模开源VLMs和专有模型进行大量实验，结果显示当前VLMs在MM - ICL中未有效利用示例级信息，各因素对性能影响有限。
            arXiv:2506.07936v1 Announce Type: new 
Abstract: Vision-language models (VLMs) are widely assumed to exhibit in-context learning (ICL), a property similar to that of their language-only counterparts. While recent work suggests VLMs can perform multimodal ICL (MM-ICL), studies show they often rely on shallow heuristics -- such as copying or majority voting -- rather than true task understanding. We revisit this assumption by evaluating VLMs under distribution shifts, where support examples come from a dataset different from the query. Surprisingly, performance often degrades with more demonstrations, and models tend to copy answers rather than learn from them. To investigate further, we propose a new MM-ICL with Reasoning pipeline that augments each demonstration with a generated rationale alongside the answer. We conduct extensive and comprehensive experiments on both perception- and reasoning-required datasets with open-source VLMs ranging from 3B to 72B and proprietary models such as Gemini 2.0. We conduct controlled studies varying shot count, retrieval method, rationale quality, and distribution. Our results show limited performance sensitivity across these factors, suggesting that current VLMs do not effectively utilize demonstration-level information as intended in MM-ICL.
        ]]></description>
    </item>
    <item>
        <title>Quantum Graph Transformer for NLP Sentiment Classification</title>
        <link>https://arxiv.org/abs/2506.07937</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07937v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Shamminuj Aktar, Andreas B\"artschi, Abdel-Hameed A. Badawy, Stephan Eidenbenz</dc:creator>
        <description><![CDATA[
            在需理解复杂结构化数据的领域，量子机器学习是构建高效、有表现力模型的有前景方向。本文提出量子图Transformer（QGT），将量子自注意力机制集成到消息传递框架用于结构化语言建模，用参数化量子电路实现注意力机制，减少可训练参数。在五个情感分类基准测试中，QGT比现有量子自然语言处理模型准确率更高或相当，与经典图Transformer相比，在真实和合成数据集上平均准确率分别提升5.42%和4.76%，在Yelp数据集上样本效率提高近50%。
            arXiv:2506.07937v1 Announce Type: new 
Abstract: Quantum machine learning is a promising direction for building more efficient and expressive models, particularly in domains where understanding complex, structured data is critical. We present the Quantum Graph Transformer (QGT), a hybrid graph-based architecture that integrates a quantum self-attention mechanism into the message-passing framework for structured language modeling. The attention mechanism is implemented using parameterized quantum circuits (PQCs), which enable the model to capture rich contextual relationships while significantly reducing the number of trainable parameters compared to classical attention mechanisms. We evaluate QGT on five sentiment classification benchmarks. Experimental results show that QGT consistently achieves higher or comparable accuracy than existing quantum natural language processing (QNLP) models, including both attention-based and non-attention-based approaches. When compared with an equivalent classical graph transformer, QGT yields an average accuracy improvement of 5.42% on real-world datasets and 4.76% on synthetic datasets. Additionally, QGT demonstrates improved sample efficiency, requiring nearly 50% fewer labeled samples to reach comparable performance on the Yelp dataset. These results highlight the potential of graph-based QNLP techniques for advancing efficient and scalable language understanding.
        ]]></description>
    </item>
    <item>
        <title>Decoupling the Image Perception and Multimodal Reasoning for Reasoning Segmentation with Digital Twin Representations</title>
        <link>https://arxiv.org/abs/2506.07943</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07943v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yizhen Li, Dell Zhang, Xuelong Li, Yiqing Shen</dc:creator>
        <description><![CDATA[
            背景：推理分割是多模态视觉文本任务，现有方法在图像标记化时会破坏对象间空间关系。方法：提出DTwinSeger，将推理分割分为两阶段，先把图像转化为保留空间关系和语义属性的结构化数字孪生表示，再用大语言模型推理；还提出针对数字孪生表示的大语言模型监督微调方法及数据集Seg - DT。效果：在两个图像推理分割和三个图像指称分割基准测试中达到了最先进水平，数字孪生表示能有效连接视觉和文本。
            arXiv:2506.07943v1 Announce Type: new 
Abstract: Reasoning Segmentation (RS) is a multimodal vision-text task that requires segmenting objects based on implicit text queries, demanding both precise visual perception and vision-text reasoning capabilities. Current RS approaches rely on fine-tuning vision-language models (VLMs) for both perception and reasoning, but their tokenization of images fundamentally disrupts continuous spatial relationships between objects. We introduce DTwinSeger, a novel RS approach that leverages Digital Twin (DT) representation as an intermediate layer to decouple perception from reasoning. Innovatively, DTwinSeger reformulates RS as a two-stage process, where the first transforms the image into a structured DT representation that preserves spatial relationships and semantic properties and then employs a Large Language Model (LLM) to perform explicit reasoning over this representation to identify target objects. We propose a supervised fine-tuning method specifically for LLM with DT representation, together with a corresponding fine-tuning dataset Seg-DT, to enhance the LLM's reasoning capabilities with DT representations. Experiments show that our method can achieve state-of-the-art performance on two image RS benchmarks and three image referring segmentation benchmarks. It yields that DT representation functions as an effective bridge between vision and text, enabling complex multimodal reasoning tasks to be accomplished solely with an LLM.
        ]]></description>
    </item>
    <item>
        <title>Thinking vs. Doing: Agents that Reason by Scaling Test-Time Interaction</title>
        <link>https://arxiv.org/abs/2506.07976</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07976v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Junhong Shen, Hao Bai, Lunjun Zhang, Yifei Zhou, Amrith Setlur, Shengbang Tong, Diego Caples, Nan Jiang, Tong Zhang, Ameet Talwalkar, Aviral Kumar</dc:creator>
        <description><![CDATA[
            背景：当前测试时间扩展范式在产生响应前生成推理轨迹，但无法从环境获取新信息或随时间调整行为。方法：提出扩展测试时间交互，增加智能体交互范围；以网络智能体为例，先展示无训练的基于提示的交互扩展能提升网络基准任务成功率，再引入基于课程的在线强化学习方法TTI，自适应调整滚动长度来训练智能体。效果：用Gemma 3 12B模型，TTI在WebVoyager和WebArena基准上产生了先进的开源、开放数据网络智能体，还能使智能体自适应平衡探索与利用。
            arXiv:2506.07976v1 Announce Type: new 
Abstract: The current paradigm of test-time scaling relies on generating long reasoning traces ("thinking" more) before producing a response. In agent problems that require interaction, this can be done by generating thinking traces before acting in the world. However, this process does not allow agents to acquire new information from the environment or adapt their behavior over time. In this work, we propose to scale test-time interaction, an untapped dimension of test-time scaling that increases the agent's interaction horizon to enable running rich behaviors such as exploration, backtracking, and dynamic re-planning within a single rollout. To demonstrate the promise of this scaling dimension, we study the domain of web agents. We first show that even prompting-based interaction scaling without any training can improve task success on web benchmarks non-trivially. Building on this, we introduce TTI (Test-Time Interaction), a curriculum-based online reinforcement learning (RL) approach that trains agents by adaptively adjusting their rollout lengths. Using a Gemma 3 12B model, TTI produces state-of-the-art open-source, open-data web agents on WebVoyager and WebArena benchmarks. We further show that TTI enables agents to balance exploration and exploitation adaptively. Our results establish interaction scaling as a powerful, complementary axis to scaling per-step compute, offering new avenues for training adaptive agents.
        ]]></description>
    </item>
    <item>
        <title>Aligning Text, Images, and 3D Structure Token-by-Token</title>
        <link>https://arxiv.org/abs/2506.08002</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08002v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Aadarsh Sahoo, Vansh Tibrewal, Georgia Gkioxari</dc:creator>
        <description><![CDATA[
            背景：使机器具备理解3D世界的能力，对辅助3D环境设计及机器人交互至关重要。方法：受语言和图像建模进展启发，提出统一大语言模型框架，对齐语言、图像和3D场景，给出关键设计选择“指南”；用量化形状编码丰富3D模态以重建复杂3D物体形状。效果：在四个3D核心任务和四个3D数据集上评估，模型在真实3D物体识别任务中有效。
            arXiv:2506.08002v1 Announce Type: new 
Abstract: Creating machines capable of understanding the world in 3D is essential in assisting designers that build and edit 3D environments and robots navigating and interacting within a three-dimensional space. Inspired by advances in language and image modeling, we investigate the potential of autoregressive models for a new modality: structured 3D scenes. To this end, we propose a unified LLM framework that aligns language, images, and 3D scenes and provide a detailed ''cookbook'' outlining critical design choices for achieving optimal training and performance addressing key questions related to data representation, modality-specific objectives, and more. We evaluate performance across four core 3D tasks -- rendering, recognition, instruction-following, and question-answering -- and four 3D datasets, synthetic and real-world. We extend our approach to reconstruct complex 3D object shapes by enriching our 3D modality with quantized shape encodings, and show our model's effectiveness on real-world 3D object recognition tasks. Project webpage: https://glab-caltech.github.io/kyvo/
        ]]></description>
    </item>
    <item>
        <title>Play to Generalize: Learning to Reason Through Game Play</title>
        <link>https://arxiv.org/abs/2506.08011</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08011v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yunfei Xie, Yinsong Ma, Shiyi Lan, Alan Yuille, Junfei Xiao, Chen Wei</dc:creator>
        <description><![CDATA[
            多模态大语言模型开发可泛化推理能力颇具挑战。受认知科学文献启发，本文提出“视觉游戏学习”（ViGaL）后训练范式，让模型通过玩类似街机游戏实现多模态推理的跨领域泛化。研究表明，用强化学习在简单街机游戏（如贪吃蛇）上对70亿参数的多模态大语言模型进行后训练，可显著提升其在多模态数学基准（如MathVista）和多学科问题（如MMMU）上的下游表现。该模型在多模态推理基准上超越经多模态推理数据微调的专业模型，且保留基础模型在通用视觉基准上的性能。
            arXiv:2506.08011v1 Announce Type: new 
Abstract: Developing generalizable reasoning capabilities in multimodal large language models (MLLMs) remains challenging. Motivated by cognitive science literature suggesting that gameplay promotes transferable cognitive skills, we propose a novel post-training paradigm, Visual Game Learning, or ViGaL, where MLLMs develop out-of-domain generalization of multimodal reasoning through playing arcade-like games. Specifically, we show that post-training a 7B-parameter MLLM via reinforcement learning (RL) on simple arcade-like games, e.g. Snake, significantly enhances its downstream performance on multimodal math benchmarks like MathVista, and on multi-discipline questions like MMMU, without seeing any worked solutions, equations, or diagrams during RL, suggesting the capture of transferable reasoning skills. Remarkably, our model outperforms specialist models tuned on multimodal reasoning data in multimodal reasoning benchmarks, while preserving the base model's performance on general visual benchmarks, a challenge where specialist models often fall short. Our findings suggest a new post-training paradigm: synthetic, rule-based games can serve as controllable and scalable pre-text tasks that unlock generalizable multimodal reasoning abilities in MLLMs.
        ]]></description>
    </item>
    <item>
        <title>Amatriciana: Exploiting Temporal GNNs for Robust and Efficient Money Laundering Detection</title>
        <link>https://arxiv.org/abs/2506.00654</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.00654v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Marco Di Gennaro, Francesco Panebianco, Marco Pianta, Stefano Zanero, Michele Carminati</dc:creator>
        <description><![CDATA[
            洗钱作为一种金融犯罪，严重威胁金融安全与社会稳定，交易数量的增长使得有必要利用自动工具来检测此类犯罪活动。本文提出了基于图神经网络的Amatriciana方法，通过考虑时间信息在交易图中检测洗钱者，该方法利用完整交易图，不将其拆分为多个基于时间的子图。实验表明，该模型能从有限数据中学习，数据增多时，其性能优于其他先进方法，F1分数达0.76，假阳性数量相比其他模型降低55%。
            arXiv:2506.00654v1 Announce Type: cross 
Abstract: Money laundering is a financial crime that poses a serious threat to financial integrity and social security. The growing number of transactions makes it necessary to use automatic tools that help law enforcement agencies detect such criminal activity. In this work, we present Amatriciana, a novel approach based on Graph Neural Networks to detect money launderers inside a graph of transactions by considering temporal information. Amatriciana uses the whole graph of transactions without splitting it into several time-based subgraphs, exploiting all relational information in the dataset. Our experiments on a public dataset reveal that the model can learn from a limited amount of data. Furthermore, when more data is available, the model outperforms other State-of-the-art approaches; in particular, Amatriciana decreases the number of False Positives (FPs) while detecting many launderers. In summary, Amatriciana achieves an F1 score of 0.76. In addition, it lowers the FPs by 55% with respect to other State-of-the-art models.
        ]]></description>
    </item>
    <item>
        <title>DELPHYNE: A Pre-Trained Model for General and Financial Time Series</title>
        <link>https://arxiv.org/abs/2506.06288</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06288v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xueying Ding, Aakriti Mittal, Achintya Gopal</dc:creator>
        <description><![CDATA[
            时间序列数据在数据科学尤其是金融领域至关重要。现有时间序列预训练模型在金融应用中表现不佳，原因一是预训练阶段缺乏金融数据，二是不同领域时间序列模式不同有负迁移效应，且时间序列数据难建模。为此，研究人员提出用于金融时间序列的预训练模型Delphyne。该模型在公开数据集上只需少量微调步骤就能取得与现有基础模型和全样本模型相当的性能，在多种金融任务中表现更优。
            arXiv:2506.06288v1 Announce Type: cross 
Abstract: Time-series data is a vital modality within data science communities. This is particularly valuable in financial applications, where it helps in detecting patterns, understanding market behavior, and making informed decisions based on historical data. Recent advances in language modeling have led to the rise of time-series pre-trained models that are trained on vast collections of datasets and applied to diverse tasks across financial domains. However, across financial applications, existing time-series pre-trained models have not shown boosts in performance over simple finance benchmarks in both zero-shot and fine-tuning settings. This phenomenon occurs because of a i) lack of financial data within the pre-training stage, and ii) the negative transfer effect due to inherently different time-series patterns across domains. Furthermore, time-series data is continuous, noisy, and can be collected at varying frequencies and with varying lags across different variables, making this data more challenging to model than languages. To address the above problems, we introduce a Pre-trained MoDEL for FINance TimE-series (Delphyne). Delphyne achieves competitive performance to existing foundation and full-shot models with few fine-tuning steps on publicly available datasets, and also shows superior performances on various financial tasks.
        ]]></description>
    </item>
    <item>
        <title>ChemGraph: An Agentic Framework for Computational Chemistry Workflows</title>
        <link>https://arxiv.org/abs/2506.06363</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06363v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Thang D. Pham, Aditya Tanikanti, Murat Ke\c{c}eli</dc:creator>
        <description><![CDATA[
            背景：原子模拟在化学和材料科学中很重要，但运行模拟因计算方法多、软件生态多样等存在挑战。方法：提出ChemGraph框架，利用基于图神经网络的基础模型进行计算，结合大语言模型实现自然语言理解、任务规划和科学推理，还可将复杂任务分解为子任务。效果：在13个基准任务中评估，小模型在简单工作流表现好，复杂任务大模型更优，且多智能体框架下小模型在特定场景能媲美或超越大模型。
            arXiv:2506.06363v1 Announce Type: cross 
Abstract: Atomistic simulations are essential tools in chemistry and materials science, accelerating the discovery of novel catalysts, energy storage materials, and pharmaceuticals. However, running these simulations remains challenging due to the wide range of computational methods, diverse software ecosystems, and the need for expert knowledge and manual effort for the setup, execution, and validation stages. In this work, we present ChemGraph, an agentic framework powered by artificial intelligence and state-of-the-art simulation tools to streamline and automate computational chemistry and materials science workflows. ChemGraph leverages graph neural network-based foundation models for accurate yet computationally efficient calculations and large language models (LLMs) for natural language understanding, task planning, and scientific reasoning to provide an intuitive and interactive interface. Users can perform tasks such as molecular structure generation, single-point energy, geometry optimization, vibrational analysis, and thermochemistry calculations with methods ranging from tight-binding and machine learning interatomic potentials to density functional theory or wave function theory-based methods. We evaluate ChemGraph across 13 benchmark tasks and demonstrate that smaller LLMs (GPT-4o-mini, Claude-3.5-haiku, Qwen2.5-14B) perform well on simple workflows, while more complex tasks benefit from using larger models like GPT-4o. Importantly, we show that decomposing complex tasks into smaller subtasks through a multi-agent framework enables smaller LLM models to match or exceed GPT-4o's performance in specific scenarios.
        ]]></description>
    </item>
    <item>
        <title>SIGMA: Refining Large Language Model Reasoning via Sibling-Guided Monte Carlo Augmentation</title>
        <link>https://arxiv.org/abs/2506.06470</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06470v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yanwei Ren, Haotian Zhang, Fuxiang Wu, Jiayan Qiu, Jiaxing Huang, Baosheng Yu, Liu Liu</dc:creator>
        <description><![CDATA[
            背景：单纯扩大数据集来增强大语言模型收益递减，传统蒙特卡罗树搜索仅保留搜索树中得分最高的轨迹，丢弃有价值的兄弟节点。方法：提出SIGMA框架，重新整合被丢弃的兄弟节点，在每个搜索路径上建立兄弟节点的语义链接，并进行两阶段细化，即批判模型识别优缺点，修订模型进行基于文本的反向传播。效果：在MATH基准测试中，SIGMA调优的7B模型仅用30K样本就达到54.92%的准确率，优于用590K样本训练的模型，减少数据使用并提升推理能力。
            arXiv:2506.06470v1 Announce Type: cross 
Abstract: Enhancing large language models by simply scaling up datasets has begun to yield diminishing returns, shifting the spotlight to data quality. Monte Carlo Tree Search (MCTS) has emerged as a powerful technique for generating high-quality chain-of-thought data, yet conventional approaches typically retain only the top-scoring trajectory from the search tree, discarding sibling nodes that often contain valuable partial insights, recurrent error patterns, and alternative reasoning strategies. This unconditional rejection of non-optimal reasoning branches may waste vast amounts of informative data in the whole search tree. We propose SIGMA (Sibling Guided Monte Carlo Augmentation), a novel framework that reintegrates these discarded sibling nodes to refine LLM reasoning. SIGMA forges semantic links among sibling nodes along each search path and applies a two-stage refinement: a critique model identifies overlooked strengths and weaknesses across the sibling set, and a revision model conducts text-based backpropagation to refine the top-scoring trajectory in light of this comparative feedback. By recovering and amplifying the underutilized but valuable signals from non-optimal reasoning branches, SIGMA substantially improves reasoning trajectories. On the challenging MATH benchmark, our SIGMA-tuned 7B model achieves 54.92% accuracy using only 30K samples, outperforming state-of-the-art models trained on 590K samples. This result highlights that our sibling-guided optimization not only significantly reduces data usage but also significantly boosts LLM reasoning.
        ]]></description>
    </item>
    <item>
        <title>WorldLLM: Improving LLMs' world modeling using curiosity-driven theory-making</title>
        <link>https://arxiv.org/abs/2506.06725</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06725v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Guillaume Levy, Cedric Colas, Pierre-Yves Oudeyer, Thomas Carta, Clement Romac</dc:creator>
        <description><![CDATA[
            大语言模型虽有通用世界知识，但在结构化、特定领域环境中难以做出精准预测，原因在于其无法将宽泛、非结构化理解与特定环境结合。为此提出WorldLLM框架，结合贝叶斯推理、自主主动探索与强化学习提升基于大语言模型的世界建模。利用大语言模型上下文学习能力，以自然语言假设引导预测，并通过贝叶斯推理框架迭代优化假设。实验表明，该框架在文本游戏环境中有效，既提高预测准确性，又能生成人类可解释的环境动态理论。
            arXiv:2506.06725v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) possess general world knowledge but often struggle to generate precise predictions in structured, domain-specific contexts such as simulations. These limitations arise from their inability to ground their broad, unstructured understanding in specific environments. To address this, we present WorldLLM, a framework that enhances LLM-based world modeling by combining Bayesian inference and autonomous active exploration with reinforcement learning. WorldLLM leverages the in-context learning abilities of LLMs to guide an LLM-based world model's predictions using natural language hypotheses given in its prompt. These hypotheses are iteratively refined through a Bayesian inference framework that leverages a second LLM as the proposal distribution given collected evidence. This evidence is collected using a curiosity-driven reinforcement learning policy that explores the environment to find transitions with a low log-likelihood under our LLM-based predictive model using the current hypotheses. By alternating between refining hypotheses and collecting new evidence, our framework autonomously drives continual improvement of the predictions. Our experiments demonstrate the effectiveness of WorldLLM in a textual game environment that requires agents to manipulate and combine objects. The framework not only enhances predictive accuracy, but also generates human-interpretable theories of environment dynamics.
        ]]></description>
    </item>
    <item>
        <title>Multimodal Spatial Language Maps for Robot Navigation and Manipulation</title>
        <link>https://arxiv.org/abs/2506.06862</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06862v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chenguang Huang, Oier Mees, Andy Zeng, Wolfram Burgard</dc:creator>
        <description><![CDATA[
            背景：以往将语言与导航代理观察关联的方法存在与环境映射脱节、缺乏几何地图空间精度等问题。方法：提出多模态空间语言地图，融合预训练多模态特征与环境3D重建，通过标准探索自主构建，有视觉 - 语言地图（VLMaps）及其扩展的视听 - 语言地图（AVLMaps）。效果：VLMaps可将自然语言命令转化为空间目标，AVLMaps能将多模态目标查询定位到空间位置，实验表明该地图能实现零样本空间和多模态目标导航，在模糊场景中召回率提高50% 。
            arXiv:2506.06862v1 Announce Type: cross 
Abstract: Grounding language to a navigating agent's observations can leverage pretrained multimodal foundation models to match perceptions to object or event descriptions. However, previous approaches remain disconnected from environment mapping, lack the spatial precision of geometric maps, or neglect additional modality information beyond vision. To address this, we propose multimodal spatial language maps as a spatial map representation that fuses pretrained multimodal features with a 3D reconstruction of the environment. We build these maps autonomously using standard exploration. We present two instances of our maps, which are visual-language maps (VLMaps) and their extension to audio-visual-language maps (AVLMaps) obtained by adding audio information. When combined with large language models (LLMs), VLMaps can (i) translate natural language commands into open-vocabulary spatial goals (e.g., "in between the sofa and TV") directly localized in the map, and (ii) be shared across different robot embodiments to generate tailored obstacle maps on demand. Building upon the capabilities above, AVLMaps extend VLMaps by introducing a unified 3D spatial representation integrating audio, visual, and language cues through the fusion of features from pretrained multimodal foundation models. This enables robots to ground multimodal goal queries (e.g., text, images, or audio snippets) to spatial locations for navigation. Additionally, the incorporation of diverse sensory inputs significantly enhances goal disambiguation in ambiguous environments. Experiments in simulation and real-world settings demonstrate that our multimodal spatial language maps enable zero-shot spatial and multimodal goal navigation and improve recall by 50% in ambiguous scenarios. These capabilities extend to mobile robots and tabletop manipulators, supporting navigation and interaction guided by visual, audio, and spatial cues.
        ]]></description>
    </item>
    <item>
        <title>Mitigating Behavioral Hallucination in Multimodal Large Language Models for Sequential Images</title>
        <link>https://arxiv.org/abs/2506.07184</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07184v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Liangliang You, Junchi Yao, Shu Yang, Guimin Hu, Lijie Hu, Di Wang</dc:creator>
        <description><![CDATA[
            多模态大语言模型虽表现出色，但存在幻觉问题，限制其可靠性与扩展性。此前研究多关注客观幻觉，而序列图像中的行为幻觉研究较少。本文揭示行为幻觉源于先验驱动偏差和雪球效应，提出轻量级两阶段框架SHE，先通过自适应时间窗口进行视觉 - 文本对齐检查检测幻觉，再通过正交投影到联合嵌入空间缓解幻觉，还提出新指标BEACH量化严重程度。实验表明，SHE使BEACH上的行为幻觉降低超10%，并保持描述准确性。
            arXiv:2506.07184v1 Announce Type: cross 
Abstract: While multimodal large language models excel at various tasks, they still suffer from hallucinations, which limit their reliability and scalability for broader domain applications. To address this issue, recent research mainly focuses on objective hallucination. However, for sequential images, besides objective hallucination, there is also behavioral hallucination, which is less studied. This work aims to fill in the gap. We first reveal that behavioral hallucinations mainly arise from two key factors: prior-driven bias and the snowball effect. Based on these observations, we introduce SHE (Sequence Hallucination Eradication), a lightweight, two-stage framework that (1) detects hallucinations via visual-textual alignment check using our proposed adaptive temporal window and (2) mitigates them via orthogonal projection onto the joint embedding space. We also propose a new metric (BEACH) to quantify behavioral hallucination severity. Empirical results on standard benchmarks demonstrate that SHE reduces behavioral hallucination by over 10% on BEACH while maintaining descriptive accuracy.
        ]]></description>
    </item>
    <item>
        <title>HOI-PAGE: Zero-Shot Human-Object Interaction Generation with Part Affordance Guidance</title>
        <link>https://arxiv.org/abs/2506.07209</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07209v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Lei Li, Angela Dai</dc:creator>
        <description><![CDATA[
            背景：现有4D人体与物体交互（HOI）合成研究多关注整体运动，生成逼真多样的HOI需细粒度理解。方法：提出HOI - PAGE方法，引入从大语言模型提炼的结构化表征Part Affordance Graphs（PAGs），用其指导三阶段合成，包括分解3D物体、生成参考视频提取运动约束、优化4D HOI运动序列。效果：实验表明该方法灵活，能生成复杂交互序列，零样本4D HOI生成的逼真度和文本对齐度显著提升。
            arXiv:2506.07209v1 Announce Type: cross 
Abstract: We present HOI-PAGE, a new approach to synthesizing 4D human-object interactions (HOIs) from text prompts in a zero-shot fashion, driven by part-level affordance reasoning. In contrast to prior works that focus on global, whole body-object motion for 4D HOI synthesis, we observe that generating realistic and diverse HOIs requires a finer-grained understanding -- at the level of how human body parts engage with object parts. We thus introduce Part Affordance Graphs (PAGs), a structured HOI representation distilled from large language models (LLMs) that encodes fine-grained part information along with contact relations. We then use these PAGs to guide a three-stage synthesis: first, decomposing input 3D objects into geometric parts; then, generating reference HOI videos from text prompts, from which we extract part-based motion constraints; finally, optimizing for 4D HOI motion sequences that not only mimic the reference dynamics but also satisfy part-level contact constraints. Extensive experiments show that our approach is flexible and capable of generating complex multi-object or multi-person interaction sequences, with significantly improved realism and text alignment for zero-shot 4D HOI generation.
        ]]></description>
    </item>
    <item>
        <title>G-Memory: Tracing Hierarchical Memory for Multi-Agent Systems</title>
        <link>https://arxiv.org/abs/2506.07398</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07398v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Guibin Zhang, Muxin Fu, Guancheng Wan, Miao Yu, Kun Wang, Shuicheng Yan</dc:creator>
        <description><![CDATA[
            背景：大语言模型驱动的多智能体系统虽能力强，但因记忆架构不完善，自我进化能力受限，现有记忆机制过于简单且缺乏定制。方法：受组织记忆理论启发，提出G - Memory这一层次化、智能体式的记忆系统，通过三层图层次管理多智能体交互，接收新查询时双向遍历记忆。效果：在五个基准测试等实验中，不修改原框架的情况下，使具身行动成功率最高提升20.89%，知识问答准确率最高提升10.12%。
            arXiv:2506.07398v1 Announce Type: cross 
Abstract: Large language model (LLM)-powered multi-agent systems (MAS) have demonstrated cognitive and execution capabilities that far exceed those of single LLM agents, yet their capacity for self-evolution remains hampered by underdeveloped memory architectures. Upon close inspection, we are alarmed to discover that prevailing MAS memory mechanisms (1) are overly simplistic, completely disregarding the nuanced inter-agent collaboration trajectories, and (2) lack cross-trial and agent-specific customization, in stark contrast to the expressive memory developed for single agents. To bridge this gap, we introduce G-Memory, a hierarchical, agentic memory system for MAS inspired by organizational memory theory, which manages the lengthy MAS interaction via a three-tier graph hierarchy: insight, query, and interaction graphs. Upon receiving a new user query, G-Memory performs bi-directional memory traversal to retrieve both $\textit{high-level, generalizable insights}$ that enable the system to leverage cross-trial knowledge, and $\textit{fine-grained, condensed interaction trajectories}$ that compactly encode prior collaboration experiences. Upon task execution, the entire hierarchy evolves by assimilating new collaborative trajectories, nurturing the progressive evolution of agent teams. Extensive experiments across five benchmarks, three LLM backbones, and three popular MAS frameworks demonstrate that G-Memory improves success rates in embodied action and accuracy in knowledge QA by up to $20.89\%$ and $10.12\%$, respectively, without any modifications to the original frameworks. Our codes are available at https://github.com/bingreeky/GMemory.
        ]]></description>
    </item>
    <item>
        <title>Beyond Jailbreaks: Revealing Stealthier and Broader LLM Security Risks Stemming from Alignment Failures</title>
        <link>https://arxiv.org/abs/2506.07402</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07402v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yukai Zhou, Sibei Yang, Wenjie Wang</dc:creator>
        <description><![CDATA[
            背景：大语言模型在现实应用中日益广泛，其安全性备受关注，以往越狱攻击忽视了无害输入可能带来的隐性危害。方法：从输出事实性和输入无害性的结构化象限视角重新审视大语言模型风险格局，提出用于捕捉隐性危害的JailFlipBench基准，涵盖单模态、多模态等场景并采用多样评估指标，还开发了初始JailFlip攻击方法。效果：通过对多个开源和黑盒大语言模型的评估，表明隐性危害存在紧迫的现实风险，呼吁更广泛的大语言模型安全评估和对齐。
            arXiv:2506.07402v1 Announce Type: cross 
Abstract: Large language models (LLMs) are increasingly deployed in real-world applications, raising concerns about their security. While jailbreak attacks highlight failures under overtly harmful queries, they overlook a critical risk: incorrectly answering harmless-looking inputs can be dangerous and cause real-world harm (Implicit Harm). We systematically reformulate the LLM risk landscape through a structured quadrant perspective based on output factuality and input harmlessness, uncovering an overlooked high-risk region. To investigate this gap, we propose JailFlipBench, a benchmark aims to capture implicit harm, spanning single-modal, multimodal, and factual extension scenarios with diverse evaluation metrics. We further develop initial JailFlip attack methodologies and conduct comprehensive evaluations across multiple open-source and black-box LLMs, show that implicit harm present immediate and urgent real-world risks, calling for broader LLM safety assessments and alignment beyond conventional jailbreak paradigms.
        ]]></description>
    </item>
    <item>
        <title>HeTa: Relation-wise Heterogeneous Graph Foundation Attack Model</title>
        <link>https://arxiv.org/abs/2506.07428</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07428v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuling Wang, Zihui Chen, Pengfei Jiao, Xiao Wang</dc:creator>
        <description><![CDATA[
            背景：异构图神经网络（HGNNs）易受攻击，现有攻击方法需复杂参数重训，而基础模型为图神经网络泛化带来新可能。方法：提出关系异构图基础攻击模型HeTa，引入基础替代模型对齐异质性、识别共享关系感知攻击单元重要性，基于识别的关系权重实施序列化逐关系攻击。效果：实验表明该方法具有强大攻击性能和泛化能力。
            arXiv:2506.07428v1 Announce Type: cross 
Abstract: Heterogeneous Graph Neural Networks (HGNNs) are vulnerable, highlighting the need for tailored attacks to assess their robustness and ensure security. However, existing HGNN attacks often require complex retraining of parameters to generate specific perturbations for new scenarios. Recently, foundation models have opened new horizons for the generalization of graph neural networks by capturing shared semantics across various graph distributions. This leads us to ask:Can we design a foundation attack model for HGNNs that enables generalizable perturbations across different HGNNs, and quickly adapts to new heterogeneous graphs (HGs)? Empirical findings reveal that, despite significant differences in model design and parameter space, different HGNNs surprisingly share common vulnerability patterns from a relation-aware perspective. Therefore, we explore how to design foundation HGNN attack criteria by mining shared attack units. In this paper, we propose a novel relation-wise heterogeneous graph foundation attack model, HeTa. We introduce a foundation surrogate model to align heterogeneity and identify the importance of shared relation-aware attack units. Building on this, we implement a serialized relation-by-relation attack based on the identified relational weights. In this way, the perturbation can be transferred to various target HGNNs and easily fine-tuned for new HGs. Extensive experiments exhibit powerful attack performances and generalizability of our method.
        ]]></description>
    </item>
    <item>
        <title>LlamaRec-LKG-RAG: A Single-Pass, Learnable Knowledge Graph-RAG Framework for LLM-Based Ranking</title>
        <link>https://arxiv.org/abs/2506.07449</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07449v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Vahid Azizi, Fatemeh Koochaki</dc:creator>
        <description><![CDATA[
            背景：现有基于大语言模型的检索增强生成（RAG）推荐系统方法多依赖平面、基于相似度的检索，未利用用户 - 项目交互中的丰富关系结构。方法：提出LlamaRec - LKG - RAG框架，将个性化知识图谱上下文集成到基于大语言模型的推荐排序中，通过轻量级用户偏好模块识别异质知识图谱中的显著关系路径，并将其集成到微调的Llama - 2模型提示中。效果：在ML - 100K和亚马逊美妆数据集上，关键排序指标（MRR、NDCG、Recall）均有显著提升。
            arXiv:2506.07449v1 Announce Type: cross 
Abstract: Recent advances in Large Language Models (LLMs) have driven their adoption in recommender systems through Retrieval-Augmented Generation (RAG) frameworks. However, existing RAG approaches predominantly rely on flat, similarity-based retrieval that fails to leverage the rich relational structure inherent in user-item interactions. We introduce LlamaRec-LKG-RAG, a novel single-pass, end-to-end trainable framework that integrates personalized knowledge graph context into LLM-based recommendation ranking. Our approach extends the LlamaRec architecture by incorporating a lightweight user preference module that dynamically identifies salient relation paths within a heterogeneous knowledge graph constructed from user behavior and item metadata. These personalized subgraphs are seamlessly integrated into prompts for a fine-tuned Llama-2 model, enabling efficient and interpretable recommendations through a unified inference step. Comprehensive experiments on ML-100K and Amazon Beauty datasets demonstrate consistent and significant improvements over LlamaRec across key ranking metrics (MRR, NDCG, Recall). LlamaRec-LKG-RAG demonstrates the critical value of structured reasoning in LLM-based recommendations and establishes a foundation for scalable, knowledge-aware personalization in next-generation recommender systems. Code is available at~\href{https://github.com/VahidAz/LlamaRec-LKG-RAG}{repository}.
        ]]></description>
    </item>
    <item>
        <title>Evaluating Large Language Models on the Frame and Symbol Grounding Problems: A Zero-shot Benchmark</title>
        <link>https://arxiv.org/abs/2506.07896</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07896v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Shoko Oka</dc:creator>
        <description><![CDATA[
            背景：大语言模型的发展使人工智能相关哲学辩论复兴，框架问题和符号接地问题在传统符号人工智能系统中被认为难以解决。方法：设计两个反映问题核心的基准任务，在零样本条件下对13个大语言模型进行测试，评估其输出质量。效果：开源模型因多种因素表现有差异，部分闭源模型多次测试中得分高，表明部分现代大语言模型有能力应对这些理论挑战。
            arXiv:2506.07896v1 Announce Type: cross 
Abstract: Recent advancements in large language models (LLMs) have revitalized philosophical debates surrounding artificial intelligence. Two of the most fundamental challenges - namely, the Frame Problem and the Symbol Grounding Problem - have historically been viewed as unsolvable within traditional symbolic AI systems. This study investigates whether modern LLMs possess the cognitive capacities required to address these problems. To do so, I designed two benchmark tasks reflecting the philosophical core of each problem, administered them under zero-shot conditions to 13 prominent LLMs (both closed and open-source), and assessed the quality of the models' outputs across five trials each. Responses were scored along multiple criteria, including contextual reasoning, semantic coherence, and information filtering. The results demonstrate that while open-source models showed variability in performance due to differences in model size, quantization, and instruction tuning, several closed models consistently achieved high scores. These findings suggest that select modern LLMs may be acquiring capacities sufficient to produce meaningful and stable responses to these long-standing theoretical challenges.
        ]]></description>
    </item>
    <item>
        <title>GUI-Reflection: Empowering Multimodal GUI Models with Self-Reflection Behavior</title>
        <link>https://arxiv.org/abs/2506.08012</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.08012v1</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Penghao Wu, Shengnan Ma, Bo Wang, Jiaheng Yu, Lewei Lu, Ziwei Liu</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型在图形用户界面（GUI）自动化方面潜力巨大，但现有GUI模型大多依赖无错误轨迹学习，缺乏反思和纠错能力。方法：提出GUI - Reflection框架，在特定训练阶段将反思和纠错能力集成到端到端多模态GUI模型中，包括构建数据管道、提出任务套件、搭建训练环境、设计迭代算法。效果：该框架赋予GUI代理反思和纠错能力，为更强大、自适应和智能的GUI自动化奠定基础，相关数据、模型等将公开。
            arXiv:2506.08012v1 Announce Type: cross 
Abstract: Multimodal Large Language Models (MLLMs) have shown great potential in revolutionizing Graphical User Interface (GUI) automation. However, existing GUI models mostly rely on learning from nearly error-free offline trajectories, thus lacking reflection and error recovery capabilities. To bridge this gap, we propose GUI-Reflection, a novel framework that explicitly integrates self-reflection and error correction capabilities into end-to-end multimodal GUI models throughout dedicated training stages: GUI-specific pre-training, offline supervised fine-tuning (SFT), and online reflection tuning. GUI-reflection enables self-reflection behavior emergence with fully automated data generation and learning processes without requiring any human annotation. Specifically, 1) we first propose scalable data pipelines to automatically construct reflection and error correction data from existing successful trajectories. While existing GUI models mainly focus on grounding and UI understanding ability, we propose the GUI-Reflection Task Suite to learn and evaluate reflection-oriented abilities explicitly. 2) Furthermore, we built a diverse and efficient environment for online training and data collection of GUI models on mobile devices. 3) We also present an iterative online reflection tuning algorithm leveraging the proposed environment, enabling the model to continuously enhance its reflection and error correction abilities. Our framework equips GUI agents with self-reflection and correction capabilities, paving the way for more robust, adaptable, and intelligent GUI automation, with all data, models, environments, and tools to be released publicly.
        ]]></description>
    </item>
    <item>
        <title>R-FORCE: Robust Learning for Random Recurrent Neural Networks</title>
        <link>https://arxiv.org/abs/2003.11660</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2003.11660v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yang Zheng, Eli Shlizerman</dc:creator>
        <description><![CDATA[
            背景：随机递归神经网络（RRNN）是处理序列数据的简单网络，但用基于梯度下降的优化方法训练时易出现梯度消失或爆炸问题。方法：研究通过推断约束网络雅可比矩阵谱保持在稳定区域的四个生成原则生成特定分布来初始化RRNN连接，结合FORCE学习提出R - FORCE训练方法。效果：实验表明R - FORCE能为多种RRNN实现更稳定、准确的目标学习，在对人体关节运动时间序列建模等多维序列建模中稳定性关键。
            arXiv:2003.11660v2 Announce Type: replace 
Abstract: Random Recurrent Neural Networks (RRNN) are the simplest recurrent networks to model and extract features from sequential data. The simplicity however comes with a price; RRNN are known to be susceptible to diminishing/exploding gradient problem when trained with gradient-descent based optimization. To enhance robustness of RRNN, alternative training approaches have been proposed. Specifically, FORCE learning approach proposed a recursive least squares alternative to train RRNN and was shown to be applicable even for the challenging task of target-learning, where the network is tasked with generating dynamic patterns with no guiding input. While FORCE training indicates that solving target-learning is possible, it appears to be effective only in a specific regime of network dynamics (edge-of-chaos). We thereby investigate whether initialization of RRNN connectivity according to a tailored distribution can guarantee robust FORCE learning. We are able to generate such distribution by inference of four generating principles constraining the spectrum of the network Jacobian to remain in stability region. This initialization along with FORCE learning provides a robust training method, i.e., Robust-FORCE (R-FORCE). We validate R-FORCE performance on various target functions for a wide range of network configurations and compare with alternative methods. Our experiments indicate that R-FORCE facilitates significantly more stable and accurate target-learning for a wide class of RRNN. Such stability becomes critical in modeling multi-dimensional sequences as we demonstrate on modeling time-series of human body joints during physical movements.
        ]]></description>
    </item>
    <item>
        <title>Rational Decision-Making Agent with Internalized Utility Judgment</title>
        <link>https://arxiv.org/abs/2308.12519</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2308.12519v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yining Ye, Xin Cong, Shizuo Tian, Yujia Qin, Chong Liu, Yankai Lin, Zhiyuan Liu, Maosong Sun</dc:creator>
        <description><![CDATA[
            背景：大语言模型在决策任务中有显著进展，但现有基于大语言模型的决策方法多依赖手动设计的外部性能指标，在现实场景中存在问题，真正的自主决策需从后续经验中发展理性判断。方法：提出RadAgent，通过包含经验探索和效用学习的迭代框架发展理性，采用基于Elo的效用构建为决策步骤分配Elo分数。效果：在ToolBench数据集实验中，RadAgent优于基线，不同任务通过率提高超10%，能提供更高质量方案并降低成本。
            arXiv:2308.12519v3 Announce Type: replace 
Abstract: Large language models (LLMs) have demonstrated remarkable advancements and have attracted significant efforts to develop LLMs into agents capable of executing intricate multi-step decision-making tasks beyond traditional NLP applications. Existing approaches to LLM-based decision-making predominantly build upon the manually-designed external performance metrics to guide the decision-making process. However, reliance on the external performance metrics as prior is problematic in real-world scenarios, where such prior may be unavailable, flawed, or even erroneous. For genuine autonomous decision making, it is imperative for the agent to develop its rationality from its posterior experiences to judge decisions independently. Central to the development of rationality is the construction of an internalized utility judgment, capable of assigning numerical utilities to each decision. This paper proposes RadAgent (Rational Decision-Making Agent), which fosters the development of its rationality through an iterative framework involving Experience Exploration and Utility Learning. Within this framework, Elo-based Utility Construction is devised to assign Elo scores to individual decision steps to judge their utilities via pairwise comparisons. Consequently, these Elo scores guide the decision-making process to derive optimal outcomes. Experimental results on the ToolBench dataset demonstrate RadAgent's superiority over baselines, achieving over 10% improvement in Pass Rate on diverse tasks. It offers higher-quality solutions and reduces costs (ChatGPT API calls), highlighting its effectiveness and efficiency.
        ]]></description>
    </item>
    <item>
        <title>Link Prediction with Relational Hypergraphs</title>
        <link>https://arxiv.org/abs/2402.04062</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2402.04062v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xingyue Huang, Miguel Romero Orth, Pablo Barcel\'o, Michael M. Bronstein, \.Ismail \.Ilkan Ceylan</dc:creator>
        <description><![CDATA[
            在图机器学习中，知识图谱的链接预测已被深入研究，但将相关架构的成功经验迁移到关系超图上仍具挑战，关系超图的链接预测任务针对 $k$ 元关系，难度更大。为此，本文提出关系超图链接预测框架，使图神经网络可应用于全关系结构。理论上，通过关系魏斯费勒 - 莱曼算法和逻辑表达能力分析模型架构的表达能力；实证上，在多个关系超图基准测试中验证其能力，该架构在归纳式链接预测中大幅超越基线，在直推式链接预测中达最优。
            arXiv:2402.04062v3 Announce Type: replace 
Abstract: Link prediction with knowledge graphs has been thoroughly studied in graph machine learning, leading to a rich landscape of graph neural network architectures with successful applications. Nonetheless, it remains challenging to transfer the success of these architectures to relational hypergraphs, where the task of link prediction is over $k$-ary relations, which is substantially harder than link prediction with knowledge graphs. In this paper, we propose a framework for link prediction with relational hypergraphs, unlocking applications of graph neural networks to fully relational structures. Theoretically, we conduct a thorough analysis of the expressive power of the resulting model architectures via corresponding relational Weisfeiler-Leman algorithms and also via logical expressiveness. Empirically, we validate the power of the proposed model architectures on various relational hypergraph benchmarks. The resulting model architectures substantially outperform every baseline for inductive link prediction, and lead to state-of-the-art results for transductive link prediction.
        ]]></description>
    </item>
    <item>
        <title>Equivariant Denoisers Cannot Copy Graphs: Align Your Graph Diffusion Models</title>
        <link>https://arxiv.org/abs/2405.17656</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2405.17656v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Najwa Laabid, Severi Rissanen, Markus Heinonen, Arno Solin, Vikas Garg</dc:creator>
        <description><![CDATA[
            背景：图扩散模型在图生成建模中占主导，但在图到图转换任务如化学反应预测方面研究不足，标准排列等变去噪器因无法打破噪声输入的对称性而受限。方法：提出对齐输入和目标图以打破输入对称性，同时在不匹配的图部分保留排列等变性。效果：在逆合成任务中，显著提升离散扩散模型性能，将top - 1准确率从5%提高到54.7%，达到了当前最优水平。
            arXiv:2405.17656v2 Announce Type: replace 
Abstract: Graph diffusion models, dominant in graph generative modeling, remain underexplored for graph-to-graph translation tasks like chemical reaction prediction. We demonstrate that standard permutation equivariant denoisers face fundamental limitations in these tasks due to their inability to break symmetries in noisy inputs. To address this, we propose aligning input and target graphs to break input symmetries while preserving permutation equivariance in non-matching graph portions. Using retrosynthesis (i.e., the task of predicting precursors for synthesis of a given target molecule) as our application domain, we show how alignment dramatically improves discrete diffusion model performance from 5% to a SOTA-matching 54.7% top-1 accuracy. Code is available at https://github.com/Aalto-QuML/DiffAlign.
        ]]></description>
    </item>
    <item>
        <title>MMScan: A Multi-Modal 3D Scene Dataset with Hierarchical Grounded Language Annotations</title>
        <link>https://arxiv.org/abs/2406.09401</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2406.09401v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ruiyuan Lyu, Jingli Lin, Tai Wang, Shuai Yang, Xiaohan Mao, Yilun Chen, Runsen Xu, Haifeng Huang, Chenming Zhu, Dahua Lin, Jiangmiao Pang</dc:creator>
        <description><![CDATA[
            背景：大语言模型与其他数据模态融合使多模态3D感知受关注，但现有数据集有限，此前研究多聚焦3D场景中物体属性或空间关系。方法：构建首个带分层语言注释的多模态3D场景数据集MMScan，基于自上而下逻辑，结合强大视觉语言模型和人工修正。效果：数据集包含140万条元注释说明、10.9万个物体、7700个区域及超304万个多样样本，用其训练模型在现有基准和实际评估中性能显著提升。
            arXiv:2406.09401v2 Announce Type: replace 
Abstract: With the emergence of LLMs and their integration with other data modalities, multi-modal 3D perception attracts more attention due to its connectivity to the physical world and makes rapid progress. However, limited by existing datasets, previous works mainly focus on understanding object properties or inter-object spatial relationships in a 3D scene. To tackle this problem, this paper builds the first largest ever multi-modal 3D scene dataset and benchmark with hierarchical grounded language annotations, MMScan. It is constructed based on a top-down logic, from region to object level, from a single target to inter-target relationships, covering holistic aspects of spatial and attribute understanding. The overall pipeline incorporates powerful VLMs via carefully designed prompts to initialize the annotations efficiently and further involve humans' correction in the loop to ensure the annotations are natural, correct, and comprehensive. Built upon existing 3D scanning data, the resulting multi-modal 3D dataset encompasses 1.4M meta-annotated captions on 109k objects and 7.7k regions as well as over 3.04M diverse samples for 3D visual grounding and question-answering benchmarks. We evaluate representative baselines on our benchmarks, analyze their capabilities in different aspects, and showcase the key problems to be addressed in the future. Furthermore, we use this high-quality dataset to train state-of-the-art 3D visual grounding and LLMs and obtain remarkable performance improvement both on existing benchmarks and in-the-wild evaluation. Codes, datasets, and benchmarks will be available at https://github.com/OpenRobotLab/EmbodiedScan.
        ]]></description>
    </item>
    <item>
        <title>ZeroDL: Zero-shot Distribution Learning for Text Clustering via Large Language Models</title>
        <link>https://arxiv.org/abs/2406.13342</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2406.13342v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hwiyeol Jo, Hyunwoo Lee, Kang Min Yoo, Taiwoo Park</dc:creator>
        <description><![CDATA[
            背景：大语言模型虽在NLP任务中取得显著进展，但当任务无法在提示中完整描述时，模型可能无法完成任务。方法：提出一种简单有效的向大语言模型情境化任务的方法，包括从整个数据集进行开放式零样本推理、聚合推理结果，最后将聚合的元信息用于实际任务。效果：在文本聚类任务中展现出有效性，使大语言模型能够执行基于文本到文本的聚类，并在多个数据集上取得改进，还探索了聚类生成的类标签。
            arXiv:2406.13342v2 Announce Type: replace 
Abstract: The advancements in large language models (LLMs) have brought significant progress in NLP tasks. However, if a task cannot be fully described in prompts, the models could fail to carry out the task. In this paper, we propose a simple yet effective method to contextualize a task toward a LLM. The method utilizes (1) open-ended zero-shot inference from the entire dataset, (2) aggregate the inference results, and (3) finally incorporate the aggregated meta-information for the actual task. We show the effectiveness in text clustering tasks, empowering LLMs to perform text-to-text-based clustering and leading to improvements on several datasets. Furthermore, we explore the generated class labels for clustering, showing how the LLM understands the task through data.
        ]]></description>
    </item>
    <item>
        <title>One Fits All: Learning Fair Graph Neural Networks for Various Sensitive Attributes</title>
        <link>https://arxiv.org/abs/2406.13544</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2406.13544v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuchang Zhu, Jintang Li, Yatao Bian, Zibin Zheng, Liang Chen</dc:creator>
        <description><![CDATA[
            背景：图神经网络存在公平性问题，现有提升公平性的方法多针对特定敏感属性，变更需求时需从头训练，计算成本高。方法：从因果建模视角分析问题，基于不变学习视角构建公平性问题，提出基于不变学习的图公平性框架FairINV，通过消除标签与敏感属性间的虚假关联来训练公平的图神经网络。效果：在多个真实数据集上的实验表明，FairINV显著优于现有公平性方法。
            arXiv:2406.13544v3 Announce Type: replace 
Abstract: Recent studies have highlighted fairness issues in Graph Neural Networks (GNNs), where they produce discriminatory predictions against specific protected groups categorized by sensitive attributes such as race and age. While various efforts to enhance GNN fairness have made significant progress, these approaches are often tailored to specific sensitive attributes. Consequently, they necessitate retraining the model from scratch to accommodate changes in the sensitive attribute requirement, resulting in high computational costs. To gain deeper insights into this issue, we approach the graph fairness problem from a causal modeling perspective, where we identify the confounding effect induced by the sensitive attribute as the underlying reason. Motivated by this observation, we formulate the fairness problem in graphs from an invariant learning perspective, which aims to learn invariant representations across environments. Accordingly, we propose a graph fairness framework based on invariant learning, namely FairINV, which enables the training of fair GNNs to accommodate various sensitive attributes within a single training session. Specifically, FairINV incorporates sensitive attribute partition and trains fair GNNs by eliminating spurious correlations between the label and various sensitive attributes. Experimental results on several real-world datasets demonstrate that FairINV significantly outperforms state-of-the-art fairness approaches, underscoring its effectiveness. Our code is available via: https://github.com/ZzoomD/FairINV/.
        ]]></description>
    </item>
    <item>
        <title>Modality-Specialized Synergizers for Interleaved Vision-Language Generalists</title>
        <link>https://arxiv.org/abs/2407.03604</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2407.03604v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhiyang Xu, Minqian Liu, Ying Shen, Joy Rimchala, Jiaxin Zhang, Qifan Wang, Yu Cheng, Lifu Huang</dc:creator>
        <description><![CDATA[
            背景：当前视觉语言通用模型（VLGs）在无缝生成文本和图像序列方面存在挑战，现有方法忽略了文本和图像的内在归纳偏差。方法：引入模态专用协同器（MOSS），用卷积LoRA建模图像局部先验、线性LoRA处理文本序列，还推出首个开源的包含184982个实例的交错指令调优数据集LEAFINSTRUCT。效果：集成MOSS的VLGs达到了最先进性能，在复杂交错生成任务中显著超越基线模型，且具有强泛化性。
            arXiv:2407.03604v2 Announce Type: replace 
Abstract: Recent advancements in Vision-Language Models (VLMs) have led to the emergence of Vision-Language Generalists (VLGs) capable of understanding and generating both text and images. However, seamlessly generating an arbitrary sequence of text and images remains a challenging task for the current VLGs. One primary limitation lies in applying a unified architecture and the same set of parameters to simultaneously model discrete text tokens and continuous image features. Recent works attempt to tackle this fundamental problem by introducing modality-aware expert models. However, they employ identical architectures to process both text and images, disregarding the intrinsic inductive biases in these two modalities. In this work, we introduce MODALITY-SPECIALIZED SYNERGIZERS (MOSS), a novel design that efficiently optimizes existing unified architectures of VLGs with modality-specialized adaptation layers, i.e., a Convolutional LoRA for modeling the local priors of image patches and a Linear LoRA for processing sequential text. This design enables more effective modeling of modality-specific features while maintaining the strong cross-modal integration gained from pretraining. In addition, to improve the instruction-following capability on interleaved text-and-image generation, we introduce LEAFINSTRUCT, the first open-sourced interleaved instruction tuning dataset comprising 184,982 high-quality instances on more than 10 diverse domains. Extensive experiments show that VLGs integrated with M OSS achieve state-of-the-art performance, significantly surpassing baseline VLGs in complex interleaved generation tasks. Furthermore, our method exhibits strong generalizability on different VLGs.
        ]]></description>
    </item>
    <item>
        <title>C3T: Cross-modal Transfer Through Time for Sensor-based Human Activity Recognition</title>
        <link>https://arxiv.org/abs/2407.16803</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2407.16803v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Abhi Kamboj, Anh Duy Nguyen, Minh N. Do</dc:creator>
        <description><![CDATA[
            该研究聚焦基于传感器的人体活动识别，背景是现有无监督模态适应（UMA）方法在对齐时将连续时间数据样本压缩为单个潜在向量，难以处理时间信息。为此提出C3T方法，通过对齐跨传感模态的一组时间潜在向量来保留对齐时的时间信息。在多个相机+IMU数据集上实验表明，C3T在UMA中的准确率比现有方法至少高8%，对时间偏移、未对齐和膨胀等时间失真有更强鲁棒性。
            arXiv:2407.16803v3 Announce Type: replace 
Abstract: In order to unlock the potential of diverse sensors, we investigate a method to transfer knowledge between time-series modalities using a multimodal \textit{temporal} representation space for Human Activity Recognition (HAR). Specifically, we explore the setting where the modality used in testing has no labeled data during training, which we refer to as Unsupervised Modality Adaptation (UMA). We categorize existing UMA approaches as Student-Teacher or Contrastive Alignment methods. These methods typically compress continuous-time data samples into single latent vectors during alignment, inhibiting their ability to transfer temporal information through real-world temporal distortions. To address this, we introduce Cross-modal Transfer Through Time (C3T), which preserves temporal information during alignment to handle dynamic sensor data better. C3T achieves this by aligning a set of temporal latent vectors across sensing modalities. Our extensive experiments on various camera+IMU datasets demonstrate that C3T outperforms existing methods in UMA by at least 8% in accuracy and shows superior robustness to temporal distortions such as time-shift, misalignment, and dilation. Our findings suggest that C3T has significant potential for developing generalizable models for time-series sensor data, opening new avenues for various multimodal applications.
        ]]></description>
    </item>
    <item>
        <title>Cool-Fusion: Fuse Large Language Models without Training</title>
        <link>https://arxiv.org/abs/2407.19807</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2407.19807v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Cong Liu, Xiaojun Quan, Yan Pan, Liang Lin, Weigang Wu, Xu Chen</dc:creator>
        <description><![CDATA[
            背景：融合多个异构大语言模型存在计算负载高，尤其是微调或对齐词汇表的挑战。方法：提出Cool - Fusion方法，无需训练即可融合源大语言模型的知识，通过在文本层面集成大语言模型，让它们以不同粒度对彼此生成的文本重新排序，以克服词汇差异。效果：在多个基准数据集上进行了大量实验，在GSM8K上，Cool - Fusion使三个强源大语言模型的准确率显著提高17.4%。
            arXiv:2407.19807v2 Announce Type: replace 
Abstract: We focus on the problem of fusing two or more heterogeneous large language models (LLMs) to leverage their complementary strengths. One of the challenges of model fusion is high computational load, specifically in fine-tuning or aligning vocabularies. To address this, we propose Cool-Fusion, a simple yet effective approach that fuses the knowledge of source LLMs, which does not require training. Unlike ensemble methods, Cool-Fusion is applicable to any set of source LLMs that have different vocabularies. To overcome the vocabulary discrepancies among LLMs, we ensemble LLMs on text level, allowing them to rerank the generated texts by each other with different granularities. Extensive experiments have been conducted across a variety of benchmark datasets. On GSM8K, Cool-Fusion increases accuracy from three strong source LLMs by a significant margin of 17.4\%.
        ]]></description>
    </item>
    <item>
        <title>Synergizing Unsupervised Episode Detection with LLMs for Large-Scale News Events</title>
        <link>https://arxiv.org/abs/2408.04873</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2408.04873v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Priyanka Kargupta, Yunyi Zhang, Yizhu Jiao, Siru Ouyang, Jiawei Han</dc:creator>
        <description><![CDATA[
            背景：现有自动事件检测在可解释性和适应大规模关键事件演变方面存在困难，而情节结构在这些方面表现出色。方法：本文提出情节检测任务，引入无监督框架EpiMine，利用文章中自然的情节划分，通过判别性术语组合的变化来识别关键事件的候选情节，再与大语言模型协同将其细化为最终情节。效果：在三个不同的真实事件数据集上，EpiMine较基线在所有指标上平均提升59.2%。
            arXiv:2408.04873v2 Announce Type: replace 
Abstract: State-of-the-art automatic event detection struggles with interpretability and adaptability to evolving large-scale key events -- unlike episodic structures, which excel in these areas. Often overlooked, episodes represent cohesive clusters of core entities performing actions at a specific time and location; a partially ordered sequence of episodes can represent a key event. This paper introduces a novel task, episode detection, which identifies episodes within a news corpus of key event articles. Detecting episodes poses unique challenges, as they lack explicit temporal or locational markers and cannot be merged using semantic similarity alone. While large language models (LLMs) can aid with these reasoning difficulties, they suffer with long contexts typical of news corpora. To address these challenges, we introduce EpiMine, an unsupervised framework that identifies a key event's candidate episodes by leveraging natural episodic partitions in articles, estimated through shifts in discriminative term combinations. These candidate episodes are more cohesive and representative of true episodes, synergizing with LLMs to better interpret and refine them into final episodes. We apply EpiMine to our three diverse, real-world event datasets annotated at the episode level, where it achieves a 59.2% average gain across all metrics compared to baselines.
        ]]></description>
    </item>
    <item>
        <title>Open-FinLLMs: Open Multimodal Large Language Models for Financial Applications</title>
        <link>https://arxiv.org/abs/2408.11878</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2408.11878v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jimin Huang, Mengxi Xiao, Dong Li, Zihao Jiang, Yuzhe Yang, Yifei Zhang, Lingfei Qian, Yan Wang, Xueqing Peng, Yang Ren, Ruoyu Xiang, Zhengyu Chen, Xiao Zhang, Yueru He, Weiguang Han, Shunian Chen, Lihang Shen, Daniel Kim, Yangyang Yu, Yupeng Cao, Zhiyang Deng, Haohang Li, Duanyu Feng, Yongfu Dai, VijayaSai Somasundaram, Peng Lu, Guojun Xiong, Zhiwei Liu, Zheheng Luo, Zhiyuan Yao, Ruey-Ling Weng, Meikang Qiu, Kaleb E Smith, Honghai Yu, Yanzhao Lai, Min Peng, Jian-Yun Nie, Jordan W. Suchow, Xiao-Yang Liu, Benyou Wang, Alejandro Lopez-Lira, Qianqian Xie, Sophia Ananiadou, Junichi Tsujii</dc:creator>
        <description><![CDATA[
            背景：现有金融大语言模型受语料稀缺、多模态能力弱和评估范围窄的限制，不适合实际应用。方法：推出Open - FinLLMs，包括在520亿标记语料库预训练的FinLLaMA、用57.3万条金融指令微调的FinLLaMA - Instruct和用143万对多模态调优数据增强的FinLLaVA，并在多任务多数据集上评估，引入两个新多模态评估数据集。效果：在多项金融和多模态任务上优于GPT - 4等模型，已开源代码和模型。
            arXiv:2408.11878v3 Announce Type: replace 
Abstract: Financial LLMs hold promise for advancing financial tasks and domain-specific applications. However, they are limited by scarce corpora, weak multimodal capabilities, and narrow evaluations, making them less suited for real-world application. To address this, we introduce \textit{Open-FinLLMs}, the first open-source multimodal financial LLMs designed to handle diverse tasks across text, tabular, time-series, and chart data, excelling in zero-shot, few-shot, and fine-tuning settings. The suite includes FinLLaMA, pre-trained on a comprehensive 52-billion-token corpus; FinLLaMA-Instruct, fine-tuned with 573K financial instructions; and FinLLaVA, enhanced with 1.43M multimodal tuning pairs for strong cross-modal reasoning. We comprehensively evaluate Open-FinLLMs across 14 financial tasks, 30 datasets, and 4 multimodal tasks in zero-shot, few-shot, and supervised fine-tuning settings, introducing two new multimodal evaluation datasets. Our results show that Open-FinLLMs outperforms afvanced financial and general LLMs such as GPT-4, across financial NLP, decision-making, and multi-modal tasks, highlighting their potential to tackle real-world challenges. To foster innovation and collaboration across academia and industry, we release all codes (https://anonymous.4open.science/r/PIXIU2-0D70/B1D7/LICENSE) and models under OSI-approved licenses.
        ]]></description>
    </item>
    <item>
        <title>VProChart: Answering Chart Question through Visual Perception Alignment Agent and Programmatic Solution Reasoning</title>
        <link>https://arxiv.org/abs/2409.01667</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2409.01667v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Muye Huang, Lingling Zhang, Lai Han, Wenjun Wu, Xinyu Zhang, Jun Liu</dc:creator>
        <description><![CDATA[
            背景：图表广泛应用，但图表问答任务中，图表图像难解读，相关问题涉及复杂推理，影响现有模型表现。方法：本文提出VProChart框架，集成轻量级视觉感知对齐代理（VPAgent）和程序化解决方案推理方法，VPAgent基于人类视觉感知原理对齐和建模图表元素，程序化方法利用大语言模型将自然语言推理问题转化为结构化解决方案程序。效果：在ChartQA和PlotQA等基准数据集实验显示，VProChart显著优于现有方法。
            arXiv:2409.01667v2 Announce Type: replace 
Abstract: Charts are widely used for data visualization across various fields, including education, research, and business. Chart Question Answering (CQA) is an emerging task focused on the automatic interpretation and reasoning of data presented in charts. However, chart images are inherently difficult to interpret, and chart-related questions often involve complex logical and numerical reasoning, which hinders the performance of existing models. This paper introduces VProChart, a novel framework designed to address these challenges in CQA by integrating a lightweight Visual Perception Alignment Agent (VPAgent) and a Programmatic Solution Reasoning approach. VPAgent aligns and models chart elements based on principles of human visual perception, enhancing the understanding of chart context. The Programmatic Solution Reasoning approach leverages large language models (LLMs) to transform natural language reasoning questions into structured solution programs, facilitating precise numerical and logical reasoning. Extensive experiments on benchmark datasets such as ChartQA and PlotQA demonstrate that VProChart significantly outperforms existing methods, highlighting its capability in understanding and reasoning with charts.
        ]]></description>
    </item>
    <item>
        <title>PropEnc: A Property Encoder for Graph Neural Networks</title>
        <link>https://arxiv.org/abs/2409.11554</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2409.11554v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Anwar Said, Waseem Abbas, Xenofon Koutsoukos</dc:creator>
        <description><![CDATA[
            背景：图机器学习依赖节点特征，但现实中很多网络因隐私、数据不完整等缺乏节点特征，现有结构和位置编码存在局限。方法：本文提出PropEnc，通过结合直方图构建与反向索引编码，从任何图指标生成有表现力的节点嵌入。效果：该方法支持低维表示和多样输入类型，缓解稀疏问题、提高计算效率，能高精度复制独热编码或近似索引。实验表明，它能从各种图指标高效构建节点特征。
            arXiv:2409.11554v3 Announce Type: replace 
Abstract: Graph machine learning, particularly using graph neural networks, heavily relies on node features. However, many real-world systems, such as social and biological networks, lack node features due to privacy concerns, incomplete data, or collection limitations. Structural and positional encoding are commonly used to address this but are constrained by the maximum values of the encoded properties, such as the highest node degree. This limitation makes them impractical for scale-free networks and applications involving large or non-categorical properties. This paper introduces PropEnc, a novel and versatile encoder to generate expressive node embedding from any graph metric. By combining histogram construction with reversed index encoding, PropEnc offers a flexible solution that supports low-dimensional representations and diverse input types, effectively mitigating sparsity issues while improving computational efficiency. Additionally, it replicates one-hot encoding or approximates indices with high accuracy, making it adaptable to a wide range of graph applications. We validate PropEnc through extensive experiments on graph classification task across several social networks lacking node features. The empirical results demonstrate that PropEnc offers an efficient mechanism for constructing node features from various graph metrics.
        ]]></description>
    </item>
    <item>
        <title>PECAN: LLM-Guided Dynamic Progress Control with Attention-Guided Hierarchical Weighted Graph for Long-Document QA</title>
        <link>https://arxiv.org/abs/2410.04790</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.04790v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xinyu Wang, Yanzheng Xiang, Lin Gui, Yulan He</dc:creator>
        <description><![CDATA[
            长文档问答面临大规模文本和长距离依赖挑战，现有大语言模型（LLMs）虽可单遍处理全文但计算成本高，检索增强生成（RAG）方法虽拆分文本但结果欠佳且易失全局信息。本文结合LLMs高精度与RAG高效性，提出PECAN方法。一是利用LLMs动态控制检索过程，依不同查询调整检索信息量；二是构建基于LLM注意力权重的分层图进行检索。实验表明，在两个单文档和两个多文档问答数据集上，PECAN达LLMs性能且计算复杂度与RAG相当。
            arXiv:2410.04790v2 Announce Type: replace 
Abstract: Long-document QA presents challenges with large-scale text and long-distance dependencies. Recent advances in Large Language Models (LLMs) enable entire documents to be processed in a single pass. However, their computational cost is significantly high. Retrieval-Augmented Generation (RAG) methods split text into smaller chunks, but they often yield inferior results and may lose global context. Recent approaches that integrate LLMs into RAG via iterative summarization either underutilize LLM capabilities or still incur high computational costs. In this paper, we combine the high accuracy of LLMs with the efficiency of RAG and propose LLM-Guided Dynamic Progress Control with Attention-Based Hierarchical Weighted Graph (PECAN). Our method introduces two key improvements: (1) LLM-Guided Dynamic Progress Control: We leverage LLMs to dynamically control the retrieval process, adjusting the amount of retrieved information based on different queries to achieve a better balance of effectiveness and efficiency. (2) Attention-Guided Retrieval: We propose a novel retrieval method that constructs a hierarchical graph where edges are derived by LLM attention weights. Experimental results demonstrate that PECAN achieves LLM-level performance while maintaining computational complexity comparable to that of RAG methods on two single-document and two multi-document QA datasets.
        ]]></description>
    </item>
    <item>
        <title>Parameter-Efficient Fine-Tuning of State Space Models</title>
        <link>https://arxiv.org/abs/2410.09016</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.09016v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kevin Galim, Wonjun Kang, Yuchen Zeng, Hyung Il Koo, Kangwook Lee</dc:creator>
        <description><![CDATA[
            背景：深度状态空间模型（SSMs）在语言建模中作用强大，但参数高效微调（PEFT）方法在基于SSM的模型中的应用研究较少。方法：研究现有PEFT方法的两个基本问题，提出针对SSM模块的PEFT方法——稀疏维度调整（SDT），并将其与用于线性投影矩阵的LoRA相结合。效果：分析表明LoRA及其变体表现优于其他PEFT方法，结合SDT和LoRA后在大量实验中达到了最先进的性能。
            arXiv:2410.09016v3 Announce Type: replace 
Abstract: Deep State Space Models (SSMs), such as Mamba (Gu & Dao, 2024), have become powerful tools for language modeling, offering high performance and linear scalability with sequence length. However, the application of parameter-efficient fine-tuning (PEFT) methods to SSM-based models remains largely underexplored. We start by investigating two fundamental questions on existing PEFT methods: (i) How do they perform on SSM-based models? (ii) Which parameters should they target for optimal results? Our analysis shows that LoRA and its variants consistently outperform all other PEFT methods. While LoRA is effective for linear projection matrices, it fails on SSM modules-yet still outperforms other methods applicable to SSMs, indicating their limitations. This underscores the need for a specialized SSM tuning approach. To address this, we propose Sparse Dimension Tuning (SDT), a PEFT method tailored for SSM modules. Combining SDT for SSMs with LoRA for linear projection matrices, we achieve state-of-the-art performance across extensive experiments.
        ]]></description>
    </item>
    <item>
        <title>Zero-shot Generalist Graph Anomaly Detection with Unified Neighborhood Prompts</title>
        <link>https://arxiv.org/abs/2410.14886</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.14886v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chaoxi Niu, Hezhe Qiao, Changlu Chen, Ling Chen, Guansong Pang</dc:creator>
        <description><![CDATA[
            图异常检测（GAD）在众多领域至关重要，但现有GAD方法是为每个图数据集训练单独模型，限制了其在现实场景中的应用。为克服这一局限，本文提出零样本通用GAD方法UNPrompt，训练一个适用于所有图数据集的检测模型。该方法通过坐标归一化对齐不同图节点属性的维度和语义，学习通用邻域提示。实验表明，UNPrompt在通用GAD设置下显著优于多种竞争方法，在单数据集单模型设置下也有很强优势。
            arXiv:2410.14886v2 Announce Type: replace 
Abstract: Graph anomaly detection (GAD), which aims to identify nodes in a graph that significantly deviate from normal patterns, plays a crucial role in broad application domains. However, existing GAD methods are one-model-for-one-dataset approaches, i.e., training a separate model for each graph dataset. This largely limits their applicability in real-world scenarios. To overcome this limitation, we propose a novel zero-shot generalist GAD approach UNPrompt that trains a one-for-all detection model, requiring the training of one GAD model on a single graph dataset and then effectively generalizing to detect anomalies in other graph datasets without any retraining or fine-tuning. The key insight in UNPrompt is that i) the predictability of latent node attributes can serve as a generalized anomaly measure and ii) generalized normal and abnormal graph patterns can be learned via latent node attribute prediction in a properly normalized node attribute space. UNPrompt achieves a generalist mode for GAD through two main modules: one module aligns the dimensionality and semantics of node attributes across different graphs via coordinate-wise normalization, while another module learns generalized neighborhood prompts that support the use of latent node attribute predictability as an anomaly score across different datasets. Extensive experiments on real-world GAD datasets show that UNPrompt significantly outperforms diverse competing methods under the generalist GAD setting, and it also has strong superiority under the one-model-for-one-dataset setting. Code is available at https://github.com/mala-lab/UNPrompt.
        ]]></description>
    </item>
    <item>
        <title>Leveraging MLLM Embeddings and Attribute Smoothing for Compositional Zero-Shot Learning</title>
        <link>https://arxiv.org/abs/2411.12584</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2411.12584v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xudong Yan, Songhe Feng, Yang Zhang, Jian Yang, Yueguan Lin, Haojun Fei</dc:creator>
        <description><![CDATA[
            这是一篇关于组合式零样本学习（CZSL）的论文。背景是以往工作存在解纠缠效果受背景影响、词嵌入无法捕捉复杂多模态语义信息、模型对见过的组合过度自信等问题。方法是提出一种新框架，利用特征自适应聚合模块减轻背景影响，用可学习条件掩码捕捉多粒度特征，以多模态大语言模型（MLLM）的最后隐藏状态作为词嵌入，还提出用大语言模型生成辅助属性进行属性平滑。效果是在三个具有挑战性的数据集上达到了最先进水平。
            arXiv:2411.12584v2 Announce Type: replace 
Abstract: Compositional zero-shot learning (CZSL) aims to recognize novel compositions of attributes and objects learned from seen compositions. Previous works disentangle attributes and objects by extracting shared and exclusive parts between the image pair sharing the same attribute (object), as well as aligning them with pretrained word embeddings to improve unseen attribute-object recognition. Despite the significant achievements of existing efforts, they are hampered by three limitations: (1) The efficacy of disentanglement is compromised due to the influence of the background and the intricate entanglement of attributes with objects in the same parts. (2) Existing word embeddings fail to capture complex multimodal semantic information. (3) Overconfidence exhibited by existing models in seen compositions hinders their generalization to novel compositions. Being aware of these, we propose a novel framework named multimodal large language model (MLLM) embeddings and attribute smoothing guided disentanglement for CZSL. First, we leverage feature adaptive aggregation modules to mitigate the impact of background, and utilize learnable condition masks to capture multi-granularity features for disentanglement. Moreover, the last hidden states of MLLM are employed as word embeddings for their superior representation capabilities. Furthermore, we propose attribute smoothing with auxiliary attributes generated by the large language model (LLM) for seen compositions to address the overconfidence challenge. Extensive experiments demonstrate that our method achieves state-of-the-art performance on three challenging datasets. The source code will be available at https://github.com/xud-yan/Trident .
        ]]></description>
    </item>
    <item>
        <title>Enhancing Few-Shot Vision-Language Classification with Large Multimodal Model Features</title>
        <link>https://arxiv.org/abs/2412.00142</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2412.00142v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chancharik Mitra, Brandon Huang, Tianning Chai, Zhiqiu Lin, Assaf Arbelle, Rogerio Feris, Leonid Karlinsky, Trevor Darrell, Deva Ramanan, Roei Herzig</dc:creator>
        <description><![CDATA[
            背景：生成式大模态模型（LMMs）虽在视觉语言任务表现出色，但生成式输出不适用于视觉语言分类任务，且从其中提取有用特征是一大挑战。方法：提出利用LMM潜在空间进行多模态特征提取的方法，即稀疏注意力向量（SAVs），它利用LMM中少于5%的稀疏注意力头激活作为强特征表示。效果：仅用少样本示例，SAVs就在一系列视觉语言分类任务上超越多种少样本和微调基线，且性能随样本增加而提升，能泛化到相似任务。
            arXiv:2412.00142v3 Announce Type: replace 
Abstract: Generative Large Multimodal Models (LMMs) like LLaVA and Qwen-VL excel at a wide variety of vision-language (VL) tasks. Despite strong performance, LMMs' generative outputs are not specialized for vision-language classification tasks (i.e., tasks with vision-language inputs and discrete labels) such as image classification and multiple-choice VQA. One key challenge in utilizing LMMs for these tasks is the extraction of useful features from generative LMMs. To overcome this, we propose an approach that leverages multimodal feature extraction from the LMM's latent space. Toward this end, we present Sparse Attention Vectors (SAVs) -- a finetuning-free method that leverages sparse attention head activations (fewer than 5% of the heads) in LMMs as strong feature representations. With only few-shot examples, SAVs demonstrate state-of-the-art performance compared to a variety of few-shot and finetuned baselines on a collection of vision-language classification tasks. Our experiments also imply that SAVs can scale in performance with additional examples and generalize to similar tasks, establishing SAVs as both effective and robust multimodal feature representations.
        ]]></description>
    </item>
    <item>
        <title>A Cognac Shot To Forget Bad Memories: Corrective Unlearning for Graph Neural Networks</title>
        <link>https://arxiv.org/abs/2412.00789</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2412.00789v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Varshita Kolipaka, Akshit Sinha, Debangan Mishra, Sumit Kumar, Arvindh Arun, Shashwat Goel, Ponnurangam Kumaraguru</dc:creator>
        <description><![CDATA[
            背景：图神经网络（GNNs）在图数据的机器学习应用中愈发广泛，但图数据不满足独立同分布假设，对抗性操作或错误数据会影响模型性能。方法：研究纠正性遗忘问题，提出新的图遗忘方法Cognac。效果：该方法即使仅识别出5%的被操纵集合，也能消除其影响，恢复大部分使用完全校正训练数据的强预言机的性能，甚至优于无删除集的从头再训练，且效率提高8倍。
            arXiv:2412.00789v4 Announce Type: replace 
Abstract: Graph Neural Networks (GNNs) are increasingly being used for a variety of ML applications on graph data. Because graph data does not follow the independently and identically distributed (i.i.d.) assumption, adversarial manipulations or incorrect data can propagate to other data points through message passing, which deteriorates the model's performance. To allow model developers to remove the adverse effects of manipulated entities from a trained GNN, we study the recently formulated problem of Corrective Unlearning. We find that current graph unlearning methods fail to unlearn the effect of manipulations even when the whole manipulated set is known. We introduce a new graph unlearning method, Cognac, which can unlearn the effect of the manipulation set even when only 5% of it is identified. It recovers most of the performance of a strong oracle with fully corrected training data, even beating retraining from scratch without the deletion set while being 8x more efficient. We hope our work assists GNN developers in mitigating harmful effects caused by issues in real-world data, post-training. Our code is publicly available at https://github.com/cognac-gnn-unlearning/corrective-unlearning-for-gnns
        ]]></description>
    </item>
    <item>
        <title>Video LLMs for Temporal Reasoning in Long Videos</title>
        <link>https://arxiv.org/abs/2412.02930</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2412.02930v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Fawad Javed Fateh, Umer Ahmed, Hamza Khan, M. Zeeshan Zia, Quoc-Huy Tran</dc:creator>
        <description><![CDATA[
            该论文背景是缺乏能有效进行时间推理和细粒度理解长视频的模型。方法是提出视频大语言模型TemporalVLM，其视觉编码器将长视频映射为含时间信息、兼具局部和全局线索的特征，先将视频分成短片段并与时间戳联合编码，再用双向长短期记忆模块聚合全局特征，还构建了大规模长视频数据集IndustryASM。效果是在多个长视频数据集实验中，TemporalVLM在时间推理和细粒度理解任务上优于以往方法。
            arXiv:2412.02930v3 Announce Type: replace 
Abstract: This paper introduces TemporalVLM, a video large language model (video LLM) capable of effective temporal reasoning and fine-grained understanding in long videos. At the core, our approach includes a visual encoder for mapping a long-term input video into features which are time-aware and contain both local and global cues. In particular, it first divides the input video into short-term clips, which are jointly encoded with their timestamps into time-sensitive local features. Next, the local features are passed through a bidirectional long short-term memory (BiLSTM) module for global feature aggregation. The extracted time-aware and multi-level features are important for accurate temporal reasoning and fine-grained understanding in long videos. Moreover, to facilitate the evaluation of TemporalVLM, we present a large-scale long video dataset of industry assembly processes, namely IndustryASM, which consists of videos recorded on factory floors with actions and timestamps annotated by industrial engineers for time and motion studies and temporal action segmentation evaluation. Finally, extensive experiments on datasets of long videos, including TimeIT and IndustryASM, show that TemporalVLM achieves superior performance than previous methods across temporal reasoning and fine-grained understanding tasks, namely dense video captioning, temporal video grounding, video highlight detection, and temporal action segmentation. To the best of our knowledge, our work is the first to incorporate LSTMs into video LLMs.
        ]]></description>
    </item>
    <item>
        <title>SMI-Editor: Edit-based SMILES Language Model with Fragment-level Supervision</title>
        <link>https://arxiv.org/abs/2412.05569</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2412.05569v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Kangjie Zheng, Siyue Liang, Junwei Yang, Bin Feng, Zequn Liu, Wei Ju, Zhiping Xiao, Ming Zhang</dc:creator>
        <description><![CDATA[
            背景：现有预训练SMILES语言模型仅关注单令牌级监督，未充分利用分子子结构信息，且训练与推理不匹配。方法：提出SMI - Editor，随机破坏分子中的子结构，将得到的SMILES输入模型，通过编辑过程恢复原始SMILES。效果：该模型可引入片段级训练信号，能使用有效SMILES输入，提升了可扩展性和捕捉片段级分子信息的能力，在多个下游分子任务中达到了最先进的性能，甚至超越了一些3D分子表示模型。
            arXiv:2412.05569v2 Announce Type: replace 
Abstract: SMILES, a crucial textual representation of molecular structures, has garnered significant attention as a foundation for pre-trained language models (LMs). However, most existing pre-trained SMILES LMs focus solely on the single-token level supervision during pre-training, failing to fully leverage the substructural information of molecules. This limitation makes the pre-training task overly simplistic, preventing the models from capturing richer molecular semantic information. Moreover, during pre-training, these SMILES LMs only process corrupted SMILES inputs, never encountering any valid SMILES, which leads to a train-inference mismatch. To address these challenges, we propose SMI-Editor, a novel edit-based pre-trained SMILES LM. SMI-Editor disrupts substructures within a molecule at random and feeds the resulting SMILES back into the model, which then attempts to restore the original SMILES through an editing process. This approach not only introduces fragment-level training signals, but also enables the use of valid SMILES as inputs, allowing the model to learn how to reconstruct complete molecules from these incomplete structures. As a result, the model demonstrates improved scalability and an enhanced ability to capture fragment-level molecular information. Experimental results show that SMI-Editor achieves state-of-the-art performance across multiple downstream molecular tasks, and even outperforming several 3D molecular representation models.
        ]]></description>
    </item>
    <item>
        <title>MeshArt: Generating Articulated Meshes with Structure-Guided Transformers</title>
        <link>https://arxiv.org/abs/2412.11596</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2412.11596v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Daoyi Gao, Yawar Siddiqui, Lei Li, Angela Dai</dc:creator>
        <description><![CDATA[
            背景：可关节化3D对象生成对创建非静态虚拟资产至关重要。方法：提出MeshArt，采用基于分层变压器的方法，分两阶段逐部分生成可关节化3D网格，将关节结构和部件网格建模为量化三角形嵌入序列，还引入结构引导调节以确保部件间的连贯性。效果：与现有技术相比有显著改进，结构覆盖率提高57.1%，网格生成FID提高209点。
            arXiv:2412.11596v2 Announce Type: replace 
Abstract: Articulated 3D object generation is fundamental for creating realistic, functional, and interactable virtual assets which are not simply static. We introduce MeshArt, a hierarchical transformer-based approach to generate articulated 3D meshes with clean, compact geometry, reminiscent of human-crafted 3D models. We approach articulated mesh generation in a part-by-part fashion across two stages. First, we generate a high-level articulation-aware object structure; then, based on this structural information, we synthesize each part's mesh faces. Key to our approach is modeling both articulation structures and part meshes as sequences of quantized triangle embeddings, leading to a unified hierarchical framework with transformers for autoregressive generation. Object part structures are first generated as their bounding primitives and articulation modes; a second transformer, guided by these articulation structures, then generates each part's mesh triangles. To ensure coherency among generated parts, we introduce structure-guided conditioning that also incorporates local part mesh connectivity. MeshArt shows significant improvements over state of the art, with 57.1% improvement in structure coverage and a 209-point improvement in mesh generation FID.
        ]]></description>
    </item>
    <item>
        <title>SWAG: Long-term Surgical Workflow Prediction with Generative-based Anticipation</title>
        <link>https://arxiv.org/abs/2412.18849</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2412.18849v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Maxence Boels, Yang Liu, Prokar Dasgupta, Alejandro Granados, Sebastien Ourselin</dc:creator>
        <description><![CDATA[
            背景：现有方法在识别当前手术阶段表现出色，但对未来手术步骤的预见和术中指导有限，且当前预测方法忽略了手术工作流的长序列性质。方法：提出SWAG框架，结合生成方法进行阶段识别和预测，研究单遍（SP）和自回归（AR）两种解码方法，用类转移概率的嵌入方法提高阶段预测准确性，还提出用剩余时间回归到分类（R2C）的生成框架。效果：单遍模型在两个数据集上取得一定F1分数，在阶段剩余时间回归任务上有较好表现。
            arXiv:2412.18849v3 Announce Type: replace 
Abstract: While existing approaches excel at recognising current surgical phases, they provide limited foresight and intraoperative guidance into future procedural steps. Similarly, current anticipation methods are constrained to predicting short-term and single events, neglecting the dense, repetitive, and long sequential nature of surgical workflows. To address these needs and limitations, we propose SWAG (Surgical Workflow Anticipative Generation), a framework that combines phase recognition and anticipation using a generative approach. This paper investigates two distinct decoding methods - single-pass (SP) and auto-regressive (AR) - to generate sequences of future surgical phases at minute intervals over long horizons. We propose a novel embedding approach using class transition probabilities to enhance the accuracy of phase anticipation. Additionally, we propose a generative framework using remaining time regression to classification (R2C). SWAG was evaluated on two publicly available datasets, Cholec80 and AutoLaparo21. Our single-pass model with class transition probability embeddings (SP*) achieves 32.1% and 41.3% F1 scores over 20 and 30 minutes on Cholec80 and AutoLaparo21, respectively. Moreover, our approach competes with existing methods on phase remaining time regression, achieving weighted mean absolute errors of 0.32 and 0.48 minutes for 2- and 3-minute horizons. SWAG demonstrates versatility across generative decoding frame works and classification and regression tasks to create temporal continuity between surgical workflow recognition and anticipation. Our method provides steps towards intraoperative surgical workflow generation for anticipation. Project: https://maxboels.github.io/swag.
        ]]></description>
    </item>
    <item>
        <title>Eliciting In-context Retrieval and Reasoning for Long-context Large Language Models</title>
        <link>https://arxiv.org/abs/2501.08248</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2501.08248v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yifu Qiu, Varun Embar, Yizhe Zhang, Navdeep Jaitly, Shay B. Cohen, Benjamin Han</dc:creator>
        <description><![CDATA[
            背景：长上下文语言模型（LCLMs）有望变革检索增强生成（RAG），但现有基准常高估其性能。方法：引入评估LCLMs的ICR²基准，包含混淆段落；提出三种提升性能的方法，如检索后生成微调等。效果：在LOFT和ICR²上评估五个知名LCLMs，最佳方法应用于Mistral - 7B时，在LOFT上精确匹配得分比普通RAG和有监督微调分别高17和15分，在ICR²上高13和2分，还在多数任务上超越GPT - 4 - Turbo。
            arXiv:2501.08248v3 Announce Type: replace 
Abstract: Recent advancements in long-context language models (LCLMs) promise to transform Retrieval-Augmented Generation (RAG) by simplifying pipelines. With their expanded context windows, LCLMs can process entire knowledge bases and perform retrieval and reasoning directly -- a capability we define as In-Context Retrieval and Reasoning (ICR^2). However, existing benchmarks like LOFT often overestimate LCLM performance by providing overly simplified contexts. To address this, we introduce ICR^2, a benchmark that evaluates LCLMs in more realistic scenarios by including confounding passages retrieved with strong retrievers. We then propose three methods to enhance LCLM performance: (1) retrieve-then-generate fine-tuning, (2) retrieval-attention-probing, which uses attention heads to filter and de-noise long contexts during decoding, and (3) joint retrieval head training alongside the generation head. Our evaluation of five well-known LCLMs on LOFT and ICR^2 demonstrates significant gains with our best approach applied to Mistral-7B: +17 and +15 points by Exact Match on LOFT, and +13 and +2 points on ICR^2, compared to vanilla RAG and supervised fine-tuning, respectively. It even outperforms GPT-4-Turbo on most tasks despite being a much smaller model.
        ]]></description>
    </item>
    <item>
        <title>GraphRAG under Fire</title>
        <link>https://arxiv.org/abs/2501.14050</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2501.14050v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiacheng Liang, Yuhui Wang, Changjiang Li, Rongyi Zhu, Tanqiu Jiang, Neil Gong, Ting Wang</dc:creator>
        <description><![CDATA[
            背景：GraphRAG通过将外部知识构建为多尺度知识图谱推动了检索增强生成，但安全影响尚不明晰。方法：提出新型攻击GragPoison，利用知识图谱中共享关系制作能同时危害多个查询的中毒文本，采用关系注入、关系增强和叙事生成三种策略。效果：在不同数据集和模型的实证评估中，GragPoison在有效性（成功率达98%）和可扩展性（使用不到68%中毒文本）上大幅超越现有攻击，还探讨了防御措施及局限。
            arXiv:2501.14050v3 Announce Type: replace 
Abstract: GraphRAG advances retrieval-augmented generation (RAG) by structuring external knowledge as multi-scale knowledge graphs, enabling language models to integrate both broad context and granular details in their generation. While GraphRAG has demonstrated success across domains, its security implications remain largely unexplored. To bridge this gap, this work examines GraphRAG's vulnerability to poisoning attacks, uncovering an intriguing security paradox: existing RAG poisoning attacks are less effective under GraphRAG than conventional RAG, due to GraphRAG's graph-based indexing and retrieval; yet, the same features also create new attack surfaces. We present GragPoison, a novel attack that exploits shared relations in the underlying knowledge graph to craft poisoning text capable of compromising multiple queries simultaneously. GragPoison employs three key strategies: (i) relation injection to introduce false knowledge, (ii) relation enhancement to amplify poisoning influence, and (iii) narrative generation to embed malicious content within coherent text. Empirical evaluation across diverse datasets and models shows that GragPoison substantially outperforms existing attacks in terms of effectiveness (up to 98% success rate) and scalability (using less than 68% poisoning text) on multiple variations of GraphRAG. We also explore potential defensive measures and their limitations, identifying promising directions for future research.
        ]]></description>
    </item>
    <item>
        <title>BRiTE: Bootstrapping Reinforced Thinking Process to Enhance Language Model Reasoning</title>
        <link>https://arxiv.org/abs/2501.18858</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2501.18858v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Han Zhong, Yutong Yin, Shenao Zhang, Xiaojun Xu, Yuanxin Liu, Yifei Zuo, Zhihan Liu, Boyi Liu, Sirui Zheng, Hongyi Guo, Liwei Wang, Mingyi Hong, Zhaoran Wang</dc:creator>
        <description><![CDATA[
            大语言模型在复杂推理任务中能力显著，但生成可靠推理过程仍是挑战。本文提出统一概率框架，通过含潜在思维过程和评估信号的图形模型形式化LLM推理。在此框架下引入BRiTE算法，先通过强化学习近似最优思维过程生成高质量推理依据，再通过最大化推理依据生成的联合概率增强基础LLM。理论上该算法收敛率为$1/T$，在数学和编码基准测试中，该方法提升了不同基础模型性能，优于现有算法，甚至可与有人类标注数据的监督微调结果媲美。
            arXiv:2501.18858v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in complex reasoning tasks, yet generating reliable reasoning processes remains a significant challenge. We present a unified probabilistic framework that formalizes LLM reasoning through a novel graphical model incorporating latent thinking processes and evaluation signals. Within this framework, we introduce the Bootstrapping Reinforced Thinking Process (BRiTE) algorithm, which works in two steps. First, it generates high-quality rationales by approximating the optimal thinking process through reinforcement learning, using a novel reward shaping mechanism. Second, it enhances the base LLM by maximizing the joint probability of rationale generation with respect to the model's parameters. Theoretically, we demonstrate BRiTE's convergence at a rate of $1/T$ with $T$ representing the number of iterations. Empirical evaluations on math and coding benchmarks demonstrate that our approach consistently improves performance across different base models without requiring human-annotated thinking processes. In addition, BRiTE demonstrates superior performance compared to existing algorithms that bootstrap thinking processes use alternative methods such as rejection sampling, and can even match or exceed the results achieved through supervised fine-tuning with human-annotated data.
        ]]></description>
    </item>
    <item>
        <title>Retrieval-augmented Large Language Models for Financial Time Series Forecasting</title>
        <link>https://arxiv.org/abs/2502.05878</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.05878v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Mengxi Xiao, Zihao Jiang, Lingfei Qian, Zhengyu Chen, Yueru He, Yijing Xu, Yuecheng Jiang, Dong Li, Ruey-Ling Weng, Min Peng, Jimin Huang, Sophia Ananiadou, Qianqian Xie</dc:creator>
        <description><![CDATA[
            准确预测股价走势对金融决策至关重要，但从嘈杂的金融时间序列数据中检索关键模式颇具挑战，传统方法难以捕捉复杂的时间依赖和特定上下文信号。为此，研究人员提出FinSrag框架，引入领域特定的检索器FinSeer，利用大语言模型反馈优化候选选择机制和相似性驱动的训练目标，筛选出相关时间序列数据段。同时，还扩充了检索语料库。实验表明，FinSeer能提升StockLLM的预测准确性，凸显特定领域检索框架处理金融时间序列数据的重要性。
            arXiv:2502.05878v3 Announce Type: replace 
Abstract: Accurately forecasting stock price movements is critical for informed financial decision-making, supporting applications ranging from algorithmic trading to risk management. However, this task remains challenging due to the difficulty of retrieving subtle yet high-impact patterns from noisy financial time-series data, where conventional retrieval methods, whether based on generic language models or simplistic numeric similarity, often fail to capture the intricate temporal dependencies and context-specific signals essential for precise market prediction. To bridge this gap, we introduce FinSrag, the first retrieval-augmented generation (RAG) framework with a novel domain-specific retriever FinSeer for financial time-series forecasting. FinSeer leverages a candidate selection mechanism refined by LLM feedback and a similarity-driven training objective to align queries with historically influential sequences while filtering out financial noise. Such training enables FinSeer to identify the most relevant time-series data segments for downstream forecasting tasks, unlike embedding or distance-based retrieval methods used in existing RAG frameworks. The retrieved patterns are then fed into StockLLM, a 1B-parameter LLM fine-tuned for stock movement prediction, which serves as the generative backbone. Beyond the retrieval method, we enrich the retrieval corpus by curating new datasets that integrate a broader set of financial indicators, capturing previously overlooked market dynamics. Experiments demonstrate that FinSeer outperforms existing textual retrievers and traditional distance-based retrieval approaches in enhancing the prediction accuracy of StockLLM, underscoring the importance of domain-specific retrieval frameworks in handling the complexity of financial time-series data.
        ]]></description>
    </item>
    <item>
        <title>RelGNN: Composite Message Passing for Relational Deep Learning</title>
        <link>https://arxiv.org/abs/2502.06784</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.06784v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tianlang Chen, Charilaos Kanatsoulis, Jure Leskovec</dc:creator>
        <description><![CDATA[
            在电商、医疗和社交媒体等领域，关系数据库的预测任务至关重要。现有关系深度学习（RDL）方法常忽略关系数据库构建图的内在结构特性，处理多对多关系效率低。为此提出RelGNN框架，引入原子路径，基于此设计新的复合消息传递和图注意力机制，减少冗余、突出关键信号。在Relbench的30个真实任务上评估，在绝大多数任务上达到了最先进性能，提升幅度最高达25%。
            arXiv:2502.06784v2 Announce Type: replace 
Abstract: Predictive tasks on relational databases are critical in real-world applications spanning e-commerce, healthcare, and social media. To address these tasks effectively, Relational Deep Learning (RDL) encodes relational data as graphs, enabling Graph Neural Networks (GNNs) to exploit relational structures for improved predictions. However, existing RDL methods often overlook the intrinsic structural properties of the graphs built from relational databases, leading to modeling inefficiencies, particularly in handling many-to-many relationships. Here we introduce RelGNN, a novel GNN framework specifically designed to leverage the unique structural characteristics of the graphs built from relational databases. At the core of our approach is the introduction of atomic routes, which are simple paths that enable direct single-hop interactions between the source and destination nodes. Building upon these atomic routes, RelGNN designs new composite message passing and graph attention mechanisms that reduce redundancy, highlight key signals, and enhance predictive accuracy. RelGNN is evaluated on 30 diverse real-world tasks from Relbench (Fey et al., 2024), and achieves state-of-the-art performance on the vast majority of tasks, with improvements of up to 25%. Code is available at https://github.com/snap-stanford/RelGNN.
        ]]></description>
    </item>
    <item>
        <title>Stop Looking for Important Tokens in Multimodal Language Models: Duplication Matters More</title>
        <link>https://arxiv.org/abs/2502.11494</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.11494v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zichen Wen, Yifeng Gao, Shaobo Wang, Junyuan Zhang, Qintong Zhang, Weijia Li, Conghui He, Linfeng Zhang</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型中视觉令牌因长度过长产生巨大计算开销，现有基于重要性标准的令牌修剪方法效果不佳。方法：提出DART，基于令牌与其他令牌的重复情况进行修剪，选择少量关键令牌并保留与之低重复的令牌，确保信息损失最小。效果：实验表明，DART可修剪88.9%的视觉令牌，同时保持性能相当，总时间和预填充阶段分别加速1.99倍和2.99倍，且与高效注意力算子兼容性良好。
            arXiv:2502.11494v2 Announce Type: replace 
Abstract: Vision tokens in multimodal large language models often dominate huge computational overhead due to their excessive length compared to linguistic modality. Abundant recent methods aim to solve this problem with token pruning, which first defines an importance criterion for tokens and then prunes the unimportant vision tokens during inference. However, in this paper, we show that the importance is not an ideal indicator to decide whether a token should be pruned. Surprisingly, it usually results in inferior performance than random token pruning and leading to incompatibility to efficient attention computation operators.Instead, we propose DART (Duplication-Aware Reduction of Tokens), which prunes tokens based on its duplication with other tokens, leading to significant and training-free acceleration. Concretely, DART selects a small subset of pivot tokens and then retains the tokens with low duplication to the pivots, ensuring minimal information loss during token pruning. Experiments demonstrate that DART can prune 88.9% vision tokens while maintaining comparable performance, leading to a 1.99$\times$ and 2.99$\times$ speed-up in total time and prefilling stage, respectively, with good compatibility to efficient attention operators. Our codes are available at https://github.com/ZichenWen1/DART.
        ]]></description>
    </item>
    <item>
        <title>Model Generalization on Text Attribute Graphs: Principles with Large Language Models</title>
        <link>https://arxiv.org/abs/2502.11836</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.11836v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Haoyu Wang, Shikun Liu, Rongzhe Wei, Pan Li</dc:creator>
        <description><![CDATA[
            这是一篇关于大语言模型在文本属性图学习中应用的研究。背景是现有方法在处理文本属性图推理时，面临大语言模型上下文长度有限、节点嵌入与模型词元空间不对齐的问题。方法是建立两条关键原则并推出LLM - BP框架：一是用任务自适应嵌入统一属性空间；二是开发通用的图信息聚合机制。效果显著，在11个真实文本属性图基准测试中，LLM - BP大幅超越现有方法，任务条件嵌入提升8.10%，自适应聚合再提升1.71%。
            arXiv:2502.11836v2 Announce Type: replace 
Abstract: Large language models (LLMs) have recently been introduced to graph learning, aiming to extend their zero-shot generalization success to tasks where labeled graph data is scarce. Among these applications, inference over text-attributed graphs (TAGs) presents unique challenges: existing methods struggle with LLMs' limited context length for processing large node neighborhoods and the misalignment between node embeddings and the LLM token space. To address these issues, we establish two key principles for ensuring generalization and derive the framework LLM-BP accordingly: (1) Unifying the attribute space with task-adaptive embeddings, where we leverage LLM-based encoders and task-aware prompting to enhance generalization of the text attribute embeddings; (2) Developing a generalizable graph information aggregation mechanism, for which we adopt belief propagation with LLM-estimated parameters that adapt across graphs. Evaluations on 11 real-world TAG benchmarks demonstrate that LLM-BP significantly outperforms existing approaches, achieving 8.10% improvement with task-conditional embeddings and an additional 1.71% gain from adaptive aggregation. The code and task-adaptive embeddings are publicly available.
        ]]></description>
    </item>
    <item>
        <title>How Expressive are Knowledge Graph Foundation Models?</title>
        <link>https://arxiv.org/abs/2502.13339</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.13339v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xingyue Huang, Pablo Barcel\'o, Michael M. Bronstein, \.Ismail \.Ilkan Ceylan, Mikhail Galkin, Juan L Reutter, Miguel Romero Orth</dc:creator>
        <description><![CDATA[
            知识图谱基础模型（KGFMs）是知识图谱深度学习的前沿方向，但目前对其理论认知有限。本文严格研究了KGFMs的表达能力，发现其表达能力直接取决于学习关系表示所使用的基序。现有文献中最典型的基序是二元的，限制了模型表达能力。为此，研究设计了使用更丰富基序的KGFMs，如基于三元关系的交互学习关系表示。实证验证表明，使用更丰富基序在多领域数据集上性能更优。
            arXiv:2502.13339v2 Announce Type: replace 
Abstract: Knowledge Graph Foundation Models (KGFMs) are at the frontier for deep learning on knowledge graphs (KGs), as they can generalize to completely novel knowledge graphs with different relational vocabularies. Despite their empirical success, our theoretical understanding of KGFMs remains very limited. In this paper, we conduct a rigorous study of the expressive power of KGFMs. Specifically, we show that the expressive power of KGFMs directly depends on the motifs that are used to learn the relation representations. We then observe that the most typical motifs used in the existing literature are binary, as the representations are learned based on how pairs of relations interact, which limits the model's expressiveness. As part of our study, we design more expressive KGFMs using richer motifs, which necessitate learning relation representations based on, e.g., how triples of relations interact with each other. Finally, we empirically validate our theoretical findings, showing that the use of richer motifs results in better performance on a wide range of datasets drawn from different domains.
        ]]></description>
    </item>
    <item>
        <title>Enhancing Input-Label Mapping in In-Context Learning with Contrastive Decoding</title>
        <link>https://arxiv.org/abs/2502.13738</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.13738v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Keqin Peng, Liang Ding, Yuanxin Ouyang, Meng Fang, Yancheng Yuan, Dacheng Tao</dc:creator>
        <description><![CDATA[
            背景：大语言模型在上下文学习中常忽略输入 - 标签映射信息，更多依赖预训练知识。方法：提出上下文对比解码（ICCD）方法，通过对比正负上下文示例的输出分布来强调输入 - 标签映射。效果：在7个自然语言理解任务的实验表明，ICCD方法在6种不同规模的大语言模型上均带来持续且显著的提升，平均提升最高达1.8，且无需额外训练，与多种示例选择方法结合也能提升性能，适用性广泛。
            arXiv:2502.13738v2 Announce Type: replace 
Abstract: Large language models (LLMs) excel at a range of tasks through in-context learning (ICL), where only a few task examples guide their predictions. However, prior research highlights that LLMs often overlook input-label mapping information in ICL, relying more on their pre-trained knowledge. To address this issue, we introduce In-Context Contrastive Decoding (ICCD), a novel method that emphasizes input-label mapping by contrasting the output distributions between positive and negative in-context examples. Experiments on 7 natural language understanding (NLU) tasks show that our ICCD method brings consistent and significant improvement (up to +1.8 improvement on average) upon 6 different scales of LLMs without requiring additional training. Our approach is versatile, enhancing performance with various demonstration selection methods, demonstrating its broad applicability and effectiveness. The code and scripts are released at https://github.com/Romainpkq/CD_ICL.
        ]]></description>
    </item>
    <item>
        <title>Tree-of-Debate: Multi-Persona Debate Trees Elicit Critical Thinking for Scientific Comparative Analysis</title>
        <link>https://arxiv.org/abs/2502.14767</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.14767v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Priyanka Kargupta, Ishika Agarwal, Tal August, Jiawei Han</dc:creator>
        <description><![CDATA[
            背景：现代技术使研究呈指数级增长，科学发现愈发碎片化，难以评估相关研究的意义等。方法：受大语言模型及多智能体辩论启发，引入Tree-of-Debate（ToD）框架，将科学论文转化为大语言模型角色，动态构建辩论树以进行结构化、批判性推理。效果：经专家评估，在多领域科学文献实验中，ToD能生成有价值论点，有效对比论文，助力研究者文献综述。
            arXiv:2502.14767v2 Announce Type: replace 
Abstract: With the exponential growth of research facilitated by modern technology and improved accessibility, scientific discoveries have become increasingly fragmented within and across fields. This makes it challenging to assess the significance, novelty, incremental findings, and equivalent ideas between related works, particularly those from different research communities. Large language models (LLMs) have recently demonstrated strong quantitative and qualitative reasoning abilities, and multi-agent LLM debates have shown promise in handling complex reasoning tasks by exploring diverse perspectives and reasoning paths. Inspired by this, we introduce Tree-of-Debate (ToD), a framework which converts scientific papers into LLM personas that debate their respective novelties. To emphasize structured, critical reasoning rather than focusing solely on outcomes, ToD dynamically constructs a debate tree, enabling fine-grained analysis of independent novelty arguments within scholarly articles. Through experiments on scientific literature across various domains, evaluated by expert researchers, we demonstrate that ToD generates informative arguments, effectively contrasts papers, and supports researchers in their literature review.
        ]]></description>
    </item>
    <item>
        <title>DISC: DISC: Dynamic Decomposition Improves LLM Inference Scaling</title>
        <link>https://arxiv.org/abs/2502.16706</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.16706v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jonathan Light, Wei Cheng, Benjamin Riviere, Wu Yue, Masafumi Oyamada, Mengdi Wang, Yisong Yue, Santiago Paternain, Haifeng Chen</dc:creator>
        <description><![CDATA[
            大语言模型的推理扩展方法常将问题分解成步骤或标记组，但这些步骤及大小通常是固定或基于领域知识手动设计的。本文提出动态分解方法，在推理时自适应、自动地将解决方案和推理轨迹分解成可管理的步骤。通过更有效地分配计算资源，尤其是细分困难步骤并优先采样，显著提高了推理效率。在APPS、MATH和LiveCodeBench等基准测试中，动态分解优于固定策略，分别降低pass@10错误率5.0%、6.7%和10.5%。
            arXiv:2502.16706v2 Announce Type: replace 
Abstract: Inference scaling methods for large language models often work by breaking problems into steps or groups of tokens, then sampling and selecting the best next steps. However, these steps and their sizes are usually fixed or manually designed based on domain knowledge. We introduce dynamic decomposition, a method that adaptively and automatically breaks down solution and reasoning traces into manageable steps during inference. By allocating compute more effectively - especially by subdividing difficult steps and prioritizing their sampling - dynamic decomposition significantly boosts inference efficiency. Experiments on benchmarks like APPS, MATH, and LiveCodeBench show that dynamic decomposition outperforms fixed strategies such as token-level, sentence-level, and single-step decompositions, reducing the pass@10 error rate by 5.0%, 6.7%, and 10.5% respectively. These results show the promise of dynamic decomposition for improving a broad range of inference scaling techniques.
        ]]></description>
    </item>
    <item>
        <title>HAIC: Improving Human Action Understanding and Generation with Better Captions for Multi-modal Large Language Models</title>
        <link>https://arxiv.org/abs/2502.20811</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.20811v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiao Wang, Jingyun Hua, Weihong Lin, Yuanxing Zhang, Fuzheng Zhang, Jianlong Wu, Di Zhang, Liqiang Nie</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型在视频理解方面取得进展，但在人类动作视频理解上因缺乏高质量数据而受限。方法：提出两阶段数据标注流程，先从网络收集清晰人类动作视频，再用标准化字幕格式标注。据此整理出HAICTrain和HAICBench两个数据集。效果：用HAICTrain训练能显著提升4个基准测试中的人类动作理解能力，还可改善文本到视频的生成结果，两个数据集已发布。
            arXiv:2502.20811v2 Announce Type: replace 
Abstract: Recent Multi-modal Large Language Models (MLLMs) have made great progress in video understanding. However, their performance on videos involving human actions is still limited by the lack of high-quality data. To address this, we introduce a two-stage data annotation pipeline. First, we design strategies to accumulate videos featuring clear human actions from the Internet. Second, videos are annotated in a standardized caption format that uses human attributes to distinguish individuals and chronologically details their actions and interactions. Through this pipeline, we curate two datasets, namely HAICTrain and HAICBench. \textbf{HAICTrain} comprises 126K video-caption pairs generated by Gemini-Pro and verified for training purposes. Meanwhile, \textbf{HAICBench} includes 412 manually annotated video-caption pairs and 2,000 QA pairs, for a comprehensive evaluation of human action understanding. Experimental results demonstrate that training with HAICTrain not only significantly enhances human understanding abilities across 4 benchmarks, but can also improve text-to-video generation results. Both the HAICTrain and HAICBench are released at https://huggingface.co/datasets/KuaishouHAIC/HAIC.
        ]]></description>
    </item>
    <item>
        <title>BRIDGE: Bootstrapping Text to Control Time-Series Generation via Multi-Agent Iterative Optimization and Diffusion Modeling</title>
        <link>https://arxiv.org/abs/2503.02445</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.02445v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hao Li, Yu-Hao Huang, Chang Xu, Viktor Schlegel, Renhe Jiang, Riza Batista-Navarro, Goran Nenadic, Jiang Bian</dc:creator>
        <description><![CDATA[
            时间序列生成（TSG）在多领域应用广泛，但现有方法多针对无条件单领域。现实需求跨领域可控生成。本文认为文本可提供语义等信息来指导TSG，提出“文本控制TSG”任务。为解决数据稀缺问题，提出基于大语言模型的多智能体框架合成文本到时间序列数据集，还引入BRIDGE框架集成语义原型与文本描述。该方法在12个数据集中的11个达到了最先进的生成保真度，与无文本输入生成相比，均方误差（MSE）可控性提高达12%，平均绝对误差（MAE）提高6%。
            arXiv:2503.02445v4 Announce Type: replace 
Abstract: Time-series Generation (TSG) is a prominent research area with broad applications in simulations, data augmentation, and counterfactual analysis. While existing methods have shown promise in unconditional single-domain TSG, real-world applications demand for cross-domain approaches capable of controlled generation tailored to domain-specific constraints and instance-level requirements. In this paper, we argue that text can provide semantic insights, domain information and instance-specific temporal patterns, to guide and improve TSG. We introduce ``Text-Controlled TSG'', a task focused on generating realistic time series by incorporating textual descriptions. To address data scarcity in this setting, we propose a novel LLM-based Multi-Agent framework that synthesizes diverse, realistic text-to-TS datasets. Furthermore, we introduce BRIDGE, a hybrid text-controlled TSG framework that integrates semantic prototypes with text description for supporting domain-level guidance. This approach achieves state-of-the-art generation fidelity on 11 of 12 datasets, and improves controllability by up to 12% on MSE and 6% MAE compared to no text input generation, highlighting its potential for generating tailored time-series data.
        ]]></description>
    </item>
    <item>
        <title>nvBench 2.0: Resolving Ambiguity in Text-to-Visualization through Stepwise Reasoning</title>
        <link>https://arxiv.org/abs/2503.12880</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.12880v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tianqi Luo, Chuhan Huang, Leixian Shen, Boyan Li, Shuyu Shen, Wei Zeng, Nan Tang, Yuyu Luo</dc:creator>
        <description><![CDATA[
            背景：文本到可视化（Text2VIS）面临解读模糊查询的挑战，用户常使用不精确语言表达需求。方法：引入nvBench 2.0基准，包含7878个自然语言查询和24076个对应可视化，通过受控歧义注入流程构建；提出基于大语言模型的Step - Text2Vis，在nvBench 2.0上训练，通过逐步偏好优化提升性能。效果：Step - Text2Vis优于所有基线模型，为模糊Text2VIS任务创造新的最优表现。
            arXiv:2503.12880v2 Announce Type: replace 
Abstract: Text-to-Visualization (Text2VIS) enables users to create visualizations from natural language queries, making data insights more accessible. However, Text2VIS faces challenges in interpreting ambiguous queries, as users often express their visualization needs in imprecise language.
  To address this challenge, we introduce nBench 2.0, a new benchmark designed to evaluate Text2VIS systems in scenarios involving ambiguous queries. nvBench 2.0 includes 7,878 natural language queries and 24,076 corresponding visualizations, derived from 780 tables across 153 domains. It is built using a controlled ambiguity-injection pipeline that generates ambiguous queries through a reverse-generation workflow. By starting with unambiguous seed visualizations and selectively injecting ambiguities, the pipeline yields multiple valid interpretations for each query, with each ambiguous query traceable to its corresponding visualization through step-wise reasoning paths.
  We evaluate various Large Language Models (LLMs) on their ability to perform ambiguous Text2VIS tasks using nBench 2.0. We also propose Step-Text2Vis, an LLM-based model trained on nvBench 2.0, which enhances performance in ambiguous scenarios through step-wise preference optimization. Our results show that Step-Text2Vis outperforms all baselines, setting a new state-of-the-art for ambiguous Text2VIS tasks. Our source code and data are available at https://nvbench2.github.io/
        ]]></description>
    </item>
    <item>
        <title>Towards Achieving Perfect Multimodal Alignment</title>
        <link>https://arxiv.org/abs/2503.15352</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.15352v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Abhi Kamboj, Minh N. Do</dc:creator>
        <description><![CDATA[
            背景：多模态对齐旨在构建联合潜在向量空间，使同一概念的不同模态映射到相邻潜在向量。方法：将其转化为逆问题，证明特定条件下各模态配对数据可映射到等效潜在向量，即完美对齐；无法实现时用多模态数据矩阵的奇异值分解近似。效果：在合成多模态高斯数据实验中，完美对齐法比对比对齐法更有效；在人体动作识别跨模态迁移应用中，显著提升模型准确率。
            arXiv:2503.15352v2 Announce Type: replace 
Abstract: Multimodal alignment constructs a joint latent vector space where modalities representing the same concept map to neighboring latent vectors. We formulate this as an inverse problem and show that, under certain conditions, paired data from each modality can map to equivalent latent vectors, which we refer to as perfect alignment. When perfect alignment cannot be achieved, it can be approximated using the Singular Value Decomposition (SVD) of a multimodal data matrix. Experiments on synthetic multimodal Gaussian data verify the effectiveness of our perfect alignment method compared to a learned contrastive alignment method. We further demonstrate the practical application of cross-modal transfer for human action recognition, showing that perfect alignment significantly enhances the model's accuracy. We conclude by discussing how these findings can be applied to various modalities and tasks and the limitations of our method. We hope these findings inspire further exploration of perfect alignment and its applications in representation learning.
        ]]></description>
    </item>
    <item>
        <title>What Changed and What Could Have Changed? State-Change Counterfactuals for Procedure-Aware Video Representation Learning</title>
        <link>https://arxiv.org/abs/2503.21055</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.21055v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chi-Hsi Kung, Frangil Ramirez, Juhyung Ha, Yi-Ting Chen, David Crandall, Yi-Hsuan Tsai</dc:creator>
        <description><![CDATA[
            背景：理解程序性活动需建模动作步骤与场景变化的相互影响，现有工作未明确学习状态变化。方法：将大语言模型生成的状态变化描述作为视频编码器的监督信号，生成模拟失败结果的状态变化反事实，使模型进行反事实推理。效果：通过在多个程序性任务上实验，验证了该方法的有效性，在多个任务上取得显著提升，后续将公开源代码和数据。
            arXiv:2503.21055v2 Announce Type: replace 
Abstract: Understanding a procedural activity requires modeling both how action steps transform the scene and how evolving scene transformations can influence the sequence of action steps, even those that are accidental or erroneous. Existing work has studied procedure-aware video representations by proposing novel approaches such as modeling the temporal order of actions, and has not explicitly learned the state changes (scene transformations). In this work, we study procedure-aware video representation learning by incorporating state-change descriptions generated by Large Language Models (LLMs) as supervision signals for video encoders. Moreover, we generate state-change counterfactuals that simulate hypothesized failure outcomes, allowing models to learn by imagining the unseen ``What if'' scenarios. This counterfactual reasoning facilitates the model's ability to understand the cause and effect of each step in an activity. To verify the procedure awareness of our model, we conduct extensive experiments on procedure-aware tasks, including temporal action segmentation, error detection, action phase classification, frame retrieval, multi-instance retrieval, and action recognition. Our results demonstrate the effectiveness of the proposed state-change descriptions and their counterfactuals, and achieve significant improvements on multiple tasks. We will make our source code and data publicly available soon.
        ]]></description>
    </item>
    <item>
        <title>ThinkEdit: Interpretable Weight Editing to Mitigate Overly Short Thinking in Reasoning Models</title>
        <link>https://arxiv.org/abs/2503.22048</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.22048v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chung-En Sun, Ge Yan, Tsui-Wei Weng</dc:creator>
        <description><![CDATA[
            背景：大语言模型结合思维链推理虽有强大解题能力，但存在推理过短致简单数学题表现不佳的问题。方法：研究推理长度在模型隐藏表征中的情况，发现其由表征空间的线性方向决定，提出ThinkEdit方法，找出约4%主导短推理的注意力头，编辑其输出投影权重以去除短推理方向，仅改动0.2%的模型参数。效果：有效减少过短推理，短推理输出准确率提升6.39%，多个数学基准测试整体提升3.34%。
            arXiv:2503.22048v3 Announce Type: replace 
Abstract: Recent studies have shown that Large Language Models (LLMs) augmented with chain-of-thought (CoT) reasoning demonstrate impressive problem-solving abilities. However, in this work, we identify a recurring issue where these models occasionally generate overly short reasoning, leading to degraded performance on even simple mathematical problems. Specifically, we investigate how reasoning length is embedded in the hidden representations of reasoning models and its impact on accuracy. Our analysis reveals that reasoning length is governed by a linear direction in the representation space, allowing us to induce overly short reasoning by steering the model along this direction. Building on this insight, we introduce \textbf{\textit{ThinkEdit}}, a simple yet effective weight-editing approach to mitigate the issue of overly short reasoning. We first identify a small subset of attention heads (approximately 4%) that predominantly drive short reasoning behavior. We then edit the output projection weights of these heads to remove the short reasoning direction. With changes to only 0.2% of the model's parameters, \textbf{\textit{ThinkEdit}} effectively reduces overly short reasoning and yields notable accuracy gains for short reasoning outputs (+6.39%), along with an overall improvement across multiple math benchmarks (+3.34%). Our findings provide new mechanistic insights into how reasoning length is controlled within LLMs and highlight the potential of fine-grained model interventions to improve reasoning quality. Our code is available at: https://github.com/Trustworthy-ML-Lab/ThinkEdit\
        ]]></description>
    </item>
    <item>
        <title>Can LLMs Interpret and Leverage Structured Linguistic Representations? A Case Study with AMRs</title>
        <link>https://arxiv.org/abs/2504.04745</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.04745v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ankush Raut, Xiaofeng Zhu, Maria Leonor Pacheco</dc:creator>
        <description><![CDATA[
            该论文背景是评估大语言模型利用结构化语言表征形式的上下文信息的能力。方法是使用8位量化和指令调优版本的Llama 3.1（8B）、Phi - 3和Mistral 7B，研究利用抽象意义表征（AMR）结构编码短、长上下文在不同语言任务中的影响。效果显示，短上下文任务中，用AMR增强提示常降低模型性能；长上下文任务如对话摘要中能提升性能，如使Llama 3.1零样本余弦相似度从66.2%提升到76%，且新的大模型更明显，还能有效从线性化AMR重构原文，最佳可达81.3%。
            arXiv:2504.04745v2 Announce Type: replace 
Abstract: This paper evaluates the ability of Large Language Models (LLMs) to leverage contextual information in the form of structured linguistic representations. Specifically, we examine the impact of encoding both short and long contexts using Abstract Meaning Representation (AMR) structures across a diverse set of language tasks. We perform our analysis using 8-bit quantized and instruction-tuned versions of Llama 3.1 (8B), Phi-3, and Mistral 7B. Our results indicate that, for tasks involving short contexts, augmenting the prompt with the AMR of the original language context often degrades the performance of the underlying LLM. However, for tasks that involve long contexts, such as dialogue summarization in the SAMSum dataset, this enhancement improves LLM performance, for example, by increasing the zero-shot cosine similarity score of Llama 3.1 from 66.2% to 76%. This improvement is more evident in the newer and larger LLMs, but does not extend to the older or smaller ones. In addition, we observe that LLMs can effectively reconstruct the original text from a linearized AMR, achieving a cosine similarity of 81.3% in the best-case scenario.
        ]]></description>
    </item>
    <item>
        <title>Skywork R1V: Pioneering Multimodal Reasoning with Chain-of-Thought</title>
        <link>https://arxiv.org/abs/2504.05599</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2504.05599v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yi Peng, Peiyu Wang, Xiaokun Wang, Yichen Wei, Jiangbo Pei, Weijie Qiu, Ai Jian, Yunzhuo Hao, Jiachun Pan, Tianyidan Xie, Li Ge, Rongxian Zhuang, Xuchen Song, Yang Liu, Yahui Zhou</dc:creator>
        <description><![CDATA[
            背景：需拓展大语言模型到视觉模态并加强视觉 - 文本对齐。方法：提出 Skywork R1V 多模态推理模型，通过高效多模态迁移方法拓展到视觉模态，用轻量级视觉投影器实现无缝适配；采用结合迭代监督微调与组相对策略优化的混合优化策略；引入自适应长度思维链蒸馏方法生成推理数据。效果：38B 参数的 Skywork R1V 表现出色，MMMU 基准得 69.0 分、MathVista 得 67.5 分，AIME 得 72.0 分、MATH500 得 94.0 分。
            arXiv:2504.05599v2 Announce Type: replace 
Abstract: We introduce Skywork R1V, a multimodal reasoning model extending the an R1-series Large language models (LLM) to visual modalities via an efficient multimodal transfer method. Leveraging a lightweight visual projector, Skywork R1V facilitates seamless multimodal adaptation without necessitating retraining of either the foundational language model or the vision encoder. To strengthen visual-text alignment, we propose a hybrid optimization strategy that combines Iterative Supervised Fine-Tuning (SFT) with Group Relative Policy Optimization (GRPO), significantly enhancing cross-modal integration efficiency. Additionally, we introduce an adaptive-length Chain-of-Thought distillation approach for reasoning data generation. This approach dynamically optimizes reasoning chain lengths, thereby enhancing inference efficiency and preventing excessive reasoning overthinking. Empirical evaluations demonstrate that Skywork R1V, with only 38B parameters, delivers competitive performance, achieving a score of 69.0 on the MMMU benchmark and 67.5 on MathVista. Meanwhile, it maintains robust textual reasoning performance, evidenced by impressive scores of 72.0 on AIME and 94.0 on MATH500. The Skywork R1V model weights have been publicly released to promote openness and reproducibility.
        ]]></description>
    </item>
    <item>
        <title>Skywork-VL Reward: An Effective Reward Model for Multimodal Understanding and Reasoning</title>
        <link>https://arxiv.org/abs/2505.07263</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.07263v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xiaokun Wang, Peiyu Wang, Jiangbo Pei, Wei Shen, Yi Peng, Yunzhuo Hao, Weijie Qiu, Ai Jian, Tianyidan Xie, Xuchen Song, Yang Liu, Yahui Zhou</dc:creator>
        <description><![CDATA[
            背景：需有效多模态奖励模型用于理解和推理任务。方法：提出Skywork - VL Reward，构建大规模多模态偏好数据集，涵盖多种任务场景；基于Qwen2.5 - VL - 7B - Instruct设计奖励模型架构，集成奖励头并在成对偏好数据上用成对排序损失进行多阶段微调。效果：在多模态VL - RewardBench取得最优结果，在文本RewardBench有竞争力，基于其构建的偏好数据能显著提升多模态推理能力，推动了多模态对齐奖励模型发展。
            arXiv:2505.07263v2 Announce Type: replace 
Abstract: We propose Skywork-VL Reward, a multimodal reward model that provides reward signals for both multimodal understanding and reasoning tasks. Our technical approach comprises two key components: First, we construct a large-scale multimodal preference dataset that covers a wide range of tasks and scenarios, with responses collected from both standard vision-language models (VLMs) and advanced VLM reasoners. Second, we design a reward model architecture based on Qwen2.5-VL-7B-Instruct, integrating a reward head and applying multi-stage fine-tuning using pairwise ranking loss on pairwise preference data. Experimental evaluations show that Skywork-VL Reward achieves state-of-the-art results on multimodal VL-RewardBench and exhibits competitive performance on the text-only RewardBench benchmark. Furthermore, preference data constructed based on our Skywork-VL Reward proves highly effective for training Mixed Preference Optimization (MPO), leading to significant improvements in multimodal reasoning capabilities. Our results underscore Skywork-VL Reward as a significant advancement toward general-purpose, reliable reward models for multimodal alignment. Our model has been publicly released to promote transparency and reproducibility.
        ]]></description>
    </item>
    <item>
        <title>General-Reasoner: Advancing LLM Reasoning Across All Domains</title>
        <link>https://arxiv.org/abs/2505.14652</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.14652v5</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xueguang Ma, Qian Liu, Dongfu Jiang, Ge Zhang, Zejun Ma, Wenhu Chen</dc:creator>
        <description><![CDATA[
            背景：当前大语言模型推理研究多聚焦数学和编码领域，限制了其在其他领域的应用。方法：提出General - Reasoner训练范式，构建大规模、高质量可验证答案的数据集，开发基于生成模型的答案验证器。效果：在涵盖物理、化学等领域的12个基准测试中，General - Reasoner优于现有基线方法，实现了稳健且可泛化的推理性能，在数学推理任务中也保持高效。
            arXiv:2505.14652v5 Announce Type: replace 
Abstract: Reinforcement learning (RL) has recently demonstrated strong potential in enhancing the reasoning capabilities of large language models (LLMs). Particularly, the "Zero" reinforcement learning introduced by Deepseek-R1-Zero, enables direct RL training of base LLMs without relying on an intermediate supervised fine-tuning stage. Despite these advancements, current works for LLM reasoning mainly focus on mathematical and coding domains, largely due to data abundance and the ease of answer verification. This limits the applicability and generalization of such models to broader domains, where questions often have diverse answer representations, and data is more scarce. In this paper, we propose General-Reasoner, a novel training paradigm designed to enhance LLM reasoning capabilities across diverse domains. Our key contributions include: (1) constructing a large-scale, high-quality dataset of questions with verifiable answers curated by web crawling, covering a wide range of disciplines; and (2) developing a generative model-based answer verifier, which replaces traditional rule-based verification with the capability of chain-of-thought and context-awareness. We train a series of models and evaluate them on a wide range of datasets covering wide domains like physics, chemistry, finance, electronics etc. Our comprehensive evaluation across these 12 benchmarks (e.g. MMLU-Pro, GPQA, SuperGPQA, TheoremQA, BBEH and MATH AMC) demonstrates that General-Reasoner outperforms existing baseline methods, achieving robust and generalizable reasoning performance while maintaining superior effectiveness in mathematical reasoning tasks.
        ]]></description>
    </item>
    <item>
        <title>Seeing Far and Clearly: Mitigating Hallucinations in MLLMs with Attention Causal Decoding</title>
        <link>https://arxiv.org/abs/2505.16652</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.16652v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Feilong Tang, Chengzhi Liu, Zhongxing Xu, Ming Hu, Zelin Peng, Zhiwei Yang, Jionglong Su, Minquan Lin, Yifan Peng, Xuelian Cheng, Imran Razzak, Zongyuan Ge</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型（MLLMs）在视觉问答中表现进步，但常出现幻觉问题。方法：将幻觉分为初始幻觉和滚雪球幻觉两类，受因果推理启发，提出利用因果掩码建立多模态标记间信息传播，干预传播过程以增强上下文推理，推出FarSight解码策略，设计注意力寄存器结构，提出位置感知编码方法。效果：大量实验表明，FarSight在图像和视频基准测试中，能显著减轻不同MLLMs的幻觉问题。
            arXiv:2505.16652v2 Announce Type: replace 
Abstract: Recent advancements in multimodal large language models (MLLMs) have significantly improved performance in visual question answering. However, they often suffer from hallucinations. In this work, hallucinations are categorized into two main types: initial hallucinations and snowball hallucinations. We argue that adequate contextual information can be extracted directly from the token interaction process. Inspired by causal inference in the decoding strategy, we propose to leverage causal masks to establish information propagation between multimodal tokens. The hypothesis is that insufficient interaction between those tokens may lead the model to rely on outlier tokens, overlooking dense and rich contextual cues. Therefore, we propose to intervene in the propagation process by tackling outlier tokens to enhance in-context inference. With this goal, we present FarSight, a versatile plug-and-play decoding strategy to reduce attention interference from outlier tokens merely by optimizing the causal mask. The heart of our method is effective token propagation. We design an attention register structure within the upper triangular matrix of the causal mask, dynamically allocating attention to capture attention diverted to outlier tokens. Moreover, a positional awareness encoding method with a diminishing masking rate is proposed, allowing the model to attend to further preceding tokens, especially for video sequence tasks. With extensive experiments, FarSight demonstrates significant hallucination-mitigating performance across different MLLMs on both image and video benchmarks, proving its effectiveness.
        ]]></description>
    </item>
    <item>
        <title>Four Eyes Are Better Than Two: Harnessing the Collaborative Potential of Large Models via Differentiated Thinking and Complementary Ensembles</title>
        <link>https://arxiv.org/abs/2505.16784</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.16784v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jun Xie, Xiongjun Guan, Yingjian Zhu, Zhaoran Zhao, Xinming Wang, Hongzhu Yi, Feng Chen, Zhepeng Wang</dc:creator>
        <description><![CDATA[
            背景：受大模型成功启发，需解决视频理解任务。方法：评估并利用前沿可访问的多模态大模型，通过少样本学习和模型集成策略使其适配视频理解任务，系统探索和评估多样化提示风格与过程范式，还引入额外阶段促进周期结果的合作与集成。效果：精心设计的方法下，单个多模态模型直接使用就超越此前包含多个额外过程的最优方法，且集成策略实现了显著的性能提升。
            arXiv:2505.16784v2 Announce Type: replace 
Abstract: In this paper, we present the runner-up solution for the Ego4D EgoSchema Challenge at CVPR 2025 (Confirmed on May 20, 2025). Inspired by the success of large models, we evaluate and leverage leading accessible multimodal large models and adapt them to video understanding tasks via few-shot learning and model ensemble strategies. Specifically, diversified prompt styles and process paradigms are systematically explored and evaluated to effectively guide the attention of large models, fully unleashing their powerful generalization and adaptability abilities. Experimental results demonstrate that, with our carefully designed approach, directly utilizing an individual multimodal model already outperforms the previous state-of-the-art (SOTA) method which includes several additional processes. Besides, an additional stage is further introduced that facilitates the cooperation and ensemble of periodic results, which achieves impressive performance improvements. We hope this work serves as a valuable reference for the practical application of large models and inspires future research in the field. Our Code is available at https://github.com/XiongjunGuan/EgoSchema-CVPR25.
        ]]></description>
    </item>
    <item>
        <title>ChartGalaxy: A Dataset for Infographic Chart Understanding and Generation</title>
        <link>https://arxiv.org/abs/2505.18668</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.18668v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Zhen Li, Duan Li, Yukai Guo, Xinyuan Guo, Bowen Li, Lanxi Xiao, Shenyu Qiao, Jiashu Chen, Zijian Wu, Hui Zhang, Xinhuan Shu, Shixia Liu</dc:creator>
        <description><![CDATA[
            背景：信息图表结合视觉与文本信息来传达抽象数据，但丰富的视觉和结构信息给大视觉语言模型带来挑战。方法：引入百万规模的数据集ChartGalaxy，通过归纳过程识别75种图表类型、330种图表变体和68种布局模板，以此编程创建合成图表。效果：通过微调提升信息图表理解能力、对信息图表代码生成进行基准测试、实现基于示例的信息图表生成，为增强大视觉语言模型的多模态推理和生成能力提供资源。
            arXiv:2505.18668v3 Announce Type: replace 
Abstract: Infographic charts are a powerful medium for communicating abstract data by combining visual elements (e.g., charts, images) with textual information. However, their visual and structural richness poses challenges for large vision-language models (LVLMs), which are typically trained on plain charts. To bridge this gap, we introduce ChartGalaxy, a million-scale dataset designed to advance the understanding and generation of infographic charts. The dataset is constructed through an inductive process that identifies 75 chart types, 330 chart variations, and 68 layout templates from real infographic charts and uses them to create synthetic ones programmatically. We showcase the utility of this dataset through: 1) improving infographic chart understanding via fine-tuning, 2) benchmarking code generation for infographic charts, and 3) enabling example-based infographic chart generation. By capturing the visual and structural complexity of real design, ChartGalaxy provides a useful resource for enhancing multimodal reasoning and generation in LVLMs.
        ]]></description>
    </item>
    <item>
        <title>Can MLLMs Guide Me Home? A Benchmark Study on Fine-Grained Visual Reasoning from Transit Maps</title>
        <link>https://arxiv.org/abs/2505.18675</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.18675v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sicheng Feng, Song Wang, Shuyi Ouyang, Lingdong Kong, Zikai Song, Jianke Zhu, Huan Wang, Xinchao Wang</dc:creator>
        <description><![CDATA[
            背景：多模态大语言模型在视觉任务取得进展，但细粒度视觉理解推理能力评估不足。方法：引入评估MLLMs细粒度视觉理解和空间推理能力的基准ReasonMap，涵盖30个城市的高分辨率交通地图及1008个问答对，设计两级评估流程。效果：对15个流行MLLMs评估发现，开源模型中基础模型表现更好，闭源模型相反；遮挡视觉输入时性能下降，该研究为视觉推理提供新见解。
            arXiv:2505.18675v2 Announce Type: replace 
Abstract: Multimodal large language models (MLLMs) have recently achieved significant progress in visual tasks, including semantic scene understanding and text-image alignment, with reasoning variants enhancing performance on complex tasks involving mathematics and logic. However, their capacity for reasoning tasks involving fine-grained visual understanding remains insufficiently evaluated. To address this gap, we introduce ReasonMap, a benchmark designed to assess the fine-grained visual understanding and spatial reasoning abilities of MLLMs. ReasonMap encompasses high-resolution transit maps from 30 cities across 13 countries and includes 1,008 question-answer pairs spanning two question types and three templates. Furthermore, we design a two-level evaluation pipeline that properly assesses answer correctness and quality. Comprehensive evaluations of 15 popular MLLMs, including both base and reasoning variants, reveal a counterintuitive pattern: among open-source models, base models outperform reasoning ones, while the opposite trend is observed in closed-source models. Additionally, performance generally degrades when visual inputs are masked, indicating that while MLLMs can leverage prior knowledge to answer some questions, fine-grained visual reasoning tasks still require genuine visual perception for strong performance. Our benchmark study offers new insights into visual reasoning and contributes to investigating the gap between open-source and closed-source models.
        ]]></description>
    </item>
    <item>
        <title>Compliance-to-Code: Enhancing Financial Compliance Checking via Code Generation</title>
        <link>https://arxiv.org/abs/2505.19804</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.19804v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Siyuan Li, Jian Chen, Rui Yao, Xuming Hu, Peilin Zhou, Weihua Qiu, Simin Zhang, Chucheng Dong, Zhiyao Li, Qipeng Xie, Zixuan Yuan</dc:creator>
        <description><![CDATA[
            背景：金融法规复杂，现有RegTech和大语言模型在处理中文金融法规时存在知识表示不完整、推理能力不足等问题，且缺少合适数据集。方法：提出首个专注金融监管合规的大规模中文数据集Compliance - to - Code，涵盖361条法规的1159条注释条款，对条款模块化结构处理并提供代码映射等；还展示了FinCheck流程。效果：有助于自动化审计，能促进金融合规检查的代码生成。
            arXiv:2505.19804v2 Announce Type: replace 
Abstract: Nowadays, regulatory compliance has become a cornerstone of corporate governance, ensuring adherence to systematic legal frameworks. At its core, financial regulations often comprise highly intricate provisions, layered logical structures, and numerous exceptions, which inevitably result in labor-intensive or comprehension challenges. To mitigate this, recent Regulatory Technology (RegTech) and Large Language Models (LLMs) have gained significant attention in automating the conversion of regulatory text into executable compliance logic. However, their performance remains suboptimal particularly when applied to Chinese-language financial regulations, due to three key limitations: (1) incomplete domain-specific knowledge representation, (2) insufficient hierarchical reasoning capabilities, and (3) failure to maintain temporal and logical coherence. One promising solution is to develop a domain specific and code-oriented datasets for model training. Existing datasets such as LexGLUE, LegalBench, and CODE-ACCORD are often English-focused, domain-mismatched, or lack fine-grained granularity for compliance code generation. To fill these gaps, we present Compliance-to-Code, the first large-scale Chinese dataset dedicated to financial regulatory compliance. Covering 1,159 annotated clauses from 361 regulations across ten categories, each clause is modularly structured with four logical elements-subject, condition, constraint, and contextual information-along with regulation relations. We provide deterministic Python code mappings, detailed code reasoning, and code explanations to facilitate automated auditing. To demonstrate utility, we present FinCheck: a pipeline for regulation structuring, code generation, and report generation.
        ]]></description>
    </item>
    <item>
        <title>Enigmata: Scaling Logical Reasoning in Large Language Models with Synthetic Verifiable Puzzles</title>
        <link>https://arxiv.org/abs/2505.19914</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.19914v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiangjie Chen, Qianyu He, Siyu Yuan, Aili Chen, Zhicheng Cai, Weinan Dai, Hongli Yu, Qiying Yu, Xuefeng Li, Jiaze Chen, Hao Zhou, Mingxuan Wang</dc:creator>
        <description><![CDATA[
            背景：大语言模型在高级推理任务表现出色，但在人类无需领域知识就能解决的谜题推理上存在困难。方法：引入Enigmata套件，含36个任务，有可控制难度的生成器和基于规则的验证器，还提出Enigmata - Eval基准并开发多任务RLVR策略。效果：训练的Qwen2.5 - 32B - Enigmata模型在谜题推理基准上超越o3 - mini - high和o1，如ARC - AGI达32.8%、ARC - AGI 2达0.6%，且在数学推理等任务有良好泛化能力。
            arXiv:2505.19914v2 Announce Type: replace 
Abstract: Large Language Models (LLMs), such as OpenAI's o1 and DeepSeek's R1, excel at advanced reasoning tasks like math and coding via Reinforcement Learning with Verifiable Rewards (RLVR), but still struggle with puzzles solvable by humans without domain knowledge. We introduce Enigmata, the first comprehensive suite tailored for improving LLMs with puzzle reasoning skills. It includes 36 tasks across seven categories, each with 1) a generator that produces unlimited examples with controllable difficulty and 2) a rule-based verifier for automatic evaluation. This generator-verifier design supports scalable, multi-task RL training, fine-grained analysis, and seamless RLVR integration. We further propose Enigmata-Eval, a rigorous benchmark, and develop optimized multi-task RLVR strategies. Our trained model, Qwen2.5-32B-Enigmata, consistently surpasses o3-mini-high and o1 on the puzzle reasoning benchmarks like Enigmata-Eval, ARC-AGI (32.8%), and ARC-AGI 2 (0.6%). It also generalizes well to out-of-domain puzzle benchmarks and mathematical reasoning, with little multi-tasking trade-off. When trained on larger models like Seed1.5-Thinking (20B activated parameters and 200B total parameters), puzzle data from Enigmata further boosts SoTA performance on advanced math and STEM reasoning tasks such as AIME (2024-2025), BeyondAIME and GPQA (Diamond), showing nice generalization benefits of Enigmata. This work offers a unified, controllable framework for advancing logical reasoning in LLMs. Resources of this work can be found at https://seed-enigmata.github.io.
        ]]></description>
    </item>
    <item>
        <title>BioHopR: A Benchmark for Multi-Hop, Multi-Answer Reasoning in Biomedical Domain</title>
        <link>https://arxiv.org/abs/2505.22240</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22240v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yunsoo Kim, Yusuf Abdulle, Honghan Wu</dc:creator>
        <description><![CDATA[
            背景：生物医学推理需跨实体关系，现有基准缺乏对生物医学领域多跳推理的评估。方法：引入BioHopR基准，基于PrimeKG构建，含1跳和2跳推理任务，反映生物医学复杂性。效果：评估显示，O3 - mini在1跳任务精度达37.93%、2跳达14.57%，优于GPT4O等模型，但所有模型多跳性能均显著下降。BioHopR为评估推理能力设新标准，凸显模型差距，助力生物医学大模型发展。
            arXiv:2505.22240v2 Announce Type: replace 
Abstract: Biomedical reasoning often requires traversing interconnected relationships across entities such as drugs, diseases, and proteins. Despite the increasing prominence of large language models (LLMs), existing benchmarks lack the ability to evaluate multi-hop reasoning in the biomedical domain, particularly for queries involving one-to-many and many-to-many relationships. This gap leaves the critical challenges of biomedical multi-hop reasoning underexplored. To address this, we introduce BioHopR, a novel benchmark designed to evaluate multi-hop, multi-answer reasoning in structured biomedical knowledge graphs. Built from the comprehensive PrimeKG, BioHopR includes 1-hop and 2-hop reasoning tasks that reflect real-world biomedical complexities.
  Evaluations of state-of-the-art models reveal that O3-mini, a proprietary reasoning-focused model, achieves 37.93% precision on 1-hop tasks and 14.57% on 2-hop tasks, outperforming proprietary models such as GPT4O and open-source biomedical models including HuatuoGPT-o1-70B and Llama-3.3-70B. However, all models exhibit significant declines in multi-hop performance, underscoring the challenges of resolving implicit reasoning steps in the biomedical domain. By addressing the lack of benchmarks for multi-hop reasoning in biomedical domain, BioHopR sets a new standard for evaluating reasoning capabilities and highlights critical gaps between proprietary and open-source models while paving the way for future advancements in biomedical LLMs.
        ]]></description>
    </item>
    <item>
        <title>WorkForceAgent-R1: Incentivizing Reasoning Capability in LLM-based Web Agents via Reinforcement Learning</title>
        <link>https://arxiv.org/abs/2505.22942</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.22942v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yuchen Zhuang, Di Jin, Jiaao Chen, Wenqi Shi, Hanrui Wang, Chao Zhang</dc:creator>
        <description><![CDATA[
            背景：大语言模型赋能的网络代理可自动化企业环境中的复杂实时网络导航任务，但现有依赖监督微调的网络代理因推理能力不足，在处理网络交互动态性时泛化性和鲁棒性较差。方法：引入基于大语言模型的网络代理WorkForceAgent-R1，用基于规则的R1式强化学习框架训练，采用结构化奖励函数。效果：在WorkArena基准测试中，WorkForceAgent-R1比监督微调基线大幅领先10.26 - 16.59%，在面向工作场所的网络导航任务中表现与专有大语言模型代理相当。
            arXiv:2505.22942v2 Announce Type: replace 
Abstract: Large language models (LLMs)-empowered web agents enables automating complex, real-time web navigation tasks in enterprise environments. However, existing web agents relying on supervised fine-tuning (SFT) often struggle with generalization and robustness due to insufficient reasoning capabilities when handling the inherently dynamic nature of web interactions. In this study, we introduce WorkForceAgent-R1, an LLM-based web agent trained using a rule-based R1-style reinforcement learning framework designed explicitly to enhance single-step reasoning and planning for business-oriented web navigation tasks. We employ a structured reward function that evaluates both adherence to output formats and correctness of actions, enabling WorkForceAgent-R1 to implicitly learn robust intermediate reasoning without explicit annotations or extensive expert demonstrations. Extensive experiments on the WorkArena benchmark demonstrate that WorkForceAgent-R1 substantially outperforms SFT baselines by 10.26-16.59%, achieving competitive performance relative to proprietary LLM-based agents (gpt-4o) in workplace-oriented web navigation tasks.
        ]]></description>
    </item>
    <item>
        <title>Reinforcing Video Reasoning with Focused Thinking</title>
        <link>https://arxiv.org/abs/2505.24718</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.24718v3</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jisheng Dang, Jingze Wu, Teng Wang, Xuanhui Lin, Nannan Zhu, Hongbo Chen, Wei-Shi Zheng, Meng Wang, Tat-Seng Chua</dc:creator>
        <description><![CDATA[
            当前强化学习虽提升了多模态大模型复杂推理能力，但存在推理链不聚焦、二元奖励无法考虑部分正确答案等问题。本文提出TW - GRPO框架，采用标记加权机制突出高信息密度标记、抑制冗余标记；将强化学习训练从单选改为多选问答任务，用软奖励实现细粒度梯度估计；还提出问答反转的数据增强策略。实验显示，该框架在多个视频推理和理解基准测试中达最优，如在CLEVRER上准确率达50.4%，较Video - R1提升18.8%，在MMVU上达65.8%。
            arXiv:2505.24718v3 Announce Type: replace 
Abstract: Recent advancements in reinforcement learning, particularly through Group Relative Policy Optimization (GRPO), have significantly improved multimodal large language models for complex reasoning tasks. However, two critical limitations persist: 1) they often produce unfocused, verbose reasoning chains that obscure salient spatiotemporal cues and 2) binary rewarding fails to account for partially correct answers, resulting in high reward variance and inefficient learning. In this paper, we propose TW-GRPO, a novel framework that enhances visual reasoning with focused thinking and dense reward granularity. Specifically, we employs a token weighting mechanism that prioritizes tokens with high informational density (estimated by intra-group information entropy), suppressing redundant tokens like generic reasoning prefixes. Furthermore, we reformulate RL training by shifting from single-choice to multi-choice QA tasks, where soft rewards enable finer-grained gradient estimation by distinguishing partial correctness. Additionally, we propose question-answer inversion, a data augmentation strategy to generate diverse multi-choice samples from existing benchmarks. Experiments demonstrate state-of-the-art performance on several video reasoning and general understanding benchmarks. Notably, TW-GRPO achieves 50.4\% accuracy on CLEVRER (18.8\% improvement over Video-R1) and 65.8\% on MMVU. Our codes are available at \href{https://github.com/longmalongma/TW-GRPO}.
        ]]></description>
    </item>
    <item>
        <title>Comba: Improving Bilinear RNNs with Closed-loop Control</title>
        <link>https://arxiv.org/abs/2506.02475</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02475v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiaxi Hu, Yongqi Pan, Jusen Du, Disen Lan, Xiaqiang Tang, Qingsong Wen, Yuxuan Liang, Weigao Sun</dc:creator>
        <description><![CDATA[
            背景：近期如Gated DeltaNet等高效序列建模方法通过Delta学习规则监督循环内存管理提升性能，结构类似双线性系统。方法：本文先分析双线性循环神经网络（RNNs）优缺点，基于闭环控制理论提出新的双线性RNN变体Comba，采用标量加低秩状态转移及状态和输出反馈校正，在Triton实现硬件高效分块并行内核，并在大规模语料上训练340M/1.3B参数模型。效果：Comba在语言和视觉建模中性能和计算效率更优。
            arXiv:2506.02475v2 Announce Type: replace 
Abstract: Recent efficient sequence modeling methods such as Gated DeltaNet, TTT, and RWKV-7 have achieved performance improvements by supervising the recurrent memory management through Delta learning rule. Unlike previous state-space models (e.g., Mamba) and gated linear attentions (e.g., GLA), these models introduce interactions between the recurrent state and the key vector, structurally resembling bilinear systems. In this paper, we first introduce the concept of Bilinear RNNs with a comprehensive analysis on the advantages and limitations of these models. Then, based on closed-loop control theory, we propose a novel Bilinear RNN variant named Comba, which adopts a scalar-plus-low-rank state transition, with both state feedback and output feedback corrections. We also implement a hardware-efficient chunk-wise parallel kernel in Triton and train models with 340M/1.3B parameters on large-scale corpus. Comba demonstrates superior performance and computation efficiency in both language and vision modeling.
        ]]></description>
    </item>
    <item>
        <title>CoT is Not True Reasoning, It Is Just a Tight Constraint to Imitate: A Theory Perspective</title>
        <link>https://arxiv.org/abs/2506.02878</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.02878v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jintian Shao, Yiming Cheng</dc:creator>
        <description><![CDATA[
            背景：思维链（CoT）提示显著提升了大语言模型在多步推理任务上的表现，引发了模型具有推理能力的广泛观点。方法：本文提出理论反观点，认为CoT并非引发真正的抽象推理，而是作为强大的结构约束，引导大语言模型模仿推理形式，通过强制生成中间步骤，利用模型的序列预测和模式匹配能力。效果：有效约束输出，使其类似连贯的思维过程。
            arXiv:2506.02878v2 Announce Type: replace 
Abstract: Chain-of-Thought (CoT) prompting has demonstrably enhanced the performance of Large Language Models on tasks requiring multi-step inference. This success has led to widespread claims of emergent reasoning capabilities in these models. In this paper, we present a theoretical counter-perspective: Chain-of-Thought (CoT) does not elicit genuine, abstract reasoning. Instead, we argue that Chain-of-Thought functions as a powerful structural constraint that guides Large Language Models to imitate the form of reasoning. By forcing the generation of intermediate steps, Chain-of-Thought leverages the model immense capacity for sequence prediction and pattern matching, effectively constraining its output to sequences that resemble coherent thought processes. Chain-of-Thought (CoT) prompting has demonstrably enhanced the performance of Large Language Models on tasks requiring multi-step inference. This success has led to widespread claims of emergent reasoning capabilities in these models. In this paper, we present a theoretical counter-perspective: Chain-of-Thought (CoT) does not elicit genuine, abstract reasoning. Instead, we argue that Chain-of-Thought functions as a powerful structural constraint that guides Large Language Models to imitate the form of reasoning. By forcing the generation of intermediate steps, Chain-of-Thought leverages the model immense capacity for sequence prediction and pattern matching, effectively constraining its output to sequences that resemble coherent thought processes.
        ]]></description>
    </item>
    <item>
        <title>Towards Analyzing and Understanding the Limitations of VAPO: A Theoretical Perspective</title>
        <link>https://arxiv.org/abs/2506.03038</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.03038v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jintian Shao, Yiming Cheng</dc:creator>
        <description><![CDATA[
            背景：强化学习可增强大语言模型在复杂长思维链推理方面的能力，但先进的VAPO框架存在局限。方法：从理论层面分析VAPO在综合建模和利用深层、长期价值以实现细粒度、逐步策略指导方面的问题，指出局限源于信用分配困难、具有时间抽象目标的价值函数表示能力不足，以及在稀疏奖励下将全局价值信号转化为局部策略改进的难题。效果：有助于深入理解当前用于高级推理的强化学习，为构建更强大的大语言模型智能体指明研究方向。
            arXiv:2506.03038v2 Announce Type: replace 
Abstract: Reinforcement learning (RL) enhances large language models (LLMs) in complex, long-chain-of-thought (long-CoT) reasoning. The advanced VAPO framework, despite sophisticated mechanisms like Decoupled GAE, theoretically faces fundamental limitations in comprehensively modeling and leveraging deep, long-term value for fine-grained, step-by-step policy guidance in extended reasoning chains. We argue these limitations stem from inherent difficulties in credit assignment, value function representational capacity with temporally abstracted goals, and translating global value signals into local policy improvements, especially with sparse rewards. Our theoretical analysis examines these aspects to illuminate VAPO's boundaries in long-term value modeling, aiming to deepen understanding of current RL for advanced reasoning and suggest future research for more robust LLM agents.
        ]]></description>
    </item>
    <item>
        <title>Structured Pruning for Diverse Best-of-N Reasoning Optimization</title>
        <link>https://arxiv.org/abs/2506.03978</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.03978v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Hieu Trung Nguyen, Bao Nguyen, Viet Anh Nguyen</dc:creator>
        <description><![CDATA[
            背景：传统上用于节省计算量的基于Transformer的语言模型剪枝，可提升模型推理能力。方法：提出SPRINT这一新颖的对比学习框架，在推理时动态选择要剪枝的最优头和层，通过将问题嵌入与头嵌入对齐，找出能实现更准确推理的剪枝头配置。效果：大量实验表明，该方法在MATH500和GSM8K数据集上显著优于传统的最佳N策略和随机头选择策略。
            arXiv:2506.03978v2 Announce Type: replace 
Abstract: Model pruning in transformer-based language models, traditionally viewed as a means of achieving computational savings, can enhance the model's reasoning capabilities. In this work, we uncover a surprising phenomenon: the selective pruning of certain attention heads leads to improvements in reasoning performance, particularly on challenging tasks. Motivated by this observation, we propose SPRINT, a novel contrastive learning framework that dynamically selects the optimal head and layer to prune during inference. By aligning question embeddings with head embeddings, SPRINT identifies those pruned-head configurations that result in more accurate reasoning. Extensive experiments demonstrate that our method significantly outperforms traditional best-of-$N$ and random head selection strategies on the MATH500 and GSM8K datasets.
        ]]></description>
    </item>
    <item>
        <title>Numerical Investigation of Sequence Modeling Theory using Controllable Memory Functions</title>
        <link>https://arxiv.org/abs/2506.05678</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.05678v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Haotian Jiang, Zeyu Bao, Shida Wang, Qianxiao Li</dc:creator>
        <description><![CDATA[
            背景：序列建模架构不断发展，但系统刻画其优缺点仍是挑战。方法：提出合成基准框架，生成由记忆函数和参数确定的合成目标，产生不同时间复杂度的任务，聚焦四种代表性记忆函数分析模型行为。效果：对几种序列建模架构的实验证实了现有理论见解并发现新成果，表明该方法有助于推进理论理解，凸显用结构明确的可控目标评估架构的重要性。
            arXiv:2506.05678v2 Announce Type: replace 
Abstract: The evolution of sequence modeling architectures, from recurrent neural networks and convolutional models to Transformers and structured state-space models, reflects ongoing efforts to address the diverse temporal dependencies inherent in sequential data. Despite this progress, systematically characterizing the strengths and limitations of these architectures remains a fundamental challenge. In this work, we propose a synthetic benchmarking framework to evaluate how effectively different sequence models capture distinct temporal structures. The core of this approach is to generate synthetic targets, each characterized by a memory function and a parameter that determines the strength of temporal dependence. This setup allows us to produce a continuum of tasks that vary in temporal complexity, enabling fine-grained analysis of model behavior concerning specific memory properties. We focus on four representative memory functions, each corresponding to a distinct class of temporal structures. Experiments on several sequence modeling architectures confirm existing theoretical insights and reveal new findings. These results demonstrate the effectiveness of the proposed method in advancing theoretical understanding and highlight the importance of using controllable targets with clearly defined structures for evaluating sequence modeling architectures.
        ]]></description>
    </item>
    <item>
        <title>Heartcare Suite: Multi-dimensional Understanding of ECG with Raw Multi-lead Signal Modeling</title>
        <link>https://arxiv.org/abs/2506.05831</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.05831v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yihan Xie, Sijing Li, Tianwei Lin, Zhuonan Wang, Chenglin Yang, Yu Zhong, Wenqiao Zhang, Haoyuan Li, Hao Jiang, Fengda Zhang, Qishan Chen, Jun Xiao, Yueting Zhuang, Beng Chin Ooi</dc:creator>
        <description><![CDATA[
            背景：为实现对心电图（ECG）的细粒度理解。方法：提出Heartcare Suite多模态综合框架，包含高质量结构化数据集Heartcare - 220K、用于评估诊断智能的基准Heartcare - Bench，以及有定制分词器的HeartcareGPT，其通过双级向量量化和查询引导的双向扩散机制将原始多导联信号压缩为语义丰富的离散标记。效果：基于Heartcare - 220K，HeartcareGPT在多个临床任务中实现强泛化能力和最优性能，该框架在推进ECG特定多模态理解和评估方面非常有效。
            arXiv:2506.05831v2 Announce Type: replace 
Abstract: We present Heartcare Suite, a multimodal comprehensive framework for finegrained electrocardiogram (ECG) understanding. It comprises three key components: (i) Heartcare-220K, a high-quality, structured, and comprehensive multimodal ECG dataset covering essential tasks such as disease diagnosis, waveform morphology analysis, and rhythm interpretation. (ii) Heartcare-Bench, a systematic and multi-dimensional benchmark designed to evaluate diagnostic intelligence and guide the optimization of Medical Multimodal Large Language Models (Med-MLLMs) in ECG scenarios. and (iii) HeartcareGPT with a tailored tokenizer Bidirectional ECG Abstract Tokenization (Beat), which compresses raw multi-lead signals into semantically rich discrete tokens via duallevel vector quantization and query-guided bidirectional diffusion mechanism. Built upon Heartcare-220K, HeartcareGPT achieves strong generalization and SoTA performance across multiple clinically meaningful tasks. Extensive experiments demonstrate that Heartcare Suite is highly effective in advancing ECGspecific multimodal understanding and evaluation. Our project is available at https://github.com/DCDmllm/Heartcare-Suite .
        ]]></description>
    </item>
    <item>
        <title>Cross-lingual Collapse: How Language-Centric Foundation Models Shape Reasoning in Large Language Models</title>
        <link>https://arxiv.org/abs/2506.05850</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.05850v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Cheonbok Park, Jeonghoon Kim, Joosung Lee, Sanghwan Bae, Jaegul Choo, Kang Min Yoo</dc:creator>
        <description><![CDATA[
            背景：大语言模型中多语言推理机制尚未完全明晰，存在跨语言坍缩现象。方法：用Group - Relative Policy Optimization（GRPO）在GSM8K和SimpleRL - Zoo数据集的三种语言翻译版本上微调多语言大推理模型，训练中监测任务准确率和推理链语言一致性。效果：GRPO会放大预训练语言不平衡；语言一致性奖励缓解漂移但使准确率下降5 - 10个百分点；语言坍缩损害大且难逆转，表明并非所有语言在推理训练中效果相同。
            arXiv:2506.05850v2 Announce Type: replace 
Abstract: We identify \textbf{Cross-lingual Collapse}, a systematic drift in which the chain-of-thought (CoT) of a multilingual language model reverts to its dominant pre-training language even when the prompt is expressed in a different language. Recent large language models (LLMs) with reinforcement learning with verifiable reward (RLVR) have achieved strong logical reasoning performances by exposing their intermediate reasoning traces, giving rise to large reasoning models (LRMs). However, the mechanism behind multilingual reasoning in LRMs is not yet fully explored. To investigate the issue, we fine-tune multilingual LRMs with Group-Relative Policy Optimization (GRPO) on translated versions of the GSM$8$K and SimpleRL-Zoo datasets in three different languages: Chinese, Korean, and Ukrainian. During training, we monitor both task accuracy and language consistency of the reasoning chains. Our experiments reveal three key findings: (i) GRPO rapidly amplifies pre-training language imbalances, leading to the erosion of low-resource languages within just a few hundred updates; (ii) language consistency reward mitigates this drift but does so at the expense of an almost 5 - 10 pp drop in accuracy. and (iii) the resulting language collapse is severely damaging and largely irreversible, as subsequent fine-tuning struggles to steer the model back toward its original target-language reasoning capabilities. Together, these findings point to a remarkable conclusion: \textit{not all languages are trained equally for reasoning}. Furthermore, our paper sheds light on the roles of reward shaping, data difficulty, and pre-training priors in eliciting multilingual reasoning.
        ]]></description>
    </item>
    <item>
        <title>Text-to-LoRA: Instant Transformer Adaption</title>
        <link>https://arxiv.org/abs/2506.06105</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06105v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Rujikorn Charakorn, Edoardo Cetin, Yujin Tang, Robert Tjarko Lange</dc:creator>
        <description><![CDATA[
            背景：基础模型虽能快速创建内容，但常需特定任务适配，传统微调方法成本高、耗时长且对超参数敏感。方法：提出Text-to-LoRA (T2L) 模型，可仅根据目标任务的自然语言描述即时适配大语言模型，它是一个超网络，能在单次低成本前向传播中构建LoRAs。效果：在9个预训练LoRA适配器上训练后，临时重建的LoRA实例在对应测试集上表现与特定任务适配器相当，还能压缩大量LoRA实例并零样本泛化到全新任务。
            arXiv:2506.06105v2 Announce Type: replace 
Abstract: While Foundation Models provide a general tool for rapid content creation, they regularly require task-specific adaptation. Traditionally, this exercise involves careful curation of datasets and repeated fine-tuning of the underlying model. Fine-tuning techniques enable practitioners to adapt foundation models for many new applications but require expensive and lengthy training while being notably sensitive to hyperparameter choices. To overcome these limitations, we introduce Text-to-LoRA (T2L), a model capable of adapting large language models (LLMs) on the fly solely based on a natural language description of the target task. T2L is a hypernetwork trained to construct LoRAs in a single inexpensive forward pass. After training T2L on a suite of 9 pre-trained LoRA adapters (GSM8K, Arc, etc.), we show that the ad-hoc reconstructed LoRA instances match the performance of task-specific adapters across the corresponding test sets. Furthermore, T2L can compress hundreds of LoRA instances and zero-shot generalize to entirely unseen tasks. This approach provides a significant step towards democratizing the specialization of foundation models and enables language-based adaptation with minimal compute requirements.
  Our code is available at https://github.com/SakanaAI/text-to-lora
        ]]></description>
    </item>
    <item>
        <title>A Simplifying and Learnable Graph Convolutional Attention Network for Unsupervised Knowledge Graphs Alignment</title>
        <link>https://arxiv.org/abs/2410.13263</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2410.13263v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Weishan Cai, Wenjun Ma, Yuncheng Jiang</dc:creator>
        <description><![CDATA[
            当前实体对齐（EA）任务成功多依赖标注数据监督信息，因标注成本高，多数有监督方法难用于实际。现有无监督EA方法存在建模复杂或难平衡对齐有效性与实用性等问题。为此提出简化可学习的无监督知识图谱对齐图卷积注意力网络（SLU）。先引入LCAT框架建模图谱结构，设计关系结构重建法过滤无效邻居信息，提出基于一致性的相似度函数。实验表明，SLU显著提升对齐准确率，在最佳情况下Hits@1比最佳基线提高6.4%。
            arXiv:2410.13263v2 Announce Type: replace-cross 
Abstract: The success of current Entity Alignment (EA) task depends largely on the supervision information provided by labeled data. Considering the cost of labeled data, most supervised methods are difficult to apply in practical scenarios. Therefore, more and more works based on contrastive learning, active learning or other deep learning techniques have been developed, to solve the performance bottleneck caused by the lack of labeled data. However, the existing unsupervised EA methods still have some limitations, either their modeling complexity is high or they cannot balance the effectiveness and practicality of alignment. To overcome these issues, we propose a Simplifying and Learnable graph convolutional attention network for Unsupervised Knowledge Graphs alignment method (SLU). Specifically, we first introduce LCAT, a new and simple framework as the backbone network to model the graph structure of two KGs. Then we design a reconstruction method of relation structure based on potential matching relations for efficiently filtering invalid neighborhood information of aligned entities, to improve the usability and scalability of SLU. Impressively, a similarity function based on consistency is proposed to better measure the similarity of candidate entity pairs. Finally, we conduct extensive experiments on three datasets of different sizes (15K and 100K) and different types (cross-lingual and monolingual) to verify the superiority of SLU. Experimental results show that SLU significantly improves alignment accuracy, outperforming 25 supervised or unsupervised methods, and improving 6.4% in Hits@1 over the best baseline in the best case.
        ]]></description>
    </item>
    <item>
        <title>Semantic Exploration with Adaptive Gating for Efficient Problem Solving with Language Models</title>
        <link>https://arxiv.org/abs/2501.05752</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2501.05752v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sungjae Lee, Hyejin Park, Jaechang Kim, Jungseul Ok</dc:creator>
        <description><![CDATA[
            背景：现有大语言模型在多步推理任务中存在计算效率低和冗余问题，如忽视任务难度多样性、忽略推理路径语义。方法：提出语义探索与自适应门控（SEAG）方法，采用自适应门控机制动态决定是否进行树搜索，树基探索合并语义相同的推理步骤。效果：在复杂推理基准测试中，相比现有基于树搜索的方法，SEAG平均显著提高准确率4.3%，仅需31%的计算成本。
            arXiv:2501.05752v2 Announce Type: replace-cross 
Abstract: Recent advancements in large language models (LLMs) have shown remarkable potential in various complex tasks requiring multi-step reasoning methods like tree search to explore diverse reasoning paths. However, existing methods often suffer from computational inefficiency and redundancy. First, they overlook the diversity of task difficulties, leading to unnecessarily extensive searches even for easy tasks. Second, they neglect the semantics of reasoning paths, resulting in redundant exploration of semantically identical paths. To address these limitations, we propose Semantic Exploration with Adaptive Gating (SEAG), a computationally efficient method. SEAG employs an adaptive gating mechanism that dynamically decides whether to conduct a tree search, based on the confidence level of answers from a preceding simple reasoning method. Furthermore, its tree-based exploration consolidates semantically identical reasoning steps, reducing redundant explorations while maintaining or even improving accuracy. Our extensive experiments demonstrate that SEAG significantly improves accuracy by 4.3% on average while requiring only 31% of computational costs compared to existing tree search-based methods on complex reasoning benchmarks including GSM8K and ARC with diverse language models such as Llama2, Llama3, and Mistral. Our code is available at https://github.com/ml-postech/SEAG-semantic-exploration-with-adaptive-gating .
        ]]></description>
    </item>
    <item>
        <title>From Informal to Formal -- Incorporating and Evaluating LLMs on Natural Language Requirements to Verifiable Formal Proofs</title>
        <link>https://arxiv.org/abs/2501.16207</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2501.16207v4</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jialun Cao, Yaojie Lu, Meiziniu Li, Haoyang Ma, Haokun Li, Mengda He, Cheng Wen, Le Sun, Hongyu Zhang, Shengchao Qin, Shing-Chi Cheung, Cong Tian</dc:creator>
        <description><![CDATA[
            背景：基于人工智能的形式化数学推理研究呈增长趋势。方法：聚焦形式验证这一形式推理的应用场景并拆解子任务，通过提炼gpt - 4o构建18k个涵盖五种形式规范语言的高质量指令 - 响应对，对十个开源大语言模型进行评估，还微调了几个7 - 8B小模型。效果：微调后的小模型能达到与Deepseek - R1 - 671B相当的性能，且用形式化数据微调可增强数学、推理和编码能力，微调模型已发布。
            arXiv:2501.16207v4 Announce Type: replace-cross 
Abstract: The research in AI-based formal mathematical reasoning has shown an unstoppable growth trend. These studies have excelled in mathematical competitions like IMO and have made significant progress. This paper focuses on formal verification, an immediate application scenario of formal reasoning, and breaks it down into sub-tasks. We constructed 18k high-quality instruction-response pairs across five formal specification languages (Coq, Lean4, Dafny, ACSL, and TLA+) by distilling gpt-4o and evaluated against ten open-sourced LLMs, including recent popular DeepSeek-R1. We also fine-tuned several 7~8B small models to achieve comparable performance with Deepseek-R1-671B. Interestingly, we observed that fine-tuning with formal data also enhances mathematics, reasoning, and coding capabilities. Fine-tuned models are released at https: //huggingface.co/fm-universe.
        ]]></description>
    </item>
    <item>
        <title>DeepRAG: Thinking to Retrieve Step by Step for Large Language Models</title>
        <link>https://arxiv.org/abs/2502.01142</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.01142v2</guid>
        <category>我关注的研究话题是多模态大模型，尤其是与结构化数据（图、序列等）相关的研究，包括大模型结构化数据特征对齐、大模型结构化数据RAG、大模型思维链。具体的研究问题有：（1）如何有效地将结构化的信息（图、序列数据）与自然语言的语义空间进行对齐，使得模型能够同时理解数据结构和语义信息；（2）如何用适当的指令使得大模型理解结构化数据中的结构信息；（3）如何赋予大语言模型图学习下游任务的逐步推理能力，从而逐步推断出更复杂的关系和属性。（4）对于下游任务的推理能力，目前的研究比较少，针对序列数据的推理能力研究非常少。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xinyan Guan, Jiali Zeng, Fandong Meng, Chunlei Xin, Yaojie Lu, Hongyu Lin, Xianpei Han, Le Sun, Jie Zhou</dc:creator>
        <description><![CDATA[
            大语言模型虽有强大推理能力，但因参数知识的时效性、准确性和全面性受限，存在严重事实幻觉问题，限制了实际应用。同时，现有检索增强生成（RAG）因任务分解无效和冗余检索难以提升推理能力。为此，本文提出DeepRAG框架，将检索增强推理建模为马尔可夫决策过程，通过迭代分解查询，动态决定每一步是检索外部知识还是依靠参数推理。实验表明，该框架提高了检索效率，答案准确率提升26.4%。
            arXiv:2502.01142v2 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) have shown remarkable reasoning capabilities, while their practical applications are limited by severe factual hallucinations due to limitations in the timeliness, accuracy, and comprehensiveness of their parametric knowledge. Meanwhile, enhancing retrieval-augmented generation (RAG) with reasoning remains challenging due to ineffective task decomposition and redundant retrieval, which can introduce noise and degrade response quality. In this paper, we propose DeepRAG, a framework that models retrieval-augmented reasoning as a Markov Decision Process (MDP), enabling reasonable and adaptive retrieval. By iteratively decomposing queries, DeepRAG dynamically determines whether to retrieve external knowledge or rely on parametric reasoning at each step. Experiments show that DeepRAG improves retrieval efficiency and boosts answer accuracy by 26.4%, demonstrating its effectiveness in enhancing retrieval-augmented reasoning.
        ]]></description>
    </item>
    <item>
        <title>Can Quantized Audio Language Models Perform Zero-Shot Spoofing Detection?</title>
        <link>https://arxiv.org/abs/2506.06756</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06756v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Bikash Dutta, Rishabh Ranjan, Shyam Sathvik, Mayank Vatsa, Richa Singh</dc:creator>
        <description><![CDATA[
            背景：量化对在资源受限环境高效部署大型音频语言模型（LALMs）很重要，但对零样本音频欺骗检测这类复杂任务的影响尚不明晰。方法：评估五个LALMs在三个数据集上的零样本能力，研究其对不同量化（FP32、FP16、INT8）的鲁棒性。效果：各模型初始欺骗检测准确率高，但有严重预测偏差，实际表现近乎随机分类；FP16量化内存和计算需求减半且精度损失小，INT8量化加剧偏差、降低平衡准确率，表明FP16量化是最优权衡。
            arXiv:2506.06756v1 Announce Type: new 
Abstract: Quantization is essential for deploying large audio language models (LALMs) efficiently in resource-constrained environments. However, its impact on complex tasks, such as zero-shot audio spoofing detection, remains underexplored. This study evaluates the zero-shot capabilities of five LALMs, GAMA, LTU-AS, MERaLiON, Qwen-Audio, and SALMONN, across three distinct datasets: ASVspoof2019, In-the-Wild, and WaveFake, and investigates their robustness to quantization (FP32, FP16, INT8). Despite high initial spoof detection accuracy, our analysis demonstrates severe predictive biases toward spoof classification across all models, rendering their practical performance equivalent to random classification. Interestingly, quantization to FP16 precision resulted in negligible performance degradation compared to FP32, effectively halving memory and computational requirements without materially impacting accuracy. However, INT8 quantization intensified model biases, significantly degrading balanced accuracy. These findings highlight critical architectural limitations and emphasize FP16 quantization as an optimal trade-off, providing guidelines for practical deployment and future model refinement.
        ]]></description>
    </item>
    <item>
        <title>SynHate: Detecting Hate Speech in Synthetic Deepfake Audio</title>
        <link>https://arxiv.org/abs/2506.06772</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06772v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Rishabh Ranjan, Kishan Pipariya, Mayank Vatsa, Richa Singh</dc:creator>
        <description><![CDATA[
            背景：先进的文本转语音技术推动的深度伪造音频和仇恨言论兴起，威胁网络安全。方法：提出首个用于检测合成音频中仇恨言论的多语言数据集SynHate，涵盖37种语言，采用四分类方案，基于MuTox和ADIMA数据集构建；评估五种自监督模型。效果：不同语言下模型性能有显著差异，Whisper - small总体表现最佳，但跨数据集泛化仍有挑战。发布数据集和基线代码，以推动对抗合成仇恨言论的多语言解决方案发展。
            arXiv:2506.06772v1 Announce Type: new 
Abstract: The rise of deepfake audio and hate speech, powered by advanced text-to-speech, threatens online safety. We present SynHate, the first multilingual dataset for detecting hate speech in synthetic audio, spanning 37 languages. SynHate uses a novel four-class scheme: Real-normal, Real-hate, Fake-normal, and Fake-hate. Built from MuTox and ADIMA datasets, it captures diverse hate speech patterns globally and in India. We evaluate five leading self-supervised models (Whisper-small/medium, XLS-R, AST, mHuBERT), finding notable performance differences by language, with Whisper-small performing best overall. Cross-dataset generalization remains a challenge. By releasing SynHate and baseline code, we aim to advance robust, culturally sensitive, and multilingual solutions against synthetic hate speech. The dataset is available at https://www.iab-rubric.org/resources.
        ]]></description>
    </item>
    <item>
        <title>Rhythm Features for Speaker Identification</title>
        <link>https://arxiv.org/abs/2506.06834</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06834v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Nick Mehlman, Thomas Thebaud, Dani Byrd, Shri Narayanan</dc:creator>
        <description><![CDATA[
            背景：深度学习模型在说话人识别任务中表现出色，但主要依赖从频谱图或原始波形中经验性学习的低级音频特征，而说话风格影响的节奏作为身份特征被忽视。方法：应用深度学习方法，利用节奏特征进行与文本无关的说话人识别。效果：研究结果支持节奏信息对说话人识别任务有用，但同时指出即兴演讲中较高的个体内变异性会降低其有效性。
            arXiv:2506.06834v1 Announce Type: new 
Abstract: While deep learning models have demonstrated robust performance in speaker recognition tasks, they primarily rely on low-level audio features learned empirically from spectrograms or raw waveforms. However, prior work has indicated that idiosyncratic speaking styles heavily influence the temporal structure of linguistic units in speech signals (rhythm). This makes rhythm a strong yet largely overlooked candidate for a speech identity feature. In this paper, we test this hypothesis by applying deep learning methods to perform text-independent speaker identification from rhythm features. Our findings support the usefulness of rhythmic information for speaker recognition tasks but also suggest that high intra-subject variability in ad-hoc speech can degrade its effectiveness.
        ]]></description>
    </item>
    <item>
        <title>"In This Environment, As That Speaker": A Text-Driven Framework for Multi-Attribute Speech Conversion</title>
        <link>https://arxiv.org/abs/2506.07036</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07036v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jiawei Jin, Zhuhan Yang, Yixuan Zhou, Zhiyong Wu</dc:creator>
        <description><![CDATA[
            这是一篇关于音频生成的论文。背景是需要实现对说话人音色和环境声学的独立控制的语音转换。方法上，提出了TES - VC框架，通过潜在扩散模型在合成数据上训练，利用解耦的语音/环境特征消除属性间干扰，还采用基于检索的音色控制（RBTC）模块实现无配对数据下的精确操作。效果方面，实验证实该方法能有效生成音色和环境都合适的语音，内容保留度高且可控性强，有广泛应用潜力。
            arXiv:2506.07036v1 Announce Type: new 
Abstract: We propose TES-VC (Text-driven Environment and Speaker controllable Voice Conversion), a text-driven voice conversion framework with independent control of speaker timbre and environmental acoustics. TES-VC processes simultaneous text inputs for target voice and environment, accurately generating speech matching described timbre/environment while preserving source content. Trained on synthetic data with decoupled vocal/environment features via latent diffusion modeling, our method eliminates interference between attributes. The Retrieval-Based Timbre Control (RBTC) module enables precise manipulation using abstract descriptions without paired data. Experiments confirm TES-VC effectively generates contextually appropriate speech in both timbre and environment with high content retention and superior controllability which demonstrates its potential for widespread applications.
        ]]></description>
    </item>
    <item>
        <title>Insights on Harmonic Tones from a Generative Music Experiment</title>
        <link>https://arxiv.org/abs/2506.07073</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07073v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Emmanuel Deruty, Maarten Grachten</dc:creator>
        <description><![CDATA[
            本文围绕生成式音乐AI展开研究。背景是生成式音乐AI的目标是音乐制作，而跨学科的工作室实验室是利用AI音乐模型推动音乐制作的途径。研究人员、音乐制作人和AI模型参与了生成类似贝斯音频的实验，制作人利用模型输出用单一谐波复合音传达多个音高，发现模型学会用单音谐波复合音序列生成结构化、连贯的同时旋律线。这一结果促使重新思考人类能否将谐波视为不同音高的争论，还表明生成式AI可提升音乐创造力并加深对音乐的理解。
            arXiv:2506.07073v1 Announce Type: new 
Abstract: The ultimate purpose of generative music AI is music production. The studio-lab, a social form within the art-science branch of cross-disciplinarity, is a way to advance music production with AI music models. During a studio-lab experiment involving researchers, music producers, and an AI model for music generating bass-like audio, it was observed that the producers used the model's output to convey two or more pitches with a single harmonic complex tone, which in turn revealed that the model had learned to generate structured and coherent simultaneous melodic lines using monophonic sequences of harmonic complex tones. These findings prompt a reconsideration of the long-standing debate on whether humans can perceive harmonics as distinct pitches and highlight how generative AI can not only enhance musical creativity but also contribute to a deeper understanding of music.
        ]]></description>
    </item>
    <item>
        <title>Streaming Endpointer for Spoken Dialogue using Neural Audio Codecs and Label-Delayed Training</title>
        <link>https://arxiv.org/abs/2506.07081</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07081v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Sathvik Udupa, Shinji Watanabe, Petr Schwarz, Jan Cernocky</dc:creator>
        <description><![CDATA[
            准确、低延迟的端点检测对有效对话系统至关重要，传统端点检测常依赖基于频谱的音频特征。本文基于神经音频编解码器的进展，提出使用流式、低比特率神经音频编解码器（NAC）特征进行多轮对话的实时语音端点检测，并引入新的标签延迟训练方案。在160ms的固定中值延迟下，结合NAC和标签延迟的方法与基线方法相比，单流端点检测器相对截断误差降低42.7%，双流配置降低37.5%。此外，与基于编解码器的预训练语音大语言模型集成，使其中值响应时间缩短1200ms，截断误差降低35%。
            arXiv:2506.07081v1 Announce Type: new 
Abstract: Accurate, low-latency endpointing is crucial for effective spoken dialogue systems. While traditional endpointers often rely on spectrum-based audio features, this work proposes real-time speech endpointing for multi-turn dialogues using streaming, low-bitrate Neural Audio Codec (NAC) features, building upon recent advancements in neural audio codecs. To further reduce cutoff errors, we introduce a novel label delay training scheme. At a fixed median latency of 160 ms, our combined NAC and label delay approach achieves significant relative cutoff error reductions: 42.7% for a single-stream endpointer and 37.5% for a two-stream configuration, compared to baseline methods. Finally, we demonstrate efficient integration with a codec-based pretrained speech large language model, improving its median response time by 1200 ms and reducing its cutoff error by 35%.
        ]]></description>
    </item>
    <item>
        <title>RBA-FE: A Robust Brain-Inspired Audio Feature Extractor for Depression Diagnosis</title>
        <link>https://arxiv.org/abs/2506.07118</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07118v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yu-Xuan Wu, Ziyan Huang, Bin Hu, Zhi-Hong Guan</dc:creator>
        <description><![CDATA[
            这是一篇关于音频分类的论文。背景是多数深度学习模型忽视音频特征，且音频特征提取存在精度局限和噪声问题。方法上，提出RBA - FE模型，利用从原始音频提取的六种声学特征，结合改进的脉冲神经元模型ARSLIF。效果方面，该模型在MODMA数据集上精度、准确率、召回率和F1分数分别达0.8750、0.8974、0.8750和0.8750，在AVEC2014和DAIC - WOZ数据集上增强了噪声鲁棒性，还具有脑启发的可解释性。
            arXiv:2506.07118v1 Announce Type: new 
Abstract: This article proposes a robust brain-inspired audio feature extractor (RBA-FE) model for depression diagnosis, using an improved hierarchical network architecture. Most deep learning models achieve state-of-the-art performance for image-based diagnostic tasks, ignoring the counterpart audio features. In order to tailor the noise challenge, RBA-FE leverages six acoustic features extracted from the raw audio, capturing both spatial characteristics and temporal dependencies. This hybrid attribute helps alleviate the precision limitation in audio feature extraction within other learning models like deep residual shrinkage networks. To deal with the noise issues, our model incorporates an improved spiking neuron model, called adaptive rate smooth leaky integrate-and-fire (ARSLIF). The ARSLIF model emulates the mechanism of ``retuning of cellular signal selectivity" in the brain attention systems, which enhances the model robustness against environmental noises in audio data. Experimental results demonstrate that RBA-FE achieves state-of-the-art accuracy on the MODMA dataset, respectively with 0.8750, 0.8974, 0.8750 and 0.8750 in precision, accuracy, recall and F1 score. Extensive experiments on the AVEC2014 and DAIC-WOZ datasets both show enhancements in noise robustness. It is further indicated by comparison that the ARSLIF neuron model suggest the abnormal firing pattern within the feature extraction on depressive audio data, offering brain-inspired interpretability.
        ]]></description>
    </item>
    <item>
        <title>Audio synthesizer inversion in symmetric parameter spaces with approximately equivariant flow matching</title>
        <link>https://arxiv.org/abs/2506.07199</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07199v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ben Hayes, Charalampos Saitis, Gy\"orgy Fazekas</dc:creator>
        <description><![CDATA[
            背景：许多音频合成器不同参数配置可产生相同信号，从声音到参数的反演是病态问题，主要源于合成器的内在对称性。方法：先证明在置换对称下回归点估计会降低性能；将等效解视为概率分布模式，用条件生成模型提升性能；利用置换等变连续归一化流进一步提升；针对真实合成器的复杂对称性，提出自适应发现相关对称性的宽松等变策略。效果：应用于Surge XT时，该方法在音频重建指标上优于回归和生成基线。
            arXiv:2506.07199v1 Announce Type: new 
Abstract: Many audio synthesizers can produce the same signal given different parameter configurations, meaning the inversion from sound to parameters is an inherently ill-posed problem. We show that this is largely due to intrinsic symmetries of the synthesizer, and focus in particular on permutation invariance. First, we demonstrate on a synthetic task that regressing point estimates under permutation symmetry degrades performance, even when using a permutation-invariant loss function or symmetry-breaking heuristics. Then, viewing equivalent solutions as modes of a probability distribution, we show that a conditional generative model substantially improves performance. Further, acknowledging the invariance of the implicit parameter distribution, we find that performance is further improved by using a permutation equivariant continuous normalizing flow. To accommodate intricate symmetries in real synthesizers, we also propose a relaxed equivariance strategy that adaptively discovers relevant symmetries from data. Applying our method to Surge XT, a full-featured open source synthesizer used in real world audio production, we find our method outperforms regression and generative baselines across audio reconstruction metrics.
        ]]></description>
    </item>
    <item>
        <title>Reducing Object Hallucination in Large Audio-Language Models via Audio-Aware Decoding</title>
        <link>https://arxiv.org/abs/2506.07233</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07233v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Tzu-wen Hsu, Ke-Han Lu, Cheng-Han Chiang, Hung-yi Lee</dc:creator>
        <description><![CDATA[
            大音频语言模型（LALMs）能以音频和文本为输入回答音频相关问题，但会出现音频内容幻觉问题。为缓解这一问题，本文提出音频感知解码（AAD），这是一种轻量级推理策略，利用对比解码比较有无音频上下文时的token预测对数。通过对比解码，AAD提升有音频时概率增加的token。实验表明，AAD在物体幻觉数据集上使F1分数提高0.046 - 0.428，在通用音频问答数据集上使准确率提高5.4% - 10.3%。此外，还进行了消融实验探究AAD各组件的有效性。
            arXiv:2506.07233v1 Announce Type: new 
Abstract: Large Audio-Language Models (LALMs) can take audio and text as the inputs and answer questions about the audio. While prior LALMs have shown strong performance on standard benchmarks, there has been alarming evidence that LALMs can hallucinate what is presented in the audio. To mitigate the hallucination of LALMs, we introduce Audio-Aware Decoding (AAD), a lightweight inference-time strategy that uses contrastive decoding to compare the token prediction logits with and without the audio context. By contrastive decoding, AAD promotes the tokens whose probability increases when the audio is present. We conduct our experiment on object hallucination datasets with three LALMs and show that AAD improves the F1 score by 0.046 to 0.428. We also show that AAD can improve the accuracy on general audio QA datasets like Clotho-AQA by 5.4% to 10.3%. We conduct thorough ablation studies to understand the effectiveness of each component in AAD.
        ]]></description>
    </item>
    <item>
        <title>Multi-Distillation from Speech and Music Representation Models</title>
        <link>https://arxiv.org/abs/2506.07237</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07237v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Jui-Chiang Wei, Yi-Cheng Lin, Fabian Ritter-Gutierrez, Hung-yi Lee</dc:creator>
        <description><![CDATA[
            现实中音频常混合语音和音乐，但模型通常只能处理单一领域。本文提出多教师蒸馏框架，将语音和音乐模型统一为单一模型并大幅减小模型规模。该方法利用特定领域教师模型优势，如用于语音的HuBERT和用于音乐的MERT，并探索平衡两个领域的策略。实验表明，模型在不同任务中表现与特定领域模型相当。少样本学习实验显示，该模型不仅表现与专业模型相近，在少样本场景中还更优，证明跨领域方法在有限数据任务中有效。
            arXiv:2506.07237v1 Announce Type: new 
Abstract: Real-world audio often mixes speech and music, yet models typically handle only one domain. This paper introduces a multi-teacher distillation framework that unifies speech and music models into a single one while significantly reducing model size. Our approach leverages the strengths of domain-specific teacher models, such as HuBERT for speech and MERT for music, and explores various strategies to balance both domains. Experiments across diverse tasks demonstrate that our model matches the performance of domain-specific models, showing the effectiveness of cross-domain distillation. Additionally, we conduct few-shot learning experiments, highlighting the need for general models in real-world scenarios where labeled data is limited. Our results show that our model not only performs on par with specialized models but also outperforms them in few-shot scenarios, proving that a cross-domain approach is essential and effective for diverse tasks with limited data.
        ]]></description>
    </item>
    <item>
        <title>Towards Generalized Source Tracing for Codec-Based Deepfake Speech</title>
        <link>https://arxiv.org/abs/2506.07294</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07294v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Xuanjun Chen, I-Ming Lin, Lin Zhang, Haibin Wu, Hung-yi Lee, Jyh-Shing Roger Jang</dc:creator>
        <description><![CDATA[
            这是一篇关于音频生成领域的研究。背景是基于神经音频编解码器的语音生成（CoSG）模型生成的编解码深度伪造语音（CodecFake）溯源效果不佳，且用模拟数据训练的溯源模型在真实音频上泛化性差。方法是提出语义-声学溯源网络（SASTNet），联合利用Whisper进行语义特征编码，用Wav2vec2和AudioMAE进行声学特征编码。效果是SASTNet在CodecFake+数据集的CoSG测试集上达到了最优性能，能有效溯源。
            arXiv:2506.07294v1 Announce Type: new 
Abstract: Recent attempts at source tracing for codec-based deepfake speech (CodecFake), generated by neural audio codec-based speech generation (CoSG) models, have exhibited suboptimal performance. However, how to train source tracing models using simulated CoSG data while maintaining strong performance on real CoSG-generated audio remains an open challenge. In this paper, we show that models trained solely on codec-resynthesized data tend to overfit to non-speech regions and struggle to generalize to unseen content. To mitigate these challenges, we introduce the Semantic-Acoustic Source Tracing Network (SASTNet), which jointly leverages Whisper for semantic feature encoding and Wav2vec2 with AudioMAE for acoustic feature encoding. Our proposed SASTNet achieves state-of-the-art performance on the CoSG test set of the CodecFake+ dataset, demonstrating its effectiveness for reliable source tracing.
        ]]></description>
    </item>
    <item>
        <title>Speaker-Distinguishable CTC: Learning Speaker Distinction Using CTC for Multi-Talker Speech Recognition</title>
        <link>https://arxiv.org/abs/2506.07515</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07515v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Asahi Sakuma, Hiroaki Sato, Ryuga Sugano, Tadashi Kumano, Yoshihiko Kawai, Tetsuji Ogawa</dc:creator>
        <description><![CDATA[
            背景：多说话人自动语音识别中，常用的序列化输出训练（SOT）因说话人分配失败存在识别错误，且从自然对话语音中提取辅助信息有挑战。方法：提出可区分说话人的CTC（SD - CTC），它是CTC的扩展，能为每帧联合分配一个标记及其对应的说话人标签，并将其集成到SOT框架中。效果：SD - CTC和SOT的多任务学习使SOT模型的错误率降低26%，性能与依赖辅助信息的先进方法相当。
            arXiv:2506.07515v1 Announce Type: new 
Abstract: This paper presents a novel framework for multi-talker automatic speech recognition without the need for auxiliary information. Serialized Output Training (SOT), a widely used approach, suffers from recognition errors due to speaker assignment failures. Although incorporating auxiliary information, such as token-level timestamps, can improve recognition accuracy, extracting such information from natural conversational speech remains challenging. To address this limitation, we propose Speaker-Distinguishable CTC (SD-CTC), an extension of CTC that jointly assigns a token and its corresponding speaker label to each frame. We further integrate SD-CTC into the SOT framework, enabling the SOT model to learn speaker distinction using only overlapping speech and transcriptions. Experimental comparisons show that multi-task learning with SD-CTC and SOT reduces the error rate of the SOT model by 26% and achieves performance comparable to state-of-the-art methods relying on auxiliary information.
        ]]></description>
    </item>
    <item>
        <title>LeVo: High-Quality Song Generation with Multi-Preference Alignment</title>
        <link>https://arxiv.org/abs/2506.07520</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07520v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Shun Lei, Yaoxun Xu, Zhiwei Lin, Huaicheng Zhang, Wei Tan, Hangting Chen, Jianwei Yu, Yixuan Zhang, Chenyu Yang, Haina Zhu, Shuai Wang, Zhiyong Wu, Dong Yu</dc:creator>
        <description><![CDATA[
            这是一篇关于音频生成的论文。当前大语言模型虽提升了音乐生成能力，但现有方法在歌曲复杂创作和高质量数据稀缺问题下，存在音质、音乐性等方面局限。为此，研究人员提出基于语言模型的LeVo框架，由LeLM和音乐编解码器构成。LeLM能并行建模两种类型的标记，采用双解码器变压器和模块化扩展训练策略；还引入基于直接偏好优化的多偏好对齐方法。实验表明，LeVo在主客观指标上均优于现有方法。
            arXiv:2506.07520v1 Announce Type: new 
Abstract: Recent advances in large language models (LLMs) and audio language models have significantly improved music generation, particularly in lyrics-to-song generation. However, existing approaches still struggle with the complex composition of songs and the scarcity of high-quality data, leading to limitations in sound quality, musicality, instruction following, and vocal-instrument harmony. To address these challenges, we introduce LeVo, an LM-based framework consisting of LeLM and a music codec. LeLM is capable of parallelly modeling two types of tokens: mixed tokens, which represent the combined audio of vocals and accompaniment to achieve vocal-instrument harmony, and dual-track tokens, which separately encode vocals and accompaniment for high-quality song generation. It employs two decoder-only transformers and a modular extension training strategy to prevent interference between different token types. To further enhance musicality and instruction following, we introduce a multi-preference alignment method based on Direct Preference Optimization (DPO). This method handles diverse human preferences through a semi-automatic data construction process and DPO post-training. Experimental results demonstrate that LeVo consistently outperforms existing methods on both objective and subjective metrics. Ablation studies further justify the effectiveness of our designs. Audio examples are available at https://levo-demo.github.io/.
        ]]></description>
    </item>
    <item>
        <title>Generative Voice Bursts during Phone Call</title>
        <link>https://arxiv.org/abs/2506.07526</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07526v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Paritosh Ranjan, Surajit Majumder, Prodip Roy</dc:creator>
        <description><![CDATA[
            背景：常规移动电话在紧急情况下，无法向正在通话的被叫方传达紧急语音信息，标准呼叫等待提醒也无法体现等待呼叫的紧迫性和内容。方法：提出在通话中传输生成式语音突发短音频消息的新方法，利用生成式AI技术，根据位置、健康数据等上下文输入自动生成语音消息，结合语音、文本和优先级推断机制，采用GPT Neo等模型生成文本并合成音频，按可配置间隔和次数发送。效果：有望在电信、移动设备制造和应急通信平台产生重大影响。
            arXiv:2506.07526v1 Announce Type: new 
Abstract: In critical situations, conventional mobile telephony fails to convey emergency voice messages to a callee already engaged in another call. The standard call waiting alert does not provide the urgency or content of the waiting call. This paper proposes a novel method for transmitting Generative Voice Bursts short, context aware audio messages during ongoing calls, from either preauthorized or dynamically prioritized callers. By leveraging generative AI techniques, the system automatically generates spoken messages from contextual inputs example like location, health data, images, background noise when the caller is unable to speak due to incapacitation or environmental constraints. The solution incorporates voice, text, and priority inference mechanisms, allowing high priority emergency messages to bypass conventional call waiting barriers. The approach employs models such as GPT Neo for generative text, which is synthesized into audio and delivered in configurable intervals G seconds and counts N times, ensuring minimal disruption while preserving urgency. This method holds potential for significant impact across telecom, mobile device manufacturing, and emergency communication platforms.
        ]]></description>
    </item>
    <item>
        <title>SongBloom: Coherent Song Generation via Interleaved Autoregressive Sketching and Diffusion Refinement</title>
        <link>https://arxiv.org/abs/2506.07634</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.07634v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chenyu Yang, Shuai Wang, Hangting Chen, Wei Tan, Jianwei Yu, Haizhou Li</dc:creator>
        <description><![CDATA[
            在歌曲生成中，生成结构连贯、乐器和人声元素和谐的音乐是一大挑战，现有语言模型和基于扩散的方法难以平衡全局连贯性和局部保真度。本文提出SongBloom框架，采用自回归草图绘制和基于扩散的细化交错范式。它结合扩散模型的高保真度和语言模型的可扩展性，从短到长扩展音乐草图，从粗到细细化细节。实验表明，SongBloom在主客观指标上均优于现有方法，性能与最先进的商业音乐生成平台相当。
            arXiv:2506.07634v1 Announce Type: new 
Abstract: Generating music with coherent structure, harmonious instrumental and vocal elements remains a significant challenge in song generation. Existing language models and diffusion-based methods often struggle to balance global coherence with local fidelity, resulting in outputs that lack musicality or suffer from incoherent progression and mismatched lyrics. This paper introduces $\textbf{SongBloom}$, a novel framework for full-length song generation that leverages an interleaved paradigm of autoregressive sketching and diffusion-based refinement. SongBloom employs an autoregressive diffusion model that combines the high fidelity of diffusion models with the scalability of language models. Specifically, it gradually extends a musical sketch from short to long and refines the details from coarse to fine-grained. The interleaved generation paradigm effectively integrates prior semantic and acoustic context to guide the generation process. Experimental results demonstrate that SongBloom outperforms existing methods across both subjective and objective metrics and achieves performance comparable to the state-of-the-art commercial music generation platforms. Audio samples are available on our demo page: https://cypress-yang.github.io/SongBloom\_demo.
        ]]></description>
    </item>
    <item>
        <title>TESU-LLM: Training Speech-LLMs Without Speech via Unified Encoder Alignment</title>
        <link>https://arxiv.org/abs/2506.06343</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06343v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Taesoo Kim, Jong Hwan Ko</dc:creator>
        <description><![CDATA[
            现有语音语言模型大多依赖大规模语音-文本配对数据和大量计算资源，在可扩展性和可及性方面存在挑战。本文提出TESU - LLM框架，仅用文本数据训练具备语音处理能力的语言模型。其关键在于利用统一编码器将语义等价的文本和语音输入映射到共享潜在空间，通过轻量级投影网络使编码器输出与大语言模型的嵌入空间对齐。该模型仅用文本训练，在多个语音相关基准测试中表现出色，效果与使用大规模多模态数据集和大量计算资源训练的基线方法相当，证明了方法的有效性和高效性。
            arXiv:2506.06343v1 Announce Type: cross 
Abstract: Recent advances in speech-enabled language models have shown promising results in building intelligent voice assistants. However, most existing approaches rely on large-scale paired speech-text data and extensive computational resources, which pose challenges in terms of scalability and accessibility. In this paper, we present \textbf{TESU-LLM}, a novel framework that enables training speech-capable language models using only text data. Our key insight is to leverage a unified encoder that maps semantically equivalent text and speech inputs to a shared latent space. By aligning the encoder output with the embedding space of a LLM via a lightweight projection network, we enable the model to generalize from text-only supervision to speech-based inference. Despite being trained exclusively on text, TESU-LLM achieves strong performance on various speech-related benchmarks, comparable to baseline methods trained with large-scale multimodal datasets and substantial computational resources. These results highlight the effectiveness and efficiency of our approach, offering a scalable path toward building speech LLMs without speech data.
        ]]></description>
    </item>
    <item>
        <title>Beyond Classification: Towards Speech Emotion Reasoning with Multitask AudioLLMs</title>
        <link>https://arxiv.org/abs/2506.06820</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.06820v1</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Wenyu Zhang, Yingxu He, Geyu Lin, Zhuohan Liu, Shuo Sun, Bin Wang, Xunlong Zou, Jeremy H. M. Wong, Qiongqiong Wang, Hardik B. Sailor, Nancy F. Chen, Ai Ti Aw</dc:creator>
        <description><![CDATA[
            背景：音频大语言模型（AudioLLMs）在语音识别和翻译等语义任务表现出色，但在情感等副语言线索建模上有限，现有方法多将情感理解视为分类问题。方法：提出情感推理策略，利用AudioLLMs生成能力，结合推理增强的数据监督、双编码器架构和任务交替训练的统一框架。效果：在IEMOCAP和MELD数据集实验表明，该方法提高了情感预测准确率，增强了生成响应的连贯性和证据支撑。
            arXiv:2506.06820v1 Announce Type: cross 
Abstract: Audio Large Language Models (AudioLLMs) have achieved strong results in semantic tasks like speech recognition and translation, but remain limited in modeling paralinguistic cues such as emotion. Existing approaches often treat emotion understanding as a classification problem, offering little insight into the underlying rationale behind predictions. In this work, we explore emotion reasoning, a strategy that leverages the generative capabilities of AudioLLMs to enhance emotion recognition by producing semantically aligned, evidence-grounded explanations. To support this in multitask AudioLLMs, we introduce a unified framework combining reasoning-augmented data supervision, dual-encoder architecture, and task-alternating training. This approach enables AudioLLMs to effectively learn different tasks while incorporating emotional reasoning. Experiments on IEMOCAP and MELD show that our approach not only improves emotion prediction accuracy but also enhances the coherence and evidential grounding of the generated responses.
        ]]></description>
    </item>
    <item>
        <title>LLaSE-G1: Incentivizing Generalization Capability for LLaMA-based Speech Enhancement</title>
        <link>https://arxiv.org/abs/2503.00493</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.00493v3</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Boyi Kang, Xinfa Zhu, Zihan Zhang, Zhen Ye, Mingshuai Liu, Ziqian Wang, Yike Zhu, Guobin Ma, Jun Chen, Longshuai Xiao, Chao Weng, Wei Xue, Lei Xie</dc:creator>
        <description><![CDATA[
            背景：当前基于语言模型的语音增强方法多关注语义信息，忽略声学信息，导致增强后声学不一致且泛化能力有限。方法：提出基于LLaMA的语言模型LLaSE - G1，用WavLM的连续表征作输入、预测X - Codec2的语音标记以减少声学不一致；引入双通道输入输出，统一多语音增强任务。效果：优于之前特定任务的判别和生成式语音增强模型，测试时有缩放效应，对未见任务有新兴能力，还开源代码和模型支持后续研究。
            arXiv:2503.00493v3 Announce Type: replace 
Abstract: Recent advancements in language models (LMs) have demonstrated strong capabilities in semantic understanding and contextual modeling, which have flourished in generative speech enhancement (SE). However, many LM-based SE approaches primarily focus on semantic information, often neglecting the critical role of acoustic information, which leads to acoustic inconsistency after enhancement and limited generalization across diverse SE tasks. In this paper, we introduce LLaSE-G1, a LLaMA-based language model that incentivizes generalization capabilities for speech enhancement. LLaSE-G1 offers the following key contributions: First, to mitigate acoustic inconsistency, LLaSE-G1 employs continuous representations from WavLM as input and predicts speech tokens from X-Codec2, maximizing acoustic preservation. Second, to promote generalization capability, LLaSE-G1 introduces dual-channel inputs and outputs, unifying multiple SE tasks without requiring task-specific IDs. Third, LLaSE-G1 outperforms prior task-specific discriminative and generative SE models, demonstrating scaling effects at test time and emerging capabilities for unseen SE tasks. Additionally, we release our code and models to support further research in this area.
        ]]></description>
    </item>
    <item>
        <title>A Hypernetwork-Based Approach to KAN Representation of Audio Signals</title>
        <link>https://arxiv.org/abs/2503.02585</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.02585v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Patryk Marsza{\l}ek, Maciej Rut, Piotr Kawa, Przemys{\l}aw Spurek, Piotr Syga</dc:creator>
        <description><![CDATA[
            这是一篇关于音频表示的研究。背景是隐式神经表示（INR）在音频信号中的应用有限。方法上，提出了使用可学习激活函数的Kolmogorov - Arnold Network（KAN）作为有效的音频表示INR模型，并提出基于超网络的FewSound架构来增强INR参数更新。效果方面，KAN在感知性能上优于以往INR，1.5秒音频的Log - SpectralDistance低至1.29，Perceptual Evaluation of Speech Quality高达3.57；FewSound在MSE上比HyperSound提升33.3%，在SI - SNR上提升60.87%。
            arXiv:2503.02585v2 Announce Type: replace 
Abstract: Implicit neural representations (INR) have gained prominence for efficiently encoding multimedia data, yet their applications in audio signals remain limited. This study introduces the Kolmogorov-Arnold Network (KAN), a novel architecture using learnable activation functions, as an effective INR model for audio representation. KAN demonstrates superior perceptual performance over previous INRs, achieving the lowest Log-SpectralDistance of 1.29 and the highest Perceptual Evaluation of Speech Quality of 3.57 for 1.5 s audio. To extend KAN's utility, we propose FewSound, a hypernetwork-based architecture that enhances INR parameter updates. FewSound outperforms the state-of-the-art HyperSound, with a 33.3% improvement in MSE and 60.87% in SI-SNR. These results show KAN as a robust and adaptable audio representation with the potential for scalability and integration into various hypernetwork frameworks. The source code can be accessed at https://github.com/gmum/fewsound.git.
        ]]></description>
    </item>
    <item>
        <title>Baseline Systems and Evaluation Metrics for Spatial Semantic Segmentation of Sound Scenes</title>
        <link>https://arxiv.org/abs/2503.22088</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.22088v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Binh Thien Nguyen, Masahiro Yasuda, Daiki Takeuchi, Daisuke Niizumi, Yasunori Ohishi, Noboru Harada</dc:creator>
        <description><![CDATA[
            背景：沉浸式通信发展显著，DCASE 2025 挑战引入空间语义分割声音场景（S5）任务。方法：本文探索解决 S5 任务的方法，提出结合音频标记（AT）和标签查询源分离（LSS）模型的基线 S5 系统，研究基于 ResUNet 架构的两种 LSS 方法，还提出新的类感知指标以同时评估声源和标签。效果：在一阶环绕声空间音频上的实验结果证明了所提系统的有效性，也证实了指标的功效。
            arXiv:2503.22088v2 Announce Type: replace 
Abstract: Immersive communication has made significant advancements, especially with the release of the codec for Immersive Voice and Audio Services. Aiming at its further realization, the DCASE 2025 Challenge has recently introduced a task for spatial semantic segmentation of sound scenes (S5), which focuses on detecting and separating sound events in spatial sound scenes. In this paper, we explore methods for addressing the S5 task. Specifically, we present baseline S5 systems that combine audio tagging (AT) and label-queried source separation (LSS) models. We investigate two LSS approaches based on the ResUNet architecture: a) extracting a single source for each detected event and b) querying multiple sources concurrently. Since each separated source in S5 is identified by its sound event class label, we propose new class-aware metrics to evaluate both the sound sources and labels simultaneously. Experimental results on first-order ambisonics spatial audio demonstrate the effectiveness of the proposed systems and confirm the efficacy of the metrics.
        ]]></description>
    </item>
    <item>
        <title>FLAM: Frame-Wise Language-Audio Modeling</title>
        <link>https://arxiv.org/abs/2505.05335</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2505.05335v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Yusong Wu, Christos Tsirigotis, Ke Chen, Cheng-Zhi Anna Huang, Aaron Courville, Oriol Nieto, Prem Seetharaman, Justin Salamon</dc:creator>
        <description><![CDATA[
            背景：现有多模态音频语言模型在逐帧音频理解上存在不足，传统声音事件检测模型又局限于预定义类别。方法：本文提出FLAM，这是一种开放词汇的对比音频语言模型，采用内存高效且经过校准的逐帧目标和对数调整，以解决训练中的虚假关联问题，还利用含多样音频事件的大规模数据集、大语言模型生成的字幕及模拟来实现逐帧监督。效果：实验和案例表明，FLAM显著提升开放词汇定位能力，且在全局检索和下游任务中表现出色。
            arXiv:2505.05335v2 Announce Type: replace 
Abstract: Recent multi-modal audio-language models (ALMs) excel at text-audio retrieval but struggle with frame-wise audio understanding. Prior works use temporal-aware labels or unsupervised training to improve frame-wise capabilities, but they still lack fine-grained labeling capability to pinpoint when an event occurs. While traditional sound event detection models can precisely localize events, they are limited to pre-defined categories, making them ineffective for real-world scenarios with out-of-distribution events. In this work, we introduce FLAM, an open-vocabulary contrastive audio-language model capable of localizing specific sound events. FLAM employs a memory-efficient and calibrated frame-wise objective with logit adjustment to address spurious correlations, such as event dependencies and label imbalances during training. To enable frame-wise supervision, we leverage a large-scale dataset with diverse audio events, LLM-generated captions and simulation. Experimental results and case studies demonstrate that FLAM significantly improves the open-vocabulary localization capability while maintaining strong performance in global retrieval and downstream tasks.
        ]]></description>
    </item>
    <item>
        <title>Dynamic-SUPERB Phase-2: A Collaboratively Expanding Benchmark for Measuring the Capabilities of Spoken Language Models with 180 Tasks</title>
        <link>https://arxiv.org/abs/2411.05361</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2411.05361v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Chien-yu Huang, Wei-Chih Chen, Shu-wen Yang, Andy T. Liu, Chen-An Li, Yu-Xiang Lin, Wei-Cheng Tseng, Anuj Diwan, Yi-Jen Shih, Jiatong Shi, William Chen, Chih-Kai Yang, Wenze Ren, Xuanjun Chen, Chi-Yuan Hsiao, Puyuan Peng, Shih-Heng Wang, Chun-Yi Kuan, Ke-Han Lu, Kai-Wei Chang, Fabian Ritter-Gutierrez, Kuan-Po Huang, Siddhant Arora, You-Kuan Lin, Ming To Chuang, Eunjung Yeo, Kalvin Chang, Chung-Ming Chien, Kwanghee Choi, Jun-You Wang, Cheng-Hsiu Hsieh, Yi-Cheng Lin, Chee-En Yu, I-Hsiang Chiu, Heitor R. Guimar\~aes, Jionghao Han, Tzu-Quan Lin, Tzu-Yuan Lin, Homu Chang, Ting-Wu Chang, Chun Wei Chen, Shou-Jen Chen, Yu-Hua Chen, Hsi-Chun Cheng, Kunal Dhawan, Jia-Lin Fang, Shi-Xin Fang, Kuan-Yu Fang Chiang, Chi An Fu, Hsien-Fu Hsiao, Ching Yu Hsu, Shao-Syuan Huang, Lee Chen Wei, Hsi-Che Lin, Hsuan-Hao Lin, Hsuan-Ting Lin, Jian-Ren Lin, Ting-Chun Liu, Li-Chun Lu, Tsung-Min Pai, Ankita Pasad, Shih-Yun Shan Kuan, Suwon Shon, Yuxun Tang, Yun-Shao Tsai, Jui-Chiang Wei, Tzu-Chieh Wei, Chengxi Wu, Dien-Ruei Wu, Chao-Han Huck Yang, Chieh-Chi Yang, Jia Qi Yip, Shao-Xiang Yuan, Vahid Noroozi, Zhehuai Chen, Haibin Wu, Karen Livescu, David Harwath, Shinji Watanabe, Hung-yi Lee</dc:creator>
        <description><![CDATA[
            背景：多模态基础模型虽革新人机交互，但缺乏全面评估基准阻碍通用口语模型发展。方法：提出Dynamic - SUPERB Phase - 2，在第一代基础上新增125个全球研究社区协作贡献的任务，共180个任务，且拓宽评估能力，涵盖多种新任务。效果：评估结果显示无模型能普遍表现良好，SALMONN - 13B在英语自动语音识别中出色，Qwen2 - Audio - 7B - Instruct在情感识别中准确率高，但现有模型仍需创新以处理更多任务，相关数据和评估流程已开源。
            arXiv:2411.05361v2 Announce Type: replace-cross 
Abstract: Multimodal foundation models, such as Gemini and ChatGPT, have revolutionized human-machine interactions by seamlessly integrating various forms of data. Developing a universal spoken language model that comprehends a wide range of natural language instructions is critical for bridging communication gaps and facilitating more intuitive interactions. However, the absence of a comprehensive evaluation benchmark poses a significant challenge. We present Dynamic-SUPERB Phase-2, an open and evolving benchmark for the comprehensive evaluation of instruction-based universal speech models. Building upon the first generation, this second version incorporates 125 new tasks contributed collaboratively by the global research community, expanding the benchmark to a total of 180 tasks, making it the largest benchmark for speech and audio evaluation. While the first generation of Dynamic-SUPERB was limited to classification tasks, Dynamic-SUPERB Phase-2 broadens its evaluation capabilities by introducing a wide array of novel and diverse tasks, including regression and sequence generation, across speech, music, and environmental audio. Evaluation results show that no model performed well universally. SALMONN-13B excelled in English ASR and Qwen2-Audio-7B-Instruct showed high accuracy in emotion recognition, but current models still require further innovations to handle a broader range of tasks. We open-source all task data and the evaluation pipeline at https://github.com/dynamic-superb/dynamic-superb.
        ]]></description>
    </item>
    <item>
        <title>RestoreGrad: Signal Restoration Using Conditional Denoising Diffusion Models with Jointly Learned Prior</title>
        <link>https://arxiv.org/abs/2502.13574</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2502.13574v3</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Ching-Hua Lee, Chouchang Yang, Jaejin Cho, Yashas Malur Saidutta, Rakshith Sharma Srinivasa, Yilin Shen, Hongxia Jin</dc:creator>
        <description><![CDATA[
            这是一篇关于音频生成中基础音频生成模型的研究。背景是现有条件去噪扩散概率模型（DDPMs）在信号恢复时采用标准高斯作为先验分布，会丢弃退化信号中关于目标干净数据分布的有用信息，导致性能不佳。方法是提出RestoreGrad框架，将DDPMs集成到变分自编码器（VAE）框架中，联合学习更具信息性的先验。效果是在语音和图像恢复任务上，比现有DDPM基线收敛更快（训练步数少5 - 10倍），推理时使用更少采样步数的鲁棒性更好（少2 - 2.5倍）。
            arXiv:2502.13574v3 Announce Type: replace-cross 
Abstract: Denoising diffusion probabilistic models (DDPMs) can be utilized to recover a clean signal from its degraded observation(s) by conditioning the model on the degraded signal. The degraded signals are themselves contaminated versions of the clean signals; due to this correlation, they may encompass certain useful information about the target clean data distribution. However, existing adoption of the standard Gaussian as the prior distribution in turn discards such information when shaping the prior, resulting in sub-optimal performance. In this paper, we propose to improve conditional DDPMs for signal restoration by leveraging a more informative prior that is jointly learned with the diffusion model. The proposed framework, called RestoreGrad, seamlessly integrates DDPMs into the variational autoencoder (VAE) framework, taking advantage of the correlation between the degraded and clean signals to encode a better diffusion prior. On speech and image restoration tasks, we show that RestoreGrad demonstrates faster convergence (5-10 times fewer training steps) to achieve better quality of restored signals over existing DDPM baselines and improved robustness to using fewer sampling steps in inference time (2-2.5 times fewer), advocating the advantages of leveraging jointly learned prior for efficiency improvements in the diffusion process.
        ]]></description>
    </item>
    <item>
        <title>Imagine to Hear: Auditory Knowledge Generation can be an Effective Assistant for Language Models</title>
        <link>https://arxiv.org/abs/2503.16853</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2503.16853v2</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Suho Yoo, Hyunjong Ok, Jaeho Lee</dc:creator>
        <description><![CDATA[
            这是一篇关于音频生成领域中能够处理音频的大语言模型的研究。仅在文本语料库上预训练的语言模型处理需要听觉常识知识的任务时表现不佳，以往通过从外部音频数据库检索知识的方法存在局限。为此，提出Imagine to Hear方法，利用生成模型动态生成听觉知识，框架能从给定提示中检测多个与音频相关的文本片段并生成对应知识，还开发了处理机制。实验表明，该方法在AuditoryBench上不依赖外部数据库就达到了最先进水平。
            arXiv:2503.16853v2 Announce Type: replace-cross 
Abstract: Language models pretrained on text-only corpora often struggle with tasks that require auditory commonsense knowledge. Previous work addresses this problem by augmenting the language model to retrieve knowledge from external audio databases. This approach has several limitations, such as the potential lack of relevant audio in databases and the high costs associated with constructing the databases. To address these issues, we propose Imagine to Hear, a novel approach that dynamically generates auditory knowledge using generative models. Our framework detects multiple audio-related textual spans from the given prompt and generates corresponding auditory knowledge. We develop several mechanisms to efficiently process multiple auditory knowledge, including a CLAP-based rejection sampler and a language-audio fusion module. Our experiments show that our method achieves state-of-the-art performance on AuditoryBench without relying on external databases, highlighting the effectiveness of our generation-based approach.
        ]]></description>
    </item>
    <item>
        <title>NTPP: Generative Speech Language Modeling for Dual-Channel Spoken Dialogue via Next-Token-Pair Prediction</title>
        <link>https://arxiv.org/abs/2506.00975</link>
        <guid isPermaLink="false">oai:arXiv.org:oai:arXiv.org:2506.00975v3</guid>
        <category>我关注的研究话题是：1) 音频分类，包括Audioset/DCASE等数据集上有关audio tagging/sound event detection的工作，尤其是与Audioset Ontology相关的研究。2) 音频生成，包括：a）基础音频生成模型，包括Diffusion、Flow、VQGAN等；b）能够处理音频的LLM，包括音频的tokenization、音频的prompt、音频的上下文学习等。</category>
        <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
        <arxiv:announce_type>new</arxiv:announce_type>
        <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
        <dc:creator>Qichao Wang, Ziqiao Meng, Wenqian Cui, Yifei Zhang, Pengcheng Wu, Bingzhe Wu, Irwin King, Liang Chen, Peilin Zhao</dc:creator>
        <description><![CDATA[
            背景：受GPT - 4o能力启发，人们对语音语言模型（SLMs）实现自然流畅人机对话兴趣渐浓，但现有方法未充分利用双通道语音数据。方法：系统探索在现代大语言模型中使用双通道语音数据，提出Next - Token - Pair Prediction（NTPP）生成建模范式，首次用仅解码器架构实现与说话者无关的双通道口语对话学习。效果：在标准基准测试中，NTPP显著提升SLMs对话能力，且推理延迟更低，适合实时应用。
            arXiv:2506.00975v3 Announce Type: replace-cross 
Abstract: Inspired by the impressive capabilities of GPT-4o, there is growing interest in enabling speech language models (SLMs) to engage in natural, fluid spoken interactions with humans. Recent advancements have led to the development of several SLMs that demonstrate promising results in this area. However, current approaches have yet to fully exploit dual-channel speech data, which inherently captures the structure and dynamics of human conversation. In this work, we systematically explore the use of dual-channel speech data in the context of modern large language models, and introduce a novel generative modeling paradigm, Next-Token-Pair Prediction (NTPP), to enable speaker-independent dual-channel spoken dialogue learning using decoder-only architectures for the first time. We evaluate our approach on standard benchmarks, and empirical results show that our proposed method, NTPP, significantly improves the conversational abilities of SLMs in terms of turn-taking prediction, response coherence, and naturalness. Moreover, compared to existing methods, NTPP achieves substantially lower inference latency, highlighting its practical efficiency for real-time applications.
        ]]></description>
    </item>
</channel>
</rss>